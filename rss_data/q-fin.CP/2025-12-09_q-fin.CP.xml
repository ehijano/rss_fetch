<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Dec 2025 02:44:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Market Reactions and Information Spillovers in Bank Mergers: A Multi-Method Analysis of the Japanese Banking Sector</title>
      <link>https://arxiv.org/abs/2512.06550</link>
      <description>arXiv:2512.06550v1 Announce Type: new 
Abstract: Major bank mergers and acquisitions (M&amp;A) transform the financial market structure, but their valuation and spillover effects remain open to question. This study examines the market reaction to two M&amp;A events: the 2005 creation of Mitsubishi UFJ Financial Group following the Financial Big Bang in Japan, and the 2018 merger involving Resona Holdings after the global financial crisis. The multi-method analysis in this research combines several distinct methods to explore these M&amp;A events. An event study using the market model, the capital asset pricing model (CAPM), and the Fama-French three-factor model is implemented to estimate cumulative abnormal returns (CAR) for valuation purposes. Vector autoregression (VAR) models are used to test for Granger causality and map dynamic effects using impulse response functions (IRFs) to investigate spillovers. Propensity score matching (PSM) helps provide a causal estimate of the average treatment effect on the treated (ATT). The analysis detected a significant positive market reaction to the mergers. The findings also suggest the presence of prolonged positive spillovers to other banks, which may indicate a synergistic effect among Japanese banks. Combining these methods provides a unique perspective on M&amp;A events in the Japanese banking sector, offering valuable insights for investors, managers, and regulators concerned with market efficiency and systemic stability</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06550v1</guid>
      <category>q-fin.CP</category>
      <category>econ.EM</category>
      <category>q-fin.PM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Takeshi Tsuyuguchi</dc:creator>
    </item>
    <item>
      <title>Unveiling Hedge Funds: Topic Modeling and Sentiment Correlation with Fund Performance</title>
      <link>https://arxiv.org/abs/2512.06620</link>
      <description>arXiv:2512.06620v1 Announce Type: new 
Abstract: The hedge fund industry presents significant challenges for investors due to its opacity and limited disclosure requirements. This pioneering study introduces two major innovations in financial text analysis. First, we apply topic modeling to hedge fund documents-an unexplored domain for automated text analysis-using a unique dataset of over 35,000 documents from 1,125 hedge fund managers. We compared three state-of-the-art methods: Latent Dirichlet Allocation (LDA), Top2Vec, and BERTopic. Our findings reveal that LDA with 20 topics produces the most interpretable results for human users and demonstrates higher robustness in topic assignments when the number of topics varies, while Top2Vec shows superior classification performance. Second, we establish a novel quantitative framework linking document sentiment to fund performance, transforming qualitative information traditionally requiring expert interpretation into systematic investment signals. In sentiment analysis, contrary to expectations, the general-purpose DistilBERT outperforms the finance-specific FinBERT in generating sentiment scores, demonstrating superior adaptability to diverse linguistic patterns found in hedge fund documents that extend beyond specialized financial news text. Furthermore, sentiment scores derived using DistilBERT in combination with Top2Vec show stronger correlations with subsequent fund performance compared to other model combinations. These results demonstrate that automated topic modeling and sentiment analysis can effectively process hedge fund documents, providing investors with new data-driven decision support tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06620v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chang Liu</dc:creator>
    </item>
    <item>
      <title>DeepSVM: Learning Stochastic Volatility Models with Physics-Informed Deep Operator Networks</title>
      <link>https://arxiv.org/abs/2512.07162</link>
      <description>arXiv:2512.07162v1 Announce Type: new 
Abstract: Real-time calibration of stochastic volatility models (SVMs) is computationally bottlenecked by the need to repeatedly solve coupled partial differential equations (PDEs). In this work, we propose DeepSVM, a physics-informed Deep Operator Network (PI-DeepONet) designed to learn the solution operator of the Heston model across its entire parameter space. Unlike standard data-driven deep learning (DL) approaches, DeepSVM requires no labelled training data. Rather, we employ a hard-constrained ansatz that enforces terminal payoffs and static no-arbitrage conditions by design. Furthermore, we use Residual-based Adaptive Refinement (RAR) to stabilize training in difficult regions subject to high gradients. Overall, DeepSVM achieves a final training loss of $10^{-5}$ and predicts highly accurate option prices across a range of typical market dynamics. While pricing accuracy is high, we find that the model's derivatives (Greeks) exhibit noise in the at-the-money (ATM) regime, highlighting the specific need for higher-order regularization in physics-informed operator learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07162v1</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kieran A. Malandain, Selim Kalici, Hakob Chakhoyan</dc:creator>
    </item>
    <item>
      <title>BondBERT: What we learn when assigning sentiment in the bond market</title>
      <link>https://arxiv.org/abs/2511.01869</link>
      <description>arXiv:2511.01869v2 Announce Type: replace 
Abstract: Bond markets respond differently to macroeconomic news compared to equity markets, yet most sentiment models are trained primarily on general financial or equity news data. However, bond prices often move in the opposite direction to economic optimism, making general or equity-based sentiment tools potentially misleading. We introduce BondBERT, a transformer-based language model fine-tuned on bond-specific news. BondBERT can act as the perception and reasoning component of a financial decision-support agent, providing sentiment signals that integrate with forecasting models. We propose a generalisable framework for adapting transformers to low-volatility, domain-inverse sentiment tasks by compiling and cleaning 30,000 UK bond market articles (2018-2025). BondBERT's sentiment predictions are compared against FinBERT, FinGPT, and Instruct-FinGPT using event-based correlation, up/down accuracy analyses, and LSTM forecasting across ten UK sovereign bonds. We find that BondBERT consistently produces positive correlations with bond returns, and achieves higher alignment and forecasting accuracy than the three baseline models. These results demonstrate that domain-specific sentiment adaptation better captures fixed income dynamics, bridging a gap between NLP advances and bond market analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01869v2</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toby Barter, Zheng Gao, Eva Christodoulaki, Jing Chen, John Cartlidge</dc:creator>
    </item>
    <item>
      <title>Optimal Investment, Consumption, and Insurance with Durable Goods under Stochastic Depreciation Risk</title>
      <link>https://arxiv.org/abs/1903.00631</link>
      <description>arXiv:1903.00631v2 Announce Type: replace-cross 
Abstract: We study an infinite-horizon optimal investment, consumption and insurance problem for an economic agent who consumes a perishable and a durable good. The agent trades in a risk-free asset, a risky asset, and a durable good whose price follows a correlated diffusion, while the stock of the durable good depreciates deterministically and is subject to insurable Poisson loss shocks. The agent can partially hedge these shocks via an insurance contract with loading and chooses optimal perishable consumption, portfolio holdings, and insurance coverage to maximise expected discounted CRRA utility. Exploiting the homogeneity of the problem, we reduce the Hamilton--Jacobi--Bellman equation to a static one-dimensional optimisation over constant portfolio shares and derive a semi-explicit optimal strategy. We then prove a verification theorem for the associated jump-diffusion wealth process with insurance, establishing the existence and optimality of this constant-fraction strategy under explicit transversality conditions for both risk-aversion regimes $0&lt;\gamma&lt;1$ and $\gamma&gt;1$. Numerical experiments illustrate the impact of stochastic depreciation risk and insurance loading on the optimal allocation to financial assets, durable goods, and insurance coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:1903.00631v2</guid>
      <category>econ.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Arandjelovi\'c, Ryle S. Perera, Pavel V. Shevchenko, Tak Kuen Siu, Jin Sun</dc:creator>
    </item>
    <item>
      <title>Exploiting Supply Chain Interdependencies for Stock Return Prediction: A Full-State Graph Convolutional LSTM</title>
      <link>https://arxiv.org/abs/2303.09406</link>
      <description>arXiv:2303.09406v2 Announce Type: replace-cross 
Abstract: Stock return prediction is fundamental to financial decision-making, yet traditional time series models fail to capture the complex interdependencies between companies in modern markets. We propose the Full-State Graph Convolutional LSTM (FS-GCLSTM), a novel temporal graph neural network that incorporates value-chain relationships to enhance stock return forecasting. Our approach features two key innovations: First, we represent inter-firm dependencies through value-chain networks, where nodes correspond to companies and edges capture supplier-customer relationships, enabling the model to leverage information beyond historical price data. Second, FS-GCLSTM applies graph convolutions to all LSTM components - current input features, previous hidden states, and cell states - ensuring that spatial information from the value-chain network influences every aspect of the temporal update mechanism. We evaluate FS-GCLSTM on Eurostoxx 600 and S&amp;P 500 datasets using LSEG value-chain data. While not achieving the lowest traditional prediction errors, FS-GCLSTM consistently delivers superior portfolio performance, attaining the highest annualized returns, Sharpe ratios, and Sortino ratios across both markets. Performance gains are more pronounced in the denser Eurostoxx 600 network, and robustness tests confirm stability across different input sequence lengths, demonstrating the practical value of integrating value-chain data with temporal graph neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.09406v2</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chang Liu</dc:creator>
    </item>
    <item>
      <title>Order-Flow Filtration and Directional Association with Short-Horizon Returns</title>
      <link>https://arxiv.org/abs/2507.22712</link>
      <description>arXiv:2507.22712v2 Announce Type: replace-cross 
Abstract: Electronic markets generate dense order flow with many transient orders, which degrade directional signals derived from the limit order book (LOB). We study whether simple structural filters on order lifetime, modification count, and modification timing sharpen the association between order book imbalance (OBI) and short-horizon returns in BankNifty index futures, where unfiltered OBI is already known to be a strong short-horizon directional indicator. The efficacy of each filter is evaluated using a three-step diagnostic ladder: contemporaneous correlations, linear association between discretised regimes, and Hawkes event-time excitation between OBI and return regimes. Our results indicate that filtration of the aggregate order flow produces only modest changes relative to the unfiltered benchmark. By contrast, when filters are applied on the parent orders of executed trades, the resulting OBI series exhibits systematically stronger directional association. Motivated by recent regulatory initiatives to curb noisy order flow, we treat the association between OBI and short-horizon returns as a policy-relevant diagnostic of market quality. We then compare unfiltered and filtered OBI series, using tick-by-tick data from the National Stock Exchange of India, to infer how structural filters on the order flow affect OBI-return dynamics in an emerging market setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22712v2</guid>
      <category>q-fin.TR</category>
      <category>q-fin.CP</category>
      <category>q-fin.GN</category>
      <category>q-fin.ST</category>
      <category>stat.ME</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aditya Nittur Anantha, Shashi Jain, Prithwish Maiti</dc:creator>
    </item>
    <item>
      <title>Sharpening Shapley Allocation: from Basel 2.5 to FRTB</title>
      <link>https://arxiv.org/abs/2511.12391</link>
      <description>arXiv:2511.12391v2 Announce Type: replace-cross 
Abstract: Risk allocation, the decomposition of a portfolio-wide risk measure into component contributions, is a fundamental problem in financial risk management due to the non-additive nature of risk measures, the layered organizational structures of financial institutions, and the range of possible allocation strategies characterized by different rationales and properties.
  In this work, we conduct a systematic review of the major risk allocation strategies typically used in finance, comparing their theoretical properties, practical advantages, and limitations. To this scope we set up a specific testing framework, including both simplified settings, designed to highlight basic intrinsic behaviours, and realistic financial portfolios under different risk regulations, i.e. Basel 2.5 and FRTB. Furthermore, we develop and test novel practical solutions to manage the issue of negative risk allocations and of multi-level risk allocation in the layered organizational structure of financial institutions, while preserving the additivity property. Finally, we devote particular attention to the computational aspects of risk allocation.
  Our results show that, in this context, the Shapley allocation strategy offers the best compromise between simplicity, mathematical properties, risk representation and computational cost. The latter is still acceptable even in the challenging case of many business units, provided that an efficient Monte Carlo simulation is employed, which offers excellent scaling and convergence properties. While our empirical applications focus on market risk, our methodological framework is fully general and applicable to other financial context such as valuation risk, liquidity risk, credit risk, and counterparty credit risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12391v2</guid>
      <category>q-fin.RM</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Scaringi, Marco Bianchetti</dc:creator>
    </item>
    <item>
      <title>Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations</title>
      <link>https://arxiv.org/abs/2512.05156</link>
      <description>arXiv:2512.05156v2 Announce Type: replace-cross 
Abstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\bf Q}$ and ${\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05156v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Igor Halperin</dc:creator>
    </item>
  </channel>
</rss>
