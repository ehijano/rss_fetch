<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 04:01:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Secrecy Energy Efficiency Maximization in RIS-Aided Networks: Active or Nearly-Passive RIS?</title>
      <link>https://arxiv.org/abs/2507.07241</link>
      <description>arXiv:2507.07241v1 Announce Type: new 
Abstract: This work addresses the problem of secrecy energy efficiency (SEE) maximization in RIS-aided wireless networks. The use of active and nearly-passive RISs are compared and their trade-off in terms of SEE is analyzed. Considering both perfect and statistical channel state information, two SEE maximization algorithms are developed to optimize the transmit powers of the mobile users, the RIS reflection coefficients, and the base station receive filters. Numerical results quantify the trade-off between active and nearly-passive RISs in terms of SEE, with active RISs yielding worse SEE values as the static power consumed by each reflecting element increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07241v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Kuku Fotock, Agbotiname Lucky Imoize, Alessio Zappone, Marco Di Renzo, Roberto Garello</dc:creator>
    </item>
    <item>
      <title>Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path</title>
      <link>https://arxiv.org/abs/2507.07263</link>
      <description>arXiv:2507.07263v1 Announce Type: new 
Abstract: This work analyzes convergence times and robustness bounds for asynchronous distributed shortest-path computation. We focus on the Adaptive Bellman--Ford algorithm, a self-stabilizing method in which each agent updates its shortest-path estimate based only on the estimates of its neighbors and forgetting its previous estimate. In the asynchronous framework considered in this paper, agents are allowed to idle or encounter race conditions during their execution of the Adaptive Bellman--Ford algorithm. We build on Lyapunov-based results that develop finite-time convergence and robustness bounds for the synchronous shortest-path setting, in order to produce finite-time convergence and robustness bounds for the asynchronous setting. We also explore robustness against interval-bounded noise processes and establish convergence and robustness guarantees for asynchronous most-probable-path algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07263v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Mattia Bianchi, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence for the Last Iterate of Stochastic Gradient Descent Schemes</title>
      <link>https://arxiv.org/abs/2507.07281</link>
      <description>arXiv:2507.07281v1 Announce Type: new 
Abstract: We study the almost sure convergence rate for the last iterate of stochastic gradient descent (SGD) and stochastic heavy ball (SHB) in the parametric setting when the objective function $F$ is globally convex or non-convex whose gradient is $\gamma$-H\"{o}lder. Using only discrete Gronwall's inequality without Robbins-Siegmund theorem nor martingale convergence theory, we recover results for both SGD and SHB: $\min_{s\leq t} \|\nabla F(w_s)\|^2 = o(t^{p-1})$ for non-convex objectives and $F(w_t) - F_* = o(t^{2\gamma/(1+\gamma) \cdot \max(p-1,-2p+1)-\epsilon})$ for $\beta \in (0, 1)$ and $\min_{s \leq t} F(w_s) - F_* = o(t^{p-1})$ almost surely for convex objectives. In addition, we proved that SHB with constant momentum parameter $\beta \in (0, 1)$ attains a convergence rate of $F(w_t) - F_* = O(t^{\max(p-1,-2p+1)} \log^2 \frac{t}{\delta})$ with probability at least $1-\delta$ when $F$ is convex and $\gamma = 1$ and step size $\alpha_t = \Theta(t^{-p})$ with $p \in (\frac{1}{2}, 1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07281v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Hudiani</dc:creator>
    </item>
    <item>
      <title>Qualitative and Generalized Differentiation Properties of Optimal Value Functions with Applications to Duality</title>
      <link>https://arxiv.org/abs/2507.07377</link>
      <description>arXiv:2507.07377v1 Announce Type: new 
Abstract: In this paper, we investigate general and generalized differentiation properties of theoptimal value function associated with perturbed optimization problems. We begin with a comprehensive analysis of its effective domain, epigraph, strict epigraph, convexity, near convexity, continuity, and Lipschitz-type behavior, in both convex and nonconvex settings. Next, we propose a duality framework for constrained optimization problems with set-valued constraints, based on the notion of the Fenchel conjugate for set-valued mappings, which offers new insights into duality theory in a broad context. Finally, we compute the {\epsilon}-subdifferentials of the optimal value function and its Fenchel conjugate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07377v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vo Si Trong Long, Nguyen Mau Nam, Len White</dc:creator>
    </item>
    <item>
      <title>Relocated Fixed-Point Iterations with Applications to Variable Stepsize Resolvent Splitting</title>
      <link>https://arxiv.org/abs/2507.07428</link>
      <description>arXiv:2507.07428v1 Announce Type: new 
Abstract: In this work, we develop a convergence framework for iterative algorithms whose updates can be described by a one-parameter family of nonexpansive operators. Within the framework, each step involving one of the main algorithmic operators is followed by a second step which ''relocates'' fixed-points of the current operator to the next. As a consequence, our analysis does not require the family of nonexpansive operators to have a common fixed-point, as is common in the literature. Our analysis uses a parametric extension of the demiclosedness principle for nonexpansive operators. As an application of our convergence results, we develop a version of the graph-based extension of the Douglas--Rachford algorithm for finding a zero of the sum of $N\geq 2$ maximally monotone operators, which does not require the resolvent parameter to be constant across iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07428v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Atenas, Heinz H. Bauschke, Minh N. Dao, Matthew K. Tam</dc:creator>
    </item>
    <item>
      <title>On the local null controllability of a viscous Burgers' system in finite time</title>
      <link>https://arxiv.org/abs/2507.07442</link>
      <description>arXiv:2507.07442v1 Announce Type: new 
Abstract: This paper is devoted to the local null controllability of the Burgers control system $y_t - y_{xx} + y y_x = u(t)$ on a bounded interval imposed by the zero Dirichlet boundary condition. It is known from the work of Marbach that this control system is not locally null controllable in small time. In this paper, we prove that the system is not locally null controllable in finite time as well. Our approach is inspired by the works of Coron, Koenig, and Nguyen, and Nguyen on the controllability of the KdV system and is different from the one of Marbach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07442v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoai-Minh Nguyen, Minh-Nguyen Tran</dc:creator>
    </item>
    <item>
      <title>Combinatorial Algorithm for Tropical Linearly Factorized Programming</title>
      <link>https://arxiv.org/abs/2507.07596</link>
      <description>arXiv:2507.07596v1 Announce Type: new 
Abstract: The tropical semiring is a set of numbers $\mathbb{R}\cup\{-\infty\}$ with addition $a\oplus b:=\max(a,b)$ and multiplication $a\otimes b:=a+b$. As well as in conventional algebra, linear programming problem in the tropical semiring has been developed. In this study, we introduce a new type of tropical optimization problem, namely, tropical linearly factorized programming problem. This problem involves minimizing the objective function given by the product of tropical linear forms $c_{k,1}\otimes x_1\oplus \cdots\oplus c_{k,n}\otimes x_n$ divided by a tropical monomial, subject to tropical linear inequality constraints. The objective function is convex in the conventional sense but not in the tropical sense, while the feasible set is convex in the tropical sense but not in the conventional sense.
  Our algorithm for tropical linearly factorized programming is based on the descent method and exploits tangent digraphs. First, we demonstrate that the feasible descent direction at the current solution can be obtained by solving the minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph. Although exponentially many such digraphs may exist in general, a more efficient algorithm is devised in cases where the problem is non-degenerate. Focusing on the fact that tangent digraphs become spanning trees in non-degenerate cases, we present a simplex-like algorithm that updates the tree structure iteratively. We show that each iteration can be executed in $O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero'' coefficients in the linear constraints and objective function, respectively. For integer instances, our algorithm finds a local optimum in $O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision variables and constraints, respectively, $M$ is the maximum absolute value of coefficients and $D$ is the degree of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07596v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Nishida</dc:creator>
    </item>
    <item>
      <title>An Adaptive Order Caputo Fractional Gradient Descent Method for Multi-objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2507.07674</link>
      <description>arXiv:2507.07674v1 Announce Type: new 
Abstract: This article introduces the multi-objective adaptive order Caputo fractional gradient descent (MOAOCFGD) algorithm for solving unconstrained multi-objective problems. The proposed method performs equally well for both smooth and non-smooth multi-objective optimization problems. Moreover, the proposed method does not require any a priori chosen parameters or ordering information of the objective functions. At every iteration of the proposed method, a subproblem is solved to identify a suitable descent direction toward an optimal solution. This subproblem involves an adaptive-order Caputo fractional gradient for each objective function. An Armijo-type line search is applied to determine a suitable step length. The convergence of this method for the Tikhonov-regularized solution is justified under mild assumptions. The proposed method is verified using different numerical problems, including neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07674v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Barsha Shaw, Md Abu Talhamainuddin Ansary</dc:creator>
    </item>
    <item>
      <title>Efficient Stochastic BFGS methods Inspired by Bayesian Principles</title>
      <link>https://arxiv.org/abs/2507.07729</link>
      <description>arXiv:2507.07729v1 Announce Type: new 
Abstract: Quasi-Newton methods are ubiquitous in deterministic local search due to their efficiency and low computational cost. This class of methods uses the history of gradient evaluations to approximate second-order derivatives. However, only noisy gradient observations are accessible in stochastic optimization; thus, deriving quasi-Newton methods in this setting is challenging. Although most existing quasi-Newton methods for stochastic optimization rely on deterministic equations that are modified to circumvent noise, we propose a new approach inspired by Bayesian inference to assimilate noisy gradient information and derive the stochastic counterparts to standard quasi-Newton methods. We focus on the derivations of stochastic BFGS and L-BFGS, but our methodology can also be employed to derive stochastic analogs of other quasi-Newton methods. The resulting stochastic BFGS (S-BFGS) and stochastic L-BFGS (L-S-BFGS) can effectively learn an inverse Hessian approximation even with small batch sizes. For a problem of dimension $d$, the iteration cost of S-BFGS is $\bigO{d^2}$, and the cost of L-S-BFGS is $\bigO{d}$. Numerical experiments with a dimensionality of up to $30,720$ demonstrate the efficiency and robustness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07729v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'e Carlon, Luis Espath, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>A Model-Free Extremum Seeking Controller with Application to Tracking a Nonlinear Chemical Reaction</title>
      <link>https://arxiv.org/abs/2507.07749</link>
      <description>arXiv:2507.07749v1 Announce Type: new 
Abstract: In this paper, we develop the extremum-seeking approach to generate admissible trajectories in a neighborhood of a given reference curve in the state space. The cost function of the problem represents the distance between the current system state and the reference curve, which is parameterized as a function of time. Such reference curves naturally arise as optimal trajectories in isoperimetric optimization problems for nonlinear chemical reactions, where the objective is to maximize the average reaction product over a given period. We apply the proposed extremum seeking control design to a nonisothermal reaction model and illustrate the resulting tracking errors through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07749v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Victoria Grushkovska</dc:creator>
    </item>
    <item>
      <title>Dissipativity-based time domain decomposition for optimal control of hyperbolic PDEs</title>
      <link>https://arxiv.org/abs/2507.07812</link>
      <description>arXiv:2507.07812v1 Announce Type: new 
Abstract: We propose a time domain decomposition approach to optimal control of partial differential equations (PDEs) based on semigroup theoretic methods. We formulate the optimality system consisting of two coupled forward-backward PDEs, the state and adjoint equation, as a sum of dissipative operators, which enables a Peaceman-Rachford-type fixed-point iteration. The iteration steps may be understood and implemented as solutions of many decoupled, and therefore highly parallelizable, time-distributed optimal control problems. We prove the convergence of the state, the control, and the corresponding adjoint state in function space. Due to the general framework of $C_0$-(semi)groups, the results are particularly well applicable, e.g., to hyperbolic equations, such as beam or wave equations. We illustrate the convergence and efficiency of the proposed method by means of two numerical examples subject to a 2D wave equation and a 3D heat equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07812v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>B\'alint Farkas, Birgit Jacob, Manuel Schaller, Merlin Schmitz</dc:creator>
    </item>
    <item>
      <title>Complexity Analysis of a Bicriteria Directed Multimodal Transportation Network Design Problem</title>
      <link>https://arxiv.org/abs/2507.07894</link>
      <description>arXiv:2507.07894v1 Announce Type: new 
Abstract: In this paper, we address a bicriteria network design problem that arises from practical applications in urban and rural public transportation planning. We establish the problem's complexity and demonstrate inapproximability results, highlighting the inherent difficulties in finding optimal solutions. Additionally, we identify special cases where approximability can be achieved, providing valuable insights for practitioners. Our proofs leverage complexity results related to directed network design problems, an area that has received limited attention in the existing literature. By investigating these complexity results, we aim to fill a critical gap and enhance the understanding of the interplay between bicriteria decision-making and network design challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07894v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Leib, Susanne Fritzler, Neele Leith\"auser</dc:creator>
    </item>
    <item>
      <title>Convergence rates for regularized unbalanced optimal transport: the discrete case</title>
      <link>https://arxiv.org/abs/2507.07917</link>
      <description>arXiv:2507.07917v1 Announce Type: new 
Abstract: Unbalanced optimal transport (UOT) is a natural extension of optimal transport (OT) allowing comparison between measures of different masses. It arises naturally in machine learning by offering a robustness against outliers. The aim of this work is to provide convergence rates of the regularized transport cost and plans towards their original solution when both measures are weighted sums of Dirac masses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07917v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Nenna, Paul Pegon, Louis Tocquec</dc:creator>
    </item>
    <item>
      <title>Weak Optimal Transport: When is the Dual Potential Convex?</title>
      <link>https://arxiv.org/abs/2507.07200</link>
      <description>arXiv:2507.07200v1 Announce Type: cross 
Abstract: Weak optimal transport generalizes the classical theory of optimal transportation to nonlinear cost functions and covers a range of problems that lie beyond the traditional theory - including entropic transport, martingale transport, and applications in mechanism design. As in the classical case, the weak transport problem can also be written as a dual maximization problem over a pair of conjugate potentials.
  We identify sharp monotonicity conditions on the cost under which the dual problem can be restricted to convex potentials. This framework unifies several known results from the literature, including barycentric transport, martingale Benamou-Brenier, the multiple-good monopolist problem, Strassen's theorem, stochastic order projections and the classical Brenier theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07200v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filip Pramenkovi\'c</dc:creator>
    </item>
    <item>
      <title>On-Manifold Low-Thrust Maneuvering of Quasi-Periodic Orbits</title>
      <link>https://arxiv.org/abs/2507.07940</link>
      <description>arXiv:2507.07940v1 Announce Type: cross 
Abstract: A bi-level optimal control framework is introduced to solve the low-thrust re-phasing problem on quasi-periodic invariant tori in multi-body environments where deviations away from the torus during maneuver are considered unsafe or irresponsible. It is shown for a large class of mechanical systems that conformity to the torus manifold during periods of non-zero control input is infeasible. The most feasible trajectories on the torus surface are generated through the minimization of fictitious control input in the torus space using phase space control variables mapped via the torus function. These reference trajectories are then transitioned to the phase space both through a minimum tracking error homotopy and minimum time patched solutions. Results are compared to torus agnostic low-thrust transfers using measures of fuel consumption, cumulative torus error, and coast time spent on the torus during maneuver. Modifications to the framework are made for the inclusion of quasi-periodically forced dynamical systems. Lastly, minimum time recovery trajectories with free final torus conditions expose the disparity between the proposed framework and torus agnostic approaches. Examples are drawn from the circular and elliptical restricted three-body problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07940v1</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian M. Down, Manoranjan Majji, Kathleen C. Howell</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Algorithms for Convex Simple Bilevel Optimization under Weak Assumptions</title>
      <link>https://arxiv.org/abs/2409.08948</link>
      <description>arXiv:2409.08948v2 Announce Type: replace 
Abstract: This paper considers the simple bilevel optimization (SBO) problem, which minimizes a composite convex function over the optimal solution set of another composite convex minimization problem. We first show that this bilevel problem is equivalent to finding the left-most root of a nonlinear equation. Based on this and a novel dual approach for solving the subproblem in each iteration, we efficiently obtain an $(\epsilon, \epsilon)$-optimal solution through the bisection and Newton methods. The proposed methods achieve near-optimal operation complexity of ${\tilde{\mathcal{O}}(\sqrt{1/\epsilon})}$ under mild assumptions, aligning with the lower complexity bounds of the first-order methods in SBO with both level objectives being smooth convex and unconstrained composite convex optimization when ignoring logarithmic terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08948v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rujun Jiang, Xu Shi, Weizheng Song, Jiulin Wang</dc:creator>
    </item>
    <item>
      <title>Spanning and Splitting: Integer Semidefinite Programming for the Quadratic Minimum Spanning Tree Problem</title>
      <link>https://arxiv.org/abs/2410.04997</link>
      <description>arXiv:2410.04997v3 Announce Type: replace 
Abstract: In the quadratic minimum spanning tree problem (QMSTP) one wants to find the minimizer of a quadratic function over all possible spanning trees of a graph. We present a formulation of the QMSTP as a mixed-integer semidefinite program exploiting the algebraic connectivity of a graph. Based on this formulation, we derive a doubly nonnegative relaxation for the QMSTP and investigate classes of valid inequalities to strengthen the relaxation using the Chv\'atal-Gomory procedure for mixed-integer conic programming. Solving the resulting relaxations is out of reach for off-the-shelf software. We therefore develop and implement a version of the Peaceman-Rachford splitting method that allows to compute the new bounds for graphs from the literature. The computational results demonstrate that our bounds significantly improve over existing bounds from the literature in both quality and computation time, in particular for graphs with more than 30 vertices. This work is further evidence that semidefinite programming is a valuable tool to obtain high-quality bounds for problems in combinatorial optimization, in particular for those that can be modelled as a quadratic problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04997v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank de Meijer, Melanie Siebenhofer, Renata Sotirov, Angelika Wiegele</dc:creator>
    </item>
    <item>
      <title>Adaptive Gradient Normalization and Independent Sampling for (Stochastic) Generalized-Smooth Optimization</title>
      <link>https://arxiv.org/abs/2410.14054</link>
      <description>arXiv:2410.14054v3 Announce Type: replace 
Abstract: Recent studies have shown that many nonconvex machine learning problems satisfy a generalized-smooth condition that extends beyond traditional smooth nonconvex optimization. However, the existing algorithms are not fully adapted to such generalized-smooth nonconvex geometry and encounter significant technical limitations on their convergence analysis. In this work, we first analyze the convergence of adaptively normalized gradient descent under function geometries characterized by generalized-smoothness and generalized P{\L} condition, revealing the advantage of adaptive gradient normalization. Our results provide theoretical insights into adaptive normalization across various scenarios.For stochastic generalized-smooth nonconvex optimization, we propose \textbf{I}ndependent-\textbf{A}daptively \textbf{N}ormalized \textbf{S}tochastic \textbf{G}radient \textbf{D}escent algorithm, which leverages adaptive gradient normalization, independent sampling, and gradient clipping to achieve an $\mathcal{O}(\epsilon^{-4})$ sample complexity under relaxed noise assumptions. Experiments on large-scale nonconvex generalized-smooth problems demonstrate the fast convergence of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14054v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufeng Yang, Erin Tripp, Yifan Sun, Shaofeng Zou, Yi Zhou</dc:creator>
    </item>
    <item>
      <title>Stochastic dynamic programming under recursive Epstein-Zin preferences</title>
      <link>https://arxiv.org/abs/2410.19181</link>
      <description>arXiv:2410.19181v3 Announce Type: replace 
Abstract: This paper investigates discrete-time Markov decision processes with
  recursive utilities (or payoffs) defined by the classic CES aggregator and
  the Kreps-Porteus certainty equivalent operator. According to the classification introduced by Marinacci and Montrucchio, some aggregators that we consider are Thompson and some of them are neither Thompson nor Blackwell. We focus on the existence and uniqueness of a solution to the Bellman equation. Since the per-period utilities can be unbounded, we work with the weighted supremum norm. Our paper shows three major points for such models. Firstly, we prove that the Bellman equation can be obtained by the Banach fixed point theorem for contraction mappings acting on a standard complete metric space. Secondly, we need not assume any boundary conditions, which are present when the Thompson metric or the Du's theorem are used. Thirdly, our results give better bounds for the geometric convergence of the value iteration algorithm than those obtained by Du's fixed point theorem. Moreover, our techniques allow to derive the Bellman equation for some values of parameters in the CES aggregator and the Kreps-Porteus certainty equivalent that cannot be solved by Du's theorem for increasing and convex or concave operators acting on an ordered Banach space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19181v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anna Ja\'skiewicz, Andrzej S. Nowak</dc:creator>
    </item>
    <item>
      <title>Stability of Jordan Recurrent Neural Network Estimator</title>
      <link>https://arxiv.org/abs/2502.04551</link>
      <description>arXiv:2502.04551v2 Announce Type: replace 
Abstract: State estimation refers to determining the states of a dynamical system that starts from a noisy initial condition and evolves under process noise, based on noisy measurements and a known system model. For linear dynamical systems with white Gaussian noises of known mean and variance, Kalman filtering is a well-known method that leads to stable error dynamics for detectable systems. There are some non-optimal extensions to nonlinear systems. Recent work has used neural networks to develop estimators for nonlinear systems that optimize a criterion. Stability of the error dynamics is even more important than optimality. Jordan recurrent neural networks (JRNs) have a structure that mimics that of a dynamical system and are thus appealing for estimator design. We show that a JRN performs better than an extended Kalman filter(EKF) and unscented Kalman filter(UKF) for several examples. The main contribution of this paper is an input-to-state stability analysis of the error dynamics of JRNs. The stability of the error dynamics of several examples is shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04551v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avneet Kaur, Ruikun Zhou, Jun Liu, Kirsten Morris</dc:creator>
    </item>
    <item>
      <title>On Discounted Infinite-Time Mean Field Games</title>
      <link>https://arxiv.org/abs/2505.15131</link>
      <description>arXiv:2505.15131v2 Announce Type: replace 
Abstract: In this paper, we study the infinite-time mean field games with discounting, establishing an equilibrium where individual optimal strategies collectively regenerate the mean-field distribution. To solve this problem, we partition all agents into a representative player and the social equilibrium. When the optimal strategy of the representative player shares the same feedback form with the strategy of the social equilibrium, we say the system achieves a Nash equilibrium.
  We construct a Nash equilibrium using the stochastic maximum principle and infinite-time forward-backward stochastic differential equations. By employing the elliptic master equations, a class of distribution-dependent elliptic PDEs , we provide a representation for the Nash equilibrium. And we prove that the solutions to a system of infinite-time forward-backward stochastic differential equations can be employed to construct viscosity solutions for a class of distribution-dependent elliptic PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15131v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Yang, Yongsheng Song</dc:creator>
    </item>
    <item>
      <title>Conservative Bias Linear Power Flow Approximations: Application to Unit Commitment</title>
      <link>https://arxiv.org/abs/2404.09876</link>
      <description>arXiv:2404.09876v2 Announce Type: replace-cross 
Abstract: The power flow equations are central to many problems in power system planning, analysis, and control. However, their inherent non-linearity and non-convexity present substantial challenges during problem-solving processes, especially for optimization problems. Accordingly, linear approximations are commonly employed to streamline computations, although this can often entail compromises in accuracy and feasibility. This paper proposes an approach termed Conservative Bias Linear Approximations (CBLA) for addressing these limitations. By minimizing approximation errors across a specified operating range while incorporating conservativeness (over- or under-estimating quantities of interest), CBLA strikes a balance between accuracy and tractability by maintaining linear constraints. By allowing users to design loss functions tailored to the specific approximated function, the bias approximation approach significantly enhances approximation accuracy. We illustrate the effectiveness of our proposed approach through several test cases, including its application to a unit commitment problem, where CBLA consistently achieves lower operating costs and improved feasibility compared to traditional linearization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09876v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paprapee Buason, Sidhant Misra, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>A Bilevel Optimization Framework for Imbalanced Data Classification</title>
      <link>https://arxiv.org/abs/2410.11171</link>
      <description>arXiv:2410.11171v3 Announce Type: replace-cross 
Abstract: Data rebalancing techniques, including oversampling and undersampling, are a common approach to addressing the challenges of imbalanced data. To tackle unresolved problems related to both oversampling and undersampling, we propose a new undersampling approach that: (i) avoids the pitfalls of noise and overlap caused by synthetic data and (ii) avoids the pitfall of under-fitting caused by random undersampling. Instead of undersampling majority data randomly, our method undersamples datapoints based on their ability to improve model loss. Using improved model loss as a proxy measurement for classification performance, our technique assesses a datapoint's impact on loss and rejects those unable to improve it. In so doing, our approach rejects majority datapoints redundant to datapoints already accepted and, thereby, finds an optimal subset of majority training data for classification. The accept/reject component of our algorithm is motivated by a bilevel optimization problem uniquely formulated to identify the optimal training set we seek. Experimental results show our proposed technique with F1 scores up to 10% higher than state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11171v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karen Medlin, Sven Leyffer, Krishnan Raghavan</dc:creator>
    </item>
    <item>
      <title>Constraint Programming Models For Serial Batch Scheduling With Minimum Batch Size</title>
      <link>https://arxiv.org/abs/2504.08793</link>
      <description>arXiv:2504.08793v2 Announce Type: replace-cross 
Abstract: In serial batch (s-batch) scheduling, jobs are grouped in batches and processed sequentially within their batch. This paper considers multiple parallel machines, nonidentical job weights and release times, and sequence-dependent setup times between batches of different families. Although s-batch has been widely studied in the literature, very few papers have taken into account a minimum batch size, typical in practical settings such as semiconductor manufacturing and the metal industry. The problem with this minimum batch size requirement has been mostly tackled with dynamic programming and meta-heuristics, and no article has ever used constraint programming (CP) to do so. This paper fills this gap by proposing, three CP models for s-batching with minimum batch size: (i) an \textit{Interval Assignment} model that computes and bounds the size of the batches using the presence literals of interval variables of the jobs. (ii) A \textit{Global} model that exclusively uses global constraints that track the size of the batches over time. (iii) And a \textit{Hybrid} model that combines the benefits of the extra global constraints with the efficiency of the sum-of-presences constraints to ensure the minimum batch sizes. The computational experiments on standard cases compare the three CP models with two existing mixed-integer programming (MIP) models from the literature. The results demonstrate the versatility of the proposed CP models to handle multiple variations of s-batching; and their ability to produce, in large instances, better solutions than the MIP models faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08793v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge A. Huertas, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Autoregressive Stochastic Clock Jitter Compensation in Analog-to-Digital Converters</title>
      <link>https://arxiv.org/abs/2505.05030</link>
      <description>arXiv:2505.05030v3 Announce Type: replace-cross 
Abstract: This paper deals with the mathematical modeling and compensation of stochastic discrete time clock jitter in Analog-to-Digital Converters (ADCs). Two novel, computationally efficient de-jittering sample pilots-based algorithms for baseband signals are proposed: one consisting in solving a sequence of weighted least-squares problems and another that fully leverages the correlated jitter structure in a Kalman filter-type routine. Alongside, a comprehensive and rigorous mathematical analysis of the linearization errors committed is presented, and the work is complemented with extensive synthetic simulations and performance benchmarking with the scope of gauging and stress-testing the techniques in different scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05030v3</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Gerosa, Rui Hou, Vimar Bj\"ork, Ulf Gustavsson, Thomas Eriksson</dc:creator>
    </item>
    <item>
      <title>Position: Adopt Constraints Over Penalties in Deep Learning</title>
      <link>https://arxiv.org/abs/2505.20628</link>
      <description>arXiv:2505.20628v2 Announce Type: replace-cross 
Abstract: Recent efforts to develop trustworthy AI systems with accountability guarantees have led to widespread use of machine learning formulations incorporating external requirements, or constraints. These requirements are often enforced via penalization--adding fixed-weight terms to the task loss. We argue this approach is fundamentally ill-suited since there may be no penalty coefficient that simultaneously ensures constraint satisfaction and optimal constrained performance, i.e., that truly solves the constrained problem. Moreover, tuning these coefficients requires costly trial-and-error, incurring significant time and computational overhead. We, therefore, advocate for broader adoption of tailored constrained optimization methods--such as the Lagrangian approach, which jointly optimizes the penalization "coefficients" (the Lagrange multipliers) and the model parameters. Such methods (i) truly solve the constrained problem and do so accountably, by clearly defining feasibility and verifying when it is achieved, (ii) eliminate the need for extensive penalty tuning, and (iii) integrate seamlessly with modern deep learning pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20628v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Ramirez, Meraj Hashemizadeh, Simon Lacoste-Julien</dc:creator>
    </item>
  </channel>
</rss>
