<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Aug 2025 04:01:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Interpretable Scalar-on-Image Linear Regression Models via the Generalized Dantzig Selector</title>
      <link>https://arxiv.org/abs/2508.20278</link>
      <description>arXiv:2508.20278v1 Announce Type: new 
Abstract: The scalar-on-image regression model examines the association between a scalar response and a bivariate function (e.g., images) through the estimation of a bivariate coefficient function. Existing approaches often impose smoothness constraints to control the bias-variance trade-off, and thus prevent overfitting. However, such assumptions can hinder interpretability, especially when only certain regions of an image influence changes in the response. In such a scenario, interpretability can be better captured by imposing sparsity assumptions on the coefficient function. To address this challenge, we propose the Generalized Dantzig Selector, a novel method that jointly enforces sparsity and smoothness on the coefficient function. The proposed approach enhances interpretability by accurately identifying regions with no contribution to the changes of response, while preserving stability in estimation. Extensive simulation studies and real data applications demonstrate that the new method is highly interpretable and achieves notable improvements over existing approaches. Moreover, we rigorously establish non-asymptotic bounds for the estimation error, providing strong theoretical guarantees for the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20278v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sijia Liao, Xiaoxiao Sun, Ning Hao, Hao Helen Zhang</dc:creator>
    </item>
    <item>
      <title>Latent Factor Point Processes for Patient Representation in Electronic Health Records</title>
      <link>https://arxiv.org/abs/2508.20327</link>
      <description>arXiv:2508.20327v1 Announce Type: new 
Abstract: Electronic health records (EHR) contain valuable longitudinal patient-level information, yet most statistical methods reduce the irregular timing of EHR codes into simple counts, thereby discarding rich temporal structure. Existing temporal models often impose restrictive parametric assumptions or are tailored to code level rather than patient-level tasks. We propose the latent factor point process model, which represents code occurrences as a high-dimensional point process whose conditional intensity is driven by a low dimensional latent Poisson process. This low-rank structure reflects the clinical reality that thousands of codes are governed by a small number of underlying disease processes, while enabling statistically efficient estimation in high dimensions. Building on this model, we introduce the Fourier-Eigen embedding, a patient representation constructed from the spectral density matrix of the observed process. We establish theoretical guarantees showing that these embeddings efficiently capture subgroup-specific temporal patterns for downstream classification and clustering. Simulations and an application to an Alzheimer's disease EHR cohort demonstrate the practical advantages of our approach in uncovering clinically meaningful heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20327v1</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parker Knight, Doudou Zhou, Zongqi Xia, Tianxi Cai, Junwei Lu</dc:creator>
    </item>
    <item>
      <title>Covariate-adjusted win statistics in randomized clinical trials with ordinal outcomes</title>
      <link>https://arxiv.org/abs/2508.20349</link>
      <description>arXiv:2508.20349v1 Announce Type: new 
Abstract: Ordinal outcomes are common in clinical settings where they often represent increasing levels of disease progression or different levels of functional impairment. Such outcomes can characterize differences in meaningful patient health states that are directly relevant to clinical researchers and frequently represent composite outcomes that include absorbing states such as death. To compare different intervention strategies in clinical trials, the direct use of ordinal logistic regression models may not be ideal for analyzing ranked outcomes due to non-collapsibility, lack of estimation and clarity, or failure of the common underlying proportional odds assumption. In this article, we focus on representing the average treatment effect for ordinal outcomes via intrinsic pairwise outcome comparisons captured through win estimates, such as the win ratio and win difference. We first develop propensity score weighting estimators, including both inverse probability weighting (IPW) and overlap weighting (OW), tailored to estimating win parameters. Furthermore, we develop augmented weighting estimators that leverage an additional ordinal outcome regression to potentially improve efficiency over weighting alone. Leveraging the theory of U-statistics, we establish the asymptotic theory for all estimators, and derive closed-form variance estimators to support statistical inference. Through extensive simulations we demonstrate the enhanced efficiency of the weighted estimators over the unadjusted estimator, with the augmented weighting estimators showing a further improvement in efficiency except for extreme cases. Finally, we illustrate our proposed methods with the ORCHID trial, and implement our covariate adjustment methods in an R package winPSW to facilitate the practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20349v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhiqiang Cao, Scott Zuo, Mary Ryan Baumann, Kendra Plourde, Patrick Heagerty, Guangyu Tong, Fan Li</dc:creator>
    </item>
    <item>
      <title>When Is Causal Inference Possible? A Statistical Test for Unmeasured Confounding</title>
      <link>https://arxiv.org/abs/2508.20366</link>
      <description>arXiv:2508.20366v1 Announce Type: new 
Abstract: This paper clarifies a fundamental difference between causal inference and traditional statistical inference by formalizing a mathematical distinction between their respective parameters. We connect two major approaches to causal inference, the potential outcomes framework and causal structure graphs, which are typically studied separately. While the unconfoundedness assumption in the potential outcomes framework cannot be assessed from an observational dataset alone, causal structure graphs help explain when causal effects are identifiable through graphical models. We propose a statistical test to assess the unconfoundedness assumption, equivalent to the absence of unmeasured confounding, by comparing two datasets: a randomized controlled trial and an observational study. The test controls the Type I error probability, and we analyze its power under linear models. Our approach provides a practical method to evaluate when real-world data are suitable for causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20366v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muye Liu, Jun Xie</dc:creator>
    </item>
    <item>
      <title>Stable and practical semi-Markov modelling of intermittently-observed data</title>
      <link>https://arxiv.org/abs/2508.20949</link>
      <description>arXiv:2508.20949v1 Announce Type: new 
Abstract: Multi-state models are commonly used for intermittent observations of a state over time, but these are generally based on the Markov assumption, that transition rates are independent of the time spent in current and previous states. In a semi-Markov model, the rates can depend on the time spent in the current state, though available methods for this are either restricted to specific state structures or lack general software. This paper develops the approach of using a "phase-type" distribution for the sojourn time in a state, which expresses a semi-Markov model as a hidden Markov model, allowing the likelihood to be calculated easily for any state structure. While this approach involves a proliferation of latent parameters, identifiability can be improved by restricting the phase-type family to one which approximates a simpler distribution such as the Gamma or Weibull. This paper proposes a moment-matching method to obtain this approximation, making general semi-Markov models for intermittent data accessible in software for the first time. The method is implemented in a new R package, "msmbayes", which implements Bayesian or maximum likelihood estimation for multi-state models with general state structures and covariates. The software is tested using simulation-based calibration, and an application to cognitive function decline illustrates the use of the method in a typical modelling workflow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20949v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Jackson</dc:creator>
    </item>
    <item>
      <title>Optional subsampling for generalized estimating equations in growing-dimensional longitudinal Data</title>
      <link>https://arxiv.org/abs/2508.20803</link>
      <description>arXiv:2508.20803v1 Announce Type: cross 
Abstract: As a powerful tool for longitudinal data analysis, the generalized estimating equations have been widely studied in the academic community. However, in large-scale settings, this approach faces pronounced computational and storage challenges. In this paper, we propose an optimal Poisson subsampling algorithm for generalized estimating equations in large-scale longitudinal data with diverging covariate dimension, and establish the asymptotic properties of the resulting estimator. We further derive the optimal Poisson subsampling probability based on A- and L-optimality criteria. An approximate optimal Poisson subsampling algorithm is proposed, which adopts a two-step procedure to construct these probabilities. Simulation studies are conducted to evaluate the performance of the proposed method under three different working correlation matrices. The results show that the method remains effective even when the working correlation matrices are misspecified. Finally, we apply the proposed method to the CHFS dataset to illustrate its empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20803v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunjing Li, Jiahui Zhang, Xiaohui Yuan</dc:creator>
    </item>
    <item>
      <title>Transfer Learning for Classification under Decision Rule Drift with Application to Optimal Individualized Treatment Rule Estimation</title>
      <link>https://arxiv.org/abs/2508.20942</link>
      <description>arXiv:2508.20942v1 Announce Type: cross 
Abstract: In this paper, we extend the transfer learning classification framework from regression function-based methods to decision rules. We propose a novel methodology for modeling posterior drift through Bayes decision rules. By exploiting the geometric transformation of the Bayes decision boundary, our method reformulates the problem as a low-dimensional empirical risk minimization problem. Under mild regularity conditions, we establish the consistency of our estimators and derive the risk bounds. Moreover, we illustrate the broad applicability of our method by adapting it to the estimation of optimal individualized treatment rules. Extensive simulation studies and analyses of real-world data further demonstrate both superior performance and robustness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20942v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohan Wang, Yang Ning</dc:creator>
    </item>
    <item>
      <title>Pivotal inference for linear predictions in stationary processes</title>
      <link>https://arxiv.org/abs/2508.21025</link>
      <description>arXiv:2508.21025v1 Announce Type: cross 
Abstract: In this paper we develop pivotal inference for the final (FPE) and relative final prediction error (RFPE) of linear forecasts in stationary processes. Our approach is based on a novel self-normalizing technique and avoids the estimation of the asymptotic variances of the empirical autocovariances. We provide pivotal confidence intervals for the (R)FPE, develop estimates for the minimal order of a linear prediction that is required to obtain a prespecified forecasting accuracy and also propose (pivotal) statistical tests for the hypotheses that the (R)FPE exceeds a given threshold. Additionally, we provide new (pivotal) inference tools for the partial autocorrelation, which do not require the assumption of an autoregressive process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21025v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Holger Dette, Sebastian K\"uhnert</dc:creator>
    </item>
    <item>
      <title>Causal machine learning methods and use of cross-fitting in settings with high-dimensional confounding</title>
      <link>https://arxiv.org/abs/2405.15242</link>
      <description>arXiv:2405.15242v3 Announce Type: replace 
Abstract: Observational epidemiological studies commonly seek to estimate the causal effect of an exposure on an outcome. Adjustment for potential confounding bias in modern studies is challenging due to the presence of high-dimensional confounding, which occurs when there are many confounders relative to sample size or complex relationships between continuous confounders and exposure and outcome. Doubly robust methods such as Augmented Inverse Probability Weighting (AIPW) and Targeted Maximum Likelihood Estimation (TMLE) have the potential to address these challenges, using data-adaptive approaches and cross-fitting, but despite recent advances limited evaluation and guidance are available on their implementation in realistic settings where high-dimensional confounding is present. Motivated by an early-life cohort study, we conducted an extensive simulation study to compare the relative performance of AIPW and TMLE using data-adaptive approaches for estimating the average causal effect (ACE). We evaluated the benefits of using cross-fitting with a varying number of folds, as well as the impact of using a reduced versus full (larger, more diverse) library in the Super Learner ensemble learning approach used for implementation. We found that AIPW and TMLE performed similarly in most cases for estimating the ACE, but TMLE was more stable. Cross-fitting improved the performance of both methods, but was more important for variance estimation and coverage than for point estimates, with the number of folds a less important consideration. Using a full Super Learner library was important to reduce bias and variance in complex scenarios typical of modern health research studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15242v3</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Susan Ellul, Stijn Vansteelandt, John B. Carlin, Margarita Moreno-Betancur</dc:creator>
    </item>
    <item>
      <title>HAL-Based Plug-in Estimation with Pointwise Asymptotic Normality of the Causal Dose-Response Curve</title>
      <link>https://arxiv.org/abs/2406.05607</link>
      <description>arXiv:2406.05607v4 Announce Type: replace 
Abstract: Estimating and obtaining reliable inference for the marginally adjusted causal dose-response curve for continuous treatments without relying on parametric assumptions is a well-known statistical challenge. Parametric models risk introducing significant bias through model misspecification, compromising the accurate representation of the underlying data and dose-response relationship. On the other hand, nonparametric models face difficulties as the dose-response curve is not pathwise differentiable, preventing consistent estimation at standard rates. The Highly Adaptive Lasso (HAL) maximum likelihood estimator offers a promising approach to this issue. In this paper, we introduce a HAL-based plug-in estimator for the causal dose-response curve, bridge theoretical development and empirical application, and assess its empirical performance against other estimators. This work emphasizes not just theoretical proofs, but also demonstrates their application through comprehensive simulations, thereby filling an essential gap between theory and practice. Our comprehensive simulations demonstrate that the HAL-based estimator achieves pointwise asymptotic normality with valid inference and consistently outperforms existing approaches for estimating the causal dose-response curve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05607v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junming Shi, Wenxin Zhang, Alan E. Hubbard, Mark van der Laan</dc:creator>
    </item>
    <item>
      <title>Approximate Bayesian Computation with Statistical Distances for Model Selection</title>
      <link>https://arxiv.org/abs/2410.21603</link>
      <description>arXiv:2410.21603v3 Announce Type: replace 
Abstract: Model selection is a key task in statistics, playing a critical role across various scientific disciplines. While no model can fully capture the complexities of a real-world data-generating process, identifying the model that best approximates it can provide valuable insights. Bayesian statistics offers a flexible framework for model selection by updating prior beliefs as new data becomes available, allowing for ongoing refinement of candidate models. This is typically achieved by calculating posterior probabilities, which quantify the support for each model given the observed data. However, in cases where likelihood functions are intractable, exact computation of these posterior probabilities becomes infeasible. Approximate Bayesian computation (ABC) has emerged as a likelihood-free method and it is traditionally used with summary statistics to reduce data dimensionality, however this often results in information loss difficult to quantify, particularly in model selection contexts. Recent advancements propose the use of full data approaches based on statistical distances, offering a promising alternative that bypasses the need for handcrafted summary statistics and can yield posterior approximations that more closely reflect the true posterior under suitable conditions. Despite these developments, full data ABC approaches have not yet been widely applied to model selection problems. This paper seeks to address this gap by investigating the performance of ABC with statistical distances in model selection. Through simulation studies and an application to toad movement models, this work explores whether full data approaches can overcome the limitations of summary statistic-based ABC for model choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21603v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clara Grazian</dc:creator>
    </item>
    <item>
      <title>Identification and Scaling of Latent Variables in Ordinal Factor Analysis</title>
      <link>https://arxiv.org/abs/2501.06094</link>
      <description>arXiv:2501.06094v2 Announce Type: replace 
Abstract: Social science researchers are generally accustomed to treating ordinal variables as though they are continuous. In this paper, we consider how identification constraints in ordinal factor analysis can mimic the treatment of ordinal variables as continuous. We describe model constraints that lead to latent variable predictions equaling the average of ordinal variables. This result leads us to propose minimal identification constraints, which we call "integer constraints," that center the latent variables around the scale of the observed, integer-coded ordinal variables. The integer constraints lead to intuitive model parameterizations because researchers are already accustomed to thinking about ordinal variables as though they are continuous. We provide a proof that our proposed integer constraints are indeed minimal identification constraints, as well as an illustration of how integer constraints work with real data. We also provide simulation results indicating that integer constraints are similar to other identification constraints in terms of estimation convergence and admissibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06094v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edgar C. Merkle, Sonja D. Winter, Ellen Fitzsimmons</dc:creator>
    </item>
    <item>
      <title>A Metropolis-Adjusted Langevin Algorithm for Sampling Jeffreys Prior</title>
      <link>https://arxiv.org/abs/2504.06372</link>
      <description>arXiv:2504.06372v3 Announce Type: replace-cross 
Abstract: Inference and estimation are fundamental in statistics, system identification, and machine learning. When prior knowledge about the system is available, Bayesian analysis provides a natural framework for encoding it through a prior distribution. In practice, such knowledge is often too vague to specify a full prior distribution, motivating the use of default 'uninformative' priors that minimize subjective bias. Jeffreys prior is an appealing uninformative prior because: (i) it is invariant under any re-parameterization of the model, (ii) it encodes the intrinsic geometric structure of the parameter space through the Fisher information matrix, which in turn enhances the diversity of parameter samples. Despite these benefits, drawing samples from Jeffreys prior is challenging. In this paper, we develop a general sampling scheme using the Metropolis-Adjusted Langevin Algorithm that enables sampling of parameter values from Jeffreys prior; the method extends naturally to nonlinear state-space models. The resulting samples can be directly used in sampling-based system identification methods and Bayesian experiment design, providing an objective, information-geometric description of parameter uncertainty. Several numerical examples demonstrate the efficiency and accuracy of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06372v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yibo Shi, Braghadeesh Lakshminarayanan, Cristian R. Rojas</dc:creator>
    </item>
    <item>
      <title>Irredundant $k$-Fold Cross-Validation</title>
      <link>https://arxiv.org/abs/2507.20048</link>
      <description>arXiv:2507.20048v2 Announce Type: replace-cross 
Abstract: In traditional k-fold cross-validation, each instance is used ($k-1$) times for training and once for testing, leading to redundancy that lets many instances disproportionately influence the learning phase. We introduce Irredundant $k$-fold cross-validation, a novel method that guarantees each instance is used exactly once for training and once for testing across the entire validation procedure. This approach ensures a more balanced utilization of the dataset, mitigates overfitting due to instance repetition, and enables sharper distinctions in comparative model analysis. The method preserves stratification and remains model-agnostic, i.e., compatible with any classifier. Experimental results demonstrate that it delivers consistent performance estimates across diverse datasets -- comparable to $k$-fold cross-validation -- while providing less optimistic variance estimates because training partitions are non-overlapping, and significantly reducing the overall computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20048v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jesus S. Aguilar-Ruiz</dc:creator>
    </item>
  </channel>
</rss>
