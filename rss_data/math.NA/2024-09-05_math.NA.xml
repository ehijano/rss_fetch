<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 01:39:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A virtual element method for a convective Brinkman-Forchheimer problem coupled with a heat equation</title>
      <link>https://arxiv.org/abs/2409.02252</link>
      <description>arXiv:2409.02252v1 Announce Type: new 
Abstract: We develop a virtual element method to solve a convective Brinkman-Forchheimer problem coupled with a heat equation. This coupled model may allow for thermal diffusion and viscosity as a function of temperature. Under standard discretization assumptions, we prove the well posedness of the proposed numerical scheme. We also derive optimal error estimates under appropriate regularity assumptions for the solution. We conclude with a series of numerical tests performed with different mesh families that complement our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02252v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danilo Amigo, Felipe Lepe, Enrique Otarola, Gonzalo Rivera</dc:creator>
    </item>
    <item>
      <title>UAV-Mounted Movable Antenna: Joint Optimization of UAV Placement and Antenna Configuration</title>
      <link>https://arxiv.org/abs/2409.02469</link>
      <description>arXiv:2409.02469v1 Announce Type: new 
Abstract: Recently, movable antennas (MAs) have garnered immense attention due to their capability to favorably alter channel conditions through agile movement. In this letter, we delve into a spectrum sharing system enabled by unmanned aerial vehicle (UAV) mounted MAs, thereby introducing a new degree of freedom vertically alongside the horizontal local mobility for MAs. Our objective is to maximize the minimum beamforming gain for secondary users (SUs) while ensuring that interference to the primary users (PUs) remains below a predefined threshold, which necessitates a joint optimization involving the UAV's height, the antenna weight vector (AWV), and the antenna position vector (APV). However, the formulated optimization problem is non-convex and challenging to solve optimally. To tackle this issue, we propose an alternating optimization algorithm that optimizes the UAV's height, APV and AWV in an iterative manner, thus yielding a near-optimal solution. Numerical results demonstrate the superiority of the proposed scheme as well as its ability to deliver full beamforming gain to SUs with reduced computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02469v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Wei Tang, Yunmei Shi, Yi Huang, Qingqing Wu</dc:creator>
    </item>
    <item>
      <title>Cointegration test in time series analysis by global optimisation</title>
      <link>https://arxiv.org/abs/2409.02552</link>
      <description>arXiv:2409.02552v2 Announce Type: new 
Abstract: In this paper, we provide an optimisation approach motivated by the Blind Source Separation, or also known as Independent Component Analysis, for cointegration between financial time series. Two methods for cointegration tests are introduced, namely decorrelation for the bivariate case and maximisation of nongaussianity for higher-dimensions. The advantages of our methods, especially the better performances in limited sample size, enable a wider range of application and accessibility for researchers and practitioners to identify cointegrating relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02552v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvey Qianli Lin, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Novel Approach for solving the discrete Stokes problems based on Augmented Lagrangian and Global Techniques: Application to Saddle-Point Linear Systems from Incompressible flow</title>
      <link>https://arxiv.org/abs/2409.02652</link>
      <description>arXiv:2409.02652v1 Announce Type: new 
Abstract: In this paper, a novel augmented Lagrangian preconditioner based on global Arnoldi for accelerating the convergence of Krylov subspace methods applied to linear systems of equations with a block three-by-three structure, these systems typically arise from discretizing the Stokes equations using mixed-finite element methods. In practice, the components of velocity are always approximated using a single finite element space. More precisely, in two dimensions, our new approach based on standard space of scalar finite element basis functions to discretize the velocity space. This componentwise splitting can be shown to induce a natural block three-by-three structure. Spectral analyses is established for the exact versions of these preconditioners. Finally, the obtained numerical results claim that our novel approach is more efficient and robust for solving the discrete Stokes problems. The efficiency of our new approach is evaluated by measuring computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02652v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>A. Badahmane, A. Ratnani, H. Sadok</dc:creator>
    </item>
    <item>
      <title>A Parareal algorithm without Coarse Propagator?</title>
      <link>https://arxiv.org/abs/2409.02673</link>
      <description>arXiv:2409.02673v1 Announce Type: new 
Abstract: The Parareal algorithm was invented in 2001 in order to parallelize the solution of evolution problems in the time direction. It is based on parallel fine time propagators called F and sequential coarse time propagators called G, which alternatingly solve the evolution problem and iteratively converge to the fine solution. The coarse propagator G is a very important component of Parareal, as one sees in the convergence analyses. We present here for the first time a Parareal algorithm without coarse propagator, and explain why this can work very well for parabolic problems. We give a new convergence proof for coarse propagators approximating in space, in contrast to the more classical coarse propagators which are approximations in time, and our proof also applies in the absence of the coarse propagator. We illustrate our theoretical results with numerical experiments, and also explain why this approach can not work for hyperbolic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02673v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin J. Gander, Mario Ohlberger, Stephan Rave</dc:creator>
    </item>
    <item>
      <title>Online learning of quadratic manifolds from streaming data for nonlinear dimensionality reduction and nonlinear model reduction</title>
      <link>https://arxiv.org/abs/2409.02703</link>
      <description>arXiv:2409.02703v1 Announce Type: new 
Abstract: This work introduces an online greedy method for constructing quadratic manifolds from streaming data, designed to enable in-situ analysis of numerical simulation data on the Petabyte scale. Unlike traditional batch methods, which require all data to be available upfront and take multiple passes over the data, the proposed online greedy method incrementally updates quadratic manifolds in one pass as data points are received, eliminating the need for expensive disk input/output operations as well as storing and loading data points once they have been processed. A range of numerical examples demonstrate that the online greedy method learns accurate quadratic manifold embeddings while being capable of processing data that far exceed common disk input/output capabilities and volumes as well as main-memory sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02703v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Schwerdtner, Prakash Mohan, Aleksandra Pachalieva, Julie Bessac, Daniel O'Malley, Benjamin Peherstorfer</dc:creator>
    </item>
    <item>
      <title>A hybrid FEM-PINN method for time-dependent partial differential equations</title>
      <link>https://arxiv.org/abs/2409.02810</link>
      <description>arXiv:2409.02810v1 Announce Type: new 
Abstract: In this work, we present a hybrid numerical method for solving evolution partial differential equations (PDEs) by merging the time finite element method with deep neural networks. In contrast to the conventional deep learning-based formulation where the neural network is defined on a spatiotemporal domain, our methodology utilizes finite element basis functions in the time direction where the space-dependent coefficients are defined as the output of a neural network. We then apply the Galerkin or collocation projection in the time direction to obtain a system of PDEs for the space-dependent coefficients which is approximated in the framework of PINN. The advantages of such a hybrid formulation are twofold: statistical errors are avoided for the integral in the time direction, and the neural network's output can be regarded as a set of reduced spatial basis functions. To further alleviate the difficulties from high dimensionality and low regularity, we have developed an adaptive sampling strategy that refines the training set. More specifically, we use an explicit density model to approximate the distribution induced by the PDE residual and then augment the training set with new time-dependent random samples given by the learned density model. The effectiveness and efficiency of our proposed method have been demonstrated through a series of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02810v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaodong Feng, Haojiong Shangguan, Tao Tang, Xiaoliang Wan, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Adaptive and frugal BDDC coarse spaces for virtual element discretizations of a Stokes problem with heterogeneous viscosity</title>
      <link>https://arxiv.org/abs/2409.02860</link>
      <description>arXiv:2409.02860v1 Announce Type: new 
Abstract: The virtual element method (VEM) is a family of numerical methods to discretize partial differential equations on general polygonal or polyhedral computational grids. However, the resulting linear systems are often ill-conditioned and robust preconditioning techniques are necessary for an iterative solution. Here, a balancing domain decomposition by constraints (BDDC) preconditioner is considered. Techniques to enrich the coarse space of BDDC applied to a Stokes problem with heterogeneous viscosity are proposed. In this framework a comparison between two adaptive techniques and a computationally cheaper heuristic approach is carried out. Numerical results computed on a physically realistic model show that the latter approach in combination with the deluxe scaling is a promising alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02860v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Bevilacqua, Axel Klawonn, Martin Lanser</dc:creator>
    </item>
    <item>
      <title>TreeTOp: Topology Optimization using Constructive Solid Geometry Trees</title>
      <link>https://arxiv.org/abs/2409.02300</link>
      <description>arXiv:2409.02300v1 Announce Type: cross 
Abstract: Feature-mapping methods for topology optimization (FMTO) facilitate direct geometry extraction by leveraging high-level geometric descriptions of the designs. However, FMTO often relies solely on Boolean unions, which can restrict the design space. This work proposes an FMTO framework leveraging an expanded set of Boolean operations, namely, union, intersection, and subtraction. The optimization process entails determining the primitives and the optimal Boolean operation tree. In particular, the framework leverages a recently proposed unified Boolean operation approach. This approach presents a continuous and differentiable function that interpolates the Boolean operations, enabling gradient-based optimization. The proposed methodology is agnostic to the specific primitive parametrization and is showcased through various numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02300v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Kumar Padhy, Pramod Thombre, Krishnan Suresh, Aaditya Chandrasekhar</dc:creator>
    </item>
    <item>
      <title>Optimal sampling for least-squares approximation</title>
      <link>https://arxiv.org/abs/2409.02342</link>
      <description>arXiv:2409.02342v1 Announce Type: cross 
Abstract: Least-squares approximation is one of the most important methods for recovering an unknown function from data. While in many applications the data is fixed, in many others there is substantial freedom to choose where to sample. In this paper, we review recent progress on optimal sampling for (weighted) least-squares approximation in arbitrary linear spaces. We introduce the Christoffel function as a key quantity in the analysis of (weighted) least-squares approximation from random samples, then show how it can be used to construct sampling strategies that possess near-optimal sample complexity: namely, the number of samples scales log-linearly in $n$, the dimension of the approximation space. We discuss a series of variations, extensions and further topics, and throughout highlight connections to approximation theory, machine learning, information-based complexity and numerical linear algebra. Finally, motivated by various contemporary applications, we consider a generalization of the classical setting where the samples need not be pointwise samples of a scalar-valued function, and the approximation space need not be linear. We show that even in this significantly more general setting suitable generalizations of the Christoffel function still determine the sample complexity. This provides a unified procedure for designing improved sampling strategies for general recovery problems. This article is largely self-contained, and intended to be accessible to nonspecialists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02342v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Adcock</dc:creator>
    </item>
    <item>
      <title>Enforcing Katz and PageRank Centrality Measures in Complex Networks</title>
      <link>https://arxiv.org/abs/2409.02524</link>
      <description>arXiv:2409.02524v1 Announce Type: cross 
Abstract: We investigate the problem of enforcing a desired centrality measure in complex networks, while still keeping the original pattern of the network. Specifically, by representing the network as a graph with suitable nodes and weighted edges, we focus on computing the smallest perturbation on the weights required to obtain a prescribed PageRank or Katz centrality index for the nodes. Our approach relies on optimization procedures that scale with the number of modified edges, enabling the exploration of different scenarios and altering network structure and dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02524v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Stefano Cipolla, Fabio Durastante, Beatrice Meini</dc:creator>
    </item>
    <item>
      <title>Pseudospectral method for solving PDEs using Matrix Product States</title>
      <link>https://arxiv.org/abs/2409.02916</link>
      <description>arXiv:2409.02916v1 Announce Type: cross 
Abstract: This research focuses on solving time-dependent partial differential equations (PDEs), in particular the time-dependent Schr\"odinger equation, using matrix product states (MPS). We propose an extension of Hermite Distributed Approximating Functionals (HDAF) to MPS, a highly accurate pseudospectral method for approximating functions of derivatives. Integrating HDAF into an MPS finite precision algebra, we test four types of quantum-inspired algorithms for time evolution: explicit Runge-Kutta methods, Crank-Nicolson method, explicitly restarted Arnoli iteration and split-step. The benchmark problem is the expansion of a particle in a quantum quench, characterized by a rapid increase in space requirements, where HDAF surpasses traditional finite difference methods in accuracy with a comparable cost. Moreover, the efficient HDAF approximation to the free propagator avoids the need for Fourier transforms in split-step methods, significantly enhancing their performance with an improved balance in cost and accuracy. Both approaches exhibit similar error scaling and run times compared to FFT vector methods; however, MPS offer an exponential advantage in memory, overcoming vector limitations to enable larger discretizations and expansions. Finally, the MPS HDAF split-step method successfully reproduces the physical behavior of a particle expansion in a double-well potential, demonstrating viability for actual research scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02916v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge Gidi, Paula Garc\'ia-Molina, Luca Tagliacozzo, Juan Jos\'e Garc\'ia-Ripoll</dc:creator>
    </item>
    <item>
      <title>Sharp preasymptotic error bounds for the Helmholtz $h$-FEM</title>
      <link>https://arxiv.org/abs/2301.03574</link>
      <description>arXiv:2301.03574v3 Announce Type: replace 
Abstract: In the analysis of the $h$-version of the finite-element method (FEM), with fixed polynomial degree $p$, applied to the Helmholtz equation with wavenumber $k\gg 1$, the $\textit{asymptotic regime}$ is when $(hk)^p C_{\rm sol}$ is sufficiently small and the sequence of Galerkin solutions are quasioptimal; here $C_{\rm sol}$ is the $L^2 \to L^2$ norm of the Helmholtz solution operator, with $C_{\rm sol} \sim k$ for nontrapping problems. In the $\textit{preasymptotic regime}$, one expects that if $(hk)^{2p}C_{\rm sol}$ is sufficiently small, then (for physical data) the relative error of the Galerkin solution is controllably small. In this paper, we prove the natural error bounds in the preasymptotic regime for the variable-coefficient Helmholtz equation in the exterior of a Dirichlet, or Neumann, or penetrable obstacle (or combinations of these) and with the radiation condition $\textit{either}$ realised exactly using the Dirichlet-to-Neumann map on the boundary of a ball $\textit{or}$ approximated either by a radial perfectly-matched layer (PML) or an impedance boundary condition. Previously, such bounds for $p&gt;1$ were only available for Dirichlet obstacles with the radiation condition approximated by an impedance boundary condition. Our result is obtained via a novel generalisation of the "elliptic-projection" argument (the argument used to obtain the result for $p=1$) which can be applied to a wide variety of abstract Helmholtz-type problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.03574v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Galkowski, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Adaptive operator learning for infinite-dimensional Bayesian inverse problems</title>
      <link>https://arxiv.org/abs/2310.17844</link>
      <description>arXiv:2310.17844v3 Announce Type: replace 
Abstract: The fundamental computational issues in Bayesian inverse problems (BIP) governed by partial differential equations (PDEs) stem from the requirement of repeated forward model evaluations. A popular strategy to reduce such costs is to replace expensive model simulations with computationally efficient approximations using operator learning, motivated by recent progress in deep learning. However, using the approximated model directly may introduce a modeling error, exacerbating the already ill-posedness of inverse problems. Thus, balancing between accuracy and efficiency is essential for the effective implementation of such approaches. To this end, we develop an adaptive operator learning framework that can reduce modeling error gradually by forcing the surrogate to be accurate in local areas. This is accomplished by adaptively fine-tuning the pre-trained approximate model with training points chosen by a greedy algorithm during the posterior evaluation process. To validate our approach, we use DeepOnet to construct the surrogate and unscented Kalman inversion (UKI) to approximate the BIP solution, respectively. Furthermore, we present a rigorous convergence guarantee in the linear case using the UKI framework. The approach is tested on a number of benchmarks, including the Darcy flow, the heat source inversion problem, and the reaction-diffusion problem. The numerical results show that our method can significantly reduce computational costs while maintaining inversion accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17844v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiwei Gao, Liang Yan, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Adaptive time step selection for Spectral Deferred Correction</title>
      <link>https://arxiv.org/abs/2403.13454</link>
      <description>arXiv:2403.13454v2 Announce Type: replace 
Abstract: Spectral Deferred Correction (SDC) is an iterative method for the numerical solution of ordinary differential equations. It works by refining the numerical solution for an initial value problem by approximately solving differential equations for the error, and can be interpreted as a preconditioned fixed-point iteration for solving the fully implicit collocation problem. We adopt techniques from embedded Runge-Kutta Methods (RKM) to SDC in order to provide a mechanism for adaptive time step size selection and thus increase computational efficiency of SDC. We propose two SDC-specific estimates of the local error that are generic and do not rely on problem specific quantities. We demonstrate a gain in efficiency over standard SDC with fixed step size and compare efficiency favorably against state-of-the-art adaptive RKM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13454v2</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Baumann, Sebastian G\"otschel, Thibaut Lunet, Daniel Ruprecht, Robert Speck</dc:creator>
    </item>
    <item>
      <title>Exploring tau protein and amyloid-beta propagation: a sensitivity analysis of mathematical models based on biological data</title>
      <link>https://arxiv.org/abs/2404.14169</link>
      <description>arXiv:2404.14169v2 Announce Type: replace 
Abstract: Alzheimer's disease is the most common dementia worldwide. Its pathological development is well known to be connected with the accumulation of two toxic proteins: tau protein and amyloid-$\beta$. Mathematical models and numerical simulations can predict the spreading patterns of misfolded proteins in this context. However, the calibration of the model parameters plays a crucial role in the final solution. In this work, we perform a sensitivity analysis of heterodimer and Fisher-Kolmogorov models to evaluate the impact of the equilibrium values of protein concentration on the solution patterns. We adopt advanced numerical methods such as the IMEX-DG method to accurately describe the propagating fronts in the propagation phenomena in a polygonal mesh of sagittal patient-specific brain geometry derived from magnetic resonance images. We calibrate the model parameters using biological measurements in the brain cortex for the tau protein and the amyloid-$\beta$ in Alzheimer's patients and controls. Finally, using the sensitivity analysis results, we discuss the applicability of both models in the correct simulation of the spreading of the two proteins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14169v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.brain.2024.100098</arxiv:DOI>
      <arxiv:journal_reference>Brain Multiphysics 431. 100098 (2024)</arxiv:journal_reference>
      <dc:creator>Mattia Corti</dc:creator>
    </item>
    <item>
      <title>Evaluation of resonances: adaptivity and AAA rational approximation of randomly scalarized boundary integral resolvents</title>
      <link>https://arxiv.org/abs/2405.19582</link>
      <description>arXiv:2405.19582v2 Announce Type: replace 
Abstract: This paper presents a novel algorithm, based on use of rational approximants of a randomly scalarized boundary integral resolvent in conjunction with an adaptive search strategy and an exponentially convergent secant-method termination stage, for the evaluation of acoustic and electromagnetic resonances in open and closed cavities. The desired cavity resonances are obtained as the poles of associated rational approximants; both the approximants and their poles are obtained by means of the recently introduced AAA rational-approximation algorithm. In fact, the proposed resonance-search method applies to any nonlinear eigenvalue problem associated with a given function $F: U \to \mathbb{C}^{d\times d}$, wherein, denoting $F(k) = F_k$, a complex value $k$ is sought for which $F_kw = 0$ for some nonzero $w\in \mathbb{C}^d$. For the scattering problems considered in this paper, $F_k$ is taken to equal a spectrally discretized version of a Green function-based boundary integral operator at spatial frequency $k$. In all cases, the scalarized resolvent is given by an expression of the form $u^* F_k^{-1} v$, where $u,v \in \mathbb{C}^d$ are fixed random vectors. The proposed adaptive search strategy relies on use of a rectangular subdivision of the resonance search domain which is locally refined to ensure that all resonances in the domain are captured. The approach works equally well in the case in which the search domain is an interval of the real line, in which case the rectangles used degenerate into subintervals of the search domain. A variety of numerical results are presented, including comparisons with well-known methods based on complex contour integration, and a discussion of the asymptotics that result as open cavities approach closed cavities -- in all, demonstrating the accuracy provided by the method, for low- and high-frequency states alike.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19582v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar P. Bruno, Manuel A. Santana, Lloyd N. Trefethen</dc:creator>
    </item>
    <item>
      <title>Total Lagrangian Smoothed Particle Hydrodynamics with An Improved Bond-Based Deformation Gradient for Large Strain Solid Dynamics</title>
      <link>https://arxiv.org/abs/2407.04021</link>
      <description>arXiv:2407.04021v2 Announce Type: replace 
Abstract: Total Lagrangian Smoothed Particle Hydrodynamics (TLSPH) is one variant of SPH where the variables are described using the fixed reference configuration and a Lagrangian smoothing kernel. TLSPH elevates the computational efficiency of the standard SPH when no topological change is involved, and it alleviates the stability of SPH scheme with respect to tensile loading. However, instabilities associated with spurious mode, or hourglass/zero-energy mode, persists and often affects the simulation of solids undergoing extremely large strain. This work proposes an alternative formulation to compute deformation gradient with improved accuracy and therefore minimising the possibility of encountering the zero-energy mode. Specifically, we leverage the local discrete computation of bond-based (or pairwise) deformation gradient smoothed by the kernel. Additionally, the bond of a particle with itself is considered to preserve the polynomial reproducibility imposed by the kernel correction scheme. We showcase the convergence of the approach using a two-dimensional benchmark example. Furthermore, the accuracy, robustness, and stability of the proposed approach are assessed in various two- and three-dimensional examples, highlighting on the stability improvement that allows for solid dynamic simulations with more extreme elongation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04021v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.113309</arxiv:DOI>
      <dc:creator>I. M. Wiragunarsa, L. R. Zuhal, T. Dirgantara, I. S. Putra, E. Febrianto</dc:creator>
    </item>
    <item>
      <title>Multilevel Tau preconditioners for symmetrized multilevel Toeplitz systems with applications to solving space fractional diffusion equations</title>
      <link>https://arxiv.org/abs/2407.19386</link>
      <description>arXiv:2407.19386v2 Announce Type: replace 
Abstract: In this work, we develop a novel multilevel Tau matrix-based preconditioned method for a class of non-symmetric multilevel Toeplitz systems. This method not only accounts for but also improves upon an ideal preconditioner pioneered by [J. Pestana. Preconditioners for symmetrized Toeplitz and multilevel Toeplitz matrices. SIAM J. Matrix Anal. Appl., 40(3):870-887, 2019]. The ideal preconditioning approach was primarily examined numerically in that study, and an effective implementation was not included. To address these issues, we first rigorously show in this study that this ideal preconditioner can indeed achieve optimal convergence when employing the MINRES method, with a convergence rate is that independent of the mesh size. Then, building on this preconditioner, we develop a practical and optimal preconditioned MINRES method. To further illustrate its applicability and develop a fast implementation strategy, we consider solving Riemann-Liouville fractional diffusion equations as an application. Specifically, following standard discretization on the equation, the resultant linear system is a non-symmetric multilevel Toeplitz system, affirming the applicability of our preconditioning method. Through a simple symmetrization strategy, we transform the original linear system into a symmetric multilevel Hankel system. Subsequently, we propose a symmetric positive definite multilevel Tau preconditioner for the symmetrized system, which can be efficiently implemented using discrete sine transforms. Theoretically, we demonstrate that mesh-independent convergence can be achieved. In particular, we prove that the eigenvalues of the preconditioned matrix are bounded within disjoint intervals containing $\pm 1$, without any outliers. Numerical examples are provided to critically discuss the results, showcase the spectral distribution, and support the efficacy of our strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19386v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Congcong Li, Sean Hon</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of inner-iteration preconditioned GMRES</title>
      <link>https://arxiv.org/abs/2408.00693</link>
      <description>arXiv:2408.00693v2 Announce Type: replace 
Abstract: The objective of this paper is to understand the superlinear convergence behavior of the inner-iteration preconditioned GMRES method. In order to understand the phenomenon, we analyze the convergence using the Vandermonde matrix which is defined using the eigenvalues of the coefficient matrix. Although eigenvalues alone cannot explain the convergence, they may provide an upper bound of the residual, together with the right hand side vector and the eigenvectors. For the diagonalizable case, if the eigenvalues of the coefficient matrix are clustered, the upper bound of the convergence curve shows superlinear convergence, when the norm of the matrix obtained by decomposing the right hand side vector into the eigenvector components is not so large. We especially analyze the effect of inner-iteration preconditioning for least squares problems, where the eigenvalues cluster towards 1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00693v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Liao, Ken Hayami</dc:creator>
    </item>
    <item>
      <title>Domain Decomposition-based coupling of Operator Inference reduced order models via the Schwarz alternating method</title>
      <link>https://arxiv.org/abs/2409.01433</link>
      <description>arXiv:2409.01433v2 Announce Type: replace 
Abstract: This paper presents and evaluates an approach for coupling together subdomain-local reduced order models (ROMs) constructed via non-intrusive operator inference (OpInf) with each other and with subdomain-local full order models (FOMs), following a domain decomposition of the spatial geometry on which a given partial differential equation (PDE) is posed. Joining subdomain-local models is accomplished using the overlapping Schwarz alternating method, a minimally-intrusive multiscale coupling technique that works by transforming a monolithic problem into a sequence of subdomain-local problems, which communicate through transmission boundary conditions imposed on the subdomain interfaces. After formulating the overlapping Schwarz alternating method for OpInf ROMs, termed OpInf-Schwarz, we evaluate the method's accuracy and efficiency on several test cases involving the heat equation in two spatial dimensions. We demonstrate that the method is capable of coupling together arbitrary combinations of OpInf ROMs and FOMs, and that speed-ups over a monolithic FOM are possible when performing OpInf ROM coupling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01433v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian Moore, Christopher Wentland, Anthony Gruber, Irina Tezaur</dc:creator>
    </item>
    <item>
      <title>An Efficient Framework for Global Non-Convex Polynomial Optimization with Algebraic Constraints</title>
      <link>https://arxiv.org/abs/2311.02037</link>
      <description>arXiv:2311.02037v2 Announce Type: replace-cross 
Abstract: We present an efficient framework for solving algebraically-constrained global non-convex polynomial optimization problems over subsets of the hypercube. We prove the existence of an equivalent nonlinear reformulation of such problems that possesses essentially no spurious local minima. Through numerical experiments on previously intractable global constrained polynomial optimization problems in high dimension, we show that polynomial scaling in dimension and degree is achievable when computing the optimal value and location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02037v2</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mitchell Tong Harris, Pierre-David Letourneau, Dalton Jones, M. Harper Langston</dc:creator>
    </item>
    <item>
      <title>Tensor product algorithms for inference of contact network from epidemiological data</title>
      <link>https://arxiv.org/abs/2401.15031</link>
      <description>arXiv:2401.15031v2 Announce Type: replace-cross 
Abstract: We consider a problem of inferring contact network from nodal states observed during an epidemiological process. In a black--box Bayesian optimisation framework this problem reduces to a discrete likelihood optimisation over the set of possible networks. The cardinality of this set grows combinatorially with the number of network nodes, which makes this optimisation computationally challenging. For each network, its likelihood is the probability for the observed data to appear during the evolution of the epidemiological process on this network. This probability can be very small, particularly if the network is significantly different from the ground truth network, from which the observed data actually appear. A commonly used stochastic simulation algorithm struggles to recover rare events and hence to estimate small probabilities and likelihoods. In this paper we replace the stochastic simulation with solving the chemical master equation for the probabilities of all network states. Since this equation also suffers from the curse of dimensionality, we apply tensor train approximations to overcome it and enable fast and accurate computations. Numerical simulations demonstrate efficient black--box Bayesian inference of the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15031v2</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1186/s12859-024-05910-7</arxiv:DOI>
      <arxiv:journal_reference>BMC Bioinformatics 25, 285 (2024)</arxiv:journal_reference>
      <dc:creator>Sergey Dolgov, Dmitry Savostyanov</dc:creator>
    </item>
    <item>
      <title>Fast and interpretable Support Vector Classification based on the truncated ANOVA decomposition</title>
      <link>https://arxiv.org/abs/2402.02438</link>
      <description>arXiv:2402.02438v2 Announce Type: replace-cross 
Abstract: Support Vector Machines (SVMs) are an important tool for performing classification on scattered data, where one usually has to deal with many data points in high-dimensional spaces. We propose solving SVMs in primal form using feature maps based on trigonometric functions or wavelets. In small dimensional settings the Fast Fourier Transform (FFT) and related methods are a powerful tool in order to deal with the considered basis functions. For growing dimensions the classical FFT-based methods become inefficient due to the curse of dimensionality. Therefore, we restrict ourselves to multivariate basis functions, each of which only depends on a small number of dimensions. This is motivated by the well-known sparsity of effects and recent results regarding the reconstruction of functions from scattered data in terms of truncated analysis of variance (ANOVA) decompositions, which makes the resulting model even interpretable in terms of importance of the features as well as their couplings. The usage of small superposition dimensions has the consequence that the computational effort no longer grows exponentially but only polynomially with respect to the dimension. In order to enforce sparsity regarding the basis coefficients, we use the frequently applied $\ell_2$-norm and, in addition, $\ell_1$-norm regularization. The found classifying function, which is the linear combination of basis functions, and its variance can then be analyzed in terms of the classical ANOVA decomposition of functions. Based on numerical examples we show that we are able to recover the signum of a function that perfectly fits our model assumptions. Furthermore, we perform classification on different artificial and real-world data sets. We obtain better results with $\ell_1$-norm regularization, both in terms of accuracy and clarity of interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02438v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kseniya Akhalaya, Franziska Nestler, Daniel Potts</dc:creator>
    </item>
  </channel>
</rss>
