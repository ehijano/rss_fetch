<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 04:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deconvolution of distribution functions without integral transforms</title>
      <link>https://arxiv.org/abs/2510.25916</link>
      <description>arXiv:2510.25916v1 Announce Type: new 
Abstract: We study the recovery of the distribution function $F_X$ of a random variable $X$ that is subject to an independent additive random error $\varepsilon$. To be precise, it is assumed that the target variable $X$ is available only in the form of a blurred surrogate $Y = X + \varepsilon$. The distribution function $F_Y$ then corresponds to the convolution of $F_X$ and $F_\varepsilon$, so that the reconstruction of $F_X$ is some kind of deconvolution problem. Those have a long history in mathematics and various approaches have been proposed in the past. Most of them use integral transforms or matrix algorithms. The present article avoids these tools and is entirely confined to the domain of distribution functions. Our main idea relies on a transformation of a first kind to a second kind integral equation. Thereof, starting with a right-lateral discrete target and error variable, a representation for $F_X$ in terms of available quantities is obtained, which facilitates the unbiased estimation through a $Y$-sample. It turns out that these results even extend to cases in which $X$ is not discrete. Finally, in a general setup, our approach gives rise to an approximation for $F_X$ as a certain Neumann sum. The properties of this sum are briefly examined theoretically and visually. The paper is concluded with a short discussion of operator theoretical aspects and an outlook on further research. Various plots underline our results and illustrate the capabilities of our functions with regard to estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25916v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Kaiser</dc:creator>
    </item>
    <item>
      <title>Fixed and Increasing Domain Asymptotics for the Roughness and Scale of Isotropic Gaussian Random Fields</title>
      <link>https://arxiv.org/abs/2510.26045</link>
      <description>arXiv:2510.26045v1 Announce Type: new 
Abstract: We establish a rigorous asymptotic theory for the joint estimation of roughness and scale parameters in two-dimensional Gaussian random fields with power-law generalized covariances \cite{Matheron1973, Stein1999, Yaglom1987}. Our main results are bivariate central limit theorems for a class of method-of-moments estimators under increasing-domain and fixed-domain asymptotics. The fixed-domain result follows immediately from the increasing-domain result from the self-similarity of Gaussian random fields with power-law generalized covariances \cite{IstasLang1997, Coeurjolly2001, ZhuStein2002}. These results provide a unified distributional framework across these two classical regimes \cite{AvramLeonenkoSakhno2010-ESAIM, BiermeBonamiLeon2011-EJP} that makes the unusual behavior of the estimates under fixed-domain asymptotics intuitively obvious. Our increasing-domain asymptotic results use spatial averages of quadratic forms of (iterated) bilinear product difference filters that yield explicit expressions for the estimates of roughness and scale to which existing theorems on such averages \cite{BreuerMajor1983,Hannan1970} can be readily applied. We further show that the asymptotics remain valid under modestly irregular sampling due to jitter or missing observations. For the fixed-domain setting, the results extend to models that behave sufficiently like the power-law model at high frequencies such as the often used Mat\'ern model \cite{ZhuStein2006, WangLoh2011EJS, KaufmanShaby2017EJS}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26045v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Varun Kotharkar, Michael L. Stein</dc:creator>
    </item>
    <item>
      <title>Sequential Change Detection Under A Markov Setup With Unknown Pre-Change and Post-Change Distributions</title>
      <link>https://arxiv.org/abs/2510.26204</link>
      <description>arXiv:2510.26204v1 Announce Type: new 
Abstract: In this work we extend the results developed in 2022 for a sequential change detection algorithm making use of Page's CUSUM statistic, the empirical distribution as an estimate of the pre-change distribution, and a universal code as a tool for estimating the post-change distribution, from the i.i.d. case to the Markov setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26204v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashish Bhoopesh Gulaguli, Shashwat Singh, Rakesh Kumar Bansal</dc:creator>
    </item>
    <item>
      <title>A theoretical comparison of weight constraints in forecast combination and model averaging</title>
      <link>https://arxiv.org/abs/2510.26456</link>
      <description>arXiv:2510.26456v1 Announce Type: new 
Abstract: Forecast combination and model averaging have become popular tools in forecasting and prediction, both of which combine a set of candidate estimates with certain weights and are often shown to outperform single estimates. A data-driven method to determine combination/averaging weights typically optimizes a criterion under certain weight constraints. While a large number of studies have been devoted to developing and comparing various weight choice criteria, the role of weight constraints on the properties of combination forecasts is relatively less understood, and the use of various constraints in practice is also rather arbitrary. In this study, we summarize prevalent weight constraints used in the literature, and theoretically and numerically compare how they influence the properties of the combined forecast. Our findings not only provide a comprehensive understanding on the role of various weight constraints but also practical guidance for empirical researchers how to choose relevant constraints based on prior information and targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26456v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahui Zou, Andrey Vasnev, Wendun Wang, Xinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Linear regression with known noise distribution up to a scale: The reward of not using the OLSE</title>
      <link>https://arxiv.org/abs/2510.26539</link>
      <description>arXiv:2510.26539v1 Announce Type: new 
Abstract: While the ordinary least squares estimator (OLSE) is still the most used estimator in linear regression models, other estimators can be more efficient when the error distribution is not Gaussian. In this paper, our goal is to evaluate this efficiency in the case of the Maximum Likelihood estimator (MLE) when the noise distribution belongs to a scale family. Under some regularity conditions, we show that (\beta_n,s_n), the MLE of the unknown regression vector \beta_0 and the scale s_0 exists and give the expression of the asymptotic efficiency of \beta_n over the OLSE. For given three scale families of densities, we quantify the true statistical gain of the MLE as a function of their deviation from the Gaussian family. To illustrate the theory, we present simulation results for different settings and also compare the MLE to the OLSE for the real market fish dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26539v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fadoua Balabdaoui, Justine Leclerc</dc:creator>
    </item>
    <item>
      <title>Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms</title>
      <link>https://arxiv.org/abs/2510.25811</link>
      <description>arXiv:2510.25811v1 Announce Type: cross 
Abstract: We consider a stochastic multi-armed bandit problem with i.i.d. rewards where the expected reward function is multimodal with at most m modes. We propose the first known computationally tractable algorithm for computing the solution to the Graves-Lai optimization problem, which in turn enables the implementation of asymptotically optimal algorithms for this bandit problem. The code for the proposed algorithms is publicly available at https://github.com/wilrev/MultimodalBandits</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25811v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William R\'eveillard, Richard Combes</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference in Boundary Discontinuity Designs: Distance-Based Methods</title>
      <link>https://arxiv.org/abs/2510.26051</link>
      <description>arXiv:2510.26051v1 Announce Type: cross 
Abstract: We study the statistical properties of nonparametric distance-based (isotropic) local polynomial regression estimators of the boundary average treatment effect curve, a key causal functional parameter capturing heterogeneous treatment effects in boundary discontinuity designs. We present necessary and/or sufficient conditions for identification, estimation, and inference in large samples, both pointwise and uniformly along the boundary. Our theoretical results highlight the crucial role played by the ``regularity'' of the boundary (a one-dimensional manifold) over which identification, estimation, and inference are conducted. Our methods are illustrated with simulated data. Companion general-purpose software is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26051v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo (Rae), Rocio Titiunik (Rae),  Ruiqi (Rae),  Yu</dc:creator>
    </item>
    <item>
      <title>Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization</title>
      <link>https://arxiv.org/abs/2510.26068</link>
      <description>arXiv:2510.26068v1 Announce Type: cross 
Abstract: This paper proposes a novel paradigm for machine learning that moves beyond traditional parameter optimization. Unlike conventional approaches that search for optimal parameters within a fixed geometric space, our core idea is to treat the model itself as a malleable geometric entity. Specifically, we optimize the metric tensor field on a manifold with a predefined topology, thereby dynamically shaping the geometric structure of the model space. To achieve this, we construct a variational framework whose loss function carefully balances data fidelity against the intrinsic geometric complexity of the manifold. The former ensures the model effectively explains observed data, while the latter acts as a regularizer, penalizing overly curved or irregular geometries to encourage simpler models and prevent overfitting. To address the computational challenges of this infinite-dimensional optimization problem, we introduce a practical method based on discrete differential geometry: the continuous manifold is discretized into a triangular mesh, and the metric tensor is parameterized by edge lengths, enabling efficient optimization using automatic differentiation tools. Theoretical analysis reveals a profound analogy between our framework and the Einstein-Hilbert action in general relativity, providing an elegant physical interpretation for the concept of "data-driven geometry". We further argue that even with fixed topology, metric optimization offers significantly greater expressive power than models with fixed geometry. This work lays a solid foundation for constructing fully dynamic "meta-learners" capable of autonomously evolving their geometry and topology, and it points to broad application prospects in areas such as scientific model discovery and robust representation learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26068v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.DG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
    <item>
      <title>Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics</title>
      <link>https://arxiv.org/abs/2510.26324</link>
      <description>arXiv:2510.26324v1 Announce Type: cross 
Abstract: Given a noisy linear measurement $y = Ax + \xi$ of a distribution $p(x)$, and a good approximation to the prior $p(x)$, when can we sample from the posterior $p(x \mid y)$? Posterior sampling provides an accurate and fair framework for tasks such as inpainting, deblurring, and MRI reconstruction, and several heuristics attempt to approximate it. Unfortunately, approximate posterior sampling is computationally intractable in general.
  To sidestep this hardness, we focus on (local or global) log-concave distributions $p(x)$. In this regime, Langevin dynamics yields posterior samples when the exact scores of $p(x)$ are available, but it is brittle to score--estimation error, requiring an MGF bound (sub-exponential error). By contrast, in the unconditional setting, diffusion models succeed with only an $L^2$ bound on the score error. We prove that combining diffusion models with an annealed variant of Langevin dynamics achieves conditional sampling in polynomial time using merely an $L^4$ bound on the score error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26324v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyang Xun, Shivam Gupta, Eric Price</dc:creator>
    </item>
    <item>
      <title>Higher-Order Regularization Learning on Hypergraphs</title>
      <link>https://arxiv.org/abs/2510.26533</link>
      <description>arXiv:2510.26533v1 Announce Type: cross 
Abstract: Higher-Order Hypergraph Learning (HOHL) was recently introduced as a principled alternative to classical hypergraph regularization, enforcing higher-order smoothness via powers of multiscale Laplacians induced by the hypergraph structure. Prior work established the well- and ill-posedness of HOHL through an asymptotic consistency analysis in geometric settings. We extend this theoretical foundation by proving the consistency of a truncated version of HOHL and deriving explicit convergence rates when HOHL is used as a regularizer in fully supervised learning. We further demonstrate its strong empirical performance in active learning and in datasets lacking an underlying geometric structure, highlighting HOHL's versatility and robustness across diverse learning settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26533v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrien Weihs, Andrea Bertozzi, Matthew Thorpe</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</title>
      <link>https://arxiv.org/abs/2510.26723</link>
      <description>arXiv:2510.26723v1 Announce Type: cross 
Abstract: The goal of policy learning is to train a policy function that recommends a treatment given covariates to maximize population welfare. There are two major approaches in policy learning: the empirical welfare maximization (EWM) approach and the plug-in approach. The EWM approach is analogous to a classification problem, where one first builds an estimator of the population welfare, which is a functional of policy functions, and then trains a policy by maximizing the estimated welfare. In contrast, the plug-in approach is based on regression, where one first estimates the conditional average treatment effect (CATE) and then recommends the treatment with the highest estimated outcome. This study bridges the gap between the two approaches by showing that both are based on essentially the same optimization problem. In particular, we prove an exact equivalence between EWM and least squares over a reparameterization of the policy class. As a consequence, the two approaches are interchangeable in several respects and share the same theoretical guarantees under common conditions. Leveraging this equivalence, we propose a novel regularization method for policy learning. Our findings yield a convex and computationally efficient training procedure that avoids the NP-hard combinatorial step typically required in EWM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26723v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</title>
      <link>https://arxiv.org/abs/2510.26783</link>
      <description>arXiv:2510.26783v1 Announce Type: cross 
Abstract: This note introduces a unified theory for causal inference that integrates Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted maximum likelihood estimation (TMLE), and the matching estimator in average treatment effect (ATE) estimation. In ATE estimation, the balancing weights and the regression functions of the outcome play important roles, where the balancing weights are referred to as the Riesz representer, bias-correction term, and clever covariates, depending on the context. Riesz regression, covariate balancing, DRE, and the matching estimator are methods for estimating the balancing weights, where Riesz regression is essentially equivalent to DRE in the ATE context, the matching estimator is a special case of DRE, and DRE is in a dual relationship with covariate balancing. TMLE is a method for constructing regression function estimators such that the leading bias term becomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density Ratio Estimation and Riesz Regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26783v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Wasserstein Rate Driven CLTs for Markov Chains with Weighted Lipschitz, Sobolev, and Stein Test Functions</title>
      <link>https://arxiv.org/abs/2002.09427</link>
      <description>arXiv:2002.09427v5 Announce Type: replace 
Abstract: Many tools are available to bound the convergence rate of Markov chains in total variation (TV) distance. Such results can be used to establish central limit theorems (CLT) that enable error evaluations of Monte Carlo estimates in practice. However, convergence analysis based on TV distance is often non-scalable to high-dimensional Markov chains (Qin and Hobert (2018); Rajaratnam and Sparks (2015)). Alternatively, robust bounds in Wasserstein distance are often easier to obtain, thanks to a coupling argument. Our work is concerned with the implication of such convergence results, in particular, do they lead to CLTs of the corresponding Markov chains? One indirect and typically non-trivial way is to first convert Wasserstein bounds into total variation bounds. Alternatively, we provide two CLTs that directly depend on (sub-geometric) convergence rates in Wasserstein distance. Our CLTs hold for Lipschitz functions under certain moment conditions. We also present two possible ways to lift obtained CLTs to a larger weighted Lipschitz class of functions. We further take an analytic route to obtain CLTs for a weighted Sobolev class and Stein test functions based on $W_2$ convergence. Finally, we apply these CLTs to five sets of Markov chain examples including a class of nonlinear autoregressive processes, a linear Gaussian chain, an exponential integrator version of the metropolis adjusted Langevin algorithm (EI-MALA), an unadjusted Langevin algorithm (ULA), and a special autoregressive model that generates reducible chains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.09427v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Jin, Aixin Tan</dc:creator>
    </item>
    <item>
      <title>Survey Data Integration for Distribution Function Estimation</title>
      <link>https://arxiv.org/abs/2409.14284</link>
      <description>arXiv:2409.14284v5 Announce Type: replace 
Abstract: Estimates of finite population cumulativedistribution functions (CDFs) and quantiles are critical forpolicy-making, resource allocation, and public health planning. For instance, federal finance agencies may require accurate estimates of the proportion of individuals with income below the federal poverty line to determine funding eligibility, while health organizations may rely on precise quantile estimates of key health variables to guide local health interventions. Despite growing interest in survey data integration, research on the integration of probability and nonprobability samples toestimate CDFs and quantiles remains limited. In this study, we propose a novel residual-based CDF estimator that integrates information from a probability sample with data from potentially large nonprobability samples. Our approach leverages shared covariates observed in both datasets, while the response variable is available only in the nonprobability sample. Using a semiparametric approach, we train an outcome model on the nonprobability sample and incorporate model residuals with sampling weights from the probability sample to estimate the CDF of the target variable. Based on this CDF estimator, we define a quantile estimator and introduce linearization and bootstrap methods for variance estimation of both the CDF and quantile estimators. Under certain regularity conditions, we establish the asymptotic properties, including bias and variance, of the CDF estimator. Our empirical findings support the theoretical results and demonstrate the favorable performance of the proposed estimators relative to plug-in mass imputation estimators and the na\"ive estimators derived from the nonprobability sample only. A real data example is presented to illustrate the proposed estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14284v5</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Flood, Sayed Mostafa</dc:creator>
    </item>
    <item>
      <title>Extreme Value Analysis based on Blockwise Top-Two Order Statistics</title>
      <link>https://arxiv.org/abs/2502.15036</link>
      <description>arXiv:2502.15036v2 Announce Type: replace 
Abstract: Extreme value analysis for time series is often based on the block maxima method, in particular for environmental applications. In the classical univariate case, the latter is based on fitting an extreme-value distribution to the sample of (annual) block maxima. Mathematically, the target parameters of the extreme-value distribution also show up in limit results for other high order statistics, which suggests estimation based on blockwise large order statistics. It is shown that a naive approach based on maximizing an independence log-likelihood yields an estimator that is inconsistent in general. A consistent, bias-corrected estimator is proposed, and is analyzed theoretically and in finite-sample simulation studies. The new estimator is shown to be more efficient than traditional counterparts, for instance for estimating large return levels or return periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15036v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Axel B\"ucher, Erik Haufs</dc:creator>
    </item>
    <item>
      <title>Parameter estimation from local measurements for a class of stochastic Burgers equations</title>
      <link>https://arxiv.org/abs/2503.09507</link>
      <description>arXiv:2503.09507v2 Announce Type: replace 
Abstract: We deal with a class of semilinear SPDEs driven by space-time white noise that includes the one dimensional stochastic Burgers equation. Such equations can have nonlocal and quadratic nonlinearities. We consider the problem of estimation of the diffusivity parameter in front of the second-order spatial derivative. Based on local observations in space, we study the estimator derived in [Altmeyer, Rei\ss , Ann. Appl. Probab.(2021)] for linear stochastic heat equation that has also been used in [Altmeyer, Cialenco, Pasemann, Bernoulli (2023)] to cover certain class of semilinear SPDEs including stochastic Burgers equations driven by trace class noise. The space-time white noise case we consider has also relevant physical motivations. After we establish new regularity results for the solution, we are able to show that our proposed estimator is strongly consistent and asymptotically normal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09507v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josef Jan\'ak, Enrico Priola</dc:creator>
    </item>
    <item>
      <title>A Fourier-based inference method for learning interaction kernels in particle systems</title>
      <link>https://arxiv.org/abs/2505.05207</link>
      <description>arXiv:2505.05207v2 Announce Type: replace 
Abstract: We consider the problem of inferring the interaction kernel of stochastic interacting particle systems from observations of a single particle. We adopt a semi-parametric approach and represent the interaction kernel in terms of a generalized Fourier series. The basis functions in this expansion are tailored to the problem at hand and are chosen to be orthogonal polynomials with respect to the invariant measure of the mean-field dynamics. The generalized Fourier coefficients are obtained as the solution of an appropriate linear system whose coefficients depend on the moments of the invariant measure, and which are approximated from the particle trajectory that we observe. We quantify the approximation error in the Lebesgue space weighted by the invariant measure and study the asymptotic properties of the estimator in the joint limit as the observation interval and the number of particles tend to infinity, i.e. the joint large time-mean field limit. We also explore the regime where an increasing number of generalized Fourier coefficients is needed to represent the interaction kernel. Our theoretical results are supported by extensive numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05207v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigorios A. Pavliotis, Andrea Zanoni</dc:creator>
    </item>
    <item>
      <title>Maximum Likelihood Estimation in the Multivariate and Matrix Variate Symmetric Laplace Distributions through Group Actions</title>
      <link>https://arxiv.org/abs/2510.24863</link>
      <description>arXiv:2510.24863v2 Announce Type: replace 
Abstract: In this paper, we study the maximum likelihood estimation of the parameters of the multivariate and matrix variate symmetric Laplace distributions through group actions. The multivariate and matrix variate symmetric Laplace distributions are not in the exponential family of distributions. We relate the maximum likelihood estimation problems of these distributions to norm minimization over a group and build a correspondence between stability of data with respect to the group action and the properties of the likelihood function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24863v2</guid>
      <category>math.ST</category>
      <category>math.AG</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pooja Yadav, Tanuja Srivastava</dc:creator>
    </item>
    <item>
      <title>Random pairing MLE for estimation of item parameters in Rasch model</title>
      <link>https://arxiv.org/abs/2406.13989</link>
      <description>arXiv:2406.13989v2 Announce Type: replace-cross 
Abstract: The Rasch model, a classical model in the item response theory, is widely used in psychometrics to model the relationship between individuals' latent traits and their binary responses to assessments or questionnaires. In this paper, we introduce a new likelihood-based estimator -- random pairing maximum likelihood estimator ($\mathrm{RP\text{-}MLE}$) and its bootstrapped variant multiple random pairing MLE ($\mathrm{MRP\text{-}MLE}$) which faithfully estimate the item parameters in the Rasch model. The new estimators have several appealing features compared to existing ones. First, both work for sparse observations, an increasingly important scenario in the big data era. Second, both estimators are provably minimax optimal in terms of finite sample $\ell_{\infty}$ estimation error. Lastly, both admit precise distributional characterization that allows uncertainty quantification on the item parameters, e.g., construction of confidence intervals for the item parameters. The main idea underlying $\mathrm{RP\text{-}MLE}$ and $\mathrm{MRP\text{-}MLE}$ is to randomly pair user-item responses to form item-item comparisons. This is carefully designed to reduce the problem size while retaining statistical independence. We also provide empirical evidence of the efficacy of the two new estimators using both simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13989v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuepeng Yang, Cong Ma</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference in Boundary Discontinuity Designs: Location-Based Methods</title>
      <link>https://arxiv.org/abs/2505.05670</link>
      <description>arXiv:2505.05670v2 Announce Type: replace-cross 
Abstract: Boundary discontinuity designs are used to learn about causal treatment effects along a continuous assignment boundary that splits units into control and treatment groups according to a bivariate location score. We analyze the statistical properties of local polynomial treatment effect estimators employing location information for each unit. We develop pointwise and uniform estimation and inference methods for both the conditional treatment effect function at the assignment boundary as well as for transformations thereof, which aggregate information along the boundary. We illustrate our methods with an empirical application. Companion general-purpose software is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05670v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Rocio Titiunik, Ruiqi Rae Yu</dc:creator>
    </item>
    <item>
      <title>Direct Debiased Machine Learning via Bregman Divergence Minimization</title>
      <link>https://arxiv.org/abs/2510.23534</link>
      <description>arXiv:2510.23534v2 Announce Type: replace-cross 
Abstract: We develop a direct debiased machine learning framework comprising Neyman targeted estimation and generalized Riesz regression. Our framework unifies Riesz regression for automatic debiased machine learning, covariate balancing, targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In many problems involving causal effects or structural models, the parameters of interest depend on regression functions. Plugging regression functions estimated by machine learning methods into the identifying equations can yield poor performance because of first-stage bias. To reduce such bias, debiased machine learning employs Neyman orthogonal estimating equations. Debiased machine learning typically requires estimation of the Riesz representer and the regression function. For this problem, we develop a direct debiased machine learning framework with an end-to-end algorithm. We formulate estimation of the nuisance parameters, the regression function and the Riesz representer, as minimizing the discrepancy between Neyman orthogonal scores computed with known and unknown nuisance parameters, which we refer to as Neyman targeted estimation. Neyman targeted estimation includes Riesz representer estimation, and we measure discrepancies using the Bregman divergence. The Bregman divergence encompasses various loss functions as special cases, where the squared loss yields Riesz regression and the Kullback-Leibler divergence yields entropy balancing. We refer to this Riesz representer estimation as generalized Riesz regression. Neyman targeted estimation also yields TMLE as a special case for regression function estimation. Furthermore, for specific pairs of models and Riesz representer estimation methods, we can automatically obtain the covariate balancing property without explicitly solving the covariate balancing objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23534v2</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
  </channel>
</rss>
