<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 01:51:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Low-Depth Quantum Signal-Processing Phase Estimation</title>
      <link>https://arxiv.org/abs/2407.01583</link>
      <description>arXiv:2407.01583v1 Announce Type: cross 
Abstract: Quantum effects like entanglement and coherent amplification can be used to drastically enhance the accuracy of quantum parameter estimation beyond classical limits. However, challenges such as decoherence and time-dependent errors hinder Heisenberg-limited amplification. We introduce Quantum Signal-Processing Phase Estimation algorithms that are robust against these challenges and achieve optimal performance as dictated by the Cram\'{e}r-Rao bound. These algorithms use quantum signal transformation to decouple interdependent phase parameters into largely orthogonal ones, ensuring that time-dependent errors in one do not compromise the accuracy of learning the other. Combining provably optimal classical estimation with near-optimal quantum circuit design, our approach achieves an unprecedented standard deviation accuracy of $10^{-4}$ radians for estimating unwanted swap angles in superconducting two-qubit experiments, using low-depth ($&lt;10$) circuits. This represents up to two orders of magnitude improvement over existing methods. Theoretically and numerically, we demonstrate the optimality of our algorithm against time-dependent phase errors, observing that the variance of the time-sensitive parameter $\varphi$ scales faster than the asymptotic Heisenberg scaling in the small-depth regime. Our results are rigorously validated against the quantum Fisher information, confirming our protocol's ability to achieve unmatched precision for two-qubit gate learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01583v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulong Dong, Jonathan A. Gross, Murphy Yuezhen Niu</dc:creator>
    </item>
    <item>
      <title>Statistical signatures of abstraction in deep neural networks</title>
      <link>https://arxiv.org/abs/2407.01656</link>
      <description>arXiv:2407.01656v1 Announce Type: cross 
Abstract: We study how abstract representations emerge in a Deep Belief Network (DBN) trained on benchmark datasets. Our analysis targets the principles of learning in the early stages of information processing, starting from the "primordial soup" of the under-sampling regime. As the data is processed by deeper and deeper layers, features are detected and removed, transferring more and more "context-invariant" information to deeper layers. We show that the representation approaches an universal model -- the Hierarchical Feature Model (HFM) -- determined by the principle of maximal relevance. Relevance quantifies the uncertainty on the model of the data, thus suggesting that "meaning" -- i.e. syntactic information -- is that part of the data which is not yet captured by a model. Our analysis shows that shallow layers are well described by pairwise Ising models, which provide a representation of the data in terms of generic, low order features. We also show that plasticity increases with depth, in a similar way as it does in the brain. These findings suggest that DBNs are capable of extracting a hierarchy of features from the data which is consistent with the principle of maximal relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01656v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlo Orientale Caputo, Matteo Marsili</dc:creator>
    </item>
    <item>
      <title>A Mereological Approach to Higher-Order Structure in Complex Systems: from Macro to Micro with M\"obius</title>
      <link>https://arxiv.org/abs/2404.14423</link>
      <description>arXiv:2404.14423v4 Announce Type: replace 
Abstract: Relating microscopic interactions to macroscopic observables is a central challenge in the study of complex systems. Addressing this question requires understanding both pairwise and higher-order interactions, but the latter are less well understood. We present a unified mathematical formalism for deriving higher-order interactions from macroscopic observables, relative to a chosen decomposition of the system into its parts. Applying this framework to a diverse range of systems, we demonstrate that many existing notions of higher-order interactions, from epistasis in genetics and many-body couplings in physics, to synergy in game theory and artificial intelligence, naturally and uniquely arise from an appropriate mereological decomposition through the M\"obius inversion theorem. By revealing the common mathematical structure underlying seemingly disparate phenomena, our work highlights the fundamental role of decomposition choice in the definition and estimation of higher-order interactions. We discuss how this unifying perspective can facilitate the transfer of insights across domains, guide the selection of appropriate system decompositions, and enable the search for new notions of interaction. To illustrate how this works in practice, we derive a new decomposition of the Kullback-Leibler divergence, and show that it correctly disentangles divergences among the variables of simulated spin models. Our results suggest that the M\"obius inversion theorem provides a powerful and practical lens for understanding the emergence of complex behaviour from the interplay of microscopic parts, with applications across a wide range of disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14423v4</guid>
      <category>physics.data-an</category>
      <category>physics.bio-ph</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abel Jansma</dc:creator>
    </item>
    <item>
      <title>Type-II Saddles and Probabilistic Stability of Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2303.13093</link>
      <description>arXiv:2303.13093v4 Announce Type: replace-cross 
Abstract: Characterizing and understanding the dynamics of stochastic gradient descent (SGD) around saddle points remains an open problem. We first show that saddle points in neural networks can be divided into two types, among which the Type-II saddles are especially difficult to escape from because the gradient noise vanishes at the saddle. The dynamics of SGD around these saddles are thus to leading order described by a random matrix product process, and it is thus natural to study the dynamics of SGD around these saddles using the notion of probabilistic stability and the related Lyapunov exponent. Theoretically, we link the study of SGD dynamics to well-known concepts in ergodic theory, which we leverage to show that saddle points can be either attractive or repulsive for SGD, and its dynamics can be classified into four different phases, depending on the signal-to-noise ratio in the gradient close to the saddle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13093v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liu Ziyin, Botao Li, Tomer Galanti, Masahito Ueda</dc:creator>
    </item>
    <item>
      <title>Learning protein-ligand unbinding pathways via single-parameter community detection</title>
      <link>https://arxiv.org/abs/2402.07103</link>
      <description>arXiv:2402.07103v4 Announce Type: replace-cross 
Abstract: Understanding the dynamics of biomolecular complexes, e.g., of protein-ligand (un)binding, requires the understanding of paths such systems take between metastable states. In MD simulation data, paths are usually not observable per se, but need to be inferred from simulation trajectories. Here we present a novel approach to cluster trajectories based on a community detection algorithm that requires the definition of only a single free parameter. Using the streptavidin-biotin complex as benchmark system and the A\textsubscript{2a} adenosine receptor in complex with the inhibitor ZM241385 as an elaborate application, we demonstrate how such clusters of trajectories correspond to pathways, and how the approach helps in the identification of reaction coordinates for a considered (un)binding process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07103v4</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1021/acs.jctc.4c00250</arxiv:DOI>
      <arxiv:journal_reference>J. Chem. Theory Comput. 20, 5058-5067 (2024)</arxiv:journal_reference>
      <dc:creator>Victor T\"anzel, Miriam J\"ager, Steffen Wolf</dc:creator>
    </item>
    <item>
      <title>Classifier Surrogates: Sharing AI-based Searches with the World</title>
      <link>https://arxiv.org/abs/2402.15558</link>
      <description>arXiv:2402.15558v2 Announce Type: replace-cross 
Abstract: In recent years, neural network-based classification has been used to improve data analysis at collider experiments. While this strategy proves to be hugely successful, the underlying models are not commonly shared with the public and rely on experiment-internal data as well as full detector simulations. We show a concrete implementation of a newly proposed strategy, so-called Classifier Surrogates, to be trained inside the experiments, that only utilise publicly accessible features and truth information. These surrogates approximate the original classifier distribution, and can be shared with the public. Subsequently, such a model can be evaluated by sampling the classification output from high-level information without requiring a sophisticated detector simulation. Technically, we show that Continuous Normalizing Flows are a suitable generative architecture that can be efficiently trained to sample classification results using Conditional Flow Matching. We further demonstrate that these models can be easily extended by Bayesian uncertainties to indicate their degree of validity when confronted with unknown inputs by the user. For a concrete example of tagging jets from hadronically decaying top quarks, we demonstrate the application of flows in combination with uncertainty estimation through either inference of a mean-field Gaussian weight posterior, or Monte Carlo sampling network weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15558v2</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Bieringer, Gregor Kasieczka, Jan Kieseler, Mathias Trabs</dc:creator>
    </item>
  </channel>
</rss>
