<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Jan 2025 11:19:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Knowledge Phenomenology Research of Future Industrial Iconic Product Innovation</title>
      <link>https://arxiv.org/abs/2501.07141</link>
      <description>arXiv:2501.07141v1 Announce Type: new 
Abstract: Iconic products, as innovative carriers supporting the development of future industries, are key breakthrough points for driving the transformation of new quality productive forces. This article is grounded in the philosophy of technology and examines the evolution of human civilization to accurately identify the patterns of product innovation. By integrating theories from systems science, it analyzes the intrinsic logical differences between traditional products and iconic products. The study finds that iconic products are based on a comprehensive knowledge system that integrates explicit and tacit knowledge, enabling them to adapt to complex dynamic environments. Therefore, based on the method of phenomenological essence reduction and the process of specialized knowledge acquisition, this study establishes the first principle of knowledge phenomenology: "knowledge generation-moving from the tacit to the explicit-moving from the explicit to the tacit-fusion of the explicit and tacit." Grounded in knowledge phenomenology, it reconstructs the product design evolution process and establishes a forward innovative design framework for iconic products, consisting of "design problem space-explicit knowledge space-tacit knowledge space-innovative solution space." Furthermore, based on FBS design theory, it develops a disruptive technology innovation forecasting framework of "technology problem space-knowledge base prediction-application scenario prediction-coupled technology prediction," which collectively advances the innovation systems engineering of iconic products. In light of the analysis of the global future industrial competitive landscape, it proposes a strategy for enhancing embodied intelligence in iconic products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07141v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiang Xu, Haoxiang Qu</dc:creator>
    </item>
    <item>
      <title>Entry deterrence by exploiting economies of scope in data aggregation</title>
      <link>https://arxiv.org/abs/2501.07235</link>
      <description>arXiv:2501.07235v1 Announce Type: new 
Abstract: We model a market for data where an incumbent and a challenger compete for data from a producer. The incumbent has access to an exclusive data producer, and it uses this exclusive access, together with economies of scope in the aggregation of the data, as a strategy against the potential entry by the challenger. We assess the incumbent incentives to either deter or accommodate the entry of the challenger. We show that the incumbent will accommodate when the exclusive access is costly and when the economies of scope are low, and it will blockade or deter otherwise. The results would justify an access regulation that incentivizes the entry of the challenger, e.g., by increasing production costs for the exclusive data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07235v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luis Guijarro, Jos\'e-Ram\'on Vidal, Vicent Pla</dc:creator>
    </item>
    <item>
      <title>Making Tennis Fairer: The Grand Tiebreaker</title>
      <link>https://arxiv.org/abs/2501.07309</link>
      <description>arXiv:2501.07309v1 Announce Type: new 
Abstract: Tennis, like other games and sports, is governed by rules, including the rules that determine the winner of points, games, sets, and matches. If the two players are equally skilled -- each has the same probability of winning a point when serving or when receiving -- we show that each has an equal chance of winning games, sets, and matches, whether or not sets go to a tiebreak. However, in a women's match that is decided by 2 out of 3 sets, and a men's match that is decided by 3 out of 5 sets, it is possible that the player who wins the most games may not be the player who wins the match. We calculate the probability that this happens and show that it has actually occurred -- most notably, in the 2019 men's Wimbledon final between Novak Djokovic and Roger Federer, which took almost five hours to complete and is considered one of the greatest tennis matches ever (Djokovic won). We argue that the discrepancy between the game winner and the match winner, when it occurs, should be resolved by a Grand Tiebreak (GT) -- played according to the rules of tiebreaks in sets -- because each player has a valid claim to being called the rightful winner. A GT would have the salutary effect of -- even every point -- lest he/she win in sets but lose more games. This would make competition keener throughout a match and probably decrease the need for a GT, because the game and set winner would more likely coincide when the players fight hard for every point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07309v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven J. Brams, Mehmet S. Ismail, D. Marc Kilgour</dc:creator>
    </item>
    <item>
      <title>Sectorial Exclusion Criteria in the Marxist Analysis of the Average Rate of Profit: The United States Case (1960-2020)</title>
      <link>https://arxiv.org/abs/2501.06270</link>
      <description>arXiv:2501.06270v1 Announce Type: cross 
Abstract: The long-term estimation of the Marxist average rate of profit does not adhere to a theoretically grounded standard regarding which economic activities should or should not be included for such purposes, which is relevant because methodological non-uniformity can be a significant source of overestimation or underestimation, generating a less accurate reflection of the capital accumulation dynamics. This research aims to provide a standard Marxist decision criterion regarding the inclusion and exclusion of economic activities for the calculation of the Marxist average profit rate for the case of United States economic sectors from 1960 to 2020, based on the Marxist definition of productive labor, its location in the circuit of capital, and its relationship with the production of surplus value. Using wavelet-transformed Daubechies filters with increased symmetry, empirical mode decomposition, Hodrick-Prescott filter embedded in unobserved components model, and a wide variety of unit root tests the internal theoretical consistency of the presented criteria is evaluated. Also, the objective consistency of the theory is evaluated by a dynamic factor auto-regressive model, Principal Component Analysis, Singular Value Decomposition and Backward Elimination with Linear and Generalized Linear Models. The results are consistent both theoretically and econometrically with the logic of Marx's political economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06270v1</guid>
      <category>econ.GN</category>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Mauricio Gomez Julian</dc:creator>
    </item>
    <item>
      <title>Identifying the Distribution of Welfare from Discrete Choice</title>
      <link>https://arxiv.org/abs/2303.02645</link>
      <description>arXiv:2303.02645v2 Announce Type: replace 
Abstract: Empirical welfare analyses often impose stringent parametric assumptions on individuals' preferences and neglect unobserved preference heterogeneity. We develop a framework to conduct individual and social welfare analysis for discrete choice that does not suffer from these drawbacks. We first adapt the class of individual welfare measures introduced by Fleurbaey (2009) to settings where individual choice is discrete. Allowing for unrestricted, unobserved preference heterogeneity, these measures become random variables. We then demonstrate that their distribution can be derived from choice probabilities, which can be estimated nonparametrically from cross-sectional data. Additionally, we derive nonparametric results for the joint distribution of welfare and welfare differences, and for social welfare. The former is an important tool in determining whether the winners of a price change belong disproportionately to those groups who were initially well-off.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02645v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart Cap\'eau, Liebrecht De Sadeleer, Sebastiaan Maes</dc:creator>
    </item>
    <item>
      <title>Istanbul Flower Auction: The Need for Speed</title>
      <link>https://arxiv.org/abs/2404.08288</link>
      <description>arXiv:2404.08288v2 Announce Type: replace 
Abstract: We examine a unique auction format used in the Istanbul flower market, which could transform into either Dutch or English auction depending on bidders' bidding behaviors. By introducing a time cost that reduces the value of a perishable good as time passes, we explore how this hybrid auction format accommodates the desire for speed via an adaptive starting price. We show that the Istanbul Flower Auction outperforms both the Dutch and English auctions in terms of the auctioneer's utility. With numerical analysis, we also illustrate the Istanbul Flower Auction's superiority in terms of social welfare and auction duration. Our results highlight the critical role of auction design in improving welfare when the duration of the auction process plays a role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08288v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Isa Hafalir, Onur Kesten, Donglai Luo, Katerina Sherstyuk, Cong Tao</dc:creator>
    </item>
    <item>
      <title>Bargaining via Weber's law</title>
      <link>https://arxiv.org/abs/2408.02492</link>
      <description>arXiv:2408.02492v3 Announce Type: replace 
Abstract: We solve the two-player bargaining problem employing Weber's law in psychophysics, which is applied to the perception of utility changes. Using this law, the players define the jointly acceptable range of utilities on the Pareto line, which narrows down the range of possible solutions. Choosing a unique solution can be achieved by applying the Weber approach iteratively. The solution is covariant to independent affine transformations of utilities. We provide a behavioral interpretation of this solution, where the players negotiate via Weber's law. For susceptible players, iterations are unnecessary, so they converge in one stage toward the (axiomatic) asymmetric Nash solution of the bargaining problem, where the weights of each player are expressed via their Weber constants. Thus the Nash solution is reached without external arbiters and without requiring the independence of irrelevant alternatives. We also show that our solution applies to the ultimatum game (which is not bargaining but still involves offer formation) and leads to an affine-covariant solution of this game that can reproduce its empirical features. Unlike previous solutions (e.g. the one based on fairness), ours does not involve comparing inter-personal utilities and is based on a partial symmetry between the proposer and respondent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02492v3</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>V. G. Bardakhchyan, A. E. Allahverdyan</dc:creator>
    </item>
  </channel>
</rss>
