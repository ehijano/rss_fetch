<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Mar 2025 04:01:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Block-Based Heuristic Algorithm for the Three-Dimensional Nuclear Waste Packing Problem</title>
      <link>https://arxiv.org/abs/2503.08705</link>
      <description>arXiv:2503.08705v1 Announce Type: new 
Abstract: In this study, we present a block-based heuristic search algorithm to address the nuclear waste container packing problem in the context of real-world nuclear power plants. Additionally, we provide a dataset comprising 1600 problem instances for future researchers to use. Experimental results on this dataset demonstrate that the proposed algorithm effectively enhances the disposal pool's space utilization while minimizing the radiation dose within the pool. The code and data employed in this study are publicly available to facilitate reproducibility and further investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08705v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yajie Wen, Defu Zhang</dc:creator>
    </item>
    <item>
      <title>A Beam Search Based Parallel Algorithm for the Two-Dimensional Strip Packing Problem</title>
      <link>https://arxiv.org/abs/2503.08711</link>
      <description>arXiv:2503.08711v1 Announce Type: new 
Abstract: This paper introduces BSPA, a parallel algorithm that leverages beam search to address the two-dimensional strip packing problem. The study begins with a comprehensive review of existing approaches and methodologies, followed by a detailed presentation of the BSPA algorithm. Experimental results demonstrate the effectiveness of the proposed method. To facilitate further research, both the code and datasets are publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08711v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yajie Wen, Defu Zhang</dc:creator>
    </item>
    <item>
      <title>Revisiting Frank-Wolfe for Structured Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2503.08921</link>
      <description>arXiv:2503.08921v1 Announce Type: new 
Abstract: We introduce a new projection-free (Frank-Wolfe) method for optimizing structured nonconvex functions that are expressed as a difference of two convex functions. This problem class subsumes smooth nonconvex minimization, positioning our method as a promising alternative to the classical Frank-Wolfe algorithm. DC decompositions are not unique; by carefully selecting a decomposition, we can better exploit the problem structure, improve computational efficiency, and adapt to the underlying problem geometry to find better local solutions. We prove that the proposed method achieves a first-order stationary point in $O(1/\epsilon^2)$ iterations, matching the complexity of the standard Frank-Wolfe algorithm for smooth nonconvex minimization in general. Specific decompositions can, for instance, yield a gradient-efficient variant that requires only $O(1/\epsilon)$ calls to the gradient oracle. Finally, we present numerical experiments demonstrating the effectiveness of the proposed method compared to the standard Frank-Wolfe algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08921v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoomaan Maskan, Yikun Hou, Suvrit Sra, Alp Yurtsever</dc:creator>
    </item>
    <item>
      <title>Ensemble optimal control for managing drug resistance in cancer therapies</title>
      <link>https://arxiv.org/abs/2503.08927</link>
      <description>arXiv:2503.08927v1 Announce Type: new 
Abstract: In this paper, we explore the application of ensemble optimal control to derive enhanced strategies for pharmacological cancer treatment. In particular, we focus on moving beyond the classical clinical approach of giving the patient the maximal tolerated drug dose (MTD), which does not properly exploit the fight among sensitive and resistant cells for the available resources. Here, we employ a Lotka-Volterra model to describe the two competing subpopulations, and we enclose this system within the ensemble control framework. In the first part, we establish general results suitable for application to various solid cancers. Then, we carry out numerical simulations in the setting of prostate cancer treated with androgen deprivation therapy, yielding a computed policy that is reminiscent of the medical 'active surveillance' paradigm. Finally, inspired by the numerical evidence, we propose a variant of the celebrated adaptive therapy (AT), which we call 'Off-On' AT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08927v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Scagliotti, Federico Scagliotti, Laura Deborah Locati, Federico Sottotetti</dc:creator>
    </item>
    <item>
      <title>Accelerating Point-Based Value Iteration via Active Sampling of Belief Points and Gaussian Process Regression</title>
      <link>https://arxiv.org/abs/2503.08982</link>
      <description>arXiv:2503.08982v1 Announce Type: new 
Abstract: Partially Observable Markov Decision Processes (POMDPs) are fundamental to decision-making under uncertainty. We introduce a novel scalable approach to accelerate upper bound estimation in Point-Based Value Iteration (PBVI) algorithms, the leading method to solve large-scale POMDPs. PBVI approximates the value function using a set of belief points rather than the entire continuous belief space and relies on lower and upper bounds for convergence. While lower bounds are straightforward to compute, PVBI requires repeated sawtooth projection operations to approximate the upper bound convex hull, significantly increasing the computational burden although many of these sawtooth projections become redundant as the belief set expands. To address this, we infer the upper bound using the upper confidence bound of a Gaussian Process Regression (GP-UCB) fitted over a subset of the most informative reachable belief points--the ones that exhibit linear independence in some high-dimensional Hilbert space. This approach reduces the number of sawtooth projections by 84.3% on average without compromising the solution quality. We further establish the theoretical consistency of the proposed GP-UCB estimate of the upper bound and show convergence to the true upper bound convex hull. We implement GP-UCB and test its performance using five benchmark finite-horizon POMDPs, demonstrating its effectiveness in estimating upper bounds and improving PBVI performance. GP-UCB reduces computation time by 30% to 60% on smaller problems and up to 99.7% on larger ones, while achieving the same gaps as the pure sawtooth projection method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08982v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siqiong Zhou, Ashif S. Iquebal, Esma S. Gel</dc:creator>
    </item>
    <item>
      <title>Degradation-based Energy Management for Microgrids in the Presence of Energy Storage Elements</title>
      <link>https://arxiv.org/abs/2503.09028</link>
      <description>arXiv:2503.09028v1 Announce Type: new 
Abstract: Integration of Inverter-based Resources (IBRs) such as solar-powered plants which lack the intrinsic characteristics such as the inertial response of the traditional synchronous-generator (SG) based sources presents a new challenge in the form of analyzing the grid stability under their presence. For example, solar power is available for approximately from 9 AM-5 PM. However, the result of the rise in power consumption after 6 PM and the reverting back to the non-renewable source of power generation during that period puts immense stress on the grid, testing the ramp limitations of the SGs. Failure to meet the required power demand due to SG ramp limitations leads to failure of the power grid and other catastrophes. Numerous mitigation techniques exist in order to address the ramping issues with adding the energy storage elements (ESE) to the grid being one. ESEs have higher ramping capabilities compared to the traditional SGs. Also, the ESEs can store the energy and supply it to the grid when required making them extremely responsive to high ramp situations. However, the rate of degradation of the ESEs is faster than the SGs. This raises an important issue of addressing the degradation of the ESEs while meeting the required power demand objectives and constraints. This work proposes a battery degradation-aware model predictive energy management strategy and it is tested via a numerical simulation on multiple physical systems such as Shipboard Power Systems (SPS). Moreover, the risk arising due to the fault in the IBR is also studied by means of a numerical simulation. Overall, the goal of this study is to make the existing power grid more robust, resilient, and risk-free from component degradation and eventual failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09028v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satish Vedula</dc:creator>
    </item>
    <item>
      <title>Modeling of Rumor Propagation in Large Populations with Network via Graphon Games</title>
      <link>https://arxiv.org/abs/2503.09107</link>
      <description>arXiv:2503.09107v1 Announce Type: new 
Abstract: In this paper, we propose a graphon game model to understand how rumor (such as fake news) propagates in large populations that are interacting on a network and how different policies affect the spread. We extend the SKIR model that is used to model rumor propagation and implement individual controls and weighted interactions with other agents to have controlled dynamics. The agents aim to minimize their own expected costs non-cooperatively. We give the finite player game model and the limiting graphon game model to approximate the Nash equilibrium in the population. We give the graphon game Nash equilibrium as a solution to a continuum of ordinary differential equations (ODEs) and give existence results. Finally, we give a numerical approach and analyze examples where we use piecewise constant graphon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09107v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huaning Liu, Gokce Dayanikli</dc:creator>
    </item>
    <item>
      <title>Optimal control for multiagent systems with simultaneous aggregation</title>
      <link>https://arxiv.org/abs/2503.09168</link>
      <description>arXiv:2503.09168v1 Announce Type: new 
Abstract: In this paper, we introduce an optimal control problem for multi-agent systems with non-local cost which favors simultaneous aggregation of particles. This is done introducing a time-dependent notion of multiplicity whose intrinsic dynamical nature differs from more established geometric-like definitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09168v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauro Bonafini, Giulia Cavagnari, Antonio Marigonda</dc:creator>
    </item>
    <item>
      <title>Reachability for multiagent control systems via Lyapunov functions</title>
      <link>https://arxiv.org/abs/2503.09179</link>
      <description>arXiv:2503.09179v1 Announce Type: new 
Abstract: This paper concerns the problem of reachability of a given state for a multiagent control system in $\mathbb{R}^d$. In such a system, at every time each agent can choose his/her velocity which depends both on his/her position and on the position of the whole crowd of agents (modeled by a probability measure on $ \mathbb{R}^d$). The main contribution of the paper is to study the above reachability problem with a given rate of attainability through a Lyapunov method adapted to the Wasserstein space of probability measures. As a byproduct we obtain a new comparison result for viscosity solutions of Hamilton Jacobi equations in the Wasserstein space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09179v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulia Cavagnari, Marc Quincampoix</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Medical Drug in a Nonlocal Model of Solid Tumor Growth</title>
      <link>https://arxiv.org/abs/2503.09208</link>
      <description>arXiv:2503.09208v1 Announce Type: new 
Abstract: This paper presents a mathematical framework for optimizing drug delivery in cancer treatment using a nonlocal model of solid tumor growth. We present a coupled system of partial differential equations that incorporate long-range cellular interactions through integral terms and drug-induced cell death. The model accounts for spatial heterogeneity in both tumor cell density and drug concentration while capturing the complex dynamics of drug resistance development. We first establish the well-posedness of the coupled system by proving the existence and uniqueness of a solution under appropriate regularity conditions. The optimal control problem is then formulated to minimize tumor size while accounting for drug toxicity constraints. Using variational methods, we derive the necessary optimality conditions and characterize the optimal control through an adjoint system. Theoretical results can help to design effective chemotherapy schedules that balance treatment efficacy with adverse effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09208v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bouhamidi Abderrahman, El Harraki Imad, Melouani Yassine</dc:creator>
    </item>
    <item>
      <title>Magnetization control problem for the 2D and 3D evolutionary Landau-Lifshitz-Bloch equation</title>
      <link>https://arxiv.org/abs/2503.09266</link>
      <description>arXiv:2503.09266v1 Announce Type: new 
Abstract: In this study, we investigate the optimal control of the Landau-Lifshitz-Bloch equation within confined domains in $\mathbb R^n$ for $n= 2, 3.$ We establish the existence of strong solutions for dimensions $n=1, 2, 3$ under suitable growth conditions on the control, and analyze the existence and uniqueness of regular solutions. We formulate the control problem in which only a fixed set of finite magnetic field coils can constitute the external magnetic field (control). We define a cost functional by aiming at minimizing the energy discrepancy between the evolving magnetic moment and the desired state. We demonstrate the existence of an optimal solution pair and employ the classical adjoint problem approach to derive a first-order necessary optimality condition. Given the non-convex nature of the optimal control problem, we derive a second-order sufficient optimality condition using a cone of critical directions. Finally, we prove two crucial results, namely, a global optimality condition and uniqueness of an optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09266v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sidhartha Patnaik, Kumarasamy Sakthivel</dc:creator>
    </item>
    <item>
      <title>A convex reformulation for speed planning of a vehicle under the travel time and energy consumption objectives</title>
      <link>https://arxiv.org/abs/2503.09424</link>
      <description>arXiv:2503.09424v1 Announce Type: new 
Abstract: In this paper we address the speed planning problem for a vehicle along a predefined path. A weighted average of two (conflicting) terms, energy consumption and travel time, is minimized. After deriving a non-convex mathematical model of the problem, we introduce a convex relaxation of the model and show that, after the application of a suitable feasibility-based bound tightening procedure, the convex relaxation shares the same optimal value and solution of the non-convex problem. We also establish that the feasible region of the non-convex problem is a lattice and, through that, a necessary and sufficient condition for the non-emptiness of the feasible region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09424v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Ardizzoni, Luca Consolini, Mattia Laurini, Marco Locatelli</dc:creator>
    </item>
    <item>
      <title>Fast computation of the TGOSPA metric for multiple target tracking via unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2503.09449</link>
      <description>arXiv:2503.09449v1 Announce Type: new 
Abstract: In multiple target tracking, it is important to be able to evaluate the performance of different tracking algorithms. The trajectory generalized optimal sub-pattern assignment metric (TGOSPA) is a recently proposed metric for such evaluations. The TGOSPA metric is computed as the solution to an optimization problem, but for large tracking scenarios, solving this problem becomes computationally demanding. In this paper, we present an approximation algorithm for evaluating the TGOSPA metric, based on casting the TGOSPA problem as an unbalanced multimarginal optimal transport problem. Following recent advances in computational optimal transport, we introduce an entropy regularization and derive an iterative scheme for solving the Lagrangian dual of the regularized problem. Numerical results suggest that our proposed algorithm is more computationally efficient than the alternative of computing the exact metric using a linear programming solver, while still providing an adequate approximation of the metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09449v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Nevelius Wernholm, Alfred W\"arns\"ater, Axel Ringh</dc:creator>
    </item>
    <item>
      <title>One-vs-one Threat-Aware Weaponeering with Basic Engagement Zones</title>
      <link>https://arxiv.org/abs/2503.09475</link>
      <description>arXiv:2503.09475v1 Announce Type: new 
Abstract: In this paper we address the problem of 'weaponeering', i.e., placing the weapon engagement zone (WEZ) of a vehicle on a moving target, while simultaneously avoiding the target's WEZ. A WEZ describes the lethality region of a range-limited weapon considering both the range of the weapon along with the state of the target. The weapons are assumed to have simple motion, while the vehicles carrying the weapons are modeled with Dubins dynamics. Three scenarios are investigated and are differentiated in the assumptions that can be made about the target in the process of the vehicle control design: 1) no knowledge of target control, 2) avoid unsafe positions assuming the target's optimal control, 3) full knowledge of target's optimal control. The engagement is formulated as a stochastic optimal control problem with uncertainty in the target's control modeled using a noise parameter applied to the target's control input. After discretizing the Hamilton-Jacobi-Bellman equation, Value iteration is then used to obtain an approximate solution for the optimal vehicle control and time-to-go. Simulation results support usage of the first paradigm: assume no knowledge of the target's control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09475v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Von Moll, Dejan Milutinovi\'c, Isaac Weintraub, David W. Casbeer</dc:creator>
    </item>
    <item>
      <title>A Multi-objective Sequential Quadratic Programming Algorithm Based on Low-order Smooth Penalty Function</title>
      <link>https://arxiv.org/abs/2503.09476</link>
      <description>arXiv:2503.09476v1 Announce Type: new 
Abstract: In this paper,we propose a Multi-Objective Sequential Quadratic Programming (MOSQP) algorithm for constrained multi-objective optimization problems,basd on a low-order smooth penalty function as the merit function for line search. The algorithm constructs single-objective optimization subproblems based on each objective function, solves quadratic programming (QP) subproblems to obtain descent directions for expanding the iterative point set within the feasible region, and filters non-dominated points after expansion. A new QP problem is then formulated using information from all objective functions to derive descent directions. The Armijo step size rule is employed for line search, combined with Powell's correction formula (1978) for B iteration updates. If QP subproblems is infesible, the negative gradient of the merit function is adopted as the search direction. The algorithm is proven to converge to an approximate Pareto front for constrained multi-objective optimization. Finally, numerical experiments are performed for specific multi-objective optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09476v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zanyang Kong</dc:creator>
    </item>
    <item>
      <title>Sequential Quadratic Optimization for Solving Expectation Equality Constrained Stochastic Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.09490</link>
      <description>arXiv:2503.09490v1 Announce Type: new 
Abstract: A sequential quadratic programming method is designed for solving general smooth nonlinear stochastic optimization problems subject to expectation equality constraints. We consider the setting where the objective and constraint function values, as well as their derivatives, are not directly available. The algorithm applies an adaptive step size policy and only relies on objective gradient estimates, constraint function estimates, and constraint derivative estimates to update iterates. Both asymptotic and non-asymptotic convergence properties of the algorithm are analyzed. Under reasonable assumptions, the algorithm generates a sequence of iterates whose first-order stationary measure diminishes in expectation. In addition, we identify the iteration and sample complexity for obtaining a first-order $\varepsilon$-stationary iterate in expectation. The results of numerical experiments demonstrate the efficiency and efficacy of our proposed algorithm compared to a penalty method and an augmented Lagrangian method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09490v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoming Shen, Yang Zeng, Baoyu Zhou</dc:creator>
    </item>
    <item>
      <title>The turnpike control in stochastic multi-agent dynamics: a discrete-time approach with exponential integrators</title>
      <link>https://arxiv.org/abs/2503.09549</link>
      <description>arXiv:2503.09549v1 Announce Type: new 
Abstract: In this manuscript, we study the turnpike property in stochastic discrete-time optimal control problems for interacting agents. Extending previous deterministic results, we show that the turnpike effect persists in the presence of noise under suitable dissipativity and controllability conditions. To handle the possible stiffness in the system dynamics, we employ for the time discretization, integrators of exponential type. Numerical experiments validate our findings, demonstrating the advantages of exponential integrators over standard explicit schemes and confirming the effectiveness of the turnpike control even in the stochastic setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09549v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Cassini, Chiara Segala</dc:creator>
    </item>
    <item>
      <title>Stochastic Model Predictive Control for Sub-Gaussian Noise</title>
      <link>https://arxiv.org/abs/2503.08795</link>
      <description>arXiv:2503.08795v1 Announce Type: cross 
Abstract: We propose a stochastic Model Predictive Control (MPC) framework that ensures closed-loop chance constraint satisfaction for linear systems with general sub-Gaussian process and measurement noise. By considering sub-Gaussian noise, we can provide guarantees for a large class of distributions, including time-varying distributions. Specifically, we first provide a new characterization of sub-Gaussian random vectors using matrix variance proxies, which can more accurately represent the predicted state distribution. We then derive tail bounds under linear propagation for the new characterization, enabling tractable computation of probabilistic reachable sets of linear systems. Lastly, we utilize these probabilistic reachable sets to formulate a stochastic MPC scheme that provides closed-loop guarantees for general sub-Gaussian noise. We further demonstrate our approach in simulations, including a challenging task of surgical planning from image observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08795v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunke Ao, Johannes K\"ohler, Manish Prajapat, Yarden As, Melanie Zeilinger, Philipp F\"urnstahl, Andreas Krause</dc:creator>
    </item>
    <item>
      <title>Reliable Solution to Dynamic Optimization Problems using Integrated Residual Regularized Direct Collocation</title>
      <link>https://arxiv.org/abs/2503.09123</link>
      <description>arXiv:2503.09123v1 Announce Type: cross 
Abstract: Direct collocation is a widely used method for solving dynamic optimization problems (DOPs), but its implementation simplicity and computational efficiency are limited for challenging problems like those involving singular arcs. In this paper, we introduce the direct transcription method of integrated residual regularized direct collocation (IRR-DC). This method enforces dynamic constraints through a combination of explicit constraints and penalty terms within discretized DOPs. This method retains the implementation simplicity of direct collocation while significantly improving both solution accuracy and efficiency, particularly for challenging problem types. Through the examples, we demonstrate that for difficult problems where traditional direct collocation results in excessive fluctuations or large errors between collocation points, IRR-DC effectively suppresses oscillations and yields solutions with greater accuracy (several magnitudes lower in various error metrics) compared to other regularization alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09123v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanbo Nie, Eric C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>Task Allocation for Multi-agent Systems via Unequal-dimensional Optimal Transport</title>
      <link>https://arxiv.org/abs/2503.09369</link>
      <description>arXiv:2503.09369v1 Announce Type: cross 
Abstract: We consider a probabilistic model for large-scale task allocation problems for multi-agent systems, aiming to determine an optimal deployment strategy that minimizes the overall transport cost. Specifically, we assign transportation agents to delivery tasks with given pick-up and drop-off locations, pairing the spatial distribution of transport resources with the joint distribution of task origins and destinations. This aligns with the optimal mass transport framework where the problem and is in the unequal-dimensional setting. The task allocation problem can be thus seen as a linear programming problem that minimizes a quadratic transport cost functional, optimizing the energy of all transport units. The problem is motivated by time-sensitive medical deliveries using drones, such as emergency equipment and blood transport. In this paper, we establish the existence, uniqueness, and smoothness of the optimal solution, and illustrate its properties through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09369v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Karl H. Johansson, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Benefits of Learning Rate Annealing for Tuning-Robustness in Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2503.09411</link>
      <description>arXiv:2503.09411v1 Announce Type: cross 
Abstract: The learning rate in stochastic gradient methods is a critical hyperparameter that is notoriously costly to tune via standard grid search, especially for training modern large-scale models with billions of parameters. We identify a theoretical advantage of learning rate annealing schemes that decay the learning rate to zero at a polynomial rate, such as the widely-used cosine schedule, by demonstrating their increased robustness to initial parameter misspecification due to a coarse grid search. We present an analysis in a stochastic convex optimization setup demonstrating that the convergence rate of stochastic gradient descent with annealed schedules depends sublinearly on the multiplicative misspecification factor $\rho$ (i.e., the grid resolution), achieving a rate of $O(\rho^{1/(2p+1)}/\sqrt{T})$ where $p$ is the degree of polynomial decay and $T$ is the number of steps, in contrast to the $O(\rho/\sqrt{T})$ rate that arises with fixed stepsizes and exhibits a linear dependence on $\rho$. Experiments confirm the increased robustness compared to tuning with a fixed stepsize, that has significant implications for the computational overhead of hyperparameter search in practical training scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09411v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Attia, Tomer Koren</dc:creator>
    </item>
    <item>
      <title>Learning Spatially Adaptive $\ell_1$-Norms Weights for Convolutional Synthesis Regularization</title>
      <link>https://arxiv.org/abs/2503.09483</link>
      <description>arXiv:2503.09483v1 Announce Type: cross 
Abstract: We propose an unrolled algorithm approach for learning spatially adaptive parameter maps in the framework of convolutional synthesis-based $\ell_1$ regularization. More precisely, we consider a family of pre-trained convolutional filters and estimate deeply parametrized spatially varying parameters applied to the sparse feature maps by means of unrolling a FISTA algorithm to solve the underlying sparse estimation problem. The proposed approach is evaluated for image reconstruction of low-field MRI and compared to spatially adaptive and non-adaptive analysis-type procedures relying on Total Variation regularization and to a well-established model-based deep learning approach. We show that the proposed approach produces visually and quantitatively comparable results with the latter approaches and at the same time remains highly interpretable. In particular, the inferred parameter maps quantify
  the local contribution of each filter in the reconstruction, which provides valuable insight into the algorithm mechanism and could potentially be used to discard unsuited filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09483v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Kofler, Luca Calatroni, Christoph Kolbitsch, Kostas Papafitsoros</dc:creator>
    </item>
    <item>
      <title>Global Convergence and Rich Feature Learning in $L$-Layer Infinite-Width Neural Networks under $\mu$P Parametrization</title>
      <link>https://arxiv.org/abs/2503.09565</link>
      <description>arXiv:2503.09565v1 Announce Type: cross 
Abstract: Despite deep neural networks' powerful representation learning capabilities, theoretical understanding of how networks can simultaneously achieve meaningful feature learning and global convergence remains elusive. Existing approaches like the neural tangent kernel (NTK) are limited because features stay close to their initialization in this parametrization, leaving open questions about feature properties during substantial evolution. In this paper, we investigate the training dynamics of infinitely wide, $L$-layer neural networks using the tensor program (TP) framework. Specifically, we show that, when trained with stochastic gradient descent (SGD) under the Maximal Update parametrization ($\mu$P) and mild conditions on the activation function, SGD enables these networks to learn linearly independent features that substantially deviate from their initial values. This rich feature space captures relevant data information and ensures that any convergent point of the training process is a global minimum. Our analysis leverages both the interactions among features across layers and the properties of Gaussian random variables, providing new insights into deep representation learning. We further validate our theoretical findings through experiments on real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09565v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixiang Chen, Greg Yang, Qingyue Zhao, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>On Optimality Conditions in Control Theory</title>
      <link>https://arxiv.org/abs/1610.02829</link>
      <description>arXiv:1610.02829v5 Announce Type: replace 
Abstract: We study optimality conditions for various types of control problems like the standard optimal control problem, optimal multiprocesses, problems with infinite horizon or the control of Volterra integral equations. To derive necessary conditions the needle variation method of Ioffe &amp; Tichomirov is the central tool. In the particular control problem with infinite horizon the question of a suitable setting arises. We propose the framework of continuous state trajectories converging at infinity. This requires a version of Riesz' representation theorem and the introduction of regular Borel measures on the extended real number line. The control of Volterra integral equations including an inner and outer time variable. Consequently, we deal with a two-dimensional time set. We extend the needle variation method of Ioffe &amp; Tichomirov to this case. The obtained optimality conditions are demonstrated in illustrative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:1610.02829v5</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nico Tauchnitz</dc:creator>
    </item>
    <item>
      <title>Finite adaptability in two-stage robust optimization: asymptotic optimality and tractability</title>
      <link>https://arxiv.org/abs/2305.05399</link>
      <description>arXiv:2305.05399v5 Announce Type: replace 
Abstract: Two-stage robust optimization is a fundamental paradigm for modeling and solving optimization problems with uncertain parameters. A now classical method within this paradigm is finite adaptability, introduced by Bertsimas and Caramanis (IEEE Transactions on Automatic Control, 2010). It consists in restricting the recourse to a finite number $k$ of possible values. In this work, we point out that the continuity assumption they stated to ensure the convergence of the method when $k$ goes to infinity is not correct, and we propose an alternative assumption for which we prove the desired convergence. Bertsimas and Caramanis also established that finite adaptability is NP-hard, even in the special case when $k=2$, the variables are continuous, and only specific parameters are subject to uncertainty. We provide a theorem showing that this special case becomes polynomial when the uncertainty set is a polytope with a bounded number of vertices, and we extend this theorem for $k=3$ as well. On our way, we establish new geometric results on coverings of polytopes with convex sets, which might be interesting for their own sake.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05399v5</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Safia Kedad-Sidhoum, Anton Medvedev, Fr\'ed\'eric Meunier</dc:creator>
    </item>
    <item>
      <title>Controlled Diffusions under Full, Partial and Decentralized Information: Existence of Optimal Policies and Discrete-Time Approximations</title>
      <link>https://arxiv.org/abs/2311.03254</link>
      <description>arXiv:2311.03254v2 Announce Type: replace 
Abstract: We present existence and discrete-time approximation results on optimal control policies for continuous-time stochastic control problems under a variety of information structures. These include fully observed models, partially observed models and multi-agent models with decentralized information structures. While there exist comprehensive existence and approximations results for the fully observed setup in the literature, few prior research exists on discrete-time approximation results for partially observed models. For decentralized models, even existence results have not received much attention except for specialized models and approximation has been an open problem. Our existence and approximations results lead to the applicability of well-established partially observed Markov decision processes and the relatively more mature theory of discrete-time decentralized stochastic control to be applicable for computing near optimal solutions for continuous-time stochastic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03254v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somnath Pradhan, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Carrot John domains in variational problems</title>
      <link>https://arxiv.org/abs/2401.08133</link>
      <description>arXiv:2401.08133v2 Announce Type: replace 
Abstract: In this paper, we explore carrot John domains within variational problems, dividing our examination into two distinct sections. The initial part is dedicated to establishing the lower semicontinuity of the (optimal) John constant concerning Hausdorff convergence for bounded John domains. This result holds promising implications for both shape optimization problems and Techm\"uller theory.
  In the subsequent section, we demonstrate that an unbounded open set satisfying the carrot John condition with a center at $\infty$, appearing in the Mumford-Shah problem, can be covered by a uniformly finite number of unbounded John domains (defined conventionally through cigars). These domains, in particular, support Sobolev-Poincar\'e inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08133v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weicong Su, Yi Ru-Ya Zhang</dc:creator>
    </item>
    <item>
      <title>Tensor train based sampling algorithms for approximating regularized Wasserstein proximal operators</title>
      <link>https://arxiv.org/abs/2401.13125</link>
      <description>arXiv:2401.13125v3 Announce Type: replace 
Abstract: We present a tensor train (TT) based algorithm designed for sampling from a target distribution and employ TT approximation to capture the high-dimensional probability density evolution of overdamped Langevin dynamics. This involves utilizing the regularized Wasserstein proximal operator, which exhibits a simple kernel integration formulation, i.e., the softmax formula of the traditional proximal operator. The integration, performed in $\mathbb{R}^d$, poses a challenge in practical scenarios, making the algorithm practically implementable only with the aid of TT approximation. In the specific context of Gaussian distributions, we rigorously establish the unbiasedness and linear convergence of our sampling algorithm towards the target distribution. To assess the effectiveness of our proposed methods, we apply them to various scenarios, including Gaussian families, Gaussian mixtures, bimodal distributions, and Bayesian inverse problems in numerical examples. The sampling algorithm exhibits superior accuracy and faster convergence when compared to classical Langevin dynamics-type sampling algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13125v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuqun Han, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>On discount functions for economic model predictive control without terminal conditions</title>
      <link>https://arxiv.org/abs/2405.14361</link>
      <description>arXiv:2405.14361v2 Announce Type: replace 
Abstract: In this paper, we investigate discounted economic model predictive control (E-MPC) schemes without terminal conditions in scenarios where the optimal operating behavior is a periodic orbit. For such a setting, it is known that a linearly discounted stage cost guarantees asymptotic stability of any arbitrarily small neighborhood of the optimal orbit if the prediction horizon is sufficiently long. However, in some examples very long prediction horizons are needed to achieve the desired performance. In this work, we extend these results by providing the same qualitative stability guarantees for a large class of discount functions. Numerical examples illustrate the influence of the discount function and show that with suitable discounting we can achieve significantly better performance than the linearly discounted E-MPC, even for short prediction horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14361v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Schwenkel, Daniel Briem, Matthias A. M\"uller, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Constrained Approximate Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2407.13445</link>
      <description>arXiv:2407.13445v2 Announce Type: replace 
Abstract: We investigate finding a map $g$ within a function class $G$ that minimises an Optimal Transport (OT) cost between a target measure $\nu$ and the image by $g$ of a source measure $\mu$. This is relevant when an OT map from $\mu$ to $\nu$ does not exist or does not satisfy the desired constraints of $G$. We address existence and uniqueness for generic subclasses of $L$-Lipschitz functions, including gradients of (strongly) convex functions and typical Neural Networks. We explore a variant that approaches a transport plan, showing equivalence to a map problem in some cases. For the squared Euclidean cost, we propose alternating minimisation over a transport plan $\pi$ and map $g$, with the optimisation over $g$ being the $L^2$ projection on $G$ of the barycentric mapping $\overline{\pi}$. In dimension one, this global problem equates the $L^2$ projection of $\overline{\pi^*}$ onto $G$ for an OT plan $\pi^*$ between $\mu$ and $\nu$, but this does not extend to higher dimensions. We introduce a simple kernel method to find $g$ within a Reproducing Kernel Hilbert Space in the discrete case. We present numerical methods for $L$-Lipschitz gradients of $\ell$-strongly convex potentials, and study the convergence of Stochastic Gradient Descent methods for Neural Networks. We finish with an illustration on colour transfer, applying learned maps on new images, and showcasing outlier robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13445v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Tanguy, Agn\`es Desolneux, Julie Delon</dc:creator>
    </item>
    <item>
      <title>An Adaptive Sampling-based Progressive Hedging Algorithm for Stochastic Programming</title>
      <link>https://arxiv.org/abs/2407.20944</link>
      <description>arXiv:2407.20944v2 Announce Type: replace 
Abstract: The progressive hedging algorithm (PHA) is a cornerstone among algorithms for large-scale stochastic programming problems. However, its traditional implementation is hindered by some limitations, including the requirement to solve all scenario subproblems in each iteration, reliance on an explicit probability distribution, and a convergence process that is highly sensitive to the choice of certain penalty parameters. This paper introduces a sampling-based PHA which aims to overcome these limitations. Our approach employs a dynamic selection process for the number of scenario subproblems solved per iteration. It incorporates adaptive sequential sampling for determining sample sizes, a stochastic conjugate subgradient method for direction finding, and a line-search technique to update the dual variables. Experimental results demonstrate that this novel algorithm not only addresses the bottlenecks of the conventional PHA but also potentially surpasses its scalability, representing a substantial improvement in the field of stochastic programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20944v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang, Yihang Zhang, Suvrajeet Sen</dc:creator>
    </item>
    <item>
      <title>Correction to: A Lagrangian dual method for two-stage robust optimization with binary uncertainties</title>
      <link>https://arxiv.org/abs/2411.04307</link>
      <description>arXiv:2411.04307v3 Announce Type: replace 
Abstract: We provide a correction to the sufficient conditions under which closed-form expressions for the optimal Lagrange multiplier are provided in arXiv:2112.13138 [math.OC]. We first present a simple counterexample where the original conditions are insufficient, highlight where the original proof fails, and then provide modified conditions along with a correct proof of their validity. Finally, although the original paper discusses modifications to their method for problems that may not satisfy any sufficient conditions, we substantiate that discussion along two directions. We first show that computing an optimal Lagrange multiplier can still be done in polynomial time. We then provide complete and correct versions of the corresponding Benders and column-and-constraint generation algorithms in which the original method is used. We also discuss the implications of our findings on computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04307v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Lefebvre, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>The Small-Gain Condition for Infinite Networks</title>
      <link>https://arxiv.org/abs/2503.03925</link>
      <description>arXiv:2503.03925v2 Announce Type: replace 
Abstract: In recent years, attempts have been made to extend ISS small-gain theorems from finite networks to countably infinite, locally finite networks. Under specific assumptions about the interconnection gains and the ISS formulation, corresponding infinite-dimensional small-gain results have been proven. However, concerning these assumptions, the results are still too narrow to be considered a full extension of the state-of-the-art for finite networks. We take a step to closing this gap by a thorough investigation of various monotone operators associated with an infinite network and a specific ISS formulation. Our results shed more light on the theory of finite networks, yield complete characterizations of the small-gain condition for specific ISS formulations, and show which obstacles still have to be overcome to obtain a complete theory for the most general case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03925v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Kawan</dc:creator>
    </item>
    <item>
      <title>Quantum Feasibility Labeling for NP-complete Vertex Coloring Problem</title>
      <link>https://arxiv.org/abs/2301.01589</link>
      <description>arXiv:2301.01589v3 Announce Type: replace-cross 
Abstract: Many important science and engineering problems can be converted into NP-complete problems which are of significant importance in computer science and mathematics. Currently, neither existing classical nor quantum algorithms can solve these problems in polynomial time. To address this difficulty, this paper proposes a quantum feasibility labeling (QFL) algorithm to label all possible solutions to the vertex coloring problem, which is a well-known NP-complete problem. The QFL algorithm converts the vertex coloring problem into the problem of searching an unstructured database where good and bad elements are labeled. The recently proposed variational quantum search (VQS) algorithm was demonstrated to achieve an exponential speedup, in circuit depth, up to 26 qubits in finding good element(s) from an unstructured database. Using the labels and the associated possible solutions as input, the VQS can find all feasible solutions to the vertex coloring problem. The number of qubits and the circuit depth required by the QFL each is a polynomial function of the number of vertices, the number of edges, and the number of colors of a vertex coloring problem. We have implemented the QFL on an IBM Qiskit simulator to solve a 4-colorable 4-vertex 3-edge coloring problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.01589v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <category>math.QA</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2025.3545262</arxiv:DOI>
      <dc:creator>Junpeng Zhan</dc:creator>
    </item>
    <item>
      <title>Input-Output Feedback Linearization Preserving Task Priority for Multivariate Nonlinear Systems Having Singular Input Gain Matrix</title>
      <link>https://arxiv.org/abs/2305.01903</link>
      <description>arXiv:2305.01903v4 Announce Type: replace-cross 
Abstract: We propose an extension of the input-output feedback linearization for a class of multivariate systems that are not input-output linearizable in a classical manner. The key observation is that the usual input-output linearization problem can be interpreted as the problem of solving simultaneous linear equations associated with the input gain matrix: thus, even at points where the input gain matrix becomes singular, it is still possible to solve a part of linear equations, by which a subset of input-output relations is made linear or close to be linear. Based on this observation, we adopt the task priority-based approach in the input-output linearization problem. First, we generalize the classical Byrnes-Isidori normal form to a prioritized normal form having a triangular structure, so that the singularity of a subblock of the input gain matrix related to lower-priority tasks does not directly propagate to higher-priority tasks. Next, we present a prioritized input-output linearization via the multi-objective optimization with the lexicographical ordering, resulting in a prioritized semilinear form that establishes input output relations whose subset with higher priority is linear or close to be linear. Finally, Lyapunov analysis on ultimate boundedness and task achievement is provided, particularly when the proposed prioritized input-output linearization is applied to the output tracking problem. This work introduces a new control framework for complex systems having critical and noncritical control issues, by assigning higher priority to the critical ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01903v4</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3547538</arxiv:DOI>
      <dc:creator>Sang-ik An, Dongheui Lee, Gyunghoon Park</dc:creator>
    </item>
    <item>
      <title>On a class of interdiction problems with partition matroids: complexity and polynomial-time algorithms</title>
      <link>https://arxiv.org/abs/2401.12010</link>
      <description>arXiv:2401.12010v4 Announce Type: replace-cross 
Abstract: In this study, we consider a class of linear matroid interdiction problems, where the feasible sets for the upper-level decision-maker (referred to as a leader) and the lower-level decision-maker (referred to as a follower) are induced by two distinct partition matroids with a common weighted ground set. Unlike classical network interdiction models where the leader is subject to a single budget constraint, in our setting, both the leader and the follower are subject to several independent capacity constraints and engage in a zero-sum game. While the problem of finding a maximum weight independent set in a partition matroid is known to be polynomially solvable, we prove that the considered bilevel problem is $NP$-hard even when the weights of ground elements are all binary. On a positive note, it is revealed that, if the number of capacity constraints is fixed for either the leader or the follower, then the considered class of bilevel problems admits several polynomial-time solution schemes. Specifically, these schemes are based on a single-level dual reformulation, a dynamic programming-based approach, and a greedy algorithm for the leader.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12010v4</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sergey S. Ketkov, Oleg A. Prokopyev</dc:creator>
    </item>
    <item>
      <title>On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions</title>
      <link>https://arxiv.org/abs/2402.16442</link>
      <description>arXiv:2402.16442v2 Announce Type: replace-cross 
Abstract: Modern datasets span billions of samples, making training on all available data infeasible. Selecting a high quality subset helps in reducing training costs and enhancing model quality. Submodularity, a discrete analogue of convexity, is commonly used for solving such subset selection problems. However, existing algorithms for optimizing submodular functions are sequential, and the prior distributed methods require at least one central machine to fit the target subset in DRAM. At billion datapoint scale, even the subset may not fit a single machine, and the sequential algorithms are prohibitively slow. In this paper, we relax the requirement of having a central machine for the target subset by proposing a novel distributed bounding algorithm with provable approximation guarantees. The algorithm iteratively bounds the minimum and maximum utility values to select high quality points and discard the unimportant ones. When bounding does not find the complete subset, we use a multi-round, partition-based distributed greedy algorithm to identify the remaining subset. We discuss how to implement these algorithms in a distributed data processing framework and empirically analyze different configurations. We find high quality subsets on CIFAR-100 and ImageNet with marginal or no loss in quality compared to centralized methods, and scale to a dataset with 13 billion points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16442v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian B\"other, Abraham Sebastian, Pranjal Awasthi, Ana Klimovic, Srikumar Ramalingam</dc:creator>
    </item>
    <item>
      <title>Modular Forms in Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2404.15546</link>
      <description>arXiv:2404.15546v2 Announce Type: replace-cross 
Abstract: Modular symmetries hidden in the combinatorial optimization framework remain mostly unexplored which has hindered any significant improvement in the solution quality. To unveil the modular structure, we map the cost and decision variables into complex domain and develop a novel framework for the Asymmetric Traveling Salesman Problem (ATSP). The transformed formulation is proven to be translation and inversion invariant, thereby allowing us to establish that achieving global optimum is equivalent to an infinite number of moment cancellations for each arc. The underlying idea is to achieve a delicate balance between cost and decision variables, expressed mathematically as an equilibrium condition, that allows for very strong modular symmetry to hold. The infinite moment cancellation is proven to be both necessary and sufficient condition for global optimality. In fact, we show that for strongly modular case, the rapid decay of moment contributions shall lead to series truncation with controllable error, allowing for efficient approximations. In contrast, weak modularity retains residual error thereby, reinforcing NP-hardness. These insights can inform the development of sophisticated algorithms that improve the quality of solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15546v2</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Varsha Gupta</dc:creator>
    </item>
    <item>
      <title>Quantum Global Minimum Finder based on Variational Quantum Search</title>
      <link>https://arxiv.org/abs/2405.00450</link>
      <description>arXiv:2405.00450v2 Announce Type: replace-cross 
Abstract: The search for global minima is a critical challenge across multiple fields including engineering, finance, and artificial intelligence, particularly with non-convex functions that feature multiple local optima, complicating optimization efforts. We introduce the Quantum Global Minimum Finder (QGMF), an innovative quantum computing approach that efficiently identifies global minima. QGMF combines binary search techniques to shift the objective function to a suitable position and then employs Variational Quantum Search to precisely locate the global minimum within this targeted subspace. Designed with a low-depth circuit architecture, QGMF is optimized for Noisy Intermediate-Scale Quantum (NISQ) devices, utilizing the logarithmic benefits of binary search to enhance scalability and efficiency. This work demonstrates the impact of QGMF in advancing the capabilities of quantum computing to overcome complex non-convex optimization challenges effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00450v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <category>math.QA</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1038/s41598-025-91407-z</arxiv:DOI>
      <dc:creator>Mohammadreza Soltaninia, Junpeng Zhan</dc:creator>
    </item>
    <item>
      <title>Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion Dynamics</title>
      <link>https://arxiv.org/abs/2410.04301</link>
      <description>arXiv:2410.04301v2 Announce Type: replace-cross 
Abstract: This work extends the recent opinion dynamics model from Cheng et al., emphasizing the role of group pressure in consensus formation. We generalize the findings to incorporate social influence algorithms with general time-varying, opinion-dependent weights and multidimensional opinions, beyond bounded confidence dynamics. We demonstrate that, with uniformly positive conformity levels, group pressure consistently drives consensus and provide a tighter estimate for the convergence rate. Unlike previous models, the common public opinion in our framework can assume arbitrary forms within the convex hull of current opinions, offering flexibility applicable to real-world scenarios such as opinion polls with random participant selection. This analysis provides deeper insights into how group pressure mechanisms foster consensus under diverse conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04301v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Iryna Zabarianska, Anton V. Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Solving Functional Optimization with Deep Networks and Variational Principles</title>
      <link>https://arxiv.org/abs/2410.06277</link>
      <description>arXiv:2410.06277v4 Announce Type: replace-cross 
Abstract: Can neural networks solve math problems using first a principle alone? This paper shows how to leverage the fundamental theorem of the calculus of variations to design deep neural networks to solve functional optimization without requiring training data (e.g., ground-truth optimal solutions). Our approach is particularly crucial when the solution is a function defined over an unknown interval or support\textemdash such as in minimum-time control problems. By incorporating the necessary conditions satisfied by the optimal function solution, as derived from the calculus of variation, in the design of the deep architecture, CalVNet leverages overparameterized neural networks to learn these optimal functions directly. We validate CalVNet by showing that, without relying on ground-truth data and simply incorporating first principles, it successfully derives the Kalman filter for linear filtering, the bang-bang optimal control for minimum-time problems, and finds geodesics on manifolds. Our results demonstrate that CalVNet can be trained in an unsupervised manner, without relying on ground-truth data, establishing a promising framework for addressing general, potentially unsolved functional optimization problems that still lack analytical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06277v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kawisorn Kamtue, Jose M. F. Moura, Orathai Sangpetch</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Using Ricci Flow</title>
      <link>https://arxiv.org/abs/2411.04292</link>
      <description>arXiv:2411.04292v2 Announce Type: replace-cross 
Abstract: This paper proposes a theoretical framework for modeling and optimizing the bounded functions based on the Fourier series approximation and Ricci flow. Specifically, the initial manifold, $\mathcal{M}_0$ is approximated using Fourier series approximation in conjunction with the center and boundary sampling procedure introduced in the paper. The manifold is iteratively evolved using an algorithm that involves sampling along geodesic hyper-sphere defined by the Riemannian metric tensor. Thus obtained surrogate manifold is optimized by applying inverse Ricci flow i.e. instead of regularizing the manifold, flow allows for the high curvature regions to blow into finite time singularities. This allows for the singularities to occur at potential global optima assuming the deviation of the manifold at any point is smaller than the optimum. In addition, the error bound is established on the accuracy of the surrogate manifold. Finally, the proposed method is tested on stochastic sampling from five benchmark functions to illustrate the utility of this method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04292v2</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Varsha Gupta</dc:creator>
    </item>
    <item>
      <title>Memory-Efficient 4-bit Preconditioned Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2412.10663</link>
      <description>arXiv:2412.10663v2 Announce Type: replace-cross 
Abstract: Preconditioned stochastic optimization algorithms, exemplified by Shampoo, outperform first-order optimizers by offering theoretical convergence benefits and practical gains in large-scale neural network training. However, they incur substantial memory overhead due to the storage demands of non-diagonal preconditioning matrices. To address this, we introduce 4-bit quantization for Shampoo's preconditioners. We introduce two key methods: First, we apply Cholesky decomposition followed by quantization of the Cholesky factors, reducing memory usage by leveraging their lower triangular structure while better preserving spectral properties to minimize information loss. To our knowledge, this is the first quantization approach applied to Cholesky factors of preconditioners. Second, we incorporate error feedback in the quantization process, efficiently storing Cholesky factor and error state in the lower and upper triangular parts of the same matrix. Through extensive experiments, we demonstrate that combining Cholesky quantization with error feedback enhances memory efficiency and algorithm performance in large-scale deep-learning tasks. Theoretically, we also provide convergence proofs for quantized Shampoo under both smooth and non-smooth stochastic optimization settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10663v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyang Li, Kuangyu Ding, Kim-Chuan Toh, Pan Zhou</dc:creator>
    </item>
    <item>
      <title>Optimal Output Feedback Learning Control for Discrete-Time Linear Quadratic Regulation</title>
      <link>https://arxiv.org/abs/2503.06226</link>
      <description>arXiv:2503.06226v2 Announce Type: replace-cross 
Abstract: This paper studies the linear quadratic regulation (LQR) problem of unknown discrete-time systems via dynamic output feedback learning control. In contrast to the state feedback, the optimality of the dynamic output feedback control for solving the LQR problem requires an implicit condition on the convergence of the state observer. Moreover, due to unknown system matrices and the existence of observer error, it is difficult to analyze the convergence and stability of most existing output feedback learning-based control methods. To tackle these issues, we propose a generalized dynamic output feedback learning control approach with guaranteed convergence, stability, and optimality performance for solving the LQR problem of unknown discrete-time linear systems. In particular, a dynamic output feedback controller is designed to be equivalent to a state feedback controller. This equivalence relationship is an inherent property without requiring convergence of the estimated state by the state observer, which plays a key role in establishing the off-policy learning control approaches. By value iteration and policy iteration schemes, the adaptive dynamic programming based learning control approaches are developed to estimate the optimal feedback control gain. In addition, a model-free stability criterion is provided by finding a nonsingular parameterization matrix, which contributes to establishing a switched iteration scheme. Furthermore, the convergence, stability, and optimality analyses of the proposed output feedback learning control approaches are given. Finally, the theoretical results are validated by two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06226v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kedi Xie, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu</dc:creator>
    </item>
  </channel>
</rss>
