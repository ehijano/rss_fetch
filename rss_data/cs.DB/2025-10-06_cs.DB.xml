<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Oct 2025 02:45:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A New Normalization Form for Limited Distinct Attributes</title>
      <link>https://arxiv.org/abs/2510.02865</link>
      <description>arXiv:2510.02865v1 Announce Type: new 
Abstract: In modern databases, the practice of data normalization continues to be important in improving data integrity, minimizing redundancies, and eliminating anomalies. However, since its inception and consequent improvements, there have been no attempts to document a method which constrains the values of attributes capable of only possessing a limited quantity of values. These non-limited distinct attributes pose a problem throughout many relational databases as they have the potential to cause data anomalies and query inaccuracies. Thus, a new database normalization method, Limited Distinct Normal Form (LDNF), is necessary in order to improve upon the currently established data normalization process. In brief, LDNF is a method which turns non-limited distinct attributes into limited distinct attributes by forcing the attributes to conform to a limited quantity of values. Utilizing LDNF in tandem with existing normal forms fulfills a need in normalization that is otherwise not present when only using current methods. A formal approach to LDNF is therefore proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02865v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niko S. Snell, Rayen C. Lee</dc:creator>
    </item>
    <item>
      <title>OpenZL: A Graph-Based Model for Compression</title>
      <link>https://arxiv.org/abs/2510.03203</link>
      <description>arXiv:2510.03203v1 Announce Type: cross 
Abstract: Research in general-purpose lossless compression over the last decade has largely found improvements in compression ratio that come at great cost to resource utilization and processing throughput. However, most production workloads require high throughput and low resource utilization, so most research systems have seen little adoption. Instead, real world improvements in compression are increasingly often realized by building application-specific compressors which can exploit knowledge about the structure and semantics of the data being compressed. These systems easily outperform even the best generic compressors, but application-specific compression schemes are not without drawbacks. They are inherently limited in applicability and are difficult to maintain and deploy.
  We show that these challenges can be overcome with a new way of thinking about compression. We propose the ``graph model'' of compression, a new theoretical framework for representing compression as a directed acyclic graph of modular codecs. This motivates OpenZL, an implementation of this model that compresses data into a self-describing wire format, any configuration of which can be decompressed by a universal decoder. OpenZL's design enables rapid development of tailored compressors with minimal code, its universal decoder eliminates deployment lag, and its investment in a well-vetted standard component library minimizes security risks. Experimental results demonstrate that OpenZL achieves superior compression ratios and speeds compared to state-of-the-art general-purpose compressors on a variety of real-world datasets. Internal deployments at Meta have also shown consistent improvements in size and/or speed, with development timelines reduced from months to days. OpenZL thus represents an advance in practical, scalable, and maintainable data compression for modern data-intensive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03203v1</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yann Collet, Nick Terrell, W. Felix Handte, Danielle Rozenblit, Victor Zhang, Kevin Zhang, Yaelle Goldschlag, Jennifer Lee, Daniel Riegel, Stan Angelov, Nadav Rotem</dc:creator>
    </item>
    <item>
      <title>Galley: Modern Query Optimization for Sparse Tensor Programs</title>
      <link>https://arxiv.org/abs/2408.14706</link>
      <description>arXiv:2408.14706v5 Announce Type: replace 
Abstract: The tensor programming abstraction is a foundational paradigm which allows users to write high performance programs via a high-level imperative interface. Recent work on sparse tensor compilers has extended this paradigm to sparse tensors (i.e., tensors where most entries are not explicitly represented). With these systems, users define the semantics of the program and the algorithmic decisions in a concise language that can be compiled to efficient low-level code. However, these systems still require users to make complex decisions about program structure and memory layouts to write efficient programs.
  This work presents Galley, a system for declarative tensor programming that allows users to write efficient tensor programs without making complex algorithmic decisions. Galley is the first system to perform cost based lowering of sparse tensor algebra to the imperative language of sparse tensor compilers, and the first to optimize arbitrary operators beyond sum and product. First, it decomposes the input program into a sequence of aggregation steps through a novel extension of the FAQ framework. Second, Galley optimizes and converts each aggregation step to a concrete program, which is compiled and executed with a sparse tensor compiler. We show that Galley produces programs that are 1-300x faster than competing methods for machine learning over joins and 5-20x faster than a state-of-the-art relational database for subgraph counting workloads with a minimal optimization overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14706v5</guid>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyle Deeds, Willow Ahrens, Magda Balazinska, Dan Suciu</dc:creator>
    </item>
    <item>
      <title>Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward</title>
      <link>https://arxiv.org/abs/2505.12380</link>
      <description>arXiv:2505.12380v3 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) has been widely adopted to enhance the performance of large language models (LLMs) on Text-to-SQL tasks. However, existing methods often rely on execution-based or LLM-based Bradley-Terry reward models. The former suffers from high execution latency caused by repeated database calls, whereas the latter imposes substantial GPU memory overhead, both of which significantly hinder the efficiency and scalability of RL pipelines. To this end, we propose a novel reward model framework for RL-based Text-to-SQL named Graph-Reward-SQL, which employs the GMNScore outcome reward model. We leverage SQL graph representations to provide accurate reward signals while significantly reducing time cost and GPU memory usage. Building on this foundation, we further introduce StepRTM, a stepwise reward model that provides intermediate supervision over Common Table Expression (CTE) subqueries. This encourages both functional correctness and readability of SQL. Extensive comparative and ablation experiments on standard benchmarks, including Spider and BIRD, demonstrate that our method consistently outperforms existing reward models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12380v3</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Han Weng, Puzhen Wu, Longjie Cui, Yi Zhan, Boyi Liu, Yuanfeng Song, Dun Zeng, Yingxiang Yang, Qianru Zhang, Dong Huang, Xiaoming Yin, Yang Sun, Xing Chen</dc:creator>
    </item>
  </channel>
</rss>
