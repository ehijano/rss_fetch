<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Apr 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploring UAV Networking from the Terrain Information Completeness Perspective: A Tutorial</title>
      <link>https://arxiv.org/abs/2404.04505</link>
      <description>arXiv:2404.04505v1 Announce Type: new 
Abstract: Terrain information is a crucial factor affecting the performance of unmanned aerial vehicle (UAV) networks. As a tutorial, this article provides a unique perspective on the completeness of terrain information, summarizing and enhancing the research on terrain-based UAV deployment. In the presence of complete terrain information, two highly discussed topics are UAV-aided map construction and dynamic trajectory design based on maps. We propose a case study illustrating the mutually reinforcing relationship between them. When terrain information is incomplete, and only terrain-related feature parameters are available, we discuss how existing models map terrain features to blockage probabilities. By introducing the application of this model with stochastic geometry, a case study is proposed to analyze the accuracy of the model. When no terrain information is available, UAVs gather terrain information during the real-time networking process and determine the next position by collected information. This real-time search method is currently limited to relay communication. In the case study, we extend it to a multi-user scenario and summarize three trade-offs of the method. Finally, we conduct a qualitative analysis to assess the impact of three factors that have been overlooked in terrain-based UAV deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04505v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhengying Lou, Ruibo Wang, Baha Eddine Youcef Belmekki, Mustafa A. Kishk, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>EVT-enriched Radio Maps for URLLC</title>
      <link>https://arxiv.org/abs/2404.04558</link>
      <description>arXiv:2404.04558v1 Announce Type: new 
Abstract: This paper introduces a sophisticated and adaptable framework combining extreme value theory with radio maps to spatially model extreme channel conditions accurately. Utilising existing signal-to-noise ratio (SNR) measurements and leveraging Gaussian processes, our approach predicts the tail of the SNR distribution, which entails estimating the parameters of a generalised Pareto distribution, at unobserved locations. This innovative method offers a versatile solution adaptable to various resource allocation challenges in ultra-reliable low-latency communications. We evaluate the performance of this method in a rate maximisation problem with defined outage constraints and compare it with a benchmark in the literature. Notably, the proposed approach meets the outage demands in a larger percentage of the coverage area and reaches higher transmission rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04558v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dian Echevarr\'ia P\'erez, Onel L. Alcaraz L\'opez, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>RIS in Cellular Networks -- Challenges and Issues</title>
      <link>https://arxiv.org/abs/2404.04753</link>
      <description>arXiv:2404.04753v1 Announce Type: new 
Abstract: Reconfigurable intelligent surface (RIS) has been suggested to be a key 6G feature and was suggested to be considered as a study-item in both 3GPP Releases 18 and 19. However, in both releases, it has been decided not to continue with it as a study-item, and to leave it for possible future specification. In this paper, we present the rationale for such a decision. Particularly, we demonstrate the practical issues which may affect the feasibility or usefulness of RIS in cellular networks, and present open problems to be addressed before RIS can be used in practice. Moreover, we compare the performance of RIS with network-controlled repeater, the node with the most similar characteristics to RIS and which has been standardized in 3GPP Release 18. Finally, different simulations are presented to evaluate the performance of RIS-assisted networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04753v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Magnus {\AA}str\"om, Philipp Gentner, Omer Haliloglu, Behrooz Makki, Ola Tageman</dc:creator>
    </item>
    <item>
      <title>Theoretical Analysis of the Three-Dimensional CAC Considering Connection and Communication Quality</title>
      <link>https://arxiv.org/abs/2404.04894</link>
      <description>arXiv:2404.04894v1 Announce Type: new 
Abstract: In emergencies such as disasters, the number of voice calls (VoIP sessions) increases rapidly for a variety of purposes. Thus, a control server near a disaster area may not be able to connect to VoIP sessions due to congestion. To solve this problem, a Call Admission Control (CAC) is needed to determine whether a VoIP session requesting a connection can be accepted or rejected. A CAC has the purpose of guaranteeing the connection quality and communication quality of VoIP sessions. One conventional method classifies VoIP sessions into three classes (emergency VoIP sessions, VoIP sessions from the disaster area, and VoIP sessions from outside the disaster area) by focusing on the outgoing location and offers a CAC with a priority level for each. However, a conventional CAC method cannot be applied to VoIP networks because reception control is designed for Public Switched Telephone Networks (PSTN). When conventional methods are applied to VoIP networks, the connection quality is guaranteed, however the communication quality cannot be guaranteed because the packet dropping probability is not considered. In this paper, we propose a three-dimensional CAC that controls three classes of VoIP sessions and guarantees both communication and connection quality in VoIP networks during emergencies. A conventional CAC method and our proposed CAC method are evaluated in terms of the call blocking probability, which guarantees the connection quality, and packet dropping probability, which guarantees the communication quality, to show the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04894v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sota Narikiyo, Sumiko Miyata, Ken-ichi Baba, Katsunori Yamaoka</dc:creator>
    </item>
    <item>
      <title>QRscript: Embedding a Programming Language in QR codes to support Decision and Management</title>
      <link>https://arxiv.org/abs/2404.05073</link>
      <description>arXiv:2404.05073v1 Announce Type: new 
Abstract: Embedding a programming language in a QR code is a new and extremely promising opportunity, as it makes devices and objects smarter without necessarily requiring an Internet connection. In this paper, all the steps needed to translate a program written in a high-level programming language to its binary representation encoded in a QR code, and the opposite process that, starting from the QR code, executes it by means of a virtual machine, have been carefully detailed. The proposed programming language was named QRscript, and can be easily extended so as to integrate new features. One of the main design goals was to produce a very compact target binary code. In particular, in this work we propose a specific sub-language (a dialect) that is aimed at encoding decision trees. Besides industrial scenarios, this is useful in many other application fields. The reported example, related to the configuration of an industrial networked device, highlights the potential of the proposed technology, and permits to better understand all the translation steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05073v1</guid>
      <category>cs.NI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ETFA52439.2022.9921530</arxiv:DOI>
      <arxiv:journal_reference>27th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA 2022)</arxiv:journal_reference>
      <dc:creator>Stefano Scanzio, Gianluca Cena, Adriano Valenzano</dc:creator>
    </item>
    <item>
      <title>Exact Analysis of the Age of Information in the Multi-Source M/GI/1 Queueing System</title>
      <link>https://arxiv.org/abs/2404.05167</link>
      <description>arXiv:2404.05167v1 Announce Type: new 
Abstract: We consider a situation that multiple monitoring applications (each with a different sensor-monitor pair) compete for a common service resource such as a communication link. Each sensor reports the latest state of its own time-varying information source to its corresponding monitor, incurring queueing and processing delays at the shared resource. The primary performance metric of interest is the age of information (AoI) of each sensor-monitor pair, which is defined as the elapsed time from the generation of the information currently displayed on the monitor. Although the multi-source first-come first-served (FCFS) M/GI/1 queue is one of the most fundamental model to describe such competing sensors, its exact analysis has been an open problem for years. In this paper, we show that the Laplace-Stieltjes transform (LST) of the stationary distribution of the AoI in this model, as well as the mean AoI, is given by a simple explicit formula, utilizing the double Laplace transform of the transient workload in the M/GI/1 queue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05167v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshiaki Inoue, Tetsuya Takine</dc:creator>
    </item>
    <item>
      <title>Can Edge Computing fulfill the requirements of automated vehicular services using 5G network ?</title>
      <link>https://arxiv.org/abs/2404.05296</link>
      <description>arXiv:2404.05296v1 Announce Type: new 
Abstract: Communication and computation services supporting Connected and Automated Vehicles (CAVs) are characterized by stringent requirements, in terms of response time and reliability. Fulfilling these requirements is crucial for ensuring road safety and traffic optimization. The conceptually simple solution of hosting these services in the vehicles increases their cost (mainly due to the installation and maintenance of computation infrastructure) and may drain their battery excessively. Such disadvantages can be tackled via Multi-Access Edge Computing (MEC), consisting in deploying computation capability in network nodes deployed close to the devices (vehicles in this case), such as to satisfy the stringent CAV requirements. However, it is not yet clear under which conditions MEC can support CAV requirements and for which services. To shed light on this question, we conduct a simulation campaign using well-known open-source simulation tools, namely OMNeT++, Simu5G, Veins, INET, and SUMO. We are thus able to provide a reality check on MEC for CAV, pinpointing what are the computation capacities that must be installed in the MEC, to support the different services, and the amount of vehicles that a single MEC node can support. We find that such parameters must vary a lot, depending on the service considered. This study can serve as a preliminary basis for network operators to plan future deployment of MEC to support CAV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05296v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wendlasida Ouedraogo, Andrea Araldo, Badii Jouaber, Hind Castel, Remy Grunblatt</dc:creator>
    </item>
    <item>
      <title>Liquid Neural Network-based Adaptive Learning vs. Incremental Learning for Link Load Prediction amid Concept Drift due to Network Failures</title>
      <link>https://arxiv.org/abs/2404.05304</link>
      <description>arXiv:2404.05304v1 Announce Type: new 
Abstract: Adapting to concept drift is a challenging task in machine learning, which is usually tackled using incremental learning techniques that periodically re-fit a learning model leveraging newly available data. A primary limitation of these techniques is their reliance on substantial amounts of data for retraining. The necessity of acquiring fresh data introduces temporal delays prior to retraining, potentially rendering the models inaccurate if a sudden concept drift occurs in-between two consecutive retrainings. In communication networks, such issue emerges when performing traffic forecasting following a~failure event: post-failure re-routing may induce a drastic shift in distribution and pattern of traffic data, thus requiring a timely model adaptation. In this work, we address this challenge for the problem of traffic forecasting and propose an approach that exploits adaptive learning algorithms, namely, liquid neural networks, which are capable of self-adaptation to abrupt changes in data patterns without requiring any retraining. Through extensive simulations of failure scenarios, we compare the predictive performance of our proposed approach to that of a reference method based on incremental learning. Experimental results show that our proposed approach outperforms incremental learning-based methods in situations where the shifts in traffic patterns are drastic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05304v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omran Ayoub, Davide Andreoletti, Aleksandra Knapi\'nska, R\'o\.za Go\'scie\'n, Piotr Lechowicz, Tiziano Leidi, Silvia Giordano, Cristina Rottondi, Krzysztof Walkowiak</dc:creator>
    </item>
    <item>
      <title>Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2404.05564</link>
      <description>arXiv:2404.05564v1 Announce Type: new 
Abstract: With the uptake of intelligent data-driven applications, edge computing infrastructures necessitate a new generation of admission control algorithms to maximize system performance under limited and highly heterogeneous resources. In this paper, we study how to optimally select information flows which belong to different classes and dispatch them to multiple edge servers where deployed applications perform flow analytic tasks. The optimal policy is obtained via constrained Markov decision process (CMDP) theory accounting for the demand of each edge application for specific classes of flows, the constraints on computing capacity of edge servers and of the access network.
  We develop DR-CPO, a specialized primal-dual Safe Reinforcement Learning (SRL) method which solves the resulting optimal admission control problem by reward decomposition. DR-CPO operates optimal decentralized control and mitigates effectively state-space explosion while preserving optimality. Compared to existing Deep Reinforcement Learning (DRL) solutions, extensive results show that DR-CPO achieves 15\% higher reward on a wide variety of environments, while requiring on average only 50\% of the amount of learning episodes to converge. Finally, we show how to match DR-CPO and load-balancing to dispatch optimally information streams to available edge servers and further improve system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05564v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Fox (Avignon Universit\'e), F. De Pellegrini (Avignon Universit\'e), F. Faticanti (ENS Lyon), E. Altman (Inria), F. Bronzino (ENS Lyon)</dc:creator>
    </item>
    <item>
      <title>Distributed No-Regret Learning for Multi-Stage Systems with End-to-End Bandit Feedback</title>
      <link>https://arxiv.org/abs/2404.04509</link>
      <description>arXiv:2404.04509v1 Announce Type: cross 
Abstract: This paper studies multi-stage systems with end-to-end bandit feedback. In such systems, each job needs to go through multiple stages, each managed by a different agent, before generating an outcome. Each agent can only control its own action and learn the final outcome of the job. It has neither knowledge nor control on actions taken by agents in the next stage. The goal of this paper is to develop distributed online learning algorithms that achieve sublinear regret in adversarial environments.
  The setting of this paper significantly expands the traditional multi-armed bandit problem, which considers only one agent and one stage. In addition to the exploration-exploitation dilemma in the traditional multi-armed bandit problem, we show that the consideration of multiple stages introduces a third component, education, where an agent needs to choose its actions to facilitate the learning of agents in the next stage. To solve this newly introduced exploration-exploitation-education trilemma, we propose a simple distributed online learning algorithm, $\epsilon-$EXP3. We theoretically prove that the $\epsilon-$EXP3 algorithm is a no-regret policy that achieves sublinear regret. Simulation results show that the $\epsilon-$EXP3 algorithm significantly outperforms existing no-regret online learning algorithms for the traditional multi-armed bandit problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04509v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>I-Hong Hou</dc:creator>
    </item>
    <item>
      <title>Self-Evolving Wireless Communications: A Novel Intelligence Trend for 6G and Beyond</title>
      <link>https://arxiv.org/abs/2404.04844</link>
      <description>arXiv:2404.04844v1 Announce Type: cross 
Abstract: Wireless communication is rapidly evolving, and future wireless communications (6G and beyond) will be more heterogeneous, multi-layered, and complex, which poses challenges to traditional communications. Adaptive technologies in traditional communication systems respond to environmental changes by modifying system parameters and structures on their own and are not flexible and agile enough to satisfy requirements in future communications. To tackle these challenges, we propose a novel self-evolving communication framework, which consists of three layers: data layer, information layer, and knowledge layer. The first two layers allow communication systems to sense environments, fuse data, and generate a knowledge base for the knowledge layer. When dealing with a variety of application scenarios and environments, the generated knowledge is subsequently fed back to the first two layers for communication in practical application scenarios to obtain self-evolving ability and enhance the robustness of the system. In this paper, we first highlight the limitations of current adaptive communication systems and the need for intelligence, automation, and self-evolution in future wireless communications. We overview the development of self-evolving technologies and conceive the concept of self-evolving communications with its hypothetical architecture. To demonstrate the power of self-evolving modules, we compare the performances of a communication system with and without evolution. We then provide some potential techniques that enable self-evolving communications and challenges in implementing them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04844v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangxin Qian, Ping Yang, Jun Zhao, Ze Chen, Wanbin Tang</dc:creator>
    </item>
    <item>
      <title>Session Types for the Transport Layer: Towards an Implementation of TCP</title>
      <link>https://arxiv.org/abs/2404.05478</link>
      <description>arXiv:2404.05478v1 Announce Type: cross 
Abstract: Session types are a typing discipline used to formally describe communication-driven applications with the aim of fewer errors and easier debugging later into the life cycle of the software. Protocols at the transport layer such as TCP, UDP, and QUIC underpin most of the communication on the modern Internet and affect billions of end-users. The transport layer has different requirements and constraints compared to the application layer resulting in different requirements for verification. Despite this, to our best knowledge, no work shows the application of session types at the transport layer. In this work, we discuss how multiparty session types (MPST) can be applied to implement the TCP protocol. We develop an MPST-based implementation of a subset of a TCP server in Rust and test its interoperability against the Linux TCP stack. Our results highlight the differences in assumptions between session type theory and the way transport layer protocols are usually implemented. This work is the first step towards bringing session types into the transport layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05478v1</guid>
      <category>cs.PL</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.401.3</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 401, 2024, pp. 22-36</arxiv:journal_reference>
      <dc:creator>Samuel Cavoj (University of Glasgow), Ivan Nikitin (University of Glasgow), Colin Perkins (University of Glasgow), Ornela Dardha (University of Glasgow)</dc:creator>
    </item>
    <item>
      <title>AI-Enabled System for Efficient and Effective Cyber Incident Detection and Response in Cloud Environments</title>
      <link>https://arxiv.org/abs/2404.05602</link>
      <description>arXiv:2404.05602v1 Announce Type: cross 
Abstract: The escalating sophistication and volume of cyber threats in cloud environments necessitate a paradigm shift in strategies. Recognising the need for an automated and precise response to cyber threats, this research explores the application of AI and ML and proposes an AI-powered cyber incident response system for cloud environments. This system, encompassing Network Traffic Classification, Web Intrusion Detection, and post-incident Malware Analysis (built as a Flask application), achieves seamless integration across platforms like Google Cloud and Microsoft Azure. The findings from this research highlight the effectiveness of the Random Forest model, achieving an accuracy of 90% for the Network Traffic Classifier and 96% for the Malware Analysis Dual Model application. Our research highlights the strengths of AI-powered cyber security. The Random Forest model excels at classifying cyber threats, offering an efficient and robust solution. Deep learning models significantly improve accuracy, and their resource demands can be managed using cloud-based TPUs and GPUs. Cloud environments themselves provide a perfect platform for hosting these AI/ML systems, while container technology ensures both efficiency and scalability. These findings demonstrate the contribution of the AI-led system in guaranteeing a robust and scalable cyber incident response solution in the cloud.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05602v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed A. M. Farzaan, Mohamed Chahine Ghanem, Ayman El-Hajjar</dc:creator>
    </item>
    <item>
      <title>Bodyless Block Propagation: TPS Fully Scalable Blockchain with Pre-Validation</title>
      <link>https://arxiv.org/abs/2204.08769</link>
      <description>arXiv:2204.08769v3 Announce Type: replace 
Abstract: Despite numerous prior attempts to boost transaction per second (TPS) of blockchain systems, many sacrifice decentralization and security. This paper proposes a bodyless block propagation (BBP) scheme for which the blockbody is not validated and transmitted during block propagation, to increase TPS without compromising security. Nodes in the blockchain network anticipate the transactions and their ordering in the next upcoming block so that these transactions can be pre-executed and pre-validated before the block is born. For a network with $N$ nodes, our theoretical analysis reveals that BBP can improve TPS scalability from $O(1/log(N))$ to $O(1)$.
  Ensuring consensus on the next block's transaction content is crucial. We propose a transaction selection, ordering, and synchronization algorithm to drive this consensus. To address the undetermined Coinbase address issue, we further present an algorithm for such unresolvable transactions, ensuring a consistent and TPS-efficient scheme. With BBP, most transactions require neither validation nor transmission during block propagation, liberating system from transaction-block dependencies and rendering TPS scalable. Both theoretical analysis and experiments underscore BBP's potential for full TPS scalability. Experimental results reveal a 4x reduction in block propagation time compared to Ethereum blockchain, with TPS performance being limited by node hardware rather than block propagation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.08769v3</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chonghe Zhao, Shengli Zhang, Taotao Wang, Soung Chang Liew</dc:creator>
    </item>
    <item>
      <title>Digital Twin-Driven Network Architecture for Video Streaming</title>
      <link>https://arxiv.org/abs/2310.19079</link>
      <description>arXiv:2310.19079v2 Announce Type: replace 
Abstract: Digital twin (DT) is revolutionizing the emerging video streaming services through tailored network management. By integrating diverse advanced communication technologies, DTs are promised to construct a holistic virtualized network for better network management performance. To this end, we develop a DT-driven network architecture for video streaming (DTN4VS) to enable network virtualization and tailored network management. With the architecture, various types of DTs can characterize physical entities' status, separate the network management functions from the network controller, and empower the functions with emulated data and tailored strategies. To further enhance network management performance, three potential approaches are proposed, i.e., domain data exploitation, performance evaluation, and adaptive DT model update. We present a case study pertaining to DT-assisted network slicing for short video streaming, followed by some open research issues for DTN4VS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19079v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Huang, Haojun Yang, Shisheng Hu, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>5G-CT: Automated Deployment and Over-the-Air Testing of End-to-End Open Radio Access Networks</title>
      <link>https://arxiv.org/abs/2311.03206</link>
      <description>arXiv:2311.03206v3 Announce Type: replace 
Abstract: Deploying and testing cellular networks is a complex task due to the multitude of components involved -- from the core to the Radio Access Network (RAN) and User Equipment (UE) -- all of which requires integration and constant monitoring. Additional challenges are posed by the nature of the wireless channel, whose inherent randomness hinders the repeatability and consistency of the testing process. Consequently, existing solutions for both private and public cellular systems still rely heavily on human intervention for operations such as network reconfiguration, performance monitoring, and end-to-end testing. This reliance significantly slows the pace of innovation in cellular systems. To address these challenges, we introduce 5G-CT, an automation framework based on OpenShift and the GitOps workflow, capable of deploying a softwarized end-to-end 5G and O-RAN-compliant system in a matter of seconds without the need for any human intervention. We have deployed 5G-CT to test the integration and performance of open-source cellular stacks, including OpenAirInterface, and have collected months of automated over-the-air testing results involving software-defined radios. 5G-CT brings cloud-native continuous integration and delivery to the RAN, effectively addressing the complexities associated with managing spectrum, radios, heterogeneous devices, and distributed components. Moreover, it endows cellular networks with much needed automation and continuous testing capabilities, providing a platform to evaluate the robustness and resiliency of Open RAN software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03206v3</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo Bonati, Michele Polese, Salvatore D'Oro, Pietro Brach del Prever, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>IEEE 802.11be Network Throughput Optimization with Multi-Link Operation and AP Coordination</title>
      <link>https://arxiv.org/abs/2312.00345</link>
      <description>arXiv:2312.00345v2 Announce Type: replace 
Abstract: IEEE 802.11be (Wi-Fi 7) introduces a new concept called multi-link operation (MLO), which allows multiple Wi-Fi interfaces in different bands (2.4, 5, and 6 GHz) to work together to increase network throughput, reduce latency, and improve spectrum reuse efficiency in dense overlapping networks. To make the most of MLO, this paper proposes a new data-driven resource allocation algorithm for the 11be network with the aid of an access point (AP) controller. To maximize network throughput, a network topology optimization problem is formulated for 11be network, which is solved by exploiting the totally unimodular property of the bipartite graph formed by the connection between AP and station (STA) in Wi-Fi networks. Subsequently, a proportional fairness algorithm is applied for radio link allocation, network throughput optimization considering the channel condition, and the fairness of the multi-link device (MLD) data rate. The performance of the proposed algorithm on two main MLO implementations - multi-link multi-radio (MLMR) with simultaneous transmission and reception (STR), and the interplay between multiple nodes employing them are evaluated through cross-layer (PHY-MAC) data rate simulation with PHY abstraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00345v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lyutianyang Zhang, Hao Yin, Sumit Roy, Liu Cao, Xiangyu Gao, Vanlin Sathya</dc:creator>
    </item>
    <item>
      <title>NeuraLunaDTNet: Feedforward Neural Network-Based Routing Protocol for Delay-Tolerant Lunar Communication Networks</title>
      <link>https://arxiv.org/abs/2403.20199</link>
      <description>arXiv:2403.20199v2 Announce Type: replace 
Abstract: Space Communication poses challenges such as severe delays, hard-to-predict routes and communication disruptions. The Delay Tolerant Network architecture, having been specifically designed keeping such scenarios in mind, is suitable to address some challenges. The traditional DTN routing protocols fall short of delivering optimal performance, due to the inherent complexities of space communication. Researchers have aimed at using recent advancements in AI to mitigate some routing challenges [9]. We propose utilising a feedforward neural network to develop a novel protocol NeuraLunaDTNet, which enhances the efficiency of the PRoPHET routing protocol for lunar communication, by learning contact plans in dynamically changing spatio-temporal graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20199v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parth Patel, Milena Radenkovic</dc:creator>
    </item>
    <item>
      <title>When Digital Twin Meets Generative AI: Intelligent Closed-Loop Network Management</title>
      <link>https://arxiv.org/abs/2404.03025</link>
      <description>arXiv:2404.03025v2 Announce Type: replace 
Abstract: Generative artificial intelligence (GAI) and digital twin (DT) are advanced data processing and virtualization technologies to revolutionize communication networks. Thanks to the powerful data processing capabilities of GAI, integrating it into DT is a potential approach to construct an intelligent holistic virtualized network for better network management performance. To this end, we propose a GAI-driven DT (GDT) network architecture to enable intelligent closed-loop network management. In the architecture, various GAI models can empower DT status emulation, feature abstraction, and network decision-making. The interaction between GAI-based and model-based data processing can facilitate intelligent external and internal closed-loop network management. To further enhance network management performance, three potential approaches are proposed, i.e., model light-weighting, adaptive model selection, and data-model-driven network management. We present a case study pertaining to data-model-driven network management for the GDT network, followed by some open research issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03025v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Huang, Haojun Yang, Conghao Zhou, Mingcheng He, Xuemin Shen, Weihua Zhuang</dc:creator>
    </item>
    <item>
      <title>Fedstellar: A Platform for Decentralized Federated Learning</title>
      <link>https://arxiv.org/abs/2306.09750</link>
      <description>arXiv:2306.09750v4 Announce Type: replace-cross 
Abstract: In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train Machine Learning (ML) models across the participants of a federation while preserving data privacy. Since its birth, Centralized FL (CFL) has been the most used approach, where a central entity aggregates participants' models to create a global one. However, CFL presents limitations such as communication bottlenecks, single point of failure, and reliance on a central server. Decentralized Federated Learning (DFL) addresses these issues by enabling decentralized model aggregation and minimizing dependency on a central entity. Despite these advances, current platforms training DFL models struggle with key issues such as managing heterogeneous federation network topologies. To overcome these challenges, this paper presents Fedstellar, a platform extended from p2pfl library and designed to train FL models in a decentralized, semi-decentralized, and centralized fashion across diverse federations of physical or virtualized devices. The Fedstellar implementation encompasses a web application with an interactive graphical interface, a controller for deploying federations of nodes using physical or virtual devices, and a core deployed on each device which provides the logic needed to train, aggregate, and communicate in the network. The effectiveness of the platform has been demonstrated in two scenarios: a physical deployment involving single-board devices such as Raspberry Pis for detecting cyberattacks, and a virtualized deployment comparing various FL approaches in a controlled environment using MNIST and CIFAR-10 datasets. In both scenarios, Fedstellar demonstrated consistent performance and adaptability, achieving F1 scores of 91%, 98%, and 91.2% using DFL for detecting cyberattacks and classifying MNIST and CIFAR-10, respectively, reducing training time by 32% compared to centralized approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09750v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.eswa.2023.122861</arxiv:DOI>
      <dc:creator>Enrique Tom\'as Mart\'inez Beltr\'an, \'Angel Luis Perales G\'omez, Chao Feng, Pedro Miguel S\'anchez S\'anchez, Sergio L\'opez Bernal, G\'er\^ome Bovet, Manuel Gil P\'erez, Gregorio Mart\'inez P\'erez, Alberto Huertas Celdr\'an</dc:creator>
    </item>
    <item>
      <title>Securing OPEN-RAN Equipment Using Blockchain-Based Supply Chain Verification</title>
      <link>https://arxiv.org/abs/2402.17632</link>
      <description>arXiv:2402.17632v2 Announce Type: replace-cross 
Abstract: The disaggregated and multi-vendor nature of OPEN-RAN networks introduces new supply chain security risks, making equipment authenticity and integrity crucial challenges. Robust solutions are needed to mitigate vulnerabilities in manufacturing and integration. This paper puts forth a novel blockchain-based approach to secure OPEN-RAN equipment through its lifecycle. By combining firmware authentication codes, a permissioned blockchain ledger, and equipment node validators, we architect a tamper-resistant ecosystem to track provenance. The outlined design, while conceptual, establishes a foundation and roadmap for future realization. Through careful implementation planning, development of core components like firmware signed hashes and smart contracts, and rigorous performance evaluation, this paper can evolve from concept to practice. There is a vivid potential to make OPEN-RAN supply chains corner to corner secure, igniting further research and real-world deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17632v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Mehrban, Mostafa Jani</dc:creator>
    </item>
  </channel>
</rss>
