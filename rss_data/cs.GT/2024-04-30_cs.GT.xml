<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 May 2024 04:00:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 01 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Effect of Bounded Rationality in Electricity Markets</title>
      <link>https://arxiv.org/abs/2404.19236</link>
      <description>arXiv:2404.19236v1 Announce Type: new 
Abstract: Nash equilibrium is a common solution concept that captures the strategic interaction in electricity market analysis. However, it requires a fundamental but impractical assumption that all market participants are fully rational, which implies unlimited computational resources and cognitive abilities. To tackle the limitation, level-k reasoning is proposed and studied to model the bounded rational behaviors. In this paper, we consider a Cournot competition in electricity markets with two suppliers both following level-k reasoning. One is a self-interested firm and the other serves as a benevolent social planner. First, we observe that the optimal strategy of the social planner is to be of a particular rationality level. Being less or more rational may both result in reduced social welfare. Then, we investigate the effect of bounded rationality on social welfare performance and find that it could largely deviate from that at the Nash equilibrium point. Finally, we characterize optimal, mean maximizing and max-min strategies for the benevolent social planner, when having access to different information. The numerical experiments further demonstrate and validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19236v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lihui Yi, Ermin Wei</dc:creator>
    </item>
    <item>
      <title>A Negotiator's Backup Plan: Optimal Concessions with a Reservation Value</title>
      <link>https://arxiv.org/abs/2404.19361</link>
      <description>arXiv:2404.19361v1 Announce Type: new 
Abstract: Automated negotiation is a well-known mechanism for autonomous agents to reach agreements. To realize beneficial agreements quickly, it is key to employ a good bidding strategy. When a negotiating agent has a good back-up plan, i.e., a high reservation value, failing to reach an agreement is not necessarily disadvantageous. Thus, the agent can adopt a risk-seeking strategy, aiming for outcomes with a higher utilities.
  Accordingly, this paper develops an optimal bidding strategy called MIA-RVelous for bilateral negotiations with private reservation values. The proposed greedy algorithm finds the optimal bid sequence given the agent's beliefs about the opponent in $O(n^2D)$ time, with $D$ the maximum number of rounds and $n$ the number of outcomes. The results obtained here can pave the way to realizing effective concurrent negotiations, given that concurrent negotiations can serve as a (probabilistic) backup plan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19361v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamara C. P. Florijn, Pinar Yolum, Tim Baarslag</dc:creator>
    </item>
    <item>
      <title>Complexity of Round-Robin Allocation with Potentially Noisy Queries</title>
      <link>https://arxiv.org/abs/2404.19402</link>
      <description>arXiv:2404.19402v1 Announce Type: new 
Abstract: We study the complexity of a fundamental algorithm for fairly allocating indivisible items, the round-robin algorithm. For $n$ agents and $m$ items, we show that the algorithm can be implemented in time $O(nm\log(m/n))$ in the worst case. If the agents' preferences are uniformly random, we establish an improved (expected) running time of $O(nm + m\log m)$. On the other hand, assuming comparison queries between items, we prove that $\Omega(nm + m\log m)$ queries are necessary to implement the algorithm, even when randomization is allowed. We also derive bounds in noise models where the answers to queries are incorrect with some probability. Our proofs involve novel applications of tools from multi-armed bandit, information theory, as well as posets and linear extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19402v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihan Li, Pasin Manurangsi, Jonathan Scarlett, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>Collaborative Control Method of Transit Signal Priority Based on Cooperative Game and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2404.19683</link>
      <description>arXiv:2404.19683v1 Announce Type: new 
Abstract: To address the low efficiency in priority signal control within intelligent transportation systems, this study introduces a novel eight-phase priority signal control method, CBQL-TSP, leveraging a hybrid decision-making framework that integrates cooperative game theory and reinforcement learning. This approach conceptualizes the allocation of bus signal priorities as a multi-objective decision-making problem across an eight-phase signal sequence, differentiating between priority and non-priority phases. It employs a cooperative game model to facilitate this differentiation. The developed hybrid decision-making algorithm, CBQL, effectively tackles the multi-objective decision-making challenges inherent in the eight-phase signal sequence. By computing the Shapley value function, it quantifies the marginal contributions of each participant, which in turn inform the construction of a state transition probability equation based on Shapley value ratios. Compared to conventional control methods, the CBQL-TSP method not only upholds the fairness principles of cooperative game theory but also harnesses the adaptive learning capabilities of Q-Learning. This enables dynamic adjustments to signal timing in response to real-time traffic conditions, significantly enhancing the flexibility and efficiency of priority signal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19683v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Qin, Weishi Zhang</dc:creator>
    </item>
    <item>
      <title>Almost Envy-Freeness under Weakly Lexicographic Preferences</title>
      <link>https://arxiv.org/abs/2404.19740</link>
      <description>arXiv:2404.19740v1 Announce Type: new 
Abstract: In fair division of indivisible items, domain restriction has played a key role in escaping from negative results and providing structural insights into the computational and axiomatic boundaries of fairness. One notable subdomain of additive preferences, the lexicographic domain, has yielded several positive results in dealing with goods, chores, and mixtures thereof. However, the majority of work within this domain primarily consider strict linear orders over items, which do not allow the modeling of more expressive preferences that contain indifferences (ties). We investigate the most prominent fairness notions of envy-freeness up to any (EFX) or some (EF1) item under weakly lexicographic preferences. For the goods-only setting, we develop an algorithm that can be customized to guarantee EF1, EFX, maximin share (MMS), or a combination thereof, along the efficiency notion of Pareto optimality (PO). From the conceptual perspective, we propose techniques such as preference graphs and potential envy that are independently of interest when dealing with ties. Finally, we demonstrate challenges in dealing with chores and highlight key algorithmic and axiomatic differences of finding EFX solutions with the goods-only setting. Nevertheless, we show that there is an algorithm that always returns an EF1 and PO allocation for the chores-only instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19740v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Aghaheybat Mammadov, Tomasz W\k{a}s</dc:creator>
    </item>
    <item>
      <title>Mitigating Pilot Contamination and Enabling IoT Scalability in Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2310.03278</link>
      <description>arXiv:2310.03278v1 Announce Type: cross 
Abstract: Massive MIMO is expected to play an important role in the development of 5G networks. This paper addresses the issue of pilot contamination and scalability in massive MIMO systems. The current practice of reusing orthogonal pilot sequences in adjacent cells leads to difficulty in differentiating incoming inter- and intra-cell pilot sequences. One possible solution is to increase the number of orthogonal pilot sequences, which results in dedicating more space of coherence block to pilot transmission than data transmission. This, in turn, also hinders the scalability of massive MIMO systems, particularly in accommodating a large number of IoT devices within a cell. To overcome these challenges, this paper devises an innovative pilot allocation scheme based on the data transfer patterns of IoT devices. The scheme assigns orthogonal pilot sequences to clusters of devices instead of individual devices, allowing multiple devices to utilize the same pilot for periodically transmitting data. Moreover, we formulate the pilot assignment problem as a graph coloring problem and use the max k-cut graph partitioning approach to overcome the pilot contamination in a multicell massive MIMO system. The proposed scheme significantly improves the spectral efficiency and enables the scalability of massive MIMO systems; for instance, by using ten orthogonal pilot sequences, we are able to accommodate 200 devices with only a 12.5% omission rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03278v1</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Kamran Saeed, Ahmed E. Kamal, Ashfaq Khokhar</dc:creator>
    </item>
    <item>
      <title>Smart Pilot Assignment for IoT in Massive MIMO Systems: A Path Towards Scalable IoT Infrastructure</title>
      <link>https://arxiv.org/abs/2404.10188</link>
      <description>arXiv:2404.10188v1 Announce Type: cross 
Abstract: 5G sets the foundation for an era of creativity with its faster speeds, increased data throughput, reduced latency, and enhanced IoT connectivity, all enabled by Massive MIMO (M-MIMO) technology. M-MIMO boosts network efficiency and enhances user experience by employing intelligent user scheduling. This paper presents a user scheduling scheme and pilot assignment strategy designed for IoT devices, emphasizing mitigating pilot contamination, a key obstacle to improving spectral efficiency (SE) and system scalability in M-MIMO networks. We utilize a user clustering-based pilot allocation scheme to boost IoT device scalability in M-MIMO systems. Additionally, our smart pilot allocation minimizes interference and enhances SE by treating pilot assignment as a graph coloring problem, optimizing it through integer linear programming (ILP). Recognizing the computational complexity of ILP, we introduced a binary search-based heuristic predicated on interference threshold to expedite the computation, while maintaining a near-optimal solution. The simulation results show a significant decrease in the required pilot overhead (about 17%), and substantial enhancement in SE (about 8-14%).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10188v1</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Kamran Saeed, Ashfaq Khokhar</dc:creator>
    </item>
    <item>
      <title>Disentangling Exploration from Exploitation</title>
      <link>https://arxiv.org/abs/2404.19116</link>
      <description>arXiv:2404.19116v1 Announce Type: cross 
Abstract: Starting from Robbins (1952), the literature on experimentation via multi-armed bandits has wed exploration and exploitation. Nonetheless, in many applications, agents' exploration and exploitation need not be intertwined: a policymaker may assess new policies different than the status quo; an investor may evaluate projects outside her portfolio. We characterize the optimal experimentation policy when exploration and exploitation are disentangled in the case of Poisson bandits, allowing for general news structures. The optimal policy features complete learning asymptotically, exhibits lots of persistence, but cannot be identified by an index a la Gittins. Disentanglement is particularly valuable for intermediate parameter values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19116v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Lizzeri, Eran Shmaya, Leeat Yariv</dc:creator>
    </item>
    <item>
      <title>Bias Mitigation via Compensation: A Reinforcement Learning Perspective</title>
      <link>https://arxiv.org/abs/2404.19256</link>
      <description>arXiv:2404.19256v1 Announce Type: cross 
Abstract: As AI increasingly integrates with human decision-making, we must carefully consider interactions between the two. In particular, current approaches focus on optimizing individual agent actions but often overlook the nuances of collective intelligence. Group dynamics might require that one agent (e.g., the AI system) compensate for biases and errors in another agent (e.g., the human), but this compensation should be carefully developed. We provide a theoretical framework for algorithmic compensation that synthesizes game theory and reinforcement learning principles to demonstrate the natural emergence of deceptive outcomes from the continuous learning dynamics of agents. We provide simulation results involving Markov Decision Processes (MDP) learning to interact. This work then underpins our ethical analysis of the conditions in which AI agents should adapt to biases and behaviors of other agents in dynamic and complex decision-making environments. Overall, our approach addresses the nuanced role of strategic deception of humans, challenging previous assumptions about its detrimental effects. We assert that compensation for others' biases can enhance coordination and ethical alignment: strategic deception, when ethically managed, can positively shape human-AI interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19256v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nandhini Swaminathan, David Danks</dc:creator>
    </item>
    <item>
      <title>Counterbalancing Learning and Strategic Incentives in Allocation Markets</title>
      <link>https://arxiv.org/abs/2110.14865</link>
      <description>arXiv:2110.14865v2 Announce Type: replace 
Abstract: This paper considers the problem of offering a scarce object with a common unobserved quality to strategic agents in a priority queue. Each agent has a private signal over the quality of the object and observes the decisions made by other agents. We first show that, under the widely-used first-come-first-served sequential offering mechanism, herding behavior emerges: initial rejections create an information cascade resulting in inefficient waste. To address this issue, we then introduce a class of batching mechanisms. Agents in each batch report whether they would be willing to accept or reject the object based on their private signals and prior information. If the majority opts to accept, the object is randomly allocated within that batch. We prove that suitable batching mechanisms are incentive-compatible and improve efficiency. A key property of the mechanism is the gradual increase of the batch size after each failed allocation; the size is chosen so that it elicits as much information as possible without distorting the incentives of agents to report truthfully. Additionally, from a healthcare policy perspective, our results can shed light on the large wastage in organ allocation. In particular, wastage that arises due to herding may be reduced by applying adaptive simultaneous offering mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.14865v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Itai Ashlagi, Jamie Kang, Moran Koren, Faidra Monachou</dc:creator>
    </item>
    <item>
      <title>Existence of MMS Allocations with Mixed Manna</title>
      <link>https://arxiv.org/abs/2401.07490</link>
      <description>arXiv:2401.07490v2 Announce Type: replace 
Abstract: Maximin share (MMS) allocations are a popular relaxation of envy-free allocations that have received wide attention in the context of the fair division of indivisible items. Although MMS allocations can fail to exist [1], previous work has found conditions under which they exist. Specifically, MMS allocations exist whenever $m \leq n+5$ in the context of goods allocation, and this bound is tight in the sense that MMS allocations can fail to exist when $m = n+6$ [2]. Unfortunately, the technique used to establish this result does not generalize readily to the chores and mixed manna settings. This paper generalizes this result to the chores setting and provides a partial solution for the mixed manna setting. Our results depend on the presence of certain types of agents. Specifically, an agent $i$ is a goods agent (resp. chores agent) if every item is a good (resp. chore) to $i$, and a non-negative mixed agent if $i$ is neither a goods nor a chores agent and the MMS guarantee of $i$ is non-negative. In this paper, we prove that an MMS allocation exists if $m \leq n+5$ and there exists a goods agent, a non-negative mixed agent, or only chores agents.
  [1] David Kurokawa, Ariel D Procaccia, and Junxing Wang. When can the maximin share guarantee be guaranteed? In Thirtieth AAAI Conference on Artificial Intelligence, 2016.
  [2] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for mms fair allocations. In International Conference on Web and Internet Economics, pages 355-372. Springer, 2021.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07490v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Hsu</dc:creator>
    </item>
    <item>
      <title>am-AMM: An Auction-Managed Automated Market Maker</title>
      <link>https://arxiv.org/abs/2403.03367</link>
      <description>arXiv:2403.03367v2 Announce Type: replace-cross 
Abstract: Automated market makers (AMMs) have emerged as the dominant market mechanism for trading on decentralized exchanges implemented on blockchains. This paper presents a single mechanism that targets two important unsolved problems for AMMs: reducing losses to informed orderflow, and maximizing revenue from uninformed orderflow. The "auction-managed AMM" works by running a censorship-resistant onchain auction for the right to temporarily act as "pool manager" for a constant-product AMM. The pool manager sets the swap fee rate on the pool, and also receives the accrued fees from swaps. The pool manager can exclusively capture some arbitrage by trading against the pool in response to small price movements, and also can set swap fees incorporating price sensitivity of retail orderflow and adapting to changing market conditions, with the benefits from both ultimately accruing to liquidity providers. Liquidity providers can enter and exit the pool freely in response to changing rent, though they must pay a small fee on withdrawal. We prove that under certain assumptions, this AMM should have higher liquidity in equilibrium than any standard, fixed-fee AMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03367v2</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Austin Adams, Ciamac Moallemi, Sara Reynolds, Dan Robinson</dc:creator>
    </item>
    <item>
      <title>Proof-of-Learning with Incentive Security</title>
      <link>https://arxiv.org/abs/2404.09005</link>
      <description>arXiv:2404.09005v3 Announce Type: replace-cross 
Abstract: Most concurrent blockchain systems rely heavily on the Proof-of-Work (PoW) or Proof-of-Stake (PoS) mechanisms for decentralized consensus and security assurance. However, the substantial energy expenditure stemming from computationally intensive yet meaningless tasks has raised considerable concerns surrounding traditional PoW approaches, The PoS mechanism, while free of energy consumption, is subject to security and economic issues. Addressing these issues, the paradigm of Proof-of-Useful-Work (PoUW) seeks to employ challenges of practical significance as PoW, thereby imbuing energy consumption with tangible value. While previous efforts in Proof of Learning (PoL) explored the utilization of deep learning model training SGD tasks as PoUW challenges, recent research has revealed its vulnerabilities to adversarial attacks and the theoretical hardness in crafting a byzantine-secure PoL mechanism. In this paper, we introduce the concept of incentive-security that incentivizes rational provers to behave honestly for their best interest, bypassing the existing hardness to design a PoL mechanism with computational efficiency, a provable incentive-security guarantee and controllable difficulty. Particularly, our work is secure against two attacks to the recent work of Jia et al. [2021], and also improves the computational overhead from $\Theta(1)$ to $O(\frac{\log E}{E})$. Furthermore, while most recent research assumes trusted problem providers and verifiers, our design also guarantees frontend incentive-security even when problem providers are untrusted, and verifier incentive-security that bypasses the Verifier's Dilemma. By incorporating ML training into blockchain consensus mechanisms with provable guarantees, our research not only proposes an eco-friendly solution to blockchain systems, but also provides a proposal for a completely decentralized computing power market in the new AI age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09005v3</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zishuo Zhao, Zhixuan Fang, Xuechao Wang, Xi Chen, Yuan Zhou</dc:creator>
    </item>
  </channel>
</rss>
