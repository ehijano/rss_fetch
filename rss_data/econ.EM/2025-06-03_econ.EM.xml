<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 02:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Residual Income Valuation and Stock Returns: Evidence from a Value-to-Price Investment Strategy</title>
      <link>https://arxiv.org/abs/2506.00206</link>
      <description>arXiv:2506.00206v1 Announce Type: new 
Abstract: We hypothesize that portfolio sorts based on the V/P ratio generate excess returns and consist of companies that are undervalued for prolonged periods. Results, for the US market show that high V/P portfolios outperform low V/P portfolios across horizons extending from one to three years. The V/P ratio is positively correlated to future stock returns after controlling for firm characteristics, which are well known risk proxies. Findings also indicate that profitability and investment add explanatory power to the Fama and French three factor model and for stocks with V/P ratio close to 1. However, these factors cannot explain all variation in excess returns especially for years two and three and for stocks with high V/P ratio. Finally, portfolios with the highest V/P stocks select companies that are significantly mispriced relative to their equity (investment) and profitability growth persistence in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00206v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Haboub, Aris Kartsaklas, Vasilis Sarafidis</dc:creator>
    </item>
    <item>
      <title>Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks</title>
      <link>https://arxiv.org/abs/2506.00856</link>
      <description>arXiv:2506.00856v1 Announce Type: new 
Abstract: Can AI effectively perform complex econometric analysis traditionally requiring human expertise? This paper evaluates an agentic AI's capability to master econometrics, focusing on empirical analysis performance. We develop an ``Econometrics AI Agent'' built on the open-source MetaGPT framework. This agent exhibits outstanding performance in: (1) planning econometric tasks strategically, (2) generating and executing code, (3) employing error-based reflection for improved robustness, and (4) allowing iterative refinement through multi-round conversations. We construct two datasets from academic coursework materials and published research papers to evaluate performance against real-world challenges. Comparative testing shows our domain-specialized agent significantly outperforms both benchmark large language models (LLMs) and general-purpose AI agents. This work establishes a testbed for exploring AI's impact on social science research and enables cost-effective integration of domain expertise, making advanced econometric methods accessible to users with minimal coding expertise. Furthermore, our agent enhances research reproducibility and offers promising pedagogical applications for econometrics teaching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00856v1</guid>
      <category>econ.EM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiang Chen, Tianyang Han, Jin Li, Ye Luo, Yuxiao Wu, Xiaowei Zhang, Tuo Zhou</dc:creator>
    </item>
    <item>
      <title>Large Bayesian VARs for Binary and Censored Variables</title>
      <link>https://arxiv.org/abs/2506.01422</link>
      <description>arXiv:2506.01422v1 Announce Type: new 
Abstract: We extend the standard VAR to jointly model the dynamics of binary, censored and continuous variables, and develop an efficient estimation approach that scales well to high-dimensional settings. In an out-of-sample forecasting exercise, we show that the proposed VARs forecast recessions and short-term interest rates well. We demonstrate the utility of the proposed framework using a wide rage of empirical applications, including conditional forecasting and a structural analysis that examines the dynamic effects of a financial shock on recession probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01422v1</guid>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua C. C. Chan, Michael Pfarrhofer</dc:creator>
    </item>
    <item>
      <title>Life Sequence Transformer: Generative Modelling for Counterfactual Simulation</title>
      <link>https://arxiv.org/abs/2506.01874</link>
      <description>arXiv:2506.01874v1 Announce Type: new 
Abstract: Social sciences rely on counterfactual analysis using surveys and administrative data, generally depending on strong assumptions or the existence of suitable control groups, to evaluate policy interventions and estimate causal effects. We propose a novel approach that leverages the Transformer architecture to simulate counterfactual life trajectories from large-scale administrative records. Our contributions are: the design of a novel encoding method that transforms longitudinal administrative data to sequences and the proposal of a generative model tailored to life sequences with overlapping events across life domains. We test our method using data from the Istituto Nazionale di Previdenza Sociale (INPS), showing that it enables the realistic and coherent generation of life trajectories. This framework offers a scalable alternative to classical counterfactual identification strategy, such as difference-in-differences and synthetic controls, particularly in contexts where these methods are infeasible or their assumptions unverifiable. We validate the model's utility by comparing generated life trajectories against established findings from causal studies, demonstrating its potential to enrich labour market research and policy evaluation through individual-level simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01874v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Cabezas, Carlotta Montorsi</dc:creator>
    </item>
    <item>
      <title>Stock Market Telepathy: Graph Neural Networks Predicting the Secret Conversations between MINT and G7 Countries</title>
      <link>https://arxiv.org/abs/2506.01945</link>
      <description>arXiv:2506.01945v1 Announce Type: new 
Abstract: Emerging economies, particularly the MINT countries (Mexico, Indonesia, Nigeria, and T\"urkiye), are gaining influence in global stock markets, although they remain susceptible to the economic conditions of developed countries like the G7 (Canada, France, Germany, Italy, Japan, the United Kingdom, and the United States). This interconnectedness and sensitivity of financial markets make understanding these relationships crucial for investors and policymakers to predict stock price movements accurately. To this end, we examined the main stock market indices of G7 and MINT countries from 2012 to 2024, using a recent graph neural network (GNN) algorithm called multivariate time series forecasting with graph neural network (MTGNN). This method allows for considering complex spatio-temporal connections in multivariate time series. In the implementations, MTGNN revealed that the US and Canada are the most influential G7 countries regarding stock indices in the forecasting process, and Indonesia and T\"urkiye are the most influential MINT countries. Additionally, our results showed that MTGNN outperformed traditional methods in forecasting the prices of stock market indices for MINT and G7 countries. Consequently, the study offers valuable insights into economic blocks' markets and presents a compelling empirical approach to analyzing global stock market dynamics using MTGNN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01945v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nurbanu Bursa</dc:creator>
    </item>
    <item>
      <title>Aligning Language Models with Observational Data: Opportunities and Risks from a Causal Perspective</title>
      <link>https://arxiv.org/abs/2506.00152</link>
      <description>arXiv:2506.00152v1 Announce Type: cross 
Abstract: Large language models are being widely used across industries to generate content that contributes directly to key performance metrics, such as conversion rates. Pretrained models, however, often fall short when it comes to aligning with human preferences or optimizing for business objectives. As a result, fine-tuning with good-quality labeled data is essential to guide models to generate content that achieves better results. Controlled experiments, like A/B tests, can provide such data, but they are often expensive and come with significant engineering and logistical challenges. Meanwhile, companies have access to a vast amount of historical (observational) data that remains underutilized. In this work, we study the challenges and opportunities of fine-tuning LLMs using observational data. We show that while observational outcomes can provide valuable supervision, directly fine-tuning models on such data can lead them to learn spurious correlations. We present empirical evidence of this issue using various real-world datasets and propose DeconfoundLM, a method that explicitly removes the effect of known confounders from reward signals. Using simulation experiments, we demonstrate that DeconfoundLM improves the recovery of causal relationships and mitigates failure modes found in fine-tuning methods that ignore or naively incorporate confounding variables. Our findings highlight that while observational data presents risks, with the right causal corrections, it can be a powerful source of signal for LLM alignment. Please refer to the project page for code and related resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00152v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Erfan Loghmani</dc:creator>
    </item>
    <item>
      <title>Learning from Double Positive and Unlabeled Data for Potential-Customer Identification</title>
      <link>https://arxiv.org/abs/2506.00436</link>
      <description>arXiv:2506.00436v1 Announce Type: cross 
Abstract: In this study, we propose a method for identifying potential customers in targeted marketing by applying learning from positive and unlabeled data (PU learning). We consider a scenario in which a company sells a product and can observe only the customers who purchased it. Decision-makers seek to market products effectively based on whether people have loyalty to the company. Individuals with loyalty are those who are likely to remain interested in the company even without additional advertising. Consequently, those loyal customers would likely purchase from the company if they are interested in the product. In contrast, people with lower loyalty may overlook the product or buy similar products from other companies unless they receive marketing attention. Therefore, by focusing marketing efforts on individuals who are interested in the product but do not have strong loyalty, we can achieve more efficient marketing. To achieve this goal, we consider how to learn, from limited data, a classifier that identifies potential customers who (i) have interest in the product and (ii) do not have loyalty to the company. Although our algorithm comprises a single-stage optimization, its objective function implicitly contains two losses derived from standard PU learning settings. For this reason, we refer to our approach as double PU learning. We verify the validity of the proposed algorithm through numerical experiments, confirming that it functions appropriately for the problem at hand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00436v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato, Yuki Ikeda abd Kentaro Baba, Takashi Imai, Ryo Inokuchi</dc:creator>
    </item>
    <item>
      <title>Spillovers and Effect Attenuation in Firearm Policy Research in the United States</title>
      <link>https://arxiv.org/abs/2506.01695</link>
      <description>arXiv:2506.01695v1 Announce Type: cross 
Abstract: In the United States, firearm-related deaths and injuries are a major public health issue. Because of limited federal action, state policies are particularly important, and their evaluation informs the actions of other policymakers. The movement of firearms across state and local borders, however, can undermine the effectiveness of these policies and have statistical consequences for their empirical evaluation. This movement causes spillover and bypass effects of policies, wherein interventions affect nearby control states and the lack of intervention in nearby states reduces the effectiveness in the intervention states. While some causal inference methods exist to account for spillover effects and reduce bias, these do not necessarily align well with the data available for firearm research or with the most policy-relevant estimands. Integrated data infrastructure and new methods are necessary for a better understanding of the effects these policies would have if widely adopted. In the meantime, appropriately understanding and interpreting effect estimates from quasi-experimental analyses is crucial for ensuring that effective policies are not dismissed due to these statistical challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01695v1</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lee Kennedy-Shaffer, Alan Hamilton Kennedy</dc:creator>
    </item>
    <item>
      <title>Two-Step Estimation of a Strategic Network Formation Model with Clustering</title>
      <link>https://arxiv.org/abs/2001.03838</link>
      <description>arXiv:2001.03838v4 Announce Type: replace 
Abstract: This paper explores strategic network formation under incomplete information using data from a single large network. We allow the utility function to be nonseparable in an individual's link choices to capture the spillover effects from friends in common. In a network with n individuals, an individual with a nonseparable utility function chooses between 2^{n-1} overlapping portfolios of links. We develop a novel approach that applies the Legendre transform to the utility function so that the optimal link choices can be represented as a sequence of correlated binary choices. The link dependence that results from the preference for friends in common is captured by an auxiliary variable introduced by the Legendre transform. We propose a two-step estimator that is consistent and asymptotically normal. We also derive a limiting approximation of the game as n grows large that simplifies the computation in large networks. We apply these methods to favor exchange networks in rural India and find that the direction of support from a mutual link matters in facilitating favor provision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.03838v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geert Ridder, Shuyang Sheng</dc:creator>
    </item>
    <item>
      <title>Inference on Extreme Quantiles of Unobserved Individual Heterogeneity</title>
      <link>https://arxiv.org/abs/2210.08524</link>
      <description>arXiv:2210.08524v4 Announce Type: replace 
Abstract: We develop a methodology for conducting inference on extreme quantiles of unobserved individual heterogeneity (e.g., heterogeneous coefficients, treatment effects) in panel data and meta-analysis settings. Inference is challenging in such settings: only noisy estimates of heterogeneity are available, and central limit approximations perform poorly in the tails. We derive a necessary and sufficient condition under which noisy estimates are informative about extreme quantiles, along with sufficient rate and moment conditions. Under these conditions, we establish an extreme value theorem and an intermediate order theorem for noisy estimates. These results yield simple optimization-free confidence intervals for extreme quantiles. Simulations show that our confidence intervals have favorable coverage and that the rate conditions matter for the validity of inference. We illustrate the method with an application to firm productivity differences between denser and less dense areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08524v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladislav Morozov</dc:creator>
    </item>
    <item>
      <title>Model-Adaptive Approach to Dynamic Discrete Choice Models with Large State Spaces</title>
      <link>https://arxiv.org/abs/2501.18746</link>
      <description>arXiv:2501.18746v2 Announce Type: replace 
Abstract: Estimation and counterfactual experiments in dynamic discrete choice models with large state spaces pose computational difficulties. This paper develops a novel model-adaptive approach to solve the linear system of fixed point equations of the policy valuation operator. We propose a model-adaptive sieve space, constructed by iteratively augmenting the space with the residual from the previous iteration. We show both theoretically and numerically that model-adaptive sieves dramatically improve performance. In particular, the approximation error decays at a superlinear rate in the sieve dimension, unlike a linear rate achieved using conventional methods. Our method works for both conditional choice probability estimators and full-solution estimators with policy iteration. We apply the method to analyze consumer demand for laundry detergent using Kantar's Worldpanel Take Home data. On average, our method is 51.5% faster than conventional methods in solving the dynamic programming problem, making the Bayesian MCMC estimator computationally feasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18746v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ertian Chen</dc:creator>
    </item>
    <item>
      <title>Causal Inference for Experiments with Latent Outcomes: Key Results and Their Implications for Design and Analysis</title>
      <link>https://arxiv.org/abs/2505.21909</link>
      <description>arXiv:2505.21909v2 Announce Type: replace 
Abstract: How should researchers analyze randomized experiments in which the main outcome is measured in multiple ways but each measure contains some degree of error? We describe modeling approaches that enable researchers to identify causal parameters of interest, suggest ways that experimental designs can be augmented so as to make linear latent variable models more credible, and discuss empirical tests of key modeling assumptions. We show that when experimental researchers invest appropriately in multiple outcome measures, an optimally weighted index of the outcome measures enables researchers to obtain efficient and interpretable estimates of causal parameters by applying standard regression methods, and that weights may be obtained using instrumental variables regression. Maximum likelihood and generalized method of moments estimators can be used to obtain estimates and standard errors in a single step. An empirical application illustrates the gains in precision and robustness that multiple outcome measures can provide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21909v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Fu, Donald P. Green</dc:creator>
    </item>
    <item>
      <title>A Gibbs Sampler for Efficient Bayesian Inference in Sign-Identified SVARs</title>
      <link>https://arxiv.org/abs/2505.23542</link>
      <description>arXiv:2505.23542v2 Announce Type: replace 
Abstract: We develop a new algorithm for inference based on structural vector autoregressions (SVARs) identified with sign restrictions. The key insight of our algorithm is to break apart from the accept-reject tradition associated with sign-identified SVARs. We show that embedding an elliptical slice sampling within a Gibbs sampler approach can deliver dramatic gains in speed and turn previously infeasible applications into feasible ones. We provide a tractable example to illustrate the power of the elliptical slice sampling applied to sign-identified SVARs. We demonstrate the usefulness of our algorithm by applying it to a well-known small-SVAR model of the oil market featuring a tight identified set, as well as to a large SVAR model with more than 100 sign restrictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23542v2</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas E. Arias, Juan F. Rubio-Ram\'irez, Minchul Shin</dc:creator>
    </item>
    <item>
      <title>Load Asymptotics and Dynamic Speed Optimization for the Greenest Path Problem: A Comprehensive Analysis</title>
      <link>https://arxiv.org/abs/2306.01687</link>
      <description>arXiv:2306.01687v2 Announce Type: replace-cross 
Abstract: We study the effect of using high-resolution elevation data on the selection of the most fuel-efficient(greenest) path for different trucks in various urban environments.We adapt a variant of the Comprehensive Modal Emission Model(CMEM) to show that the optimal speed and the greenest path are slope dependent (dynamic).When there are no elevation changes in a road network, the most fuel-efficient path is the shortest path with a constant (static) optimal speed throughout.However, if the network is not flat, then the shortest path is not necessarily the greenest path, and the optimal driving speed is dynamic.We prove that the greenest path converges to an asymptotic greenest path as the payload approaches infinity and that this limiting path is attained for a finite load.In a set of extensive numerical experiments, we benchmark the CO2emissions reduction of our dynamic speed and the greenest path policies against policies that ignore elevation data.We use the geospatial data of 25major cities across 6continents.We observe numerically that the greenest path quickly diverges from the shortest path and attains the asymptotic greenest path even for moderate payloads.Based on an analysis of variance, the main determinants of the CO2emissions reduction potential are the variation of the road gradients along the shortest path as well as the relative elevation of the source from the target.Using speed data estimates for rush hour in New York City, we test CO2emissions reduction by comparing the greenest paths with optimized speeds against the fastest paths with traffic speed.We observe that selecting the greenest paths instead of the fastest paths can significantly reduce CO2emissions.Additionally,our results show that while speed optimization on uphill arcs can significantly help CO2reduction,the potential to leverage gravity for acceleration on downhill arcs is limited due to traffic congestion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01687v2</guid>
      <category>math.OC</category>
      <category>econ.EM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00291-024-00793-9</arxiv:DOI>
      <dc:creator>Poulad Moradi, Joachim Arts, Josu\'e C. Vel\'azquez-Mart\'inez</dc:creator>
    </item>
  </channel>
</rss>
