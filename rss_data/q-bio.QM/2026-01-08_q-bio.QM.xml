<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Comprehensive Database of Leaf Temperature, Water, and CO 2 Fluxes in Young Oil Palm Plants Across Diverse Climate Scenarios</title>
      <link>https://arxiv.org/abs/2601.03308</link>
      <description>arXiv:2601.03308v1 Announce Type: new 
Abstract: Functional-structural plant models (FSPM) replicate plants' responses to their environment and are useful for predicting behavior in a changing climate. However, they rely on detailed measurements of traits, which are difficult to collect consistently across scales, often limiting model parameterization and thorough evaluation, and thereby reducing confidence in model predictions. Here, we provided a comprehensive dataset of structural and biophysical measurements from four oil palm plants (Elaeis guinnensis) grown under multiple controlled environmental scenarios, including varying CO2 concentrations, light, temperature and humidity conditions. The dataset included detailed reconstructions of the three-dimensional plant structures derived from terrestrial LiDAR point clouds, and enabled the parametrization of biophysical processes at the leaf scale such as photosynthesis and stomatal conductance, as well as the collection of plant-scale measurements (gas exchange measurements of CO2 and H20), which can be compared with FSPM simulations. The tree-dimensional reconstructions effectively represented the architecture of the plants and showed strong correlation with the measured total leaf area. Hence, future comparisons between simulated and observed physiological traits could be used to evaluate the quality of the physiological formalisms independently. By bridging the scales from individual leaves to the entire plant, this database allows modellers to both calibrate their biophysical models at a fine spatial resolution and evaluate their predictive accuracy at the plant scale. The provided data will facilitate benchmarking of biophysical models, help identify sources of model uncertainty, and ultimately enhance model predictions, which can be applied in various fields, from cognitive studies to decision support applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03308v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raphael Perez (UMR AGAP, Cirad-BIOS), Valentin Torrelli (UMR AGAP, UMR AMAP, Cirad-BIOS), Sandrine Roques (UMR AGAP, Cirad-BIOS), S\'ebastien Devidal (UMR AMAP, Cirad-BIOS), Cl\'ement Piel (UMR AMAP, Cirad-BIOS), Damien Landais (UMR AMAP, Cirad-BIOS), Merlin Ramel (UMR AMAP, Cirad-BIOS), Thomas Arsouze (UMR AMAP, Cirad-BIOS), Julien Lamour (CRBE), Jean-Pierre Caliman (SMARTRI), R\'emi Vezy (UMR AMAP, Cirad-BIOS)</dc:creator>
    </item>
    <item>
      <title>Progressive Bayesian Confidence Architectures for Cold-Start Personal Health Analytics: Formalizing Early Insight Through Posterior Contraction and Risk-Aware Interpretation</title>
      <link>https://arxiv.org/abs/2601.03299</link>
      <description>arXiv:2601.03299v1 Announce Type: cross 
Abstract: Personal health analytics systems face a persistent cold-start dilemma: users expect meaningful insights early in data collection, while conventional statistical inference requires data volumes that often exceed engagement horizons. Existing approaches either delay inference until fixed statistical thresholds are met -- leading to user disengagement -- or surface heuristic insights without formal uncertainty quantification, risking false confidence. We propose a progressive Bayesian confidence architecture that formalizes early-stage inference through phased interpretation of posterior uncertainty. Drawing on Bayesian updating and epistemic strategies from financial risk modeling under sparse observations, we map posterior contraction to interpretable tiers of insight, ranging from exploratory directional evidence to robust associative inference. We demonstrate the framework's performance through controlled experimentation with synthetic N-of-1 health data, showing that calibrated early insights can be generated within 5--7 days while maintaining explicit epistemic humility. Compared to fixed-threshold baselines requiring 30+ days of data, the proposed approach yields earlier directional signals (mean: 5.3 vs 31.7 days, p&lt;0.001) while controlling false discovery rates below 6% (5.9% at day 30) despite 26-day earlier detection, compared to 0% FDR for fixed-threshold baselines that delay insights by 30 days. In addition, we show strong uncertainty calibration (76% credible interval coverage for ground-truth correlations at day 90). This work contributes a methodological framework for uncertainty-aware early inference in personalized health analytics that bridges the gap between user engagement requirements and statistical rigor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03299v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.TH</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richik Chakraborty</dc:creator>
    </item>
    <item>
      <title>Investigating Knowledge Distillation Through Neural Networks for Protein Binding Affinity Prediction</title>
      <link>https://arxiv.org/abs/2601.03704</link>
      <description>arXiv:2601.03704v1 Announce Type: cross 
Abstract: The trade-off between predictive accuracy and data availability makes it difficult to predict protein--protein binding affinity accurately. The lack of experimentally resolved protein structures limits the performance of structure-based machine learning models, which generally outperform sequence-based methods. In order to overcome this constraint, we suggest a regression framework based on knowledge distillation that uses protein structural data during training and only needs sequence data during inference. The suggested method uses binding affinity labels and intermediate feature representations to jointly supervise the training of a sequence-based student network under the guidance of a structure-informed teacher network. Leave-One-Complex-Out (LOCO) cross-validation was used to assess the framework on a non-redundant protein--protein binding affinity benchmark dataset. A maximum Pearson correlation coefficient (P_r) of 0.375 and an RMSE of 2.712 kcal/mol were obtained by sequence-only baseline models, whereas a P_r of 0.512 and an RMSE of 2.445 kcal/mol were obtained by structure-based models. With a P_r of 0.481 and an RMSE of 2.488 kcal/mol, the distillation-based student model greatly enhanced sequence-only performance. Improved agreement and decreased bias were further confirmed by thorough error analyses. With the potential to close the performance gap between sequence-based and structure-based models as larger datasets become available, these findings show that knowledge distillation is an efficient method for transferring structural knowledge to sequence-based predictors. The source code for running inference with the proposed distillation-based binding affinity predictor can be accessed at https://github.com/wajidarshad/ProteinAffinityKD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03704v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wajid Arshad Abbasi, Syed Ali Abbas, Maryum Bibi, Saiqa Andleeb, Muhammad Naveed Akhtar</dc:creator>
    </item>
    <item>
      <title>Minimal branching and fusion morphogenesis approaches biological multi-objective optimality</title>
      <link>https://arxiv.org/abs/2601.03877</link>
      <description>arXiv:2601.03877v1 Announce Type: cross 
Abstract: Many biological networks grow by elongation of filaments that can branch and fuse -- typical examples include fungal mycelium or slime mold. These networks must simultaneously perform multiple tasks such as transport, exploration, and robustness under finite resources. Yet, how such multi-task architectures emerge from local growth processes remains poorly understood. Here, we introduce a minimal model of spatial network morphogenesis based solely on stochastic branching, fusion, and stopping, during elongation. Despite the absence of global optimization or feedback, the model generates a broad morphospace from tree-like, to loopy, as well as hybrid architectures. By quantifying multiple functional objectives, we show that (i) these synthetic structures occupy similar regions of performance space than evolved empirical fungal networks, and (ii) that their Pareto front of optimal trade-offs lies close to that of these same fungal networks. Our results show that biological architectures approaching multi-objective optimality can arise from simple local growth rules, and identify branching and fusion as fundamental ingredients shaping the architecture of living transport networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03877v1</guid>
      <category>nlin.AO</category>
      <category>physics.soc-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxime Lucas, Corentin Bisot, Giovanni Petri, St\'ephane Declerck, Timoteo Carletti</dc:creator>
    </item>
    <item>
      <title>$\textit{sentropy}$: A Python Package for Revealing Hidden Differences in Complex Datasets</title>
      <link>https://arxiv.org/abs/2401.00102</link>
      <description>arXiv:2401.00102v2 Announce Type: replace 
Abstract: Machine-learning datasets are typically characterized by measuring their size and class balance. However, there exists a richer and potentially more useful set of measures, termed S-entropy (similarity-sensitive entropy), that incorporate elements' frequencies and between-element similarities. Although these have been available in the R and Julia programming languages for other applications, they have not been as readily available in Python, which is widely used for machine learning, and are not easily applied to machine-learning-sized datasets without special coding considerations. To address these issues, we developed $\textit{sentropy}$, a Python package that calculates S-entropy and is tailored to large datasets. $\textit{sentropy}$ can calculate any of the frequency-sensitive measures of Hill's D-number framework and their similarity-sensitive counterparts. $\textit{sentropy}$ also outputs measures that compare datasets. We first briefly review S-entropy, illustrating how it incorporates elements' frequencies and elements' pairwise similarities. We then describe $\textit{sentropy}$'s key features and usage. We end with several examples - immunomics, metagenomics, computational pathology, and medical imaging - illustrating $\textit{sentropy}$'s applicability across a range of dataset types and fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00102v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Phuc Nguyen, Rohit Arora, Elliot D. Hill, Jasper Braun, Alexandra Morgan, Liza M. Quintana, Gabrielle Mazzoni, Ghee Rye Lee, Rima Arnaout, Ramy Arnaout</dc:creator>
    </item>
  </channel>
</rss>
