<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.ST</link>
    <description>q-fin.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 02:55:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Extremity Premium: Sentiment Regimes and Adverse Selection in Cryptocurrency Markets</title>
      <link>https://arxiv.org/abs/2602.07018</link>
      <description>arXiv:2602.07018v1 Announce Type: new 
Abstract: Using the Crypto Fear &amp; Greed Index and Bitcoin daily data, we document that sentiment extremity predicts excess uncertainty beyond realized volatility. Extreme fear and extreme greed regimes exhibit significantly higher spreads than neutral periods -- a phenomenon we term the "extremity premium." Extended validation on the full Fear &amp; Greed history (February 2018--January 2026, N = 2,896) confirms the finding: within-volatility-quintile comparisons show a significant premium (p &lt; 0.001, Cohen's d = 0.21), Granger causality from uncertainty to spreads is strong (F = 211), and placebo tests reject the null (p &lt; 0.0001). The effect replicates on Ethereum and across 6 of 7 market cycles. However, the premium is sensitive to functional form: comprehensive regression controls absorb regime effects, while nonparametric stratification preserves them. We interpret this as evidence that sentiment extremity captures volatility-regime interactions not fully represented by parametric controls -- consistent with, but not conclusively separable from, the F&amp;G Index's embedded volatility component. An agent-based model reproduces the pattern qualitatively. The results suggest that intensity, not direction, drives uncertainty-linked liquidity withdrawal in cryptocurrency markets, though identification of "pure" sentiment effects from volatility remains an open challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07018v1</guid>
      <category>q-fin.ST</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murad Farzulla</dc:creator>
    </item>
    <item>
      <title>Financial Bond Similarity Search Using Representation Learning</title>
      <link>https://arxiv.org/abs/2602.07020</link>
      <description>arXiv:2602.07020v1 Announce Type: new 
Abstract: Finding similar bonds remains challenging in fixed-income analytics, as numerical financial attributes often overshadow categorical non-financial ones such as issuer sector and domicile. This paper shows that these categorical attributes dominate the predictability of spread curves and proposes embedding models to capture their semantic similarities, outperforming one-hot and many other baselines. Evaluated via sparse-issuer augmentation, the approach improves risk modeling and curve construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07020v1</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amin Haeri, Mahdi Ghelichi, Nishant Agrawal, David Li, Catalina Gomez Sanchez</dc:creator>
    </item>
    <item>
      <title>Sentiment Without Structure: Differential Market Responses to Infrastructure vs Regulatory Events in Cryptocurrency Markets</title>
      <link>https://arxiv.org/abs/2602.07046</link>
      <description>arXiv:2602.07046v1 Announce Type: new 
Abstract: We investigate differential market responses to infrastructure versus regulatory events in cryptocurrency markets using event study methodology with 4-category event classification. From 50 candidate events (2019-2025), 31 meet our impact and estimation-data criteria across 4 cryptocurrencies: Bitcoin (BTC), Ethereum (ETH), Solana (SOL), and Cardano (ADA). We employ constant mean and market-adjusted models with event-level block bootstrap confidence intervals (CIs) that properly account for cross-sectional correlation.
  Our primary comparison focuses on negative-valence events: infrastructure failures (10 events identified; 8 with sufficient estimation data for analysis) versus regulatory enforcement (7 events). We find infrastructure failures produce mean Cumulative Abnormal Return (CAR) of -7.6% (bootstrap 95% CI: [-25.8%, +11.3%]) and regulatory enforcement produces mean CAR of -11.1% (CI: [-31.0%, +10.7%]). The difference in mean CARs of +3.6 percentage points (pp) has CI [-25.3%, +30.9%], p = 0.81. This is a null finding: markets respond similarly to both shock types when controlling for event valence.
  Robustness checks confirm: (1) consistent negative sign across all window specifications ([0, +1] to [-5, +30]), (2) results survive leave-one-out exclusion of FTX and Terra, (3) market model with BTC/equal-weighted (EW) proxy attenuates but does not flip results. The 4-category classification addresses prior conflation of upgrades with failures.
  Interpretation note: This exploratory analysis should be treated as hypothesis-generating; any post-hoc theoretical framing requires prospective testing with larger samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07046v1</guid>
      <category>q-fin.ST</category>
      <category>q-fin.CP</category>
      <category>stat.AP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murad Farzulla</dc:creator>
    </item>
    <item>
      <title>QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining</title>
      <link>https://arxiv.org/abs/2602.07085</link>
      <description>arXiv:2602.07085v1 Announce Type: new 
Abstract: Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard &amp; Poor's 500 Index (S&amp;P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07085v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Han, Shuo Zhang, Wei Li, Zhi Yang, Yifan Dong, Tu Hu, Jialuo Yuan, Xiaomin Yu, Yumo Zhu, Fangqi Lou, Xin Guo, Zhaowei Liu, Tianyi Jiang, Ruichuan An, Jingping Liu, Biao Wu, Rongze Chen, Kunyi Wang, Yifan Wang, Sen Hu, Xinbing Kong, Liwen Zhang, Ronghao Chen, Huacan Wang</dc:creator>
    </item>
    <item>
      <title>RealFin: How Well Do LLMs Reason About Finance When Users Leave Things Unsaid?</title>
      <link>https://arxiv.org/abs/2602.07096</link>
      <description>arXiv:2602.07096v1 Announce Type: new 
Abstract: Reliable financial reasoning requires knowing not only how to answer, but also when an answer cannot be justified. In real financial practice, problems often rely on implicit assumptions that are taken for granted rather than stated explicitly, causing problems to appear solvable while lacking enough information for a definite answer. We introduce REALFIN, a bilingual benchmark that evaluates financial reasoning by systematically removing essential premises from exam-style questions while keeping them linguistically plausible. Based on this, we evaluate models under three formulations that test answering, recognizing missing information, and rejecting unjustified options, and find consistent performance drops when key conditions are absent. General-purpose models tend to over-commit and guess, while most finance-specialized models fail to clearly identify missing premises. These results highlight a critical gap in current evaluations and show that reliable financial models must know when a question should not be answered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07096v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yuyang Dai, Yan Lin, Zhuohan Xie, Yuxia Wang</dc:creator>
    </item>
    <item>
      <title>LLM as a Risk Manager: LLM Semantic Filtering for Lead-Lag Trading in Prediction Markets</title>
      <link>https://arxiv.org/abs/2602.07048</link>
      <description>arXiv:2602.07048v1 Announce Type: cross 
Abstract: Prediction markets provide a unique setting where event-level time series are directly tied to natural-language descriptions, yet discovering robust lead-lag relationships remains challenging due to spurious statistical correlations. We propose a hybrid two-stage causal screener to address this challenge: (i) a statistical stage that uses Granger causality to identify candidate leader-follower pairs from market-implied probability time series, and (ii) an LLM-based semantic stage that re-ranks these candidates by assessing whether the proposed direction admits a plausible economic transmission mechanism based on event descriptions. Because causal ground truth is unobserved, we evaluate the ranked pairs using a fixed, signal-triggered trading protocol that maps relationship quality into realized profit and loss (PnL). On Kalshi Economics markets, our hybrid approach consistently outperforms the statistical baseline. Across rolling evaluations, the win rate increases from 51.4% to 54.5%. Crucially, the average magnitude of losing trades decreases substantially from 649 USD to 347 USD. This reduction is driven by the LLM's ability to filter out statistically fragile links that are prone to large losses, rather than relying on rare gains. These improvements remain stable across different trading configurations, indicating that the gains are not driven by specific parameter choices. Overall, the results suggest that LLMs function as semantic risk managers on top of statistical discovery, prioritizing lead-lag relationships that generalize under changing market conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07048v1</guid>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumin Kim, Minjae Kim, Jihoon Kwon, Yoon Kim, Nicole Kagan, Joo Won Lee, Oscar Levy, Alejandro Lopez-Lira, Yongjae Lee, Chanyeol Choi</dc:creator>
    </item>
    <item>
      <title>Algorithmic Monitoring: Measuring Market Stress with Machine Learning</title>
      <link>https://arxiv.org/abs/2602.07066</link>
      <description>arXiv:2602.07066v1 Announce Type: cross 
Abstract: I construct a Market Stress Probability Index (MSPI) that estimates the probability of high stress in the U.S. equity market one month ahead using information from the cross-section of individual stocks. Using CRSP daily data, each month is summarized by a set of interpretable cross-sectional fragility signals and mapped into a forward-looking stress probability via an L1-regularized logistic regression in a real-time expanding-window design. Out of sample, MSPI tracks major stress episodes and improves discrimination and accuracy relative to a parsimonious benchmark based on lagged market return and realized volatility, delivering calibrated stress probabilities on an economically meaningful scale. Further, I illustrate how MSPI can be used as a probability-based measurement object in financial econometrics. The resulting index provides a transparent and easily updated measure of near-term equity-market stress risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07066v1</guid>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Schmitt</dc:creator>
    </item>
    <item>
      <title>Continuous Program Search</title>
      <link>https://arxiv.org/abs/2602.07659</link>
      <description>arXiv:2602.07659v1 Announce Type: cross 
Abstract: Genetic Programming yields interpretable programs, but small syntactic mutations can induce large, unpredictable behavioral shifts, degrading locality and sample efficiency. We frame this as an operator-design problem: learn a continuous program space where latent distance has behavioral meaning, then design mutation operators that exploit this structure without changing the evolutionary optimizer.
  We make locality measurable by tracking action-level divergence under controlled latent perturbations, identifying an empirical trust region for behavior-local continuous variation. Using a compact trading-strategy DSL with four semantic components (long/short entry and exit), we learn a matching block-factorized embedding and compare isotropic Gaussian mutation over the full latent space to geometry-compiled mutation that restricts updates to semantically paired entry--exit subspaces and proposes directions using a learned flow-based model trained on logged mutation outcomes.
  Under identical $(\mu+\lambda)$ evolution strategies and fixed evaluation budgets across five assets, the learned mutation operator discovers strong strategies using an order of magnitude fewer evaluations and achieves the highest median out-of-sample Sharpe ratio. Although isotropic mutation occasionally attains higher peak performance, geometry-compiled mutation yields faster, more reliable progress, demonstrating that semantically aligned mutation can substantially improve search efficiency without modifying the underlying evolutionary algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07659v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.6169788</arxiv:DOI>
      <dc:creator>Matthew Siper, Muhammad Umair Nasir, Ahmed Khalifa, Lisa Soros, Jay Azhang, Julian Togelius</dc:creator>
    </item>
    <item>
      <title>A Quadratic Link between Out-of-Sample $R^2$ and Directional Accuracy</title>
      <link>https://arxiv.org/abs/2602.07841</link>
      <description>arXiv:2602.07841v1 Announce Type: cross 
Abstract: This study provides a novel perspective on the metric disconnect phenomenon in financial time series forecasting through an analytical link that reconciles the out-of-sample $R^2$ ($R^2_{OOS}$) and directional accuracy (DA). In particular, using the random walk model as a baseline and assuming that sign correctness is independent of realized magnitude, we show that these two metrics exhibit a quadratic relationship for MSE-optimal point forecasts. For point forecasts with modest DA, the theoretical value of $R^2_{OOS}$ is intrinsically negligible. Thus, a negative empirical $R^2_{OOS}$ is expected if the model is suboptimal or affected by finite sample noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07841v1</guid>
      <category>econ.EM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cheng Zhang</dc:creator>
    </item>
    <item>
      <title>Nansde-net: A neural sde framework for generating time series with memory</title>
      <link>https://arxiv.org/abs/2602.08182</link>
      <description>arXiv:2602.08182v1 Announce Type: cross 
Abstract: Modeling time series with long- or short-memory characteristics is a fundamental challenge in many scientific and engineering domains. While fractional Brownian motion has been widely used as a noise source to capture such memory effects, its incompatibility with It\^o calculus limits its applicability in neural stochastic differential equation~(SDE) frameworks. In this paper, we propose a novel class of noise, termed Neural Network-kernel ARMA-type noise~(NA-noise), which is an It\^o-process-based alternative capable of capturing both long- and short-memory behaviors. The kernel function defining the noise structure is parameterized via neural networks and decomposed into a product form to preserve the Markov property. Based on this noise process, we develop NANSDE-Net, a generative model that extends Neural SDEs by incorporating NA-noise. We prove the theoretical existence and uniqueness of the solution under mild conditions and derive an efficient backpropagation scheme for training. Empirical results on both synthetic and real-world datasets demonstrate that NANSDE-Net matches or outperforms existing models, including fractional SDE-Net, in reproducing long- and short-memory features of the data, while maintaining computational tractability within the It\^o calculus framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08182v1</guid>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiromu Ozai, Kei Nakagawa</dc:creator>
    </item>
    <item>
      <title>Modern approaches to building interpretable models of the property market using machine learning on the base of mass cadastral valuation</title>
      <link>https://arxiv.org/abs/2506.15723</link>
      <description>arXiv:2506.15723v3 Announce Type: replace 
Abstract: In this paper, we review modern approaches to building interpretable models of property markets using machine learning on the base of mass valuation of property in the Primorye region, Russia. There are numerous potential difficulties one could encounter in the effort to build a good model. Their main source is the huge difference between noisy real market data and ideal data usually used in tutorials on machine learning. This paper covers all stages of modeling: collection of initial data, identification of outliers, search and analysis of patterns in the data, formation and final choice of price factors, building of the model, and evaluation of its efficiency. For each stage, we highlight potential issues and describe sound methods for overcoming emerging difficulties on actual examples. We show that the combination of classical linear regression with kriging (interpolation method of geostatistics) allows to build an effective model for land parcels. For flats, when many objects are attributed to one spatial point, the application of geostatistical methods becomes problematic. Instead, we suggest linear regression with automatic generation and selection of additional rules on the base of decision trees, so called the RuleFit method. We compare the performance of our inherently interpretable models with well-proven "black-box" Random Forest method and demonstrate similar results. Thus we show, that despite such a strong restriction as the requirement of interpretability which is important in practical aspects, for example, legal matters, it is still possible to build effective models of real property markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15723v3</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexey S. Tanashkin, Irina G. Tanashkina, Alexander S. Maksimchuik</dc:creator>
    </item>
    <item>
      <title>Reproducing the first and second moments of empirical degree distributions</title>
      <link>https://arxiv.org/abs/2505.10373</link>
      <description>arXiv:2505.10373v4 Announce Type: replace-cross 
Abstract: The study of probabilistic models for the analysis of complex networks represents a flourishing research field. Among the former, Exponential Random Graphs (ERGs) have gained increasing attention over the years. So far, only linear ERGs have been extensively employed to gain insight into the structural organisation of real-world complex networks. None, however, is capable of accounting for the variance of the empirical degree distribution. To this aim, non-linear ERGs must be considered. After showing that the usual mean-field approximation forces the degree-corrected version of the two-star model to degenerate, we define a fitness-induced variant of it. Such a `softened' model is capable of reproducing the sample variance, while retaining the explanatory power of its linear counterpart, within a purely canonical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10373v4</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/3vtj-5nlt</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Research 8 (013141) (2026)</arxiv:journal_reference>
      <dc:creator>Mattia Marzi, Francesca Giuffrida, Diego Garlaschelli, Tiziano Squartini</dc:creator>
    </item>
  </channel>
</rss>
