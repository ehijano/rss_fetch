<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 04:01:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation</title>
      <link>https://arxiv.org/abs/2507.14270</link>
      <description>arXiv:2507.14270v1 Announce Type: new 
Abstract: We propose the APTx Neuron, a novel, unified neural computation unit that integrates non-linear activation and linear transformation into a single trainable expression. The APTx Neuron is derived from the APTx activation function, thereby eliminating the need for separate activation layers and making the architecture both computationally efficient and elegant. The proposed neuron follows the functional form $y = \sum_{i=1}^{n} ((\alpha_i + \tanh(\beta_i x_i)) \cdot \gamma_i x_i) + \delta$, where all parameters $\alpha_i$, $\beta_i$, $\gamma_i$, and $\delta$ are trainable. We validate our APTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69\% test accuracy in just 20 epochs using approximately 332K trainable parameters. The results highlight the superior expressiveness and computational efficiency of the APTx Neuron compared to traditional neurons, pointing toward a new paradigm in unified neuron design and the architectures built upon it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14270v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ravin Kumar</dc:creator>
    </item>
    <item>
      <title>Training oscillator Ising machines to assign the dynamic stability of their equilibrium points</title>
      <link>https://arxiv.org/abs/2507.14386</link>
      <description>arXiv:2507.14386v1 Announce Type: new 
Abstract: We propose a neural network model, which, with appropriate assignment of the stability of its equilibrium points (EPs), achieves Hopfield-like associative memory. The oscillator Ising machine (OIM) is an ideal candidates for such a model, as all its $0/\pi$ binary EPs are structurally stable with their dynamic stability tunable by the coupling weights. Traditional Hopfield-based models store the desired patterns by designing the coupling weights between neurons. The design of coupling weights should simultaneously take into account both the existence and the dynamic stability of the EPs for the storage of the desired patterns. For OIMs, since all $0/\pi$ binary EPs are structurally stable, the design of the coupling weights needs only to focus on assigning appropriate stability for the $0/\pi$ binary EPs according to the desired patterns. In this paper, we establish a connection between the stability and the Hamiltonian energy of EPs for OIMs, and, based on this connection, provide a Hamiltonian-Regularized Eigenvalue Contrastive Method (HRECM) to train the coupling weights of OIMs for assigning appropriate stability to their EPs. Finally, numerical experiments are performed to validate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14386v1</guid>
      <category>cs.NE</category>
      <category>cs.IR</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Cheng, Zongli Lin</dc:creator>
    </item>
    <item>
      <title>Analyzing Internal Activity and Robustness of SNNs Across Neuron Parameter Space</title>
      <link>https://arxiv.org/abs/2507.14757</link>
      <description>arXiv:2507.14757v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) offer energy-efficient and biologically plausible alternatives to traditional artificial neural networks, but their performance depends critically on the tuning of neuron model parameters. In this work, we identify and characterize an operational space - a constrained region in the neuron hyperparameter domain (specifically membrane time constant tau and voltage threshold vth) - within which the network exhibits meaningful activity and functional behavior. Operating inside this manifold yields optimal trade-offs between classification accuracy and spiking activity, while stepping outside leads to degeneration: either excessive energy use or complete network silence.
  Through systematic exploration across datasets and architectures, we visualize and quantify this manifold and identify efficient operating points. We further assess robustness to adversarial noise, showing that SNNs exhibit increased spike correlation and internal synchrony when operating outside their optimal region. These findings highlight the importance of principled hyperparameter tuning to ensure both task performance and energy efficiency. Our results offer practical guidelines for deploying robust and efficient SNNs, particularly in neuromorphic computing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14757v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szymon Mazurek, Jakub Caputa, Maciej Wielgosz</dc:creator>
    </item>
    <item>
      <title>DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving</title>
      <link>https://arxiv.org/abs/2507.15615</link>
      <description>arXiv:2507.15615v1 Announce Type: new 
Abstract: Primal heuristics play a critical role in improving the efficiency of mixed integer programming (MILP) solvers. As large language models (LLMs) have demonstrated superior code generation abilities, recent MILP works are devoted to leveraging the evolutionary computation approaches with LLMs to generate effective primal heuristics. Although the generated heuristics have achieved better solving performance than the hand-crafted ones with little adaptability, the advantage of current LLM-based methods is limited to few MILP instances in one problem class, as they fail to capture the instance characteristics in the problem class (the MILP instances generated from the same mathematical model are defined as a problem class). Since MILP instances often differ significantly in structure and feature distribution, the neglect of their characteristics in the evolution process results in poor generalization within the same problem class. To overcome this challenge, we propose a data-algorithm co-evolution framework (DHEvo) that iteratively selects representative instances and evolves corresponding heuristics. With the initial instance distribution, we develop an LLM-based multi-agent system to generate data-code pairs simultaneously. These data-code pairs are iteratively refined based on their fitness scores, leading to the identification of the most effective heuristic over the entire problem class. Extensive experiments across diverse MILP benchmarks demonstrate that our approach significantly outperforms both human-designed heuristics and existing LLM-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15615v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Zhang, Siyuan Li, Chenxi Li, Feifan Liu, Mengjing Chen, Kai Li, Tao Zhong, Bo An, Peng Liu</dc:creator>
    </item>
    <item>
      <title>TONUS: Neuromorphic human pose estimation for artistic sound co-creation</title>
      <link>https://arxiv.org/abs/2507.15734</link>
      <description>arXiv:2507.15734v1 Announce Type: new 
Abstract: Human machine interaction is a huge source of inspiration in today's media art and digital design, as machines and humans merge together more and more. Its place in art reflects its growing applications in industry, such as robotics. However, those interactions often remains too technical and machine-driven for people to really engage into. On the artistic side, new technologies are often not explored in their full potential and lag a bit behind, so that state-of-the-art research does not make its way up to museums and exhibitions. Machines should support people's imagination and poetry in a seamless interface to their body or soul. We propose an artistic sound installation featuring neuromorphic body sensing to support a direct yet non intrusive interaction with the visitor with the purpose of creating sound scapes together with the machine. We design a neuromorphic multihead human pose estimation neural sensor that shapes sound scapes and visual output with fine body movement control. In particular, the feature extractor is a spiking neural network tailored for a dedicated neuromorphic chip. The visitor, immersed in a sound atmosphere and a neurally processed representation of themselves that they control, experience the dialogue with a machine that thinks neurally, similarly to them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15734v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jules Lecomte (Fortiss GmbH, Munich, Germany), Konrad Zinner (Hochschule f\"ur Musik und Theater Munich, Germany), Michael Neumeier (Fortiss GmbH, Munich, Germany), Axel von Arnim (Fortiss GmbH, Munich, Germany)</dc:creator>
    </item>
    <item>
      <title>Enhancing Celestial Imaging: High Dynamic Range with Neuromorphic Cameras</title>
      <link>https://arxiv.org/abs/2503.22814</link>
      <description>arXiv:2503.22814v1 Announce Type: cross 
Abstract: Conventional frame-based cameras often struggle with limited dynamic range, leading to saturation and loss of detail when capturing scenes with significant brightness variations. Neuromorphic cameras, inspired by human retina, offer a solution by providing an inherently high dynamic range. This capability enables them to capture both bright and faint celestial objects without saturation effects, preserving details across a wide range of luminosities. This paper investigates the application of neuromorphic imaging technology for capturing celestial bodies across a wide range of flux levels. Its advantages are demonstrated through examples such as the bright planet Saturn with its faint moons and the bright star Sirius A alongside its faint companion, Sirius B.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22814v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.22580/iSciNoteJ9.9.3</arxiv:DOI>
      <dc:creator>Satyapreet Singh Yadav, Nirupam Roy, Chetan Singh Thakur</dc:creator>
    </item>
    <item>
      <title>Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI</title>
      <link>https://arxiv.org/abs/2507.14172</link>
      <description>arXiv:2507.14172v1 Announce Type: cross 
Abstract: Many program synthesis tasks prove too challenging for even state-of-the-art language models to solve in single attempts. Search-based evolutionary methods offer a promising alternative by exploring solution spaces iteratively, but their effectiveness remain limited by the fixed capabilities of the underlying generative model.
  We propose SOAR, a method that learns program synthesis by integrating language models into a self-improving evolutionary loop.
  SOAR alternates between (1) an evolutionary search that uses an LLM to sample and refine candidate solutions, and (2) a hindsight learning phase that converts search attempts into valid problem-solution pairs used to fine-tune the LLM's sampling and refinement capabilities\, -- \,enabling increasingly effective search in subsequent iterations.
  On the challenging ARC-AGI benchmark, SOAR achieves significant performance gains across model scales and iterations, leveraging positive transfer between the sampling and refinement finetuning tasks. These improvements carry over to test-time adaptation, enabling SOAR to solve 52\% of the public test set. Our code is open-sourced at: https://github.com/flowersteam/SOAR</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14172v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 42 nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025</arxiv:journal_reference>
      <dc:creator>Julien Pourcel, C\'edric Colas, Pierre-Yves Oudeyer</dc:creator>
    </item>
    <item>
      <title>Pruning Increases Orderedness in Recurrent Computation</title>
      <link>https://arxiv.org/abs/2507.14747</link>
      <description>arXiv:2507.14747v1 Announce Type: cross 
Abstract: Inspired by the prevalence of recurrent circuits in biological brains, we investigate the degree to which directionality is a helpful inductive bias for artificial neural networks. Taking directionality as topologically-ordered information flow between neurons, we formalise a perceptron layer with all-to-all connections (mathematically equivalent to a weight-tied recurrent neural network) and demonstrate that directionality, a hallmark of modern feed-forward networks, can be induced rather than hard-wired by applying appropriate pruning techniques. Across different random seeds our pruning schemes successfully induce greater topological ordering in information flow between neurons without compromising performance, suggesting that directionality is not a prerequisite for learning, but may be an advantageous inductive bias discoverable by gradient descent and sparsification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14747v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yiding Song</dc:creator>
    </item>
    <item>
      <title>Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings</title>
      <link>https://arxiv.org/abs/2507.15118</link>
      <description>arXiv:2507.15118v1 Announce Type: cross 
Abstract: Goal: Epilepsy remains under-diagnosed in low-income countries due to scarce neurologists and costly diagnostic tools. We propose a graph-based deep learning framework to detect epilepsy from low-cost Electroencephalography (EEG) hardware, tested on recordings from Nigeria and Guinea-Bissau. Our focus is on fair, accessible automatic assessment and explainability to shed light on epilepsy biomarkers. Methods: We model EEG signals as spatio-temporal graphs, classify them, and identify interchannel relationships and temporal dynamics using graph attention networks (GAT). To emphasize connectivity biomarkers, we adapt the inherently node-focused GAT to analyze edges. We also designed signal preprocessing for low-fidelity recordings and a lightweight GAT architecture trained on Google Colab and deployed on RaspberryPi devices. Results: The approach achieves promising classification performance, outperforming a standard classifier based on random forest and graph convolutional networks in terms of accuracy and robustness over multiple sessions, but also highlighting specific connections in the fronto-temporal region. Conclusions: The results highlight the potential of GATs to provide insightful and scalable diagnostic support for epilepsy in underserved regions, paving the way for affordable and accessible neurodiagnostic tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15118v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szymon Mazurek, Stephen Moore, Alessandro Crimi</dc:creator>
    </item>
    <item>
      <title>Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm</title>
      <link>https://arxiv.org/abs/2507.15132</link>
      <description>arXiv:2507.15132v1 Announce Type: cross 
Abstract: The research community continues to seek increasingly more advanced synthetic data generators to reliably evaluate the strengths and limitations of machine learning methods. This work aims to increase the availability of datasets encompassing a diverse range of problem complexities by proposing a genetic algorithm that optimizes a set of problem complexity measures for classification and regression tasks towards specific targets. For classification, a set of 10 complexity measures was used, while for regression tasks, 4 measures demonstrating promising optimization capabilities were selected. Experiments confirmed that the proposed genetic algorithm can generate datasets with varying levels of difficulty by transforming synthetically created datasets to achieve target complexity values through linear feature projections. Evaluations involving state-of-the-art classifiers and regressors revealed a correlation between the complexity of the generated data and the recognition quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15132v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joanna Komorniczak</dc:creator>
    </item>
    <item>
      <title>The Role of Excitatory Parvalbumin-positive Neurons in the Tectofugal Pathway of Pigeon (Columba livia) Hierarchical Visual Processing</title>
      <link>https://arxiv.org/abs/2507.15486</link>
      <description>arXiv:2507.15486v1 Announce Type: cross 
Abstract: The visual systems of birds and mammals exhibit remarkable organizational similarities: the dorsal ventricular ridge (DVR) demonstrates a columnar microcircuitry that parallels the cortical architecture observed in mammals. However, the specific neuronal subtypes involved and their functional roles in pigeon hierarchical visual processing remain unclear. This study investigates the role of excitatory parvalbumin (PV+) neurons within the Ento-MVL (entoallium-mesopallium venterolaterale) circuit of pigeons underlying hierarchical moving target recognition. Electrophysiological recordings and immunofluorescence staining reveal that excitatory PV+ neurons originating from the entopallial internal (Ei) predominantly modulate MVL responses to varying visual stimuli. Using a heterochronous-speed recurrent neural network (HS-RNN) model, we further validated these dynamics, replicating the rapid adaptation of the Ento-MVL circuit to moving visual targets. The findings suggest that the fast-spiking and excitatory properties of PV+ neurons enable rapid processing of motion-related information within the Ento-MVL circuit. Our results elucidate the functional role of excitatory PV+ neurons in hierarchical information processing under the columnar organization of the visual DVR and underscore the convergent neural processing strategies shared by avian and mammalian visual systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15486v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shan Lu, Xiaoteng Zhang, Yueyang Cang, Shihao Pan, Yanyan Peng, Xinwei Li, Shaoju Zeng, Yingjie Zhu, Li Shi</dc:creator>
    </item>
    <item>
      <title>Continual Learning with Neuromorphic Computing: Foundations, Methods, and Emerging Applications</title>
      <link>https://arxiv.org/abs/2410.09218</link>
      <description>arXiv:2410.09218v3 Announce Type: replace 
Abstract: The challenging deployment of compute- and memory-intensive methods from Deep Neural Network (DNN)-based Continual Learning (CL) underscores the critical need for a paradigm shift towards more efficient approaches. Neuromorphic Continual Learning (NCL) appears as an emerging solution, by leveraging the principles of Spiking Neural Networks (SNNs) which enable efficient CL algorithms executed in dynamically-changed environments with resource-constrained computing systems. Motivated by the need for a holistic study of NCL, in this survey, we first provide a detailed background on CL, encompassing the desiderata, settings, metrics, scenario taxonomy, Online Continual Learning (OCL) paradigm, recent DNN-based methods to address catastrophic forgetting (CF). Then, we analyze these methods considering CL desiderata, computational and memory costs, as well as network complexity, hence emphasizing the need for energy-efficient CL. Afterward, we provide background of low-power neuromorphic systems including encoding techniques, neuronal dynamics, network architectures, learning rules, hardware processors, software and hardware frameworks, datasets, benchmarks, and evaluation metrics. Then, this survey comprehensively reviews and analyzes state-of-the-art in NCL. The key ideas, implementation frameworks, and performance assessments are also provided. This survey covers several hybrid approaches that combine supervised and unsupervised learning paradigms. It also covers optimization techniques including SNN operations reduction, weight quantization, and knowledge distillation. Then, this survey discusses the progress of real-world NCL applications. Finally, this paper provides a future perspective on the open research challenges for NCL, since the purpose of this study is to be useful for the wider neuromorphic AI research community and to inspire future research in bio-plausible OCL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09218v3</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2025.3588665</arxiv:DOI>
      <dc:creator>Mishal Fatima Minhas, Rachmad Vidya Wicaksana Putra, Falah Awwad, Osman Hasan, Muhammad Shafique</dc:creator>
    </item>
    <item>
      <title>TSkips: Efficiency Through Explicit Temporal Delay Connections in Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2411.16711</link>
      <description>arXiv:2411.16711v2 Announce Type: replace 
Abstract: Spiking Neural Networks (SNNs) with their bio-inspired Leaky Integrate-and-Fire (LIF) neurons inherently capture temporal information. This makes them well-suited for sequential tasks like processing event-based data from Dynamic Vision Sensors (DVS) and event-based speech tasks. Harnessing the temporal capabilities of SNNs requires mitigating vanishing spikes during training, capturing spatio-temporal patterns and enhancing precise spike timing. To address these challenges, we propose TSkips, augmenting SNN architectures with forward and backward skip connections that incorporate explicit temporal delays. These connections capture long-term spatio-temporal dependencies and facilitate better spike flow over long sequences. The introduction of TSkips creates a vast search space of possible configurations, encompassing skip positions and time delay values. To efficiently navigate this search space, this work leverages training-free Neural Architecture Search (NAS) to identify optimal network structures and corresponding delays. We demonstrate the effectiveness of our approach on four event-based datasets: DSEC-flow for optical flow estimation, DVS128 Gesture for hand gesture recognition and Spiking Heidelberg Digits (SHD) and Spiking Speech Commands (SSC) for speech recognition. Our method achieves significant improvements across these datasets: up to 18% reduction in Average Endpoint Error (AEE) on DSEC-flow, 8% increase in classification accuracy on DVS128 Gesture, and up to 8% and 16% higher classification accuracy on SHD and SSC, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16711v2</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prajna G. Malettira, Shubham Negi, Wachirawit Ponghiran, Kaushik Roy</dc:creator>
    </item>
    <item>
      <title>EvoRL: A GPU-accelerated Framework for Evolutionary Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2501.15129</link>
      <description>arXiv:2501.15129v3 Announce Type: replace 
Abstract: Evolutionary Reinforcement Learning (EvoRL) has emerged as a promising approach to overcoming the limitations of traditional reinforcement learning (RL) by integrating the Evolutionary Computation (EC) paradigm with RL. However, the population-based nature of EC significantly increases computational costs, thereby restricting the exploration of algorithmic design choices and scalability in large-scale settings. To address this challenge, we introduce $\texttt{$\textbf{EvoRL}$}$, the first end-to-end EvoRL framework optimized for GPU acceleration. The framework executes the entire training pipeline on accelerators, including environment simulations and EC processes, leveraging hierarchical parallelism through vectorization and compilation techniques to achieve superior speed and scalability. This design enables the efficient training of large populations on a single machine. In addition to its performance-oriented design, $\texttt{$\textbf{EvoRL}$}$ offers a comprehensive platform for EvoRL research, encompassing implementations of traditional RL algorithms (e.g., A2C, PPO, DDPG, TD3, SAC), Evolutionary Algorithms (e.g., CMA-ES, OpenES, ARS), and hybrid EvoRL paradigms such as Evolutionary-guided RL (e.g., ERL, CEM-RL) and Population-Based AutoRL (e.g., PBT). The framework's modular architecture and user-friendly interface allow researchers to seamlessly integrate new components, customize algorithms, and conduct fair benchmarking and ablation studies. The project is open-source and available at: https://github.com/EMI-Group/evorl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15129v3</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Zheng, Ran Cheng, Kay Chen Tan</dc:creator>
    </item>
    <item>
      <title>Brain-Inspired Online Adaptation for Remote Sensing with Spiking Neural Network</title>
      <link>https://arxiv.org/abs/2409.02146</link>
      <description>arXiv:2409.02146v2 Announce Type: replace-cross 
Abstract: On-device computing, or edge computing, is becoming increasingly important for remote sensing, particularly in applications like deep network-based perception on on-orbit satellites and unmanned aerial vehicles (UAVs). In these scenarios, two brain-like capabilities are crucial for remote sensing models: (1) high energy efficiency, allowing the model to operate on edge devices with limited computing resources, and (2) online adaptation, enabling the model to quickly adapt to environmental variations, weather changes, and sensor drift. This work addresses these needs by proposing an online adaptation framework based on spiking neural networks (SNNs) for remote sensing. Starting with a pretrained SNN model, we design an efficient, unsupervised online adaptation algorithm, which adopts an approximation of the BPTT algorithm and only involves forward-in-time computation that significantly reduces the computational complexity of SNN adaptation learning. Besides, we propose an adaptive activation scaling scheme to boost online SNN adaptation performance, particularly in low time-steps. Furthermore, for the more challenging remote sensing detection task, we propose a confidence-based instance weighting scheme, which substantially improves adaptation performance in the detection task. To our knowledge, this work is the first to address the online adaptation of SNNs. Extensive experiments on seven benchmark datasets across classification, segmentation, and detection tasks demonstrate that our proposed method significantly outperforms existing domain adaptation and domain generalization approaches under varying weather conditions. The proposed method enables energy-efficient and fast online adaptation on edge devices, and has much potential in applications such as remote perception on on-orbit satellites and UAV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02146v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dexin Duan, Peilin liu, Bingwei Hui, Fei Wen</dc:creator>
    </item>
    <item>
      <title>DiCE-Extended: A Robust Approach to Counterfactual Explanations in Machine Learning</title>
      <link>https://arxiv.org/abs/2504.19027</link>
      <description>arXiv:2504.19027v2 Announce Type: replace-cross 
Abstract: Explainable artificial intelligence (XAI) has become increasingly important in decision-critical domains such as healthcare, finance, and law. Counterfactual (CF) explanations, a key approach in XAI, provide users with actionable insights by suggesting minimal modifications to input features that lead to different model outcomes. Despite significant advancements, existing CF generation methods often struggle to balance proximity, diversity, and robustness, limiting their real-world applicability. A widely adopted framework, Diverse Counterfactual Explanations (DiCE), emphasizes diversity but lacks robustness, making CF explanations sensitive to perturbations and domain constraints. To address these challenges, we introduce DiCE-Extended, an enhanced CF explanation framework that integrates multi-objective optimization techniques to improve robustness while maintaining interpretability. Our approach introduces a novel robustness metric based on the Dice-S{\o}rensen coefficient, enabling stability under small input variations. Additionally, we refine CF generation using weighted loss components (lambda_p, lambda_d, lambda_r) to balance proximity, diversity, and robustness. We empirically validate DiCE-Extended on benchmark datasets (COMPAS, Lending Club, German Credit, Adult Income) across multiple ML backends (Scikit-learn, PyTorch, TensorFlow). Results demonstrate improved CF validity, stability, and alignment with decision boundaries compared to standard DiCE-generated explanations. Our findings highlight the potential of DiCE-Extended in generating more reliable and interpretable CFs for high-stakes applications. Future work could explore adaptive optimization techniques and domain-specific constraints to further enhance CF generation in real-world scenarios</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19027v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volkan Bakir, Polat Goktas, Sureyya Akyuz</dc:creator>
    </item>
    <item>
      <title>Multi-parameter Control for the $(1+(\lambda,\lambda))$-GA on OneMax via Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.12982</link>
      <description>arXiv:2505.12982v3 Announce Type: replace-cross 
Abstract: It is well known that evolutionary algorithms can benefit from dynamic choices of the key parameters that control their behavior, to adjust their search strategy to the different stages of the optimization process. A prominent example where dynamic parameter choices have shown a provable super-constant speed-up is the $(1+(\lambda,\lambda))$ Genetic Algorithm optimizing the OneMax function. While optimal parameter control policies result in linear expected running times, this is not possible with static parameter choices. This result has spurred a lot of interest in parameter control policies. However, many works, in particular theoretical running time analyses, focus on controlling one single parameter. Deriving policies for controlling multiple parameters remains very challenging. In this work we reconsider the problem of the $(1+(\lambda,\lambda))$ Genetic Algorithm optimizing OneMax. We decouple its four main parameters and investigate how well state-of-the-art deep reinforcement learning techniques can approximate good control policies. We show that although making deep reinforcement learning learn effectively is a challenging task, once it works, it is very powerful and is able to find policies that outperform all previously known control policies on the same benchmark. Based on the results found through reinforcement learning, we derive a simple control policy that consistently outperforms the default theory-recommended setting by $27\%$ and the irace-tuned policy, the strongest existing control policy on this benchmark, by $13\%$, for all tested problem sizes up to $40{,}000$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12982v3</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3729878.3746703</arxiv:DOI>
      <dc:creator>Tai Nguyen, Phong Le, Carola Doerr, Nguyen Dang</dc:creator>
    </item>
    <item>
      <title>Plan for Speed: Dilated Scheduling for Masked Diffusion Language Models</title>
      <link>https://arxiv.org/abs/2506.19037</link>
      <description>arXiv:2506.19037v2 Announce Type: replace-cross 
Abstract: Masked diffusion language models (MDLMs) promise fast, non-autoregressive text generation, yet existing samplers, which pick tokens to unmask based on model confidence, ignore interactions when unmasking multiple positions in parallel and effectively reduce to slow, autoregressive behavior. We propose the Dilated Unmasking Scheduler (DUS), an inference-only, planner-model-free method that partitions sequence positions into non-adjacent dilated groups and unmasked them in parallel so as to minimize an upper bound on joint entropy gain at each denoising step. By explicitly trading off the number of network calls against generation quality, DUS recovers most of the performance lost under traditional parallel unmasking strategies. Across math (GSM8K, MATH500), code (HumanEval, MBPP) and general-knowledge benchmarks (BBH, MMLU-Pro), DUS outperforms confidence-based planners, without modifying the underlying denoiser, and reveals the true speed-quality frontier of MDLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19037v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Luxembourg, Haim Permuter, Eliya Nachmani</dc:creator>
    </item>
  </channel>
</rss>
