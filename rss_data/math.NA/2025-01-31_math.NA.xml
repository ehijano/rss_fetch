<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Numerical Approximation of Caputo Fractional Derivative of Higher Orders Using A Shifted Gegenbauer Pseudospectral Method: Two-Point Boundary Value Problems of the Bagley Torvik Type Case Study</title>
      <link>https://arxiv.org/abs/2501.17956</link>
      <description>arXiv:2501.17956v1 Announce Type: new 
Abstract: This work introduces a novel framework for approximating Caputo fractional derivatives (FDs) of orders greater than one using a shifted Gegenbauer pseudospectral (SGPS) method. Unlike traditional approaches, our method employs a strategic change of variables to transform the Caputo FD into a scaled integral of the mth-derivative of the Lagrange interpolating polynomial, where m is the ceiling of the fractional order {\alpha}. This transformation mitigates the singularity inherent in the Caputo derivative near zero, thereby improving numerical stability and accuracy. The numerical approximation of the Caputo FD is finally furnished by linking the mth derivative of SG polynomials with another set of shifted Gegenbauer (SG) polynomials of lower degrees and higher parameter values whose integration can be recovered within excellent accuracies using SG quadratures. By employing orthogonal collocation and SG quadratures in barycentric form, we achieve a highly accurate and computationally efficient scheme for solving fractional differential equations. Furthermore, we provide a rigorous error analysis showing that the SGPS method is convergent when implemented within a semi-analytic framework, where all necessary integrals are computed analytically, and is conditionally convergent with an exponential rate of convergence for sufficiently smooth functions when performed using finite-precision arithmetic. This exponential convergence generally leads to superior accuracy compared to existing wavelet-based, operational matrix, and finite difference methods. The SGPS is highly flexible in the sense that the SG parameters associated with SG interpolation and quadratures allow for flexibility in adjusting the method to suit different types of problems. These parameters influence the clustering of collocation and quadrature points and can be tuned for optimal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17956v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kareem T. Elgindy</dc:creator>
    </item>
    <item>
      <title>A fully adaptive, high-order, fast Poisson solver for complex two-dimensional geometries</title>
      <link>https://arxiv.org/abs/2501.17967</link>
      <description>arXiv:2501.17967v1 Announce Type: new 
Abstract: We present a new framework for the fast solution of inhomogeneous elliptic boundary value problems in domains with smooth boundaries. High-order solvers based on adaptive box codes or the fast Fourier transform can efficiently treat the volumetric inhomogeneity, but require care to be taken near the boundary to ensure that the volume data is globally smooth. We avoid function extension or cut-cell quadratures near the boundary by dividing the domain into two regions: a bulk region away from the boundary that is efficiently treated with a truncated free-space box code, and a variable-width boundary-conforming strip region that is treated with a spectral collocation method and accompanying fast direct solver. Particular solutions in each region are then combined with Laplace layer potentials to yield the global solution. The resulting solver has an optimal computational complexity of $O(N)$ for an adaptive discretization with $N$ degrees of freedom. With an efficient two-dimensional (2D) implementation we demonstrate adaptive resolution of volumetric data, boundary data, and geometric features across a wide range of length scales, to typically 10-digit accuracy. The cost of all boundary corrections remains small relative to that of the bulk box code. The extension to 3D is expected to be straightforward in many cases because the strip ``thickens'' an existing boundary quadrature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17967v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Fortunato, David B. Stein, Alex H. Barnett</dc:creator>
    </item>
    <item>
      <title>A comprehensive numerical investigation of a coupled mathematical model of neuronal excitability</title>
      <link>https://arxiv.org/abs/2501.18013</link>
      <description>arXiv:2501.18013v1 Announce Type: new 
Abstract: Being an example for a relaxation oscillator, the FitzHugh-Nagumo model has been widely employed for describing the generation of action potentials. In this paper, we begin with a biological interpretation of what the subsequent mathematical and numerical analyses of the model entail. The interaction between action potential variable and recovery variable is then revisited through linear stability analysis around the equilibrium and local stability conditions are determined. Analytical results are compared with numerical simulations. The study aims to show an alternative approach regarding Taylor polynomials and constructed difference scheme which play a key role in the numerical approach for the problem. The robustness of the schemes is investigated in terms of convergency and stability of the techniques. This systematic approach by the combination of numerical techniques provides beneficial results which are uniquely designed for the FitzHugh-Nagumo model. We describe the matrix representations with the collocation points. Then the method is applied in order to acquire a system of nonlinear algebraic equations. On the other hand, we apply finite difference scheme and its stability is also performed. Moreover, the numerical simulations are shown. Consequently, a comprehensive investigation of the related model is examined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18013v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Burcu G\"urb\"uz, Ayt\"ul G\"ok\c{c}e, Mahmut Modanl{\i}</dc:creator>
    </item>
    <item>
      <title>Collect, Commit, Expand: Efficient CPQR-Based Column Selection for Extremely Wide Matrices</title>
      <link>https://arxiv.org/abs/2501.18035</link>
      <description>arXiv:2501.18035v1 Announce Type: new 
Abstract: Column-pivoted QR (CPQR) factorization is a computational primitive used in numerous applications that require selecting a small set of ``representative'' columns from a much larger matrix. These include applications in spectral clustering, model-order reduction, low-rank approximation, and computational quantum chemistry, where the matrix being factorized has a moderate number of rows but an extremely large number of columns. We describe a modification of the Golub-Businger algorithm which, for many matrices of this type, can perform CPQR-based column selection much more efficiently. This algorithm, which we call CCEQR, is based on a three-step ``collect, commit, expand'' strategy that limits the number of columns being manipulated, while also transferring more computational effort from level-2 BLAS to level-3. Unlike most CPQR algorithms that exploit level-3 BLAS, CCEQR is deterministic, and provably recovers a column permutation equivalent to the one computed by the Golub-Businger algorithm. Tests on spectral clustering and Wannier basis localization problems demonstrate that on appropriately structured problems, CCEQR can significantly outperform GEQP3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18035v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Armstrong, Anil Damle</dc:creator>
    </item>
    <item>
      <title>High order-accurate solution of scattering integral equations with unbounded solutions at corners</title>
      <link>https://arxiv.org/abs/2501.18065</link>
      <description>arXiv:2501.18065v1 Announce Type: new 
Abstract: Although high-order Maxwell integral equation solvers provide significant advantages in terms of speed and accuracy over corresponding low-order integral methods, their performance significantly degrades in presence of non-smooth geometries--owing to field enhancement and singularities that arise at sharp edges and corners which, if left untreated, give rise to significant accuracy losses. The problem is particularly challenging in cases in which the "density" (i.e., the solution of the integral equation) tends to infinity at corners and edges--a difficulty that can be bypassed for 2D configurations, but which is unavoidable in 3D Maxwell integral formulations, wherein the component tangential to an edge of the electrical-current integral density vector tends to infinity at the edge. In order to tackle the problem this paper restricts attention to the simplest context in which the unbounded-density difficulty arises, namely, integral formulations in 2D space whose integral density blows up at corners; the strategies proposed, however, generalize directly to the 3D context. The novel methodologies presented in this paper yield high-order convergence for such challenging equations and achieve highly accurate solutions (even near edges and corners) without requiring a priori analysis of the geometry or use of singular bases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18065v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Constantine Sideris, Davit Aslanyan, Oscar P. Bruno</dc:creator>
    </item>
    <item>
      <title>Inverse source problem of sub-diffusion of variable exponent</title>
      <link>https://arxiv.org/abs/2501.18228</link>
      <description>arXiv:2501.18228v1 Announce Type: new 
Abstract: This work investigates both direct and inverse problems of the variable-exponent sub-diffusion model, which attracts increasing attentions in both practical applications and theoretical aspects. Based on the perturbation method, which transfers the original model to an equivalent but more tractable form, the analytical extensibility of the solutions and the weak unique continuation principle are proved, which results in the uniqueness of the inverse space-dependent source problem from local internal observation. Then, based on the variational identity connecting the inversion input data with the unknown source function, we propose a weak norm and prove the conditional stability for the inverse problem in this norm. The iterative thresholding algorithm and Nesterov iteration scheme are employed to numerically reconstruct the smooth and non-smooth sources, respectively. Numerical experiments are performed to investigate their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18228v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Li, Chunlong Sun, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>Numerical approximation of Cahn-Hilliard type nonlinear SPDEs with additive space-time white noise</title>
      <link>https://arxiv.org/abs/2501.18240</link>
      <description>arXiv:2501.18240v1 Announce Type: new 
Abstract: We consider the strong numerical approximation for a stochastic Cahn-Hilliard type nonlinear SPDE driven by space-time white noise on $2$-dimensional torus.
  We consider its full discretisation with a splitting scheme: a spectral Galerkin scheme in space and Euler scheme in time. We show the convergence with almost spatial rate $\frac{1}{2}$ and $1$-temporal rate obtained mainly via stochastic sewing technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18240v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dirk Bl\"omker, Chengcheng Ling, Johannes Rimmele</dc:creator>
    </item>
    <item>
      <title>A hybrid two-level weighted Schwartz method for time-harmonic Maxwell equations</title>
      <link>https://arxiv.org/abs/2501.18305</link>
      <description>arXiv:2501.18305v1 Announce Type: new 
Abstract: This paper concerns the preconditioning technique for discrete systems arising from time-harmonic Maxwell equations with absorptions, where the discrete systems are generated by N\'ed\'elec finite element methods of fixed order on meshes with suitable size. This kind of preconditioner is defined as a two-level hybrid form, which falls into the class of ``unsymmetrically weighted'' Schwarz method based on the overlapping domain decomposition with impedance boundary subproblems. The coarse space in this preconditioner is constructed by specific eigenfunctions solving a series of generalized eigenvalue problems in the local discrete Maxwell-harmonic spaces according to a user-defined tolerance $\rho$. We establish a stability result for the considered discrete variational problem. Using this discrete stability, we prove that the two-level hybrid Schwarz preconditioner is robust in the sense that the convergence rate of GMRES is independent of the mesh size, the subdomain size and the wave-number when $\rho$ is chosen appropriately. We also define an economical variant that avoids solving generalized eigenvalue problems. Numerical experiments confirm the theoretical results and illustrate the efficiency of the preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18305v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Li, Qiya Hu</dc:creator>
    </item>
    <item>
      <title>Finite element discretization of nonlinear models of ultrasound heating</title>
      <link>https://arxiv.org/abs/2501.18307</link>
      <description>arXiv:2501.18307v1 Announce Type: new 
Abstract: Heating generated by high-intensity focused ultrasound waves is central to many emerging medical applications, including non-invasive cancer therapy and targeted drug delivery. In this study, we aim to gain a fundamental understanding of numerical simulations in this context by analyzing conforming finite element approximations of the underlying nonlinear models that describe ultrasound-heat interactions. These models are based on a coupling of a nonlinear Westervelt--Kuznetsov acoustic wave equation to the heat equation with a pressure-dependent source term. A particular challenging feature of the system is that the acoustic medium parameters may depend on the temperature. The core of our new arguments in the \emph{a prior} error analysis lies in devising energy estimates for the coupled semi-discrete system that can accommodate the nonlinearities present in the model. To derive them, we exploit the parabolic nature of the system thanks to the strong damping present in the acoustic component. Theoretically obtained optimal convergence rates in the energy norm are confirmed by the numerical experiments. In addition, we conduct a further numerical study of the problem, where we simulate the propagation of acoustic waves in liver tissue for an initially excited profile and under high-frequency sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18307v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julio Careaga, Benjamin D\"orich, Vanja Nikoli\'c</dc:creator>
    </item>
    <item>
      <title>Exponential quadrature rules for problems with time-dependent fractional source</title>
      <link>https://arxiv.org/abs/2501.18395</link>
      <description>arXiv:2501.18395v1 Announce Type: new 
Abstract: In this manuscript, we propose newly-derived exponential quadrature rules for stiff linear differential equations with time-dependent fractional sources in the form $h(t^r)$, with $0&lt;r&lt;1$ and $h$ a sufficiently smooth function. To construct the methods, the source term is interpolated at $\nu$ collocation points by a suitable non-polynomial function, yielding to time marching schemes that we call Exponential Quadrature Rules for Fractional sources (EQRF$\nu$). The error analysis is done in the framework of strongly continuous semigroups. Compared to classical exponential quadrature rules, which in our case of interest converge with order $1+r$ at most, we prove that the new methods may reach order $1+\nu r$ for proper choices of the collocation points. We also show that the proposed integrators can be written in terms of special instances of the Mittag--Leffler functions that we call fractional $\varphi$ functions. Several numerical experiments demonstrate the theoretical findings and highlight the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18395v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Caliari, Fabio Cassini</dc:creator>
    </item>
    <item>
      <title>Convergence of a semi-explicit scheme for a one dimensional periodic nonlocal eikonal equation modeling dislocation dynamics</title>
      <link>https://arxiv.org/abs/2501.18428</link>
      <description>arXiv:2501.18428v1 Announce Type: new 
Abstract: In this paper, we derive a periodic model from a one dimensional nonlocal eikonal equation set on the full space modeling dislocation dynamics. Thanks to a gradient entropy estimate, we show that this periodic model converges toward the initial one when the period goes to infinity. Moreover, we design a semi-explicit numerical scheme for the periodic model that we introduce. We show the well-posedness of the scheme and a discrete gradient entropy inequality. We also prove the convergence of the scheme and we present some numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18428v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diana Al Zareef, Ahmad El Hajj, Hassan Ibrahim, Antoine Zurek</dc:creator>
    </item>
    <item>
      <title>Assessment of the January 2025 Los Angeles County wildfires: A multi-modal analysis of impact, response, and population exposure</title>
      <link>https://arxiv.org/abs/2501.17880</link>
      <description>arXiv:2501.17880v1 Announce Type: cross 
Abstract: This study presents a comprehensive analysis of four significant California wildfires: Palisades, Eaton, Kenneth, and Hurst, examining their impacts through multiple dimensions, including land cover change, jurisdictional management, structural damage, and demographic vulnerability. Using the Chebyshev-Kolmogorov-Arnold network model applied to Sentinel-2 imagery, the extent of burned areas was mapped, ranging from 315.36 to 10,960.98 hectares. Our analysis revealed that shrubland ecosystems were consistently the most affected, comprising 57.4-75.8% of burned areas across all events. The jurisdictional assessment demonstrated varying management complexities, from singular authority (98.7% in the Palisades Fire) to distributed management across multiple agencies. A structural impact analysis revealed significant disparities between urban interface fires (Eaton: 9,869 structures; Palisades: 8,436 structures) and rural events (Kenneth: 24 structures; Hurst: 17 structures). The demographic analysis showed consistent gender distributions, with 50.9% of the population identified as female and 49.1% as male. Working-age populations made up the majority of the affected populations, ranging from 53.7% to 54.1%, with notable temporal shifts in post-fire periods. The study identified strong correlations between urban interface proximity, structural damage, and population exposure. The Palisades and Eaton fires affected over 20,000 people each, compared to fewer than 500 in rural events. These findings offer valuable insights for the development of targeted wildfire management strategies, particularly in wildland urban interface zones, and emphasize the need for age- and gender-conscious approaches in emergency response planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17880v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyd Teymoor Seydi</dc:creator>
    </item>
    <item>
      <title>Computing AD-compatible subgradients of convex relaxations of implicit functions</title>
      <link>https://arxiv.org/abs/2501.18471</link>
      <description>arXiv:2501.18471v1 Announce Type: cross 
Abstract: Automatic generation of convex relaxations and subgradients is critical in global optimization, and is typically carried out using variants of automatic/algorithmic differentiation (AD). At previous AD conferences, variants of the forward and reverse AD modes were presented to evaluate accurate subgradients for convex relaxations of supplied composite functions. In a recent approach for generating convex relaxations of implicit functions, these relaxations are constructed as optimal-value functions; this formulation is versatile but complicates sensitivity analysis. We present the first subgradient propagation rules for these implicit function relaxations, based on supplied AD-like knowledge of the residual function. Our new subgradient rules allow implicit function relaxations to be added to the elemental function libraries for the forward AD modes for subgradient propagation of convex relaxations. Proof-of-concept numerical results in Julia are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18471v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingkai Song, Kamil A. Khan</dc:creator>
    </item>
    <item>
      <title>New complementarity formulations for root-finding and optimization of piecewise-affine functions in abs-normal form</title>
      <link>https://arxiv.org/abs/2501.18503</link>
      <description>arXiv:2501.18503v1 Announce Type: cross 
Abstract: Nonsmooth functions have been used to model discrete-continuous phenomena such as contact mechanics, and are also prevalent in neural network formulations via activation functions such as ReLU. At previous AD conferences, Griewank et al. showed that nonsmooth functions may be approximated well by piecewise-affine functions constructed using an AD-like procedure. Moreover, such a piecewise-affine function may always be represented in an "abs-normal form", encoding it as a collection of four matrices and two vectors. We present new general complementarity formulations for root-finding and optimization of piecewise-affine functions in abs-normal form, with significantly fewer restrictions than previous approaches. In particular, piecewise-affine root-finding may always be represented as a mixed-linear complementarity problem (MLCP), which may often be simplified to a linear complementarity problem (LCP). We also present approaches for verifying existence of solutions to these problems. A proof-of-concept implementation in Julia is discussed and applied to several numerical examples, using the PATH solver to solve complementarity problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18503v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulan Zhang, Kamil A. Khan</dc:creator>
    </item>
    <item>
      <title>Comparison of lubrication theory and Stokes flow models in step bearings with flow separation</title>
      <link>https://arxiv.org/abs/2501.18575</link>
      <description>arXiv:2501.18575v1 Announce Type: cross 
Abstract: The Reynolds equation from lubrication theory and the Stokes equations for low Reynolds number flows are distinct models for an incompressible fluid with negligible inertia. Here we investigate the sensitivity of the Reynolds equation to large gradients in the surface geometry. We present an analytic solution to the Reynolds equation in a piecewise-linear domain alongside a more general finite difference solution. For the Stokes equations, we use a finite difference solution for the biharmonic stream-velocity formulation. We compare the fluid velocity, pressure, and resistance for various step bearing geometries in the lubrication and Stokes limits. We find that the solutions to the Reynolds equation do not capture flow separation resulting from large cross-film pressure gradients. Flow separation and corner flow recirculation in step bearings are explored further; we consider the effect of smoothing large gradients in the surface geometry in order to recover limits under which the lubrication and Stokes approximations converge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18575v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Dennis, Thomas G. Fai</dc:creator>
    </item>
    <item>
      <title>Minimum-residual a posteriori error estimates for hybridizable discontinuous Galerkin discretizations of the Helmholtz equation</title>
      <link>https://arxiv.org/abs/2304.00418</link>
      <description>arXiv:2304.00418v2 Announce Type: replace 
Abstract: We propose and analyze two a posteriori error indicators for hybridizable discontinuous Galerkin (HDG) discretizations of the Helmholtz equation. These indicators are built to minimize the residual associated with a local superconvergent postprocessing scheme for the primal variable, measured in a dual norm of an enlarged discrete test space. The residual minimization is reformulated into equivalent local saddle-point problems, each yielding a superconvergent postprocessed approximation of the primal variable in the asymptotic regime for sufficiently regular exact solutions and a built-in residual representation with minimal computational effort. Both error indicators are based on frequency-dependent postprocessing schemes and verify reliability and efficiency estimates for a frequency-weighted $H^1$-error for the scalar variable and the $L^2$-error for the flux. We illustrate our theoretical findings through ad-hoc numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00418v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liliana Camargo, Sergio Rojas, Patrick Vega</dc:creator>
    </item>
    <item>
      <title>A Fully-discrete Semi-Lagrangian scheme for a price formation MFG model</title>
      <link>https://arxiv.org/abs/2403.02785</link>
      <description>arXiv:2403.02785v2 Announce Type: replace 
Abstract: Here, we examine a fully-discrete Semi-Lagrangian scheme for a mean-field game price formation model. We show the existence of the solution of the discretized problem and that it is monotone as a multivalued operator. Moreover, we show that the limit of the discretization converges to the weak solution of the continuous price formation mean-field game using monotonicity methods. Numerical simulations demonstrate that this scheme can provide results efficiently, comparing favorably with other methods in the examples we tested.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02785v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuri Ashrafyan, Diogo Gomes</dc:creator>
    </item>
    <item>
      <title>Efficient Multifidelity Uncertainty Propagation in the Presence of Process Noise</title>
      <link>https://arxiv.org/abs/2405.15993</link>
      <description>arXiv:2405.15993v2 Announce Type: replace 
Abstract: A multifidelity method for the nonlinear propagation of uncertainties in the presence of stochastic accelerations is presented. The proposed algorithm treats the uncertainty propagation (UP) problem by separating the propagation of the initial uncertainty from that of the process noise. The initial uncertainty is propagated using an adaptive Gaussian mixture model (GMM) method which exploits a low-fidelity dynamical model to minimize the computational costs. The effects of process noise are instead computed using the PoLynomial Algebra Stochastic Moments Analysis (PLASMA) technique, which considers a high-fidelity model of the stochastic dynamics. The main focus of the paper is on the latter and on the key idea to approximate the probability density function (pdf) of the solution by a polynomial representation of its moments, which are efficiently computed using differential algebra (DA) techniques. The two estimates are finally combined to restore the accuracy of the low-fidelity surrogate and account for both sources of uncertainty. The proposed approach is applied to the problem of nonlinear orbit UP and its performance compared to that of Monte Carlo (MC) simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15993v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alberto Foss\`a, Roberto Armellin, Emmanuel Delande, Francesco Sanfedino</dc:creator>
    </item>
    <item>
      <title>Solving Roughly Forced Nonlinear PDEs via Misspecified Kernel Methods and Neural Networks</title>
      <link>https://arxiv.org/abs/2501.17110</link>
      <description>arXiv:2501.17110v2 Announce Type: replace 
Abstract: We consider the use of Gaussian Processes (GPs) or Neural Networks (NNs) to numerically approximate the solutions to nonlinear partial differential equations (PDEs) with rough forcing or source terms, which commonly arise as pathwise solutions to stochastic PDEs. Kernel methods have recently been generalized to solve nonlinear PDEs by approximating their solutions as the maximum a posteriori estimator of GPs that are conditioned to satisfy the PDE at a finite set of collocation points. The convergence and error guarantees of these methods, however, rely on the PDE being defined in a classical sense and its solution possessing sufficient regularity to belong to the associated reproducing kernel Hilbert space. We propose a generalization of these methods to handle roughly forced nonlinear PDEs while preserving convergence guarantees with an oversmoothing GP kernel that is misspecified relative to the true solution's regularity. This is achieved by conditioning a regular GP to satisfy the PDE with a modified source term in a weak sense (when integrated against a finite number of test functions). This is equivalent to replacing the empirical $L^2$-loss on the PDE constraint by an empirical negative-Sobolev norm. We further show that this loss function can be used to extend physics-informed neural networks (PINNs) to stochastic equations, thereby resulting in a new NN-based variant termed Negative Sobolev Norm-PINN (NeS-PINN).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17110v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Baptista, Edoardo Calvello, Matthieu Darcy, Houman Owhadi, Andrew M. Stuart, Xianjin Yang</dc:creator>
    </item>
    <item>
      <title>Generative Adversarial Reduced Order Modelling</title>
      <link>https://arxiv.org/abs/2305.15881</link>
      <description>arXiv:2305.15881v2 Announce Type: replace-cross 
Abstract: In this work, we present GAROM, a new approach for reduced order modelling (ROM) based on generative adversarial networks (GANs). GANs have the potential to learn data distribution and generate more realistic data. While widely applied in many areas of deep learning, little research is done on their application for ROM, i.e. approximating a high-fidelity model with a simpler one. In this work, we combine the GAN and ROM framework, by introducing a data-driven generative adversarial model able to learn solutions to parametric differential equations. The latter is achieved by modelling the discriminator network as an autoencoder, extracting relevant features of the input, and applying a conditioning mechanism to the generator and discriminator networks specifying the differential equation parameters. We show how to apply our methodology for inference, provide experimental evidence of the model generalisation, and perform a convergence study of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15881v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dario Coscia, Nicola Demo, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Degrees-of-freedom penalized piecewise regression</title>
      <link>https://arxiv.org/abs/2312.16512</link>
      <description>arXiv:2312.16512v2 Announce Type: replace-cross 
Abstract: Many popular piecewise regression models rely on minimizing a cost function on the model fit with a linear penalty on the number of segments. However, this penalty does not take into account varying complexities of the model functions on the segments potentially leading to overfitting when models with varying complexities, such as polynomials of different degrees, are used. In this work, we enhance on this approach by instead using a penalty on the sum of the degrees of freedom over all segments, called degrees-of-freedom penalized piecewise regression (DofPPR). We show that the solutions of the resulting minimization problem are unique for almost all input data in a least squares setting. We develop a fast algorithm which does not only compute a minimizer but also determines an optimal hyperparameter -- in the sense of rolling cross validation with the one standard error rule -- exactly. This eliminates manual hyperparameter selection. Our method supports optional user parameters for incorporating domain knowledge. We provide an open-source Python/Rust code for the piecewise polynomial least squares case which can be extended to further models. We demonstrate the practical utility through a simulation study and by applications to real data. A constrained variant of the proposed method gives state-of-the-art results in the Turing benchmark for unsupervised changepoint detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16512v2</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Volz, Martin Storath, Andreas Weinmann</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Regularized Nonnegative Scale-invariant Low-rank Approximation Models</title>
      <link>https://arxiv.org/abs/2403.18517</link>
      <description>arXiv:2403.18517v4 Announce Type: replace-cross 
Abstract: Regularized nonnegative low-rank approximations, such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition, form an important branch of dimensionality reduction models known for their enhanced interpretability. From a practical perspective, however, selecting appropriate regularizers and regularization coefficients, as well as designing efficient algorithms, remains challenging due to the multifactor nature of these models and the limited theoretical guidance available. This paper addresses these challenges by studying a more general model, the Homogeneous Regularized Scale-Invariant model. We prove that the scale-invariance inherent to low-rank approximation models induces an implicit regularization effect that balances solutions. This insight provides a deeper understanding of the role of regularization functions in low-rank approximation models, informs the selection of regularization hyperparameters, and enables the design of balancing strategies to accelerate the empirical convergence of optimization algorithms.
  Additionally, we propose a generic Majorization-Minimization (MM) algorithm capable of handling $\ell_p^p$-regularized nonnegative low-rank approximations with non-Euclidean loss functions, with convergence guarantees. Our contributions are demonstrated on sparse Nonnegative Matrix Factorization, ridge-regularized Nonnegative Canonical Polyadic Decomposition, and sparse Nonnegative Tucker Decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18517v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy E. Cohen, Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>Coupling Fluid Plasma and Kinetic Neutral Models using Correlated Monte Carlo Methods</title>
      <link>https://arxiv.org/abs/2407.10936</link>
      <description>arXiv:2407.10936v2 Announce Type: replace-cross 
Abstract: While boundary plasmas in present-day tokamaks generally fall in a fluid regime, neutral species near the boundary often require kinetic models due to long mean-free-paths compared to characteristic spatial scales in the region. Monte-Carlo (MC) methods provide a complete, high-fidelity approach to solving kinetic models, and must be coupled to fluid plasma models to simulate the full plasma-neutrals system. The statistical nature of MC methods, however, prevents the convergence of coupled fluid-kinetic simulations to an exact self-consistent steady-state. Moreover, this forces the use of explicit methods that can suffer from numerical errors and require huge computational resources. Correlated Monte-Carlo (CMC) methods are expected to alleviate these issues but have historically enjoyed only mixed success. Here, a fully implicit method for coupled plasma-neutral systems is demonstrated in 1D using the UEDGE plasma code and a homemade CMC code. In particular, it is shown that ensuring the CMC method is a differentiable function of the background plasma is sufficient to employ a Jacobian-Free Newton-Krylov solver for implicit time steps. The convergence of the implicit coupling method is explored and compared with explicit coupling and uncorrelated methods. It is shown that ensuring differentiability by controlling random seeds in the MC is sufficient to achieve convergence, and that the use of implicit time-stepping methods has the potential for improved stability and runtimes over explicit coupling methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10936v2</guid>
      <category>physics.plasm-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory J. Parker, Maxim V. Umansky, Benjamin D. Dudson</dc:creator>
    </item>
    <item>
      <title>Distillation of Discrete Diffusion through Dimensional Correlations</title>
      <link>https://arxiv.org/abs/2410.08709</link>
      <description>arXiv:2410.08709v2 Announce Type: replace-cross 
Abstract: Diffusion models have demonstrated exceptional performances in various fields of generative modeling, but suffer from slow sampling speed due to their iterative nature. While this issue is being addressed in continuous domains, discrete diffusion models face unique challenges, particularly in capturing dependencies between elements (e.g., pixel relationships in image, sequential dependencies in language) mainly due to the computational cost of processing high-dimensional joint distributions. In this paper, (i) we propose "mixture" models for discrete diffusion that are capable of treating dimensional correlations while remaining scalable, and (ii) we provide a set of loss functions for distilling the iterations of existing models. Two primary theoretical insights underpin our approach: First, conventional models with element-wise independence can well approximate the data distribution, but essentially require many sampling steps. Second, our loss functions enable the mixture models to distill such many-step conventional models into just a few steps by learning the dimensional correlations. Our experimental results show the effectiveness of the proposed method in distilling pretrained discrete diffusion models across image and language domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08709v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Satoshi Hayakawa, Yuhta Takida, Masaaki Imaizumi, Hiromi Wakaki, Yuki Mitsufuji</dc:creator>
    </item>
  </channel>
</rss>
