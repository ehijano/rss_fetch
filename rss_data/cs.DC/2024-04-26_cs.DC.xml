<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Apr 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Rollup Comparison Framework</title>
      <link>https://arxiv.org/abs/2404.16150</link>
      <description>arXiv:2404.16150v1 Announce Type: new 
Abstract: Rollups are a popular blockchain paradigm where one blockchain network is anchored to a different blockchain network, typically though smart contracts and data commitments. The rollup executes transactions on its own network and periodically publishes them along with the state root of the rollup network. The state root is determined to be final by a protocol, often enforced by smart contracts on the anchoring blockchain, which may let the state roots be challenged or verify an accompanying validity proof. While this core functionality is universal to existing rollups, these systems have introduced unique features as they vie for users and market dominance. In this paper, we aim to classify ways in which these rollups differ in order to establish a common ground of understanding. We explore various dimensions in which these system can differ: familiarity, finality time, modularity, and maturity. The result is a framework that can be used to understand and compare the properties of rollups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16150v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Gorzny, Martin Derka</dc:creator>
    </item>
    <item>
      <title>Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services</title>
      <link>https://arxiv.org/abs/2404.16283</link>
      <description>arXiv:2404.16283v1 Announce Type: new 
Abstract: The advent of large language models (LLMs) has transformed text-based services, enabling capabilities ranging from real-time translation to AI-driven chatbots. However, existing serving systems primarily focus on optimizing server-side aggregate metrics like token generation throughput, ignoring individual user experience with streamed text. As a result, under high and/or bursty load, a significant number of users can receive unfavorable service quality or poor Quality-of-Experience (QoE). In this paper, we first formally define QoE of text streaming services, where text is delivered incrementally and interactively to users, by considering the end-to-end token delivery process throughout the entire interaction with the user. Thereafter, we propose Andes, a QoE-aware serving system that enhances user experience for LLM-enabled text streaming services. At its core, Andes strategically allocates contended GPU resources among multiple requests over time to optimize their QoE. Our evaluations demonstrate that, compared to the state-of-the-art LLM serving systems like vLLM, Andes improves the average QoE by up to 3.2$\times$ under high request rate, or alternatively, it attains up to 1.6$\times$ higher request rate while preserving high QoE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16283v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jiachen Liu, Zhiyu Wu, Jae-Won Chung, Fan Lai, Myungjin Lee, Mosharaf Chowdhury</dc:creator>
    </item>
    <item>
      <title>Dirigent: Lightweight Serverless Orchestration</title>
      <link>https://arxiv.org/abs/2404.16393</link>
      <description>arXiv:2404.16393v1 Announce Type: new 
Abstract: While Function as a Service (FaaS) platforms can initialize function sandboxes on worker nodes in 10-100s of milliseconds, the latency to schedule functions in real FaaS clusters can be orders of magnitude higher. We find that the current approach of building FaaS cluster managers on top of legacy orchestration systems like Kubernetes leads to high scheduling delay at high sandbox churn, which is typical in FaaS clusters. While generic cluster managers use hierarchical abstractions and multiple internal components to manage and reconcile state with frequent persistent updates, this becomes a bottleneck for FaaS, where cluster state frequently changes as sandboxes are created on the critical path of requests. Based on our root cause analysis of performance issues in existing FaaS cluster managers, we propose Dirigent, a clean-slate system architecture for FaaS orchestration with three key principles. First, Dirigent optimizes internal cluster manager abstractions to simplify state management. Second, it eliminates persistent state updates on the critical path of function invocations, leveraging the fact that FaaS abstracts sandboxes from users to relax exact state reconstruction guarantees. Finally, Dirigent runs monolithic control and data planes to minimize internal communication overheads and maximize throughput. We compare Dirigent to state-of-the-art FaaS platforms and show that Dirigent reduces 99th percentile per-function scheduling latency for a production workload by 2.79x compared to AWS Lambda and can spin up 2500 sandboxes per second at low latency, which is 1250x more than with Knative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16393v1</guid>
      <category>cs.DC</category>
      <category>cs.OS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lazar Cvetkovi\'c, Fran\c{c}ois Costa, Mihajlo Djokic, Michal Friedman, Ana Klimovic</dc:creator>
    </item>
    <item>
      <title>On Software Ageing Indicators in OpenStack</title>
      <link>https://arxiv.org/abs/2404.16446</link>
      <description>arXiv:2404.16446v1 Announce Type: new 
Abstract: Distributed systems in general and cloud systems in particular, are susceptible to failures that can lead to substantial economic and data losses, security breaches, and even potential threats to human safety. Software ageing is an example of one such vulnerability. It emerges due to routine re-usage of computational systems units which induce fatigue within the components, resulting in an increased failure rate and potential system breakdown. Due to its stochastic nature, ageing cannot be directly measured, instead ageing indicators as proxies are used. While there are dozens of studies on different ageing indicators, their comprehensive comparison in different settings remains underexplored. In this paper, we compare two ageing indicators in OpenStack as a use case. Specifically, our evaluation compares memory usage (including swap memory) and request response time, as readily available indicators. By executing multiple OpenStack deployments with varying configurations, we conduct a series of experiments and analyze the ageing indicators. Comparative analysis through statistical tests provides valuable insights into the strengths and weaknesses of the utilised ageing indicators. Finally, through an in-depth analysis of other OpenStack failures, we identify underlying failure patterns and their impact on the studied ageing indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16446v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yevhen Yazvinskyi, Jasmin Bogatinovski, Jorge Cardoso, Odej Kao</dc:creator>
    </item>
    <item>
      <title>Blockchain-enabled Energy Trading and Battery-based Sharing in Microgrids</title>
      <link>https://arxiv.org/abs/2404.16462</link>
      <description>arXiv:2404.16462v1 Announce Type: new 
Abstract: Carbon footprint reduction can be achieved through various methods, including the adoption of renewable energy sources. The installation of such sources, like photovoltaic panels, while environmentally beneficial, is cost-prohibitive for many. Those lacking photovoltaic solutions typically resort to purchasing energy from utility grids that often rely on fossil fuels. Moreover, when users produce their own energy, they may generate excess that goes unused, leading to inefficiencies. To address these challenges, this paper proposes innovative blockchain-enabled energy-sharing algorithms that allow consumers -- without financial means -- to access energy through the use of their own energy storage units. We explore two sharing models: a centralized method and a peer-to-peer (P2P) one. Our analysis reveals that the P2P model is more effective, enhancing the sharing process significantly compared to the centralized method. We also demonstrate that, when contrasted with traditional battery-supported trading algorithm, the P2P sharing algorithm substantially reduces wasted energy and energy purchases from the grid by 73.6%, and 12.3% respectively. The proposed system utilizes smart contracts to decentralize its structure, address the single point of failure concern, improve overall system transparency, and facilitate peer-to-peer payments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16462v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abdulrezzak Zekiye, Ouns Bouachir, \"Oznur \"Ozkasap, Moayad Aloqaily</dc:creator>
    </item>
    <item>
      <title>A Communication- and Memory-Aware Model for Load Balancing Tasks</title>
      <link>https://arxiv.org/abs/2404.16793</link>
      <description>arXiv:2404.16793v1 Announce Type: new 
Abstract: While load balancing in distributed-memory computing has been well-studied, we present an innovative approach to this problem: a unified, reduced-order model that combines three key components to describe "work" in a distributed system: computation, communication, and memory. Our model enables an optimizer to explore complex tradeoffs in task placement, such as increased parallelism at the expense of data replication, which increases memory usage. We propose a fully distributed, heuristic-based load balancing optimization algorithm, and demonstrate that it quickly finds close-to-optimal solutions. We formalize the complex optimization problem as a mixed-integer linear program, and compare it to our strategy. Finally, we show that when applied to an electromagnetics code, our approach obtains up to 2.3x speedups for the imbalanced execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16793v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Lifflander, Philippe P. Pebay, Nicole L. Slattengren, Pierre L. Pebay, Robert A. Pfeiffer, Joseph D. Kotulski, Sean T. McGovern</dc:creator>
    </item>
    <item>
      <title>ESG: Pipeline-Conscious Efficient Scheduling of DNN Workflows on Serverless Platforms with Shareable GPUs</title>
      <link>https://arxiv.org/abs/2404.16812</link>
      <description>arXiv:2404.16812v1 Announce Type: new 
Abstract: Recent years have witnessed increasing interest in machine learning inferences on serverless computing for its auto-scaling and cost effective properties. Existing serverless computing, however, lacks effective job scheduling methods to handle the schedule space dramatically expanded by GPU sharing, task batching, and inter-task relations. Prior solutions have dodged the issue by neglecting some important factors, leaving some large performance potential locked. This paper presents ESG, a new scheduling algorithm that directly addresses the difficulties. ESG treats sharable GPU as a first-order factor in scheduling. It employs an optimality-guided adaptive method by combining A*-search and a novel dual-blade pruning to dramatically prune the scheduling space without compromising the quality. It further introduces a novel method, dominator-based SLO distribution, to ensure the scalability of the scheduler. The results show that ESG can significantly improve the SLO hit rates 61%-80% while saving 47%-187% costs over prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16812v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinning Hui, Yuanchao Xu, Zhishan Guo, Xipeng Shen</dc:creator>
    </item>
    <item>
      <title>The Feasibility of Implementing Large-Scale Transformers on Multi-FPGA Platforms</title>
      <link>https://arxiv.org/abs/2404.16158</link>
      <description>arXiv:2404.16158v1 Announce Type: cross 
Abstract: FPGAs are rarely mentioned when discussing the implementation of large machine learning applications, such as Large Language Models (LLMs), in the data center. There has been much evidence showing that single FPGAs can be competitive with GPUs in performance for some computations, especially for low latency, and often much more efficient when power is considered. This suggests that there is merit to exploring the use of multiple FPGAs for large machine learning applications. The challenge with using multiple FPGAs is that there is no commonly-accepted flow for developing and deploying multi-FPGA applications, i.e., there are no tools to describe a large application, map it to multiple FPGAs and then deploy the application on a multi-FPGA platform. In this paper, we explore the feasibility of implementing large transformers using multiple FPGAs by developing a scalable multi-FPGA platform and some tools to map large applications to the platform. We validate our approach by designing an efficient multi-FPGA version of the I-BERT transformer and implement one encoder using six FPGAs as a working proof-of-concept to show that our platform and tools work. Based on our proof-of-concept prototype and the estimations of performance using the latest FPGAs compared to GPUs, we conclude that there can be a place for FPGAs in the world of large machine learning applications. We demonstrate a promising first step that shows that with the right infrastructure and tools it is reasonable to continue to explore the possible benefits of using FPGAs for applications such as LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16158v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Gao, Juan Camilo Vega, Paul Chow</dc:creator>
    </item>
    <item>
      <title>Efficient Data Management for IPFS dApps</title>
      <link>https://arxiv.org/abs/2404.16210</link>
      <description>arXiv:2404.16210v1 Announce Type: cross 
Abstract: Inefficient data management has been the Achilles heel of blockchain-based decentralized applications (dApps). An off-chain storage layer, which lies between the application and the blockchain layers, can improve space efficiency and data availability with erasure codes and decentralized maintenance. This paper presents two fundamental components of such storage layer designed and implemented for the IPFS network. The IPFS Community is a component built on top of the IPFS network that encodes and decodes data before uploading to the network. Since data is encoded with alpha entanglement codes, the solution requires less storage space than the native IPFS solution which replicates data by pinning content with the IPFS Cluster. To detect and repair failures in a timely manner, we introduce the monitoring and repair component. This novel component is activated by any node and distributes the load of repairs among various nodes. These two components are implemented as pluggable modules, and can, therefore, be easily migrated to other distributed file systems by adjusting the connector component.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16210v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vero Estrada-Gali\~nanes, Ahmad ElRouby, L\'eo Marc-Andr\'e Theytaz</dc:creator>
    </item>
    <item>
      <title>NeRF-XL: Scaling NeRFs with Multiple GPUs</title>
      <link>https://arxiv.org/abs/2404.16221</link>
      <description>arXiv:2404.16221v1 Announce Type: cross 
Abstract: We present NeRF-XL, a principled method for distributing Neural Radiance Fields (NeRFs) across multiple GPUs, thus enabling the training and rendering of NeRFs with an arbitrarily large capacity. We begin by revisiting existing multi-GPU approaches, which decompose large scenes into multiple independently trained NeRFs, and identify several fundamental issues with these methods that hinder improvements in reconstruction quality as additional computational resources (GPUs) are used in training. NeRF-XL remedies these issues and enables the training and rendering of NeRFs with an arbitrary number of parameters by simply using more hardware. At the core of our method lies a novel distributed training and rendering formulation, which is mathematically equivalent to the classic single-GPU case and minimizes communication between GPUs. By unlocking NeRFs with arbitrarily large parameter counts, our approach is the first to reveal multi-GPU scaling laws for NeRFs, showing improvements in reconstruction quality with larger parameter counts and speed improvements with more GPUs. We demonstrate the effectiveness of NeRF-XL on a wide variety of datasets, including the largest open-source dataset to date, MatrixCity, containing 258K images covering a 25km^2 city area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16221v1</guid>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.GR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruilong Li, Sanja Fidler, Angjoo Kanazawa, Francis Williams</dc:creator>
    </item>
    <item>
      <title>SECO: Secure Inference With Model Splitting Across Multi-Server Hierarchy</title>
      <link>https://arxiv.org/abs/2404.16232</link>
      <description>arXiv:2404.16232v1 Announce Type: cross 
Abstract: In the context of prediction-as-a-service, concerns about the privacy of the data and the model have been brought up and tackled via secure inference protocols. These protocols are built up by using single or multiple cryptographic tools designed under a variety of different security assumptions.
  In this paper, we introduce SECO, a secure inference protocol that enables a user holding an input data vector and multiple server nodes deployed with a split neural network model to collaboratively compute the prediction, without compromising either party's data privacy. We extend prior work on secure inference that requires the entire neural network model to be located on a single server node, to a multi-server hierarchy, where the user communicates to a gateway server node, which in turn communicates to remote server nodes. The inference task is split across the server nodes and must be performed over an encrypted copy of the data vector.
  We adopt multiparty homomorphic encryption and multiparty garbled circuit schemes, making the system secure against dishonest majority of semi-honest servers as well as protecting the partial model structure from the user. We evaluate SECO on multiple models, achieving the reduction of computation and communication cost for the user, making the protocol applicable to user's devices with limited resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16232v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Shuangyi Chen, Ashish Khisti</dc:creator>
    </item>
    <item>
      <title>Parallel and (Nearly) Work-Efficient Dynamic Programming</title>
      <link>https://arxiv.org/abs/2404.16314</link>
      <description>arXiv:2404.16314v1 Announce Type: cross 
Abstract: The idea of dynamic programming (DP), proposed by Bellman in the 1950s, is one of the most important algorithmic techniques. However, in parallel, many fundamental and sequentially simple problems become more challenging, and open to a (nearly) work-efficient solution (i.e., the work is off by at most a polylogarithmic factor over the best sequential solution). In fact, sequential DP algorithms employ many advanced optimizations such as decision monotonicity or special data structures, and achieve better work than straightforward solutions. Many such optimizations are inherently sequential, which creates extra challenges for a parallel algorithm to achieve the same work bound.
  The goal of this paper is to achieve (nearly) work-efficient parallel DP algorithms by parallelizing classic, highly-optimized and practical sequential algorithms. We show a general framework called the Cordon Algorithm for parallel DP algorithms, and use it to solve several classic problems. Our selection of problems includes Longest Increasing Subsequence (LIS), sparse Longest Common Subsequence (LCS), convex/concave generalized Least Weight Subsequence (LWS), Optimal Alphabetic Tree (OAT), and more. We show how the Cordon Algorithm can be used to achieve the same level of optimization as the sequential algorithms, and achieve good parallelism. Many of our algorithms are conceptually simple, and we show some experimental results as proofs-of-concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16314v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3626183.3659958</arxiv:DOI>
      <dc:creator>Xiangyun Ding, Yan Gu, Yihan Sun</dc:creator>
    </item>
    <item>
      <title>Byzantine Attacks Exploiting Penalties in Ethereum PoS</title>
      <link>https://arxiv.org/abs/2404.16363</link>
      <description>arXiv:2404.16363v1 Announce Type: cross 
Abstract: In May 2023, the Ethereum blockchain experienced its first inactivity leak, a mechanism designed to reinstate chain finalization amid persistent network disruptions. This mechanism aims to reduce the voting power of validators who are unreachable within the network, reallocating this power to active validators. This paper investigates the implications of the inactivity leak on safety within the Ethereum blockchain. Our theoretical analysis reveals scenarios where actions by Byzantine validators expedite the finalization of two conflicting branches, and instances where Byzantine validators reach a voting power exceeding the critical safety threshold of one-third. Additionally, we revisit the probabilistic bouncing attack, illustrating how the inactivity leak can result in a probabilistic breach of safety, potentially allowing Byzantine validators to exceed the one-third safety threshold. Our findings uncover how penalizing inactive nodes can compromise blockchain properties, particularly in the presence of Byzantine validators capable of coordinating actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16363v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulysse Pavloff, Yackolley Amoussou-Genou, Sara Tucci-Piergiovanni</dc:creator>
    </item>
    <item>
      <title>Tightening I/O Lower Bounds through the Hourglass Dependency Pattern</title>
      <link>https://arxiv.org/abs/2404.16443</link>
      <description>arXiv:2404.16443v1 Announce Type: cross 
Abstract: When designing an algorithm, one cares about arithmetic/computational complexity, but data movement (I/O) complexity plays an increasingly important role that highly impacts performance and energy consumption. For a given algorithm and a given I/O model, scheduling strategies such as loop tiling can reduce the required I/O down to a limit, called the I/O complexity, inherent to the algorithm itself. The objective of I/O complexity analysis is to compute, for a given program, its minimal I/O requirement among all valid schedules. We consider a sequential execution model with two memories, an infinite one, and a small one of size S on which the computations retrieve and produce data. The I/O is the number of reads and writes between the two memories. We identify a common "hourglass pattern" in the dependency graphs of several common linear algebra kernels. Using the properties of this pattern, we mathematically prove tighter lower bounds on their I/O complexity, which improves the previous state-of-the-art bound by a parametric ratio. This proof was integrated inside the IOLB automatic lower bound derivation tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16443v1</guid>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>36th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '24), Jun 2024, Nantes, France</arxiv:journal_reference>
      <dc:creator>Lionel Eyraud-Dubois (TOPAL), Guillaume Iooss (CORSE), Julien Langou (ROMA), Fabrice Rastello (CORSE)</dc:creator>
    </item>
    <item>
      <title>Modifying the Asynchronous Jacobi Method for Data Corruption Resilience</title>
      <link>https://arxiv.org/abs/2206.08479</link>
      <description>arXiv:2206.08479v3 Announce Type: replace 
Abstract: Moving scientific computation from high-performance computing (HPC) and cloud computing (CC) environments to devices on the edge, i.e., physically near instruments of interest, has received tremendous interest in recent years. Such edge computing environments can operate on data in-situ, offering enticing benefits over data aggregation to HPC and CC facilities that include avoiding costs of transmission, increased data privacy, and real-time data analysis. Because of the inherent unreliability of edge computing environments, new fault tolerant approaches must be developed before the benefits of edge computing can be realized. Motivated by algorithm-based fault tolerance, a variant of the asynchronous Jacobi (ASJ) method is developed that achieves resilience to data corruption by rejecting solution approximations from neighbor devices according to a bound derived from convergence theory. Numerical results on a two-dimensional Poisson problem show the new rejection criterion, along with a novel approximation to the shortest path length on which the criterion depends, restores convergence for the ASJ variant in the presence of certain types data corruption. Numerical results are obtained for when the singular values in the analytic bound are approximated. A linear system with a more dense sparsity pattern is also explored. All results indicate that successful resilience to data corruption depends on whether the bound tightens fast enough to reject corrupted data before the iteration evolution deviates significantly from that predicted by the convergence theory defining the bound. This observation generalizes to future work on algorithm-based fault tolerance for other asynchronous algorithms, including upcoming approaches that leverage Krylov subspaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08479v3</guid>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher J. Vogl, Zachary Atkins, Alyson Fox, Agnieszka Miedlar, Colin Ponce</dc:creator>
    </item>
    <item>
      <title>Benchmarking Machine Learning Applications on Heterogeneous Architecture using Reframe</title>
      <link>https://arxiv.org/abs/2404.10536</link>
      <description>arXiv:2404.10536v2 Announce Type: replace 
Abstract: With the rapid increase in machine learning workloads performed on HPC systems, it is beneficial to regularly perform machine learning specific benchmarks to monitor performance and identify issues. Furthermore, as part of the Edinburgh International Data Facility, EPCC currently hosts a wide range of machine learning accelerators including Nvidia GPUs, the Graphcore Bow Pod64 and Cerebras CS-2, which are managed via Kubernetes and Slurm. We extended the Reframe framework to support the Kubernetes scheduler backend, and utilise Reframe to perform machine learning benchmarks, and we discuss the preliminary results collected and challenges involved in integrating Reframe across multiple platforms and architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10536v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Rae, Joseph K. L. Lee, James Richings, Michele Weiland</dc:creator>
    </item>
    <item>
      <title>RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation</title>
      <link>https://arxiv.org/abs/2404.12457</link>
      <description>arXiv:2404.12457v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has shown significant improvements in various natural language processing tasks by integrating the strengths of large language models (LLMs) and external knowledge databases. However, RAG introduces long sequence generation and leads to high computation and memory costs. We propose RAGCache, a novel multilevel dynamic caching system tailored for RAG. Our analysis benchmarks current RAG systems, pinpointing the performance bottleneck (i.e., long sequence due to knowledge injection) and optimization opportunities (i.e., caching knowledge's intermediate states). Based on these insights, we design RAGCache, which organizes the intermediate states of retrieved knowledge in a knowledge tree and caches them in the GPU and host memory hierarchy. RAGCache proposes a replacement policy that is aware of LLM inference characteristics and RAG retrieval patterns. It also dynamically overlaps the retrieval and inference steps to minimize the end-to-end latency. We implement RAGCache and evaluate it on vLLM, a state-of-the-art LLM inference system and Faiss, a state-of-the-art vector database. The experimental results show that RAGCache reduces the time to first token (TTFT) by up to 4x and improves the throughput by up to 2.1x compared to vLLM integrated with Faiss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12457v2</guid>
      <category>cs.DC</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Jin, Zili Zhang, Xuanlin Jiang, Fangyue Liu, Xin Liu, Xuanzhe Liu, Xin Jin</dc:creator>
    </item>
    <item>
      <title>Frosty: Bringing strong liveness guarantees to the Snow family of consensus protocols</title>
      <link>https://arxiv.org/abs/2404.14250</link>
      <description>arXiv:2404.14250v2 Announce Type: replace 
Abstract: Snowman is the consensus protocol implemented by the Avalanche blockchain and is part of the Snow family of protocols, first introduced through the original Avalanche leaderless consensus protocol. A major advantage of Snowman is that each consensus decision only requires an expected constant communication overhead per processor in the `common' case that the protocol is not under substantial Byzantine attack, i.e. it provides a solution to the scalability problem which ensures that the expected communication overhead per processor is independent of the total number of processors $n$ during normal operation. This is the key property that would enable a consensus protocol to scale to 10,000 or more independent validators (i.e. processors). On the other hand, the two following concerns have remained:
  (1) Providing formal proofs of consistency for Snowman has presented a formidable challenge.
  (2) Liveness attacks exist in the case that a Byzantine adversary controls more than $O(\sqrt{n})$ processors, slowing termination to more than a logarithmic number of steps.
  In this paper, we address the two issues above. We consider a Byzantine adversary that controls at most $f&lt;n/5$ processors. First, we provide a simple proof of consistency for Snowman. Then we supplement Snowman with a `liveness module' that can be triggered in the case that a substantial adversary launches a liveness attack, and which guarantees liveness in this event by temporarily forgoing the communication complexity advantages of Snowman, but without sacrificing these low communication complexity advantages during normal operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14250v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Buchwald, Stephen Buttolph, Andrew Lewis-Pye, Patrick O'Grady, Kevin Sekniqi</dc:creator>
    </item>
    <item>
      <title>Cross-Silo Federated Learning for Multi-Tier Networks with Vertical and Horizontal Data Partitioning</title>
      <link>https://arxiv.org/abs/2108.08930</link>
      <description>arXiv:2108.08930v4 Announce Type: replace-cross 
Abstract: We consider federated learning in tiered communication networks. Our network model consists of a set of silos, each holding a vertical partition of the data. Each silo contains a hub and a set of clients, with the silo's vertical data shard partitioned horizontally across its clients. We propose Tiered Decentralized Coordinate Descent (TDCD), a communication-efficient decentralized training algorithm for such two-tiered networks. The clients in each silo perform multiple local gradient steps before sharing updates with their hub to reduce communication overhead. Each hub adjusts its coordinates by averaging its workers' updates, and then hubs exchange intermediate updates with one another. We present a theoretical analysis of our algorithm and show the dependence of the convergence rate on the number of vertical partitions and the number of local updates. We further validate our approach empirically via simulation-based experiments using a variety of datasets and objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.08930v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3543433</arxiv:DOI>
      <dc:creator>Anirban Das, Timothy Castiglia, Shiqiang Wang, Stacy Patterson</dc:creator>
    </item>
    <item>
      <title>Low-Latency Video Conferencing via Optimized Packet Routing and Reordering</title>
      <link>https://arxiv.org/abs/2310.05054</link>
      <description>arXiv:2310.05054v2 Announce Type: replace-cross 
Abstract: In the face of rising global demand for video meetings, managing traffic across geographically distributed (geo-distributed) data centers presents a significant challenge due to the dynamic and limited nature of inter-DC network performance. Facing these issues, this paper introduces two novel techniques, VCRoute and WMJitter, to optimize the performance of geo-distributed video conferencing systems. VCRoute is a routing method designed for audio data packets of video conferences. It treats the routing problem as a Multi-Armed Bandit issue, and utilizes a tailored Thompson Sampling algorithm for resolution. Unlike traditional approaches, VCRoute considers transmitting latency and its variance simultaneously by using Thompson Sampling algorithm, which leads to effective end-to-end latency optimization. In conjunction with VCRoute, we present WMJitter, a watermark-based mechanism for managing network jitter, which can further reduce the end-to-end delay and keep an improved balance between latency and loss rate. Evaluations based on real geo-distributed network performance demonstrate the effectiveness and scalability of VCRoute and WMJitter, offering robust solutions for optimizing video conferencing systems in geo-distributed settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05054v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Xiao, Sitian Chen, Amelie Chi Zhou, Shuhao Zhang, Yi Wang, Rui Mao, Xuan Yang</dc:creator>
    </item>
    <item>
      <title>A Grassroots Architecture to Supplant Global Digital Platforms by a Global Digital Democracy</title>
      <link>https://arxiv.org/abs/2404.13468</link>
      <description>arXiv:2404.13468v2 Announce Type: replace-cross 
Abstract: We present an architectural alternative to global digital platforms termed grassroots, designed to serve the social, economic, civic, and political needs of local digital communities, as well as their federation. Grassroots platforms may offer local communities an alternative to global digital platforms while operating solely on the smartphones of their members, forsaking any global resources other than the network itself. Such communities may form digital economies without initial capital or external credit, exercise sovereign democratic governance, and federate, ultimately resulting in the grassroots formation of a global digital democracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13468v2</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>NeuraChip: Accelerating GNN Computations with a Hash-based Decoupled Spatial Accelerator</title>
      <link>https://arxiv.org/abs/2404.15510</link>
      <description>arXiv:2404.15510v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) are emerging as a formidable tool for processing non-euclidean data across various domains, ranging from social network analysis to bioinformatics. Despite their effectiveness, their adoption has not been pervasive because of scalability challenges associated with large-scale graph datasets, particularly when leveraging message passing.
  To tackle these challenges, we introduce NeuraChip, a novel GNN spatial accelerator based on Gustavson's algorithm. NeuraChip decouples the multiplication and addition computations in sparse matrix multiplication. This separation allows for independent exploitation of their unique data dependencies, facilitating efficient resource allocation. We introduce a rolling eviction strategy to mitigate data idling in on-chip memory as well as address the prevalent issue of memory bloat in sparse graph computations. Furthermore, the compute resource load balancing is achieved through a dynamic reseeding hash-based mapping, ensuring uniform utilization of computing resources agnostic of sparsity patterns. Finally, we present NeuraSim, an open-source, cycle-accurate, multi-threaded, modular simulator for comprehensive performance analysis.
  Overall, NeuraChip presents a significant improvement, yielding an average speedup of 22.1x over Intel's MKL, 17.1x over NVIDIA's cuSPARSE, 16.7x over AMD's hipSPARSE, and 1.5x over prior state-of-the-art SpGEMM accelerator and 1.3x over GNN accelerator. The source code for our open-sourced simulator and performance visualizer is publicly accessible on GitHub https://neurachip.us</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15510v2</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaustubh Shivdikar, Nicolas Bohm Agostini, Malith Jayaweera, Gilbert Jonatan, Jose L. Abellan, Ajay Joshi, John Kim, David Kaeli</dc:creator>
    </item>
    <item>
      <title>Replacing Cryptopuzzles with Useful Computation in Blockchain Proof-of-Work Protocols</title>
      <link>https://arxiv.org/abs/2404.15735</link>
      <description>arXiv:2404.15735v2 Announce Type: replace-cross 
Abstract: Proof-of-Work (PoW) blockchains have emerged as a robust and effective consensus mechanism in open environments like the Internet, leading to widespread deployment with numerous cryptocurrency platforms and substantial investments. However, the current PoW implementation primarily focuses on validating the discovery of a winning nonce. Exploring the notion of replacing cryptographic puzzles with useful computing tasks becomes compelling, given the substantial computational capacity of blockchain networks and the global pursuit of a more sustainable IT infrastructure. In this study, we conduct a comprehensive analysis of the prerequisites for alternative classes of tasks, examining proposed designs from existing literature in light of these requirements. We distill pertinent techniques and address gaps in the current state-of-the-art, providing valuable insights into the evolution of consensus mechanisms beyond traditional PoW.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15735v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Merlina, Thiago Garrett, Roman Vitenberg</dc:creator>
    </item>
  </channel>
</rss>
