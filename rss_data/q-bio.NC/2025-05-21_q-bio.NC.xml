<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 May 2025 01:48:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>ReBaCCA-ss: Relevance-Balanced Continuum Correlation Analysis with Smoothing and Surrogating for Quantifying Similarity Between Population Spiking Activities</title>
      <link>https://arxiv.org/abs/2505.13748</link>
      <description>arXiv:2505.13748v1 Announce Type: new 
Abstract: Quantifying similarity between population spike patterns is essential for understanding how neural dynamics encode information. Traditional approaches, which combine kernel smoothing, PCA, and CCA, have limitations: smoothing kernel bandwidths are often empirically chosen, CCA maximizes alignment between patterns without considering the variance explained within patterns, and baseline correlations from stochastic spiking are rarely corrected. We introduce ReBaCCA-ss (Relevance-Balanced Continuum Correlation Analysis with smoothing and surrogating), a novel framework that addresses these challenges through three innovations: (1) balancing alignment and variance explanation via continuum canonical correlation; (2) correcting for noise using surrogate spike trains; and (3) selecting the optimal kernel bandwidth by maximizing the difference between true and surrogate correlations. ReBaCCA-ss is validated on both simulated data and hippocampal recordings from rats performing a Delayed Nonmatch-to-Sample task. It reliably identifies spatio-temporal similarities between spike patterns. Combined with Multidimensional Scaling, ReBaCCA-ss reveals structured neural representations across trials, events, sessions, and animals, offering a powerful tool for neural population analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13748v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiang Zhang, Chenlin Xu, Zhouxiao Lu, Haonan Wang, Dong Song</dc:creator>
    </item>
    <item>
      <title>Investigation of the neural origin of non-Euclidean visual space and analysis of visual phenomena using information geometry</title>
      <link>https://arxiv.org/abs/2505.13917</link>
      <description>arXiv:2505.13917v1 Announce Type: new 
Abstract: The present paper aims to develop a mathematical model concerning the visual perception of spatial information. It is a challenging problem in theoretical neuroscience to investigate how the spatial information of the objects in the physical space is encoded and decoded in the neural processes in the brain. In the past, researchers conjectured the existence of an abstract visual space where spatial information processing takes place. Based on several experimental data it was conjectured that the said psychological manifold is non-Euclidean. However, the consideration of the neural origin of the non-Euclidean character of the visual space was not explicit in the models. In the present paper, we showed that the neural mechanism and specifically the Fisher information contained in the neural population code plays the role of energy-momentum tensor to create the space-dependent metric tensor resulting in a curved space described by a curvature tensor. The theoretical prediction of information geometry regarding the emergence of curved manifolds in the presence of the Fisher information is verified in the present work in the domain of neural processing of spatial information at mid-level vision. Several well-known phenomena of visual optics are analyzed using the notion of non-Euclidean visual space, the geodesics of the space, and the Fisher-Rao metric as the suitable psychometric distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13917v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Debasis Mazumdar, Kuntal Ghosh, Soma Mitra, Late Kamales Bhaumik</dc:creator>
    </item>
    <item>
      <title>From the perceptron to the cerebellum</title>
      <link>https://arxiv.org/abs/2505.14355</link>
      <description>arXiv:2505.14355v1 Announce Type: new 
Abstract: The perceptron has served as a prototypical neuronal learning machine in the physics community interested in neural networks and artificial intelligence, which included G\'erard Toulouse as one of its prominent figures. It has also been used as a model of Purkinje cells of the cerebellum, a brain structure involved in motor learning, in the early influential theories of David Marr and James Albus. We review these theories, more recent developments in the field, and highlight questions of current interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14355v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.bio-ph</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicolas Brunel, Vincent Hakim, Jean-Pierre Nadal</dc:creator>
    </item>
    <item>
      <title>The nature of quantum parallel processing and its implications for coding in brain neural networks: a novel computational mechanism</title>
      <link>https://arxiv.org/abs/2505.14503</link>
      <description>arXiv:2505.14503v1 Announce Type: new 
Abstract: Conventionally it is assumed that the nerve impulse is an electrical process based upon the observation that electrical stimuli produce an action potential as defined by Hodgkin Huxley (1952) (HH). Consequently, investigations into the computation of nerve impulses have almost universally been directed to electrically observed phenomenon. However, models of computation are fundamentally flawed and assume that an undiscovered timing system exists within the nervous system. In our view it is synchronisation of the action potential pulse (APPulse) that effects computation. The APPulse, a soliton pulse, is a novel purveyor of computation and is a quantum mechanical pulse: i.e. It is a non-Turing synchronised computational event. Furthermore, the APPulse computational interactions change frequencies measured in microseconds, rather than milliseconds, producing effective efficient computation. However, the HH action potential is a necessary component for entropy equilibrium, providing energy to open ion channels, but it is too slow to be functionally computational in a neural network. Here, we demonstrate that only quantum non-electrical soliton pulses converging to points of computation are the main computational structure with synaptic transmission occurring at slower millisecond speeds. Thus, the APPulse accompanying the action potential is the purveyor of computation; a novel computational mechanism, that is incompatible with Turing timed computation and artificial intelligence (AI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14503v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew S Johnson, William Winlow</dc:creator>
    </item>
    <item>
      <title>Inference with correlated priors using sisters cells</title>
      <link>https://arxiv.org/abs/2505.14579</link>
      <description>arXiv:2505.14579v1 Announce Type: new 
Abstract: A common view of sensory processing is as probabilistic inference of latent causes from receptor activations. Standard approaches often assume these causes are a priori independent, yet real-world generative factors are typically correlated. Representing such structured priors in neural systems poses architectural challenges, particularly when direct interactions between units representing latent causes are biologically implausible or computationally expensive. Inspired by the architecture of the olfactory bulb, we propose a novel circuit motif that enables inference with correlated priors without requiring direct interactions among latent cause units. The key insight lies in using sister cells: neurons receiving shared receptor input but connected differently to local interneurons. The required interactions among latent units are implemented indirectly through their connections to the sister cells, such that correlated connectivity implies anti-correlation in the prior and vice versa. We use geometric arguments to construct connectivity that implements a given prior and to bound the number of causes for which such priors can be constructed. Using simulations, we demonstrate the efficacy of such priors for inference in noisy environments and compare the inference dynamics to those experimentally observed. Finally, we show how, under certain assumptions on latent representations, the prior used can be inferred from sister cell activations. While biologically grounded in the olfactory system, our mechanism generalises to other natural and artificial sensory systems and may inform the design of architectures for efficient inference under correlated latent structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14579v1</guid>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sina Tootoonian, Andreas T. Schaefer</dc:creator>
    </item>
    <item>
      <title>Learning Dynamics of RNNs in Closed-Loop Environments</title>
      <link>https://arxiv.org/abs/2505.13567</link>
      <description>arXiv:2505.13567v1 Announce Type: cross 
Abstract: Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer powerful models of brain computation. However, typical training paradigms rely on open-loop, supervised settings, whereas real-world learning unfolds in closed-loop environments. Here, we develop a mathematical theory describing the learning dynamics of linear RNNs trained in closed-loop contexts. We first demonstrate that two otherwise identical RNNs, trained in either closed- or open-loop modes, follow markedly different learning trajectories. To probe this divergence, we analytically characterize the closed-loop case, revealing distinct stages aligned with the evolution of the training loss. Specifically, we show that the learning dynamics of closed-loop RNNs, in contrast to open-loop ones, are governed by an interplay between two competing objectives: short-term policy improvement and long-term stability of the agent-environment interaction. Finally, we apply our framework to a realistic motor control task, highlighting its broader applicability. Taken together, our results underscore the importance of modeling closed-loop dynamics in a biologically plausible setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13567v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoav Ger, Omri Barak</dc:creator>
    </item>
    <item>
      <title>Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations</title>
      <link>https://arxiv.org/abs/2505.13763</link>
      <description>arXiv:2505.13763v1 Announce Type: cross 
Abstract: Large language models (LLMs) can sometimes report the strategies they actually use to solve tasks, but they can also fail to do so. This suggests some degree of metacognition -- the capacity to monitor one's own cognitive processes for subsequent reporting and self-control. Metacognitive abilities enhance AI capabilities but raise safety concerns, as models might obscure their internal processes to evade neural-activation-based oversight mechanisms designed to detect harmful behaviors. Given society's increased reliance on these models, it is critical that we understand the limits of their metacognitive abilities, particularly their ability to monitor their internal activations. To address this, we introduce a neuroscience-inspired neurofeedback paradigm designed to quantify the ability of LLMs to explicitly report and control their activation patterns. By presenting models with sentence-label pairs where labels correspond to sentence-elicited internal activations along specific directions in the neural representation space, we demonstrate that LLMs can learn to report and control these activations. The performance varies with several factors: the number of example pairs provided, the semantic interpretability of the target neural direction, and the variance explained by that direction. These results reveal a "metacognitive space" with dimensionality much lower than the model's neural space, suggesting LLMs can monitor only a subset of their neural mechanisms. Our findings provide empirical evidence quantifying metacognitive capabilities in LLMs, with significant implications for AI safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13763v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Ji-An, Hua-Dong Xiong, Robert C. Wilson, Marcelo G. Mattar, Marcus K. Benna</dc:creator>
    </item>
    <item>
      <title>Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning</title>
      <link>https://arxiv.org/abs/2505.14125</link>
      <description>arXiv:2505.14125v1 Announce Type: cross 
Abstract: Biological brains learn continually from a stream of unlabeled data, while integrating specialized information from sparsely labeled examples without compromising their ability to generalize. Meanwhile, machine learning methods are susceptible to catastrophic forgetting in this natural learning setting, as supervised specialist fine-tuning degrades performance on the original task. We introduce task-modulated contrastive learning (TMCL), which takes inspiration from the biophysical machinery in the neocortex, using predictive coding principles to integrate top-down information continually and without supervision. We follow the idea that these principles build a view-invariant representation space, and that this can be implemented using a contrastive loss. Then, whenever labeled samples of a new class occur, new affine modulations are learned that improve separation of the new class from all others, without affecting feedforward weights. By co-opting the view-invariance learning mechanism, we then train feedforward weights to match the unmodulated representation of a data sample to its modulated counterparts. This introduces modulation invariance into the representation space, and, by also using past modulations, stabilizes it. Our experiments show improvements in both class-incremental and transfer learning over state-of-the-art unsupervised approaches, as well as over comparable supervised approaches, using as few as 1% of available labels. Taken together, our work suggests that top-down modulations play a crucial role in balancing stability and plasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14125v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viet Anh Khoa Tran, Emre Neftci, Willem. A. M. Wybo</dc:creator>
    </item>
    <item>
      <title>Beginning with You: Perceptual-Initialization Improves Vision-Language Representation and Alignment</title>
      <link>https://arxiv.org/abs/2505.14204</link>
      <description>arXiv:2505.14204v1 Announce Type: cross 
Abstract: We introduce Perceptual-Initialization (PI), a paradigm shift in visual representation learning that incorporates human perceptual structure during the initialization phase rather than as a downstream fine-tuning step. By integrating human-derived triplet embeddings from the NIGHTS dataset to initialize a CLIP vision encoder, followed by self-supervised learning on YFCC15M, our approach demonstrates significant zero-shot performance improvements, without any task-specific fine-tuning, across 29 zero shot classification and 2 retrieval benchmarks. On ImageNet-1K, zero-shot gains emerge after approximately 15 epochs of pretraining. Benefits are observed across datasets of various scales, with improvements manifesting at different stages of the pretraining process depending on dataset characteristics. Our approach consistently enhances zero-shot top-1 accuracy, top-5 accuracy, and retrieval recall (e.g., R@1, R@5) across these diverse evaluation tasks, without requiring any adaptation to target domains. These findings challenge the conventional wisdom of using human-perceptual data primarily for fine-tuning and demonstrate that embedding human perceptual structure during early representation learning yields more capable and vision-language aligned systems that generalize immediately to unseen tasks. Our work shows that "beginning with you", starting with human perception, provides a stronger foundation for general-purpose vision-language intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14204v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Hu, Runchen Wang, Stephen Chong Zhao, Xuhui Zhan, Do Hun Kim, Mark Wallace, David A. Tovar</dc:creator>
    </item>
    <item>
      <title>Inward rectifier potassium channels interact with calcium channels to promote robust and physiological bistability</title>
      <link>https://arxiv.org/abs/2411.14107</link>
      <description>arXiv:2411.14107v2 Announce Type: replace 
Abstract: In the dorsal horn, projection neurons play a crucial role in pain processing by transmitting sensory stimuli to supraspinal centers during nociception. Following exposure to intense noxious stimuli, a sensitization process occurs that alters the functional state of the dorsal horn. Notably, projection neurons can undergo a switch in firing pattern -- from tonic firing to plateau potentials with sustained afterdischarges. For afterdischarges to occur following this switch, the neuron must exhibit bistability, defined as the ability to exhibit resting and spiking states at the same input current depending on the prior context. In many cases, neuronal bistability arises through the activity of voltage-gated calcium channels. However, computational studies have shown a trade-off between bistability and the plausibility of resting states when calcium channels are counterbalanced by voltage-gated potassium channels. Despite this, the mechanisms underlying the emergence of robust bistability, plateau potentials, and sustained afterdischarges through calcium channels remain poorly understood. In this study, we used a conductance-based model to investigate how L-type calcium (CaL) channels can give rise to bistability when combined with either M-type potassium (KM) channels or inward-rectifying potassium (Kir) channels. Unlike KM channels, Kir channels enhance bistability. When combined with CaL channels, KM and Kir channels promote distinct forms of bistability, differing in both robustness and functional implications. An analysis of their inward and outward current properties revealed that these differences stem from their distinct steady-state current profiles. Altogether, the complementarity between CaL and Kir channels provides a robust mechanism for central sensitization in the dorsal horn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14107v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ana\"elle De Worm, Guillaume Drion, Pierre Sacr\'e</dc:creator>
    </item>
    <item>
      <title>Low Dimensional Dynamics of Globally Coupled Complex Riccati Equations: Exact Firing-rate Equations for Spiking Neurons with Clustered Substructure</title>
      <link>https://arxiv.org/abs/2503.15537</link>
      <description>arXiv:2503.15537v2 Announce Type: replace 
Abstract: We report on an exact theory for ensembles of globally coupled, heterogeneous complex Riccati equations. A drastic dimensionality reduction to a few ordinary differential equations is achieved for Lorentzian heterogeneity. By applying this technique, we obtain low-dimensional firing-rate equations for populations of spiking neurons with a clustered substructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15537v2</guid>
      <category>q-bio.NC</category>
      <category>nlin.SI</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.111.L052201</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E 111, L052201 (2025)</arxiv:journal_reference>
      <dc:creator>Diego Paz\'o, Rok Cestnik</dc:creator>
    </item>
    <item>
      <title>Low-dimensional representation of brain networks for seizure risk forecasting</title>
      <link>https://arxiv.org/abs/2505.00856</link>
      <description>arXiv:2505.00856v2 Announce Type: replace 
Abstract: Identifying preictal states -- periods during which seizures are more likely to occur -- remains a central challenge in clinical computational neuroscience. In this study, we introduce a novel framework that embeds functional brain connectivity networks, derived from intracranial EEG (iEEG) recordings, into a low-dimensional Euclidean space. This compact representation captures essential topological features of brain dynamics and facilitates the detection of subtle connectivity changes preceding seizures. Using standard machine learning techniques, we define a dimensionless biomarker, $\mathcal{B}$, that discriminates between interictal (seizure-free) and preictal (within 24 hours of seizure) network states. Our method focuses on connectivity patterns among a subset of informative iEEG electrodes, enabling robust classification of brain states across time. We validate our approach using a leave-one-out cross-validation scheme and a pseudo-prospective forecasting strategy, assessing performance with metrics such as F1-score and balanced accuracy. Results show that low-dimensional Euclidean embeddings of iEEG connectivity yield interpretable and predictive markers of preictal activity, offering promising implications for real-time seizure forecasting and individualized therapeutic interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00856v2</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Rico-Aparicio, Martin Guillemaud, Alice Longhena, Vincent Navarro, Louis Cousyn, Mario Chavez</dc:creator>
    </item>
    <item>
      <title>Burstiness and interpersonal foraging between human infants and caregivers in the vocal domain</title>
      <link>https://arxiv.org/abs/2505.01545</link>
      <description>arXiv:2505.01545v2 Announce Type: replace 
Abstract: Vocal responses from caregivers are believed to promote more frequent and more advanced infant vocalizations. However, studies that examine this relationship typically do not account for the fact that infant and adult vocalizations are distributed in hierarchical clusters over the course of the day. These bursts and lulls create a challenge for accurately detecting the effects of adult input at immediate turn-by-turn timescales within real-world behavior, as adult responses tend to happen during already occurring bursts of infant vocalizations. Analyzing daylong audio recordings of real-world vocal communication between human infants (ages 3, 6, 9, and 18 months) and their adult caregivers, we first show that both infant and caregiver vocalization events are clustered in time, as evidenced by positive correlations between successive inter-event intervals (IEIs). We propose an approach informed by flight time analyses in foraging studies to assess whether the timing of a vocal agent's next vocalization is modified by inputs from another vocal agent, controlling for the first agent's previous IEI. For both infants and adults, receiving a social response predicts that the individual will vocalize again sooner than they would have in the absence of a response. Overall, our results are consistent with a view of infant-caregiver vocal interactions as an 'interpersonal foraging' process with inherent multi-scale dynamics wherein social responses are among the resources the individuals are foraging for. The analytic approaches introduced here have broad utility to study communication in other modalities, contexts, and species.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01545v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>VPS Ritwika, Sara Schneider, Lukas D. Lopez, Jeffrey Mai, Ajay Gopinathan, Christopher T. Kello, Anne S. Warlaumont</dc:creator>
    </item>
  </channel>
</rss>
