<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 01:47:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dendritic Computing with Multi-Gate Ferroelectric Field-Effect Transistors</title>
      <link>https://arxiv.org/abs/2505.01635</link>
      <description>arXiv:2505.01635v1 Announce Type: new 
Abstract: Although inspired by neuronal systems in the brain, artificial neural networks generally employ point-neurons, which offer far less computational complexity than their biological counterparts. Neurons have dendritic arbors that connect to different sets of synapses and offer local non-linear accumulation - playing a pivotal role in processing and learning. Inspired by this, we propose a novel neuron design based on a multi-gate ferroelectric field-effect transistor that mimics dendrites. It leverages ferroelectric nonlinearity for local computations within dendritic branches, while utilizing the transistor action to generate the final neuronal output. The branched architecture paves the way for utilizing smaller crossbar arrays in hardware integration, leading to greater efficiency. Using an experimentally calibrated device-circuit-algorithm co-simulation framework, we demonstrate that networks incorporating our dendritic neurons achieve superior performance in comparison to much larger networks without dendrites ($\sim$17$\times$ fewer trainable weight parameters). These findings suggest that dendritic hardware can significantly improve computational efficiency, and learning capacity of neuromorphic systems optimized for edge applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01635v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A N M Nafiul Islam, Xuezhong Niu, Jiahui Duan, Shubham Kumar, Kai Ni, Abhronil Sengupta</dc:creator>
    </item>
    <item>
      <title>Brain-Inspired Quantum Neural Architectures for Pattern Recognition: Integrating QSNN and QLSTM</title>
      <link>https://arxiv.org/abs/2505.01735</link>
      <description>arXiv:2505.01735v1 Announce Type: new 
Abstract: Recent advances in the fields of deep learning and quantum computing have paved the way for innovative developments in artificial intelligence. In this manuscript, we leverage these cutting-edge technologies to introduce a novel model that emulates the intricate functioning of the human brain, designed specifically for the detection of anomalies such as fraud in credit card transactions. Leveraging the synergies of Quantum Spiking Neural Networks (QSNN) and Quantum Long Short-Term Memory (QLSTM) architectures, our approach is developed in two distinct stages, closely mirroring the information processing mechanisms found in the brain's sensory and memory systems. In the initial stage, similar to the brain's hypothalamus, we extract low-level information from the data, emulating sensory data processing patterns. In the subsequent stage, resembling the hippocampus, we process this information at a higher level, capturing and memorizing correlated patterns. We will compare this model with other quantum models such as Quantum Neural Networks among others and their corresponding classical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01735v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Andr\'es, Manuel Pegalajar Cu\'ellar, Gabriel Navarro</dc:creator>
    </item>
    <item>
      <title>Content Addressable Memory Design with Reference Resistor for Improved Search Resolution</title>
      <link>https://arxiv.org/abs/2505.02285</link>
      <description>arXiv:2505.02285v1 Announce Type: new 
Abstract: Despite the parallel in-memory search capabilities of content addressable memories (CAMs), their use in applications is constrained by their limited resolution that worsens as they are scaled to larger arrays or advanced nodes. In this work we present experimental results for a novel back-end-of-line compatible reference resistive device that can significantly improve the search resolution of CAMs implemented with CMOS and beyond-CMOS technologies to less than or equal to 5-bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02285v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siri Narla, Steven J. Koester, Rebecca A. Dawley, Ageeth A. Bol, Piyush Kumar, Azad Naeemi</dc:creator>
    </item>
    <item>
      <title>LLM-Enabled EV Charging Stations Recommendation</title>
      <link>https://arxiv.org/abs/2505.01447</link>
      <description>arXiv:2505.01447v1 Announce Type: cross 
Abstract: Charging infrastructure is not expanding quickly enough to accommodate the increasing usage of Electric Vehicles (EVs). For this reason, EV owners experience extended waiting periods, range anxiety, and overall dissatisfaction. Challenges, such as fragmented data and the complexity of integrating factors like location, energy pricing, and user preferences, make the current recommendation systems ineffective. To overcome these limitations, we propose RecomBot, which is a Large Language Model (LLM)-powered prompt-based recommender system that dynamically suggests optimal Charging Stations (CSs) using real-time heterogeneous data. By leveraging natural language reasoning and fine-tuning EV-specific datasets, RecomBot enhances personalization, improves charging efficiency, and adapts to various EV types, offering a scalable solution for intelligent EV recommendation systems. Through testing across various prompt engineering scenarios, the results obtained underline the capability and efficiency of the proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01447v1</guid>
      <category>cs.IR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeinab Teimoori</dc:creator>
    </item>
    <item>
      <title>Quantum-Assisted Vehicle Routing: Realizing QAOA-based Approach on Gate-Based Quantum Computer</title>
      <link>https://arxiv.org/abs/2505.01614</link>
      <description>arXiv:2505.01614v1 Announce Type: cross 
Abstract: The Vehicle Routing Problem (VRP) is a crucial optimization challenge with significant economic and environmental implications, particularly in logistics and transportation planning. While classical algorithms struggle to efficiently solve large-scale instances of VRP due to its combinatorial complexity, quantum computing presents a promising alternative for tackling such problems. In this work, we explore the application of the Quantum Approximate Optimization Algorithm (QAOA) to solve instances of VRP, analyzing its effectiveness and scalability. We formulate VRP as a Quadratic Unconstrained Binary Optimization (QUBO) problem by encoding the constraints into a single cost function suitable for QAOA. Our study investigates the impact of problem size on quantum circuit complexity and evaluate the feasibility of executing QAOA-based VRP solutions on near-term quantum hardware. The results indicate that while QAOA demonstrates potential for solving VRP, the primary limitation lies in circuit depth and noise-induced errors, which critically affect performance on current quantum processors. Overcoming these challenges will require advancements in error mitigation techniques and more efficient quantum circuit designs to realize the full potential of quantum computing for combinatorial optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01614v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Talha Azfar, Ruimin Ke, Osama Muhammad Raisuddin, Jose Holguin-Veras</dc:creator>
    </item>
    <item>
      <title>Divide-and-Conquer Simulation of Open Quantum Systems</title>
      <link>https://arxiv.org/abs/2505.01623</link>
      <description>arXiv:2505.01623v1 Announce Type: cross 
Abstract: One of the promises of quantum computing is to simulate physical systems efficiently. However, the simulation of open quantum systems - where interactions with the environment play a crucial role - remains challenging for quantum computing, as it is impossible to implement deterministically non-unitary operators on a quantum computer without auxiliary qubits. The Stinespring dilation can simulate an open dynamic but requires a high circuit depth, which is impractical for NISQ devices. An alternative approach is parallel probabilistic block-encoding methods, such as the Sz.-Nagy and Singular Value Decomposition dilations. These methods result in shallower circuits but are hybrid methods, and we do not simulate the quantum dynamic on the quantum computer. In this work, we describe a divide-and-conquer strategy for preparing mixed states to combine the output of each Kraus operator dilation and obtain the complete dynamic on quantum hardware with a lower circuit depth. The work also introduces a balanced strategy that groups the original Kraus operators into an expanded operator, leading to a trade-off between circuit depth, CNOT count, and number of qubits. We perform a computational analysis to demonstrate the advantages of the new method and present a proof-of-concept simulation of the Fenna-Matthews-Olson dynamic on current quantum hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01623v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Melo D. Azevedo, Caio Almeida, Pedro Linck, Adenilton J. da Silva, Nadja K. Bernardes</dc:creator>
    </item>
    <item>
      <title>PhytoSynth: Leveraging Multi-modal Generative Models for Crop Disease Data Generation with Novel Benchmarking and Prompt Engineering Approach</title>
      <link>https://arxiv.org/abs/2505.01823</link>
      <description>arXiv:2505.01823v1 Announce Type: cross 
Abstract: Collecting large-scale crop disease images in the field is labor-intensive and time-consuming. Generative models (GMs) offer an alternative by creating synthetic samples that resemble real-world images. However, existing research primarily relies on Generative Adversarial Networks (GANs)-based image-to-image translation and lack a comprehensive analysis of computational requirements in agriculture. Therefore, this research explores a multi-modal text-to-image approach for generating synthetic crop disease images and is the first to provide computational benchmarking in this context. We trained three Stable Diffusion (SD) variants-SDXL, SD3.5M (medium), and SD3.5L (large)-and fine-tuned them using Dreambooth and Low-Rank Adaptation (LoRA) fine-tuning techniques to enhance generalization. SD3.5M outperformed the others, with an average memory usage of 18 GB, power consumption of 180 W, and total energy use of 1.02 kWh/500 images (0.002 kWh per image) during inference task. Our results demonstrate SD3.5M's ability to generate 500 synthetic images from just 36 in-field samples in 1.5 hours. We recommend SD3.5M for efficient crop disease data generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01823v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitin Rai, Arnold W. Schumann, Nathan Boyd</dc:creator>
    </item>
    <item>
      <title>Closed-loop control of seizure activity via real-time seizure forecasting by reservoir neuromorphic computing</title>
      <link>https://arxiv.org/abs/2505.02003</link>
      <description>arXiv:2505.02003v1 Announce Type: cross 
Abstract: Closed-loop brain stimulation holds potential as personalized treatment for drug-resistant epilepsy (DRE) but still suffers from limitations that result in highly variable efficacy. First, stimulation is typically delivered upon detection of the seizure to abort rather than prevent it; second, the stimulation parameters are established by trial and error, requiring lengthy rounds of fine-tuning, which delay steady-state therapeutic efficacy. Here, we address these limitations by leveraging the potential of neuromorphic computing. We present a system capable of driving personalized free-run stimulations based on seizure forecasting, wherein each forecast triggers an electrical pulse rather than an arbitrarily predefined fixed-frequency stimulus train. We validate the system against hippocampal spheroids coupled to 3D microelectrode array as a simplified testbed, showing that it can achieve seizure reduction &gt;97% while primarily using instantaneous stimulation frequencies within 20 Hz, well below what typically used in clinical settings. Our work demonstrates the potential of neuromorphic systems as a next-generation neuromodulation strategy for personalized DRE treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02003v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maryam Sadeghi, Dar\'io Fern\'andez Khatiboun, Yasser Rezaeiyan, Saima Rizwan, Alessandro Barcellona, Andrea Merello, Marco Crepaldi, Gabriella Panuccio, Farshad Moradi</dc:creator>
    </item>
    <item>
      <title>Triple-identity Authentication: The Future of Secure Access</title>
      <link>https://arxiv.org/abs/2505.02004</link>
      <description>arXiv:2505.02004v1 Announce Type: cross 
Abstract: In a typical authentication process, the local system verifies the user's identity using a stored hash value generated by a cross-system hash algorithm. This article shifts the research focus from traditional password encryption to the establishment of gatekeeping mechanisms for effective interactions between a system and the outside world. Here, we propose a triple-identity authentication system to achieve this goal. Specifically, this local system opens the inner structure of its hash algorithm to all user credentials, including the login name, login password, and authentication password. When a login credential is entered, the local system hashes it and then creates a unique identifier using intermediate hash elements randomly selected from the open algorithm. Importantly, this locally generated unique identifier (rather than the stored hash produced by the open algorithm) is utilized to verify the user's combined identity, which is generated by combining the entered credential with the International Mobile Equipment Identity and the International Mobile Subscriber Identity. The verification process is implemented at each interaction point: the login name field, the login password field, and the server's authentication point. Thus, within the context of this triple-identity authentication system, we establish a robust gatekeeping mechanism for system interactions, ultimately providing a level of security that is equivalent to multi-factor authentication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02004v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Suyun Borjigin</dc:creator>
    </item>
    <item>
      <title>Student Perspectives on the Benefits and Risks of AI in Education</title>
      <link>https://arxiv.org/abs/2505.02198</link>
      <description>arXiv:2505.02198v1 Announce Type: cross 
Abstract: The use of chatbots equipped with artificial intelligence (AI) in educational settings has increased in recent years, showing potential to support teaching and learning. However, the adoption of these technologies has raised concerns about their impact on academic integrity, students' ability to problem-solve independently, and potential underlying biases. To better understand students' perspectives and experiences with these tools, a survey was conducted at a large public university in the United States. Through thematic analysis, 262 undergraduate students' responses regarding their perceived benefits and risks of AI chatbots in education were identified and categorized into themes.
  The results discuss several benefits identified by the students, with feedback and study support, instruction capabilities, and access to information being the most cited. Their primary concerns included risks to academic integrity, accuracy of information, loss of critical thinking skills, the potential development of overreliance, and ethical considerations such as data privacy, system bias, environmental impact, and preservation of human elements in education.
  While student perceptions align with previously discussed benefits and risks of AI in education, they show heightened concerns about distinguishing between human and AI generated work - particularly in cases where authentic work is flagged as AI-generated. To address students' concerns, institutions can establish clear policies regarding AI use and develop curriculum around AI literacy. With these in place, practitioners can effectively develop and implement educational systems that leverage AI's potential in areas such as immediate feedback and personalized learning support. This approach can enhance the quality of students' educational experiences while preserving the integrity of the learning process with AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02198v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Griffin Pitts, Viktoria Marcus, Sanaz Motamedi</dc:creator>
    </item>
    <item>
      <title>Beyond the model: Key differentiators in large language models and multi-agent services</title>
      <link>https://arxiv.org/abs/2505.02489</link>
      <description>arXiv:2505.02489v1 Announce Type: cross 
Abstract: With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, it has become evident that large language models (LLMs) are no longer the sole defining factor in generative AI. As many now operate at comparable levels of capability, the real race is not about having the biggest model but optimizing the surrounding ecosystem, including data quality and management, computational efficiency, latency, and evaluation frameworks. This review article delves into these critical differentiators that ensure modern AI services are efficient and profitable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02489v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SE</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.30574/wjarr.2025.26.1.1295</arxiv:DOI>
      <arxiv:journal_reference>World Journal of Advanced Research and Reviews, 2025, 26(01), 2703-2706</arxiv:journal_reference>
      <dc:creator>Muskaan Goyal, Pranav Bhasin</dc:creator>
    </item>
    <item>
      <title>Open Challenges for a Production-ready Cloud Environment on top of RISC-V hardware</title>
      <link>https://arxiv.org/abs/2505.02650</link>
      <description>arXiv:2505.02650v1 Announce Type: cross 
Abstract: As part of the Vitamin-V European project, we have built a prototype of a RISC-V cluster managed by OpenStack, with the goal of realizing a functional RISC-V cloud ecosystem. In this poster we explain the hardware and software challenges encountered while porting some elements of OpenStack. We also discuss the current performance gaps that challenge a performance-ready cloud environment over such new ISA, an essential element to fulfill in order to achieve european technological sovereignty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02650v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Call, Ramon Nou, Guillem Senabre</dc:creator>
    </item>
    <item>
      <title>Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow</title>
      <link>https://arxiv.org/abs/2505.02780</link>
      <description>arXiv:2505.02780v1 Announce Type: cross 
Abstract: Pathologists rely on gigapixel whole-slide images (WSIs) to diagnose diseases like cancer, yet current digital pathology tools hinder diagnosis. The immense scale of WSIs, often exceeding 100,000 X 100,000 pixels, clashes with the limited views traditional monitors offer. This mismatch forces constant panning and zooming, increasing pathologist cognitive load, causing diagnostic fatigue, and slowing pathologists' adoption of digital methods. PathVis, our mixed-reality visualization platform for Apple Vision Pro, addresses these challenges. It transforms the pathologist's interaction with data, replacing cumbersome mouse-and-monitor navigation with intuitive exploration using natural hand gestures, eye gaze, and voice commands in an immersive workspace. PathVis integrates AI to enhance diagnosis. An AI-driven search function instantly retrieves and displays the top five similar patient cases side-by-side, improving diagnostic precision and efficiency through rapid comparison. Additionally, a multimodal conversational AI assistant offers real-time image interpretation support and aids collaboration among pathologists across multiple Apple devices. By merging the directness of traditional pathology with advanced mixed-reality visualization and AI, PathVis improves diagnostic workflows, reduces cognitive strain, and makes pathology practice more effective and engaging. The PathVis source code and a demo video are publicly available at: https://github.com/jaiprakash1824/Path_Vis</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02780v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jai Prakash Veerla, Partha Sai Guttikonda, Helen H. Shang, Mohammad Sadegh Nasr, Cesar Torres, Jacob M. Luber</dc:creator>
    </item>
    <item>
      <title>Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review</title>
      <link>https://arxiv.org/abs/2505.02828</link>
      <description>arXiv:2505.02828v1 Announce Type: cross 
Abstract: Explainable Artificial Intelligence (XAI) has emerged as a pillar of Trustworthy AI and aims to bring transparency in complex models that are opaque by nature. Despite the benefits of incorporating explanations in models, an urgent need is found in addressing the privacy concerns of providing this additional information to end users. In this article, we conduct a scoping review of existing literature to elicit details on the conflict between privacy and explainability. Using the standard methodology for scoping review, we extracted 57 articles from 1,943 studies published from January 2019 to December 2024. The review addresses 3 research questions to present readers with more understanding of the topic: (1) what are the privacy risks of releasing explanations in AI systems? (2) what current methods have researchers employed to achieve privacy preservation in XAI systems? (3) what constitutes a privacy preserving explanation? Based on the knowledge synthesized from the selected studies, we categorize the privacy risks and preservation methods in XAI and propose the characteristics of privacy preserving explanations to aid researchers and practitioners in understanding the requirements of XAI that is privacy compliant. Lastly, we identify the challenges in balancing privacy with other system desiderata and provide recommendations for achieving privacy preserving XAI. We expect that this review will shed light on the complex relationship of privacy and explainability, both being the fundamental principles of Trustworthy AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02828v1</guid>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sonal Allana, Mohan Kankanhalli, Rozita Dara</dc:creator>
    </item>
  </channel>
</rss>
