<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Aug 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the utility of toy models for theories of consciousness</title>
      <link>https://arxiv.org/abs/2508.00190</link>
      <description>arXiv:2508.00190v1 Announce Type: new 
Abstract: Toy models are highly idealized and deliberately simplified models that retain only the essential features of a system in order to explore specific theoretical questions. Long used in physics and other sciences, they have recently begun to play a more visible role in consciousness research. This chapter examines the potential utility of toy models for developing and evaluating scientific theories of consciousness in terms of their ability to clarify theoretical frameworks, test assumptions, and illuminate philosophical challenges. Drawing primarily on examples from Integrated Information Theory (IIT) and Global Workspace Theory (GWT), I show how these simplified systems could make abstract concepts more tangible, enabling researchers to probe the coherence, consistency, and implications of competing frameworks. In addition to supporting theory development, toy models can also address specific features of experience, as exemplified by the account of spatial extendedness and temporal flow provided by integrated information theory (IIT) and recent theory-independent structural approaches. Moreover, toy models bring philosophical debates into sharper focus, such as the distinction between functional and structural theories of consciousness. By bridging abstract claims and empirical inquiry, toy models provide essential insights into the challenges of building comprehensive theories of consciousness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00190v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Larissa Albantakis</dc:creator>
    </item>
    <item>
      <title>State-switching navigation strategies in C. elegans are beneficial for chemotaxis</title>
      <link>https://arxiv.org/abs/2508.00191</link>
      <description>arXiv:2508.00191v1 Announce Type: new 
Abstract: Animals employ different strategies for relating sensory input to behavioral output to navigate sensory environments, but what strategy to use, when to switch and why remain unclear. In C. elegans, navigation is composed of 'steering' and 'turns', corresponding to small heading changes and large reorientation events, respectively. It is unclear whether transitions between these elements are driven solely by sensory input or are influenced by internal states that persist over time. It also remains unknown how worms accomplish seemingly surprising feats of navigation--for example, worms appear to exit turns correctly oriented toward a goal, despite their presumed lack of spatial awareness during the turn. Here, we resolve these questions using detailed measurements of sensory-guided navigation and a novel statistical model of state-dependent navigation. We show that the worm's navigation is well described by a sensory-driven state-switching model with two distinct states, each persisting over many seconds and producing different mixtures of sensorimotor relations. One state is enriched for steering, while the other is enriched for turning. This hierarchical, temporal organization of strategies challenges the previous assumption that strategies are static over time and driven solely by immediate sensory input. Sensory input causally drives transitions between these persistent internal states, and creates the appearance of 'directed turns.' Genetic perturbations and a data-constrained reinforcement learning model demonstrate that state-switching enhances gradient-climbing performance. By combining measurement, perturbation, and modeling, we show that state-switching plays a functionally beneficial role in organizing behavior over time--a principle likely to generalize across species and contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00191v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin S. Chen, Andrew M. Leifer, Jonathan W. Pillow</dc:creator>
    </item>
    <item>
      <title>The Repeated-Stimulus Confound in Electroencephalography</title>
      <link>https://arxiv.org/abs/2508.00531</link>
      <description>arXiv:2508.00531v1 Announce Type: new 
Abstract: In neural-decoding studies, recordings of participants' responses to stimuli are used to train models. In recent years, there has been an explosion of publications detailing applications of innovations from deep-learning research to neural-decoding studies. The data-hungry models used in these experiments have resulted in a demand for increasingly large datasets. Consequently, in some studies, the same stimuli are presented multiple times to each participant to increase the number of trials available for use in model training. However, when a decoding model is trained and subsequently evaluated on responses to the same stimuli, stimulus identity becomes a confounder for accuracy. We term this the repeated-stimulus confound. We identify a susceptible dataset, and 16 publications which report model performance based on evaluation procedures affected by the confound. We conducted experiments using models from the affected studies to investigate the likely extent to which results in the literature have been misreported. Our findings suggest that the decoding accuracies of these models were overestimated by between 4.46-7.42%. Our analysis also indicates that per 1% increase in accuracy under the confound, the magnitude of the overestimation increases by 0.26%. The confound not only results in optimistic estimates of decoding performance, but undermines the validity of several claims made within the affected publications. We conducted further experiments to investigate the implications of the confound in alternative contexts. We found that the same methodology used within the affected studies could also be used to justify an array of pseudoscientific claims, such as the existence of extrasensory perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00531v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jack A. Kilgallen, Barak A. Pearlmutter, Jeffrey Mark Siskind</dc:creator>
    </item>
    <item>
      <title>Design, Simulation, and Fabrication of a Hexagonal Microfluidic Platform for Culturing Neurons</title>
      <link>https://arxiv.org/abs/2508.00425</link>
      <description>arXiv:2508.00425v1 Announce Type: cross 
Abstract: Developing an organoid computing platform from neurons in vitro demands stable, precisely controlled microenvironments. To address this requirement, we designed, simulated, and fabricated a microfluidic device featuring hexagonal wells ($34.64\,\mathrm{\mu m}$ side length) in a honeycomb array connected by $20\,\mathrm{\mu m}$ channels. Computational fluid dynamics (CFD) modeling, validated by high mesh quality ($0.934$ orthogonal quality) and robust convergence, confirmed the architecture supports flow regimes ideal for ensuring cell viability. At target flow rates of $0.1$ - $1\,\mathrm{\mu L/min}$, simulations revealed the extrapolated pressure differential across the full $50{,}000\,\mathrm{\mu m}$ device remains within stable operating limits at $177\,\mathrm{kPa}$ (average) and $329\,\mathrm{kPa}$ (maximum). Photolithography successfully produced this architecture, with only minor corner rounding observed at feature interfaces. This work therefore establishes a computationally validated and fabricated platform, paving the way for experimental flow characterization and subsequent neural integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00425v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.bio-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxx Yung</dc:creator>
    </item>
    <item>
      <title>Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System</title>
      <link>https://arxiv.org/abs/2504.10053</link>
      <description>arXiv:2504.10053v2 Announce Type: replace-cross 
Abstract: In this study, we explore how the combination of synthetic biology, neuroscience modeling, and neuromorphic electronic systems offers a new approach to creating an artificial system that mimics the natural sense of smell. We argue that a co-design approach offers significant advantages in replicating the complex dynamics of odor sensing and processing. We propose a hybrid system of synthetic sensory neurons that provides three key features: (a) receptor-gated ion channels, (b) interface between synthetic biology and semiconductors and (c) event-based encoding and computing based on spiking networks. Our approach is validated using simulation-based modeling of the complete sensing and processing pipeline. This research seeks to develop a platform for ultra-sensitive, specific, and energy-efficient odor detection, with potential implications for environmental monitoring, medical diagnostics, and security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10053v2</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/2634-4386/aded2d</arxiv:DOI>
      <arxiv:journal_reference>Neuromorphic Computing and Engineering, 2025, Volume 5, Number 3</arxiv:journal_reference>
      <dc:creator>Kevin Max, Larissa Sames, Shimeng Ye, Jan Steink\"uhler, Federico Corradi</dc:creator>
    </item>
    <item>
      <title>HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Recordings</title>
      <link>https://arxiv.org/abs/2507.17224</link>
      <description>arXiv:2507.17224v2 Announce Type: replace-cross 
Abstract: Extracellular recordings are transient voltage fluctuations in the vicinity of neurons, serving as a fundamental modality in neuroscience for decoding brain activity at single-neuron resolution. Spike sorting, the process of attributing each detected spike to its corresponding neuron, is a pivotal step in brain sensing pipelines. However, it remains challenging under low signal-to-noise ratio (SNR), electrode drift, and cross-session variability. In this paper, we propose HuiduRep, a robust self-supervised representation learning framework that extracts discriminative and generalizable features from extracellular recordings. By integrating contrastive learning with a denoising autoencoder, HuiduRep learns latent representations robust to noise and drift. With HuiduRep, we develop a spike sorting pipeline that clusters spike representations without ground truth labels. Experiments on hybrid and real-world datasets demonstrate that HuiduRep achieves strong robustness. Furthermore, the pipeline significantly outperforms state-of-the-art tools such as KiloSort4 and MountainSort5 on accuracy and precision on diverse datasets. These findings demonstrate the potential of self-supervised spike representation learning as a foundational tool for robust and generalizable processing of extracellular recordings. Code is available at: https://github.com/IgarashiAkatuki/HuiduRep</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17224v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Feng Cao, Zishuo Feng, Wei Shi, Jicong Zhang</dc:creator>
    </item>
    <item>
      <title>Breaking the mould of Social Mixed Reality -- State-of-the-Art and Glossary</title>
      <link>https://arxiv.org/abs/2507.23454</link>
      <description>arXiv:2507.23454v2 Announce Type: replace-cross 
Abstract: This article explores a critical gap in Mixed Reality (MR) technology: while advances have been made, MR still struggles to authentically replicate human embodiment and socio-motor interaction. For MR to enable truly meaningful social experiences, it needs to incorporate multi-modal data streams and multi-agent interaction capabilities. To address this challenge, we present a comprehensive glossary covering key topics such as Virtual Characters and Autonomisation, Responsible AI, Ethics by Design, and the Scientific Challenges of Social MR within Neuroscience, Embodiment, and Technology. Our aim is to drive the transformative evolution of MR technologies that prioritize human-centric innovation, fostering richer digital connections. We advocate for MR systems that enhance social interaction and collaboration between humans and virtual autonomous agents, ensuring inclusivity, ethical design and psychological safety in the process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23454v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.GR</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marta Bie\'nkiewicz, Julia Ayache, Panayiotis Charalambous, Cristina Becchio, Marco Corragio, Bertram Taetz, Francesco De Lellis, Antonio Grotta, Anna Server, Daniel Rammer, Richard Kulpa, Franck Multon, Azucena Garcia-Palacios, Jessica Sutherland, Kathleen Bryson, St\'ephane Donikian, Didier Stricker, Beno\^it Bardy</dc:creator>
    </item>
  </channel>
</rss>
