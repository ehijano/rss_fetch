<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>RIP Twitter API: A eulogy to its vast research contributions</title>
      <link>https://arxiv.org/abs/2404.07340</link>
      <description>arXiv:2404.07340v1 Announce Type: new 
Abstract: Since 2006, Twitter's Application Programming Interface (API) has been a treasure trove of high-quality data for researchers studying everything from the spread of misinformation, to social psychology and emergency management. However, in the spring of 2023, Twitter (now called X) began changing $42,000/month for its Enterprise access level, an essential death knell for researcher use. Lacking sufficient funds to pay this monthly fee, academics are now scrambling to continue their research without this important data source. This study collects and tabulates the number of studies, number of citations, dates, major disciplines, and major topic areas of studies that used Twitter data between 2006 and 2023. While we cannot know for certain what will be lost now that Twitter data is cost prohibitive, we can illustrate its research value during the time it was available. A search of 8 databases and 3 related APIs found that since 2006, a total of 27,453 studies have been published in 7,432 publication venues, with 1,303,142 citations, across 14 disciplines. Major disciplines include: computational social science, engineering, data science, social media studies, public health, and medicine. Major topics include: information dissemination, assessing the credibility of tweets, strategies for conducting data research, detecting and analyzing major events, and studying human behavior. Twitter data studies have increased every year since 2006, but following Twitter's decision to begin charging for data in the spring of 2023, the number of studies published in 2023 decreased by 13% compared to 2022. We assume that much of the data used for studies published in 2023 were collected prior to Twitter's shutdown, and thus the number of new studies are likely to decline further in subsequent years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07340v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ryan Murtfeldt, Naomi Alterman, Ihsan Kahveci, Jevin D. West</dc:creator>
    </item>
    <item>
      <title>The Survey on Multi-Source Data Fusion in Cyber-Physical-Social Systems:Foundational Infrastructure for Industrial Metaverses and Industries 5.0</title>
      <link>https://arxiv.org/abs/2404.07476</link>
      <description>arXiv:2404.07476v1 Announce Type: new 
Abstract: As the concept of Industries 5.0 develops, industrial metaverses are expected to operate in parallel with the actual industrial processes to offer ``Human-Centric" Safe, Secure, Sustainable, Sensitive, Service, and Smartness ``6S" manufacturing solutions. Industrial metaverses not only visualize the process of productivity in a dynamic and evolutional way, but also provide an immersive laboratory experimental environment for optimizing and remodeling the process. Besides, the customized user needs that are hidden in social media data can be discovered by social computing technologies, which introduces an input channel for building the whole social manufacturing process including industrial metaverses. This makes the fusion of multi-source data cross Cyber-Physical-Social Systems (CPSS) the foundational and key challenge. This work firstly proposes a multi-source-data-fusion-driven operational architecture for industrial metaverses on the basis of conducting a comprehensive literature review on the state-of-the-art multi-source data fusion methods. The advantages and disadvantages of each type of method are analyzed by considering the fusion mechanisms and application scenarios. Especially, we combine the strengths of deep learning and knowledge graphs in scalability and parallel computation to enable our proposed framework the ability of prescriptive optimization and evolution. This integration can address the shortcomings of deep learning in terms of explainability and fact fabrication, as well as overcoming the incompleteness and the challenges of construction and maintenance inherent in knowledge graphs. The effectiveness of the proposed architecture is validated through a parallel weaving case study. In the end, we discuss the challenges and future directions of multi-source data fusion cross CPSS for industrial metaverses and social manufacturing in Industries 5.0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07476v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.inffus.2024.102321</arxiv:DOI>
      <arxiv:journal_reference>Information Fusion 2024</arxiv:journal_reference>
      <dc:creator>Xiao Wang, Yutong Wang, Jing Yang, Xiaofeng Jia, Lijun Li, Weiping Ding, Fei-Yue Wang</dc:creator>
    </item>
    <item>
      <title>Measuring Geographic Diversity of Foundation Models with a Natural Language--based Geo-guessing Experiment on GPT-4</title>
      <link>https://arxiv.org/abs/2404.07612</link>
      <description>arXiv:2404.07612v1 Announce Type: new 
Abstract: Generative AI based on foundation models provides a first glimpse into the world represented by machines trained on vast amounts of multimodal data ingested by these models during training. If we consider the resulting models as knowledge bases in their own right, this may open up new avenues for understanding places through the lens of machines. In this work, we adopt this thinking and select GPT-4, a state-of-the-art representative in the family of multimodal large language models, to study its geographic diversity regarding how well geographic features are represented. Using DBpedia abstracts as a ground-truth corpus for probing, our natural language--based geo-guessing experiment shows that GPT-4 may currently encode insufficient knowledge about several geographic feature types on a global level. On a local level, we observe not only this insufficiency but also inter-regional disparities in GPT-4's geo-guessing performance on UNESCO World Heritage Sites that carry significance to both local and global populations, and the inter-regional disparities may become smaller as the geographic scale increases. Morever, whether assessing the geo-guessing performance on a global or local level, we find inter-model disparities in GPT-4's geo-guessing performance when comparing its unimodal and multimodal variants. We hope this work can initiate a discussion on geographic diversity as an ethical principle within the GIScience community in the face of global socio-technical challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07612v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zilong Liu, Krzysztof Janowicz, Kitty Currier, Meilin Shi</dc:creator>
    </item>
    <item>
      <title>On the role of ethics and sustainability in business innovation</title>
      <link>https://arxiv.org/abs/2404.07678</link>
      <description>arXiv:2404.07678v1 Announce Type: new 
Abstract: For organizations to survive and flourish in the long term, innovation and novelty must be continually introduced, which is particularly true in today's rapidly changing world. This raises a variety of ethical and sustainability considerations that seldom receive the attention they deserve. Existing innovation adoption frameworks often focus on technological, organizational, environmental, and social factors impacting adoption. In this chapter, we explore the ethical and sustainability angles, particularly as they relate to emerging technologies, artificial intelligence (AI) being a prominent example. We consider how to facilitate the development and cultivation of innovation cultures in organizations, including budding startups as well as established enterprises, through approaches such as systems thinking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07678v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Maria Fay, Frederik F. Fl\"other</dc:creator>
    </item>
    <item>
      <title>An equilibrium-seeking search algorithm for integrating large-scale activity-based and dynamic traffic assignment models</title>
      <link>https://arxiv.org/abs/2404.07789</link>
      <description>arXiv:2404.07789v1 Announce Type: new 
Abstract: This paper proposes an iterative methodology to integrate large-scale behavioral activity-based models with dynamic traffic assignment models. The main novelty of the proposed approach is the decoupling of the two parts, allowing the ex-post integration of any existing model as long as certain assumptions are satisfied. A measure of error is defined to characterize a search space easily explorable within its boundaries. Within it, a joint distribution of the number of trips and travel times is identified as the equilibrium distribution, i.e., the distribution for which trip numbers and travel times are bound in the neighborhood of the equilibrium between supply and demand. The approach is tested on a medium-sized city of 400,000 inhabitants and the results suggest that the proposed iterative approach does perform well, reaching equilibrium between demand and supply in a limited number of iterations thanks to its perturbation techniques. Overall, 15 iterations are needed to reach values of the measure of error lower than 10%. The equilibrium identified this way is then validated against baseline distributions to demonstrate the goodness of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07789v1</guid>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serio Agriesti, Claudio Roncoli, Bat-hen Nahmias-Biran</dc:creator>
    </item>
    <item>
      <title>EduAgent: Generative Student Agents in Learning</title>
      <link>https://arxiv.org/abs/2404.07963</link>
      <description>arXiv:2404.07963v1 Announce Type: new 
Abstract: Student simulation in online education is important to address dynamic learning behaviors of students with diverse backgrounds. Existing simulation models based on deep learning usually need massive training data, lacking prior knowledge in educational contexts. Large language models (LLMs) may contain such prior knowledge since they are pre-trained from a large corpus. However, because student behaviors are dynamic and multifaceted with individual differences, directly prompting LLMs is not robust nor accurate enough to capture fine-grained interactions among diverse student personas, learning behaviors, and learning outcomes. This work tackles this problem by presenting a newly annotated fine-grained large-scale dataset and proposing EduAgent, a novel generative agent framework incorporating cognitive prior knowledge (i.e., theoretical findings revealed in cognitive science) to guide LLMs to first reason correlations among various behaviors and then make simulations. Our two experiments show that EduAgent could not only mimic and predict learning behaviors of real students but also generate realistic learning behaviors of virtual students without real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07963v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Songlin Xu, Xinyu Zhang, Lianhui Qin</dc:creator>
    </item>
    <item>
      <title>Machine Learning-based Approach for Ex-post Assessment of Community Risk and Resilience Based on Coupled Human-infrastructure Systems Performance</title>
      <link>https://arxiv.org/abs/2404.07966</link>
      <description>arXiv:2404.07966v1 Announce Type: new 
Abstract: There is a limitation in the literature of data-driven analyses for the ex-post evaluation of community risk and resilience, particularly using features related to the performance of coupled human-infrastructure systems. To address this gap, in this study we created a machine learning-based method for the ex-post assessment of community risk and resilience and their interplay based on features related to the coupled human-infrastructure systems performance. Utilizing feature groups related to population protective actions, infrastructure/building performance features, and recovery features, we examined the risk and resilience performance of communities in the context of the 2017 Hurricane Harvey in Harris County, Texas. These features related to the coupled human-infrastructure systems performance were processed using the K-means clustering method to classify census block groups into four distinct clusters then, based on feature analysis, these clusters were labeled and designated into four quadrants of risk-resilience archetypes. Finally, we analyzed the disparities in risk-resilience status of spatial areas across different clusters as well as different income groups. The findings unveil the risk-resilience status of spatial areas shaped by their coupled human-infrastructure systems performance and their interactions. The results also inform about features that contribute to high resilience in high-risk areas. For example, the results indicate that in high-risk areas, evacuation rates contributed to a greater resilience, while in low-risk areas, preparedness contributed to greater resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07966v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiangpeng Li, Ali Mostafavi</dc:creator>
    </item>
    <item>
      <title>Evolving Military Broadband Wireless Communication Systems: WiMAX, LTE and WLAN</title>
      <link>https://arxiv.org/abs/2404.07207</link>
      <description>arXiv:2404.07207v1 Announce Type: cross 
Abstract: Emerging technologies for mobile broadband wireless are being considered as a Commercial Off-The-Shelf solution to cover the operational requirements of the future warfare. The capabilities of these technologies are being enhanced to meet the growing market demands on performance. In this context, several standards such as WiMAX, LTE or WLAN are introducing themselves as strong candidates to fulfill these requirements. This paper presents an innovative scenario-based approach to develop a Military Broadband Wireless Communication System (MBWCS). Its main objective is to analyze how similar a military MBWCS can be to the identified civil standards, taking operational and high level technical requirements into account. This specification will be used for analyzing the applicability and the modifications of each of the standards layers individually. Proving the feasibility and aptitude of each standard provides strong foundations to address a MBWCS in the most efficient way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07207v1</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICMCIS.2016.7496570</arxiv:DOI>
      <dc:creator>P. Fraga-Lamas, L. Castedo-Ribas, A. Morales-M\'endez, J. M. Camas-Albar</dc:creator>
    </item>
    <item>
      <title>FairEM360: A Suite for Responsible Entity Matching</title>
      <link>https://arxiv.org/abs/2404.07354</link>
      <description>arXiv:2404.07354v1 Announce Type: cross 
Abstract: Entity matching is one the earliest tasks that occur in the big data pipeline and is alarmingly exposed to unintentional biases that affect the quality of data. Identifying and mitigating the biases that exist in the data or are introduced by the matcher at this stage can contribute to promoting fairness in downstream tasks. This demonstration showcases FairEM360, a framework for 1) auditing the output of entity matchers across a wide range of fairness measures and paradigms, 2) providing potential explanations for the underlying reasons for unfairness, and 3) providing resolutions for the unfairness issues through an exploratory process with human-in-the-loop feedback, utilizing an ensemble of matchers. We aspire for FairEM360 to contribute to the prioritization of fairness as a key consideration in the evaluation of EM pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07354v1</guid>
      <category>cs.DB</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nima Shahbazi, Mahdi Erfanian, Abolfazl Asudeh, Fatemeh Nargesian, Divesh Srivastava</dc:creator>
    </item>
    <item>
      <title>Laissez-Faire Harms: Algorithmic Biases in Generative Language Models</title>
      <link>https://arxiv.org/abs/2404.07475</link>
      <description>arXiv:2404.07475v1 Announce Type: cross 
Abstract: The rapid deployment of generative language models (LMs) has raised concerns about social biases affecting the well-being of diverse consumers. The extant literature on generative LMs has primarily examined bias via explicit identity prompting. However, prior research on bias in earlier language-based technology platforms, including search engines, has shown that discrimination can occur even when identity terms are not specified explicitly. Studies of bias in LM responses to open-ended prompts (where identity classifications are left unspecified) are lacking and have not yet been grounded in end-consumer harms. Here, we advance studies of generative LM bias by considering a broader set of natural use cases via open-ended prompting. In this "laissez-faire" setting, we find that synthetically generated texts from five of the most pervasive LMs (ChatGPT3.5, ChatGPT4, Claude2.0, Llama2, and PaLM2) perpetuate harms of omission, subordination, and stereotyping for minoritized individuals with intersectional race, gender, and/or sexual orientation identities (AI/AN, Asian, Black, Latine, MENA, NH/PI, Female, Non-binary, Queer). We find widespread evidence of bias to an extent that such individuals are hundreds to thousands of times more likely to encounter LM-generated outputs that portray their identities in a subordinated manner compared to representative or empowering portrayals. We also document a prevalence of stereotypes (e.g. perpetual foreigner) in LM-generated outputs that are known to trigger psychological harms that disproportionately affect minoritized individuals. These include stereotype threat, which leads to impaired cognitive performance and increased negative self-perception. Our findings highlight the urgent need to protect consumers from discriminatory harms caused by language models and invest in critical AI education programs tailored towards empowering diverse consumers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07475v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan Shieh, Faye-Marie Vassel, Cassidy Sugimoto, Thema Monroe-White</dc:creator>
    </item>
    <item>
      <title>Analyzing Toxicity in Deep Conversations: A Reddit Case Study</title>
      <link>https://arxiv.org/abs/2404.07879</link>
      <description>arXiv:2404.07879v1 Announce Type: cross 
Abstract: Online social media has become increasingly popular in recent years due to its ease of access and ability to connect with others. One of social media's main draws is its anonymity, allowing users to share their thoughts and opinions without fear of judgment or retribution. This anonymity has also made social media prone to harmful content, which requires moderation to ensure responsible and productive use. Several methods using artificial intelligence have been employed to detect harmful content. However, conversation and contextual analysis of hate speech are still understudied. Most promising works only analyze a single text at a time rather than the conversation supporting it. In this work, we employ a tree-based approach to understand how users behave concerning toxicity in public conversation settings. To this end, we collect both the posts and the comment sections of the top 100 posts from 8 Reddit communities that allow profanity, totaling over 1 million responses. We find that toxic comments increase the likelihood of subsequent toxic comments being produced in online conversations. Our analysis also shows that immediate context plays a vital role in shaping a response rather than the original post. We also study the effect of consensual profanity and observe overlapping similarities with non-consensual profanity in terms of user behavior and patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07879v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vigneshwaran Shankaran, Rajesh Sharma</dc:creator>
    </item>
    <item>
      <title>Content Knowledge Identification with Multi-Agent Large Language Models (LLMs)</title>
      <link>https://arxiv.org/abs/2404.07960</link>
      <description>arXiv:2404.07960v1 Announce Type: cross 
Abstract: Teachers' mathematical content knowledge (CK) is of vital importance and need in teacher professional development (PD) programs. Computer-aided asynchronous PD systems are the most recent proposed PD techniques, which aim to help teachers improve their PD equally with fewer concerns about costs and limitations of time or location. However, current automatic CK identification methods, which serve as one of the core techniques of asynchronous PD systems, face challenges such as diversity of user responses, scarcity of high-quality annotated data, and low interpretability of the predictions. To tackle these challenges, we propose a Multi-Agent LLMs-based framework, LLMAgent-CK, to assess the user responses' coverage of identified CK learning goals without human annotations. By taking advantage of multi-agent LLMs in strong generalization ability and human-like discussions, our proposed LLMAgent-CK presents promising CK identifying performance on a real-world mathematical CK dataset MaCKT. Moreover, our case studies further demonstrate the working of the multi-agent framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07960v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaiqi Yang, Yucheng Chu, Taylor Darwin, Ahreum Han, Hang Li, Hongzhi Wen, Yasemin Copur-Gencturk, Jiliang Tang, Hui Liu</dc:creator>
    </item>
    <item>
      <title>A Survey of Knowledge Tracing: Models, Variants, and Applications</title>
      <link>https://arxiv.org/abs/2105.15106</link>
      <description>arXiv:2105.15106v4 Announce Type: replace 
Abstract: Modern online education has the capacity to provide intelligent educational services by automatically analyzing substantial amounts of student behavioral data. Knowledge Tracing (KT) is one of the fundamental tasks for student behavioral data analysis, aiming to monitor students' evolving knowledge state during their problem-solving process. In recent years, a substantial number of studies have concentrated on this rapidly growing field, significantly contributing to its advancements. In this survey, we will conduct a thorough investigation of these progressions. Firstly, we present three types of fundamental KT models with distinct technical routes. Subsequently, we review extensive variants of the fundamental KT models that consider more stringent learning assumptions. Moreover, the development of KT cannot be separated from its applications, thereby we present typical KT applications in various scenarios. To facilitate the work of researchers and practitioners in this field, we have developed two open-source algorithm libraries: EduData that enables the download and preprocessing of KT-related datasets, and EduKTM that provides an extensible and unified implementation of existing mainstream KT models. Finally, we discuss potential directions for future research in this rapidly growing field. We hope that the current survey will assist both researchers and practitioners in fostering the development of KT, thereby benefiting a broader range of students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.15106v4</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TLT.2024.3383325</arxiv:DOI>
      <dc:creator>Shuanghong Shen, Qi Liu, Zhenya Huang, Yonghe Zheng, Minghao Yin, Minjuan Wang, Enhong Chen</dc:creator>
    </item>
    <item>
      <title>Epistemic Power, Objectivity and Gender in AI Ethics Labor: Legitimizing Located Complaints</title>
      <link>https://arxiv.org/abs/2402.08171</link>
      <description>arXiv:2402.08171v3 Announce Type: replace 
Abstract: What counts as legitimate AI ethics labor, and consequently, what are the epistemic terms on which AI ethics claims are rendered legitimate? Based on 75 interviews with technologists including researchers, developers, open source contributors, and activists, this paper explores the various epistemic bases from which AI ethics is discussed and practiced. In the context of outside attacks on AI ethics as an impediment to "progress," I show how some AI ethics practices have reached toward authority from automation and quantification, and achieved some legitimacy as a result, while those based on richly embodied and situated lived experience have not. This paper draws together the work of feminist Anthropology and Science and Technology Studies scholars Diana Forsythe and Lucy Suchman with the works of postcolonial feminist theorist Sara Ahmed and Black feminist theorist Kristie Dotson to examine the implications of dominant AI ethics practices.
  By entrenching the epistemic power of quantification, dominant AI ethics practices-Model Cards and similar interventions-risk legitimizing AI ethics as a project in equal and opposite measure to which they delegitimize and marginalize embodied and lived experiences as legitimate parts of the same project. In response, I propose humble technical practices: quantified or technical practices which specifically seek to make their epistemic limits clear in order to flatten hierarchies of epistemic power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08171v3</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>David Gray Widder</dc:creator>
    </item>
    <item>
      <title>Remote Possibilities: Where there is a WIL, is there a Way? AI Education for Remote Learners in a New Era of Work-Integrated-Learning</title>
      <link>https://arxiv.org/abs/2402.12667</link>
      <description>arXiv:2402.12667v2 Announce Type: replace 
Abstract: Increasing diversity in educational settings is challenging in part due to the lack of access to resources for non-traditional learners in remote communities. Post-pandemic platforms designed specifically for remote and hybrid learning -- supporting team-based collaboration online -- are positioned to bridge this gap. Our work combines the use of these new platforms with co-creation and collaboration tools for AI assisted remote Work-Integrated-Learning (WIL) opportunities, including efforts in community and with the public library system. This paper outlines some of our experiences to date, and proposes methods to further integrate AI education into community-driven applications for remote WIL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12667v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Derek Jacoby, Saiph Savage, Yvonne Coady</dc:creator>
    </item>
    <item>
      <title>An Empirical Analysis on the Use and Reporting of National Security Letters</title>
      <link>https://arxiv.org/abs/2403.02768</link>
      <description>arXiv:2403.02768v3 Announce Type: replace 
Abstract: National Security Letters (NSLs) are similar to administrative subpoenas and can be issued directly by elements of the executive branch without requiring prior approval from a court or grand jury. Importantly, NSLs authorize the imposition of nondisclosure orders (aka "gag orders") on the receiving party. Controversy about potential abuses of this authority has driven a range of legal and policy discussions. To address these concerns, both the public sector and the private sector have sought to document the usage of NSLs in aggregated form. However, each data source is limited in scope, time, and kind.
  In this paper, we consolidate the available data around NSLs and answer two questions: (1) what can the public effectively learn from the reported data and does this information suffice to assess the NSL usage? (2) how accessible is this data collection? We show that longitudinal trends in the usage of NSLs can be observed. For instance, we find a significant increase in NSL requests for non-US persons and that the policy reforms to decrease the mandated nondisclosure period appear to be effective. The observed trends suggest that the current transparency mechanisms are viable safeguards against the excessive use of NSLs. However, aggregating and normalizing the data requires manual reviewing, parsing, and validating. We even find inconsistencies within and across official data sources. Overall, the laborious data collection process hinders external and internal auditing efforts and demonstrates the need for a unified and more usable dataset for NSLs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02768v3</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Bellon, Miro Haller, Andrey Labunets, Enze Liu, Stefan Savage</dc:creator>
    </item>
    <item>
      <title>AI and Identity</title>
      <link>https://arxiv.org/abs/2403.07924</link>
      <description>arXiv:2403.07924v2 Announce Type: replace 
Abstract: AI-empowered technologies' impact on the world is undeniable, reshaping industries, revolutionizing how humans interact with technology, transforming educational paradigms, and redefining social codes. However, this rapid growth is accompanied by two notable challenges: a lack of diversity within the AI field and a widening AI divide. In this context, This paper examines the intersection of AI and identity as a pathway to understand biases, inequalities, and ethical considerations in AI development and deployment. We present a multifaceted definition of AI identity, which encompasses its creators, applications, and their broader impacts. Understanding AI's identity involves understanding the associations between the individuals involved in AI's development, the technologies produced, and the social, ethical, and psychological implications. After exploring the AI identity ecosystem and its societal dynamics, We propose a framework that highlights the need for diversity in AI across three dimensions: Creators, Creations, and Consequences through the lens of identity. This paper proposes the need for a comprehensive approach to fostering a more inclusive and responsible AI ecosystem through the lens of identity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07924v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sri Yash Tadimalla, Mary Lou Maher</dc:creator>
    </item>
    <item>
      <title>KTbench: A Novel Data Leakage-Free Framework for Knowledge Tracing</title>
      <link>https://arxiv.org/abs/2403.15304</link>
      <description>arXiv:2403.15304v2 Announce Type: replace 
Abstract: Knowledge Tracing (KT) is concerned with predicting students' future performance on learning items in intelligent tutoring systems. Learning items are tagged with skill labels called knowledge concepts (KCs). Many KT models expand the sequence of item-student interactions into KC-student interactions by replacing learning items with their constituting KCs. This often results in a longer sequence length. This approach addresses the issue of sparse item-student interactions and minimises model parameters. However, two problems have been identified with such models.
  The first problem is the model's ability to learn correlations between KCs belonging to the same item, which can result in the leakage of ground truth labels and hinder performance. This problem can lead to a significant decrease in performance on datasets with a higher number of KCs per item. The second problem is that the available benchmark implementations ignore accounting for changes in sequence length when expanding KCs, leading to different models being tested with varying sequence lengths but still compared against the same benchmark.
  To address these problems, we introduce a general masking framework that mitigates the first problem and enhances the performance of such KT models while preserving the original model architecture without significant alterations. Additionally, we introduce KTbench, an open-source benchmark library designed to ensure the reproducibility of this work while mitigating the second problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15304v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahya Badran, Christine Preisach</dc:creator>
    </item>
    <item>
      <title>From Protoscience to Epistemic Monoculture: How Benchmarking Set the Stage for the Deep Learning Revolution</title>
      <link>https://arxiv.org/abs/2404.06647</link>
      <description>arXiv:2404.06647v2 Announce Type: replace 
Abstract: Over the past decade, AI research has focused heavily on building ever-larger deep learning models. This approach has simultaneously unlocked incredible achievements in science and technology, and hindered AI from overcoming long-standing limitations with respect to explainability, ethical harms, and environmental efficiency. Drawing on qualitative interviews and computational analyses, our three-part history of AI research traces the creation of this "epistemic monoculture" back to a radical reconceptualization of scientific progress that began in the late 1980s. In the first era of AI research (1950s-late 1980s), researchers and patrons approached AI as a "basic" science that would advance through autonomous exploration and organic assessments of progress (e.g., peer-review, theoretical consensus). The failure of this approach led to a retrenchment of funding in the 1980s. Amid this "AI Winter," an intervention by the U.S. government reoriented the field towards measurable progress on tasks of military and commercial interest. A new evaluation system called "benchmarking" provided an objective way to quantify progress on tasks by focusing exclusively on increasing predictive accuracy on example datasets. Distilling science down to verifiable metrics clarified the roles of scientists, allowed the field to rapidly integrate talent, and provided clear signals of significance and progress. But history has also revealed a tradeoff to this streamlined approach to science: the consolidation around external interests and inherent conservatism of benchmarking has disincentivized exploration beyond scaling monoculture. In the discussion, we explain how AI's monoculture offers a compelling challenge to the belief that basic, exploration-driven research is needed for scientific progress. Implications for the spread of AI monoculture to other sciences in the era of generative AI are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06647v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bernard J. Koch, David Peterson</dc:creator>
    </item>
  </channel>
</rss>
