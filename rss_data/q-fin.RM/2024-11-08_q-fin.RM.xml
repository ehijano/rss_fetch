<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Preference Robust Optimization with Quasi-Concave Choice Functions in Multi-Attribute Decision-Making: Characterization and Computation</title>
      <link>https://arxiv.org/abs/2008.13309</link>
      <description>arXiv:2008.13309v5 Announce Type: replace 
Abstract: In behavioural economics, a decision maker's (DM's) preferences are often expressed by a preference functional such as expected utility or a distortion risk measure, which assigns a numerical value to a risky prospect. Preference robust optimization (PRO) is about decision making where the DM's preference functional is ambiguous and the optimal decision is based on the worst-case preference functional from a set of plausible ones constructed from available partial information about the DM's true preferences. In this paper, we propose a choice function (a particular class of preference functionals) based PRO model where the DM's preferences over a prospect space satisfy Von Neumann-Morgenstern's (VNM's) axioms of completeness, monotonicity, and continuity. We concentrate on the class of choice functions which are monotonic, quasi-concave, and multi-attribute. The resulting PRO model is broader than the existing expected utility-based PRO models in that: (a) it captures a broader class of DM's preferences; and (b) it can be effectively applied to multi-attribute decision making problems where the DM's preferences over different attributes are related in a nonlinear manner. We propose a cutting plane-type method for evaluating the worst-case choice function and solve the resulting PRO problem by solving a sequence of convex optimization problems. We examine the behavior and scalability of the proposed model and computational schemes numerically on a multi-portfolio optimization problem and a capital allocation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.13309v5</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Wu, William B. Haskell, Wenjie Huang, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>The TruEnd-procedure: Treating trailing zero-valued balances in credit data</title>
      <link>https://arxiv.org/abs/2404.17008</link>
      <description>arXiv:2404.17008v2 Announce Type: replace 
Abstract: A novel procedure is presented for finding the true but latent endpoints within the repayment histories of individual loans. The monthly observations beyond these true endpoints are false, largely due to operational failures that delay account closure, thereby corrupting some loans in the dataset with `false' observations. Detecting these false observations is difficult at scale since each affected loan history might have a different sequence of zero (or very small) month-end balances that persist towards the end. Identifying these trails of diminutive balances would require an exact definition of a "small balance", which can be found using our so-called TruEnd-procedure. We demonstrate this procedure and isolate the ideal small-balance definition using residential mortgages from a large South African bank. Evidently, corrupted loans are remarkably prevalent and have excess histories that are surprisingly long, which ruin the timing of certain risk events and compromise any subsequent time-to-event model such as survival analysis. Excess histories can be discarded using the ideal small-balance definition, which demonstrably improves the accuracy of both the predicted timing and severity of risk events, without materially impacting the monetary value of the portfolio. The resulting estimates of credit losses are lower and less biased, which augurs well for raising accurate credit impairments under the IFRS 9 accounting standard. Our work therefore addresses a pernicious data error, which highlights the pivotal role of data preparation in producing credible forecasts of credit risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17008v2</guid>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arno Botha, Tanja Verster, Roelinde Bester</dc:creator>
    </item>
    <item>
      <title>A Personal data Value at Risk Approach</title>
      <link>https://arxiv.org/abs/2411.03217</link>
      <description>arXiv:2411.03217v2 Announce Type: replace 
Abstract: What if the main data protection vulnerability is risk management? Data Protection merges three disciplines: data protection law, information security, and risk management. Nonetheless, very little research has been made on the field of data protection risk management, where subjectivity and superficiality are the dominant state of the art. Since the GDPR tells you what to do, but not how to do it, the solution for approaching GDPR compliance is still a gray zone, where the trend is using the rule of thumb. Considering that the most important goal of risk management is to reduce uncertainty in order to take informed decisions, risk management for the protection of the rights and freedoms of the data subjects cannot be disconnected from the impact materialization that data controllers and processors need to assess. This paper proposes a quantitative approach to data protection risk-based compliance from a data controllers perspective, with the aim of proposing a mindset change, where data protection impact assessments can be improved by using data protection analytics, quantitative risk analysis, and calibrating expert opinions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03217v2</guid>
      <category>q-fin.RM</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Luis Enriquez</dc:creator>
    </item>
  </channel>
</rss>
