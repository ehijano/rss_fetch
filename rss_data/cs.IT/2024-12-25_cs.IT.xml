<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Democratic Ramp Secret Sharing</title>
      <link>https://arxiv.org/abs/2412.17987</link>
      <description>arXiv:2412.17987v1 Announce Type: new 
Abstract: In this work we revisit the fundamental findings by Chen et al. in [5] on general information transfer in linear ramp secret sharing schemes to conclude that their method not only gives a way to establish worst case leakage [5, 25] and best case recovery [5, 19], but can also lead to additional insight on non-qualifying sets for any prescribed amount of information. We then apply this insight to schemes defined from monomial-Cartesian codes and by doing so we demonstrate that the good schemes from Sec.\ IV in [14] have a second layer of security. Elaborating further, when given a designed recovery number, in a new construction the focus is entirely on ensuring that the access structure possess desirable second layer security, rather on what is the worst case information leakage in terms of number of participants. The particular structure of largest possible sets being not able to determine given amount of information suggests that we call such schemes democratic</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17987v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olav Geil</dc:creator>
    </item>
    <item>
      <title>Age Optimal Sampling for Unreliable Channels under Unknown Channel Statistics</title>
      <link>https://arxiv.org/abs/2412.18119</link>
      <description>arXiv:2412.18119v1 Announce Type: new 
Abstract: In this paper, we study a system in which a sensor forwards status updates to a receiver through an error-prone channel, while the receiver sends the transmission results back to the sensor via a reliable channel. Both channels are subject to random delays. To evaluate the timeliness of the status information at the receiver, we use the Age of Information (AoI) metric. The objective is to design a sampling policy that minimizes the expected time-average AoI, even when the channel statistics (e.g., delay distributions) are unknown. We first review the threshold structure of the optimal offline policy under known channel statistics and then reformulate the design of the online algorithm as a stochastic approximation problem. We propose a Robbins-Monro algorithm to solve this problem and demonstrate that the optimal threshold can be approximated almost surely. Moreover, we prove that the cumulative AoI regret of the online algorithm increases with rate $\mathcal{O}(\ln K)$, where $K$ is the number of successful transmissions. In addition, our algorithm is shown to be minimax order optimal, in the sense that for any online learning algorithm, the cumulative AoI regret up to the $K$-th successful transmissions grows with the rate at least $\Omega(\ln K)$ in the worst case delay distribution. Finally, we improve the stability of the proposed online learning algorithm through a momentum-based stochastic gradient descent algorithm. Simulation results validate the performance of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18119v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hongyi He, Haoyue Tang, Jiayu Pan, Jintao Wang, Jian Song, Leandros Tassiulas</dc:creator>
    </item>
    <item>
      <title>SAR Despeckling via Log-Yeo-Johnson Transformation and Sparse Representation</title>
      <link>https://arxiv.org/abs/2412.18121</link>
      <description>arXiv:2412.18121v1 Announce Type: new 
Abstract: Synthetic Aperture Radar (SAR) images are widely used in remote sensing due to their all-weather, all-day imaging capabilities. However, SAR images are highly susceptible to noise, particularly speckle noise, caused by the coherent imaging process, which severely degrades image quality. This has driven increasing research interest in SAR despeckling. Sparse representation-based denoising has been extensively applied in natural image processing, yet SAR despeckling requires addressing non-Gaussian noise and ensuring sparsity in the transform domain. In this work, we propose an innovative SAR despeckling approach grounded in compressive sensing theory. By applying the Log-Yeo-Johnson transformation, we convert gamma-distributed noise into an approximate Gaussian distribution, facilitating sparse representation. The method incorporates noise and sparsity priors, leveraging a non-local sparse representation through auxiliary matrices: one capturing varying noise characteristics across regions and the other encoding adaptive sparsity information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18121v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuran Hu, Mingzhe Zhu, Djordje Stankovi\'c, Zhenpeng Feng, Shouhan Mao, Ljubi\v{s}a Stankovi\'c</dc:creator>
    </item>
    <item>
      <title>GDM4MMIMO: Generative Diffusion Models for Massive MIMO Communications</title>
      <link>https://arxiv.org/abs/2412.18281</link>
      <description>arXiv:2412.18281v1 Announce Type: new 
Abstract: Massive multiple-input multiple-output (MIMO) offers significant advantages in spectral and energy efficiencies, positioning it as a cornerstone technology of fifth-generation (5G) wireless communication systems and a promising solution for the burgeoning data demands anticipated in sixth-generation (6G) networks. In recent years, with the continuous advancement of artificial intelligence (AI), a multitude of task-oriented generative foundation models (GFMs) have emerged, achieving remarkable performance in various fields such as computer vision (CV), natural language processing (NLP), and autonomous driving. As a pioneering force, these models are driving the paradigm shift in AI towards generative AI (GenAI). Among them, the generative diffusion model (GDM), as one of state-of-the-art families of generative models, demonstrates an exceptional capability to learn implicit prior knowledge and robust generalization capabilities, thereby enhancing its versatility and effectiveness across diverse applications. In this paper, we delve into the potential applications of GDM in massive MIMO communications. Specifically, we first provide an overview of massive MIMO communication, the framework of GFMs, and the working mechanism of GDM. Following this, we discuss recent research advancements in the field and present a case study of near-field channel estimation based on GDM, demonstrating its promising potential for facilitating efficient ultra-dimensional channel statement information (CSI) acquisition in the context of massive MIMO communications. Finally, we highlight several pressing challenges in future mobile communications and identify promising research directions surrounding GDM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18281v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhenzhou Jin, Li You, Huibin Zhou, Yuanshuo Wang, Xiaofeng Liu, Xinrui Gong, Xiqi Gao, Derrick Wing Kwan Ng, Xiang-Gen Xia</dc:creator>
    </item>
    <item>
      <title>Signal Constellation Construction via Radio Frequency Mirrors</title>
      <link>https://arxiv.org/abs/2412.18315</link>
      <description>arXiv:2412.18315v1 Announce Type: new 
Abstract: By integrating feedback with Radio Frequency (RF) mirrors, we develop a closed-loop media-based modulation system for efficient utilization of the signal space. Specifically, this closed-loop construction optimizes the inherited signal constellation from the media, achieving a significantly larger minimum pairwise Euclidean distance than the original configuration. The initial signal constellation, derived from the media, is used to compute a set of complex weights for all activation patterns of the RF mirrors. These complex weights are then fed back to the transmitter to refine the transmit signal before it reaches the mirrors. This feedback mechanism ensures that the received, shaped signal constellation retains improved properties, enabling more reliable transmission. Notably, the closed-loop approach enables the media-based modulation to approach the performance of an AWGN channel, while the channel from each mirror to the single-antenna receiver is modeled as Rayleigh fading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18315v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE WCNC 2025</arxiv:journal_reference>
      <dc:creator>Majid Nasiri Khormuji</dc:creator>
    </item>
    <item>
      <title>On Codes over Eisenstein Integers</title>
      <link>https://arxiv.org/abs/2412.18328</link>
      <description>arXiv:2412.18328v1 Announce Type: new 
Abstract: We propose constructions of codes over quotient rings of Eisenstein integers equipped with the Euclidean, square Euclidean, and hexagonal distances as a generalization of codes over Eisenstein integer fields. By set partitioning, we effectively divide the ring of Eisenstein integers into equal-sized subsets for distinct encoding. Unlike in Eisenstein integer fields of prime size, where partitioning is not feasible due to structural limitations, we partition the quotient rings into additive subgroups in such a way that the minimum square Euclidean and hexagonal distances of each subgroup are strictly larger than in the original set. This technique facilitates multilevel coding and enhances signal constellation efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18328v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdul Hadi, Uha Isnaini, Indah Emilia Wijayanti, Martianus Frederic Ezerman</dc:creator>
    </item>
    <item>
      <title>Calculating the I/O Cost of Linear Repair Schemes for RS Codes Evaluated on Subspaces via Exponential Sums</title>
      <link>https://arxiv.org/abs/2412.18430</link>
      <description>arXiv:2412.18430v1 Announce Type: new 
Abstract: The I/O cost, defined as the amount of data accessed at helper nodes during the repair process, is a crucial metric for repair efficiency of Reed-Solomon (RS) codes. Recently, a formula that relates the I/O cost to the Hamming weight of some linear spaces was proposed in [Liu\&amp;Zhang-TCOM2024]. In this work, we introduce an effective method for calculating the Hamming weight of such linear spaces using exponential sums. With this method, we derive lower bounds on the I/O cost for RS codes evaluated on a $d$-dimensional subspace of $\mathbb{F}_{q^\ell}$ with $r=2$ or $3$ parities. These bounds are exactly matched in the cases $r=2,\ell-d+1\mid\ell$ and $r=3,d=\ell$ or $\ell-d+2\mid\ell$, via the repair schemes designed in this work. We refer to schemes that achieve the lower bound as I/O-optimal repair schemes. Additionally, we characterize the optimal repair bandwidth of I/O-optimal repair schemes for full-length RS codes with two parities, and build an I/O-optimal repair scheme for full-length RS codes with three parities, achieving lower repair bandwidth than previous schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18430v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyan Liu, Jingke Xu, Zhifang Zhang</dc:creator>
    </item>
    <item>
      <title>Continuous-variable designs and design-based shadow tomography from random lattices</title>
      <link>https://arxiv.org/abs/2412.17909</link>
      <description>arXiv:2412.17909v1 Announce Type: cross 
Abstract: We investigate state designs for continuous-variable quantum systems using the aid of lattice-like quantum states. These are code states of Gottesman-Kitaev-Preskill (GKP) codes. We show that for an n-mode system, the set of all GKP states forms a rigged continuous-variable state 2-design. We use these lattice state designs to construct a continuous variable shadow tomography protocol, derive sample complexity bounds for both global- and local GKP shadows under reasonable physical assumptions, and provide the physical gadgets needed to implement this protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17909v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OA</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Conrad, Joseph T. Iosue, Ansgar G. Burchards, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>Extendible quantum measurements and limitations on classical communication</title>
      <link>https://arxiv.org/abs/2412.18556</link>
      <description>arXiv:2412.18556v1 Announce Type: cross 
Abstract: Unextendibility of quantum states and channels is inextricably linked to the no-cloning theorem of quantum mechanics, it has played an important role in understanding and quantifying entanglement, and more recently it has found applications in providing limitations on quantum error correction and entanglement distillation. Here we generalize the framework of unextendibility to quantum measurements and define $k$-extendible measurements for every integer $k\ge 2$. Our definition provides a hierarchy of semidefinite constraints that specify a set of measurements containing every measurement that can be realized by local operations and one-way classical communication. Furthermore, the set of $k$-extendible measurements converges to the set of measurements that can be realized by local operations and one-way classical communication as $k\to \infty$. To illustrate the utility of $k$-extendible measurements, we establish a semidefinite programming upper bound on the one-shot classical capacity of a channel, which outperforms the best known efficiently computable bound from [Matthews and Wehner, IEEE Trans. Inf. Theory 60, pp. 7317-7329 (2014)] and also leads to efficiently computable upper bounds on the $n$-shot classical capacity of a channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18556v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vishal Singh, Theshani Nuradha, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Double Spending Analysis of Nakamoto Consensus for Time-Varying Mining Rates with Ruin Theory</title>
      <link>https://arxiv.org/abs/2412.18599</link>
      <description>arXiv:2412.18599v1 Announce Type: cross 
Abstract: Theoretical guarantees for double spending probabilities for the Nakamoto consensus under the $k$-deep confirmation rule have been extensively studied for zero/bounded network delays and fixed mining rates. In this paper, we introduce a ruin-theoretical model of double spending for Nakamoto consensus under the $k$-deep confirmation rule when the honest mining rate is allowed to be an arbitrary function of time including the block delivery periods, i.e., time periods during which mined blocks are being delivered to all other participants of the network. Time-varying mining rates are considered to capture the intrinsic characteristics of the peer to peer network delays as well as dynamic participation of miners such as the gap game and switching between different cryptocurrencies. Ruin theory is leveraged to obtain the double spend probabilities and numerical examples are presented to validate the effectiveness of the proposed analytical method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18599v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa Doger, Sennur Ulukus, Nail Akar</dc:creator>
    </item>
    <item>
      <title>Generalized Orthogonal Procrustes Problem under Arbitrary Adversaries</title>
      <link>https://arxiv.org/abs/2106.15493</link>
      <description>arXiv:2106.15493v3 Announce Type: replace 
Abstract: The generalized orthogonal Procrustes problem (GOPP) plays a fundamental role in several scientific disciplines including statistics, imaging science and computer vision. Despite its tremendous practical importance, it is generally an NP-hard problem to find the least squares estimator. We study the semidefinite relaxation (SDR) and an iterative method named generalized power method (GPM) to find the least squares estimator, and investigate the performance under a signal-plus-noise model. We show that the SDR recovers the least squares estimator exactly and moreover the generalized power method with a proper initialization converges linearly to the global minimizer to the SDR, provided that the signal-to-noise ratio is large. The main technique follows from showing the nonlinear mapping involved in the GPM is essentially a local contraction mapping and then applying the well-known Banach fixed-point theorem finishes the proof. In addition, we analyze the low-rank factorization algorithm and show the corresponding optimization landscape is free of spurious local minimizers under nearly identical conditions that enables the success of SDR approach. The highlight of our work is that the theoretical guarantees are purely algebraic and do not assume any statistical priors of the additive adversaries, and thus it applies to various interesting settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.15493v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>Explicit Performance Bound of Finite Blocklength Coded MIMO: Time-Domain versus Spatiotemporal Channel Coding</title>
      <link>https://arxiv.org/abs/2406.13922</link>
      <description>arXiv:2406.13922v2 Announce Type: replace 
Abstract: In the sixth generation (6G), ultra-reliable low-latency communications (URLLC) will further develop to achieve TKu extreme connectivity, and multiple-input multiple-output (MIMO) is expected to be a key enabler for its realization. On the premise of ensuring the same rate and reliability, the spatial domain advantage of MIMO has the potential to further shorten the time-domain code length. Different coded MIMO schemes exhibit disparities in exploiting the spatial domain characteristics, so it is necessary to theoretically elucidate the performance of different coding schemes to illustrate how MIMO can support 6G TKu transmission. We consider two extreme MIMO coding schemes, namely, time-domain coded MIMO where the codewords on multiple spatial channels are independent of each other, and spatiotemporal coded MIMO in which multiple spatial channels are jointly coded. In this paper, by analyzing the statistical characteristics of information density and utilizing the normal approximation, we provide explicit performance bounds for finite blocklength coded MIMO under time-domain coding and spatiotemporal coding. We find that spatiotemporal coding can effectively alleviate the performance degradation induced by short blocklength by improving the spatial degrees of freedom (DoF). However, for time-domain coding, the independent coding of each spatial link results in more severe performance degradation due to shorter blocklength, even when a relatively large spatial DoF is available. These results indicate that spatiotemporal coding can optimally exploit the spatial dimension advantages of MIMO systems compared with time-domain coding, enabling extremely low error-rate communication under stringent blocklength constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13922v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Ye, Xiaohu You, Jiamin Li, Chuan Zhang, Chen Ji</dc:creator>
    </item>
    <item>
      <title>Multibeam Satellite Communications with Massive MIMO: Asymptotic Performance Analysis and Design Insights</title>
      <link>https://arxiv.org/abs/2407.10461</link>
      <description>arXiv:2407.10461v2 Announce Type: replace 
Abstract: To achieve high performance without substantial overheads associated with channel state information (CSI) of ground users, we consider a fixed-beam precoding approach, where a satellite forms multiple fixed-beams without relying on CSI, then select a suitable user set for each beam. Upon this precoding method, we put forth a satellite equipped with massive multiple-input multiple-output (MIMO), by which inter-beam interference is efficiently mitigated by narrowing corresponding beam width. By modeling the ground users' locations via a Poisson point process, we rigorously analyze the achievable performance of the presented multibeam satellite system. In particular, we investigate the asymptotic scaling laws that reveal the interplay between the user density, the number of beams, and the number of antennas. Our analysis offers critical design insights for the multibeam satellite with massive MIMO: i) If the user density scales in power with the number of antennas, the considered precoding can achieve a linear fraction of the optimal rate in the asymptotic regime. ii) A certain additional scaling factor for the user density is needed as the number of beams increases to maintain the asymptotic optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10461v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Seyong Kim, Jinseok Choi, Wonjae Shin, Namyoon Lee, Jeonghun Park</dc:creator>
    </item>
    <item>
      <title>3D Extended Target Sensing in ISAC: Cram\'er-Rao Bound Analysis and Beamforming Design</title>
      <link>https://arxiv.org/abs/2412.06353</link>
      <description>arXiv:2412.06353v2 Announce Type: replace 
Abstract: This paper investigates an integrated sensing and communication (ISAC) system where the sensing target is a three-dimensional (3D) extended target, for which multiple scatterers from the target surface can be resolved. We first introduce a second-order truncated Fourier series surface model for an arbitrarily-shaped 3D ET. Utilizing this model, we derive tractable Cramer-Rao bounds (CRBs) for estimating the ET kinematic parameters, including the center range, azimuth, elevation, and orientation. These CRBs depend explicitly on the transmit covariance matrix and ET shape. Then we formulate two transmit beamforming optimization problems for the base station (BS) to simultaneously support communication with multiple users and sensing of the 3D ET. The first minimizes the sensing CRB while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for each user, and it is solved using semidefinite relaxation. The second balances minimizing the CRB and maximizing communication rates through a weight factor, and is solved via successive convex approximation. To reduce the computational complexity, we further propose ISACBeam-GNN, a novel graph neural network-based beamforming method that employs a separate-then-integrate structure, learning communication and sensing (C&amp;S) objectives independently before integrating them to balance C&amp;S trade-offs. Simulation results show that the proposed beamforming designs that account for ET shapes significantly outperform existing baselines, offering better communication-sensing performance trade-offs as well as an improved beampattern for sensing. Results also demonstrate that ISACBeam-GNN is an efficient alternative to the optimization-based methods, with remarkable adaptability and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06353v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqiu Wang, Meixia Tao, Shu Sun, Wei Cao</dc:creator>
    </item>
    <item>
      <title>Directivity-Aware Degrees of Freedom Analysis for Extremely Large-Scale MIMO</title>
      <link>https://arxiv.org/abs/2412.14657</link>
      <description>arXiv:2412.14657v2 Announce Type: replace 
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) communications, enabled by numerous antenna elements integrated into large antenna surfaces, can provide increased effective degree of freedom (EDoF) to achieve high diversity gain. However, it remains an open problem that how the EDoF is influenced by the directional radiation pattern of antenna elements. In this work, empowered by the wavenumber-domain channel representation, we analyze the EDoF in a general case where the directivity of antennas, determined by the antenna structure and element spacing, is considered. Specifically, we first reveal the uneven distribution of directivity-aware wavenumber-domain coupling coefficients, i.e., channel gain towards different directions, in the isotropic Rayleigh fading channel. EDoF is then calculated based on such distribution of coupling coefficients. A numerical method is also provided to obtain coupling coefficients via electromagnetic full-wave simulations. Due to the influence of antenna directivity, how EDoF and ergodic channel capacity vary with the element spacing are explored via simulations for different antenna types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14657v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaohua Yue, Liang Liu, Boya Di</dc:creator>
    </item>
    <item>
      <title>Complexity of inversion of functions on the reals</title>
      <link>https://arxiv.org/abs/2412.07592</link>
      <description>arXiv:2412.07592v2 Announce Type: replace-cross 
Abstract: We study the complexity of deterministic and probabilistic inversions of partial computable functions on the reals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07592v2</guid>
      <category>math.LO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Barmpalias, Mingyang Wang, Xiaoyan Zhang</dc:creator>
    </item>
    <item>
      <title>L3TC: Leveraging RWKV for Learned Lossless Low-Complexity Text Compression</title>
      <link>https://arxiv.org/abs/2412.16642</link>
      <description>arXiv:2412.16642v2 Announce Type: replace-cross 
Abstract: Learning-based probabilistic models can be combined with an entropy coder for data compression. However, due to the high complexity of learning-based models, their practical application as text compressors has been largely overlooked. To address this issue, our work focuses on a low-complexity design while maintaining compression performance. We introduce a novel Learned Lossless Low-complexity Text Compression method (L3TC). Specifically, we conduct extensive experiments demonstrating that RWKV models achieve the fastest decoding speed with a moderate compression ratio, making it the most suitable backbone for our method. Second, we propose an outlier-aware tokenizer that uses a limited vocabulary to cover frequent tokens while allowing outliers to bypass the prediction and encoding. Third, we propose a novel high-rank reparameterization strategy that enhances the learning capability during training without increasing complexity during inference. Experimental results validate that our method achieves 48% bit saving compared to gzip compressor. Besides, L3TC offers compression performance comparable to other learned compressors, with a 50x reduction in model parameters. More importantly, L3TC is the fastest among all learned compressors, providing real-time decoding speeds up to megabytes per second. Our code is available at https://github.com/alipay/L3TC-leveraging-rwkv-for-learned-lossless-low-complexity-text-compression.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16642v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.MM</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junxuan Zhang, Zhengxue Cheng, Yan Zhao, Shihao Wang, Dajiang Zhou, Guo Lu, Li Song</dc:creator>
    </item>
  </channel>
</rss>
