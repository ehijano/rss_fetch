<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Dec 2025 05:03:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Robust Two-Sample Mean Inference under Serial Dependence</title>
      <link>https://arxiv.org/abs/2512.11259</link>
      <description>arXiv:2512.11259v1 Announce Type: new 
Abstract: We propose robust two-sample tests for comparing means in time series. The framework accommodates a wide range of applications, including structural breaks, treatment-control comparisons, and group-averaged panel data. We first consider series HAR two-sample t-tests, where standardization employs orthonormal basis projections, ensuring valid inference under heterogeneity and nonparametric dependence structures. We propose a Welch-type t-approximation with adjusted degrees of freedom to account for long-run variance heterogeneity across the series. We further develop a series-based HAR wild bootstrap test, extending traditional wild bootstrap methods to the time-series setting. Our bootstrap avoids resampling blocks of observations and delivers superior finite-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11259v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ulrich Hounyo, Min Seong Kim</dc:creator>
    </item>
    <item>
      <title>Testing Parametric Distribution Family Assumptions via Differences in Differential Entropy</title>
      <link>https://arxiv.org/abs/2512.11305</link>
      <description>arXiv:2512.11305v1 Announce Type: new 
Abstract: We introduce a broadly applicable statistical procedure for testing which parametric distribution family generated a random sample of data. The method, termed the Difference in Differential Entropy (DDE) test, provides a unified framework applicable to a wide range of distributional families, with asymptotic validity grounded in established maximum likelihood, bootstrap, and kernel density estimation principles. The test is straightforward to implement, computationally efficient, and requires no tuning parameters or specialized regularity conditions. It compares an MLE-based estimate of differential entropy under the null hypothesis with a nonparametric bootstrapped kernel density estimate, using their divergence as an information-theoretic measure of model fit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11305v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ron Mittelhammer, George Judge, Miguel Henry</dc:creator>
    </item>
    <item>
      <title>Counting Defiers: A Design-Based Model of an Experiment Can Reveal Evidence Beyond the Average Effect</title>
      <link>https://arxiv.org/abs/2412.16352</link>
      <description>arXiv:2412.16352v4 Announce Type: replace 
Abstract: We estimate the numbers of always takers, compliers, defiers, and never takers in the sample of people in an experiment, rather than a hypothetical population from which it was drawn, using structure from the randomization design. Our data include only a binary intervention and outcome. We develop a visualization to show that samples with defiers can sometimes generate the data in more ways than samples without defiers, yielding a higher design-based likelihood. We propose a maximum likelihood decision rule that can harness this evidence, which is not captured by standard hypothesis tests, and we provide optimality conditions. We illustrate the output of our decision rule for all possible data in samples of 50 and 200 with half in intervention, demonstrating a pattern in when the MLE includes defiers despite a positive average effect. We provide insights into effect heterogeneity in two published experiments with interventions that could plausibly backfire for some people despite statistically significant positive average effects on takeup of desirable health behaviors. In both, our 95% credible sets include the estimated Frechet bounds, demonstrating that evidence is weak. Yet, our MLE includes no defiers in one; in the other, the MLE includes a count of defiers equal to the estimated upper Frechet bound, over 18% of the sample. The MLE can support a monotonicity assumption or a specific alternative as a step toward improving the average effect of future interventions by targeting them away from noncompliers. Our dbmle package, compatible with Python and Stata, implements our statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16352v4</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neil Christy, Amanda Ellen Kowalski</dc:creator>
    </item>
    <item>
      <title>A sensitivity analysis for the average derivative effect</title>
      <link>https://arxiv.org/abs/2511.06243</link>
      <description>arXiv:2511.06243v2 Announce Type: replace-cross 
Abstract: In observational studies, exposures are often continuous rather than binary or discrete. At the same time, sensitivity analysis is an important tool that can help determine the robustness of a causal conclusion to a certain level of unmeasured confounding, which can never be ruled out in an observational study. Sensitivity analysis approaches for continuous exposures have now been proposed for several causal estimands. In this article, we focus on the average derivative effect (ADE). We obtain closed-form bounds for the ADE under a sensitivity model that constrains the odds ratio (at any two dose levels) between the latent and observed generalized propensity score. We propose flexible, efficient estimators for the bounds, as well as point-wise and simultaneous (over the sensitivity parameter) confidence intervals. We examine the finite sample performance of the methods through simulations and illustrate the methods on a study assessing the effect of parental income on educational attainment and a study assessing the price elasticity of petrol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06243v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Zhang</dc:creator>
    </item>
  </channel>
</rss>
