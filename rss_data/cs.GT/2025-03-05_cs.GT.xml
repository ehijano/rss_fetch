<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Mar 2025 02:49:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning a Game by Paying the Agents</title>
      <link>https://arxiv.org/abs/2503.01976</link>
      <description>arXiv:2503.01976v1 Announce Type: new 
Abstract: We study the problem of learning the utility functions of agents in a normal-form game by observing the agents play the game repeatedly. Differing from most prior literature, we introduce a principal with the power to observe the agents playing the game, send the agents signals, and send the agents payments as a function of their actions. Under reasonable behavioral models for the agents such as iterated dominated action removal or a no-regret assumption, we show that the principal can, using a number of rounds polynomial in the size of the game, learn the utility functions of all agents to any desirable precision $\varepsilon &gt; 0$. We also show lower bounds in both models, which nearly match the upper bounds in the former model and also strictly separate the two models: the principal can learn strictly faster in the iterated dominance model. Finally, we discuss implications for the problem of steering agents to a desired equilibrium: in particular, we introduce, using our utility-learning algorithm as a subroutine, the first algorithm for steering learning agents without prior knowledge of their utilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01976v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Hu Zhang, Tao Lin, Yiling Chen, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Proportionality in Thumbs Up and Down Voting</title>
      <link>https://arxiv.org/abs/2503.01985</link>
      <description>arXiv:2503.01985v1 Announce Type: new 
Abstract: Consider the decision-making setting where agents elect a panel by expressing both positive and negative preferences. Prominently, in constitutional AI, citizens democratically select a slate of ethical preferences on which a foundation model is to be trained. There, in practice, agents may both approve and disapprove of different ethical principles. Proportionality has been well-studied in computational social choice for approval ballots, but its meaning remains unclear when negative sentiments are also considered. In this work, we propose two conceptually distinct approaches to interpret proportionality in the presence of up and down votes. The first approach treats the satisfaction from electing candidates and the impact of vetoing them as comparable, leading to combined proportionality guarantees. The second approach considers veto power separately, introducing guarantees distinct from traditional proportionality. We formalize axioms for each perspective and examine their satisfiability by suitable adaptations of Phragm\'en's rule, Proportional Approval Voting rule and the Method of Equal Shares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01985v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sonja Kraiczy, Georgios Papasotiropoulos, Grzegorz Pierczy\'nski, Piotr Skowron</dc:creator>
    </item>
    <item>
      <title>Online Fair Division: Towards Ex-Post Constant MMS Guarantees</title>
      <link>https://arxiv.org/abs/2503.02088</link>
      <description>arXiv:2503.02088v1 Announce Type: new 
Abstract: We investigate the problem of fairly allocating $m$ indivisible items among $n$ sequentially arriving agents with additive valuations, under the sought-after fairness notion of maximin share (MMS). We first observe a strong impossibility: without appropriate knowledge about the valuation functions of the incoming agents, no online algorithm can ensure any non-trivial MMS approximation, even when there are only two agents. Motivated by this impossibility, we introduce OnlineKTypeFD (online $k$-type fair division), a model that balances theoretical tractability with real-world applicability. In this model, each arriving agent belongs to one of $k$ types, with all agents of a given type sharing the same known valuation function. We do not constrain $k$ to be a constant. Upon arrival, an agent reveals her type, receives an irrevocable allocation, and departs. We study the ex-post MMS guarantees of online algorithms under two arrival models:
  1- Adversarial arrivals: In this model, an adversary determines the type of each arriving agent. We design a $\frac{1}{k}$-MMS competitive algorithm and complement it with a lower bound, ruling out any $\Omega(\frac{1}{\sqrt{k}})$-MMS-competitive algorithm, even for binary valuations.
  2- Stochastic arrivals: In this model, the type of each arriving agent is independently drawn from an underlying, possibly unknown distribution. Unlike the adversarial setting where the dependence on $k$ is unavoidable, we surprisingly show that in the stochastic setting, an asymptotic, arbitrarily close-to-$\frac{1}{2}$-MMS competitive guarantee is achievable under mild distributional assumptions.
  Our results extend naturally to a learning-augmented framework; when given access to predictions about valuation functions, we show that the competitive ratios of our algorithms degrade gracefully with multiplicative prediction errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02088v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pooja Kulkarni, Ruta Mehta, Parnian Shahkar</dc:creator>
    </item>
    <item>
      <title>Improved MMS Approximations for Few Agent Types</title>
      <link>https://arxiv.org/abs/2503.02089</link>
      <description>arXiv:2503.02089v1 Announce Type: new 
Abstract: We study fair division of indivisible goods under the maximin share (MMS) fairness criterion in settings where agents are grouped into a small number of types, with agents within each type having identical valuations. For the special case of a single type, an exact MMS allocation is always guaranteed to exist. However, for two or more distinct agent types, exact MMS allocations do not always exist, shifting the focus to establishing the existence of approximate-MMS allocations. A series of works over the last decade has resulted in the best-known approximation guarantee of $\frac{3}{4} + \frac{3}{3836}$.
  In this paper, we improve the approximation guarantees for settings where agents are grouped into two or three types, a scenario that arises in many practical settings. Specifically, we present novel algorithms that guarantee a $\frac{4}{5}$-MMS allocation for two agent types and a $\frac{16}{21}$-MMS allocation for three agent types. Our approach leverages the MMS partition of the majority type and adapts it to provide improved fairness guarantees for all types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02089v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jugal Garg, Parnian Shahkar</dc:creator>
    </item>
    <item>
      <title>A differential model of $N$ player games concerning ethical dilemmas</title>
      <link>https://arxiv.org/abs/2503.02326</link>
      <description>arXiv:2503.02326v1 Announce Type: new 
Abstract: Ethics play an important role in determining the behavior of an individual under certain circumstances. Ethical or unethical behavior can be treated as a strategy of a player in a pay-off game. In this paper, we present two analytical solutions to studying time evolution of behavior of an individual from ethics perspective. We also present the effect of a third player as a perturbation to a two player game and develop a general approach for a $N$ player game. We demonstrate geometric modeling of behavioral characteristics of individuals as polytopes residing in $D$ dimensional space. We treat three player and two player games using set of differential equations that lead to time evolution of phase trajectories which reveal about the interdependencies and self dependencies of each player. We also demonstrate the effect of strategies of each player on other players in cardinal games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02326v1</guid>
      <category>cs.GT</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramkrishna Joshi, Aniruddha Joshi</dc:creator>
    </item>
    <item>
      <title>The Inversion Paradox and Ranking Methods in Tournaments</title>
      <link>https://arxiv.org/abs/2503.02429</link>
      <description>arXiv:2503.02429v1 Announce Type: new 
Abstract: This article deals with ranking methods. We study the situation where a tournament between $n$ players $P_1$, $P_2$, \ldots $P_n$ gives the ranking $P_1 \succ P_2 \succ \cdots \succ P_n$, but, if the results of $P_n$ are no longer taken into account (for example $P_n$ is suspended for doping), then the ranking becomes $P_{n-1} \succ P_{n-2} \succ \cdots \succ P_2 \succ P_1$. If such a situation arises, we call it an inversion paradox. In this article, we give a sufficient condition for the inversion paradox to occur. More precisely, we give an impossibility theorem. We prove that if a ranking method satisfies three reasonable properties (the ranking must be natural, reducible by Condorcet tournaments and satisfies the long tournament property) then we cannot avoid the inversion paradox, i.e., there are tournaments where the inversion paradox occurs. We then show that this paradox can occur when we use classical methods, e.g., Borda, Massey, Colley and Markov methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02429v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Ch\'eze (IMT), Etienne Fieux (IMT)</dc:creator>
    </item>
    <item>
      <title>Succinct Ambiguous Contracts</title>
      <link>https://arxiv.org/abs/2503.02592</link>
      <description>arXiv:2503.02592v1 Announce Type: new 
Abstract: Real-world contracts are often ambiguous. Recent work by D\"utting et al. (EC 2023, Econometrica 2024) models ambiguous contracts as a collection of classic contracts, with the agent choosing an action that maximizes his worst-case utility. In this model, optimal ambiguous contracts have been shown to be ``simple" in that they consist of single-outcome payment (SOP) contracts, and can be computed in polynomial-time. However, this simplicity is challenged by the potential need for many classic contracts. Motivated by this, we explore \emph{succinct} ambiguous contracts, where the ambiguous contract is restricted to consist of at most $k$ classic contracts. Unlike in the unrestricted case, succinct ambiguous contracts are no longer composed solely of SOP contracts, making both their structure and computation more complex.
  We show that, despite this added complexity, optimal succinct ambiguous contracts are governed by a simple divide-and-conquer principle, showing that they consist of ``shifted min-pay contracts" for a suitable partition of the actions. This structural insight implies a characterization of implementability by succinct ambiguous contracts, and can be leveraged to devise an algorithm for the optimal succinct ambiguous contract. While this algorithm is polynomial for $k$ sufficiently close to $n$, for smaller values of $k$, this algorithm is exponential, and we show that this is inevitable (unless P=NP) by establishing NP-hardness for any constant $k$, or $k=\beta n$ for some $\beta\in(0,1)$. Finally, we introduce the succinctness gap measure to quantify the loss incurred due to succinctness, and provide upper and lower bounds on this gap. Interestingly, in the case where we are missing just a single contract from the number sufficient to obtain the utility of the unrestricted case, the principal's utility drops by a factor of $2$, and this is tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02592v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Duetting, Michal Feldman, Yarden Rashti</dc:creator>
    </item>
    <item>
      <title>A Game-Theoretic Approach for High-Resolution Automotive FMCW Radar Interference Avoidance</title>
      <link>https://arxiv.org/abs/2503.02327</link>
      <description>arXiv:2503.02327v1 Announce Type: cross 
Abstract: Nonlinear frequency hopping has emerged as a promising approach for mitigating interference and enhancing range resolution in automotive FMCW radar systems. Achieving an optimal balance between high range-resolution and effective interference mitigation remains challenging, especially without centralized frequency scheduling. This paper presents a game-theoretic framework for interference avoidance, in which each radar operates as an independent player, optimizing its performance through decentralized decision-making. We examine two equilibrium concepts--Nash Equilibrium (NE) and Coarse Correlated Equilibrium (CCE)--as strategies for frequency band allocation, with CCE demonstrating particular effectiveness through regret minimization algorithms. We propose two interference avoidance algorithms: Nash Hopping, a model-based approach, and No-Regret Hopping, a model-free adaptive method. Simulation results indicate that both methods effectively reduce interference and enhance the signal-to-interference-plus-noise ratio (SINR). Notably, No-regret Hopping further optimizes frequency spectrum utilization, achieving improved range resolution compared to Nash Hopping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02327v1</guid>
      <category>eess.SP</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunian Pan, Jun Li, Lifan Xu, Shunqiao Sun, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Playing games with Large language models: Randomness and strategy</title>
      <link>https://arxiv.org/abs/2503.02582</link>
      <description>arXiv:2503.02582v1 Announce Type: cross 
Abstract: Playing games has a long history of describing intricate interactions in simplified forms. In this paper we explore if large language models (LLMs) can play games, investigating their capabilities for randomisation and strategic adaptation through both simultaneous and sequential game interactions. We focus on GPT-4o-Mini-2024-08-17 and test two games between LLMs: Rock Paper Scissors (RPS) and games of strategy (Prisoners Dilemma PD). LLMs are often described as stochastic parrots, and while they may indeed be parrots, our results suggest that they are not very stochastic in the sense that their outputs - when prompted to be random - are often very biased. Our research reveals that LLMs appear to develop loss aversion strategies in repeated games, with RPS converging to stalemate conditions while PD shows systematic shifts between cooperative and competitive outcomes based on prompt design. We detail programmatic tools for independent agent interactions and the Agentic AI challenges faced in implementation. We show that LLMs can indeed play games, just not very well. These results have implications for the use of LLMs in multi-agent LLM systems and showcase limitations in current approaches to model output for strategic decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02582v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alicia Vidler, Toby Walsh</dc:creator>
    </item>
    <item>
      <title>A Tight Regret Analysis of Non-Parametric Repeated Contextual Brokerage</title>
      <link>https://arxiv.org/abs/2503.02646</link>
      <description>arXiv:2503.02646v1 Announce Type: cross 
Abstract: We study a contextual version of the repeated brokerage problem. In each interaction, two traders with private valuations for an item seek to buy or sell based on the learner's-a broker-proposed price, which is informed by some contextual information. The broker's goal is to maximize the traders' net utility-also known as the gain from trade-by minimizing regret compared to an oracle with perfect knowledge of traders' valuation distributions. We assume that traders' valuations are zero-mean perturbations of the unknown item's current market value-which can change arbitrarily from one interaction to the next-and that similar contexts will correspond to similar market prices. We analyze two feedback settings: full-feedback, where after each interaction the traders' valuations are revealed to the broker, and limited-feedback, where only transaction attempts are revealed. For both feedback types, we propose algorithms achieving tight regret bounds. We further strengthen our performance guarantees by providing a tight 1/2-approximation result showing that the oracle that knows the traders' valuation distributions achieves at least 1/2 of the gain from trade of the omniscient oracle that knows in advance the actual realized traders' valuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02646v1</guid>
      <category>stat.ML</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc, Tommaso Cesari, Roberto Colomboni</dc:creator>
    </item>
    <item>
      <title>On Separation Between Best-Iterate, Random-Iterate, and Last-Iterate Convergence of Learning in Games</title>
      <link>https://arxiv.org/abs/2503.02825</link>
      <description>arXiv:2503.02825v1 Announce Type: cross 
Abstract: Non-ergodic convergence of learning dynamics in games is widely studied recently because of its importance in both theory and practice. Recent work (Cai et al., 2024) showed that a broad class of learning dynamics, including Optimistic Multiplicative Weights Update (OMWU), can exhibit arbitrarily slow last-iterate convergence even in simple $2 \times 2$ matrix games, despite many of these dynamics being known to converge asymptotically in the last iterate. It remains unclear, however, whether these algorithms achieve fast non-ergodic convergence under weaker criteria, such as best-iterate convergence. We show that for $2\times 2$ matrix games, OMWU achieves an $O(T^{-1/6})$ best-iterate convergence rate, in stark contrast to its slow last-iterate convergence in the same class of games. Furthermore, we establish a lower bound showing that OMWU does not achieve any polynomial random-iterate convergence rate, measured by the expected duality gaps across all iterates. This result challenges the conventional wisdom that random-iterate convergence is essentially equivalent to best-iterate convergence, with the former often used as a proxy for establishing the latter. Our analysis uncovers a new connection to dynamic regret and presents a novel two-phase approach to best-iterate convergence, which could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02825v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Gabriele Farina, Julien Grand-Cl\'ement, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Approximate Optimality of Linear Contracts Under Uncertainty</title>
      <link>https://arxiv.org/abs/2211.06850</link>
      <description>arXiv:2211.06850v3 Announce Type: replace 
Abstract: We consider a hidden-action principal-agent model, in which actions require different amounts of effort, and the agent privately knows his ability that determines his cost of effort. We show that linear contracts admit approximation guarantees that improve with a natural metric that captures the degree of uncertainty in the contracting setting. We thus show that linear contracts are near-optimal whenever there is enough uncertainty. In contrast, other simple contract formats such as debt contracts may suffer from a loss linear in the number of possible actions, even when there is sufficient uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06850v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tal Alon, Paul D\"utting, Yingkai Li, Inbal Talgam-Cohen</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games</title>
      <link>https://arxiv.org/abs/2311.00676</link>
      <description>arXiv:2311.00676v2 Announce Type: replace 
Abstract: We study last-iterate convergence properties of algorithms for solving two-player zero-sum games based on Regret Matching$^+$ (RM$^+$). Despite their widespread use for solving real games, virtually nothing is known about their last-iterate convergence. A major obstacle to analyzing RM-type dynamics is that their regret operators lack Lipschitzness and (pseudo)monotonicity. We start by showing numerically that several variants used in practice, such as RM$^+$, predictive RM$^+$ and alternating RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\times 3$ matrix game. We then prove that recent variants of these algorithms based on a smoothing technique, extragradient RM$^{+}$ and smooth Predictive RM$^+$, enjoy asymptotic last-iterate convergence (without a rate), $1/\sqrt{t}$ best-iterate convergence, and when combined with restarting, linear-rate last-iterate convergence. Our analysis builds on a new characterization of the geometric structure of the limit points of our algorithms, marking a significant departure from most of the literature on last-iterate convergence. We believe that our analysis may be of independent interest and offers a fresh perspective for studying last-iterate convergence in algorithms based on non-monotone operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00676v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Gabriele Farina, Julien Grand-Cl\'ement, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Compatibility of Fairness and Nash Welfare under Subadditive Valuations</title>
      <link>https://arxiv.org/abs/2407.12461</link>
      <description>arXiv:2407.12461v3 Announce Type: replace 
Abstract: We establish a compatibility between fairness and efficiency, captured via Nash Social Welfare (NSW), under the broad class of subadditive valuations. We prove that, for subadditive valuations, there always exists a partial allocation that is envy-free up to the removal of any good (EFx) and has NSW at least half of the optimal; here, optimality is considered across all allocations, fair or otherwise. We also prove, for subadditive valuations, the universal existence of complete allocations that are envy-free up to one good (EF1) and also achieve a factor $1/2$ approximation to the optimal NSW. Our EF1 result resolves an open question posed by Garg, Husic, Li, V\'{e}gh, and Vondr\'{a}k (STOC 2023).
  In addition, we develop a polynomial-time algorithm which, given an arbitrary allocation $\widetilde{A}$ as input, returns an EF1 allocation with NSW at least $\frac{1}{e^{2/e}}\approx \frac{1}{2.08}$ times that of $\widetilde{A}$. Therefore, our results imply that the EF1 criterion can be attained simultaneously with a constant-factor approximation to optimal NSW in polynomial time (with demand queries), for subadditive valuations. The previously best-known approximation factor for optimal NSW, under EF1 and among $n$ agents, was $O(n)$ -- we improve this bound to $O(1)$.
  It is known that EF1 and exact Pareto efficiency (PO) are incompatible with subadditive valuations. Complementary to this negative result, the current work shows that we regain compatibility by just considering a factor $1/2$ approximation: EF1 can be achieved in conjunction with $\frac{1}{2}$-PO under subadditive valuations. As such, our results serve as a general tool that can be used as a black box to convert any efficient outcome into a fair one, with only a marginal decrease in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12461v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Barman, Mashbat Suzuki</dc:creator>
    </item>
    <item>
      <title>Semicoarse Correlated Equilibria and LP-Based Guarantees for Gradient Dynamics in Normal-Form Games</title>
      <link>https://arxiv.org/abs/2502.20466</link>
      <description>arXiv:2502.20466v2 Announce Type: replace 
Abstract: Projected gradient ascent describes a form of no-regret learning algorithm that is known to converge to a coarse correlated equilibrium. Recent results showed that projected gradient ascent often finds the Nash equilibrium, even in situations where the set of coarse correlated equilibria is very large. We introduce semicoarse correlated equilibria, a solution concept that refines coarse correlated equilibria for the outcomes of gradient dynamics, while remaining computationally tractable through linear programming representations. Our theoretical analysis of the discretised Bertrand competition mirrors those recently established for mean-based learning in first-price auctions. With at least two firms of lowest marginal cost, Nash equilibria emerge as the only semicoarse equilibria under concavity conditions on firm profits. In first-price auctions, the granularity of the bid space affects semicoarse equilibria, but finer granularity for lower bids also induces convergence to Nash equilibria. Unlike previous work that aims to prove convergence to a Nash equilibrium that often relies on epoch based analysis and probability theoretic machinery, our LP-based duality approach enables a simple and tractable analysis of equilibrium selection under gradient-based learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20466v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mete \c{S}eref Ahunbay, Martin Bichler</dc:creator>
    </item>
    <item>
      <title>Static Pricing Guarantees for Queueing Systems</title>
      <link>https://arxiv.org/abs/2305.09168</link>
      <description>arXiv:2305.09168v4 Announce Type: replace-cross 
Abstract: We consider a general queueing model with price-sensitive customers in which the service provider seeks to balance two objectives, maximizing the average revenue rate and minimizing the average queue length. Customers arrive according to a Poisson process, observe an offered price, and decide to join the queue if their valuation exceeds the price. The queue is operated first-in first-out, and the service times are exponential. Our model represents applications in areas like make-to-order manufacturing, cloud computing, and food delivery.
  The optimal solution for our model is dynamic; the price changes as the state of the system changes. However, such dynamic pricing policies may be undesirable for a variety of reasons. In this work, we provide performance guarantees for a simple and natural class of static pricing policies which charge a fixed price up to a certain occupancy threshold and then allow no more customers into the system. We provide a series of results showing that such static policies can simultaneously guarantee a constant fraction of the optimal revenue with at most a constant factor increase in expected queue length. For instance, our policy for the M/M/1 setting allows bi-criteria approximations of $(0.5, 1), (0.66, 1.16), (0.75, 1.54)$ and $(0.8, 2)$ for the revenue and queue length, respectively. We also provide guarantees for settings with multiple customer classes and multiple servers, as well as the expected sojourn time objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09168v4</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Bergquist, Adam N. Elmachtoub</dc:creator>
    </item>
    <item>
      <title>Anytime-Constrained Equilibria in Polynomial Time</title>
      <link>https://arxiv.org/abs/2410.23637</link>
      <description>arXiv:2410.23637v2 Announce Type: replace-cross 
Abstract: We extend anytime constraints to the Markov game setting and the corresponding solution concept of an anytime-constrained equilibrium (ACE). Then, we present a comprehensive theory of anytime-constrained equilibria that includes (1) a computational characterization of feasible policies, (2) a fixed-parameter tractable algorithm for computing ACE, and (3) a polynomial-time algorithm for approximately computing ACE. Since computing a feasible policy is NP-hard even for two-player zero-sum games, our approximation guarantees are optimal so long as $P \neq NP$. We also develop the first theory of efficient computation for action-constrained Markov games, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23637v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan</dc:creator>
    </item>
  </channel>
</rss>
