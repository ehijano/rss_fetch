<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 05:00:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Turing Machine Simulation with Transformers</title>
      <link>https://arxiv.org/abs/2512.00003</link>
      <description>arXiv:2512.00003v1 Announce Type: new 
Abstract: Constant bit-size Transformers are known to be Turing complete, but existing constructions require $\Omega(s(n))$ chain-of-thought (CoT) steps per simulated Turing machine (TM) step, leading to impractical reasoning lengths. In this paper, we significantly reduce this efficiency gap by proving that any $(t(n),s(n))$-bounded multi-tape TM can be simulated by a constant bit-size Transformer with an optimal $O(s(n))$-long context window and only $O(s(n)^c)$ CoT steps per TM step, where $c&gt;0$ can be made arbitrarily small by letting the Transformers' head-layer product sufficiently large. In addition, our construction shows that sparse attention with fixed geometric offsets suffices for efficient universal computation. Our proof leverages multi-queue TMs as a bridge. The main technical novelty is a more efficient simulation of multi-tape TMs by synchronous multi-queue TMs, improving both time and space complexity under stricter model assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00003v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Li, Yuyi Wang</dc:creator>
    </item>
    <item>
      <title>On the Holographic Geometry of Deterministic Computation</title>
      <link>https://arxiv.org/abs/2512.00607</link>
      <description>arXiv:2512.00607v1 Announce Type: new 
Abstract: Standard simulations of Turing machines suggest a linear relationship between the temporal duration $t$ of a run and the amount of information that must be stored by known simulations to certify, verify, or regenerate the configuration at time $t$. For deterministic multitape Turing machines over a fixed finite alphabet, this apparent linear dependence is not intrinsic: any length-$t$ run can be simulated in space $O(\sqrt{t})$ via a Height Compression Theorem for succinct computation trees together with an Algebraic Replay Engine. In this paper we recast that construction in geometric and information-theoretic language. We interpret the execution trace as a spacetime dependency DAG and exhibit a family of recursively defined holographic boundary summaries such that, along the square-root-space simulation, the total description length of all boundary data stored at any time is $O(\sqrt{t})$. Using Kolmogorov complexity, we prove that every internal configuration has constant conditional description complexity given the appropriate boundary summary and time index, establishing that the spacetime bulk carries no additional algorithmic information beyond its boundary. We express this as a one-dimensional computational area law: there exists a simulation in which the information capacity of the active "holographic screen'' needed to generate a spacetime region of volume $t$ is bounded by $O(\sqrt{t})$. In this precise sense, deterministic computation on a one-dimensional work tape admits a holographic representation, with the bulk history algebraically determined by data residing on a lower-dimensional boundary screen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00607v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Nye</dc:creator>
    </item>
    <item>
      <title>Total Search Problems in $\mathsf{ZPP}$</title>
      <link>https://arxiv.org/abs/2512.01138</link>
      <description>arXiv:2512.01138v1 Announce Type: new 
Abstract: We initiate a systematic study of ${\sf TFZPP}$, the class of total ${\sf NP}$ search problems solvable by polynomial time randomized algorithms. ${\sf TFZPP}$ contains a variety of important search problems such as $\text{Bertrand-Chebyshev}$ (finding a prime between $N$ and $2N$), refuter problems for many circuit lower bounds, and $\text{Lossy-Code}$. The $\text{Lossy-Code}$ problem has found prominence due to its fundamental connections to derandomization, catalytic computing, and the metamathematics of complexity theory, among other areas.
  While ${\sf TFZPP}$ collapses to ${\sf FP}$ under standard derandomization assumptions in the white-box setting, we are able to separate ${\sf TFZPP}$ from the major ${\sf TFNP}$ subclasses in the black-box setting. In fact, we are able to separate it from every uniform ${\sf TFNP}$ class assuming that ${\sf NP}$ is not in quasi-polynomial time. To do so, we extend the connection between proof complexity and black-box ${\sf TFNP}$ to randomized proof systems and randomized reductions.
  Next, we turn to developing a taxonomy of ${\sf TFZPP}$ problems. We highlight a problem called $\text{Nephew}$, originating from an infinity axiom in set theory. We show that $\text{Nephew}$ is in $\mathsf{PWPP}\cap \mathsf{TFZPP}$ and conjecture that it is not reducible to $\text{Lossy-Code}$. Intriguingly, except for some artificial examples, most other black-box ${\sf TFZPP}$ problems that we are aware of reduce to $\text{Lossy-Code}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01138v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Noah Fleming, Stefan Grosser, Siddhartha Jain, Jiawei Li, Hanlin Ren, Morgan Shirley, Weiqiang Yuan</dc:creator>
    </item>
    <item>
      <title>Multiquadratic Sum-of-Squares Lower Bounds Imply VNC$^1$ $\neq$ VNP</title>
      <link>https://arxiv.org/abs/2512.01227</link>
      <description>arXiv:2512.01227v1 Announce Type: new 
Abstract: The \emph{sum-of-squares (SoS) complexity} of a $d$-multiquadratic polynomial $f$ (quadratic in each of $d$ blocks of $n$ variables) is the minimum $s$ such that $f = \sum_{i=1}^s g_i^2$ with each $g_i$ $d$-multilinear. In the case $d=2$, Hrube\v{s}, Wigderson and Yehudayoff (2011) showed that an $n^{1+\Omega(1)}$ lower bound on the SoS complexity of explicit biquadratic polynomials implies an exponential lower bound for non-commutative arithmetic circuits. In this paper, we establish an analogous connection between general \emph{multiquadratic sum-of-squares} and \emph{commutative arithmetic formulas}. Specifically, we show that an $n^{d-o(\log d)}$ lower bound on the SoS complexity of explicit $d$-multiquadratic polynomials, for any $d = d(n)$ with $\omega(1) \le d(n) \le O(\frac{\log n}{\log\log n})$, would separate the algebraic complexity classes VNC$^1$ and VNP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01227v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benjamin Rossman, Davidson Zhu</dc:creator>
    </item>
    <item>
      <title>Samplability makes learning easier</title>
      <link>https://arxiv.org/abs/2512.01276</link>
      <description>arXiv:2512.01276v1 Announce Type: new 
Abstract: The standard definition of PAC learning (Valiant 1984) requires learners to succeed under all distributions -- even ones that are intractable to sample from. This stands in contrast to samplable PAC learning (Blum, Furst, Kearns, and Lipton 1993), where learners only have to succeed under samplable distributions. We study this distinction and show that samplable PAC substantially expands the power of efficient learners.
  We first construct a concept class that requires exponential sample complexity in standard PAC but is learnable with polynomial sample complexity in samplable PAC. We then lift this statistical separation to the computational setting and obtain a separation relative to a random oracle. Our proofs center around a new complexity primitive, explicit evasive sets, that we introduce and study. These are sets for which membership is easy to determine but are extremely hard to sample from.
  Our results extend to the online setting to similarly show how its landscape changes when the adversary is assumed to be efficient instead of computationally unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01276v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Blanc, Caleb Koch, Jane Lange, Carmen Strassle, Li-Yang Tan</dc:creator>
    </item>
    <item>
      <title>Fast list recovery of univariate multiplicity and folded Reed-Solomon codes</title>
      <link>https://arxiv.org/abs/2512.00248</link>
      <description>arXiv:2512.00248v1 Announce Type: cross 
Abstract: A recent work of Goyal, Harsha, Kumar and Shankar gave nearly linear time algorithms for the list decoding of Folded Reed-Solomon codes (FRS) and univariate multiplicity codes up to list decoding capacity in their natural setting of parameters. A curious aspect of this work was that unlike most list decoding algorithms for codes that also naturally extend to the problem of list recovery, the algorithm in the work of Goyal et al. seemed to be crucially tied to the problem of list decoding. In particular, it wasn't clear if their algorithm could be generalized to solve the problem of list recovery FRS and univariate multiplicity codes in near linear time.
  In this work, we address this question and design $\tilde{O}(n)$-time algorithms for list recovery of Folded Reed-Solomon codes and univariate Multiplicity codes up to capacity, where $n$ is the blocklength of the code. For our proof, we build upon the lattice based ideas crucially used by Goyal et al. with one additional technical ingredient - we show the construction of appropriately structured lattices over the univariate polynomial ring that \emph{capture} the list recovery problem for these codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00248v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rohan Goyal, Prahladh Harsha, Mrinal Kumar, Ashutosh Shankar</dc:creator>
    </item>
    <item>
      <title>Counting and Sampling Traces in Regular Languages</title>
      <link>https://arxiv.org/abs/2512.00314</link>
      <description>arXiv:2512.00314v1 Announce Type: cross 
Abstract: In this work, we study the problems of counting and sampling Mazurkiewicz traces that a regular language touches. Fix an alphabet $\Sigma$ and an independence relation $\mathbb{I} \subseteq \Sigma \times \Sigma$. The input consists of a regular language $L \subseteq \Sigma^*$, given by a finite automaton with $m$ states, and a natural number $n$ (in unary). For the counting problem, the goal is to compute the number of Mazurkiewicz traces (induced by $\mathbb{I}$) that intersect the $n^\text{th}$ slice $L_n = L \cap \Sigma^n$, i.e., traces that admit at least one linearization in $L_n$. For the sampling problem, the goal is to output a trace drawn from a distribution that is approximately uniform over all such traces. These tasks are motivated by bounded model checking with partial-order reduction, where an \emph{a priori} estimate of the reduced state space is valuable, and by testing methods for concurrent programs that use partial-order-aware random exploration.
  We first show that the counting problem is #P-hard even when $L$ is accepted by a deterministic automaton, in sharp contrast to counting words of a DFA, which is polynomial-time solvable. We then prove that the problem lies in #P for both NFAs and DFAs, irrespective of whether $L$ is trace-closed. Our main algorithmic contributions are a \emph{fully polynomial-time randomized approximation scheme} (FPRAS) that, with high probability, approximates the desired count within a prescribed accuracy, and a \emph{fully polynomial-time almost uniform sampler} (FPAUS) that generates traces whose distribution is provably close to uniform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00314v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3776723</arxiv:DOI>
      <dc:creator>Alexis de Colnet, Kuldeep S. Meel, Umang Mathur</dc:creator>
    </item>
    <item>
      <title>A List of Complexity Bounds for Property Testing by Quantum Sample-to-Query Lifting</title>
      <link>https://arxiv.org/abs/2512.01971</link>
      <description>arXiv:2512.01971v1 Announce Type: cross 
Abstract: Quantum sample-to-query lifting, a relation between quantum sample complexity and quantum query complexity presented in Wang and Zhang (SIAM J. Comput. 2025), was significantly strengthened by Tang, Wright, and Zhandry (2025) to the case of state-preparation oracles. In this paper, we compile a list of quantum lower and upper bounds for property testing that are obtained by quantum sample-to-query lifting. The problems of interest include testing properties of probability distributions and quantum states, such as entropy and closeness. This collection contains new results, as well as new proofs of known bounds. In total, we present 49 complexity bounds, where 41 are new and 18 are (near-)optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01971v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kean Chen, Qisheng Wang, Zhicheng Zhang</dc:creator>
    </item>
    <item>
      <title>Graph-Based Deterministic Polynomial Algorithm for NP Problems</title>
      <link>https://arxiv.org/abs/2508.13166</link>
      <description>arXiv:2508.13166v3 Announce Type: replace 
Abstract: The P = NP problem asks whether every problem whose solution can be verified in polynomial time (NP) can also be solved in polynomial time (P). In this paper, we present a proof that P = NP, demonstrating that every NP problem can be solved deterministically in polynomial time. We introduce a new Computation Model that enables the simulation of a Turing machine, and show that NP problems can be simulated efficiently within this framework. By introducing the concept of a Feasible Graph, we ensure that the simulation can be performed in polynomial time, providing a direct path to resolving the P = NP question. Our result has significant implications for fields such as cryptography, optimization, and artificial intelligence, where NP-complete problems play a central role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13166v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changryeol Lee (Department of Software, Yonsei University, Mirae Campus)</dc:creator>
    </item>
    <item>
      <title>The communication complexity of distributed estimation</title>
      <link>https://arxiv.org/abs/2511.21015</link>
      <description>arXiv:2511.21015v2 Announce Type: replace 
Abstract: We study an extension of the standard two-party communication model in which Alice and Bob hold probability distributions $p$ and $q$ over domains $X$ and $Y$, respectively. Their goal is to estimate \[ \mathbb{E}_{x \sim p,\, y \sim q}[f(x, y)] \] to within additive error $\varepsilon$ for a bounded function $f$, known to both parties. We refer to this as the distributed estimation problem. Special cases of this problem arise in a variety of areas including sketching, databases and learning. Our goal is to understand how the required communication scales with the communication complexity of $f$ and the error parameter $\varepsilon$.
  The random sampling approach -- estimating the mean by averaging $f$ over $O(1/\varepsilon^2)$ random samples -- requires $O(R(f)/\varepsilon^2)$ total communication, where $R(f)$ is the randomized communication complexity of $f$. We design a new debiasing protocol which improves the dependence on $1/\varepsilon$ to be linear instead of quadratic. Additionally we show better upper bounds for several special classes of functions, including the Equality and Greater-than functions. We introduce lower bound techniques based on spectral methods and discrepancy, and show the optimality of many of our protocols: the debiasing protocol is tight for general functions, and that our protocols for the equality and greater-than functions are also optimal. Furthermore, we show that among full-rank Boolean functions, Equality is essentially the easiest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21015v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parikshit Gopalan, Raghu Meka, Prasad Raghavendra, Mihir Singhal, Avi Wigderson</dc:creator>
    </item>
    <item>
      <title>Trade-offs between Entanglement and Communication</title>
      <link>https://arxiv.org/abs/2306.01233</link>
      <description>arXiv:2306.01233v2 Announce Type: replace-cross 
Abstract: We study the advantages of quantum communication models over classical communication models that are equipped with a limited number of qubits of entanglement. In this direction, we give explicit partial functions on $n$ bits for which reducing the entanglement increases the classical communication complexity exponentially. Our separations are as follows. For every $k\ge 1$:
  $Q\|^*$ versus $R2^*$: We show that quantum simultaneous protocols with $\tilde{\Theta}(k^5 \log^3 n)$ qubits of entanglement can exponentially outperform two-way randomized protocols with $O(k)$ qubits of entanglement. This resolves an open problem from [Gav08] and improves the state-of-the-art separations between quantum simultaneous protocols with entanglement and two-way randomized protocols without entanglement [Gav19, GRT22].
  $R\|^*$ versus $Q\|^*$: We show that classical simultaneous protocols with $\tilde{\Theta}(k \log n)$ qubits of entanglement can exponentially outperform quantum simultaneous protocols with $O(k)$ qubits of entanglement, resolving an open question from [GKRW06, Gav19]. The best result prior to our work was a relational separation against protocols without entanglement [GKRW06].
  $R\|^*$ versus $R1^*$: We show that classical simultaneous protocols with $\tilde{\Theta}(k\log n)$ qubits of entanglement can exponentially outperform randomized one-way protocols with $O(k)$ qubits of entanglement. Prior to our work, only a relational separation was known [Gav08].
  Our techniques can also be used to show advantages of quantum communication models over hybrid classical-quantum models, i.e., models that have a large amount of both classical communication and quantum simultaneous communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01233v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Uma Girish</dc:creator>
    </item>
    <item>
      <title>A parallel framework for graphical optimal transport</title>
      <link>https://arxiv.org/abs/2406.10849</link>
      <description>arXiv:2406.10849v2 Announce Type: replace-cross 
Abstract: We study multi-marginal optimal transport (MOT) problems where the underlying cost has a graphical structure. These graphical multi-marginal optimal transport problems have found applications in several domains including traffic flow control, barycenter and regression problems in the Wasserstein space, and Hidden Markov model inference problems. The MOT problem can be approached through two formulations: a single big MOT problem, or coupled minor OT problems. In this paper, we focus on the latter approach and demonstrate its efficiency gain from parallelization. For tree-structured MOT problems, we introduce a novel parallelizable algorithm that significantly reduces computational complexity. Additionally, we adapt this algorithm for general graphs, employing the modified junction trees to enable parallel updates. Our contributions, validated through numerical experiments, offer new avenues for MOT applications and establish benchmarks in computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10849v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaojiao Fan, Isabel Haasler, Qinsheng Zhang, Johan Karlsson, Yongxin Chen</dc:creator>
    </item>
  </channel>
</rss>
