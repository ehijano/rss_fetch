<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 01:52:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Opening the Black-Box: Symbolic Regression with Kolmogorov-Arnold Networks for Energy Applications</title>
      <link>https://arxiv.org/abs/2504.03913</link>
      <description>arXiv:2504.03913v1 Announce Type: cross 
Abstract: While most modern machine learning methods offer speed and accuracy, few promise interpretability or explainability -- two key features necessary for highly sensitive industries, like medicine, finance, and engineering. Using eight datasets representative of one especially sensitive industry, nuclear power, this work compares a traditional feedforward neural network (FNN) to a Kolmogorov-Arnold Network (KAN). We consider not only model performance and accuracy, but also interpretability through model architecture and explainability through a post-hoc SHAP analysis. In terms of accuracy, we find KANs and FNNs comparable across all datasets, when output dimensionality is limited. KANs, which transform into symbolic equations after training, yield perfectly interpretable models while FNNs remain black-boxes. Finally, using the post-hoc explainability results from Kernel SHAP, we find that KANs learn real, physical relations from experimental data, while FNNs simply produce statistically accurate results. Overall, this analysis finds KANs a promising alternative to traditional machine learning methods, particularly in applications requiring both accuracy and comprehensibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03913v1</guid>
      <category>cs.LG</category>
      <category>cs.SC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nataly R. Panczyk, Omer F. Erdem, Majdi I. Radaideh</dc:creator>
    </item>
    <item>
      <title>Construction of birational trilinear volumes via tensor rank criteria</title>
      <link>https://arxiv.org/abs/2405.16936</link>
      <description>arXiv:2405.16936v2 Announce Type: replace-cross 
Abstract: We provide effective methods to construct and manipulate trilinear birational maps $\phi:(\mathbb{P}^1)^3\dashrightarrow \mathbb{P}^3$ by establishing a novel connection between birationality and tensor rank. These yield four families of nonlinear birational transformations between 3D spaces that can be operated with enough flexibility for applications in computer-aided geometric design. More precisely, we describe the geometric constraints on the defining control points of the map that are necessary for birationality, and present constructions for such configurations. For adequately constrained control points, we prove that birationality is achieved if and only if a certain $2\times 2\times 2$ tensor has rank one. As a corollary, we prove that the locus of weights that ensure birationality is $\mathbb{P}^1\times\mathbb{P}^1\times\mathbb{P}^1$. Additionally, we provide formulas for the inverse $\phi^{-1}$ as well as the explicit defining equations of the irreducible components of the base loci. Finally, we introduce a notion of "distance to birationality" for trilinear rational maps, and explain how to continuously deform birational maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16936v2</guid>
      <category>math.AG</category>
      <category>cs.SC</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Bus\'e, Pablo Maz\'on</dc:creator>
    </item>
  </channel>
</rss>
