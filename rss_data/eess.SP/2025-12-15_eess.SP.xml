<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Dec 2025 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>RMSup: Physics-Informed Radio Map Super-Resolution for Compute-Enhanced Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2512.10965</link>
      <description>arXiv:2512.10965v1 Announce Type: new 
Abstract: Radio maps (RMs) provide a spatially continuous description of wireless propagation, enabling cross-layer optimization and unifying communication and sensing for integrated sensing and communications (ISAC). However, constructing high-fidelity RMs at operational scales is difficult, since physics-based solvers are time-consuming and require precise scene models, while learning methods degrade under incomplete priors and sparse measurements, often smoothing away critical discontinuities. We present RMSup, a physics-informed super-resolution framework that functions with uniform sparse sampling and imperfect environment priors. RMSup extracts Helmholtz equation-informed boundary and singularity prompts from the measurements, fuses them with base-station side information and coarse scene descriptors as conditional inputs, and employs a boundary-aware dual-head network to reconstruct a high-fidelity RM and recover environmental contours jointly. Experimental results show the proposed RMsup achieves state-of-the-art performance both in RM construction and ISAC-related environment sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10965v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiming Zhang, Xiucheng Wang, Nan Cheng, Zhisheng Yin, Xiang Li</dc:creator>
    </item>
    <item>
      <title>Uplink Rate Maximization for Pinching Antenna- Assisted Covert Backscatter Communication</title>
      <link>https://arxiv.org/abs/2512.10970</link>
      <description>arXiv:2512.10970v1 Announce Type: new 
Abstract: The emerging pinching antenna (PA) technology enables flexible antenna positioning for creating line-of-sight (LoS) links, thus offering substantial potential to facilitate ambient signal-based backscatter communication (BSC). This paper investigates PA-assisted BSC for enhanced communication and covertness in the presence of a randomly distributed eavesdropper. An optimization problem is formulated to maximize the uplink covert transmission rate by jointly optimizing the transmit power and antenna positions while satisfying both communication reliability and covertness constraints. An alternative optimization (AO)-based framework is proposed to solve this problem. Numerical results demonstrate that the proposed PA-BSC effectively mitigates the double near-far problem, where energy harvesting and backscatter transmission degrade simultaneously due to distance disparities, thereby improving downlink energy harvesting and uplink data transmission while maintaining covertness performance under practical deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10970v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulei Wang, Yalin Liu, Yaru Fu, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>A Unified Theory of Dynamic Programming Algorithms in Small Target Detection</title>
      <link>https://arxiv.org/abs/2512.11170</link>
      <description>arXiv:2512.11170v1 Announce Type: new 
Abstract: Small target detection is inherently challenging due to the minimal size, lack of distinctive features, and the presence of complex backgrounds. Heavy noise further complicates the task by both obscuring and imitating the target appearance. Weak target signals require integrating target trajectories over multiple frames, an approach that can be computationally intensive. Dynamic programming offers an efficient solution by decomposing the problem into iterative maximization. This, however, has limited the analytical tools available for their study. In this paper, we present a robust framework for this class of algorithms and establish rigorous convergence results for error rates under mild assumptions. We depart from standard analysis by modeling error probabilities as a function of distance from the target, allowing us to construct a relationship between uncertainty in location and uncertainty in existence. From this framework, we introduce a novel algorithm, Normalized Path Integration (NPI), that utilizes the similarity between sequential observations, enabling target detection with unknown or time varying features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11170v1</guid>
      <category>eess.SP</category>
      <category>eess.IV</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas Bampton, Tian J. Ma, Minh N. Do</dc:creator>
    </item>
    <item>
      <title>Robust Detection of Underwater Target Against Non-Uniform Noise With Optical Fiber DAS Array</title>
      <link>https://arxiv.org/abs/2512.11231</link>
      <description>arXiv:2512.11231v1 Announce Type: new 
Abstract: The detection of underwater targets is severely affected by the non-uniform spatial characteristics of marine environmental noise. Additionally, the presence of both natural and anthropogenic acoustic sources, including shipping traffic, marine life, and geological activity, further complicates the underwater acoustic landscape. Addressing these challenges requires advanced underwater sensors and robust signal processing techniques. In this paper, we present a novel approach that leverages an optical fiber distributed acoustic sensing (DAS) system combined with a broadband generalized sparse covariance-fitting framework for underwater target direction sensing, particularly focusing on robustness against non-uniform noise. The DAS system incorporates a newly developed spiral-sensitized optical cable, which significantly improves sensitivity compared to conventional submarine cables. This innovative design enables the system to capture acoustic signals with greater precision. Notably, the sensitivity of the spiral-wound sensitized cable is around -145.69 dB re: 1 rad / (uPa*m), as measured inside the standing-wave tube. Employing simulations, we assess the performance of the algorithm across diverse noise levels and target configurations, consistently revealing higher accuracy and reduced background noise compared to conventional beamforming techniques and other sparse techniques. In a controlled pool experiment, the correlation coefficient between waveforms acquired by the DAS system and a standard hydrophone reached 0.973, indicating high fidelity in signal capture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11231v1</guid>
      <category>eess.SP</category>
      <category>eess.AS</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/tim.2025.3643081</arxiv:DOI>
      <dc:creator>Siyuan Cang, Cong Liu, Xueli Sheng, Xiaoming Cui, Chao Li, Changxin Fa, Jiantong Chen, Chaoran Yang, Huayong Yang</dc:creator>
    </item>
    <item>
      <title>Source Localization and Power Estimation through RISs: Performance Analysis and Prototype Validations</title>
      <link>https://arxiv.org/abs/2512.11420</link>
      <description>arXiv:2512.11420v1 Announce Type: new 
Abstract: This paper investigates the capabilities and effectiveness of backward localization centered on reconfigurable intelligent surfaces (RISs). In the backward sensing paradigm, the region of interest (RoI) is illuminated using a set of diverse radiation patterns. These patterns encode spatial information into a sequence of measurements, which are subsequently processed to reconstruct the RoI. We show that a single RIS can estimate the direction of arrival of incident waves by leveraging configurational diversity, and that the spatial diversity provided by multiple RISs further improves the accuracy of source localization and power estimation. The underlying structure of the sensing operator in the multi-snapshot measurement process is clarified. For single-RIS localization, the sensing operator is decomposed into a product of structured matrices, each corresponding to a specific physical process: wave propagation to and from the RIS, the relative phase offsets of elements with respect to the reference point, and the applied phase configuration of each element. A unified framework for identifying key performance indicators is established by analyzing the conditioning of the sensing operators. In the multi-RIS setting, we derive--via rank analysis--the governing law among the RoI size, the number of elements, and the number of measurements. Upper bounds on the relative error of the least squares reconstruction algorithm are derived. These bounds clarify how key performance indicators affect estimation error and provide valuable guidance for system-level optimization. Numerical experiments confirm that the trend of the relative error is consistent with the theoretical bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11420v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuhai Wang, Tiebin Mi, Chun Wang, Rujing Xiong, Zhengyu Wang, Robert Caiming Qiu</dc:creator>
    </item>
    <item>
      <title>Point Target Near-Field Bistatic Imaging: Chirp-Based Aliasing Analysis</title>
      <link>https://arxiv.org/abs/2512.11444</link>
      <description>arXiv:2512.11444v1 Announce Type: new 
Abstract: This paper presents a chirp-based framework for characterising aliasing in a bistatic Near-Field (NF) imaging system equipped with multidimensional antenna arrays. Extending monostatic formulations, we derive closed-form expressions for the maximum spatial frequency, enabling the analytical derivations of the conditions for aliasing-free image reconstruction. The framework also provides a geometric interpretation of aliasing based on the antenna array geometry, target position, and antenna element spacing. Numerical results corroborate theoretical findings and show that the aliasing-free region enlarges with smaller antenna spacing, greater target range, lower array dimensionality, and smaller arrays. These results enable more effective design of bistatic NF imaging systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11444v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Sambon, Gilles Monnoyer, Claude Oestges, Luc Vandendorpe</dc:creator>
    </item>
    <item>
      <title>STAR-RIS-Aided Secure Communications:Analytical Insights and Performance Comparison</title>
      <link>https://arxiv.org/abs/2512.11461</link>
      <description>arXiv:2512.11461v1 Announce Type: new 
Abstract: Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) have emerged as a promising technology for enabling full-space signal manipulation and enhancing wireless network coverage and capacity. In this article, we present a comprehensive analytical comparison of STAR-RIS-assisted systems with single-input single-output (SISO), conventional RISs, and decode-and-forward (DF) relaying schemes, including both half-duplex (HD) and full-duplex (FD) modes. Closed-form expressions are derived for the achievable secrecy rates of STAR-RIS-aided communications under both the absence and presence of eavesdroppers. Unlike most existing works, the direct source destination link is incorporated in all considered schemes, and optimal transmit power allocation is investigated for HD and FD-DF relaying. Furthermore, we provide the conditions under which STAR-RIS outperforms HD- and FD-DF relaying and quantify the minimum number of STAR-RIS elements required to achieve superior rates. The impacts of key system parameters including transmit power, number of elements, reflection-to-transmission power ratio, element-splitting factor, and deployment positions on both achievable and secrecy performance are investigated. The results reveal that STAR-RIS systems can achieve superior rates and secrecy rates compared to all benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11461v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taissir Y. Elganimi, Mahmoud Aldababsa, Ali A. Nasir, Khaled M. Rabie</dc:creator>
    </item>
    <item>
      <title>RadarFuseNet: Complex-Valued Attention-Based Fusion of IQ Time- and Frequency-Domain Radar Features for Classification Tasks</title>
      <link>https://arxiv.org/abs/2512.11537</link>
      <description>arXiv:2512.11537v1 Announce Type: new 
Abstract: Millimeter-wave (mmWave) radar has emerged as a compact and powerful sensing modality for advanced perception tasks that leverage machine learning techniques. It is particularly effective in scenarios where vision-based sensors fail to capture reliable information, such as detecting occluded objects or distinguishing between different surface materials in indoor environments. Due to the non-linear characteristics of mmWave radar signals, deep learning-based methods are well suited for extracting relevant information from in-phase and quadrature (IQ) data. However, the current state of the art in IQ signal-based occluded-object and material classification still offers substantial potential for further improvement. In this paper, we propose a bidirectional cross-attention fusion network that combines IQ-signal and FFT-transformed radar features obtained by distinct complex-valued convolutional neural networks (CNNs). The proposed method achieves improved performance and robustness compared to standalone complex-valued CNNs. We achieve a near-perfect material classification accuracy of 99.92% on samples collected at same sensor-to-surface distances used during training, and an improved accuracy of 67.38% on samples measured at previously unseen distances, demonstrating improved generalization ability across varying measurement conditions. Furthermore, the accuracy for occluded object classification improves from 91.99% using standalone complex-valued CNNs to 94.20% using our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11537v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan H\"agele, Adam Misik, Eckehard Steinbach</dc:creator>
    </item>
    <item>
      <title>ACCOR: Attention-Enhanced Complex-Valued Contrastive Learning for Occluded Object Classification Using mmWave Radar IQ Signals</title>
      <link>https://arxiv.org/abs/2512.11556</link>
      <description>arXiv:2512.11556v1 Announce Type: new 
Abstract: Millimeter-wave (mmWave) radar has emerged as a robust sensing modality for several areas, offering reliable operation under adverse environmental conditions. Its ability to penetrate lightweight materials such as packaging or thin walls enables non-visual sensing in industrial and automated environments and can provide robotic platforms with enhanced environmental perception when used alongside optical sensors. Recent work with MIMO mmWave radar has demonstrated its ability to penetrate cardboard packaging for occluded object classification. However, existing models leave room for improvement and warrant a more thorough evaluation across different sensing frequencies. In this paper, we propose ACCOR, an attention-enhanced complex-valued contrastive learning approach for radar, enabling robust occluded object classification. We process complex-valued IQ radar signals using a complex-valued CNN backbone, followed by a multi-head attention layer and a hybrid loss. Our proposed loss combines a weighted cross-entropy term with a supervised contrastive term. We further extend an existing 64 GHz dataset with a 67 GHz subset of the occluded objects and evaluate our model using both center frequencies. Performance evaluation demonstrates that our approach outperforms prior radar-specific models and image classification models with adapted input, achieving classification accuracies of 96.60% at 64 GHz and 93.59% at 67 GHz for ten different objects. These results demonstrate the benefits of complex-valued deep learning with attention and contrastive learning for mmWave radar-based occluded object classification in industrial and automated environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11556v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan H\"agele, Adam Misik, Constantin Patsch, Eckehard Steinbach</dc:creator>
    </item>
    <item>
      <title>PaddleSat Optical Charging Station in Space</title>
      <link>https://arxiv.org/abs/2512.11629</link>
      <description>arXiv:2512.11629v1 Announce Type: new 
Abstract: This work investigates the feasibility and design trade-offs for a companion spacecraft, or PaddleSat, to charge a host spacecraft by wirelessly transmitting power using a directional laser system. The primary goal of the PaddleSat is to supplement power on a host spacecraft to reduce the requirements for onboard power systems of the host spacecraft or extend mission lifetimes. System performance estimates, link budget calculations, optical transmission hardware and link analysis, design tradeoffs between beam divergence, optical efficiency, and relative orbital control requirements are examined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11629v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anish Nair, Austin O' Connell, Shalomi Arulpragasam, Noah Kim</dc:creator>
    </item>
    <item>
      <title>Processing through encoding: Quantum circuit approaches for point-wise multiplication and convolution</title>
      <link>https://arxiv.org/abs/2512.11457</link>
      <description>arXiv:2512.11457v1 Announce Type: cross 
Abstract: This paper introduces quantum circuit methodologies for pointwise multiplication and convolution of complex functions, conceptualized as "processing through encoding". Leveraging known techniques, we describe an approach where multiple complex functions are encoded onto auxiliary qubits. Applying the proposed scheme for two functions $f$ and $g$, their pointwise product $f(x)g(x)$ is shown to naturally form as the coefficients of part of the resulting quantum state. Adhering to the convolution theorem, we then demonstrate how the convolution $f*g$ can be constructed. Similarly to related work, this involves the encoding of the Fourier coefficients $\mathcal{F}[f]$ and $\mathcal{F}[g]$, which facilitates their pointwise multiplication, followed by the inverse Quantum Fourier Transform. We discuss the simulation of these techniques, their integration into an extended \verb|quantumaudio| package for audio signal processing, and present initial experimental validations. This work offers a promising avenue for quantum signal processing, with potential applications in areas such as quantum-enhanced audio manipulation and synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11457v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Papageorgiou, Paulo Vitor Itaborai, Kostas Blekos, Karl Jansen</dc:creator>
    </item>
    <item>
      <title>Adaptive MIMO Radar Architecture for Energy-Efficient Wireless Sensing in the D-Band</title>
      <link>https://arxiv.org/abs/2309.17110</link>
      <description>arXiv:2309.17110v4 Announce Type: replace 
Abstract: The D-band offering an untapped wide bandwidth is promising for high data rate communication and high-resolution wireless sensing. However, these potentials are hindered by the low performance and energy efficiency of the D-band circuits and systems. We present an adaptive multi-input multi-output (MIMO) radar architecture for energy-efficient wireless sensing in the D-band, leveraging a reconfigurable 2D array of radar transceiver front-ends, a scaling approach for the receiver (RX) signal-to-noise ratio (SNR) and the transmitter (TX) output power ($P_{\rm TX}$) with target distance, and dynamic selection of the direction-of-arrival (DOA) estimation algorithm. The reconfigurable radar array, providing an adaptive radar resolution, enhances the energy efficiency by reducing power consumption in the radar RF front-end and lowering the computational complexity in the radar back-end. The RX SNR and the TX output power are scaled with the distance as ${\rm SNR} \propto d^{-p}$ and $P_{\rm TX} \propto d^{4-p}$, where $0 &lt; p &lt; 4$, leading to more efficient resource allocation in varying target distance conditions. Additionally, DOA estimation results using MUSIC and MVDR algorithms indicate that the optimum algorithm, in terms of the accuracy and computational complexity, should be selected based on the number of radar array elements. Furthermore, we develop a hardware model for the MIMO radar RF front-end to evaluate the power consumption of the TX, RX, and local oscillator (LO) distribution network. It is shown that the power consumption of the LO distribution network, which can dominate the power consumption for a large MIMO radar, can be minimized through a distribution strategy for LO amplifiers employed for compensating passive losses. Performance of the adaptive MIMO radar is evaluated in the free-space and the through-wall indoor sensing scenarios in the D-band.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.17110v4</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subbarao Korlapati, Reza Nikandish</dc:creator>
    </item>
    <item>
      <title>VERITAS: Verifying the Performance of AI-native Transceiver Actions in Base-Stations</title>
      <link>https://arxiv.org/abs/2501.09761</link>
      <description>arXiv:2501.09761v3 Announce Type: replace 
Abstract: Artificial Intelligence (AI)-native receivers prove significant performance improvement in high noise regimes and can potentially reduce communication overhead compared to the traditional receiver. However, their performance highly depends on the representativeness of the training dataset. A major issue is the uncertainty of whether the training dataset covers all test environments and waveform configurations, and thus, whether the trained model is robust in practical deployment conditions. To this end, we propose a joint measurement-recovery framework for AI-native transceivers post deployment, called VERITAS, that continuously looks for distribution shifts in the received signals and triggers finite re-training spurts. VERITAS monitors the wireless channel using 5G pilots fed to an auxiliary neural network that detects out-of-distribution channel profile, transmitter speed, and delay spread. As soon as such a change is detected, a traditional (reference) receiver is activated, which runs for a period of time in parallel to the AI-native receiver. Finally, VERTIAS compares the bit probabilities of the AI-native and the reference receivers for the same received data inputs, and decides whether or not a retraining process needs to be initiated. Our evaluations reveal that VERITAS can detect changes in the channel profile, transmitter speed, and delay spread with 99%, 97%, and 69% accuracies, respectively, followed by timely initiation of retraining for 86%, 93.3%, and 94.8% of inputs in channel profile, transmitter speed, and delay spread test sets, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09761v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nasim Soltani, Michael Loehning, Kaushik Chowdhury</dc:creator>
    </item>
    <item>
      <title>Stacked Intelligent Metasurfaces-Enhanced MIMO OFDM Wideband Communication Systems</title>
      <link>https://arxiv.org/abs/2503.00368</link>
      <description>arXiv:2503.00368v3 Announce Type: replace 
Abstract: Multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) systems rely on digital or hybrid digital and analog designs for beamforming against frequency-selective fading, which suffer from high hardware complexity and energy consumption. To address this, this work introduces a fully-analog stacked intelligent metasurfaces (SIM) architecture that directly performs wave-domain beamforming, enabling diagonalization of the end-to-end channel matrix and inherently eliminating inter-antenna interference (IAI) for MIMO OFDM transmission. By leveraging cascaded programmable metasurface layers, the proposed system establishes multiple parallel subchannels, significantly improving multi-carrier transmission efficiency while reducing hardware complexity. To optimize the SIM phase shift matrices, a block coordinate descent and penalty convex-concave procedure (BCD-PCCP) algorithm is developed to iteratively minimize the channel fitting error across subcarriers. Simulation results validate the proposed approach, determining the maximum effective bandwidth and demonstrating substantial performance improvements. Moreover, for a MIMO OFDM system operating at 28 GHz with 16 subcarriers, the proposed SIM configuration method achieves over 300% enhancement in channel capacity compared to conventional SIM configuration that only accounts for the center frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00368v3</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2025.3636393</arxiv:DOI>
      <dc:creator>Zheao Li, Jiancheng An, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Joint CSI Estimation-Feedback-Precoding via DJSCC for MU-MIMO OFDM Systems</title>
      <link>https://arxiv.org/abs/2503.04157</link>
      <description>arXiv:2503.04157v2 Announce Type: replace 
Abstract: As the number of antennas in frequency-division duplex (FDD) multiple-input multiple-output (MIMO) systems increases, acquiring channel state information (CSI) becomes increasingly challenging due to limited spectral resources and feedback overhead. In this paper, we investigate the impact of the feedback channel on CSI feedback in a multi-user MIMO orthogonal frequency-division multiplexing (OFDM) scenario, where the received downlink pilot signal is directly utilized as the source for CSI feedback in a joint design with CSI feedback and precoding. Considering the influence of the feedback channel, we propose an end-to-end joint CSI estimation-feedback-precoding network based on a deep joint source-channel coding architecture with an adaptive number of users. Experimental results demonstrate that, under the same feedback and CSI estimation overheads, the proposed joint multi-module end-to-end network achieves a higher multi-user downlink spectral efficiency than traditional algorithms based on separate architecture and partially separated artificial intelligence-based network architectures under comparable channel quality. Furthermore, compared to conventional separate architecture, the proposed network architecture with joint architecture reduces the computational burden and model storage overhead at the UE side, facilitating the deployment of low-overhead multi-module joint architectures in practice. Meanwhile, the network designed at the BS achieves user-number adaptability without increasing the number of trainable parameters, thereby reducing both model storage and distribution overhead by requiring only a single set of parameters for different numbers of users. While slightly increasing storage requirements at the base station, it reduces computational complexity and precoding design delay, effectively reducing the effects of channel aging challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04157v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiran Guo, Wei Chen, Bo Ai, Lun Li</dc:creator>
    </item>
    <item>
      <title>Integrated Sensing and Communications Over the Years: An Evolution Perspective</title>
      <link>https://arxiv.org/abs/2504.06830</link>
      <description>arXiv:2504.06830v3 Announce Type: replace 
Abstract: Integrated Sensing and Communications (ISAC) enables efficient spectrum utilization and reduces hardware costs for beyond 5G (B5G) and 6G networks, facilitating intelligent applications that require both high-performance communication and precise sensing capabilities. This survey provides a comprehensive review of the evolution of ISAC over the years. We examine the expansion of the spectrum across RF and optical ISAC, highlighting the role of advanced technologies, along with key challenges and synergies. We further discuss the advancements in network architecture from single-cell to multi-cell systems, emphasizing the integration of collaborative sensing and interference mitigation strategies. Moreover, we analyze the progress from single-modal to multi-modal sensing, with a focus on the integration of edge intelligence to enable real-time data processing, reduce latency, and enhance decision-making. Finally, we extensively review standardization efforts by 3GPP, IEEE, and ITU, examining the transition of ISAC-related technologies and their implications for the deployment of 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06830v3</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Di Zhang, Yuanhao Cui, Xiaowen Cao, Nanchi Su, Yi Gong, Fan Liu, Weijie Yuan, Xiaojun Jing, J. Andrew Zhang, Jie Xu, Christos Masouros, Dusit Niyato, Marco Di Renzo</dc:creator>
    </item>
    <item>
      <title>Multi-dimensional Parameter Estimation in RIS-aided MU-MIMO-OFDM Channels</title>
      <link>https://arxiv.org/abs/2505.02611</link>
      <description>arXiv:2505.02611v3 Announce Type: replace 
Abstract: We address the channel estimation (CE) problem in reconfigurable intelligent surface (RIS) aided orthogonal frequency-division multiplexing (OFDM) systems by proposing a dual-structure and multi-dimensional transformations (DS-MDT) algorithm.The proposed approach leverages the dual-structure features of the channel parameters to assist users experiencing weaker channel conditions, thereby enhancing CE performance. Moreover, given that the channel parameters are distributed across multiple dimensions of the received tensor, the proposed algorithm employs multi-dimensional transformations to isolate and extract distinct parameters. The numerical results demonstrate the proposed algorithm reduces the normalized mean square error (NMSE) by up to 10 dB while maintaining lower complexity compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02611v3</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linlin Mo, Yi Song, Fabio Saggese, Xinhua Lu, Zhongyong Wang, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>VoxelRF: Voxelized Radiance Field for Fast Wireless Channel Modeling</title>
      <link>https://arxiv.org/abs/2507.09987</link>
      <description>arXiv:2507.09987v2 Announce Type: replace 
Abstract: Wireless channel modeling in complex environments is crucial for wireless communication system design and deployment. Traditional channel modeling approaches face challenges in balancing accuracy, efficiency, and scalability, while recent neural approaches such as neural radiance field (NeRF) suffer from long training and slow inference. To tackle these challenges, we propose voxelized radiance field (VoxelRF), a novel neural representation for wireless channel modeling that enables fast and accurate synthesis of spatial spectra. VoxelRF replaces the costly multilayer perception (MLP) used in NeRF-based methods with trilinear interpolation of voxel grid-based representation, and two shallow MLPs to model both propagation and transmitter-dependent effects. To further accelerate training and improve generalization, we introduce progressive learning, empty space skipping, and an additional background entropy loss function. Experimental results demonstrate that VoxelRF achieves competitive accuracy with significantly reduced computation and limited training data, making it more practical for real-time and resource-constrained wireless applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09987v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihang Zeng, Shu Sun, Meixia Tao, Yin Xu, Xianghao Yu</dc:creator>
    </item>
    <item>
      <title>E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion</title>
      <link>https://arxiv.org/abs/2509.19312</link>
      <description>arXiv:2509.19312v2 Announce Type: replace 
Abstract: This paper investigates multimodal semantic non-orthogonal transmission and fusion in hybrid analog-digital massive multiple-input multiple-output (MIMO). A Transformer-based cross-modal source-channel semantic-aware network (CSC-SA-Net) framework is conceived, where channel state information (CSI) reference signal (RS), feedback, analog-beamforming/combining, and baseband semantic processing are data-driven end-to-end (E2E) optimized at the base station (BS) and user equipments (UEs). CSC-SA-Net comprises five sub-networks: BS-side CSI-RS network (BS-CSIRS-Net), UE-side channel semantic-aware network (UE-CSANet), BS-CSANet, UE-side multimodal semantic fusion network (UE-MSFNet), and BS-MSFNet. Specifically, we firstly E2E train BS-CSIRS-Net, UE-CSANet, and BS-CSANet to jointly design CSI-RS, feedback, analog-beamforming/combining with maximum {\emph{physical-layer's}} spectral-efficiency. Meanwhile, we E2E train UE-MSFNet and BS-MSFNet for optimizing {\emph{application-layer's}} source semantic downstream tasks. On these pre-trained models, we further integrate application-layer semantic processing with physical-layer tasks to E2E train five subnetworks. Extensive simulations show that the proposed CSC-SA-Net outperforms traditional separated designs, revealing the advantage of cross-modal channel-source semantic fusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19312v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minghui Wu, Zhen Gao</dc:creator>
    </item>
    <item>
      <title>Efficient Domain Generalization in Wireless Networks with Scarce Multi-Modal Data</title>
      <link>https://arxiv.org/abs/2510.04359</link>
      <description>arXiv:2510.04359v2 Announce Type: replace 
Abstract: In 6G wireless networks, multi-modal ML models can be leveraged to enable situation-aware network decisions in dynamic environments. However, trained ML models often fail to generalize under domain shifts when training and test data distributions are different because they often focus on modality-specific spurious features. In practical wireless systems, domain shifts occur frequently due to dynamic channel statistics, moving obstacles, or hardware configuration. Thus, there is a need for learning frameworks that can achieve robust generalization under scarce multi-modal data in wireless networks. In this paper, a novel and data-efficient two-phase learning framework is proposed to improve generalization performance in unseen and unfamiliar wireless environments with minimal amount of multi-modal data. In the first stage, a physics-based loss function is employed to enable each BS to learn the physics underlying its wireless environment captured by multi-modal data. The data-efficiency of the physics-based loss function is analytically investigated. In the second stage, collaborative domain adaptation is proposed to leverage the wireless environment knowledge of multiple BSs to guide under-performing BSs under domain shift. Specifically, domain-similarity-aware model aggregation is proposed to utilize the knowledge of BSs that experienced similar domains. To validate the proposed framework, a new dataset generation framework is developed by integrating CARLA and MATLAB-based mmWave channel modeling to predict mmWave RSS. Simulation results show that the proposed physics-based training requires only 13% of data samples to achieve the same performance as a state-of-the-art baseline that does not use physics-based training. Moreover, the proposed collaborative domain adaptation needs only 25% of data samples and 20% of FLOPs to achieve the convergence compared to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04359v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minsu Kim, Walid Saad, Doru Calin</dc:creator>
    </item>
    <item>
      <title>Multiport Analytical Pixel Electromagnetic Simulator (MAPES) for AI-assisted RFIC and Microwave Circuit Design</title>
      <link>https://arxiv.org/abs/2511.21274</link>
      <description>arXiv:2511.21274v2 Announce Type: replace 
Abstract: This paper proposes a novel analytical framework, termed the Multiport Analytical Pixel Electromagnetic Simulator (MAPES). MAPES enables efficient and accurate prediction of the electromagnetic (EM) performance of arbitrary pixel-based microwave (MW) and RFIC structures. Inspired by the Integrated Internal Multiport Method (IMPM), MAPES extends the concept to the pixel presence/absence domain used in AI-assisted EM design. By introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical positions, MAPES captures all horizontal, vertical, and diagonal electromagnetic couplings within a single multiport impedance matrix. Only a small set of full-wave simulations (typically about 1% of the datasets required by AI-assisted EM simulators) is needed to construct this matrix. Subsequently, any arbitrary pixel configuration can be evaluated analytically using a closed-form multiport relation without additional full-wave calculations. The proposed approach eliminates data-driven overfitting and ensures accurate results across all design variations. Comprehensive examples for single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs confirm that MAPES achieves high prediction accuracy with 600- 2000x speed improvement compared to CST simulations. Owing to its efficiency, scalability and reliability, MAPES provides a practical and versatile tool for AI-assisted MW circuit and RFIC design across diverse fabrication technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21274v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junhui Rao, Yi Liu, Jichen Zhang, Zhaoyang Ming, Tianrui Qiao, Yujie Zhang, Chi Yuk Chiu, Hua Wang, Ross Murch</dc:creator>
    </item>
    <item>
      <title>Near-Field Channel Estimation and Joint Angle-Range Recovery in XL-MIMO Systems: A Gridless Super-Resolution Approach</title>
      <link>https://arxiv.org/abs/2511.23187</link>
      <description>arXiv:2511.23187v2 Announce Type: replace 
Abstract: Existing near-field channel estimation methods for extremely large-scale MIMO (XL-MIMO) typically discretize angle and range parameters jointly, resulting in large polar-domain codebooks. This paper proposes a novel framework that formulates near-field channel estimation as a gridless super-resolution problem, eliminating the need for explicitly constructed codebooks. By employing a second-order approximation of spherical-wave steering vectors, the near-field channel is represented as a superposition of complex exponentials modulated by unknown waveforms. We demonstrate that these waveforms lie tightly in a common discrete chirp rate (DCR) subspace, with a dimension that scales as $\Theta(\sqrt{N})$ for an $N$-element array. By leveraging this structure and applying a lifting technique, we reformulate the non-convex problem as a convex program using regularized atomic norm minimization, which admits an equivalent semidefinite program. From the solution to the convex program, we obtain gridless angle estimates and derive closed-form coarse range estimates, followed by refinement under the exact spherical model using gradient-based nonlinear least squares. The proposed method avoids basis mismatch and exhaustive two-dimensional grid searches while enabling accurate joint angle-range estimation with pilot budgets that scale sublinearly with array size in sparse multipath regimes. Simulations demonstrate accurate channel reconstruction and user localization across representative near-field scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23187v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Xi, Dehui Yang</dc:creator>
    </item>
    <item>
      <title>Channel Knowledge Map Enabled Low-Altitude ISAC Networks: Joint Air Corridor Planning and Base Station Deployment</title>
      <link>https://arxiv.org/abs/2512.02464</link>
      <description>arXiv:2512.02464v2 Announce Type: replace 
Abstract: This letter addresses the joint air corridor planning and base station (BS) deployment problem for low-altitude integrated sensing and communication (ISAC) networks. In the considered system, unmanned aerial vehicles (UAVs) operate within a structured air corridor composed of connected cubic segments, and multiple BSs need to be selectively deployed at a set of candidate locations to ensure both sensing and communication coverage throughout the corridor. In particular, we leverage the channel knowledge map (CKM) to characterize wireless channels for candidate BS sites prior to deployment, thereby facilitating the offline planning. Under this setup, we minimize the system cost in terms of the weighted sum of the air corridor length and the number of deployed BSs, subject to the constraints on both sensing and communication performance across the corridor. To solve the formulated large-scale nonconvex integer programming problem, we develop a hierarchical coarse-to-fine grid decomposition algorithm. Simulation results demonstrate the benefit of the proposed joint design in reducing the overall deployment cost while ensuring the coverage of the low-altitude ISAC networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02464v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxuan Li, Yilong Chen, Fan Liu, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations</title>
      <link>https://arxiv.org/abs/2512.02757</link>
      <description>arXiv:2512.02757v2 Announce Type: replace 
Abstract: The ability to construct channel knowledge map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, considering that acquiring channel observations incurs non-negligible time and cost, we focus on constructing CKM for large-scale fading scenarios without relying on prior observations, and we design three physics-based constraints to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02757v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunzhe Zhu, Xuewen Liao, Zhenzhen Gao, Linzhou Zeng, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>Bayesian Multifractal Image Segmentation</title>
      <link>https://arxiv.org/abs/2501.08694</link>
      <description>arXiv:2501.08694v2 Announce Type: replace-cross 
Abstract: Multifractal analysis (MFA) provides a framework for the global characterization of image textures by describing the spatial fluctuations of their local regularity based on the multifractal spectrum. Several works have shown the interest of using MFA for the description of homogeneous textures in images. Nevertheless, natural images can be composed of several textures and, in turn, multifractal properties associated with those textures. This paper introduces an unsupervised Bayesian multifractal segmentation method to model and segment multifractal textures by jointly estimating the multifractal parameters and labels on images, at the pixel-level. For this, a computationally and statistically efficient multifractal parameter estimation model for wavelet leaders is firstly developed, defining different multifractality parameters for different regions of an image. Then, a multiscale Potts Markov random field is introduced as a prior to model the inherent spatial and scale correlations (referred to as cross-scale correlations) between the labels of the wavelet leaders. A Gibbs sampling methodology is finally used to draw samples from the posterior distribution of the unknown model parameters. Numerical experiments are conducted on synthetic multifractal images to evaluate the performance of the proposed segmentation approach. The proposed method achieves superior performance compared to traditional unsupervised segmentation techniques as well as modern deep learning-based approaches, showing its effectiveness for multifractal image segmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08694v2</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kareth M. Le\'on-L\'opez, Abderrahim Halimi, Jean-Yves Tourneret, Herwig Wendt</dc:creator>
    </item>
    <item>
      <title>Recent Advances in Discrete Speech Tokens: A Review</title>
      <link>https://arxiv.org/abs/2502.06490</link>
      <description>arXiv:2502.06490v4 Announce Type: replace-cross 
Abstract: The rapid advancement of speech generation technologies in the era of large language models (LLMs) has established discrete speech tokens as a foundational paradigm for speech representation. These tokens, characterized by their discrete, compact, and concise nature, are not only advantageous for efficient transmission and storage, but also inherently compatible with the language modeling framework, enabling seamless integration of speech into text-dominated LLM architectures. Current research categorizes discrete speech tokens into two principal classes: acoustic tokens and semantic tokens, each of which has evolved into a rich research domain characterized by unique design philosophies and methodological approaches. This survey systematically synthesizes the existing taxonomy and recent innovations in discrete speech tokenization, conducts a critical examination of the strengths and limitations of each paradigm, and presents systematic experimental comparisons across token types. Furthermore, we identify persistent challenges in the field and propose potential research directions, aiming to offer actionable insights to inspire future advancements in the development and application of discrete speech tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06490v4</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwei Guo, Zhihan Li, Hankun Wang, Bohan Li, Chongtian Shao, Hanglei Zhang, Chenpeng Du, Xie Chen, Shujie Liu, Kai Yu</dc:creator>
    </item>
    <item>
      <title>Random-phase Wave Splatting of Translucent Primitives for Computer-generated Holography</title>
      <link>https://arxiv.org/abs/2508.17480</link>
      <description>arXiv:2508.17480v3 Announce Type: replace-cross 
Abstract: Holographic near-eye displays offer ultra-compact form factors for VR/AR systems but rely on advanced computer-generated holography (CGH) algorithms to convert 3D scenes into interference patterns on spatial light modulators (SLMs). Conventional CGH typically generates smooth-phase holograms, limiting view-dependent effects and realistic defocus blur, while severely under-utilizing the SLM space-bandwidth product. We propose Random-phase Wave Splatting (RPWS), a unified wave optics rendering framework that converts arbitrary 3D representations based on 2D translucent primitives into random-phase holograms. RPWS is fully compatible with modern 3D representations such as Gaussians and triangles, improves bandwidth utilization which effectively enlarges eyebox size, reconstructs accurate defocus blur and parallax, and leverages time-multiplexed rendering not as a heuristic for speckle suppression, but as a mathematically exact alpha-blending mechanism derived from first principles in statistics. At the core of RPWS are (1) a new wavefront compositing procedure and (2) an alpha-blending scheme for random-phase geometric primitives, ensuring correct color reconstruction and robust occlusion when compositing millions of primitives. RPWS departs substantially from the recent primitive-based CGH algorithm, Gaussian Wave Splatting (GWS). Because GWS uses smooth-phase primitives, it struggles to capture view-dependent effects and realistic defocus blur and under-utilizes the SLM space-bandwidth product; moreover, naively extending GWS to random-phase primitives fails to reconstruct accurate colors. In contrast, RPWS is designed from the ground up for arbitrary random-phase translucent primitives, and through simulations and experimental validations we demonstrate state-of-the-art image quality and perceptually faithful 3D holograms for next-generation near-eye displays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17480v3</guid>
      <category>cs.GR</category>
      <category>cs.AR</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>physics.optics</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian Chao, Jacqueline Yang, Suyeon Choi, Manu Gopakumar, Ryota Koiso, Gordon Wetzstein</dc:creator>
    </item>
    <item>
      <title>A Digital SRAM-Based Compute-In-Memory Macro for Weight-Stationary Dynamic Matrix Multiplication in Transformer Attention Score Computation</title>
      <link>https://arxiv.org/abs/2511.12152</link>
      <description>arXiv:2511.12152v3 Announce Type: replace-cross 
Abstract: Compute-in-memory (CIM) techniques are widely employed in energy-efficient artificial intelligent (AI) processors. They alleviate power and latency bottlenecks caused by extensive data movements between compute and storage units. To extend these benefits to Transformer, this brief proposes a digital CIM macro to compute attention score. To eliminate dynamic matrix multiplication (MM), we reconstruct the computation as static MM using a combined QK-weight matrix, so that inputs can be directly fed to a single CIM macro to obtain the score results. However, this introduces a new challenge of 2-input static MM. The computation is further decomposed into four groups of bit-serial logical and addition operations. This allows 2-input to directly activate the word line via AND gate, thus realizing 2-input static MM with minimal overhead. A hierarchical zero-value bit skipping mechanism is introduced to prioritize skipping zero-value bits in the 2-input case. This mechanism effectively utilizes data sparsity of 2-input, significantly reducing redundant operations. Implemented in a 65-nm process, the 0.35 mm2 macro delivers 42.27 GOPS at 1.24 mW, yielding 34.1 TOPS/W energy and 120.77 GOPS/mm2 area efficiency. Compared to CPUs and GPUs, it achieves ~25x and ~13x higher efficiency, respectively. Against other Transformer-CIMs, it demonstrates at least 7x energy and 2x area efficiency gains, highlighting its strong potential for edge intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12152v3</guid>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianyi Yu, Tengxiao Wang, Yuxuan Wang, Xiang Fu, Fei Qiao, Ying Wang, Rui Yuan, Liyuan Liu, Cong Shi</dc:creator>
    </item>
  </channel>
</rss>
