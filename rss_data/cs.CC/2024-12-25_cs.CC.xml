<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Theoretical Constraints on the Expressive Power of $\mathsf{RoPE}$-based Tensor Attention Transformers</title>
      <link>https://arxiv.org/abs/2412.18040</link>
      <description>arXiv:2412.18040v1 Announce Type: cross 
Abstract: Tensor Attention extends traditional attention mechanisms by capturing high-order correlations across multiple modalities, addressing the limitations of classical matrix-based attention. Meanwhile, Rotary Position Embedding ($\mathsf{RoPE}$) has shown superior performance in encoding positional information in long-context scenarios, significantly enhancing transformer models' expressiveness. Despite these empirical successes, the theoretical limitations of these technologies remain underexplored. In this study, we analyze the circuit complexity of Tensor Attention and $\mathsf{RoPE}$-based Tensor Attention, showing that with polynomial precision, constant-depth layers, and linear or sublinear hidden dimension, they cannot solve fixed membership problems or $(A_{F,r})^*$ closure problems, under the assumption that $\mathsf{TC}^0 \neq \mathsf{NC}^1$. These findings highlight a gap between the empirical performance and theoretical constraints of Tensor Attention and $\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that could guide the development of more theoretically grounded approaches to Transformer model design and scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18040v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Mingda Wan</dc:creator>
    </item>
    <item>
      <title>Learning Randomized Reductions and Program Properties</title>
      <link>https://arxiv.org/abs/2412.18134</link>
      <description>arXiv:2412.18134v1 Announce Type: cross 
Abstract: The correctness of computations remains a significant challenge in computer science, with traditional approaches relying on automated testing or formal verification. Self-testing/correcting programs introduce an alternative paradigm, allowing a program to verify and correct its own outputs via randomized reductions, a concept that previously required manual derivation. In this paper, we present Bitween, a method and tool for automated learning of randomized (self)-reductions and program properties in numerical programs. Bitween combines symbolic analysis and machine learning, with a surprising finding: polynomial-time linear regression, a basic optimization method, is not only sufficient but also highly effective for deriving complex randomized self-reductions and program invariants, often outperforming sophisticated mixed-integer linear programming solvers. We establish a theoretical framework for learning these reductions and introduce RSR-Bench, a benchmark suite for evaluating Bitween's capabilities on scientific and machine learning functions. Our empirical results show that Bitween surpasses state-of-the-art tools in scalability, stability, and sample efficiency when evaluated on nonlinear invariant benchmarks like NLA-DigBench. Bitween is open-source as a Python package and accessible via a web interface that supports C language programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18134v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ferhat Erata, Orr Paradise, Timos Antonopoulos, ThanhVu Nguyen, Shafi Goldwasser, Ruzica Piskac</dc:creator>
    </item>
    <item>
      <title>Matrix Chaos Inequalities and Chaos of Combinatorial Type</title>
      <link>https://arxiv.org/abs/2412.18468</link>
      <description>arXiv:2412.18468v1 Announce Type: cross 
Abstract: Matrix concentration inequalities and their recently discovered sharp counterparts provide powerful tools to bound the spectrum of random matrices whose entries are linear functions of independent random variables. However, in many applications in theoretical computer science and in other areas one encounters more general random matrix models, called matrix chaoses, whose entries are polynomials of independent random variables. Such models have often been studied on a case-by-case basis using ad-hoc methods that can yield suboptimal dimensional factors.
  In this paper we provide general matrix concentration inequalities for matrix chaoses, which enable the treatment of such models in a systematic manner. These inequalities are expressed in terms of flattenings of the coefficients of the matrix chaos. We further identify a special family of matrix chaoses of combinatorial type for which the flattening parameters can be computed mechanically by a simple rule. This allows us to provide a unified treatment of and improved bounds for matrix chaoses that arise in a variety of applications, including graph matrices, Khatri-Rao matrices, and matrices that arise in average case analysis of the sum-of-squares hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18468v1</guid>
      <category>math.PR</category>
      <category>cs.CC</category>
      <category>math.FA</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Afonso S. Bandeira, Kevin Lucca, Petar Nizi\'c-Nikolac, Ramon van Handel</dc:creator>
    </item>
    <item>
      <title>Reduction from the partition problem: Dynamic lot sizing problem with polynomial complexity</title>
      <link>https://arxiv.org/abs/2412.05017</link>
      <description>arXiv:2412.05017v2 Announce Type: replace 
Abstract: In this note, we polynomially reduce an instance of the partition problem to a dynamic lot sizing problem, and show that solving the latter problem solves the former problem. We show that the instance of the partition problem can be solved using polynomial number of addition, multiplication and sort operations in input data using the reduction. Numerical results on solving instances of the partition problem are also provided using an implementation of the algorithm to solve the dynamic lot sizing problem that is reduced from the instance of the partition problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05017v2</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chee-Khian Sim</dc:creator>
    </item>
    <item>
      <title>CodeComplex: Dataset for Worst-Case Time Complexity Prediction</title>
      <link>https://arxiv.org/abs/2401.08719</link>
      <description>arXiv:2401.08719v2 Announce Type: replace-cross 
Abstract: Reasoning ability of Large Language Models (LLMs) is a crucial ability, especially in complex decision-making tasks. One significant task to show LLMs' reasoning capability is code time complexity prediction, which involves various intricate factors such as the input range of variables and conditional loops. Current benchmarks fall short of providing a rigorous assessment due to limited data, language constraints, and insufficient labeling. They do not consider time complexity based on input representation and merely evaluate whether predictions fall into the same class, lacking a measure of how close incorrect predictions are to the correct ones. To address these dependencies, we introduce CodeComplex, the first robust and extensive dataset designed to evaluate LLMs' reasoning abilities in predicting code time complexity. CodeComplex comprises 4,900 Java codes and an equivalent number of Python codes, overcoming language and labeling constraints, carefully annotated with complexity labels based on input characteristics by a panel of algorithmic experts. Additionally, we propose specialized evaluation metrics for the reasoning of complexity prediction tasks, offering a more precise and reliable assessment of LLMs' reasoning capabilities. We release our dataset (https://github.com/sybaik1/CodeComplex-Data) and baseline models (https://github.com/sybaik1/CodeComplex-Models) publicly to encourage the relevant (NLP, SE, and PL) communities to utilize and participate in this research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08719v2</guid>
      <category>cs.SE</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seung-Yeop Baik, Joonghyuk Hahn, Jungin Kim, Mingi Jeon,  Aditi, Yo-Sub Han, Sang-Ki Ko</dc:creator>
    </item>
    <item>
      <title>Solving The Travelling Salesman Problem Using A Single Qubit</title>
      <link>https://arxiv.org/abs/2407.17207</link>
      <description>arXiv:2407.17207v2 Announce Type: replace-cross 
Abstract: The travelling salesman problem (TSP) is a popular NP-hard-combinatorial optimization problem that requires finding the optimal way for a salesman to travel through different cities once and return to the initial city. The existing methods of solving TSPs on quantum systems are either gate-based or binary variable-based encoding. Both approaches are resource-expensive in terms of the number of qubits while performing worse compared to existing classical algorithms even for small-size problems. We present an algorithm that solves an arbitrary TSP using a single qubit by invoking the principle of quantum parallelism. The cities are represented as quantum states on the Bloch sphere while the preparation of superposition states allows us to traverse multiple paths at once. The underlying framework of our algorithm is a quantum version of the classical Brachistochrone approach. Optimal control methods are employed to create a selective superposition of the quantum states to find the shortest route of a given TSP. The numerical simulations solve a sample of four to nine cities for which exact solutions are obtained. The algorithm can be implemented on any quantum platform capable of efficiently rotating a qubit and allowing state tomography measurements. For the TSP problem sizes considered in this work, our algorithm is more resource-efficient and accurate than existing quantum algorithms with the potential for scalability. A potential speed-up of polynomial time over classical algorithms is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17207v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kapil Goswami, Gagan Anekonda Veereshi, Peter Schmelcher, Rick Mukherjee</dc:creator>
    </item>
    <item>
      <title>An alternative non-unitary implementation for the quantum search algorithm</title>
      <link>https://arxiv.org/abs/2412.16514</link>
      <description>arXiv:2412.16514v2 Announce Type: replace-cross 
Abstract: In this paper, we describe an alternative circuit implementation for the Grover search algorithm by replacing the amplitude amplification part with a non-unitary gate which can be implemented by using an additional ancilla register. We show that the final quantum state in the Grover search algorithm is the normalized marked quantum state in the Gram-Schmidt process. Therefore, one can try to generate this vector by using a non-unitary gate or an approximation of this non-unitary gate. Since we still use the marking part of the original algorithm, $U_{mark}$, the complexity of the algorithm is bounded by the complexity of this operator. We discuss how the implementation of the non-unitary may not be easy task and show the approximations to this operator e.g. through linear combination of unitary matrices or similar methods. Finally we discuss, how these approximations may change the complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16514v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ammar Daskin</dc:creator>
    </item>
  </channel>
</rss>
