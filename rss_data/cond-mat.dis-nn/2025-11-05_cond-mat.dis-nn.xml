<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Nov 2025 02:45:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the supra-linear storage in dense networks of grid and place cells</title>
      <link>https://arxiv.org/abs/2511.02441</link>
      <description>arXiv:2511.02441v1 Announce Type: new 
Abstract: Place-cell networks, typically forced to pairwise synaptic interactions, are widely studied as models of cognitive maps: such models, however, share a severely limited storage capacity, scaling linearly with network size and with a very small critical storage. This limitation is a challenge for navigation in 3-dimensional space because, oversimplifying, if encoding motion along a one-dimensional trajectory embedded in 2-dimensions requires $O(K)$ patterns (interpreted as bins), extending this to a 2-dimensional manifold embedded in a 3-dimensional space -yet preserving the same resolution- requires roughly $O(K^2)$ patterns, namely a supra-linear amount of patterns. In these regards, dense Hebbian architectures, where higher-order neural assemblies mediate memory retrieval, display much larger capacities and are increasingly recognized as biologically plausible, but have never linked to place cells so far. Here we propose a minimal two-layer model, with place cells building a layer and leaving the other layer populated by neural units that account for the internal representations (so to qualitatively resemble grid cells in the MEC of mammals): crucially, by assuming that each place cell interacts with pairs of grid cells, we show how such a model is formally equivalent to a dense Battaglia-Treves-like Hebbian network of grid cells only endowed with four-body interactions. By studying its emergent computational properties by means of statistical mechanics of disordered systems, we prove -analytically- that such effective higher-order assemblies (constructed under the guise of biological plausibility) can support supra-linear storage of continuous attractors; furthermore, we prove -numerically- that the present neural network is capable of recognition and navigation on general surfaces embedded in a 3-dimensional space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02441v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adriano Barra, Martino S. Centonze, Michela Marra Solazzo, Daniele Tantari</dc:creator>
    </item>
    <item>
      <title>Bulk-boundary decomposition of neural networks</title>
      <link>https://arxiv.org/abs/2511.02003</link>
      <description>arXiv:2511.02003v1 Announce Type: cross 
Abstract: We present the bulk-boundary decomposition as a new framework for understanding the training dynamics of deep neural networks. Starting from the stochastic gradient descent formulation, we show that the Lagrangian can be reorganized into a data-independent bulk term and a data-dependent boundary term. The bulk captures the intrinsic dynamics set by network architecture and activation functions, while the boundary reflects stochastic interactions from training samples at the input and output layers. This decomposition exposes the local and homogeneous structure underlying deep networks. As a natural extension, we develop a field-theoretic formulation of neural dynamics based on this decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02003v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>hep-ph</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donghee Lee, Hye-Sung Lee, Jaeok Yi</dc:creator>
    </item>
    <item>
      <title>How universal is the mean-field universality class for percolation in complex networks?</title>
      <link>https://arxiv.org/abs/2506.17175</link>
      <description>arXiv:2506.17175v2 Announce Type: replace 
Abstract: Clustering and degree correlations are ubiquitous in real-world complex networks. Yet, understanding their role in critical phenomena remains a challenge for theoretical studies. Here, we provide the exact solution of site percolation in a model for strongly clustered random graphs, with many overlapping loops and heterogeneous degree distribution. We systematically compare the exact solution with heterogeneous mean-field predictions obtained from a treelike random rewiring of the network, which preserves only the degree sequence. Our results demonstrate a nontrivial interplay between degree heterogeneity, correlations and network topology, which can significantly alter both the percolation threshold and the critical exponents predicted by the heterogeneous mean-field. These findings reveal limitations of heterogeneous mean-field theory, demonstrating that the degree distribution alone is insufficient to determine universality classes in complex networks with realistic structural features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17175v2</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1209/0295-5075/ae1322</arxiv:DOI>
      <arxiv:journal_reference>EPL, 152 (2025) 31002</arxiv:journal_reference>
      <dc:creator>Lorenzo Cirigliano</dc:creator>
    </item>
    <item>
      <title>Ontological differentiation as a measure of semantic accuracy</title>
      <link>https://arxiv.org/abs/2507.06208</link>
      <description>arXiv:2507.06208v3 Announce Type: replace 
Abstract: Understanding semantic relationships within complex networks derived from lexical resources is fundamental for network science and language modeling. While network embedding methods capture contextual similarity, quantifying semantic distance based directly on explicit definitional structure remains challenging. Accurate measures of semantic similarity allow for navigation on lexical networks based on maximizing semantic similarity in each navigation jump (Semantic Navigation, SN). This work introduces Ontological Differentiation (OD), a formal method for measuring divergence between concepts by analyzing overlap during recursive definition expansion. The methodology is applied to networks extracted from the Simple English Wiktionary, comparing OD scores with other measures of semantic similarity proposed in the literature (cosine similarity based on random-walk network exploration). We find weak correlations between direct pairwise OD scores and cosine similarities across $\sim$~2 million word pairs, sampled from a pool representing over 50\% of the entries in the Wiktionary lexicon. This establishes OD as a largely independent, definition-based semantic metric, whose orthogonality to cosine similarity becomes more pronounced when low-semantic-content terms were removed from the dataset. Additionally, we use cumulative OD scores to evaluate paths generated by vector-based SN and structurally optimal Shortest Paths (SP) across networks. We find SN paths consistently exhibit significantly lower cumulative OD scores than shortest paths, suggesting that SN produces trajectories more coherent with the dictionary's definitional structure, as measured by OD. Ontological Differentiation thus provides a novel, definition-grounded tool for analyzing, validating, and potentially constructing navigation processes in lexical networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06208v3</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pablo Garcia-Cuadrillero, Fabio Revuelta, Jose Angel Capitan</dc:creator>
    </item>
    <item>
      <title>Controlling quantum chaos via Parrondo strategies on noisy intermediate-scale quantum hardware</title>
      <link>https://arxiv.org/abs/2506.11225</link>
      <description>arXiv:2506.11225v2 Announce Type: replace-cross 
Abstract: Advancements in Noisy Intermediate-Scale Quantum (NISQ) computing are steadily pushing these systems toward outperforming classical supercomputers on specific, well-defined computational tasks. In this work, we explore and control quantum chaos in NISQ systems using discrete-time quantum walks (DTQW) on cyclic graphs. To efficiently implement quantum walks on NISQ hardware, we employ the quantum Fourier transform (QFT) to diagonalize the conditional shift operator, optimizing circuit depth and fidelity. We experimentally realize the transition from quantum chaos to order via DTQW dynamics on both odd and even cyclic graphs, specifically 3- and 4-cycle graphs, using the counterintuitive Parrondo's paradox strategy across three different NISQ devices. While the 4-cycle graphs exhibit high-fidelity quantum evolution, the 3-cycle implementation shows significant fidelity improvement when augmented with dynamical decoupling pulses. Our results demonstrate a practical approach to probing and harnessing controlled chaotic dynamics on real quantum hardware, laying the groundwork for future quantum algorithms and cryptographic protocols based on quantum walks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11225v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AR</category>
      <category>nlin.CD</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1103/m89r-2dy5</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E (2025)</arxiv:journal_reference>
      <dc:creator>Aditi Rath, Dinesh Kumar Panda, Colin Benjamin</dc:creator>
    </item>
    <item>
      <title>Quasiconservation Laws and Suppressed Transport in Weakly Interacting Localized Models</title>
      <link>https://arxiv.org/abs/2507.03115</link>
      <description>arXiv:2507.03115v3 Announce Type: replace-cross 
Abstract: The stability of localization in the presence of interactions remains an open problem, with finite-size effects posing significant challenges to numerical studies. In this work, we investigate the perturbative stability of noninteracting localization under weak interactions, which allows us to analyze much larger system sizes. Focusing on disordered Anderson and quasiperiodic Aubry-Andr\'e models in one dimension, and using the adiabatic gauge potential (AGP) at first order in perturbation theory, we compute first-order corrections to noninteracting local integrals of motion (LIOMs). We find that for at least an $O(1)$ fraction of the LIOMs, the corrections are well-controlled and converge at large system sizes, while others suffer from resonances. Additionally, we introduce and study the charge-transport capacity of this weakly interacting model. To first order, we find that the charge transport capacity remains bounded in the presence of interactions. Taken together, these results demonstrate that localization is perturbatively stable to weak interactions at first order, implying that, at the very least, localization persists for parametrically long times in the inverse interaction strength. We expect this perturbative stability to extend to all orders at sufficiently strong disorder, where the localization length is short, representing the true localized phase. Conversely, our findings suggest that the previously proposed interaction-induced avalanche instability, namely in the weakly localized regime of the Anderson and Aubry-Andr\'e models, is a more subtle phenomenon arising only at higher orders in perturbation theory or through nonperturbative effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03115v3</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>quant-ph</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/shj5-bvs3</arxiv:DOI>
      <dc:creator>Jessica Kaijia Jiang, Federica Maria Surace, Olexei I. Motrunich</dc:creator>
    </item>
    <item>
      <title>Quantum Transport Reservoir Computing</title>
      <link>https://arxiv.org/abs/2509.07778</link>
      <description>arXiv:2509.07778v2 Announce Type: replace-cross 
Abstract: Reservoir computing (RC), a neural network designed for temporal data, enables efficient computation with low-cost training and direct physical implementation. Recently, quantum RC has opened new possibilities for conventional RC and introduced novel ideas to tackle open problems in quantum physics and advance quantum technologies. Despite its promise, it faces challenges, including physical realization, output readout, and measurement-induced back-action. Here, we propose to implement quantum RC through quantum transport in mesoscopic electronic systems. Our approach possesses several advantages: compatibility with existing device fabrication techniques, ease of output measurement, and robustness against measurement back-action. Leveraging universal conductance fluctuations, we numerically demonstrate two benchmark tasks, spoken-digit recognition and time-series forecasting, to validate our proposal. This work establishes a novel pathway for implementing on-chip quantum RC via quantum transport and expands the mesoscopic physics applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07778v2</guid>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/w117-7gmd</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Applied 24, 044036 (2025)</arxiv:journal_reference>
      <dc:creator>Yecheng Jing, Pengfei Wang, Shuai Zhang, Zhoujie Zeng, Shi-Jun Liang, Wei Chen</dc:creator>
    </item>
    <item>
      <title>When Less is More: Approximating the Quantum Geometric Tensor with Block Structures</title>
      <link>https://arxiv.org/abs/2510.08430</link>
      <description>arXiv:2510.08430v2 Announce Type: replace-cross 
Abstract: The natural gradient is central in neural quantum states optimizations but it is limited by the cost of computing and inverting the quantum geometric tensor, the quantum analogue of the Fisher information matrix. We introduce a block-diagonal quantum geometric tensor that partitions the metric by network layers, analogous to block-structured Fisher methods such as K-FAC. This layer-wise approximation preserves essential curvature while removing noisy cross-layer correlations, improving conditioning and scalability. Experiments on Heisenberg and frustrated $J_1$-$J_2$ models show faster convergence, lower energy, and improved stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08430v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmedeo Shokry, Alessandro Santini, Filippo Vicentini</dc:creator>
    </item>
  </channel>
</rss>
