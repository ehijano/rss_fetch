<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Oct 2025 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Condorcet's Jury Theorem with Abstention</title>
      <link>https://arxiv.org/abs/2510.18062</link>
      <description>arXiv:2510.18062v1 Announce Type: new 
Abstract: The well-known Condorcet Jury Theorem states that, under majority rule, the better of two alternatives is chosen with probability approaching one as the population grows. We study an asymmetric setting where voters face varying participation costs and share a possibly heuristic belief about their pivotality (ability to influence the outcome).
  In a costly voting setup where voters abstain if their participation cost is greater than their pivotality estimate, we identify a single property of the heuristic belief -- weakly vanishing pivotality -- that gives rise to multiple stable equilibria in which elections are nearly tied. In contrast, strongly vanishing pivotality (as in the standard Calculus of Voting model) yields a unique, trivial equilibrium where only zero-cost voters participate as the population grows. We then characterize when nontrivial equilibria satisfy a version of the Jury Theorem: below a sharp threshold, the majority-preferred candidate wins with probability approaching one; above it, both candidates either win with equal probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18062v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reshef Meir, Ganesh Ghalme</dc:creator>
    </item>
    <item>
      <title>Contextual Search in Principal-Agent Games: The Curse of Degeneracy</title>
      <link>https://arxiv.org/abs/2510.18567</link>
      <description>arXiv:2510.18567v1 Announce Type: new 
Abstract: In this work, we introduce and study contextual search in general principal-agent games, where a principal repeatedly interacts with agents by offering contracts based on contextual information and historical feedback, without knowing the agents' true costs or rewards. Our model generalizes classical contextual pricing by accommodating richer agent action spaces. Over $T$ rounds with $d$-dimensional contexts, we establish an asymptotically tight exponential $T^{1 - \Theta(1/d)}$ bound in terms of the pessimistic Stackelberg regret, benchmarked against the best utility for the principal that is consistent with the observed feedback.
  We also establish a lower bound of $\Omega(T^{\frac{1}{2}-\frac{1}{2d}})$ on the classic Stackelberg regret for principal-agent games, demonstrating a surprising double-exponential hardness separation from the contextual pricing problem (a.k.a, the principal-agent game with two actions), which is known to admit a near-optimal $O(d\log\log T)$ regret bound [Kleinberg and Leighton, 2003, Leme and Schneider, 2018, Liu et al., 2021]. In particular, this double-exponential hardness separation occurs even in the special case with three actions and two-dimensional context. We identify that this significant increase in learning difficulty arises from a structural phenomenon that we call contextual action degeneracy, where adversarially chosen contexts can make some actions strictly dominated (and hence unincentivizable), blocking the principal's ability to explore or learn about them, and fundamentally limiting learning progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18567v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiding Feng, Mengfan Ma, Bo Peng, Zongqi Wan</dc:creator>
    </item>
    <item>
      <title>Likelihood of the Existence of Average Justified Representation</title>
      <link>https://arxiv.org/abs/2510.18718</link>
      <description>arXiv:2510.18718v1 Announce Type: new 
Abstract: We study the approval-based multi-winner election problem where $n$ voters jointly decide a committee of $k$ winners from $m$ candidates. We focus on the axiom \emph{average justified representation} (AJR) proposed by Fernandez, Elkind, Lackner, Garcia, Arias-Fisteus, Basanta-Val, and Skowron (2017). AJR postulates that every group of voters with a common preference should be sufficiently represented in that their average satisfaction should be no less than their Hare quota. Formally, for every group of $\lceil\ell\cdot\frac{n}{k}\rceil$ voters with $\ell$ common approved candidates, the average number of approved winners for this group should be at least $\ell$. It is well-known that a winning committee satisfying AJR is not guaranteed to exist for all multi-winner election instances. In this paper, we study the likelihood of the existence of AJR under the Erd\H{o}s--R\'enyi model. We consider the Erd\H{o}s--R\'enyi model parameterized by $p\in[0,1]$ that samples multi-winner election instances from the distribution where each voter approves each candidate with probability $p$ (and the events that voters approve candidates are independent), and we provide a clean and complete characterization of the existence of AJR committees in the case where $m$ is a constant and $n$ tends to infinity. We show that there are two phase transition points $p_1$ and $p_2$ (with $p_1\leq p_2$) for the parameter $p$ such that: 1) when $p&lt;p_1$ or $p&gt;p_2$, an AJR committee exists with probability $1-o(1)$, 2) when $p_1&lt;p&lt;p_2$, an AJR committee exists with probability $o(1)$, and 3) when $p=p_1$ or $p=p_2$, the probability that an AJR committee exists is bounded away from both $0$ and $1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18718v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qishen Han, Biaoshuai Tao, Lirong Xia, Chengkai Zhang, Houyu Zhou</dc:creator>
    </item>
    <item>
      <title>Nash Policy Gradient: A Policy Gradient Method with Iteratively Refined Regularization for Finding Nash Equilibria</title>
      <link>https://arxiv.org/abs/2510.18183</link>
      <description>arXiv:2510.18183v1 Announce Type: cross 
Abstract: Finding Nash equilibria in imperfect-information games remains a central challenge in multi-agent reinforcement learning. While regularization-based methods have recently achieved last-iteration convergence to a regularized equilibrium, they require the regularization strength to shrink toward zero to approximate a Nash equilibrium, often leading to unstable learning in practice. Instead, we fix the regularization strength at a large value for robustness and achieve convergence by iteratively refining the reference policy. Our main theoretical result shows that this procedure guarantees strictly monotonic improvement and convergence to an exact Nash equilibrium in two-player zero-sum games, without requiring a uniqueness assumption. Building on this framework, we develop a practical algorithm, Nash Policy Gradient (NashPG), which preserves the generalizability of policy gradient methods while relying solely on the current and reference policies. Empirically, NashPG achieves comparable or lower exploitability than prior model-free methods on classic benchmark games and scales to large domains such as Battleship and No-Limit Texas Hold'em, where NashPG consistently attains higher Elo ratings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18183v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eason Yu, Tzu Hao Liu, Yunke Wang, Cl\'ement L. Canonne, Nguyen H. Tran, Chang Xu</dc:creator>
    </item>
    <item>
      <title>Public Signals in Network Congestion Games</title>
      <link>https://arxiv.org/abs/2205.09823</link>
      <description>arXiv:2205.09823v2 Announce Type: replace 
Abstract: We consider a largely untapped potential for the improvement of traffic networks that is rooted in the inherent uncertainty of travel times. Travel times are subject to stochastic uncertainty resulting from various parameters such as weather condition, occurrences of road works, or traffic accidents. Large mobility services have an informational advantage over single network users as they are able to learn traffic conditions from data. A benevolent mobility service may use this informational advantage in order to steer the traffic equilibrium into a favorable direction. The resulting optimization problem is a task commonly referred to as signaling or Bayesian persuasion. Previous work has shown that the underlying signaling problem can be NP-hard to approximate within any non-trivial bounds, even for affine cost functions with stochastic offsets. In contrast, we show that in this case, the signaling problem is easy for many networks. We tightly characterize the class of single-commodity networks, in which full information revelation is always an optimal signaling strategy. Moreover, we construct a reduction from optimal signaling to computing an optimal collection of support vectors for the Wardrop equilibrium. For two states, this insight can be used to compute an optimal signaling scheme. The algorithm runs in polynomial time whenever the number of different supports resulting from any signal distribution is bounded to a polynomial in the input size. Using a cell decomposition technique, we extend the approach to a polynomial-time algorithm for multi-commodity parallel link networks with a constant number of commodities, even when we have a constant number of different states of nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.09823v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Svenja M. Griesbach, Martin Hoefer, Max Klimm, Tim Koglin</dc:creator>
    </item>
    <item>
      <title>Free-Riding in Multi-Issue Decisions</title>
      <link>https://arxiv.org/abs/2310.08194</link>
      <description>arXiv:2310.08194v2 Announce Type: replace 
Abstract: Voting in multi-issue domains allows for compromise outcomes that satisfy all voters to some extent, but such fairness considerations open the possibility of a special form of manipulation: free-riding, where voters untruthfully oppose a popular opinion in one issue to receive increased consideration in other issues; we study under which conditions this is possible and show that even weak fairness considerations enable free-riding, and through computational and experimental analysis, we find that while free-riding in multi-issue domains is often possible, it comes at a non-negligible individual risk for voters, making its allure smaller than one could intuitively assume.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08194v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Lackner, Jan Maly, Oliviero Nardi</dc:creator>
    </item>
    <item>
      <title>Fairshare Data Pricing via Data Valuation for Large Language Models</title>
      <link>https://arxiv.org/abs/2502.00198</link>
      <description>arXiv:2502.00198v3 Announce Type: replace 
Abstract: Training data is the backbone of large language models (LLMs), yet today's data markets often operate under exploitative pricing -- sourcing data from marginalized groups with little pay or recognition. This paper introduces a theoretical framework for LLM data markets, modeling the strategic interactions between buyers (LLM builders) and sellers (human annotators). We begin with theoretical and empirical analysis showing how exploitative pricing drives high-quality sellers out of the market, degrading data quality and long-term model performance. Then we introduce fairshare, a pricing mechanism grounded in data valuation that quantifies each data's contribution. It aligns incentives by sustaining seller participation and optimizing utility for both buyers and sellers. Theoretically, we show that fairshare yields mutually optimal outcomes: maximizing long-term buyer utility and seller profit while sustaining market participation. Empirically when training open-source LLMs on complex NLP tasks, including math problems, medical diagnosis, and physical reasoning, fairshare boosts seller earnings and ensures a stable supply of high-quality data, while improving buyers' performance-per-dollar and long-term welfare. Our findings offer a concrete path toward fair, transparent, and economically sustainable data markets for LLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00198v3</guid>
      <category>cs.GT</category>
      <category>cs.CL</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luyang Zhang, Cathy Jiao, Beibei Li, Chenyan Xiong</dc:creator>
    </item>
    <item>
      <title>The Power of Matching for Online Fractional Hedonic Games</title>
      <link>https://arxiv.org/abs/2505.06163</link>
      <description>arXiv:2505.06163v2 Announce Type: replace 
Abstract: We study coalition formation in the framework of fractional hedonic games (FHGs). The objective is to maximize social welfare in an online model where agents arrive one by one and must be assigned to coalitions immediately and irrevocably. A recurrent theme in online coalition formation is that online matching algorithms, where coalitions are restricted to size at most $2$, yield good competitive ratios. For example, computing maximal matchings achieves the optimal competitive ratio for general online FHGs. However, this ratio is bounded only if agents' valuations are themselves bounded.
  We identify optimal algorithms with constant competitive ratios in two related settings, independent of the range of agent valuations. First, under random agent arrival, we present an asymptotically optimal $(\frac{1}{3}-\frac 1n)$-competitive algorithm, where $n$ is the number of agents. This result builds on our identification of an optimal matching algorithm in a general model of online matching with edge weights and an unknown number of agents. In this setting, we also achieve an asymptotically optimal competitive ratio of $\frac{1}{3}-\frac 1n$. Second, when agents arrive in an arbitrary order but algorithms are allowed to irrevocably and entirely dissolve coalitions, we show that another matching-based algorithm achieves an optimal competitive ratio of $\frac{1}{6 + 4\sqrt{2}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06163v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Ren\'e Romen, Alexander Schlenga</dc:creator>
    </item>
    <item>
      <title>On Efficient Computation of DiRe Committees</title>
      <link>https://arxiv.org/abs/2402.19365</link>
      <description>arXiv:2402.19365v2 Announce Type: replace-cross 
Abstract: Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size ${at~most}$ two and a diversity constraint that stipulates the selection of ${at~least}$ one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving ${at~most}$ two candidates and a representation constraint that stipulates the selection of ${at~least}$ one candidate from each population who has a non-null set of approved candidates.
  The DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the minimum vertex cover problem on unweighted undirected graphs) concerns the determination of the smallest size committee that satisfies the given constraints. Here, for this problem, we propose an algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization. We prove the algorithm terminates in polynomial-time. We conjecture the algorithm is an unconditional deterministic polynomial-time algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19365v2</guid>
      <category>cs.CC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kunal Relia</dc:creator>
    </item>
    <item>
      <title>Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game</title>
      <link>https://arxiv.org/abs/2501.19398</link>
      <description>arXiv:2501.19398v2 Announce Type: replace-cross 
Abstract: Large language model-based (LLM-based) agents have become common in settings that include non-cooperative parties. In such settings, agents' decision-making needs to conceal information from their adversaries, reveal information to their cooperators, and infer information to identify the other agents' characteristics. To investigate whether LLMs have these information control and decision-making capabilities, we make LLM agents play the language-based hidden-identity game, The Chameleon. In this game, a group of non-chameleon agents who do not know each other aim to identify the chameleon agent without revealing a secret. The game requires the aforementioned information control capabilities both as a chameleon and a non-chameleon. We begin with a theoretical analysis for a spectrum of strategies, from concealing to revealing, and provide bounds on the non-chameleons' winning probability. The empirical results with GPT, Gemini 2.5 Pro, Llama 3.1, and Qwen3 models show that while non-chameleon LLM agents identify the chameleon, they fail to conceal the secret from the chameleon, and their winning probability is far from the levels of even trivial strategies. Based on these empirical results and our theoretical analysis, we deduce that LLM-based agents may reveal excessive information to agents of unknown identities. Interestingly, we find that, when instructed to adopt an information-revealing level, this level is linearly encoded in the LLM's internal representations. While the instructions alone are often ineffective at making non-chameleon LLMs conceal, we show that steering the internal representations in this linear direction directly can reliably induce concealing behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19398v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa O. Karabag, Jan Sobotka, Ufuk Topcu</dc:creator>
    </item>
  </channel>
</rss>
