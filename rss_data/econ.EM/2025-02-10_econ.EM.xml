<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 04:04:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Estimating Parameters of Structural Models Using Neural Networks</title>
      <link>https://arxiv.org/abs/2502.04945</link>
      <description>arXiv:2502.04945v1 Announce Type: new 
Abstract: We study an alternative use of machine learning. We train neural nets to provide the parameter estimate of a given (structural) econometric model, for example, discrete choice or consumer search. Training examples consist of datasets generated by the econometric model under a range of parameter values. The neural net takes the moments of a dataset as input and tries to recognize the parameter value underlying that dataset. Besides the point estimate, the neural net can also output statistical accuracy. This neural net estimator (NNE) tends to limited-information Bayesian posterior as the number of training datasets increases. We apply NNE to a consumer search model. It gives more accurate estimates at lighter computational costs than the prevailing approach. NNE is also robust to redundant moment inputs. In general, NNE offers the most benefits in applications where other estimation approaches require very heavy simulation costs. We provide code at: https://nnehome.github.io.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04945v1</guid>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/mksc.2022.0360</arxiv:DOI>
      <arxiv:journal_reference>Marketing Science 44(1):102-128 (2024)</arxiv:journal_reference>
      <dc:creator> Yanhao (Max),  Wei, Zhenling Jiang</dc:creator>
    </item>
    <item>
      <title>A sliced Wasserstein and diffusion approach to random coefficient models</title>
      <link>https://arxiv.org/abs/2502.04654</link>
      <description>arXiv:2502.04654v1 Announce Type: cross 
Abstract: We propose a new minimum-distance estimator for linear random coefficient models. This estimator integrates the recently advanced sliced Wasserstein distance with the nearest neighbor methods, both of which enhance computational efficiency. We demonstrate that the proposed method is consistent in approximating the true distribution. Additionally, our formulation encourages a diffusion process-based algorithm, which holds independent interest and potential for broader applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04654v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keunwoo Lim, Ting Ye, Fang Han</dc:creator>
    </item>
    <item>
      <title>A Gaussian smooth transition vector autoregressive model: An application to the macroeconomic effects of severe weather shocks</title>
      <link>https://arxiv.org/abs/2403.14216</link>
      <description>arXiv:2403.14216v3 Announce Type: replace 
Abstract: We introduce a new smooth transition vector autoregressive model with a Gaussian conditional distribution and transition weights that, for a $p$th order model, depend on the full distribution of the preceding $p$ observations. Specifically, the transition weight of each regime increases in its relative weighted likelihood. This data-driven approach facilitates capturing complex switching dynamics, enhancing the identification of gradual regime shifts. In an empirical application to the macroeconomic effects of a severe weather shock, we find that in monthly U.S. data from 1961:1 to 2022:3, the shock has stronger impact in the regime prevailing in the early part of the sample and in certain crisis periods than in the regime dominating the latter part of the sample. This suggests overall adaptation of the U.S. economy to severe weather over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14216v3</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markku Lanne, Savi Virolainen</dc:creator>
    </item>
    <item>
      <title>Prediction Sets and Conformal Inference with Censored Outcomes</title>
      <link>https://arxiv.org/abs/2501.10117</link>
      <description>arXiv:2501.10117v2 Announce Type: replace 
Abstract: Given data on a scalar random variable $Y$, a prediction set for $Y$ with miscoverage level $\alpha$ is a set of values for $Y$ that contains a randomly drawn $Y$ with probability $1 - \alpha$, where $\alpha \in (0,1)$. Among all prediction sets that satisfy this coverage property, the oracle prediction set is the one with the smallest volume. This paper provides estimation methods of such prediction sets given observed conditioning covariates when $Y$ is \textit{censored} or \textit{measured in intervals}. We first characterise the oracle prediction set under interval censoring and develop a consistent estimator for the shortest prediction {\it interval} that satisfies this coverage property.These consistency results are extended to accommodate cases where the prediction set consists of multiple disjoint intervals. We use conformal inference to construct a prediction set that achieves finite-sample validity under censoring and maintains consistency as sample size increases, using a conformity score function designed for interval data. The procedure accommodates the prediction uncertainty that is irreducible (due to the stochastic nature of outcomes), the modelling uncertainty due to partial identification and also sampling uncertainty that gets reduced as samples get larger. We conduct a set of Monte Carlo simulations and an application to data from the Current Population Survey. The results highlight the robustness and efficiency of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10117v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiguang Liu, \'Aureo de Paula, Elie Tamer</dc:creator>
    </item>
  </channel>
</rss>
