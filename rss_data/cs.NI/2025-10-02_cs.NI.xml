<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 01:47:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Wireless Laser Power Transfer for Low-altitude Uncrewed Aerial Vehicle-assisted Internet of Things: Paradigms, Challenges, and Solutions</title>
      <link>https://arxiv.org/abs/2510.00477</link>
      <description>arXiv:2510.00477v1 Announce Type: new 
Abstract: Low-altitude uncrewed aerial vehicles (UAVs) have become integral enablers for the Internet of Things (IoT) by offering enhanced coverage, improved connectivity and access to remote areas. A critical challenge limiting their operational capacity lies in the energy constraints of both aerial platforms and ground-based sensors. This paper explores WLPT as a transformative solution for sustainable energy provisioning in UAV-assisted IoT networks. We first systematically investigate the fundamental principles of WLPT and analysis the comparative advantages. Then, we introduce three operational paradigms for system integration, identify key challenges, and discuss corresponding potential solutions. In case study, we propose a multi-agent reinforcement learning framework to address the coordination and optimization challenges in WLPT-enabled UAV-assisted IoT data collection. Simulation results demonstrate that our framework significantly improves energy sustainability and data freshness. Finally, we discuss some future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00477v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhen Li, Likun Zhang, Chuang Zhang, Jiahui Li, Changyuan Zhao, Ruichen Zhang, Geng Sun</dc:creator>
    </item>
    <item>
      <title>Make a Video Call with LLM: A Measurement Campaign over Five Mainstream Apps</title>
      <link>https://arxiv.org/abs/2510.00481</link>
      <description>arXiv:2510.00481v1 Announce Type: new 
Abstract: In 2025, Large Language Model (LLM) services have launched a new feature -- AI video chat -- allowing users to interact with AI agents via real-time video communication (RTC), just like chatting with real people. Despite its significance, no systematic study has characterized the performance of existing AI video chat systems. To address this gap, this paper proposes a comprehensive benchmark with carefully designed metrics across four dimensions: quality, latency, internal mechanisms, and system overhead. Using custom testbeds, we further evaluate five mainstream AI video chatbots with this benchmark. This work provides the research community a baseline of real-world performance and identifies unique system bottlenecks. In the meantime, our benchmarking results also open up several research questions for future optimizations of AI video chatbots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00481v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <category>cs.PF</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiayang Xu, Xiangjie Huang, Zijie Li, Zili Meng</dc:creator>
    </item>
    <item>
      <title>Dynamic Low Power Traffic Pattern for Energy Constrained Wireless Sensor Networks</title>
      <link>https://arxiv.org/abs/2510.00588</link>
      <description>arXiv:2510.00588v1 Announce Type: new 
Abstract: Wireless Sensor Networks (WSNs) are extensively utilized in critical applications, including remote monitoring, target tracking, healthcare systems, industrial automation, and smart control in both residential and industrial settings. One of the primary challenges in these systems is maintaining energy efficiency, given that most sensor nodes rely on limited battery resources. To tackle this problem, this study introduces an energy-saving strategy designed for tree-structured networks with dynamic traffic patterns. The approach focuses on lowering power usage by decreasing the length and occurrence of idle listening state where nodes remain active unnecessarily while waiting for data transmissions that may never occur. By reducing this form of energy waste, the proposed approach is designed to extend the operational lifetime and enhance the throughput of the wireless sensor network. Simulation results obtained using the OMNeT++ simulator with the MiXiM framework demonstrate that the solution significantly reduces energy consumption, increases data throughput, and improves overall network efficiency and longevity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00588v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Almamoon Alauthman</dc:creator>
    </item>
    <item>
      <title>Faster Offloads by Unloading them -- The RDMA Case</title>
      <link>https://arxiv.org/abs/2510.00735</link>
      <description>arXiv:2510.00735v1 Announce Type: new 
Abstract: From hardware offloads like RDMA to software ones like eBPF, offloads are everywhere and their value is in performance. However, there is evidence that fully offloading -- even when feasible -- does not always give the expected speedups. Starting from the observation that this is due to changes the offloads make -- by moving tasks from the application/CPU closer to the network/link layer -- we argue that to further accelerate offloads, we need to make offloads reversible by unloading them -- moving back part of the offloaded tasks.
  Unloading comes with a set of challenges that we start answering in this paper by focusing on (offloaded) RDMA writes: which part of the write operation does it make sense to unload? how do we dynamically decide which writes to execute on the unload or offload path to improve performance? how do we maintain compatibility between the two paths? Our current prototype shows the potential of unloading by accelerating RDMA writes by up to 31%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00735v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgia Fragkouli, Laurent Vanbever</dc:creator>
    </item>
    <item>
      <title>Optimizing Version AoI in Energy-Harvesting IoT: Model-Based and Learning-Based Approaches</title>
      <link>https://arxiv.org/abs/2510.00904</link>
      <description>arXiv:2510.00904v1 Announce Type: new 
Abstract: Efficient data transmission in resource-constrained Internet of Things (IoT) systems requires semantics-aware management that maximizes the delivery of timely and informative data. This paper investigates the optimization of the semantic metric Version Age of Information (VAoI) in a status update system comprising an energy-harvesting (EH) sensor and a destination monitoring node. We consider three levels of knowledge about the system model -- fully known, partially known, and unknown -- and propose corresponding optimization strategies: model-based, estimation-based, and model-free methods. By employing Markov Decision Process (MDP) and Reinforcement Learning (RL) frameworks, we analyze performance trade-offs under varying degrees of model information. Our findings provide guidance for designing efficient and adaptive semantics-aware policies in both known and unknown IoT environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00904v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Delfani, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Enhancing Urban VANETs Stability: A Single-Hop Clustering Strategy in Metropolitan Environments</title>
      <link>https://arxiv.org/abs/2510.00939</link>
      <description>arXiv:2510.00939v1 Announce Type: new 
Abstract: Vehicular Ad-hoc Networks (VANETs), a subclass of Mobile Ad-hoc Networks (MANETs), are expected to play a crucial role in the future of intelligent transportation systems (ITSs). A key objective of VANETs is to enable efficient and cost-effective communication among vehicles while supporting a large number of network participants and minimizing infrastructure dependency. However, the highly dynamic nature of vehicular networks poses significant challenges to their deployment. Clustering techniques are employed to address these challenges, with a strong emphasis on stability, as they directly influence the routing process and enhance the quality of service (QoS). This paper explores the feasibility of reducing reliance on roadside units (RSUs) in metropolitan areas while improving cluster stability. We propose an efficient clustering algorithm tailored for urban environments, leveraging existing metropolitan infrastructure to compensate for the absence of RSUs. Our approach designates public transportation buses as primary cluster heads (CHs), minimizing reliance on additional infrastructure, while stand-alone vehicles (SAVs) dynamically select additional CHs. Through comprehensive case studies and comparative analysis with existing algorithms, our results demonstrate the superior performance of the proposed method across different transmission ranges (TRs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00939v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Firouzmakan, Suprakash Datta</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Simulated and Real Network Data Using Transfer Learning</title>
      <link>https://arxiv.org/abs/2510.00956</link>
      <description>arXiv:2510.00956v1 Announce Type: new 
Abstract: Machine Learning (ML)-based network models provide fast and accurate predictions for complex network behaviors but require substantial training data. Collecting such data from real networks is often costly and limited, especially for critical scenarios like failures. As a result, researchers commonly rely on simulated data, which reduces accuracy when models are deployed in real environments. We propose a hybrid approach leveraging transfer learning to combine simulated and real-world data. Using RouteNet-Fermi, we show that fine-tuning a pre-trained model with a small real dataset significantly improves performance. Our experiments with OMNeT++ and a custom testbed reduce the Mean Absolute Percentage Error (MAPE) in packet delay prediction by up to 88%. With just 10 real scenarios, MAPE drops by 37%, and with 50 scenarios, by 48%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00956v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos G\"uemes-Palau, Miquel Ferriol-Galm\'es, Jordi Paillisse-Vilanova, Albert L\'opez-Bresc\'o, Pere Barlet-Ros, Albert Cabellos-Aparicio</dc:creator>
    </item>
    <item>
      <title>A Review of Software for Designing and Operating Quantum Networks</title>
      <link>https://arxiv.org/abs/2510.00203</link>
      <description>arXiv:2510.00203v1 Announce Type: cross 
Abstract: Quantum network protocol development is crucial to realizing a production-grade network that can support distributed sensing, secure communication, and utility-scale quantum computation. However, the transition from laboratory demonstration to deployable networks requires software implementations of architectures and protocols tailored to the unique constraints of quantum systems. This paper reviews the current state of software implementations for quantum networks, organized around the three-plane abstraction of infrastructure, logical, and control/service planes. We cover software for both designing quantum network protocols (e.g., SeQUeNCe, QuISP, and NetSquid) and operating them, with a focus on essential control/service plane functions such as entanglement, topology, and resource management, in a proposed taxonomy. Our review highlights a persistent gap between theoretical protocol proposals and their realization in simulators or testbeds, particularly in dynamic topology and network management. We conclude by outlining open challenges and proposing a roadmap for developing scalable software architectures to enable hybrid, large-scale quantum networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00203v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert J. Hayek, Joaquin Chung, Rajkumar Kettimuthu</dc:creator>
    </item>
    <item>
      <title>Offline Meta-learning for Real-time Bandwidth Estimation</title>
      <link>https://arxiv.org/abs/2409.19867</link>
      <description>arXiv:2409.19867v2 Announce Type: replace 
Abstract: Real-time video applications require dynamic bitrate adjustments based on network capacity, necessitating accurate bandwidth estimation (BWE). We introduce Ivy, a novel BWE method that leverages offline meta-learning to combat data drift and maximize user Quality of Experience (QoE). Our approach dynamically selects the most suitable BWE algorithm for current network conditions, enabling effective adaptation to changing environments without requiring live network interactions. We implemented our method in Microsoft Teams and demonstrated that Ivy can enhance QoE by 5.9% to 11.2% over individual BWE algorithms and by 6.3% to 11.4% compared to existing online meta heuristics. Additionally, we show that our method is more data efficient compared to online meta-learning methods, achieving up to 21% improvement in QoE while requiring significantly less training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19867v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aashish Gottipati, Sami Khairy, Yasaman Hosseinkashi, Gabriel Mittag, Vishak Gopal, Francis Y. Yan, Ross Cutler</dc:creator>
    </item>
    <item>
      <title>Semantic Communications Services within Generalist Operated Networks</title>
      <link>https://arxiv.org/abs/2502.18238</link>
      <description>arXiv:2502.18238v2 Announce Type: replace 
Abstract: This paper addresses the challenge of integrating semantic communication principles into operated networks, traditionally optimized based on network-centric metrics rather than application-specific needs. Operated networks strongly adhere to the principle of ``separation of concerns", which emphasizes a clear distinction between network operation and application. Despite the initial perceived incompatibility between semantic communication and the principles of operated networks, this paper provides solutions to reconcile them. The foundations of these solutions include the adoption of non-arbitrary semantic representations as a standard encoding for communications, the establishment of a standard interface between the application and network, and a dedicated network control plane. These enable the application to describe the data typology and the nature of the task, and to agree upon a transmission scheme tailored to the supported task. Through three scenarios involving an application transmitting text representations, we illustrate the implementation of the proposal and demonstrate the potential of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18238v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/SPAWC60668.2024.10693977</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 25th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), Lucca, Italy, 2024, pp. 861-865</arxiv:journal_reference>
      <dc:creator>Quentin Lampin, Louis-Adrien Dufr\`ene, Guillaume Larue</dc:creator>
    </item>
    <item>
      <title>Virtualizing RAN: Science, Strategy, and Architecture of Software-Defined Mobile Networks</title>
      <link>https://arxiv.org/abs/2506.09878</link>
      <description>arXiv:2506.09878v3 Announce Type: replace 
Abstract: Virtualizing the Radio-Access Network (RAN) is increasingly viewed as an enabler of affordable 5G expansion and a stepping-stone toward AI-native 6G. Most discussions, however, still approach spectrum policy, cloud engineering and organizational practice as separate topics. This paper offers an integrated perspective spanning four pillars -- science, technology, business strategy and culture. A comparative U.S.\ case study illustrates how mid-band contiguity, complemented by selective mmWave capacity layers, can improve both coverage and churn when orchestrated through software-defined carrier aggregation. We derive analytic capacity and latency bounds for Split 7.2 $\times$ vRAN/O-RAN deployments, quantify the throughput penalty of end-to-end 256-bit encryption, and show how GPU/FPGA off-load plus digital-twin-driven automation keeps the hybrid-automatic-repeat request (HARQ) round-trip within a 0.5 ms budget. When these technical enablers are embedded in a physics-first delivery roadmap, average vRAN cycle time drops an order of magnitude -- even in the presence of cultural head-winds such as dual-ladder'' erosion. Three cybernetic templates -- the Clock-Hierarchy Law, Ashby's Requisite Variety and a delay-cost curve -- are then used to explain why silo-constrained automation can amplify, rather than absorb, integration debt. Looking forward, silicon-paced 6G evolution (9-12 month node shrinks, sub-THz joint communication-and-sensing, chiplet architectures and optical I/O) calls for a dual-resolution planning grid that couples five-year spectrum physics with six-month silicon sprints.'' The paper closes with balanced, action-oriented recommendations for operators, vendors and researchers on sub-THz fronthaul, AI-native security, energy-proportional accelerators and zero-touch assurance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09878v3</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Barker</dc:creator>
    </item>
    <item>
      <title>Dynamic Pacing for Real-time Satellite Traffic</title>
      <link>https://arxiv.org/abs/2507.09798</link>
      <description>arXiv:2507.09798v2 Announce Type: replace 
Abstract: Google's congestion control (GCC) has become a cornerstone for real-time video and audio communication, yet its performance remains fragile in emerging Low Earth Orbit (LEO) networks. In this paper, we study the behavior of videoconferencing systems in LEO constellations. We observe that video quality degrades due to inherent delays and network instability introduced by the high altitude and rapid movement of LEO satellites, with these effects exacerbated by WebRTC's conventional "one-size-fits-all" sender-side pacing queue management. To address these challenges, we introduce a data-driven queue management mechanism that tunes the maximum pacing queue capacity based on predicted handover activity, minimizing latency during no-handover periods and prioritizing stability when entering periods of increased handover activity. Our method yields up to 3x improvements in video bitrate and reduces freeze rate by 62% in emulation, while delivering up to a 41% reduction in freeze rate and 40% decrease in mean packet loss on real Starlink constellations compared to WebRTC's default pacing queue policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09798v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aashish Gottipati, Lili Qiu</dc:creator>
    </item>
    <item>
      <title>Towards Nomadic 6G Communication Networks: Implications on Architecture, Standardization, and Regulatory Aspects</title>
      <link>https://arxiv.org/abs/2508.12710</link>
      <description>arXiv:2508.12710v2 Announce Type: replace 
Abstract: The emergence of nomadic mobile communication networks for sixth-generation (6G) introduces a paradigm shift in how network infrastructure is conceptualized, deployed, and operated. Unlike traditional fixed systems, Nomadic Networks (NNs) consist of mobile and self-organizing nodes that provide radio infrastructure capabilities in motion. This paper explores the architectural implications of such systems, with a particular focus on the design and evolution of network interfaces. We analyze the requirements for inter-node communication, service discovery, and control delegation in dynamic environments. Furthermore, we examine the regulatory and licensing challenges that arise when infrastructure elements traverse jurisdictional boundaries. Based on current 6G visions and relevant research, we identify limitations in existing architectures and propose a set of interface principles tailored to nomadicity. By synthesizing findings from mobile, non-terrestrial, and organic network domains, this work contributes to the architectural foundation for future nomadic 6G communication systems and outlines directions for interface standardization in decentralized, mobile infrastructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12710v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Lindenschmitt, Marcos Rates Crippa, Hans D. Schotten</dc:creator>
    </item>
    <item>
      <title>Sim2Field: End-to-End Development of AI RANs for 6G</title>
      <link>https://arxiv.org/abs/2509.23528</link>
      <description>arXiv:2509.23528v2 Announce Type: replace 
Abstract: Following state-of-the-art research results, which showed the potential for significant performance gains by applying AI/ML techniques in the cellular Radio Access Network (RAN), the wireless industry is now broadly pushing for the adoption of AI in 5G and future 6G technology. Despite this enthusiasm, AI-based wireless systems still remain largely untested in the field. Common simulation methods for generating datasets for AI model training suffer from "reality gap" and, as a result, the performance of these simulation-trained models may not carry over to practical cellular systems. Additionally, the cost and complexity of developing high-performance proof-of-concept implementations present major hurdles for evaluating AI wireless systems in the field. In this work, we introduce a methodology which aims to address the challenges of bringing AI to real networks. We discuss how detailed Digital Twin simulations may be employed for training site-specific AI Physical (PHY) layer functions. We further present a powerful testbed for AI-RAN research and demonstrate how it enables rapid prototyping, field testing and data collection. Finally, we evaluate an AI channel estimation algorithm over-the-air with a commercial UE, demonstrating that real-world throughput gains of up to 40% are achievable by incorporating AI in the physical layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23528v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Russell Ford, Hao Chen, Pranav Madadi, Mandar Kulkarni, Xiaochuan Ma, Daoud Burghal, Guanbo Chen, Yeqing Hu, Chance Tarver, Panagiotis Skrimponis, Vitali Loseu, Yu Zhang, Yan Xin, Yang Li, Jianzhong Zhang, Shubham Khunteta, Yeswanth Guddeti Reddy, Ashok Kumar Reddy Chavva, Mahantesh Kothiwale, Davide Villa</dc:creator>
    </item>
    <item>
      <title>Introducing Large Language Models into the Design Flow of Time Sensitive Networking</title>
      <link>https://arxiv.org/abs/2509.26368</link>
      <description>arXiv:2509.26368v2 Announce Type: replace 
Abstract: The growing demand for real-time, safety-critical systems has significantly increased both the adoption and complexity of Time Sensitive Networking (TSN). Configuring an optimized TSN network is highly challenging, requiring careful planning, design, verification, validation, and deployment. Large Language Models (LLMs) have recently demonstrated strong capabilities in solving complex tasks, positioning them as promising candidates for automating end-to-end TSN deployment, referred to as TSN orchestration. This paper outlines the steps involved in TSN orchestration and the associated challenges. To assess the capabilities of existing LLM models, we conduct an initial proof-of-concept case study focused on TSN configuration across multiple models. Building on these insights, we propose an LLM-assisted orchestration framework. Unlike prior research on LLMs in computer networks, which has concentrated on general configuration and management, TSN-specific orchestration has not yet been investigated. We present the building blocks for automating TSN using LLMs, describe the proposed pipeline, and analyze opportunities and limitations for real-world deployment. Finally, we highlight key challenges and research directions, including the development of TSN-focused datasets, standardized benchmark suites, and the integration of external tools such as Network Calculus (NC) engines and simulators. This work provides the first roadmap toward assessing the feasibility of LLM-assisted TSN orchestration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26368v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rubi Debnath, Luxi Zhao, Mohammadreza Barzegaran, Sebastian Steinhorst</dc:creator>
    </item>
  </channel>
</rss>
