<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Dec 2024 05:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Predicting Artificial Neural Network Representations to Learn Recognition Model for Music Identification from Brain Recordings</title>
      <link>https://arxiv.org/abs/2412.15560</link>
      <description>arXiv:2412.15560v1 Announce Type: new 
Abstract: Recent studies have demonstrated that the representations of artificial neural networks (ANNs) can exhibit notable similarities to cortical representations when subjected to identical auditory sensory inputs. In these studies, the ability to predict cortical representations is probed by regressing from ANN representations to cortical representations. Building upon this concept, our approach reverses the direction of prediction: we utilize ANN representations as a supervisory signal to train recognition models using noisy brain recordings obtained through non-invasive measurements. Specifically, we focus on constructing a recognition model for music identification, where electroencephalography (EEG) brain recordings collected during music listening serve as input. By training an EEG recognition model to predict ANN representations-representations associated with music identification-we observed a substantial improvement in classification accuracy. This study introduces a novel approach to developing recognition models for brain recordings in response to external auditory stimuli. It holds promise for advancing brain-computer interfaces (BCI), neural decoding techniques, and our understanding of music cognition. Furthermore, it provides new insights into the relationship between auditory brain activity and ANN representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15560v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Taketo Akama, Zhuohao Zhang, Pengcheng Li, Kotaro Hongo, Hiroaki Kitano, Shun Minamikawa, Natalia Polouliakh</dc:creator>
    </item>
    <item>
      <title>Synaptic plasticity alters the nature of chaos transition in neural networks</title>
      <link>https://arxiv.org/abs/2412.15592</link>
      <description>arXiv:2412.15592v1 Announce Type: new 
Abstract: In realistic neural circuits, both neurons and synapses are coupled in dynamics with separate time scales. The circuit functions are intimately related to these coupled dynamics. However, it remains challenging to understand the intrinsic properties of the coupled dynamics. Here, we develop the neuron-synapse coupled quasi-potential method to demonstrate how learning induces the qualitative change in macroscopic behaviors of recurrent neural networks. We find that under the Hebbian learning, a large Hebbian strength will alter the nature of the chaos transition, from a continuous type to a discontinuous type, where the onset of chaos requires a smaller synaptic gain compared to the non-plastic counterpart network. In addition, our theory predicts that under feedback and homeostatic learning, the location and type of chaos transition are retained, and only the chaotic fluctuation is adjusted. Our theoretical calculations are supported by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15592v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenkang Du, Haiping Huang</dc:creator>
    </item>
    <item>
      <title>Modeling Autonomous Shifts Between Focus State and Mind-Wandering Using a Predictive-Coding-Inspired Variational RNN Model</title>
      <link>https://arxiv.org/abs/2412.15620</link>
      <description>arXiv:2412.15620v1 Announce Type: new 
Abstract: The current study investigates possible neural mechanisms underling autonomous shifts between focus state and mind-wandering by conducting model simulation experiments. On this purpose, we modeled perception processes of continuous sensory sequences using our previous proposed variational RNN model which was developed based on the free energy principle. The current study extended this model by introducing an adaptation mechanism of a meta-level parameter, referred to as the meta-prior $\mathbf{w}$, which regulates the complexity term in the free energy. Our simulation experiments demonstrated that autonomous shifts between focused perception and mind-wandering take place when $\mathbf{w}$ switches between low and high values associated with decrease and increase of the average reconstruction error over the past window. In particular, high $\mathbf{w}$ prioritized top-down predictions while low $\mathbf{w}$ emphasized bottom-up sensations. This paper explores how our experiment results align with existing studies and highlights their potential for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15620v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrique Oyama, Jun Tani</dc:creator>
    </item>
    <item>
      <title>Does the brain behave like a (complex) network? I. Dynamics</title>
      <link>https://arxiv.org/abs/2412.15711</link>
      <description>arXiv:2412.15711v1 Announce Type: new 
Abstract: Graph theory is now becoming a standard tool in system-level neuroscience. However, endowing observed brain anatomy and dynamics with a complex network structure does not entail that the brain actually works as a network. Asking whether the brain behaves as a network means asking whether network properties count. From the viewpoint of neurophysiology and, possibly, of brain physics, the most substantial issues a network structure may be instrumental in addressing relate to the influence of network properties on brain dynamics and to whether these properties ultimately explain some aspects of brain function. Here, we address the dynamical implications of complex network, examining which aspects and scales of brain activity may be understood to genuinely behave as a network. To do so, we first define the meaning of networkness, and analyse some of its implications. We then examine ways in which brain anatomy and dynamics can be endowed with a network structure and discuss possible ways in which network structure may be shown to represent a genuine organisational principle of brain activity, rather than just a convenient description of its anatomy and dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15711v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.plrev.2023.12.006</arxiv:DOI>
      <arxiv:journal_reference>Physics of Life Reviews 48 (2024) 47-98</arxiv:journal_reference>
      <dc:creator>D. Papo, J. M. Buld\'u</dc:creator>
    </item>
    <item>
      <title>How connection probability shapes fluctuations of neural population dynamics</title>
      <link>https://arxiv.org/abs/2412.16111</link>
      <description>arXiv:2412.16111v1 Announce Type: new 
Abstract: Mean-field models of neuronal populations in the brain have proven extremely useful to understand network dynamics and response to stimuli, but these models generally lack a faithful description of the fluctuations in the biologically relevant case of finite network size and connection probabilities $p&lt;1$ (non-full connectivity). To gain insight into the different fluctuation mechanisms underlying the neural variability of populations of spiking neurons, we derive and analyze a stochastic mean-field model for finite-size networks of Poisson neurons with random, non-full connectivity, external noise and disordered mean inputs. We treat the quenched disorder of the connectivity by an annealed approximation that enables a reduction to a low-dimensional closed system of coupled Langevin equations for the mean and variance of the neuronal membrane potentials as well as a variable capturing finite-size fluctuations arising specifically in the case $p&lt;1$. Comparing to microscopic simulations, we find that the mesoscopic model describes the fluctuations and nonlinearities well and outperforms previous mesoscopic models that neglected the recurrent noise effect caused by the non-full connectivity. This effect can be analytically understood by a softening of the effective nonlinearity and the multiplicative character of finite-size spiking noise. The mesoscopic theory shows that quenched disorder can stabilize the asynchronous state, and it correctly predicts large quantitiative and non-trivial qualitative effects of connection probability on the variance of the population firing rate and its dependence on stimulus strength. Our theory thus elucidates how disordered connectivity shapes nonlinear dynamics and fluctuations of neural populations at the mesoscopic scale and showcases a useful mean-field method to treat non-full connectivity in finite-size, spiking neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16111v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nils E. Greven, Jonas Ranft, Tilo Schwalger</dc:creator>
    </item>
    <item>
      <title>Functional connectomes of neural networks</title>
      <link>https://arxiv.org/abs/2412.15279</link>
      <description>arXiv:2412.15279v1 Announce Type: cross 
Abstract: The human brain is a complex system, and understanding its mechanisms has been a long-standing challenge in neuroscience. The study of the functional connectome, which maps the functional connections between different brain regions, has provided valuable insights through various advanced analysis techniques developed over the years. Similarly, neural networks, inspired by the brain's architecture, have achieved notable success in diverse applications but are often noted for their lack of interpretability. In this paper, we propose a novel approach that bridges neural networks and human brain functions by leveraging brain-inspired techniques. Our approach, grounded in the insights from the functional connectome, offers scalable ways to characterize topology of large neural networks using stable statistical and machine learning techniques. Our empirical analysis demonstrates its capability to enhance the interpretability of neural networks, providing a deeper understanding of their underlying mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15279v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tananun Songdechakraiwut, Yutong Wu</dc:creator>
    </item>
    <item>
      <title>Precision ICU Resource Planning: A Multimodal Model for Brain Surgery Outcomes</title>
      <link>https://arxiv.org/abs/2412.15818</link>
      <description>arXiv:2412.15818v1 Announce Type: cross 
Abstract: Although advances in brain surgery techniques have led to fewer postoperative complications requiring Intensive Care Unit (ICU) monitoring, the routine transfer of patients to the ICU remains the clinical standard, despite its high cost. Predictive Gradient Boosted Trees based on clinical data have attempted to optimize ICU admission by identifying key risk factors pre-operatively; however, these approaches overlook valuable imaging data that could enhance prediction accuracy. In this work, we show that multimodal approaches that combine clinical data with imaging data outperform the current clinical data only baseline from 0.29 [F1] to 0.30 [F1], when only pre-operative clinical data is used and from 0.37 [F1] to 0.41 [F1], for pre- and post-operative data. This study demonstrates that effective ICU admission prediction benefits from multimodal data fusion, especially in contexts of severe class imbalance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15818v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maximilian Fischer, Florian M. Hauptmann, Robin Peretzke, Paul Naser, Peter Neher, Jan-Oliver Neumann, Klaus Maier-Hein</dc:creator>
    </item>
    <item>
      <title>Learning Cortico-Muscular Dependence through Orthonormal Decomposition of Density Ratios</title>
      <link>https://arxiv.org/abs/2410.14697</link>
      <description>arXiv:2410.14697v2 Announce Type: replace 
Abstract: The cortico-spinal neural pathway is fundamental for motor control and movement execution, and in humans it is typically studied using concurrent electroencephalography (EEG) and electromyography (EMG) recordings. However, current approaches for capturing high-level and contextual connectivity between these recordings have important limitations. Here, we present a novel application of statistical dependence estimators based on orthonormal decomposition of density ratios to model the relationship between cortical and muscle oscillations. Our method extends from traditional scalar-valued measures by learning eigenvalues, eigenfunctions, and projection spaces of density ratios from realizations of the signal, addressing the interpretability, scalability, and local temporal dependence of cortico-muscular connectivity. We experimentally demonstrate that eigenfunctions learned from cortico-muscular connectivity can accurately classify movements and subjects. Moreover, they reveal channel and temporal dependencies that confirm the activation of specific EEG channels during movement. Our code is available at https://github.com/bohu615/corticomuscular-eigen-encoder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14697v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shihan Ma, Bo Hu, Tianyu Jia, Alexander Kenneth Clarke, Blanka Zicher, Arnault H. Caillet, Dario Farina, Jose C. Principe</dc:creator>
    </item>
    <item>
      <title>A Differentiable Model for Optimizing the Genetic Drivers of Synaptogenesis</title>
      <link>https://arxiv.org/abs/2402.07242</link>
      <description>arXiv:2402.07242v2 Announce Type: replace-cross 
Abstract: There is a growing consensus among neuroscientists that many neural circuits critical for survival result from a process of genomic decompression, hence are constructed based on the information contained within the genome. Aligning with this perspective, we introduce SynaptoGen, a novel computational framework designed to bring the advent of synthetic biological intelligence closer, facilitating the development of neural biological agents through the precise control of genetic factors governing synaptogenesis. SynaptoGen represents the first model in the well-established family of Connectome Models (CMs) to offer a possible mechanistic explanation of synaptic multiplicity based on genetic expression and protein interaction probabilities, modeling connectivity with unprecedented granularity. Furthermore, SynaptoGen connects these genetic factors through a differentiable function, effectively working as a neural network in which each synaptic weight is computed as the average number of synapses between neurons, multiplied by its corresponding conductance, and derived from a specific genetic profile. Differentiability is a critical feature of the framework, enabling its integration with gradient-based optimization techniques. This allows SynaptoGen to generate patterns of genetic expression and/or genetic rules capable of producing pre-wired biological agents tailored to specific tasks. The framework is validated in simulated synaptogenesis scenarios with varying degrees of biological plausibility. It successfully produces biological agents capable of solving tasks in four different reinforcement learning benchmarks, consistently outperforming the state-of-the-art and a control baseline designed to represent populations of neurons where synapses form freely, i.e., without guided manipulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07242v2</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tommaso Boccato, Matteo Ferrante, Nicola Toschi</dc:creator>
    </item>
  </channel>
</rss>
