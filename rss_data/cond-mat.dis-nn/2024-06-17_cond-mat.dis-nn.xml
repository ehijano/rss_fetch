<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2024 02:47:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Physical networks become what they learn</title>
      <link>https://arxiv.org/abs/2406.09689</link>
      <description>arXiv:2406.09689v1 Announce Type: new 
Abstract: Physical networks can develop diverse responses, or functions, by design, evolution or learning. We focus on electrical networks of nodes connected by resistive edges. Such networks can learn by adapting edge conductances to lower a cost function that penalizes deviations from a desired response. The network must also satisfy Kirchhoff's law, balancing currents at nodes, or, equivalently, minimizing total power dissipation by adjusting node voltages. The adaptation is thus a double optimization process, in which a cost function is minimized with respect to conductances, while dissipated power is minimized with respect to node voltages. Here we study how this physical adaptation couples the cost landscape, the landscape of the cost function in the high-dimensional space of edge conductances, to the physical landscape, the dissipated power in the high-dimensional space of node voltages. We show how adaptation links the physical and cost Hessian matrices, suggesting that the physical response of networks to perturbations holds significant information about the functions to which they are adapted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09689v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Menachem Stern, Marcelo Guzman, Felipe Martins, Andrea J Liu, Vijay Balasubramanian</dc:creator>
    </item>
    <item>
      <title>Fundamental operating regimes, hyper-parameter fine-tuning and glassiness: towards an interpretable replica-theory for trained restricted Boltzmann machines</title>
      <link>https://arxiv.org/abs/2406.09924</link>
      <description>arXiv:2406.09924v1 Announce Type: new 
Abstract: We consider restricted Boltzmann machines with a binary visible layer and a Gaussian hidden layer trained by an unlabelled dataset composed of noisy realizations of a single ground pattern. We develop a statistical mechanics framework to describe the network generative capabilities, by exploiting the replica trick and assuming self-averaging of the underlying order parameters (i.e., replica symmetry). In particular, we outline the effective control parameters (e.g., the relative number of weights to be trained, the regularization parameter), whose tuning can yield qualitatively-different operative regimes. Further, we provide analytical and numerical evidence for the existence of a sub-region in the space of the hyperparameters where replica-symmetry breaking occurs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09924v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Fachechi, Elena Agliari, Miriam Aquaro, Anthony Coolen, Menno Mulder</dc:creator>
    </item>
    <item>
      <title>Spectral and Entanglement Properties of the Random Exchange Heisenberg Chain</title>
      <link>https://arxiv.org/abs/2406.09985</link>
      <description>arXiv:2406.09985v1 Announce Type: new 
Abstract: We study the many-body localization problem in the non-abelian SU(2)-invariant random anti-ferromagnetic exchange model in 1D. Exact and sparse matrix diagonalization methods are used to calculate eigenvalues and eigenvectors of the Hamiltonian matrix. We investigate the behaviour of the energy level gap-ratio statistic, participation ratio, entanglement entropy and the entanglement spectral parameter as a function of disorder strengths. Different distributions of random couplings are considered. We find, up to L = 18, a clear distinction between our non-abelian model and the more often studied random field Heisenberg model: the regime of seemingly localized behaviour is much less pronounced in the random exchange model than in the field model case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09985v1</guid>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilun Gao, Rudolf A. R\"omer</dc:creator>
    </item>
    <item>
      <title>Universal scaling of Green's functions in disordered non-Hermitian systems</title>
      <link>https://arxiv.org/abs/2406.09502</link>
      <description>arXiv:2406.09502v1 Announce Type: cross 
Abstract: The competition between non-Hermitian skin effect and Anderson localization leads to various intriguing phenomena concerning spectrums and wavefunctions. Here, we study the linear response of disordered non-Hermitian systems, which is precisely described by the Green's function. We find that the average maximum value of matrix elements of Green's functions, which quantifies the maximum response against an external perturbation, exhibits different phases characterized by different scaling behaviors with respect to the system size. Whereas the exponential-growth phase is also seen in the translation-invariant systems, the algebraic-growth phase is unique to disordered non-Hermitian systems. We explain the findings using the large deviation theory, which provides analytical insights into the algebraic scaling factors of non-Hermitian disordered Green's functions. Furthermore, we show that these scaling behaviors can be observed in the steady states of disordered open quantum systems, offering a quantum-mechanical avenue for their experimental detection. Our work highlights an unexpected interplay between non-Hermitian skin effect and Anderson localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09502v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.optics</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin-Quan Huang, Yu-Min Hu, Wen-Tan Xue, Zhong Wang</dc:creator>
    </item>
    <item>
      <title>Characterizing out-of-distribution generalization of neural networks: application to the disordered Su-Schrieffer-Heeger model</title>
      <link>https://arxiv.org/abs/2406.10012</link>
      <description>arXiv:2406.10012v1 Announce Type: cross 
Abstract: Machine learning (ML) is a promising tool for the detection of phases of matter. However, ML models are also known for their black-box construction, which hinders understanding of what they learn from the data and makes their application to novel data risky. Moreover, the central challenge of ML is to ensure its good generalization abilities, i.e., good performance on data outside the training set. Here, we show how the informed use of an interpretability method called class activation mapping (CAM), and the analysis of the latent representation of the data with the principal component analysis (PCA) can increase trust in predictions of a neural network (NN) trained to classify quantum phases. In particular, we show that we can ensure better out-of-distribution generalization in the complex classification problem by choosing such an NN that, in the simplified version of the problem, learns a known characteristic of the phase. We show this on an example of the topological Su-Schrieffer-Heeger (SSH) model with and without disorder, which turned out to be surprisingly challenging for NNs trained in a supervised way. This work is an example of how the systematic use of interpretability methods can improve the performance of NNs in scientific problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10012v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kacper Cybi\'nski, Marcin P{\l}odzie\'n, Micha{\l} Tomza, Maciej Lewenstein, Alexandre Dauphin, Anna Dawid</dc:creator>
    </item>
    <item>
      <title>Generative random latent features models and statistics of natural images</title>
      <link>https://arxiv.org/abs/2212.02987</link>
      <description>arXiv:2212.02987v2 Announce Type: replace 
Abstract: Complex, multivariable systems are often analyzed by grouping their constituent units into components, sometimes referred to as latent features, which afford physical or biological interpretation. However, a priori many different types of latent features and data decompositions can be defined, and one typically uses a trial and error approach to determine a decomposition that is natural to the system and its data. It is highly desirable to develop principled understanding of which decomposition is appropriate for given a data set. In this work, we take a step in this direction and argue that sample-sample correlations in the data carry important information to this effect. For this we construct a generative random latent feature matrix model of large data based on linear mixing of latent features. Key ingredient of our model is that we allow for statistical dependence between the mixing coefficients and argue that the model captures characteristic properties found in many types of natural data. Latent dimensionality and correlation patterns of the data are controlled by only two model parameters. The model's data patterns include (overlapping) clusters, sparse mixing, and constrained (non-negative) mixing. We describe the characteristic correlation and eigenvalue distributions of each pattern. Finally, we fit the model on correlation data from natural images and find a near perfect match with the sparse mixing regime of our model. This finding is in line with the well-known sparse coding structure in natural scene images and provides information about the appropriate data decomposition, namely a sparse coding scheme. We believe that our work will deliver similar insights for diverse data of biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02987v2</guid>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Fleig, Ilya Nemenman</dc:creator>
    </item>
    <item>
      <title>Non-Hermitian Aubry-Andr\'e-Harper model with short- and long-range p-wave pairing</title>
      <link>https://arxiv.org/abs/2311.04605</link>
      <description>arXiv:2311.04605v2 Announce Type: replace 
Abstract: We investigate a non-Hermitian Aubry-Andr\'e-Harper model with short-range, as well as long-range p-wave pairing. Here, the non-Hermiticity is introduced through the onsite potential. A comprehensive analysis of several critical aspects of this system is conducted, which includes eigenspectra, topological properties, localization properties, and the transition from real to complex energies. Specifically, we observe the emergence of Majorana zero modes in the case of short-range pairing, whereas massive Dirac modes emerge in the case of long-range pairing. More importantly, for the case of short-range pairing, we observe two simultaneous phase transitions or double phase transitions: topological and multifractal to localized phase. On the other hand, in the case of the long-range pairing, the topological and multifractal to localized transitions do not coincide. However, for both ranges of pairing, we identify a double phase transition where delocalized (or metallic) to a critical multifractal state is accompanied by an unconventional shift from real to complex energies. Unlike the short-range pairing case, we observe mobility edges in the long-range pairing case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04605v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.other</category>
      <category>cond-mat.supr-con</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaina Gandhi, Jayendra N. Bandyopadhyay</dc:creator>
    </item>
    <item>
      <title>Physics-informed neural networks for solving functional renormalization group on a lattice</title>
      <link>https://arxiv.org/abs/2312.16038</link>
      <description>arXiv:2312.16038v3 Announce Type: replace 
Abstract: Addressing high-dimensional partial differential equations to derive effective actions within the functional renormalization group is formidable, especially when considering various field configurations, including inhomogeneous states, even on lattices. We leverage physics-informed neural networks (PINNs) as a state-of-the-art machine learning method for solving high-dimensional partial differential equations to overcome this challenge. In a zero-dimensional O($N$) model, we numerically demonstrate the construction of an effective action on an $N$-dimensional configuration space, extending up to $N=100$. Our results underscore the effectiveness of PINN approximation, even in scenarios lacking small parameters such as a small coupling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16038v3</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.str-el</category>
      <category>hep-lat</category>
      <category>hep-th</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takeru Yokota</dc:creator>
    </item>
    <item>
      <title>The Problem Of Image Super-Resolution, Denoising And Some Image Restoration Methods In Deep Learning Models</title>
      <link>https://arxiv.org/abs/2404.09817</link>
      <description>arXiv:2404.09817v3 Announce Type: replace 
Abstract: In this article, we address the challenges of image super-resolution and noise reduction, which are crucial for enhancing the quality of images derived from low-resolution or noisy data. We compared and assessed several approaches for upgrading low-resolution images to higher resolutions and for eliminating unwanted noise, all while maintaining the essential characteristics of the original images and recovering images from poor quality or damaged data using deep learning models. Our analysis and the experimental outcomes on image quality metrics indicate that the EDCNN neural network model, enhanced with pretrained weights, significantly outperforms other methods with a Train PSNR of 31.215, a Valid PSNR of 29.493, and a Test PSNR of 31.6632.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09817v3</guid>
      <category>cond-mat.dis-nn</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ngoc-Giau Pham, Thanh-Hai Tong Le, Van-Hieu Duong, Hong-Ngoc Tran, Phuoc-Hung Vo</dc:creator>
    </item>
    <item>
      <title>Initial Guessing Bias: How Untrained Networks Favor Some Classes</title>
      <link>https://arxiv.org/abs/2306.00809</link>
      <description>arXiv:2306.00809v4 Announce Type: replace-cross 
Abstract: Understanding and controlling biasing effects in neural networks is crucial for ensuring accurate and fair model performance. In the context of classification problems, we provide a theoretical analysis demonstrating that the structure of a deep neural network (DNN) can condition the model to assign all predictions to the same class, even before the beginning of training, and in the absence of explicit biases. We prove that, besides dataset properties, the presence of this phenomenon, which we call \textit{Initial Guessing Bias} (IGB), is influenced by model choices including dataset preprocessing methods, and architectural decisions, such as activation functions, max-pooling layers, and network depth. Our analysis of IGB provides information for architecture selection and model initialization. We also highlight theoretical consequences, such as the breakdown of node-permutation symmetry, the violation of self-averaging and the non-trivial effects that depth has on the phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.00809v4</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuele Francazi, Aurelien Lucchi, Marco Baity-Jesi</dc:creator>
    </item>
    <item>
      <title>Entanglement Structure and Information Protection in Noisy Hybrid Quantum Circuits</title>
      <link>https://arxiv.org/abs/2401.01593</link>
      <description>arXiv:2401.01593v2 Announce Type: replace-cross 
Abstract: In the context of measurement-induced entanglement phase transitions, the influence of quantum noises, which are inherent in real physical systems, is of great importance and experimental relevance. In this Letter, we present a comprehensive theoretical analysis of the effects of both temporally uncorrelated and correlated quantum noises on entanglement generation and information protection. This investigation reveals that entanglement within the system follows $q^{-1/3}$ scaling for both types of quantum noises, where $q$ represents the noise probability. The scaling arises from the Kardar-Parisi-Zhang fluctuation with effective length scale $L_{\text{eff}} \sim q^{-1}$. More importantly, the information protection timescales of the steady states are explored and shown to follow $q^{-1/2}$ and $q^{-2/3}$ scaling for temporally uncorrelated and correlated noises, respectively. The former scaling can be interpreted as a Hayden-Preskill protocol, while the latter is a direct consequence of Kardar-Parisi-Zhang fluctuations. We conduct extensive numerical simulations using stabilizer formalism to support the theoretical understanding. This Letter not only contributes to a deeper understanding of the interplay between quantum noises and measurement-induced phase transition but also provides a new perspective to understand the effects of Markovian and non-Markovian noises on quantum computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01593v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.132.240402</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 132, 240402 (2024)</arxiv:journal_reference>
      <dc:creator>Shuo Liu, Ming-Rui Li, Shi-Xin Zhang, Shao-Kai Jian</dc:creator>
    </item>
    <item>
      <title>Dual-Unitary Classical Shadow Tomography</title>
      <link>https://arxiv.org/abs/2404.01068</link>
      <description>arXiv:2404.01068v2 Announce Type: replace-cross 
Abstract: We introduce a classical shadow tomography scheme based on dual-unitary brick-wall circuits termed "dual-unitary shadow tomography" (DUST). For this we study operator spreading and Pauli weight dynamics in one-dimensional qubit systems, evolved by random two-local dual-unitary gates arranged in a brick-wall structure, ending with a final measurement layer. We do this by deriving general constraints on the Pauli weight transfer matrix and specializing to the case of dual-unitarity. We first show that dual-unitaries must have a minimal amount of entropy production. Remarkably, we find that operator spreading in these circuits have a rich structure resembling that of relativistic quantum field theories, with massless chiral excitations that can decay or fuse into each other, which we call left- or right-movers. We develop a mean-field description of the Pauli weight in terms of $\rho(x,t)$, which represents the probability of having nontrivial support at site $x$ and depth $t$ starting from a fixed weight distribution. We develop an equation of state for $\rho(x,t)$, and simulate it numerically using Monte Carlo simulations. Lastly, we demonstrate that the fast-thermalizing properties of dual-unitary circuits make them better at predicting large operators than shallow brick-wall Clifford circuits. Our results are robust to finite-size effects due to the chirality of dual-unitary brick-wall circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01068v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Akhtar, Namit Anand, Jeffrey Marshall, Yi-Zhuang You</dc:creator>
    </item>
    <item>
      <title>Efficient Structure-Informed Featurization and Property Prediction of Ordered, Dilute, and Random Atomic Structures</title>
      <link>https://arxiv.org/abs/2404.02849</link>
      <description>arXiv:2404.02849v2 Announce Type: replace-cross 
Abstract: Structure-informed materials informatics is a rapidly evolving discipline of materials science relying on the featurization of atomic structures or configurations to construct vector, voxel, graph, graphlet, and other representations useful for machine learning prediction of properties, fingerprinting, and generative design. This work discusses how current featurizers typically perform redundant calculations and how their efficiency could be improved by considering (1) fundamentals of crystallographic (orbits) equivalency to optimize ordered cases and (2) representation-dependent equivalency to optimize cases of dilute, doped, and defect structures with broken symmetry. It also discusses and contrasts ways of (3) approximating random solid solutions occupying arbitrary lattices under such representations. Efficiency improvements discussed in this work were implemented within pySIPFENN or python toolset for Structure-Informed Property and Feature Engineering with Neural Networks developed by authors since 2019 and shown to increase performance from 2 to 10 times for typical inputs. Throughout this work, the authors explicitly discuss how these advances can be applied to different kinds of similar tools in the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02849v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam M. Krajewski, Jonathan W. Siegel, Zi-Kui Liu</dc:creator>
    </item>
    <item>
      <title>Localized dopant motion across the 2D Ising phase transition</title>
      <link>https://arxiv.org/abs/2404.11608</link>
      <description>arXiv:2404.11608v2 Announce Type: replace-cross 
Abstract: I investigate the motion of a single hole in 2D spin lattices with square and triangular geometries. While the spins have nearest neighbor Ising spin couplings $J$, the hole is allowed to move only in 1D along a single line in the 2D lattice with nearest neighbor hopping amplitude $t$. The non-equilibrium hole dynamics is initialized by suddenly removing a single spin from the thermal Ising spin lattice. I find that for any nonzero spin coupling and temperature, the hole is localized. This is an extension of the thermally induced localization phenomenon [arXiv:2310.11193] to the case, where there is a phase transition to a long-range ordered ferromagnetic phase. The dynamics depends only on the ratio of the temperature to the spin coupling, $k_BT / |J|$, and on the ratio of the spin coupling to the hopping $J/t$. I characterize these dependencies in great detail. In particular, I find universal behavior at high temperatures, common features for the square and triangular lattices across the Curie temperatures for ferromagnetic interactions, and highly distinct behaviors for the two geometries in the presence of antiferromagnetic interactions due geometric frustration in the triangular lattice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11608v2</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.quant-gas</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Knakkergaard Nielsen</dc:creator>
    </item>
  </channel>
</rss>
