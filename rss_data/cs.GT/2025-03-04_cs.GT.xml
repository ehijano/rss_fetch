<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Mar 2025 05:01:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Equilibrium and Selfish Behavior in Network Contagion</title>
      <link>https://arxiv.org/abs/2503.00078</link>
      <description>arXiv:2503.00078v1 Announce Type: new 
Abstract: In this paper we consider non-atomic games in populations that are provided with a choice of preventive policies to act against a contagion spreading amongst interacting populations, be it biological organisms or connected computing devices. The spreading model of the contagion is the standard SIR model. Each participant of the population has a choice from amongst a set of precautionary policies with each policy presenting a payoff or utility, which we assume is the same within each group, the risk being the possibility of infection. The policy groups interact with each other. We also define a network model to model interactions between different population sets. The population sets reside at nodes of the network and follow policies available at that node. We define game-theoretic models and study the inefficiency of allowing for individual decision making, as opposed to centralized control. We study the computational aspects as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00078v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Sanjiv Kapoor</dc:creator>
    </item>
    <item>
      <title>Elastic Restaking Networks</title>
      <link>https://arxiv.org/abs/2503.00170</link>
      <description>arXiv:2503.00170v1 Announce Type: new 
Abstract: Decentralized services for blockchains often require their validators (operators) to deposit stake (collateral), which is forfeited (slashed) if they misbehave. Restaking networks let validators secure multiple services by reusing stake, giving rise to a strategic game: Validators can coordinate to misbehave across multiple services, extracting digital assets while forfeiting their stake only once.
  Previous work focused either on preventing coordinated misbehavior or on protecting services if all other services are Byzantine and might unjustly cause slashing due to bugs or malice. The first model overlooks how a single Byzantine service can collapse the network, while the second ignores shared-stake benefits.
  To bridge the gap, we model the strategic game of coordinated misbehavior when a given fraction of services are Byzantine. We introduce elastic restaking networks, where validators can allocate portions of their stake that may cumulatively exceed their total stake, and when allocations are lost, the remaining stake stretches to cover remaining allocations. We show that elastic networks exhibit superior robustness compared to previous approaches, and demonstrate a synergistic effect where an elastic restaking network enhances its blockchain's security, contrary to community concerns of an opposite effect in existing networks. We then design incentives for tuning validators' allocations.
  Our elastic restaking system and incentive design have immediate practical implications for deployed restaking networks, which have billions of dollars in stake.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00170v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roi Bar-Zur, Ittay Eyal</dc:creator>
    </item>
    <item>
      <title>The Learning Approach to Games</title>
      <link>https://arxiv.org/abs/2503.00227</link>
      <description>arXiv:2503.00227v1 Announce Type: new 
Abstract: This work provides a unified framework for exploring games. In existing literature, strategies of players are typically assigned scalar values, and the concept of Nash equilibrium is used to identify compatible strategies. However, this approach lacks the internal structure of a player, thereby failing to accurately model observed behaviors in reality. To address this limitation, we propose to characterize players by their learning algorithms, and as their estimations intrinsically induce a distribution over strategies, we introduced the notion of equilibrium in terms of characterizing the recurrent behaviors of the learning algorithms. This approach allows for a more nuanced understanding of players, and brings the focus to the challenge of learning that players face. While our explorations in discrete games, mean-field games, and reinforcement learning demonstrate the framework's broad applicability, they also set the stage for future research aimed at specific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00227v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melih \.I\c{s}eri, Erhan Bayraktar</dc:creator>
    </item>
    <item>
      <title>Taming Infinity one Chunk at a Time: Concisely Represented Strategies in One-Counter MDPs</title>
      <link>https://arxiv.org/abs/2503.00788</link>
      <description>arXiv:2503.00788v1 Announce Type: new 
Abstract: Markov decision processes (MDPs) are a canonical model to reason about decision making within a stochastic environment. We study a fundamental class of infinite MDPs: one-counter MDPs (OC-MDPs). They extend finite MDPs via an associated counter taking natural values, thus inducing an infinite MDP over the set of configurations (current state and counter value). We consider two characteristic objectives: reaching a target state (state-reachability), and reaching a target state with counter value zero (selective termination). The synthesis problem for the latter is not known to be decidable and connected to major open problems in number theory. Furthermore, even seemingly simple strategies (e.g., memoryless ones) in OC-MDPs might be impossible to build in practice (due to the underlying infinite configuration space): we need finite, and preferably small, representations.
  To overcome these obstacles, we introduce two natural classes of concisely represented strategies based on a (possibly infinite) partition of counter values in intervals. For both classes, and both objectives, we study the verification problem (does a given strategy ensure a high enough probability for the objective?), and two synthesis problems (does there exist such a strategy?): one where the interval partition is fixed as input, and one where it is only parameterized. We develop a generic approach based on a compression of the induced infinite MDP that yields decidability in all cases, with all complexities within PSPACE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00788v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michal Ajdar\'ow, James C. A. Main, Petr Novotn\'y, Mickael Randour</dc:creator>
    </item>
    <item>
      <title>Social Welfare Maximization in Approval-Based Committee Voting under Uncertainty</title>
      <link>https://arxiv.org/abs/2503.00885</link>
      <description>arXiv:2503.00885v1 Announce Type: new 
Abstract: Approval voting is widely used for making multi-winner voting decisions. The canonical rule (also called Approval Voting) used in the setting aims to maximize social welfare by selecting candidates with the highest number of approvals. We revisit approval-based multi-winner voting in scenarios where the information regarding the voters' preferences is uncertain. We present several algorithmic results for problems related to social welfare maximization under uncertainty, including computing an outcome that is social welfare maximizing with the highest probability, computing the social welfare probability distribution of a given outcome, computing the probability that a given outcome is social welfare maximizing, and understanding how robust an outcome is with respect to social welfare maximizing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00885v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haris Aziz, Yuhang Guo, Venkateswara Rao Kagita, Baharak Rastegari, Mashbat Suzuki</dc:creator>
    </item>
    <item>
      <title>The Complexity of Extending Fair Allocations of Indivisible Goods</title>
      <link>https://arxiv.org/abs/2503.01368</link>
      <description>arXiv:2503.01368v1 Announce Type: new 
Abstract: We initiate the study of computing envy-free allocations of indivisible items in the extension setting, i.e., when some part of the allocation is fixed and the task is to allocate the remaining items. Given the known NP-hardness of the problem, we investigate whether -- and under which conditions -- one can obtain fixed-parameter algorithms for computing a solution in settings where most of the allocation is already fixed. Our results provide a broad complexity-theoretic classification of the problem which includes: (a) fixed-parameter algorithms tailored to settings with few distinct types of agents or items; (b) lower bounds which exclude the generalization of these positive results to more general settings. We conclude by showing that -- unlike when computing allocations from scratch -- the non-algorithmic question of whether more relaxed EFX allocations exist can be completely resolved in the extension setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01368v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Eduard Eiben, Robert Ganian, Tiger-Lily Goldsmith, Stavros D. Ioannidis</dc:creator>
    </item>
    <item>
      <title>Online Two-Sided Markets: Many Buyers Enhance Learning</title>
      <link>https://arxiv.org/abs/2503.01529</link>
      <description>arXiv:2503.01529v1 Announce Type: new 
Abstract: We study a repeated trading problem in which a mechanism designer facilitates trade between a single seller and multiple buyers. Our model generalizes the classic bilateral trade setting to a multi-buyer environment. Specifically, the mechanism designer runs a second-price auction among the buyers -- extending the fixed-price mechanism used in bilateral trade -- before proposing a price to the seller. While this setting introduces new challenges compared to bilateral trade, it also provides an informational advantage. Indeed, the presence of multiple buyers enhances competition, inducing them to reveal their valuations in order to win the auction. However, as in bilateral trade, the seller faces a binary decision: whether to accept the proposed price or not. We show that this asymmetric feedback, which is more informative than in bilateral trade, allows us to break some lower bounds on regret minimization with a single buyer. In particular, we provide a $\tilde O(T^{2/3})$ regret upper bound with respect to an optimal strong budget-balanced mechanism, without any assumptions on the distribution of valuations. Our main tool for achieving this result is the design of an adaptive grid that approximates the optimal gain from trade across the continuum of possible mechanisms. Furthermore, we attain the same regret bound with respect to an optimal global budget-balanced mechanism, under two possible conditions: (i) buyers' and seller's valuations are independent, or (ii) valuations are drawn from a distribution with bounded density. In doing so, we provide some novel technical results on constrained MABs with feedback graphs, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01529v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Lunghi, Matteo Castiglioni, Alberto Marchesi</dc:creator>
    </item>
    <item>
      <title>Regret Minimization for Piecewise Linear Rewards: Contracts, Auctions, and Beyond</title>
      <link>https://arxiv.org/abs/2503.01701</link>
      <description>arXiv:2503.01701v1 Announce Type: new 
Abstract: Most microeconomic models of interest involve optimizing a piecewise linear function. These include contract design in hidden-action principal-agent problems, selling an item in posted-price auctions, and bidding in first-price auctions. When the relevant model parameters are unknown and determined by some (unknown) probability distributions, the problem becomes learning how to optimize an unknown and stochastic piecewise linear reward function. Such a problem is usually framed within an online learning framework, where the decision-maker (learner) seeks to minimize the regret of not knowing an optimal decision in hindsight. This paper introduces a general online learning framework that offers a unified approach to tackle regret minimization for piecewise linear rewards, under a suitable monotonicity assumption commonly satisfied by microeconomic models. We design a learning algorithm that attains a regret of $\widetilde{O}(\sqrt{nT})$, where $n$ is the number of ``pieces'' of the reward function and $T$ is the number of rounds. This result is tight when $n$ is \emph{small} relative to $T$, specifically when $n \leq T^{1/3}$. Our algorithm solves two open problems in the literature on learning in microeconomic settings. First, it shows that the $\widetilde{O}(T^{2/3})$ regret bound obtained by Zhu et al. [Zhu+23] for learning optimal linear contracts in hidden-action principal-agent problems is not tight when the number of agent's actions is small relative to $T$. Second, our algorithm demonstrates that, in the problem of learning to set prices in posted-price auctions, it is possible to attain suitable (and desirable) instance-independent regret bounds, addressing an open problem posed by Cesa-Bianchi et al. [CBCP19].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01701v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Bacchiocchi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti</dc:creator>
    </item>
    <item>
      <title>Communication and Control Co-design in Non-cooperative Games</title>
      <link>https://arxiv.org/abs/2503.00313</link>
      <description>arXiv:2503.00313v1 Announce Type: cross 
Abstract: In this article, we revisit a communication-control co-design problem for a class of two-player stochastic differential games on an infinite horizon. Each 'player' represents two active decision makers, namely a scheduler and a remote controller, which cooperate to optimize over a global objective while competing with the other player. Each player's scheduler can only intermittently relay state information to its respective controller due to associated cost/constraint to communication. The scheduler's policy determines the information structure at the controller, thereby affecting the quality of the control inputs. Consequently, it leads to the classical communication-control trade-off problem. A high communication frequency improves the control performance of the player on account of a higher communication cost, and vice versa. Under suitable information structures of the players, we first compute the Nash controller policies for both players in terms of the conditional estimate of the state. Consequently, we reformulate the problem of computing Nash scheduler policies (within a class of parametrized randomized policies) into solving for the steady-state solution of a generalized Sylvester equation. Since the above-mentioned reformulation involves infinite sum of powers of the policy parameters, we provide a projected gradient descent-based algorithm to numerically compute a Nash equilibrium using a truncated polynomial approximation. Finally, we demonstrate the performance of the Nash control and scheduler policies using extensive numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00313v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Aggarwal, Tamer Ba\c{s}ar, Dipankar Maity</dc:creator>
    </item>
    <item>
      <title>Policy Design in Long-Run Welfare Dynamics</title>
      <link>https://arxiv.org/abs/2503.00632</link>
      <description>arXiv:2503.00632v1 Announce Type: cross 
Abstract: Improving social welfare is a complex challenge requiring policymakers to optimize objectives across multiple time horizons. Evaluating the impact of such policies presents a fundamental challenge, as those that appear suboptimal in the short run may yield significant long-term benefits. We tackle this challenge by analyzing the long-term dynamics of two prominent policy frameworks: Rawlsian policies, which prioritize those with the greatest need, and utilitarian policies, which maximize immediate welfare gains. Conventional wisdom suggests these policies are at odds, as Rawlsian policies are assumed to come at the cost of reducing the average social welfare, which their utilitarian counterparts directly optimize. We challenge this assumption by analyzing these policies in a sequential decision-making framework where individuals' welfare levels stochastically decay over time, and policymakers can intervene to prevent this decay. Under reasonable assumptions, we prove that interventions following Rawlsian policies can outperform utilitarian policies in the long run, even when the latter dominate in the short run. We characterize the exact conditions under which Rawlsian policies can outperform utilitarian policies. We further illustrate our theoretical findings using simulations, which highlight the risks of evaluating policies based solely on their short-term effects. Our results underscore the necessity of considering long-term horizons in designing and evaluating welfare policies; the true efficacy of even well-established policies may only emerge over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00632v1</guid>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiduan Wu, Rediet Abebe, Moritz Hardt, Ana-Andreea Stoica</dc:creator>
    </item>
    <item>
      <title>Commitment, Conflict, and Status Quo in Bargaining</title>
      <link>https://arxiv.org/abs/2503.01053</link>
      <description>arXiv:2503.01053v1 Announce Type: cross 
Abstract: Each period, two players bargain over a unit of surplus. Each player chooses between remaining flexible and committing to a take-it-or-leave-it offer at a cost. If players' committed demands are incompatible, then the current-period surplus is destroyed in the conflict. When both players are flexible, the surplus is split according to the status quo, which is the division in the last period where there was no conflict. We show that when players are patient and the cost of commitment is small, there exist a class of symmetric Markov Perfect equilibria that are asymptotically efficient and renegotiation proof, in which players commit to fair demands in almost all periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01053v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harry Pei</dc:creator>
    </item>
    <item>
      <title>T\^atonnement in Homothetic Fisher Markets</title>
      <link>https://arxiv.org/abs/2306.04890</link>
      <description>arXiv:2306.04890v3 Announce Type: replace 
Abstract: A prevalent theme in the economics and computation literature is to identify natural price-adjustment processes by which sellers and buyers in a market can discover equilibrium prices. An example of such a process is t\^atonnement, an auction-like algorithm first proposed in 1874 by French economist Walras in which sellers adjust prices based on the Marshallian demands of buyers. A dual concept in consumer theory is a buyer's Hicksian demand. In this paper, we identify the maximum of the absolute value of the elasticity of the Hicksian demand, as an economic parameter sufficient to capture and explain a range of convergent and non-convergent t\^atonnement behaviors in a broad class of markets. In particular, we prove the convergence of t\^atonnement at a rate of $O((1+\varepsilon^2)/T)$, in homothetic Fisher markets with bounded price elasticity of Hicksian demand, i.e., Fisher markets in which consumers have preferences represented by homogeneous utility functions and the price elasticity of their Hicksian demand is bounded, where $\varepsilon \geq 0$ is the maximum absolute value of the price elasticity of Hicksian demand across all buyers. Our result not only generalizes known convergence results for CES Fisher markets, but extends them to mixed nested CES markets and Fisher markets with continuous, possibly non-concave, homogeneous utility functions. Our convergence rate covers the full spectrum of nested CES utilities, including Leontief and linear utilities, unifying previously existing disparate convergence and non-convergence results. In particular, for $\varepsilon = 0$, i.e., Leontief markets, we recover the best-known convergence rate of $O(1/T)$, and as $\varepsilon \to \infty$, e.g., linear Fisher markets, we obtain non-convergent behavior, as expected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04890v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denizalp Goktas, Jiayi Zhao, Amy Greenwald</dc:creator>
    </item>
    <item>
      <title>Replicating Electoral Success</title>
      <link>https://arxiv.org/abs/2402.17109</link>
      <description>arXiv:2402.17109v2 Announce Type: replace 
Abstract: A core tension in the study of plurality elections is the clash between the classic Hotelling-Downs model, which predicts that two office-seeking candidates should position themselves at the median voter's policy, and the empirical observation that real-world democracies often have two major parties with divergent policies. Motivated by this tension and drawing from bounded rationality, we introduce a dynamic model of candidate positioning based on a simple behavioral heuristic: candidates imitate the policy of previous winners. The resulting model is closely connected to evolutionary replicator dynamics and exhibits complex behavior, despite its simplicity. For uniformly-distributed voters, we prove that when there are $k = 2$, $3$, or $4$ candidates per election, any symmetric candidate distribution converges over time to a concentration of candidates at the center. With $k \ge 5$, however, we prove that the candidate distribution does not converge to the center. For initial distributions without any extreme candidates, we prove a stronger statement than non-convergence, showing that the density in an interval around the center goes to zero when $k \ge 5$. As a matter of robustness, our conclusions are qualitatively unchanged if a small fraction of candidates are not winner-copiers and are instead positioned uniformly at random. Beyond our theoretical analysis, we illustrate our results in simulation; for five or more candidates, we find a tendency towards the emergence of two clusters, a mechanism suggestive of Duverger's Law, the empirical finding that plurality leads to two-party systems. Our simulations also explore several variations of the model, including non-uniform voter distributions and other forms of noise, which exhibit similar convergence patterns. Finally, we discuss the relationship between our model and prior work on strategic equilibria of candidate positioning games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17109v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiran Tomlinson, Tanvi Namjoshi, Johan Ugander, Jon Kleinberg</dc:creator>
    </item>
    <item>
      <title>Adaptive Incentive Design with Learning Agents</title>
      <link>https://arxiv.org/abs/2405.16716</link>
      <description>arXiv:2405.16716v3 Announce Type: replace 
Abstract: We propose an adaptive incentive mechanism that learns the optimal incentives in environments where players continuously update their strategies. Our mechanism updates incentives based on each player's externality, defined as the difference between the player's marginal cost and the operator's marginal cost at each time step. The proposed mechanism updates the incentives on a slower timescale compared to the players' learning dynamics, resulting in a two-timescale coupled dynamical system. Notably, this mechanism is agnostic to the specific learning dynamics used by players to update their strategies. We show that any fixed point of this adaptive incentive mechanism corresponds to the optimal incentive mechanism, ensuring that the Nash equilibrium coincides with the socially optimal strategy. Additionally, we provide sufficient conditions under which the adaptive mechanism converges to a fixed point. Our results apply to both atomic and non-atomic games. To demonstrate the effectiveness of our proposed mechanism, we verify the convergence conditions in two practically relevant classes of games: atomic aggregative games and non-atomic routing games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16716v3</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chinmay Maheshwari, Kshitij Kulkarni, Manxi Wu, Shankar Sastry</dc:creator>
    </item>
    <item>
      <title>On the Viability of Open-Source Financial Rails: Economic Security of Permissionless Consensus</title>
      <link>https://arxiv.org/abs/2409.08951</link>
      <description>arXiv:2409.08951v2 Announce Type: replace 
Abstract: Bitcoin demonstrated the possibility of a financial ledger that operates without the need for a trusted central authority. However, concerns persist regarding its security and considerable energy consumption. We assess the consensus protocols that underpin Bitcoin's functionality, questioning whether they can ensure economically meaningful security while maintaining a permissionless design that allows free entry of operators. We answer this affirmatively by constructing a protocol that guarantees economic security and preserves Bitcoin's permissionless design. This protocol's security does not depend on monetary payments to miners or immense electricity consumption, which our analysis suggests are ineffective. Our framework integrates economic theory with distributed systems theory, and formalizes the role of the protocol's user community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08951v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jacob D. Leshno, Elaine Shi, Rafael Pass</dc:creator>
    </item>
    <item>
      <title>Boosting Perturbed Gradient Ascent for Last-Iterate Convergence in Games</title>
      <link>https://arxiv.org/abs/2410.02388</link>
      <description>arXiv:2410.02388v2 Announce Type: replace 
Abstract: This paper presents a payoff perturbation technique, introducing a strong convexity to players' payoff functions in games. This technique is specifically designed for first-order methods to achieve last-iterate convergence in games where the gradient of the payoff functions is monotone in the strategy profile space, potentially containing additive noise. Although perturbation is known to facilitate the convergence of learning algorithms, the magnitude of perturbation requires careful adjustment to ensure last-iterate convergence. Previous studies have proposed a scheme in which the magnitude is determined by the distance from a periodically re-initialized anchoring or reference strategy. Building upon this, we propose Gradient Ascent with Boosting Payoff Perturbation, which incorporates a novel perturbation into the underlying payoff function, maintaining the periodically re-initializing anchoring strategy scheme. This innovation empowers us to provide faster last-iterate convergence rates against the existing payoff perturbed algorithms, even in the presence of additive noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02388v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenshi Abe, Mitsuki Sakamoto, Kaito Ariu, Atsushi Iwasaki</dc:creator>
    </item>
    <item>
      <title>Efficiency in the Roommates Problem</title>
      <link>https://arxiv.org/abs/2502.16960</link>
      <description>arXiv:2502.16960v2 Announce Type: replace 
Abstract: We propose an $O(n^2)$-time algorithm to determine whether a given matching is efficient in the roommates problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16960v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Kuwahara</dc:creator>
    </item>
    <item>
      <title>Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning</title>
      <link>https://arxiv.org/abs/2407.00617</link>
      <description>arXiv:2407.00617v4 Announce Type: replace-cross 
Abstract: Reinforcement Learning with Human Feedback (RLHF) has achieved great success in aligning large language models (LLMs) with human preferences. Prevalent RLHF approaches are reward-based, following the Bradley-Terry (BT) model assumption, which may not fully capture the complexity of human preferences. In this paper, we explore RLHF under a general preference framework and approach it from a game-theoretic perspective. Specifically, we formulate the problem as a two-player game and propose a novel online algorithm, iterative Nash policy optimization (INPO). The key idea is to let the policy play against itself via no-regret learning, thereby approximating the Nash policy. Unlike previous methods, INPO bypasses the need for estimating the expected win rate for individual responses, which typically incurs high computational or annotation costs. Instead, we introduce a new loss objective that is directly minimized over a preference dataset. We provide theoretical analysis for our approach and demonstrate its effectiveness through experiments on various representative benchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6% length-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on Arena-Hard, showing substantial improvement over the state-of-the-art online RLHF algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00617v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuheng Zhang, Dian Yu, Baolin Peng, Linfeng Song, Ye Tian, Mingyue Huo, Nan Jiang, Haitao Mi, Dong Yu</dc:creator>
    </item>
    <item>
      <title>Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies</title>
      <link>https://arxiv.org/abs/2410.03968</link>
      <description>arXiv:2410.03968v2 Announce Type: replace-cross 
Abstract: Decoding strategies play a pivotal role in text generation for modern language models, yet a puzzling gap divides theory and practice. Surprisingly, strategies that should intuitively be optimal, such as Maximum a Posteriori (MAP), often perform poorly in practice. Meanwhile, popular heuristic approaches like Top-$k$ and Nucleus sampling, which employ truncation and normalization of the conditional next-token probabilities, have achieved great empirical success but lack theoretical justifications. In this paper, we propose Decoding Game, a comprehensive theoretical framework which reimagines text generation as a two-player zero-sum game between Strategist, who seeks to produce text credible in the true distribution, and Nature, who distorts the true distribution adversarially. After discussing the decomposibility of multi-step generation, we derive the optimal strategy in closed form for one-step Decoding Game. It is shown that the adversarial Nature imposes an implicit regularization on likelihood maximization, and truncation-normalization methods are first-order approximations to the optimal strategy under this regularization. Additionally, by generalizing the objective and parameters of Decoding Game, near-optimal strategies encompass diverse methods such as greedy search, temperature scaling, and hybrids thereof. Numerical experiments are conducted to complement our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03968v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sijin Chen, Omar Hagrass, Jason M. Klusowski</dc:creator>
    </item>
  </channel>
</rss>
