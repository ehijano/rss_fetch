<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 02:37:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Specification and Automatic Verification of Computational Reductions</title>
      <link>https://arxiv.org/abs/2407.04037</link>
      <description>arXiv:2407.04037v1 Announce Type: new 
Abstract: We are interested in the following validation problem for computational reductions: for algorithmic problems $P$ and $P^\star$, is a given candidate reduction indeed a reduction from $P$ to $P^\star$? Unsurprisingly, this problem is undecidable even for very restricted classes of reductions. This leads to the question: Is there a natural, expressive class of reductions for which the validation problem can be attacked algorithmically? We answer this question positively by introducing an easy-to-use graphical specification mechanism for computational reductions, called cookbook reductions. We show that cookbook reductions are sufficiently expressive to cover many classical graph reductions and expressive enough so that SAT remains NP-complete (in the presence of a linear order). Surprisingly, the validation problem is decidable for natural and expressive subclasses of cookbook reductions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04037v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Grange, Fabian Vehlken, Nils Vortmeier, Thomas Zeume</dc:creator>
    </item>
    <item>
      <title>Encoding of algebraic geometry codes with quasi-linear complexity $O(N\log N)$</title>
      <link>https://arxiv.org/abs/2407.04618</link>
      <description>arXiv:2407.04618v1 Announce Type: new 
Abstract: Fast encoding and decoding of codes have been always an important topic in code theory as well as complexity theory. Although encoding is easier than decoding in general, designing an encoding algorithm of codes of length $N$ with quasi-linear complexity $O(N\log N)$ is not an easy task. Despite the fact that algebraic geometry codes were discovered in the early of 1980s, encoding algorithms of algebraic geometry codes with quasi-linear complexity $O(N\log N)$ have not been found except for the simplest algebraic geometry codes--Reed-Solomon codes. The best-known encoding algorithm of algebraic geometry codes based on a class of plane curves has quasi-linear complexity at least $O(N\log^2 N)$. In this paper, we design an encoding algorithm of algebraic geometry codes with quasi-linear complexity $O(N\log N)$. Our algorithm works well for a large class of algebraic geometry codes based on both plane and non-plane curves.
  The main idea of this paper is to generalize the divide-and-conquer method from the fast Fourier Transform over finite fields to algebraic curves. Suppose we consider encoding of algebraic geometry codes based on an algebraic curve ${\mathcal X}$ over $\mathbb{F}_q$. We first consider a tower of Galois coverings ${\mathcal X}={\mathcal X}_0\rightarrow{\mathcal X}_1\rightarrow\cdots\rightarrow{\mathcal X}_r$ over a finite field $\mathbb{F}_q$, i.e., their function field tower $\mathbb{F}_q({\mathcal X}_0)\supsetneq\mathbb{F}_q({\mathcal X}_{1})\supsetneq\cdots \supsetneq\mathbb{F}_q({\mathcal X}_r)$ satisfies that each of extension $\mathbb{F}_q({\mathcal X}_{i-1})/\mathbb{F}_q({\mathcal X}_i)$ is a Galois extension and the extension degree $[\mathbb{F}_q({\mathcal X}_{i-1}):\mathbb{F}_q({\mathcal X}_i)]$ {is a constant}. Then encoding of an algebraic geometry code based on ${\mathcal X}$ is reduced to the encoding of an algebraic geometry code based on ${\mathcal X}_r$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04618v1</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songsong Li, Shu Liu, Liming Ma, Yunqi Wan, Chaoping Xing</dc:creator>
    </item>
    <item>
      <title>Determination Problems for Orbit Closures and Matrix Groups</title>
      <link>https://arxiv.org/abs/2407.04626</link>
      <description>arXiv:2407.04626v1 Announce Type: new 
Abstract: Computational problems concerning the orbit of a point under the action of a matrix group occur in numerous subfields of computer science, including complexity theory, program analysis, quantum computation, and automata theory. In many cases the focus extends beyond orbits proper to orbit closures under a suitable topology. Typically one starts from a group and several points and asks questions about the orbit closure of the points under the action of the group, e.g., whether two given orbit closures intersect.
  In this paper we consider a collection of what we call determination problems concerning groups and orbit closures. These problems begin with a given variety and seek to understand whether and how it arises either as an algebraic group or as an orbit closure. The how question asks whether the underlying group is $s$-generated, meaning it is topologically generated by $s$ matrices for a given number $s$. Among other applications, problems of this type have recently been studied in the context of synthesising loops subject to certain specified invariants on program variables.
  Our main result is a polynomial-space procedure that inputs a variety $V$ and a number $s$ and determines whether $V$ arises as an orbit closure of a point under an $s$-generated commutative matrix group. The main tools in our approach are rooted in structural properties of commutative algebraic matrix groups and lattice theory. We leave open the question of determining whether a variety is an orbit closure of a point under an algebraic matrix group (without the requirement of commutativity). In this regard, we note that a recent paper by Nosan et al. [NPSHW2021] gives an elementary procedure to compute the orbit closure of a point under finitely many matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04626v1</guid>
      <category>cs.CC</category>
      <category>math.AG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rida Ait El Manssour, George Kenison, Mahsa Shirmohammadi, James Worrell</dc:creator>
    </item>
    <item>
      <title>Partial Minimum Branching Program Size Problem is ETH-hard</title>
      <link>https://arxiv.org/abs/2407.04632</link>
      <description>arXiv:2407.04632v1 Announce Type: new 
Abstract: We show that assuming the Exponential Time Hypothesis, the Partial Minimum Branching Program Size Problem (MBPSP*) requires superpolynomial time. This result also applies to the partial minimization problems for many interesting subclasses of branching programs, such as read-k branching programs and OBDDs.
  Combining these results with the recent unconditional lower bounds for MCSP [Glinskih, Riazanov'22], we obtain an unconditional superpolynomial lower bound on the size of Read-Once Nondeterministic Branching Programs (1-NBP) computing the total versions of the minimum BP, read-k-BP, and OBDD size problems.
  Additionally we show that it is NP-hard to check whether a given BP computing a partial Boolean function can be compressed to a BP of a given size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04632v1</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludmila Glinskih, Artur Riazanov</dc:creator>
    </item>
    <item>
      <title>Weighted basic parallel processes and combinatorial enumeration</title>
      <link>https://arxiv.org/abs/2407.03638</link>
      <description>arXiv:2407.03638v1 Announce Type: cross 
Abstract: We study weighted basic parallel processes (WBPP), a nonlinear recursive generalisation of weighted finite automata inspired from process algebra and Petri net theory. Our main result is an algorithm of 2-EXPSPACE complexity for the WBPP equivalence problem. While (unweighted) BPP language equivalence is undecidable, we can use this algorithm to decide multiplicity equivalence of BPP and language equivalence of unambiguous BPP, with the same complexity. These are long-standing open problems for the related model of weighted context-free grammars. Our second contribution is a connection between WBPP, power series solutions of systems of polynomial differential equations, and combinatorial enumeration. To this end we consider constructible differentially finite power series (CDF), a class of multivariate differentially algebraic series introduced by Bergeron and Reutenauer in order to provide a combinatorial interpretation to differential equations. CDF series generalise rational, algebraic, and a large class of D-finite (holonomic) series, for which decidability of equivalence was an open problem. We show that CDF series correspond to commutative WBPP series. As a consequence of our result on WBPP and commutativity, we show that equivalence of CDF power series can be decided with 2-EXPTIME complexity. The complexity analysis is based on effective bounds from algebraic geometry, namely on the length of chains of polynomial ideals constructed by repeated application of finitely many, not necessarily commuting derivations of a multivariate polynomial ring. This is obtained by generalising a result of Novikov and Yakovenko in the case of a single derivation, which is noteworthy since generic bounds on ideal chains are non-primitive recursive in general. On the way, we develop the theory of \WBPP~series and \CDF~power series, exposing several of their appealing properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03638v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Clemente</dc:creator>
    </item>
    <item>
      <title>Over the Edge of Chaos? Excess Complexity as a Roadblock to Artificial General Intelligence</title>
      <link>https://arxiv.org/abs/2407.03652</link>
      <description>arXiv:2407.03652v1 Announce Type: cross 
Abstract: In this study, we explored the progression trajectories of artificial intelligence (AI) systems through the lens of complexity theory. We challenged the conventional linear and exponential projections of AI advancement toward Artificial General Intelligence (AGI) underpinned by transformer-based architectures, and posited the existence of critical points, akin to phase transitions in complex systems, where AI performance might plateau or regress into instability upon exceeding a critical complexity threshold. We employed agent-based modelling (ABM) to simulate hypothetical scenarios of AI systems' evolution under specific assumptions, using benchmark performance as a proxy for capability and complexity. Our simulations demonstrated how increasing the complexity of the AI system could exceed an upper criticality threshold, leading to unpredictable performance behaviours. Additionally, we developed a practical methodology for detecting these critical thresholds using simulation data and stochastic gradient descent to fine-tune detection thresholds. This research offers a novel perspective on AI advancement that has a particular relevance to Large Language Models (LLMs), emphasising the need for a tempered approach to extrapolating AI's growth potential and underscoring the importance of developing more robust and comprehensive AI performance benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03652v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Teo Susnjak, Timothy R. McIntosh, Andre L. C. Barczak, Napoleon H. Reyes, Tong Liu, Paul Watters, Malka N. Halgamuge</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Target Set Selection in Simple Geometric Networks</title>
      <link>https://arxiv.org/abs/2307.06976</link>
      <description>arXiv:2307.06976v4 Announce Type: replace 
Abstract: We study the following model of disease spread in a social network. At first, all individuals are either infected or healthy. Next, in discrete rounds, the disease spreads in the network from infected to healthy individuals such that a healthy individual gets infected if and only if a sufficient number of its direct neighbors are already infected. We represent the social network as a graph. Inspired by the real-world restrictions in the current epidemic, especially by social and physical distancing requirements, we restrict ourselves to networks that can be represented as geometric intersection graphs. We show that finding a minimal vertex set of initially infected individuals to spread the disease in the whole network is computationally hard, already on unit disk graphs. Hence, to provide some algorithmic results, we focus ourselves on simpler geometric graph classes, such as interval graphs and grid graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06976v4</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Dvo\v{r}\'ak, Du\v{s}an Knop, \v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>Satisfiability of commutative vs. non-commutative CSPs</title>
      <link>https://arxiv.org/abs/2404.11709</link>
      <description>arXiv:2404.11709v2 Announce Type: replace 
Abstract: The Mermin-Peres magic square is a celebrated example of a system of Boolean linear equations that is not (classically) satisfiable but is satisfiable via linear operators on a Hilbert space of dimension four. A natural question is then, for what kind of problems such a phenomenon occurs? Atserias, Kolaitis, and Severini answered this question for all Boolean Constraint Satisfaction Problems (CSPs): For 0-Valid-SAT, 1-Valid-SAT, 2-SAT, Horn-SAT, and Dual Horn-SAT, classical satisfiability and operator satisfiability is the same and thus there is no gap; for all other Boolean CSPs, these notions differ as there are gaps, i.e., there are unsatisfiable instances that are satisfiable via operators on Hilbert spaces.
  We generalize their result to CSPs on arbitrary finite domains and give an almost complete classification: First, we show that NP-hard CSPs admit a separation between classical satisfiability and satisfiability via operators on finite- and infinite-dimensional Hilbert spaces. Second, we show that tractable CSPs of bounded width have no satisfiability gaps of any kind. Finally, we show that tractable CSPs of unbounded width can simulate, in a satisfiability-gap-preserving fashion, linear equations over an Abelian group of prime order $p$; for such CSPs, we obtain a separation of classical satisfiability and satisfiability via operators on infinite-dimensional Hilbert spaces. Furthermore, if $p=2$, such CSPs also have gaps separating classical satisfiability and satisfiability via operators on finite- and infinite-dimensional Hilbert spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11709v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei A. Bulatov, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Pseudorandom Permutations from Random Reversible Circuits</title>
      <link>https://arxiv.org/abs/2404.14648</link>
      <description>arXiv:2404.14648v2 Announce Type: replace 
Abstract: We study pseudorandomness properties of permutations on $\{0,1\}^n$ computed by random circuits made from reversible $3$-bit gates (permutations on $\{0,1\}^3$). Our main result is that a random circuit of depth $n \cdot \tilde{O}(k^2)$, with each layer consisting of $\approx n/3$ random gates in a fixed nearest-neighbor architecture, yields almost $k$-wise independent permutations. The main technical component is showing that the Markov chain on $k$-tuples of $n$-bit strings induced by a single random $3$-bit nearest-neighbor gate has spectral gap at least $1/n \cdot \tilde{O}(k)$. This improves on the original work of Gowers [Gowers96], who showed a gap of $1/\mathrm{poly}(n,k)$ for one random gate (with non-neighboring inputs); and, on subsequent work [HMMR05,BH08] improving the gap to $\Omega(1/n^2k)$ in the same setting.
  From the perspective of cryptography, our result can be seen as a particularly simple/practical block cipher construction that gives provable statistical security against attackers with access to $k$~input-output pairs within few rounds. We also show that the Luby--Rackoff construction of pseudorandom permutations from pseudorandom functions can be implemented with reversible circuits. From this, we make progress on the complexity of the Minimum Reversible Circuit Size Problem (MRCSP), showing that block ciphers of fixed polynomial size are computationally secure against arbitrary polynomial-time adversaries, assuming the existence of one-way functions (OWFs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14648v2</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William He, Ryan O'Donnell</dc:creator>
    </item>
    <item>
      <title>Tight (Double) Exponential Bounds for Identification Problems: Locating-Dominating Set and Test Cover</title>
      <link>https://arxiv.org/abs/2402.08346</link>
      <description>arXiv:2402.08346v2 Announce Type: replace-cross 
Abstract: We investigate fine-grained algorithmic aspects of identification problems in graphs and set systems, with a focus on Locating-Dominating Set and Test Cover. We prove the (tight) conditional lower bounds for these problems when parameterized by treewidth and solution as. Formally, \textsc{Locating-Dominating Set} (respectively, \textsc{Test Cover}) parameterized by the treewidth of the input graph (respectively, of the natural auxiliary graph) does not admit an algorithm running in time $2^{2^{o(tw)}} \cdot poly(n)$ (respectively, $2^{2^{o(tw)}} \cdot poly(|U| + |\mathcal{F}|))$. This result augments the small list of NP-Complete problems that admit double exponential lower bounds when parameterized by treewidth. Then, we first prove that \textsc{Locating-Dominating Set} does not admit an algorithm running in time $2^{o(k^2)} \cdot poly(n)$, nor a polynomial time kernelization algorithm that reduces the solution size and outputs a kernel with $2^{o(k)}$ vertices, unless the \ETH\ fails. To the best of our knowledge, \textsc{Locating-Dominating Set} is the first problem that admits such an algorithmic lower-bound (with a quadratic function in the exponent) when parameterized by the solution size. Finally, we prove that \textsc{Test Cover} does not admit an algorithm running in time $2^{2^{o(k)}} \cdot poly(|U| + |\mathcal{F}|)$. This is also a rare example of the problem that admits a double exponential lower bound when parameterized by the solution size.
  We also present algorithms whose running times match the above lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08346v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipayan Chakraborty, Florent Foucaud, Diptapriyo Majumdar, Prafullkumar Tale</dc:creator>
    </item>
  </channel>
</rss>
