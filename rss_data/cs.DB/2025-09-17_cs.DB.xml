<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The NIAID Discovery Portal: A Unified Search Engine for Infectious and Immune-Mediated Disease Datasets</title>
      <link>https://arxiv.org/abs/2509.13524</link>
      <description>arXiv:2509.13524v1 Announce Type: new 
Abstract: The NIAID Data Ecosystem Discovery Portal (https://data.niaid.nih.gov) provides a unified search interface for over 4 million datasets relevant to infectious and immune-mediated disease (IID) research. Integrating metadata from domain-specific and generalist repositories, the Portal enables researchers to identify and access datasets using user-friendly filters or advanced queries, without requiring technical expertise. The Portal supports discovery of a wide range of resources, including epidemiological, clinical, and multi-omic datasets, and is designed to accommodate exploratory browsing and precise searches. The Portal provides filters, prebuilt queries, and dataset collections to simplify the discovery process for users. The Portal additionally provides documentation and an API for programmatic access to harmonized metadata. By easing access barriers to important biomedical datasets, the NIAID Data Ecosystem Discovery Portal serves as an entry point for researchers working to understand, diagnose, or treat IID.
  IMPORTANCE
  Valuable datasets are often overlooked because they are difficult to locate. The NIAID Data Ecosystem Discovery Portal fills this gap by providing a centralized, searchable interface that empowers users with varying levels of technical expertise to find and reuse data. By standardizing key metadata fields and harmonizing heterogeneous formats, the Portal improves data findability, accessibility, and reusability. This resource supports hypothesis generation, comparative analysis, and secondary use of public data by the IID research community, including those funded by NIAID. The Portal supports data sharing by standardizing metadata and linking to source repositories, and maximizes the impact of public investment in research data by supporting scientific advancement via secondary use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13524v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ginger Tsueng (The Scripps Research Institute, La Jolla, CA, USA), Emily Bullen (The Scripps Research Institute, La Jolla, CA, USA), Candice Czech (The Scripps Research Institute, La Jolla, CA, USA), Dylan Welzel (The Scripps Research Institute, La Jolla, CA, USA), Leandro Collares (The Scripps Research Institute, La Jolla, CA, USA), Jason Lin (The Scripps Research Institute, La Jolla, CA, USA), Everaldo Rodolpho (The Scripps Research Institute, La Jolla, CA, USA), Zubair Qazi (The Scripps Research Institute, La Jolla, CA, USA), Nichollette Acosta (The Scripps Research Institute, La Jolla, CA, USA), Lisa M. Mayer (National Institute of Allergy and Infectious Diseases, Rockville, MD, USA), Sudha Venkatachari (National Cancer Institute, Rockville, MD, USA), Zorana Mitrovi\'c Vu\v{c}i\v{c}evi\'c (Velsera, Charlestown, MA, USA), Poromendro N. Burman (Velsera, Charlestown, MA, USA), Deepti Jain (Velsera, Charlestown, MA, USA), Jack DiGiovanna (Velsera, Charlestown, MA, USA), Maria Giovanni (National Institute of Allergy and Infectious Diseases, Rockville, MD, USA), Asiyah Lin (National Institute of Allergy and Infectious Diseases, Rockville, MD, USA), Wilbert Van Panhuis (National Institute of Allergy and Infectious Diseases, Rockville, MD, USA), Laura D. Hughes (The Scripps Research Institute, La Jolla, CA, USA), Andrew I. Su (The Scripps Research Institute, La Jolla, CA, USA), Chunlei Wu (The Scripps Research Institute, La Jolla, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Tractability Frontiers of the Shapley Value for Aggregate Conjunctive Queries</title>
      <link>https://arxiv.org/abs/2509.13565</link>
      <description>arXiv:2509.13565v1 Announce Type: new 
Abstract: In recent years, the Shapley value has emerged as a general game-theoretic measure for assessing the contribution of a tuple to the result of a database query. We study the complexity of calculating the Shapley value of a tuple for an aggregate conjunctive query, which applies an aggregation function to the result of a conjunctive query (CQ) based on a value function that assigns a number to each query answer. Prior work by Livshits, Bertossi, Kimelfeld, and Sebag (2020) established that this task is #P-hard for every nontrivial aggregation function when the query is non-hierarchical with respect to its existential variables, assuming the absence of self-joins. They further showed that this condition precisely characterizes the class of intractable CQs when the aggregate function is sum or count. In addition, they posed as open problems the complexity of other common aggregate functions such as min, max, count-distinct, average, and quantile (including median). Towards the resolution of these problems, we identify for each aggregate function a class of hierarchical CQs where the Shapley value is tractable with every value function, as long as it is local (i.e., determined by the tuples of one relation). We further show that each such class is maximal: for every CQ outside of this class, there is a local (easy-to-compute) value function that makes the Shapley value #P-hard. Interestingly, our results reveal that each aggregate function corresponds to a different generalization of the class of hierarchical CQs from Boolean to non-Boolean queries. In particular, max, min, and count-distinct match the class of CQs that are all-hierarchical (i.e., hierarchical with respect to all variables), and average and quantile match the narrower class of q-hierarchical CQs introduced by Berkholz, Keppeler, and Schweikardt (2017) in the context of the fine-grained complexity of query answering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13565v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Standke, Benny Kimelfeld</dc:creator>
    </item>
    <item>
      <title>XASDB -- Design and Implementation of an Open-Access Spectral Database</title>
      <link>https://arxiv.org/abs/2509.13566</link>
      <description>arXiv:2509.13566v1 Announce Type: new 
Abstract: The increasing volume and complexity of X-ray absorption spectroscopy (XAS) data generated at synchrotron facilities worldwide require robust infrastructure for data management, sharing, and analysis. This paper introduces the XAS Database (XASDB), a comprehensive web-based platform developed and hosted by the Canadian Light Source (CLS). The database houses more than 1000 reference spectra spanning 40 elements and 324 chemical compounds. The platform employs a Node.js/MongoDB architecture designed to handle diverse data formats from multiple beamlines and synchrotron facilities. A key innovation is the XASproc JavaScript library, which enables browser-based XAS data processing including normalization, background sub- traction, extended X-ray absorption fine structure (EXAFS) extraction, and preliminary analysis traditionally limited to desktop applications. The integrated XASVue spectral viewer provides installation-free data visualization and analysis with broad accessibility across devices and operating systems. By offering standardized data output, comprehensive metadata, and integrated analytical ca- pabilities, XASDB facilitates collaborative research and promotes FAIR (Findable, Accessible, In- teroperable, and Reusable) data principles. The platform serves as a valuable resource for linear combination fitting (LCF) analysis, machine learning applications, and educational purposes. This initiative demonstrates the potential for web-centric approaches in XAS data analysis, accelerating advances in materials science, environmental research, chemistry, and biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13566v1</guid>
      <category>cs.DB</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Spasyuk</dc:creator>
    </item>
    <item>
      <title>Algorithms for Optimizing Acyclic Queries</title>
      <link>https://arxiv.org/abs/2509.14144</link>
      <description>arXiv:2509.14144v1 Announce Type: new 
Abstract: Most research on query optimization has centered on binary join algorithms like hash join and sort-merge join. However, recent years have seen growing interest in theoretically optimal algorithms, notably Yannakakis' algorithm. These algorithms rely on join trees, which differ from the operator trees for binary joins and require new optimization techniques. We propose three approaches to constructing join trees for acyclic queries. First, we give an algorithm to enumerate all join trees of an alpha-acyclic query by edits with amortized constant delay, which forms the basis of a cost-based optimizer for acyclic joins. Second, we show that the Maximum Cardinality Search algorithm by Tarjan and Yannakakis constructs a unique shallowest join tree, rooted at any relation, for a Berge-acyclic query; this tree enables parallel execution of large join queries. Finally, we prove that any connected left-deep linear plan for a gamma-acyclic query can be converted into a join tree by a simple algorithm, allowing reuse of optimization infrastructure developed for binary joins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14144v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Luo, Wim Van den Broeck, Guy Van den Broeck, Yisu Remy Wang</dc:creator>
    </item>
    <item>
      <title>LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology</title>
      <link>https://arxiv.org/abs/2509.13978</link>
      <description>arXiv:2509.13978v1 Announce Type: cross 
Abstract: Modern scientific discovery increasingly relies on workflows that process data across the Edge, Cloud, and High Performance Computing (HPC) continuum. Comprehensive and in-depth analyses of these data are critical for hypothesis validation, anomaly detection, reproducibility, and impactful findings. Although workflow provenance techniques support such analyses, at large scale, the provenance data become complex and difficult to analyze. Existing systems depend on custom scripts, structured queries, or static dashboards, limiting data interaction. In this work, we introduce an evaluation methodology, reference architecture, and open-source implementation that leverages interactive Large Language Model (LLM) agents for runtime data analysis. Our approach uses a lightweight, metadata-driven design that translates natural language into structured provenance queries. Evaluations across LLaMA, GPT, Gemini, and Claude, covering diverse query classes and a real-world chemistry workflow, show that modular design, prompt tuning, and Retrieval-Augmented Generation (RAG) enable accurate and insightful LLM agent responses beyond recorded provenance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13978v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3731599.3767582</arxiv:DOI>
      <dc:creator>Renan Souza, Timothy Poteet, Brian Etz, Daniel Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, Rafael Ferreira da Silva</dc:creator>
    </item>
    <item>
      <title>FIER: Fine-Grained and Efficient KV Cache Retrieval for Long-context LLM Inference</title>
      <link>https://arxiv.org/abs/2508.08256</link>
      <description>arXiv:2508.08256v2 Announce Type: replace 
Abstract: The Key-Value (KV) cache reading latency increases significantly with context lengths, hindering the efficiency of long-context LLM inference. To address this, previous works propose retaining a small fraction of KV cache based on token importance. For example, KV eviction uses static heuristics to retain tokens, while KV retrieval dynamically selects query-relevant tokens for more adaptive cache management. However, we observe that important tokens are often sparsely distributed across the long context. This sparsity makes existing page-level KV retrieval inaccurate, as each page may include irrelevant tokens and miss critical ones. In this work, we propose Fier, a \underline{Fi}ne-Grained and \underline{E}fficient KV cache \underline{R}etrieval method. Fier uses 1-bit quantized keys to estimate the importance of each token, resulting in efficient and precise retrieval. Experiments show that Fier matches full KV performance using only 11\% of the cache budget across various long-context tasks, reducing decoding latency by 1.2$\times$ to 1.5$\times$.Code is available at https://github.com/SimWangArizona/FIER</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08256v2</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongwei Wang, Zijie Liu, Song Wang, Yuxin Ren, Jianing Deng, Jingtong Hu, Tianlong Chen, Huanrui Yang</dc:creator>
    </item>
    <item>
      <title>Lost Data in Electron Microscopy</title>
      <link>https://arxiv.org/abs/2508.18217</link>
      <description>arXiv:2508.18217v2 Announce Type: replace 
Abstract: The goal of this study is to estimate the amount of lost data in electron microscopy and to analyze the extent to which experimentally acquired images are utilized in peer-reviewed scientific publications. Analysis of the number of images taken on electron microscopes at a core user facility and the number of images subsequently included in peer-reviewed scientific journals revealed low efficiency of data utilization. Up to around 90% of electron microscopy data generated during routine instrument operation remain unused. Of the more than 150 000 electron microscopy images evaluated in this study, only approximately 3 500 (just over 2%) were made available in publications. For the analyzed dataset, the amount of lost data in electron microscopy can be estimated as &gt;90% (in terms of data being recorded but not being published in peer-reviewed literature). On the one hand, these results highlight a shortcoming in the optimal use of microscopy images; on the other hand, they indicate the existence of a large pool of electron microscopy data that can facilitate research in data science and the development of AI-based projects. The considerations important to unlock the potential of lost data are discussed in the present article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18217v2</guid>
      <category>cs.DB</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.DL</category>
      <category>physics.chem-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nina M. Ivanova, Alexey S. Kashin, Valentine P. Ananikov</dc:creator>
    </item>
    <item>
      <title>Semi-interval Comparison Constraints in Query Containment and Their Impact on Certain Answer Computation</title>
      <link>https://arxiv.org/abs/2509.10138</link>
      <description>arXiv:2509.10138v2 Announce Type: replace 
Abstract: We consider conjunctive queries with arithmetic comparisons (CQAC) and investigate the computational complexity of the problem: Given two CQAC queries, $Q$ and $Q'$, is $Q'$ contained in $Q$? We know that, for CQAC queries, the problem of testing containment is $\Pi_2 ^p$ -complete. However, there are broad classes of queries with semi-interval arithmetic comparisons in the containing query that render the problem solvable in NP. In all cases examined the contained query is allowed to be any CQAC. Interestingly, we also prove that there are simple cases where the problem remains $\Pi_2 ^p$ -complete.
  We also investigate the complexity of computing certain answers in the framework of answering CQAC queries with semi-interval comparisons using any CQAC views. We prove that maximally contained rewritings in the language of union of CQACs always compute exactly all certain answers. We find cases where we can compute certain answers in polynomial time using maximally contained rewritings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10138v2</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Foto N. Afrati, Matthew Damigos</dc:creator>
    </item>
    <item>
      <title>SPECIAL: Synopsis Assisted Secure Collaborative Analytics</title>
      <link>https://arxiv.org/abs/2404.18388</link>
      <description>arXiv:2404.18388v2 Announce Type: replace-cross 
Abstract: Secure collaborative analytics (SCA) enable the processing of analytical SQL queries across multiple owners' data, even when direct data sharing is not feasible. Although essential for strong privacy, the large overhead from data-oblivious primitives in traditional SCA has hindered its practical adoption. Recent SCA variants that permit controlled leakages under differential privacy (DP) show a better balance between privacy and efficiency. However, they still face significant challenges, such as potentially unbounded privacy loss, suboptimal query planning, and lossy processing. To address these challenges, we introduce SPECIAL, the first SCA system that simultaneously ensures bounded privacy loss, advanced query planning, and lossless processing. SPECIAL employs a novel synopsis-assisted secure processing model, where a one-time privacy cost is spent to acquire private synopses (table statistics) from owner data. These synopses then allow SPECIAL to estimate (compaction) sizes for secure operations (e.g., filter, join) and index encrypted data without extra privacy loss. Crucially, these estimates and indexes can be prepared before runtime, thereby facilitating efficient query planning and accurate cost estimations. Moreover, by using one-sided noise mechanisms and private upper bound techniques, SPECIAL ensures strict lossless processing for complex queries (e.g., multi-join). Through a comprehensive benchmark, we show that SPECIAL significantly outperforms cutting-edge SCAs, with up to 80X faster query times and over 900X smaller memory for complex queries. Moreover, it also achieves up to an 89X reduction in privacy loss under continual processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18388v2</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenghong Wang, Lina Qiu, Johes Bater, Yukui Luo</dc:creator>
    </item>
  </channel>
</rss>
