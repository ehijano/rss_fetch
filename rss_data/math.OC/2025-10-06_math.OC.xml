<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Oct 2025 02:45:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Convergence Rates of General $N$-Player Stackelberg Games to their Mean Field Limits</title>
      <link>https://arxiv.org/abs/2510.02380</link>
      <description>arXiv:2510.02380v1 Announce Type: new 
Abstract: In this article, we establish precise convergence rates of a general class of $N$-Player Stackelberg games to their mean field limits, which allows the response time delay of information, empirical distribution based interactions, and the control-dependent diffusion coefficients. All these features makes our problem nonstandard, barely been touched in the literature, and they complicate the analysis and therefore reduce the convergence rate. We first justify the same convergence rate for both the followers and the leader. Specifically, for the most general case, the convergence rate is shown to be $\mathcal{O}\left(N^{-\frac{2(q-2)}{n_1(3q-4)}}\right)$ when $n_1&gt;4$ where $n_1$ is the dimension of the follower's state, and $q$ is the order of the integration of the initial; and this rate has yet been shown in the literature, to the best of our knowledge. Moreover, by classifying cases according to the state dimension $n_1$, the nature of the delay, and the assumptions of the coefficients, we provide several subcases where faster convergence rates can be obtained; for instance the $\mathcal{O}\left(N^{-\frac{2}{3n_1}}\right)$-convergence when the diffusion coefficients are independent of control variable. Our result extends the standard $o(1)$-convergence result for the mean field Stackelberg games in the literature, together with the $\mathcal{O}(N^{-\frac{1}{n_1+4}})$-convergence for the mean field games with major and minor players. We also discuss the special case where our coefficients are linear in distribution argument while nonlinear in state and control arguments, and we establish an $\mathcal{O}(1/\sqrt{N})$ convergence rate, which extends the linear quadratic cases in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02380v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Bensoussan, Ziyu Huang, Sheng Wang, Sheung Chi Phillip Yam</dc:creator>
    </item>
    <item>
      <title>Constraint Qualification for Generic Parameter Families of Constraints in Optimization</title>
      <link>https://arxiv.org/abs/2510.02381</link>
      <description>arXiv:2510.02381v1 Announce Type: new 
Abstract: Constraint qualifications (CQs) are central to the local analysis of constrained optimization. In this paper, we completely determine the validity of the four classical CQs -- LICQ, MFCQ, ACQ, and GCQ -- for constraint map-germs that arise in generic four-parameter families. Our approach begins by proving that all four CQs are invariant under the action of the group $\mathcal{K}[G]$ and under the operation of reduction. As a consequence, the verification of CQ-validity for a generic constraint reduces to checking CQ-validity on the $\mathcal{K}[G]$-normal forms of fully reduced map-germs. Such normal forms have been classified in our recent work. In the present paper, we verify which CQs hold in each germ appearing in the classification tables from that work. This analysis provides a complete picture of the generic landscape of the four classical CQs. Most notably, we find that there exist numerous generic map-germs for which GCQ holds while all stronger CQs fail, showing that the gap between GCQ and the other qualifications is not an exceptional phenomenon but arises generically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02381v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoki Hamada, Kenta Hayano, Hiroshi Teramoto</dc:creator>
    </item>
    <item>
      <title>Best Proximity Points for Geraghty-Type Non-Self Mappings with a Registration-Inspired Alignment Model</title>
      <link>https://arxiv.org/abs/2510.02406</link>
      <description>arXiv:2510.02406v1 Announce Type: new 
Abstract: We study Geraghty-type non-self mappings within the framework of best proximity point theory. By introducing auxiliary functions with subsequential convergence, we establish general conditions ensuring the existence and uniqueness of best proximity points. Our results extend and unify earlier work on proximal and Kannan-type contractions under a Geraghty setting, and we provide counterexamples showing that the auxiliary assumptions are essential. To demonstrate applicability, we construct a registration-inspired alignment model in which all hypotheses can be explicitly verified. This example illustrates how the theoretical framework guarantees a unique and well-defined alignment anchor, thereby highlighting the relevance of best proximity theory in registration problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02406v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatemeh Fogh, Sara Behnamian</dc:creator>
    </item>
    <item>
      <title>Inverse Design of a Layered Medium for Maximal Surface Localization</title>
      <link>https://arxiv.org/abs/2510.02662</link>
      <description>arXiv:2510.02662v1 Announce Type: new 
Abstract: Electromagnetic wave manipulation plays a crucial role in advancing technology across various domains, including photonic device design. This study presents an inverse design approach for a periodic medium that optimizes electromagnetic wave localization at the interface between a layered half-space and a homogeneous half-space. The approach finds a maximally localized mode at a specified frequency and wave number. The mode propagates in the direction of the interface. The design parameters are the permittivity of the layered medium, their relative thicknesses, and the permittivity of the homogeneous half-space. We analyze the problem using the transfer matrix method and apply the particle swarm optimization to find a rapidly decaying mode that satisfies the design constraints. The design process is demonstrated in a numerical example, which serves to illustrate the efficacy of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02662v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24S1713685</arxiv:DOI>
      <arxiv:journal_reference>SIAM Undergraduate Research Online, Vol. 18, 2025</arxiv:journal_reference>
      <dc:creator>Ziling Chen, Fadil Santosa</dc:creator>
    </item>
    <item>
      <title>Closed-loop solvability of delayed control problems: A stochastic Volterra system approach</title>
      <link>https://arxiv.org/abs/2510.02674</link>
      <description>arXiv:2510.02674v1 Announce Type: new 
Abstract: A general and new stochastic linear quadratic optimal control problem is studied, where the coefficients are allowed to be time-varying, and both state delay and control delay can appear simultaneously in the state equation and the cost functional. The closed-loop outcome control of this delayed problem is given by a new Riccati system whose solvability is carefully established. To this end, a novel method is introduced to transform the delayed problem into a control problem driven by a stochastic Volterra integral system without delay. This method offers several advantages: it bypasses the difficulty of decoupling the forward delayed state equation and the backward anticipated adjoint equation, avoids the introduction of infinite-dimensional spaces and unbounded control operators, and ensures that the closed-loop outcome control depends only on past state and control, without relying on future state or complex conditional expectation calculations. Finally, several particular important stochastic systems are discussed. It is found that the model can cover a class of stochastic integro-differential systems, whose closed-loop solvability has not been available before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02674v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijun Meng, Tianxiao Wang, Ji-Feng Zhang</dc:creator>
    </item>
    <item>
      <title>Flow Matching for Measure Transport and Feedback Stabilization of Control-Affine Systems</title>
      <link>https://arxiv.org/abs/2510.02706</link>
      <description>arXiv:2510.02706v1 Announce Type: new 
Abstract: We develop a \emph{flow-matching framework} for transporting probability measures under control-affine dynamics and for stabilizing systems to points or target sets. Starting from the continuity equation associated with the control affine system
  dx/dt = f_0(x) + \sum_{i=1}^m u_i f_i(x),
  we construct measure interpolations through exact and approximate flow matching, and extend the approach to \emph{output flow matching} when only output distributions must align. These constructions allow to directly import standard control tools, such as feedback design, oscillatory inputs, and trajectory steering, and yield sample-efficient, regression-based controllers for measure-to-measure transport.
  We also introduce a complementary ``noising + time-reversal'' perspective for classical state or set stabilization, inspired by denoising diffusion models. Here stabilization is interpreted as a denoising problem. We propose two methods for constructing the noising process: (i) PMP-based noising, which leverages the Hamiltonian system from Pontryagin's Maximum Principle and recovers the optimal controller for linear systems with convex costs, while providing feasible feedback laws in the nonlinear case; and (ii) randomized-control noising, which employs regular (non-white noise) controls through the endpoint map and naturally accommodates control constraints.
  Both approaches avoid the score blow-up seen in stochastic differential equation-based denoising methods. We establish existence of solutions to the corresponding ODEs and regularity of the induced flows on measures, even when control laws are nonsmooth.
  Finally, we illustrate the framework on linear and nonlinear systems, demonstrating its effectiveness for both measure transport and stabilization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02706v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi</dc:creator>
    </item>
    <item>
      <title>On Non-Monotone Variational Inequalities</title>
      <link>https://arxiv.org/abs/2510.02724</link>
      <description>arXiv:2510.02724v1 Announce Type: new 
Abstract: In this paper, we provide some sufficient conditions for the existence of solutions to non-monotone Variational Inequalities (VIs) based on inverse mapping theory and degree theory. We have obtained several applicable sufficient conditions for this problem and have introduced a sufficient condition for the existence of a Minty solution. We have shown that the Korpelevich and Popov methods converge to a solution of a non-monotone VI, provided that a Minty solution exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02724v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Arefizadeh, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>Quantitative Convergence Analysis of Projected Stochastic Gradient Descent for Non-Convex Losses via the Goldstein Subdifferential</title>
      <link>https://arxiv.org/abs/2510.02735</link>
      <description>arXiv:2510.02735v1 Announce Type: new 
Abstract: Stochastic gradient descent (SGD) is the main algorithm behind a large body of work in machine learning. In many cases, constraints are enforced via projections, leading to projected stochastic gradient algorithms. In recent years, a large body of work has examined the convergence properties of projected SGD for non-convex losses in asymptotic and non-asymptotic settings. Strong quantitative guarantees are available for convergence measured via Moreau envelopes. However, these results cannot be compared directly with work on unconstrained SGD, since the Moreau envelope construction changes the gradient. Other common measures based on gradient mappings have the limitation that convergence can only be guaranteed if variance reduction methods, such as mini-batching, are employed. This paper presents an analysis of projected SGD for non-convex losses over compact convex sets. Convergence is measured via the distance of the gradient to the Goldstein subdifferential generated by the constraints. Our proposed convergence criterion directly reduces to commonly used criteria in the unconstrained case, and we obtain convergence without requiring variance reduction. We obtain results for data that are independent, identically distributed (IID) or satisfy mixing conditions ($L$-mixing). In these cases, we derive asymptotic convergence and $O(N^{-1/3})$ non-asymptotic bounds in expectation, where $N$ is the number of steps. In the case of IID sub-Gaussian data, we obtain almost-sure asymptotic convergence and high-probability non-asymptotic $O(N^{-1/5})$ bounds. In particular, these are the first non-asymptotic high-probability bounds for projected SGD with non-convex losses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02735v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuping Zheng, Andrew Lamperski</dc:creator>
    </item>
    <item>
      <title>Wasserstein crossover for evolutionary algorithm-based topology optimization</title>
      <link>https://arxiv.org/abs/2510.02870</link>
      <description>arXiv:2510.02870v1 Announce Type: new 
Abstract: Evolutionary algorithms (EAs) are promising approaches for non-differentiable or strongly multimodal topology optimization problems, but they often suffer from the curse of dimensionality, generally leading to low-resolution optimized results. This limitation stems in part from the difficulty of producing effective offspring through traditional crossover operators, which struggle to recombine complex parent design features in a meaningful way. In this study, we propose a novel crossover operator for topology optimization, termed Wasserstein crossover, and develop a corresponding EA-based optimization framework. Our method leverages a morphing technique based on the Wasserstein distance -- a distance metric between probability distributions derived from the optimal transport theory. Its key idea is to treat material distributions as probability distributions and generate offspring as Wasserstein barycenters, enabling smooth and interpretable interpolation between parent designs while preserving their structural features. The proposed framework incorporates Wasserstein crossover into an EA under a multifidelity design scheme, where low-fidelity optimized initial designs evolve through iterations of Wasserstein crossover and selection based on high-fidelity evaluation. We apply the proposed framework to three topology optimization problems: maximum stress minimization in two- and three-dimensional structural mechanics, and turbulent heat transfer in two-dimensional thermofluids. The results demonstrate that candidate solutions evolve iteratively toward high-performance designs through Wasserstein crossover, highlighting its potential as an effective crossover operator and validating the usefulness of the proposed framework for solving intractable topology optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02870v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taisei Kii, Kentaro Yaji, Hiroshi Teramoto, Kikuo Fujita</dc:creator>
    </item>
    <item>
      <title>Joint Stochastic Optimal Control and Stopping in Aquaculture: Finite-Difference and PINN-Based Approaches</title>
      <link>https://arxiv.org/abs/2510.02910</link>
      <description>arXiv:2510.02910v1 Announce Type: new 
Abstract: This paper studies a joint stochastic optimal control and stopping (JCtrlOS) problem motivated by aquaculture operations, where the objective is to maximize farm profit through an optimal feeding strategy and harvesting time under stochastic price dynamics. We introduce a simplified aquaculture model capturing essential biological and economic features, distinguishing between biologically optimal and economically optimal feeding strategies. The problem is formulated as a Hamilton-Jacobi-Bellman variational inequality and corresponding free boundary problem. We develop two numerical solution approaches: First, a finite difference scheme that serves as a benchmark, and second, a Physics-Informed Neural Network (PINN)-based method, combined with a deep optimal stopping (DeepOS) algorithm to improve stopping time accuracy. Numerical experiments demonstrate that while finite differences perform well in medium-dimensional settings, the PINN approach achieves comparable accuracy and is more scalable to higher dimensions where grid-based methods become infeasible. The results confirm that jointly optimizing feeding and harvesting decisions outperforms strategies that neglect either control or stopping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02910v1</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Kamm</dc:creator>
    </item>
    <item>
      <title>Progressive Bound Strengthening via Doubly Nonnegative Cutting Planes for Nonconvex Quadratic Programs</title>
      <link>https://arxiv.org/abs/2510.02948</link>
      <description>arXiv:2510.02948v1 Announce Type: new 
Abstract: We introduce a cutting-plane framework for nonconvex quadratic programs (QPs) that progressively tightens convex relaxations. Our approach leverages the doubly nonnegative (DNN) relaxation to compute strong lower bounds and generate separating cuts, which are iteratively added to improve the relaxation. We establish that, at any Karush-Kuhn-Tucker (KKT) point satisfying a second-order sufficient condition, a valid cut can be obtained by solving a linear semidefinite program (SDP), and we devise a finite-termination local search procedure to identify such points. Extensive computational experiments on both benchmark and synthetic instances demonstrate that our approach yields tighter bounds and consistently outperforms leading commercial and academic solvers in terms of efficiency, robustness, and scalability. Notably, on a standard desktop, our algorithm reduces the relative optimality gap to 0.01% on 138 out of 140 instances of dimension 100 within one hour, without resorting to branch-and-bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02948v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Qu, Defeng Sun, Jintao Xu</dc:creator>
    </item>
    <item>
      <title>Long-Time Analysis of Stochastic Heavy Ball Dynamics for Convex Optimization and Monotone Equations</title>
      <link>https://arxiv.org/abs/2510.02951</link>
      <description>arXiv:2510.02951v1 Announce Type: new 
Abstract: In a separable real Hilbert space, we study the problem of minimizing a convex function with Lipschitz continuous gradient in the presence of noisy evaluations. To this end, we associate a stochastic Heavy Ball system, incorporating a friction coefficient, with the optimization problem. We establish existence and uniqueness of trajectory solutions for this system. Under a square integrability condition for the diffusion term, we prove almost sure convergence of the trajectory process to an optimal solution, as well as almost sure convergence of its time derivative to zero. Moreover, we derive almost sure and expected convergence rates for the function values along the trajectory towards the infimal value. Finally, we show that the stochastic Heavy Ball system is equivalent to a Su-Boyd-Cand\`{e}s-type system for a suitable choice of the parameter function, and we provide corresponding convergence rate results for the latter.
  In the second part of this paper, we extend our analysis beyond the optimization framework and investigate a monotone equation induced by a monotone and Lipschitz continuous operator, whose evaluations are assumed to be corrupted by noise. As before, we consider a stochastic Heavy Ball system with a friction coefficient and a correction term, now augmented by an additional component that accounts for the time derivative of the operator. We establish analogous convergence results for both the trajectory process and its time derivative, and derive almost sure as well as expected convergence rates for the decay of the residual and the gap function along the trajectory. As a final result, we show that a particular instance of the stochastic Heavy Ball system for monotone equations is equivalent to a stochastic second-order dynamical system with a vanishing damping term. Remarkably, this system exhibits fast convergence rates for both the residual and gap functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02951v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Ioan Bot, Chiara Schindler</dc:creator>
    </item>
    <item>
      <title>Estimating Sequences with Memory for Minimizing Convex Non-smooth Composite Functions</title>
      <link>https://arxiv.org/abs/2510.02965</link>
      <description>arXiv:2510.02965v1 Announce Type: new 
Abstract: First-order optimization methods are crucial for solving large-scale data processing problems, particularly those involving convex non-smooth composite objectives. For such problems with convex non-smooth composite objectives, we introduce a new class of generalized composite estimating sequences, devised by exploiting the information embedded in the iterates generated during the minimization process. Building on these sequences, we propose a novel accelerated first-order method tailored for such objective structures. This method features a backtracking line-search strategy and achieves an accelerated convergence rate, regardless of whether the true Lipschitz constant is known. Additionally, it exhibits robustness to imperfect knowledge of the strong convexity parameter, a property of significant practical importance. The method's efficiency and robustness are substantiated by comprehensive numerical evaluations on both synthetic and real-world datasets, demonstrating its effectiveness in data processing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02965v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Endrit Dosti, Sergiy A. Vorobyov, Themistoklis Charalambous</dc:creator>
    </item>
    <item>
      <title>Valid Inequalities for Mixed Integer Bilevel Linear Optimization Problems</title>
      <link>https://arxiv.org/abs/2510.02998</link>
      <description>arXiv:2510.02998v1 Announce Type: new 
Abstract: Despite the success of branch-and-cut methods for solving mixed integer bilevel linear optimization problems (MIBLPs) in practice, there are still gaps in both the theory and practice surrounding these methods. In the first part of this paper, we lay out a basic theory of valid inequalities and cutting-plane methods for MIBLPs that parallels the existing theory for mixed integer linear optimization problems (MILPs). We provide a general scheme for classifying valid inequalities and illustrate how the known classes of valid inequalities fit into this categorization, as well as generalizing several existing classes.
  In the second part of the paper, we assess the computational effectiveness of these valid inequalities and discuss the myriad challenges that arise in integrating methods of dynamically generating inequalities valid for MIBLPs into a branch-and-cut algorithms originally designed for solving MILPs. Although branch-and-cut methods for solving for MIBLPs are in principle straightforward generalizations of those used for MILP, there are subtle but important differences and there remain many unanswered questions regarding how to suitably modify control mechanisms and other algorithmic details in order to ensure performance in the MIBLP setting. We demonstrate that performance of version 1.2 of the open-source solver MibS was substantially improved over that of version 1.1 through a variety of improvements to the previous implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02998v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahar Tahernejad, Ted K. Ralphs</dc:creator>
    </item>
    <item>
      <title>Subgradient Methods for Nonsmooth Convex Functions with Adversarial Errors</title>
      <link>https://arxiv.org/abs/2510.03072</link>
      <description>arXiv:2510.03072v1 Announce Type: new 
Abstract: We consider minimizing nonsmooth convex functions with bounded subgradients. However, instead of directly observing a subgradient at every step $k\in [0, \dots, N-1]$, we assume that the optimizer receives an adversarially corrupted subgradient. The adversary's power is limited to a finite corruption budget, but allows the adversary to strategically time its perturbations. We show that the classical averaged subgradient descent method, which is optimal in the noiseless case, has worst-case performance that deteriorates quadratically with the corruption budget. Using performance optimization programming, (i) we construct and analyze the performance of three novel subgradient descent methods, and (ii) propose a novel lower bound on the worst-case suboptimality gap of any first-order method satisfying a mild cone condition proposed by Fatkhullin et al. (2025). The worst-case performance of each of our methods degrades only linearly with the corruption budget. Furthermore, we show that the relative difference between their worst-case suboptimality gap and our lower bound decays as $\mathcal O(\log(N)/N)$, so that all three proposed subgradient descent methods are near-optimal. Our methods achieve such near-optimal performance without a need for momentum or averaging. This suggests that these techniques are not necessary in this context, which is in line with recent results by Zamani and Glineur (2025).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03072v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martijn G\"osgens, Bart P. G. Van Parys</dc:creator>
    </item>
    <item>
      <title>Lower Bound for a Polynomial on a product of hyperellipsoids using geometric programming</title>
      <link>https://arxiv.org/abs/2510.03105</link>
      <description>arXiv:2510.03105v1 Announce Type: new 
Abstract: Let $f$ be a polynomial in $n$ variables $x_1,\dots,x_n$ with real coefficients. In [Ghasemi-Marshal], Ghasemi and Marshall give an algorithm, based on geometric programming, which computes a lower bound for $f$ on $\mathbb{R}^n$. In [Ghasemi-Lasserre-Marshall] Ghasemi, Lasserre and Marshall show how the algorithm in [Ghasemi-Marshal] can be modified to compute a lower bound for $f$ on the hyperellipsoid $\sum_{i=1}^n x_i^d \le M.$ Here $d$ is a fixed even integer, $d \ge \max\{ 2, \deg(f)\}$ and $M$ is a fixed positive real number. Suppose now that $g_j := 1-\sum_{i\in I_j} (\frac{x_i}{N_i})^d$, $j=1,\dots,m$, where $d$ is a fixed even integer $d \ge \max\{ 2, \deg(f)\}$, $N_i$ is a fixed positive real number, $i=1,\dots,n$ and $I_1,\dots, I_m$ is a fixed partition of $\{ 1,\dots,n\}$. The present paper gives an algorithm based on geometric programming for computing a lower bound for $f$ on the subset of $\mathbb{R}^n$ defined by the inequalities $g_j\ge 0$, $j=1,\dots,m$. The algorithm is implemented in a SAGE program developed by the first author. The bound obtained is typically not as sharp as the bound obtained using semidefinite programming, but it has the advantage that it is computable rapidly, even in cases where the bound obtained by semidefinite programming is not computable. When $m=1$ and $N_i = \root d \of{M}$, $i=1,\dots,n$ the algorithm produces the lower bound obtained in [Ghasemi-Lasserre-Marshall]. When $m=n$ and $I_j = \{ j \}$, $j=1,\dots,n$ the algorithm produces a lower bound for $f$ on the hypercube $\prod_{i=1}^n [-N_i,N_i]$, which in certain cases can be computed by a simple formula.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03105v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehdi Ghasemi, Murray Marshall</dc:creator>
    </item>
    <item>
      <title>Improving Online-to-Nonconvex Conversion for Smooth Optimization via Double Optimism</title>
      <link>https://arxiv.org/abs/2510.03167</link>
      <description>arXiv:2510.03167v2 Announce Type: new 
Abstract: A recent breakthrough in nonconvex optimization is the online-to-nonconvex conversion framework of [Cutkosky et al., 2023], which reformulates the task of finding an $\varepsilon$-first-order stationary point as an online learning problem. When both the gradient and the Hessian are Lipschitz continuous, instantiating this framework with two different online learners achieves a complexity of $O(\varepsilon^{-1.75}\log(1/\varepsilon))$ in the deterministic case and a complexity of $O(\varepsilon^{-3.5})$ in the stochastic case. However, this approach suffers from several limitations: (i) the deterministic method relies on a complex double-loop scheme that solves a fixed-point equation to construct hint vectors for an optimistic online learner, introducing an extra logarithmic factor; (ii) the stochastic method assumes a bounded second-order moment of the stochastic gradient, which is stronger than standard variance bounds; and (iii) different online learning algorithms are used in the two settings. In this paper, we address these issues by introducing an online optimistic gradient method based on a novel doubly optimistic hint function. Specifically, we use the gradient at an extrapolated point as the hint, motivated by two optimistic assumptions: that the difference between the hint and the target gradient remains near constant, and that consecutive update directions change slowly due to smoothness. Our method eliminates the need for a double loop and removes the logarithmic factor. Furthermore, by simply replacing full gradients with stochastic gradients and under the standard assumption that their variance is bounded by $\sigma^2$, we obtain a unified algorithm with complexity $O(\varepsilon^{-1.75} + \sigma^2 \varepsilon^{-3.5})$, smoothly interpolating between the best-known deterministic rate and the optimal stochastic rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03167v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Patitucci, Ruichen Jiang, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>ProxSTORM -- A Stochastic Trust-Region Algorithm for Nonsmooth Optimization</title>
      <link>https://arxiv.org/abs/2510.03187</link>
      <description>arXiv:2510.03187v1 Announce Type: new 
Abstract: We develop a stochastic trust-region algorithm for minimizing the sum of a possibly nonconvex Lipschitz-smooth function that can only be evaluated stochastically and a nonsmooth, deterministic, convex function. This algorithm, which we call ProxSTORM, generalizes STORM [1, 2] -- a stochastic trust-region algorithm for the unconstrained optimization of smooth functions -- and the inexact deterministic proximal trust-region algorithm in [3]. We generalize and, in some cases, simplify problem assumptions so that they reduce to more succinct version of assumptions on STORM when the convex term is zero. Our analysis follows the STORM framework by employing martingales, but again simplifies certain steps and proving global convergence and an expected complexity bound in the more general setting of a possibly nonsmooth term. To demonstrate that the method is numerically viable, we apply the algorithm to $\ell^1$-regularized neural network training and also to topology optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03187v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert J. Baraldi, Aurya Javeed, Drew P. Kouri, Katya Scheinberg</dc:creator>
    </item>
    <item>
      <title>Data-Driven Stochastic Distribution System Hardening Based on Bayesian Online Learning</title>
      <link>https://arxiv.org/abs/2510.02485</link>
      <description>arXiv:2510.02485v1 Announce Type: cross 
Abstract: Extreme weather frequently cause widespread outages in distribution systems (DSs), demonstrating the importance of hardening strategies for resilience enhancement. However, the well-utilization of real-world outage data with associated weather conditions to make informed hardening decisions in DSs is still an open issue. To bridge this research gap, this paper proposes a data-driven stochastic distribution line (DL) hardening strategy. First, a deep neural network (DNN) regression model is developed to predict the probabilistic evolution of outage scenarios under various hardening decisions. Based on the DNN predictions, the problem is formulated as a decision-dependent distributionally robust optimization (DRO) model, accounting for uncertainties in outage scenario distributions using a data-driven ambiguity set. To address decision-dependent uncertainty, a Bayesian online learning algorithm is proposed. This algorithm decomposes the original problem into inner and outer problems. Then, it iteratively refines hardening decisions by sequentially incorporating outage data and dynamically updating decision-specific ambiguity sets by using Bayes' theorem and Bayesian Inference. Also, the convergence of the algorithm is proven through dynamic regret analysis. Finally, case studies are implemented on a real-world DS in Redfield, Iowa, USA. A dataset spanning 24 years (2001-2024) is constructed based on the utility outage records. The simulation results validates the effectiveness of the proposed strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02485v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Shi, Hongyi Li, Zhaoyu Wang</dc:creator>
    </item>
    <item>
      <title>Situationally Aware Rolling Horizon Multi-Tier Load Restoration Considering Behind-The-Meter DER</title>
      <link>https://arxiv.org/abs/2510.02502</link>
      <description>arXiv:2510.02502v1 Announce Type: cross 
Abstract: Restoration in power distribution systems (PDSs) is well studied, however, most existing research focuses on network partition and microgrid formation, where load transfer is limited to adjacent feeders. This focus is not practical, as when adjacent feeders lack sufficient capacity, utilities may request support from more distant feeders in practice. Such a hirarchical restoration is complex, especially when involving changing system conditions due to cold load pickup and delayed reconnection of behind-the-meter DERs. To fill this research gap, a situationally aware multi-tier load restoration framework is proposed. Specifically, models are proposed to describe the multi-tier load restoration, including the multi-tier load transfer and substation transformer and feeder protection models. By introducing binary actional switching variables and load block transfer variables, the models effectively captures the dynamics of switches and multi-tier transfer process. To integrate situational awareness of evolving system conditions, the problem is formulated as a mixed-integer linear program (MILP) and then embedded within a rolling horizon optimization. Particularly, a set of safeguarded constraints are developed based on segment-level restoration reward bounds to mitigate the myopia of traditional rolling horizon optimization. The proposed safeguarded rolling strategy guarantees that each time step is lower bounded by a $(1-\varepsilon)$-fraction of its optimal restoration potential, thereby balancing short-term switching decisions with long-term restoration goals. Finally, cases studies on the modified IEEE 123-node test feeder validate the proposed multi-tier restoration framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02502v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Shi, Junyuan Zheng, Zhaoyu Wang</dc:creator>
    </item>
    <item>
      <title>In-memory Training on Analog Devices with Limited Conductance States via Multi-tile Residual Learning</title>
      <link>https://arxiv.org/abs/2510.02516</link>
      <description>arXiv:2510.02516v1 Announce Type: cross 
Abstract: Analog in-memory computing (AIMC) accelerators enable efficient deep neural network computation directly within memory using resistive crossbar arrays, where model parameters are represented by the conductance states of memristive devices. However, effective in-memory training typically requires at least 8-bit conductance states to match digital baselines. Realizing such fine-grained states is costly and often requires complex noise mitigation techniques that increase circuit complexity and energy consumption. In practice, many promising memristive devices such as ReRAM offer only about 4-bit resolution due to fabrication constraints, and this limited update precision substantially degrades training accuracy. To enable on-chip training with these limited-state devices, this paper proposes a \emph{residual learning} framework that sequentially learns on multiple crossbar tiles to compensate the residual errors from low-precision weight updates. Our theoretical analysis shows that the optimality gap shrinks with the number of tiles and achieves a linear convergence rate. Experiments on standard image classification benchmarks demonstrate that our method consistently outperforms state-of-the-art in-memory analog training strategies under limited-state settings, while incurring only moderate hardware overhead as confirmed by our cost analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02516v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jindan Li, Zhaoxian Wu, Gaowen Liu, Tayfun Gokmen, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Self-supervised diffusion model fine-tuning for costate initialization using Markov chain Monte Carlo</title>
      <link>https://arxiv.org/abs/2510.02527</link>
      <description>arXiv:2510.02527v1 Announce Type: cross 
Abstract: Global search and optimization of long-duration, low-thrust spacecraft trajectories with the indirect method is challenging due to a complex solution space and the difficulty of generating good initial guesses for the costate variables. This is particularly true in multibody environments. Given data that reveals a partial Pareto optimal front, it is desirable to find a flexible manner in which the Pareto front can be completed and fronts for related trajectory problems can be found. In this work we use conditional diffusion models to represent the distribution of candidate optimal trajectory solutions. We then introduce into this framework the novel approach of using Markov Chain Monte Carlo algorithms with self-supervised fine-tuning to achieve the aforementioned goals. Specifically, a random walk Metropolis algorithm is employed to propose new data that can be used to fine-tune the diffusion model using a reward-weighted training based on efficient evaluations of constraint violations and missions objective functions. The framework removes the need for separate focused and often tedious data generation phases. Numerical experiments are presented for two problems demonstrating the ability to improve sample quality and explicitly target Pareto optimality based on the theory of Markov chains. The first problem does so for a transfer in the Jupiter-Europa circular restricted three-body problem, where the MCMC approach completes a partial Pareto front. The second problem demonstrates how a dense and superior Pareto front can be generated by the MCMC self-supervised fine-tuning method for a Saturn-Titan transfer starting from the Jupiter-Europa case versus a separate dedicated global search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02527v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannik Graebner, Ryne Beeson</dc:creator>
    </item>
    <item>
      <title>Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC</title>
      <link>https://arxiv.org/abs/2510.02584</link>
      <description>arXiv:2510.02584v1 Announce Type: cross 
Abstract: This paper presents a data-driven model predictive control framework for mobile robots navigating in dynamic environments, leveraging Koopman operator theory. Unlike the conventional Koopman-based approaches that focus on the linearization of system dynamics only, our work focuses on finding a global linear representation for the optimal path planning problem that includes both the nonlinear robot dynamics and collision-avoidance constraints. We deploy extended dynamic mode decomposition to identify linear and bilinear Koopman realizations from input-state data. Our open-loop analysis demonstrates that only the bilinear Koopman model can accurately capture nonlinear state-input couplings and quadratic terms essential for collision avoidance, whereas linear realizations fail to do so. We formulate a quadratic program for the robot path planning in the presence of moving obstacles in the lifted space and determine the optimal robot action in an MPC framework. Our approach is capable of finding the safe optimal action 320 times faster than a nonlinear MPC counterpart that solves the path planning problem in the original state space. Our work highlights the potential of bilinear Koopman realizations for linearization of highly nonlinear optimal control problems subject to nonlinear state and input constraints to achieve computational efficiency similar to linear problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02584v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abtahi, Navid Mojahed, Shima Nazari</dc:creator>
    </item>
    <item>
      <title>Error estimates for finite-dimensional approximations of Hamilton-Jacobi-Bellman equations on the Wasserstein space</title>
      <link>https://arxiv.org/abs/2510.02652</link>
      <description>arXiv:2510.02652v1 Announce Type: cross 
Abstract: In this paper, we study a Hamilton-Jacobi-Bellman (HJB) equation set on the Wasserstein space $\mathcal{P}_2(\mathbb{R}^d)$, with a second order term arising from a purely common noise. We do not assume that the Hamiltonian is convex in the momentum variable, which means that we cannot rely on representation formulas coming from mean field control. In this setting, Gangbo, Mayorga, and \'Swi\k{e}ch showed via viscosity solutions methods that the HJB equation on $\mathcal{P}_2(\mathbb{R}^d)$ can be approximated by a sequence of finite-dimensional HJB equations. Our main contribution is to quantify this convergence result. The proof involves a doubling of variables argument, which leverages the Hilbertian approach of P.L. Lions for HJB equations in the Wasserstein space, rather than working with smooth metrics which have been used to obtain similar results in the presence of idiosyncratic noise. In dimension one, our doubling of variables argument is made relatively simply by the rigid structure of one-dimensional optimal transport, but in higher dimension the argument is significantly more complicated, and relies on some estimates concerning the "simultaneous quantization" of probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02652v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Daudin, Joe Jackson, Benjamin Seeger</dc:creator>
    </item>
    <item>
      <title>Optimal Characteristics of Inspection Vehicle for Drive-by Bridge Inspection</title>
      <link>https://arxiv.org/abs/2510.02658</link>
      <description>arXiv:2510.02658v1 Announce Type: cross 
Abstract: Drive-by inspection for bridge health monitoring has gained increasing attention over the past decade. This method involves analysing the coupled vehicle-bridge response, recorded by an instrumented inspection vehicle, to assess structural integrity and detect damage. However, the vehicles mechanical and dynamic properties significantly influence detection performance, limiting the effectiveness of the approach. This study presents a framework for optimising the inspection vehicle to enhance damage sensitivity. An unsupervised deep learning methodbased on adversarial autoencoders (AAE)is used to reconstruct the frequency-domain representation of acceleration responses. The mass and stiffness of the tyre suspension system of a two-axle vehicle are optimised by minimising the Wasserstein distance between damage index distributions for healthy and damaged bridge states. A Kriging meta-model is employed to approximate this objective function efficiently and identify optimal vehicle configurations in both dimensional and non-dimensional parameter spaces. Results show that vehicles with frequency ratios between 0.3 and 0.7 relative to the bridges' first natural frequency are most effective, while those near resonance perform poorly. Lighter vehicles require lower natural frequencies for optimal detection. This is the first study to rigorously optimise the sensing platform for drive-by sensing and to propose a purpose-built inspection vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02658v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Calderon Hurtado, E. Atroshchenko, K. C. Chang, C. W. Kim, M. Makki Alamdari</dc:creator>
    </item>
    <item>
      <title>Delay-Tolerant Augmented-Consensus-based Distributed Directed Optimization</title>
      <link>https://arxiv.org/abs/2510.02889</link>
      <description>arXiv:2510.02889v1 Announce Type: cross 
Abstract: Distributed optimization finds applications in large-scale machine learning, data processing and classification over multi-agent networks. In real-world scenarios, the communication network of agents may encounter latency that may affect the convergence of the optimization protocol. This paper addresses the case where the information exchange among the agents (computing nodes) over data-transmission channels (links) might be subject to communication time-delays, which is not well addressed in the existing literature. Our proposed algorithm improves the state-of-the-art by handling heterogeneous and arbitrary but bounded and fixed (time-invariant) delays over general strongly-connected directed networks. Arguments from matrix theory, algebraic graph theory, and augmented consensus formulation are applied to prove the convergence to the optimal value. Simulations are provided to verify the results and compare the performance with some existing delay-free algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02889v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Narahari Kasagatta Ramesh, Alireza Aghasi</dc:creator>
    </item>
    <item>
      <title>Oracle-based Uniform Sampling from Convex Bodies</title>
      <link>https://arxiv.org/abs/2510.02983</link>
      <description>arXiv:2510.02983v1 Announce Type: cross 
Abstract: We propose new Markov chain Monte Carlo algorithms to sample a uniform distribution on a convex body $K$. Our algorithms are based on the Alternating Sampling Framework/proximal sampler, which uses Gibbs sampling on an augmented distribution and assumes access to the so-called restricted Gaussian oracle (RGO). The key contribution of this work is the efficient implementation of RGO for uniform sampling on $K$ via rejection sampling and access to either a projection oracle or a separation oracle on $K$. In both oracle cases, we establish non-asymptotic complexities to obtain unbiased samples where the accuracy is measured in R\'enyi divergence or $\chi^2$-divergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02983v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thanh Dang, Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>A Dimension-Decomposed Learning Framework for Online Disturbance Identification in Quadrotor SE(3) Control</title>
      <link>https://arxiv.org/abs/2510.03100</link>
      <description>arXiv:2510.03100v1 Announce Type: cross 
Abstract: Quadrotor stability under complex dynamic disturbances and model uncertainties poses significant challenges. One of them remains the underfitting problem in high-dimensional features, which limits the identification capability of current learning-based methods. To address this, we introduce a new perspective: Dimension-Decomposed Learning (DiD-L), from which we develop the Sliced Adaptive-Neuro Mapping (SANM) approach for geometric control. Specifically, the high-dimensional mapping for identification is axially ``sliced" into multiple low-dimensional submappings (``slices"). In this way, the complex high-dimensional problem is decomposed into a set of simple low-dimensional tasks addressed by shallow neural networks and adaptive laws. These neural networks and adaptive laws are updated online via Lyapunov-based adaptation without any pre-training or persistent excitation (PE) condition. To enhance the interpretability of the proposed approach, we prove that the full-state closed-loop system exhibits arbitrarily close to exponential stability despite multi-dimensional time-varying disturbances and model uncertainties. This result is novel as it demonstrates exponential convergence without requiring pre-training for unknown disturbances and specific knowledge of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03100v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhua Gao</dc:creator>
    </item>
    <item>
      <title>Why Do We Need Warm-up? A Theoretical Perspective</title>
      <link>https://arxiv.org/abs/2510.03164</link>
      <description>arXiv:2510.03164v1 Announce Type: cross 
Abstract: Learning rate warm-up - increasing the learning rate at the beginning of training - has become a ubiquitous heuristic in modern deep learning, yet its theoretical foundations remain poorly understood. In this work, we provide a principled explanation for why warm-up improves training. We rely on a generalization of the $(L_0, L_1)$-smoothness condition, which bounds local curvature as a linear function of the loss sub-optimality and exhibits desirable closure properties. We demonstrate both theoretically and empirically that this condition holds for common neural architectures trained with mean-squared error and cross-entropy losses. Under this assumption, we prove that Gradient Descent with a warm-up schedule achieves faster convergence than with a fixed step-size, establishing upper and lower complexity bounds. Finally, we validate our theoretical insights through experiments on language and vision models, confirming the practical benefits of warm-up schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03164v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Foivos Alimisis, Rustem Islamov, Aurelien Lucchi</dc:creator>
    </item>
    <item>
      <title>Linear-quadratic mean-field-type difference games with coupled affine inequality constraints</title>
      <link>https://arxiv.org/abs/2303.07824</link>
      <description>arXiv:2303.07824v4 Announce Type: replace 
Abstract: In this letter, we study a class of linear-quadratic mean-field-type difference games with coupled affine inequality constraints. We show that the mean-field-type equilibrium can be characterized by the existence of a multiplier process which satisfies some implicit complementarity conditions. Further, we show that the equilibrium strategies can be computed by reformulating these conditions as a single large-scale linear complementarity problem. We illustrate our results with an energy storage problem arising in the management of microgrids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.07824v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Partha Sarathi Mohapatra, Puduru Viswanadha Reddy</dc:creator>
    </item>
    <item>
      <title>Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method</title>
      <link>https://arxiv.org/abs/2402.08992</link>
      <description>arXiv:2402.08992v2 Announce Type: replace 
Abstract: High-probability guarantees in stochastic optimization are often obtained only under strong noise assumptions such as sub-Gaussian tails. We show that such guarantees can also be achieved under the weaker assumption of bounded variance by developing a stochastic proximal point method. This method combines a proximal subproblem solver, which inherently reduces variance, with a probability booster that amplifies per-iteration reliability into high-confidence results. The analysis demonstrates convergence with low sample complexity, without restrictive noise assumptions or reliance on mini-batching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08992v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Deterministic and Stochastic Frank-Wolfe Recursion on Probability Spaces</title>
      <link>https://arxiv.org/abs/2407.00307</link>
      <description>arXiv:2407.00307v2 Announce Type: replace 
Abstract: Motivated by applications in emergency response and experimental design, we consider smooth stochastic optimization problems over probability measures supported on compact subsets of the Euclidean space. With the influence function as the variational object, we construct a deterministic Frank-Wolfe (dFW) recursion for probability spaces, made especially possible by a lemma that identifies a ``closed-form'' solution to the infinite-dimensional Frank-Wolfe sub-problem. Each iterate in dFW is expressed as a convex combination of the incumbent iterate and a Dirac measure concentrating on the minimum of the influence function at the incumbent iterate. To address common application contexts that have access only to Monte Carlo observations of the objective and influence function, we construct a stochastic Frank-Wolfe (sFW) variation that generates a random sequence of probability measures constructed using minima of increasingly accurate estimates of the influence function. We demonstrate that sFW's optimality gap sequence exhibits $O(k^{-1})$ iteration complexity almost surely and in expectation for smooth convex objectives, and $O(k^{-1/2})$ (in Frank-Wolfe gap) for smooth non-convex objectives. Furthermore, we show that an easy-to-implement fixed-step, fixed-sample version of (sFW) exhibits exponential convergence to $\varepsilon$-optimality. We end with a central limit theorem on the observed objective values at the sequence of generated random measures. To further intuition, we include several illustrative examples with exact influence function calculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00307v2</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/moor.2024.0584</arxiv:DOI>
      <dc:creator>Di Yu, Shane G. Henderson, Raghu Pasupathy</dc:creator>
    </item>
    <item>
      <title>A Tunneling Method for Nonlinear Multi-objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2407.04436</link>
      <description>arXiv:2407.04436v2 Announce Type: replace 
Abstract: In this paper, a tunneling method is developed for nonlinear multiobjective optimization problems using some ideas of the single objective tunneling method. The proposed method does not require any a priori chosen parameters or ordering information of the objective functions. At any critical point, an auxiliary function is developed to find a different critical point that dominates the previous one. By repeatedly applying the tunneling procedure, it is possible to construct a broader approximation to the global Pareto front in nonconvex multi-objective optimization problems that may contain multiple local Pareto fronts. An algorithm is then designed based on this auxiliary function, and the convergence of this algorithm is justified under some mild assumptions. Finally, several numerical examples are presented to illustrate the effectiveness of the proposed method and to justify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04436v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Annals of Mathematical Sciences and Applications, 2026</arxiv:journal_reference>
      <dc:creator>Bikram Adhikary, Md Abu Talhamainuddin Ansary</dc:creator>
    </item>
    <item>
      <title>Assortment Optimization under the Multinomial Logit Model with Covering Constraints</title>
      <link>https://arxiv.org/abs/2411.10310</link>
      <description>arXiv:2411.10310v2 Announce Type: replace 
Abstract: We consider an assortment optimization problem under the multinomial logit choice model with general covering constraints. In this problem, the seller offers an assortment that should contain a minimum number of products from multiple categories. We refer to these constraints as covering constraints. Such constraints are common in practice due to service level agreements with suppliers or diversity considerations within the assortment. We consider both the deterministic version, where the seller decides on a single assortment, and the randomized version, where they choose a distribution over assortments. In the deterministic case, we provide a $1/(\log K+2)$-approximation algorithm, where $K$ is the number of product categories, matching the problem's hardness up to a constant factor. For the randomized setting, we show that the problem is solvable in polynomial time via an equivalent linear program. We also extend our analysis to multi-segment assortment optimization with covering constraints, where there are $m$ customer segments, and an assortment is offered to each. In the randomized setting, the problem remains polynomially solvable. In the deterministic setting, we design a $(1 - \epsilon) / (\log K + 2)$-approximation algorithm for constant $m$ and a $1 / (m (\log K + 2))$-approximation for general $m$, which matches the hardness up to a logarithmic factor. Finally, we conduct a numerical experiment using real data from an online electronics store, categorizing products by price range and brand. Our findings demonstrate that, in practice, it is feasible to enforce a minimum number of representatives from each category while incurring a relatively small revenue loss. Moreover, we observe that the optimal expected revenue in both deterministic and randomized settings is often comparable, and the optimal solution in the randomized setting typically involves only a few assortments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10310v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar El Housni, Qing Feng, Huseyin Topaloglu</dc:creator>
    </item>
    <item>
      <title>Sparse Polynomial Optimization with Matrix Constraints</title>
      <link>https://arxiv.org/abs/2411.18820</link>
      <description>arXiv:2411.18820v2 Announce Type: replace 
Abstract: This paper studies the hierarchy of sparse matrix Moment-SOS relaxations for solving sparse polynomial optimization problems with matrix constraints. First, we prove a sufficient and necessary condition for the sparse hierarchy to be tight. Second, we discuss how to detect the tightness and extract minimizers. Third, for the convex case, we show that the hierarchy of the sparse matrix Moment-SOS relaxations is tight, under some general assumptions. In particular, we show that the sparse matrix Moment-SOS relaxation is tight for every order when the problem is SOS-convex. Numerical experiments are provided to show the efficiency of the sparse relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18820v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawang Nie, Zheng Qu, Xindong Tang, Linghao Zhang</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Covariance Steering for Discrete-Time Markov Jump Linear Systems</title>
      <link>https://arxiv.org/abs/2503.13675</link>
      <description>arXiv:2503.13675v4 Announce Type: replace 
Abstract: In this paper, we solve the chance-constrained covariance steering problem for discrete-time Markov Jump Linear Systems (MJLS) using a convex optimization framework. We derive the analytical expressions for the mean and covariance trajectories of time-varying discrete-time MJLS and show that they cannot be separated even without chance constraints, unlike the single-mode dynamics case. To solve the covariance steering problem, we propose a two-step convex optimization framework, which optimizes the mean and covariance subproblems sequentially. Further, we incorporate chance constraints and propose an iterative optimization framework to solve the chance-constrained covariance steering problem. Both problems are originally nonconvex, and we derive convex relaxations which are proved to be lossless at optimality using the Karush-Kuhn-Tucker (KKT) conditions. Numerical simulations demonstrate the proposed method by achieving target covariances while respecting chance constraints under additive noise, bias, and Markovian jump dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13675v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaurya Shrivastava, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Online Feedback Optimization for Monotone Systems without Timescale Separation</title>
      <link>https://arxiv.org/abs/2506.16564</link>
      <description>arXiv:2506.16564v2 Announce Type: replace 
Abstract: Online Feedback Optimization (OFO) steers a dynamical plant to a cost-efficient steady-state, only relying on input-output sensitivity information, rather than on a full plant model. Unlike traditional feedforward approaches, OFO leverages real-time measurements from the plant, thereby inheriting the robustness and adaptability of feedback control. Unfortunately, existing theoretical guarantees for OFO assume that the controller operates on a slower timescale than the plant, which can affect responsiveness and transient performance. In this paper, we focus on relaxing this ``timescale separation'' assumption. Specifically, we consider the class of monotone systems, and we prove that OFO can achieve an optimal operating point, regardless of the time constants of controller and plant. By leveraging a small gain theorem for monotone systems, we derive several sufficient conditions for global convergence. Notably, these conditions depend only on the steady-state behavior of the plant, and they are entirely independent of the transient dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16564v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mattia Bianchi, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Convergence rates for regularized unbalanced optimal transport: the discrete case</title>
      <link>https://arxiv.org/abs/2507.07917</link>
      <description>arXiv:2507.07917v2 Announce Type: replace 
Abstract: Unbalanced optimal transport (UOT) is a natural extension of optimal transport (OT) allowing comparison between measures of different masses. It arises naturally in machine learning by offering a robustness against outliers. The aim of this work is to provide convergence rates of the regularized transport cost and plans towards their original solution when both measures are weighted sums of Dirac masses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07917v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Nenna, Paul Pegon, Louis Tocquec</dc:creator>
    </item>
    <item>
      <title>Preconditioned subgradient method for composite optimization: overparameterization and fast convergence</title>
      <link>https://arxiv.org/abs/2509.11486</link>
      <description>arXiv:2509.11486v2 Announce Type: replace 
Abstract: Composite optimization problems involve minimizing the composition of a smooth map with a convex function. Such objectives arise in numerous data science and signal processing applications, including phase retrieval, blind deconvolution, and collaborative filtering. The subgradient method achieves local linear convergence when the composite loss is well-conditioned. However, if the smooth map is, in a certain sense, ill-conditioned or overparameterized, the subgradient method exhibits much slower sublinear convergence even when the convex function is well-conditioned. To overcome this limitation, we introduce a Levenberg-Morrison-Marquardt subgradient method that converges linearly under mild regularity conditions at a rate determined solely by the convex function. Further, we demonstrate that these regularity conditions hold for several problems of practical interest, including square-variable formulations, matrix sensing, and tensor factorization. Numerical experiments illustrate the benefits of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11486v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateo D\'iaz, Liwei Jiang, Abdel Ghani Labassi</dc:creator>
    </item>
    <item>
      <title>When Location Shapes Choice: Placement Optimization of Substitutable Products</title>
      <link>https://arxiv.org/abs/2310.08568</link>
      <description>arXiv:2310.08568v4 Announce Type: replace-cross 
Abstract: Strategic product placement can have a strong influence on customer purchase behavior in physical stores as well as online platforms. Motivated by this, we consider the problem of optimizing the placement of substitutable products in designated display locations to maximize the expected revenue of the seller. We model the customer behavior as a two-stage process: first, the customer visits a subset of display locations according to a browsing distribution; second, the customer chooses at most one product from the displayed products at those locations according to a choice model. Our goal is to design a general algorithm that can select and place the products optimally for any browsing distribution and choice model, and we call this the Placement problem. We give a randomized algorithm that utilizes an $\alpha$-approximate algorithm for cardinality constrained assortment optimization and outputs a $\frac{\Theta(\alpha)}{\log m}$-approximate solution (in expectation) for Placement with $m$ display locations, i.e., our algorithm outputs a solution with value at least $\frac{\Omega(\alpha)}{\log m}$ factor of the optimal and this is tight in the worst case. We also give algorithms with stronger guarantees in some special cases. In particular, we give a deterministic $\frac{\Omega(1)}{\log m}$-approximation algorithm for the Markov choice model, and a tight $(1-1/e)$-approximation algorithm for the problem when products have identical prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08568v4</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar El Housni, Rajan Udwani</dc:creator>
    </item>
    <item>
      <title>A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation</title>
      <link>https://arxiv.org/abs/2311.15238</link>
      <description>arXiv:2311.15238v2 Announce Type: replace-cross 
Abstract: The exploration-exploitation dilemma has been a central challenge in reinforcement learning (RL) with complex model classes. In this paper, we propose a new algorithm, Monotonic Q-Learning with Upper Confidence Bound (MQL-UCB) for RL with general function approximation. Our key algorithmic design includes (1) a general deterministic policy-switching strategy that achieves low switching cost, (2) a monotonic value function structure with carefully controlled function class complexity, and (3) a variance-weighted regression scheme that exploits historical trajectories with high data efficiency. MQL-UCB achieves minimax optimal regret of $\tilde{O}(d\sqrt{HK})$ when $K$ is sufficiently large and near-optimal policy switching cost of $\tilde{O}(dH)$, with $d$ being the eluder dimension of the function class, $H$ being the planning horizon, and $K$ being the number of episodes.
  Our work sheds light on designing provably sample-efficient and deployment-efficient Q-learning with nonlinear function approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15238v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heyang Zhao, Jiafan He, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Exponential Utility Maximization with Delay in a Continuous Time Gaussian Framework</title>
      <link>https://arxiv.org/abs/2311.17270</link>
      <description>arXiv:2311.17270v5 Announce Type: replace-cross 
Abstract: In this work we study the continuous time exponential utility maximization problem in the framework of an investor who is informed about the price changes with a delay. This leads to a non-Markovian stochastic control problem. In the case where the risky asset is given by a Gaussian process (with some additional properties) we establish a solution for the optimal control and the corresponding value. Our approach is purely probabilistic and is based on the theory for Radon-Nikodym derivatives of Gaussian measures developed by Shepp [6] and Hitsuda [5].</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17270v5</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Dolinsky</dc:creator>
    </item>
    <item>
      <title>A semiconcavity approach to stability of entropic plans and exponential convergence of Sinkhorn's algorithm</title>
      <link>https://arxiv.org/abs/2412.09235</link>
      <description>arXiv:2412.09235v2 Announce Type: replace-cross 
Abstract: We study stability of optimizers and convergence of Sinkhorn's algorithm for the entropic optimal transport problem. In the special case of the quadratic cost, our stability bounds imply that if one of the two entropic potentials is semiconcave, then the relative entropy between optimal plans is controlled by the squared Wasserstein distance between their marginals. When employed in the analysis of Sinkhorn's algorithm, this result gives a natural sufficient condition for its exponential convergence, which does not require the ground cost to be bounded. By controlling from above the Hessians of Sinkhorn potentials in examples of interest, we obtain new exponential convergence results. For instance, for the first time we obtain exponential convergence for log-concave marginals and quadratic costs for all values of the regularization parameter, based on semiconcavity propagation results. Moreover, the convergence rate has a linear dependence on the regularization: this behavior is sharp and had only been previously obtained for compact distributions arXiv:2407.01202. These optimal rates are also established in situations where one of the two marginals does not have subgaussian tails. Other interesting new applications include subspace elastic costs, weakly log-concave marginals, marginals with light tails (where, under reinforced assumptions, we manage to improve the rates obtained in arXiv:2311.04041), the case of Lipschitz costs with bounded Hessian, and compact Riemannian manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09235v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Chiarini, Giovanni Conforti, Giacomo Greco, Luca Tamanini</dc:creator>
    </item>
    <item>
      <title>Optimal Modified Feedback Strategies in LQ Games under Control Imperfections</title>
      <link>https://arxiv.org/abs/2503.19200</link>
      <description>arXiv:2503.19200v2 Announce Type: replace-cross 
Abstract: Game-theoretic approaches and Nash equilibrium have been widely applied across various engineering domains. However, practical challenges such as disturbances, delays, and actuator limitations can hinder the precise execution of Nash equilibrium strategies. This work investigates the impact of such implementation imperfections on game trajectories and players' costs in the context of a two-player finite-horizon linear quadratic (LQ) nonzero-sum game. Specifically, we analyze how small deviations by one player, measured or estimated at each stage, affect the state and cost function of the other player. To mitigate these effects, we propose an adjusted control policy that optimally compensates for the deviations under the stated information structure and can, under certain conditions, exploit them to improve performance. Rigorous mathematical analysis and proofs are provided, and the effectiveness of the proposed method is demonstrated through a representative numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19200v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdis Rabbani, Navid Mojahed, Shima Nazari</dc:creator>
    </item>
    <item>
      <title>Iteratively reweighted kernel machines efficiently learn sparse functions</title>
      <link>https://arxiv.org/abs/2505.08277</link>
      <description>arXiv:2505.08277v2 Announce Type: replace-cross 
Abstract: The impressive practical performance of neural networks is often attributed to their ability to learn low-dimensional data representations and hierarchical structure directly from data. In this work, we argue that these two phenomena are not unique to neural networks, and can be elicited from classical kernel methods. Namely, we show that the derivative of the kernel predictor can detect the influential coordinates with low sample complexity. Moreover, by iteratively using the derivatives to reweight the data and retrain kernel machines, one is able to efficiently learn hierarchical polynomials with finite leap complexity. Numerical experiments illustrate the developed theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08277v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Libin Zhu, Damek Davis, Dmitriy Drusvyatskiy, Maryam Fazel</dc:creator>
    </item>
    <item>
      <title>On the $O(\frac{\sqrt{d}}{K^{1/4}})$ Convergence Rate of AdamW Measured by $\ell_1$ Norm</title>
      <link>https://arxiv.org/abs/2505.11840</link>
      <description>arXiv:2505.11840v3 Announce Type: replace-cross 
Abstract: As the default optimizer for training large language models, AdamW has achieved remarkable success in deep learning. However, its convergence behavior is not theoretically well-understood. This paper establishes the convergence rate $\frac{1}{K}\sum_{k=1}^KE\left[||\nabla f(x^k)||_1\right]\leq O(\frac{\sqrt{d}C}{K^{1/4}})$ for AdamW measured by $\ell_1$ norm, where $K$ represents the iteration number, $d$ denotes the model dimension, and $C$ matches the constant in the optimal convergence rate of SGD. Theoretically, we have $||\nabla f(x)||_2\ll ||\nabla f(x)||_1\leq \sqrt{d}||\nabla f(x)||_2$ for any high-dimensional vector $x$ and $E\left[||\nabla f(x)||_1\right]\geq\sqrt{\frac{2d}{\pi}}E\left[||\nabla f(x)||_2\right]$ when each element of $\nabla f(x)$ is generated from Gaussian distribution $\mathcal N(0,1)$. Empirically, our experimental results on real-world deep learning tasks reveal $||\nabla f(x)||_1=\varTheta(\sqrt{d})||\nabla f(x)||_2$. Both support that our convergence rate can be considered to be analogous to the optimal $\frac{1}{K}\sum_{k=1}^KE\left[||\nabla f(x^k)||_2\right]\leq O(\frac{C}{K^{1/4}})$ convergence rate of SGD in the ideal case. We also extend our result to NAdamW, an AdamW variant that employs a double-momentum mechanism, and demonstrate that it maintains the same convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11840v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huan Li, Yiming Dong, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Two-point boundary value problems for quasi-monotone dynamical systems</title>
      <link>https://arxiv.org/abs/2508.01305</link>
      <description>arXiv:2508.01305v2 Announce Type: replace-cross 
Abstract: This paper studies the existence of minimal solutions to two-point boundary value problems for quasi-monotone dynamical systems. Specifically, the pointwise infimum of all supersolutions is shown to coincide with the minimal solution. This result is then applied to establish a non-uniqueness result for strong stable solutions to a class of mean field games with a continuum of players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01305v2</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorena Bociu, Madhumita Roy, Khai T. Nguyen</dc:creator>
    </item>
    <item>
      <title>Sharpness of Minima in Deep Matrix Factorization: Exact Expressions</title>
      <link>https://arxiv.org/abs/2509.25783</link>
      <description>arXiv:2509.25783v2 Announce Type: replace-cross 
Abstract: Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff &amp; Michaeli (2020). To complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25783v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anil Kamber, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>Exactly or Approximately Wasserstein Distributionally Robust Estimation According to Wasserstein Radii Being Small or Large</title>
      <link>https://arxiv.org/abs/2510.01763</link>
      <description>arXiv:2510.01763v2 Announce Type: replace-cross 
Abstract: This paper primarily considers the robust estimation problem under Wasserstein distance constraints on the parameter and noise distributions in the linear measurement model with additive noise, which can be formulated as an infinite-dimensional nonconvex minimax problem. We prove that the existence of a saddle point for this problem is equivalent to that for a finite-dimensional minimax problem, and give a counterexample demonstrating that the saddle point may not exist. Motivated by this observation, we present a verifiable necessary and sufficient condition whose parameters can be derived from a convex problem and its dual. Additionally, we also introduce a simplified sufficient condition, which intuitively indicates that when the Wasserstein radii are small enough, the saddle point always exists. In the absence of the saddle point, we solve an finite-dimensional nonconvex minimax problem, obtained by restricting the estimator to be linear. Its optimal value establishes an upper bound on the robust estimation problem, while its optimal solution yields a robust linear estimator. Numerical experiments are also provided to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01763v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Ding, Enbin Song, Dunbiao Niu, Zhujun Cao, Qingjiang Shi</dc:creator>
    </item>
  </channel>
</rss>
