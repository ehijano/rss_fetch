<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Aug 2024 01:35:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Probabilistic Approach for Queue Length Estimation Using License Plate Recognition Data: Considering Overtaking in Multi-lane Scenarios</title>
      <link>https://arxiv.org/abs/2408.06351</link>
      <description>arXiv:2408.06351v1 Announce Type: new 
Abstract: Multi-section license plate recognition (LPR) data provides input-output information and sampled travel times of the investigated link, serving as an ideal data source for lane-based queue length estimation in recent studies. However, most of these studies assumed the strict FIFO rule or a specific arrival process, thus ignoring the potential impact of overtaking and the variation of traffic flows, especially in multi-lane scenarios. To address this issue, we propose a probabilistic approach to derive the stochastic queue length by constructing a conditional probability model of no-delay arrival time (NAT), i.e., the arrival time of vehicles without experiencing any delay, based on multi-section LPR data. First, the NAT conditions for all vehicles are established based on upstream and downstream vehicle departure times and sequences. To reduce the computational dimensionality and complexity, a DP-based algorithm is developed for vehicle group partitioning based on potential interactions between vehicles. Then, the conditional probability of NATs of each vehicle group is derived and an MCMC sampling method is employed for calculation. Subsequently, the stochastic queue profile and maximum queue length for each cycle can be derived based on the NATs of vehicles. Eventually, to leverage the LPR data sufficiently, we extend our approach to multi-lane scenarios, where the problem can be converted to a weighted general exact coverage problem and solved by a backtracking algorithm with heuristics. Empirical and simulation experiments have shown that the proposed approach outperforms the state-of-the-art method, demonstrating significant improvements in accuracy and robustness across various traffic conditions, including different V/C ratios, matching rates, and FIFO violation rates. In addition, the performance of the proposed approach can be further improved by utilizing multi-lane LPR data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06351v1</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lyuzhou Luo, Hao Wu, Jiahao Liu, Keshuang Tang, Chaopeng Tan</dc:creator>
    </item>
    <item>
      <title>An Adaptive CSI Feedback Model Based on BiLSTM for Massive MIMO-OFDM Systems</title>
      <link>https://arxiv.org/abs/2408.06359</link>
      <description>arXiv:2408.06359v1 Announce Type: new 
Abstract: Deep learning (DL)-based channel state information (CSI) feedback has the potential to improve the recovery accuracy and reduce the feedback overhead in massive multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. However, the length of input CSI and the number of feedback bits should be adjustable in different scenarios, which can not be efficiently achieved by the existing CSI feedback models. Therefore, an adaptive bidirectional long short-term memory network (ABLNet) for CSI feedback is first designed to process various input CSI lengths, where the number of feedback bits is in proportion to the CSI length. Then, to realize a more flexible feedback bit number, a feedback bit control unit (FBCU) module is proposed to control the output length of feedback bits. Based on which, a target feedback performance can be adaptively achieved by a designed bit number adjusting (BNA) algorithm. Furthermore, a novel separate training approach is devised to solve the model protection problem that the UE and gNB are from different manufacturers. Experiments demonstrate that the proposed ABLNet with FBCU can fit for different input CSI lengths and feedback bit numbers; the CSI feedback performance can be stabilized by the BNA algorithm; and the proposed separate training approach can maintain the feedback performance and reduce the complexity of feedback model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06359v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongrui Shen, Long Zhao, Kan Zheng, Yuhua Cao, Pingzhi Fan</dc:creator>
    </item>
    <item>
      <title>Bayesian Learning in a Nonlinear Multiscale State-Space Model</title>
      <link>https://arxiv.org/abs/2408.06425</link>
      <description>arXiv:2408.06425v2 Announce Type: new 
Abstract: The ubiquity of multiscale interactions in complex systems is well-recognized, with development and heredity serving as a prime example of how processes at different temporal scales influence one another. This work introduces a novel multiscale state-space model to explore the dynamic interplay between systems interacting across different time scales, with feedback between each scale. We propose a Bayesian learning framework to estimate unknown states by learning the unknown process noise covariances within this multiscale model. We develop a Particle Gibbs with Ancestor Sampling (PGAS) algorithm for inference and demonstrate through simulations the efficacy of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06425v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nayely V\'elez-Cruz, Manfred D. Laubichler</dc:creator>
    </item>
    <item>
      <title>Optimal Preprocessing for Joint Detection and Classification of Wireless Communication Signals in Congested Spectrum Using Computer Vision Methods</title>
      <link>https://arxiv.org/abs/2408.06545</link>
      <description>arXiv:2408.06545v1 Announce Type: new 
Abstract: The joint detection and classification of RF signals has been a critical problem in the field of wideband RF spectrum sensing. Recent advancements in deep learning models have revolutionized this field, remarkably through the application of state-of-the-art computer vision algorithms such as YOLO (You Only Look Once) and DETR (Detection Transformer) to the spectrogram images. This paper focuses on optimizing the preprocessing stage to enhance the performance of these computer vision models. Specifically, we investigated the generation of training spectrograms via the classical Short-Time Fourier Transform (STFT) approach, examining four classical STFT parameters: FFT size, window type, window length, and overlapping ratio. Our study aims to maximize the mean average precision (mAP) scores of YOLOv10 models in detecting and classifying various digital modulation signals within a congested spectrum environment. Firstly, our results reveal that additional zero padding in FFT does not enhance detection and classification accuracy and introduces unnecessary computational cost. Secondly, our results indicated that there exists an optimal window size that balances the trade-offs between and the time and frequency resolution, with performance losses of approximately 10% and 30% if the window size is four or eight times off from the optimal. Thirdly, regarding the choice of window functions, the Hamming window yields optimal performance, with non-optimal windows resulting in up to a 10% accuracy loss. Finally, we found a 10% accuracy score performance gap between using 10% and 90% overlap. These findings highlight the potential for significant performance improvements through optimized spectrogram parameters when applying computer vision models to the problem of wideband RF spectrum sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06545v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiwen Kang, Hua-mei Chen, Genshe Chen, Kuo-Chu Chang, Thomas M. Clemons</dc:creator>
    </item>
    <item>
      <title>Can Wireless Environmental Information Decrease Pilot Overhead: A CSI Prediction Example</title>
      <link>https://arxiv.org/abs/2408.06558</link>
      <description>arXiv:2408.06558v1 Announce Type: new 
Abstract: Channel state information (CSI) is crucial for massive multi-input multi-output (MIMO) system. As the antenna scale increases, acquiring CSI results in significantly higher system overhead. In this letter, we propose a novel channel prediction method which utilizes wireless environmental information with pilot pattern optimization for CSI prediction (WEI-CSIP). Specifically, scatterers around the mobile station (MS) are abstracted from environmental information using multiview images. Then, an environmental feature map is extracted by a convolutional neural network (CNN). Additionally, the deep probabilistic subsampling (DPS) network acquires an optimal fixed pilot pattern. Finally, a CNN-based channel prediction network is designed to predict the complete CSI, using the environmental feature map and partial CSI. Simulation results show that the WEI-CSIP can reduce pilot overhead from 1/5 to 1/8, while improving prediction accuracy with normalized mean squared error reduced to 0.0113, an improvement of 83.2% compared to traditional channel prediction methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06558v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lianzheng Shi, Jianhua Zhang, Li Yu, Yuxiang Zhang, Zhen Zhang, Yichen Cai, Guangyi Liu</dc:creator>
    </item>
    <item>
      <title>Fast Transceiver Design for RIS-Assisted MIMO mmWave Wireless Communications</title>
      <link>https://arxiv.org/abs/2408.06584</link>
      <description>arXiv:2408.06584v1 Announce Type: new 
Abstract: Due to high bandwidth and small antenna size, millimeter-wave (mmWave) integrated line-of-sight (LOS) multiple-input-multiple-output (MIMO) systems have attracted much attention. Reconfigurable intelligent surfaces (RISs), which have the potential to change the characteristics of incident electromagnetic waves with low power cost, can improve the performance or the MIMO mmWave wireless communications. Uniform circular array (UCA) is an effective antenna structure with low complexity transceiver. In this paper, UCA based RIS-assisted MIMO mmWave wireless communications with transmit UCA, the RIS UCAs, and receive UCA are investigated. Since the rotation angles between the transceiver make the channel matrix noncirculant, an algorithm is developed to derive the ranges of the rotation angles based on an acceptable error and reduce the impact of rotation angles on channel matrix. Then, we propose a low-complexity precoding scheme at the transmitter, phase designs at the RIS UCAs, and a phase compensation scheme at the receiver, which can convert the channel matrix into an equivalent circulant channel matrix with a small error. Then, a fast symbol-wise maximum likelihood (ML) detection scheme is proposed to recover the signals with low computational complexity. Simulation results are presented to illustrate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06584v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyue Jing, Wenchi Cheng, Xiang-Gen Xia</dc:creator>
    </item>
    <item>
      <title>Breaking Limits of Line-of-Sight MIMO Capacity in 6G Wireless Communications</title>
      <link>https://arxiv.org/abs/2408.06586</link>
      <description>arXiv:2408.06586v1 Announce Type: new 
Abstract: Multiple-input-multiple-output (MIMO) has been proved its success for the fourth generation (4G) long term evolution (LTE) and is one of the key technical enablers for evolved mobile broadband (eMBB) in the fifth generation (5G) wireless communications. However, along with the number of antennas eventually increased to be extremely large and one-hop communication distance gradually reduced, how to significantly increase the capacity for line-of-sight (LOS) MIMO becomes more and more urgent. In this article, we introduce the quasi-fractal uniform circular array (QF-UCA) antenna structure based MIMO wireless communications, which can adequately exploit the potential of MIMO in LOS channel and greatly increase the capacity with low complexity demodulation schemes. Specifically, three advantages regarding QF-UCA based LOS MIMO are reviewed. Then, research challenges on transceiver alignment, low-rank channel matrix, extended dimensions of QF-UCA, maximum number of orthogonal streams, and the corresponding potential solutions are discussed. Compared with traditional scattering-depended MIMO communications, the QF-UCA based LOS MIMO wireless communication can achieve high-efficient transmission in LOS channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06586v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyue Jing, Wenchi Cheng, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Orbital-Angular-Momentum Versus MIMO: Orthogonality, Degree of Freedom,and Capacity</title>
      <link>https://arxiv.org/abs/2408.06588</link>
      <description>arXiv:2408.06588v1 Announce Type: new 
Abstract: The plane wave based wireless communications have becoming more and more matured, along with the well utilization of the traditional resources such as time and frequency. To further increase the capacity for rapidly increasing capacity demand of wireless communications, it is potential to use the twist wave, which has the orbital angular momentum (OAM). In this paper, we discuss the OAM based wireless communications in the aspect of orthogonality, degree of freedom (DoF), and capacity, where both the transmitter and the receiver use uniform circular array (UCA) antennas. In particular, we compare OAM based wireless communications with multiple-input-multiple-output (MIMO) based wireless communications in terms of DoF and capacity. Numerical results are presented to validate and evaluate that the DoF of OAM based wireless communications is greater than or equal to that of correlated MIMO based wireless communications when the transmitter and the receiver antennas are aligned well. The OAM based wireless communications can achieve larger capacity than the correlated MIMO in high signal-to-noise ratio (SNR) region under line-of-sight scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06588v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyue Jing, Wenchi Cheng, Xiang-Gen Xia, Hailin Zhang</dc:creator>
    </item>
    <item>
      <title>Line Spectral Estimation with Unlimited Sensing</title>
      <link>https://arxiv.org/abs/2408.06597</link>
      <description>arXiv:2408.06597v1 Announce Type: new 
Abstract: In the paper, we consider the line spectral estimation problem in an unlimited sensing framework (USF), where a modulo analog-to-digital converter (ADC) is employed to fold the input signal back into a bounded interval before quantization. Such an operation is mathematically equivalent to taking the modulo of the input signal with respect to the interval. To overcome the noise sensitivity of higher-order difference-based methods, we explore the properties of the first-order difference of modulo samples, and develop two line spectral estimation algorithms based on first-order difference, which are robust against noise. Specifically, we show that, with a high probability, the first-order difference of the original samples is equivalent to that of the modulo samples. By utilizing this property, line spectral estimation is solved via a robust sparse signal recovery approach. The second algorithms is built on our finding that, with a sufficiently high sampling rate, the first-order difference of the original samples can be decomposed as a sum of the first-order difference of the modulo samples and a sequence whose elements are confined to be three possible values. This decomposition enables us to formulate the line spectral estimation problem as a mixed integer linear program that can be efficiently solved. Simulation results show that both proposed methods are robust against noise and achieve a significant performance improvement over the higher-order difference-based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06597v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongwei Wang, Jun Fang, Hongbin Li, Geert Leus</dc:creator>
    </item>
    <item>
      <title>Joint Source-Channel Optimization for UAV Video Coding and Transmission</title>
      <link>https://arxiv.org/abs/2408.06667</link>
      <description>arXiv:2408.06667v1 Announce Type: new 
Abstract: This paper is concerned with unmanned aerial vehicle (UAV) video coding and transmission in scenarios such as emergency rescue and environmental monitoring. Unlike existing methods of modeling video source coding and channel transmission separately, we investigate the joint source-channel optimization issue for video coding and transmission. Particularly, we design eight-dimensional delay-power-rate-distortion models in terms of source coding and channel transmission and characterize the correlation between video coding and transmission, with which a joint source-channel optimization problem is formulated. Its objective is to minimize end-to-end distortion and UAV power consumption by optimizing fine-grained parameters related to UAV video coding and transmission. This problem is confirmed to be a challenging sequential-decision and non-convex optimization problem. We therefore decompose it into a family of repeated optimization problems by Lyapunov optimization and design an approximate convex optimization scheme with provable performance guarantees to tackle these problems. Based on the theoretical transformation, we propose a Lyapunov repeated iteration (LyaRI) algorithm. Extensive experiments are conducted to comprehensively evaluate the performance of LyaRI. Experimental results indicate that compared to its counterparts, LyaRI is robust to initial settings of encoding parameters, and the variance of its achieved encoding bitrate is reduced by 47.74%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06667v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kesong Wu, Xianbin Cao, Peng Yang, Haijun Zhang, Tony Q. S. Quek, Dapeng Oliver Wu</dc:creator>
    </item>
    <item>
      <title>Sum Rate Maximization for Movable Antenna Enabled Uplink NOMA</title>
      <link>https://arxiv.org/abs/2408.06789</link>
      <description>arXiv:2408.06789v1 Announce Type: new 
Abstract: Movable antenna (MA) has been recently proposed as a promising candidate technology for the next generation wireless communication systems due to its significant capability of reconfiguring wireless channels via antenna movement. In this letter, we study an MA-enabled uplink non-orthogonal multiple access (NOMA) system, where each user is equipped with a single MA. Our objective is to maximize the users' sum rate by jointly optimizing the MAs' positions, the decoding order and the power control. To solve this non-convex problem, we equivalently transform it into two tractable subproblems. First, we use the successive convex approximation (SCA) to find a locally optimal solution for the antenna position optimization subproblem. Next, we derive the closed-form optimal solution of the decoding order and power control subproblem. Numerical results show that our proposed MA-enabled NOMA system can significantly enhance the sum rate compared to fixed-position antenna (FPA) systems and orthogonal multiple access (OMA) systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06789v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2024.3403138</arxiv:DOI>
      <dc:creator>Nianzu Li, Peiran Wu, Boyu Ning, Lipeng Zhu</dc:creator>
    </item>
    <item>
      <title>Chirped DFT-s-OFDM: A new single-carrier waveform with enhanced LMMSE noise suppression</title>
      <link>https://arxiv.org/abs/2408.06796</link>
      <description>arXiv:2408.06796v1 Announce Type: new 
Abstract: In this correspondence, a new single-carrier waveform, called chirped discrete Fourier transform spread orthogonal frequency division multiplexing (DFT-s-OFDM), is proposed for the sixth generation of communications. By chirping DFT-s-OFDM in the time domain, the proposed waveform maintains the low peak-to-average-power ratio (PAPR) of DFT-s-OFDM. Thanks to full-band transmission and symbols retransmission enabled by chirping and discrete Fourier transform (DFT) precoding, the proposed waveform can enhance noise suppression of linear minimum mean square error equalization. Its bit error rate (BER) upper bound and diversity order are derived using pairwise error probability. Simulation results confirm that the proposed waveform outperforms the state-of-the-art waveforms in terms of BER, output signal-to-noise-ratio, and PAPR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06796v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Liu, Yong Liang Guan, David Gonz\'alez G., Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Spectrum Prediction With Deep 3D Pyramid Vision Transformer Learning</title>
      <link>https://arxiv.org/abs/2408.06870</link>
      <description>arXiv:2408.06870v1 Announce Type: new 
Abstract: In this paper, we propose a deep learning (DL)-based task-driven spectrum prediction framework, named DeepSPred. The DeepSPred comprises a feature encoder and a task predictor, where the encoder extracts spectrum usage pattern features, and the predictor configures different networks according to the task requirements to predict future spectrum. Based on the Deep- SPred, we first propose a novel 3D spectrum prediction method combining a flow processing strategy with 3D vision Transformer (ViT, i.e., Swin) and a pyramid to serve possible applications such as spectrum monitoring task, named 3D-SwinSTB. 3D-SwinSTB unique 3D Patch Merging ViT-to-3D ViT Patch Expanding and pyramid designs help the model accurately learn the potential correlation of the evolution of the spectrogram over time. Then, we propose a novel spectrum occupancy rate (SOR) method by redesigning a predictor consisting exclusively of 3D convolutional and linear layers to serve possible applications such as dynamic spectrum access (DSA) task, named 3D-SwinLinear. Unlike the 3D-SwinSTB output spectrogram, 3D-SwinLinear projects the spectrogram directly as the SOR. Finally, we employ transfer learning (TL) to ensure the applicability of our two methods to diverse spectrum services. The results show that our 3D-SwinSTB outperforms recent benchmarks by more than 5%, while our 3D-SwinLinear achieves a 90% accuracy, with a performance improvement exceeding 10%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06870v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangliang Pan, Qihui Wu, Bo Zhou, Jie Li, Wei Wang, Guoru Ding, David K. Y. Ya</dc:creator>
    </item>
    <item>
      <title>FoVNet: Configurable Field-of-View Speech Enhancement with Low Computation and Distortion for Smart Glasses</title>
      <link>https://arxiv.org/abs/2408.06468</link>
      <description>arXiv:2408.06468v1 Announce Type: cross 
Abstract: This paper presents a novel multi-channel speech enhancement approach, FoVNet, that enables highly efficient speech enhancement within a configurable field of view (FoV) of a smart-glasses user without needing specific target-talker(s) directions. It advances over prior works by enhancing all speakers within any given FoV, with a hybrid signal processing and deep learning approach designed with high computational efficiency. The neural network component is designed with ultra-low computation (about 50 MMACS). A multi-channel Wiener filter and a post-processing module are further used to improve perceptual quality. We evaluate our algorithm with a microphone array on smart glasses, providing a configurable, efficient solution for augmented hearing on energy-constrained devices. FoVNet excels in both computational efficiency and speech quality across multiple scenarios, making it a promising solution for smart glasses applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06468v1</guid>
      <category>cs.SD</category>
      <category>cs.MM</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongweiyang Xu, Ali Aroudi, Ke Tan, Ashutosh Pandey, Jung-Suk Lee, Buye Xu, Francesco Nesta</dc:creator>
    </item>
    <item>
      <title>Neural Speech and Audio Coding</title>
      <link>https://arxiv.org/abs/2408.06954</link>
      <description>arXiv:2408.06954v1 Announce Type: cross 
Abstract: This paper explores the integration of model-based and data-driven approaches within the realm of neural speech and audio coding systems. It highlights the challenges posed by the subjective evaluation processes of speech and audio codecs and discusses the limitations of purely data-driven approaches, which often require inefficiently large architectures to match the performance of model-based methods. The study presents hybrid systems as a viable solution, offering significant improvements to the performance of conventional codecs through meticulously chosen design enhancements. Specifically, it introduces a neural network-based signal enhancer designed to post-process existing codecs' output, along with the autoencoder-based end-to-end models and LPCNet--hybrid systems that combine linear predictive coding (LPC) with neural networks. Furthermore, the paper delves into predictive models operating within custom feature spaces (TF-Codec) or predefined transform domains (MDCTNet) and examines the use of psychoacoustically calibrated loss functions to train end-to-end neural audio codecs. Through these investigations, the paper demonstrates the potential of hybrid systems to advance the field of speech and audio coding by bridging the gap between traditional model-based approaches and modern data-driven techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06954v1</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minje Kim, Jan Skoglund</dc:creator>
    </item>
    <item>
      <title>Feature-Preserving Rate-Distortion Optimization in Image Coding for Machines</title>
      <link>https://arxiv.org/abs/2408.07028</link>
      <description>arXiv:2408.07028v1 Announce Type: cross 
Abstract: With the increasing number of images and videos consumed by computer vision algorithms, compression methods are evolving to consider both perceptual quality and performance in downstream tasks. Traditional codecs can tackle this problem by performing rate-distortion optimization (RDO) to minimize the distance at the output of a feature extractor. However, neural network non-linearities can make the rate-distortion landscape irregular, leading to reconstructions with poor visual quality even for high bit rates. Moreover, RDO decisions are made block-wise, while the feature extractor requires the whole image to exploit global information. In this paper, we address these limitations in three steps. First, we apply Taylor's expansion to the feature extractor, recasting the metric as an input-dependent squared error involving the Jacobian matrix of the neural network. Second, we make a localization assumption to compute the metric block-wise. Finally, we use randomized dimensionality reduction techniques to approximate the Jacobian. The resulting expression is monotonic with the rate and can be evaluated in the transform domain. Simulations with AVC show that our approach provides bit-rate savings while preserving accuracy in downstream tasks with less complexity than using the feature distance directly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07028v1</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Fern\'andez Mendui\~na, Eduardo Pavez, Antonio Ortega</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Radar Signal Processing Accelerator for Integrated Sensing and Communication System</title>
      <link>https://arxiv.org/abs/2303.01702</link>
      <description>arXiv:2303.01702v2 Announce Type: replace 
Abstract: IEEE 802.11ad-based integrated sensing and communications (ISAC) have been identified as a potential solution for enabling next-generation intelligent transportation systems in the millimeter wave (mmW) spectrum. The radar functionality within the ISAC enables accurate detection and localization of mobile targets, which can significantly speed up the selection of the optimal high-directional narrow beam required for mmW communications between the base station and mobile target. To bring ISAC to reality, a radar signal processing (RSP) accelerator, co-located with the wireless communication physical layer (PHY), on edge platforms, is desired. In this work, we discuss the three-dimensional digital hardware RSP framework for 802.11ad-based ISAC to detect the range, azimuth, and Doppler velocity of multiple targets. We present an efficient reconfigurable architecture for RSP on multi-processor system-on-chip (MPSoC) via hardware-software co-design, word-length optimization, and serial-parallel configurations. We demonstrate the functional correctness of the proposed fixed-point architecture and significant savings in resource utilization (40-70%), execution time (1.5x improvement), and power consumption (50%) over floating-point architecture. The acceleration on hardware offers a 120-factor improvement in execution time over the benchmark Quad-core processor. The proposed architecture enables on-the-fly reconfigurability to support different azimuth precision and Doppler velocity resolution, offering a real-time trade-off between functional accuracy and detection time. We implement end-to-end ISAC comprising RSP and PHY on MPSoC and demonstrate significant improvement in throughput over IEEE 802.11ad.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01702v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakanksha Tewari, Shragvi Sidharth Jha, Akanksha Sneh, Sumit J Darak, Shobha Sundar Ram</dc:creator>
    </item>
    <item>
      <title>Joint Mechanical and Electrical Adjustment of IRS-aided LEO Satellite MIMO Communications</title>
      <link>https://arxiv.org/abs/2401.06422</link>
      <description>arXiv:2401.06422v4 Announce Type: replace 
Abstract: In this correspondence, we propose a joint mechanical and electrical adjustment of intelligent reflecting surface (IRS) for the performance improvements of low-earth orbit (LEO) satellite multiple-input multiple-output (MIMO) communications. In particular, we construct a three-dimensional (3D) MIMO channel model for the mechanically-tilted IRS in general deployment, and consider two types of scenarios with and without the direct path of LEO-ground user link due to the orbital flight. With the aim of maximizing the end-to-end performance, we jointly optimize tilting angle and phase shift of IRS along with the transceiver beamforming, whose performance superiority is verified via simulations with the Orbcomm LEO satellite using a real orbit data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06422v4</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Doyoung Kim, Seongah Jeong</dc:creator>
    </item>
    <item>
      <title>EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based Cross-Center Brain Disease Diagnosis under Unreliable Annotations</title>
      <link>https://arxiv.org/abs/2405.00734</link>
      <description>arXiv:2405.00734v2 Announce Type: replace 
Abstract: Cross-center data heterogeneity and annotation unreliability significantly challenge the intelligent diagnosis of diseases using brain signals. A notable example is the EEG-based diagnosis of neurodegenerative diseases, which features subtler abnormal neural dynamics typically observed in small-group settings. To advance this area, in this work, we introduce a transferable framework employing Manifold Attention and Confidence Stratification (MACS) to diagnose neurodegenerative disorders based on EEG signals sourced from four centers with unreliable annotations. The MACS framework's effectiveness stems from these features: 1) The Augmentor generates various EEG-represented brain variants to enrich the data space; 2) The Switcher enhances the feature space for trusted samples and reduces overfitting on incorrectly labeled samples; 3) The Encoder uses the Riemannian manifold and Euclidean metrics to capture spatiotemporal variations and dynamic synchronization in EEG; 4) The Projector, equipped with dual heads, monitors consistency across multiple brain variants and ensures diagnostic accuracy; 5) The Stratifier adaptively stratifies learned samples by confidence levels throughout the training process; 6) Forward and backpropagation in MACS are constrained by confidence stratification to stabilize the learning system amid unreliable annotations. Our subject-independent experiments, conducted on both neurocognitive and movement disorders using cross-center corpora, have demonstrated superior performance compared to existing related algorithms. This work not only improves EEG-based diagnostics for cross-center and small-setting brain diseases but also offers insights into extending MACS techniques to other data analyses, tackling data heterogeneity and annotation unreliability in multimedia and multimodal content understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00734v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenxi Song, Ruihan Qin, Huixia Ren, Zhen Liang, Yi Guo, Min Zhang, Zhiguo Zhang</dc:creator>
    </item>
    <item>
      <title>Joint Detection and Classification of Communication and Radar Signals in Congested RF Environments Using YOLOv8</title>
      <link>https://arxiv.org/abs/2406.00582</link>
      <description>arXiv:2406.00582v2 Announce Type: replace 
Abstract: In this paper, we present a comprehensive study on the application of YOLOv8, a state-of-the-art computer vision (CV) model, to the challenging problem of joint detection and classification of signals in a highly dynamic and congested RF environment. Using our synthetic RF datasets, we explored three different scenarios with congested communication and radar signals. In the first study, we applied YOLOv8 to detect and classify multiple digital modulation signals coexisting within a highly congested and dynamic spectral environment with significant overlap in both frequency and time domains. The trained model was able to achieve an impressive mean average precision (mAP) of 0.888 at an IoU threshold of 50%, signifying its robustness against spectral congestion. The second part of our research focuses on the detection and classification of multiple polyphase pulse radar signals, including Frank code and P1 through P4 codes. We were able to successfully train YOLOv8 to deliver a nearly perfect mAP50 score of 0.995 in a densely populated signal environment, further showcasing its capability in radar signal processing. In the last scenario, we demonstrated that the model can also be applied to the multi-target detection problem for continuous-wave radar. The synthetic datasets used in these experiments reflect a realistic mix of communication and radar signals with varying degrees of interference and congestion - a setup that has been overlooked by many past research efforts, which have primarily focused on ML-based classification of digital communication signal modulation schemes. Our study demonstrated the potential of advanced CV models in addressing spectrum sensing challenges in congested and dynamic RF environments involving both communication and radar signals. We hope our findings will spur further collaborative efforts to tackle the complexities of congested RF spectrum environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00582v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiwen Kang, Hua-mei Chen, Genshe Chen, Kuo-Chu Chang, Thomas M. Clemons</dc:creator>
    </item>
    <item>
      <title>Pilot-Aided Joint Time Synchronization and Channel Estimation for OTFS</title>
      <link>https://arxiv.org/abs/2408.04192</link>
      <description>arXiv:2408.04192v2 Announce Type: replace 
Abstract: This letter proposes a pilot-aided joint time synchronization and channel estimation (JTSCE) algorithm for orthogonal time frequency space (OTFS) systems. Unlike existing algorithms, JTSCE employs a maximum length sequence (MLS) rather than an isolated signal as the pilot. Distinctively, JTSCE explores MLS's autocorrelation properties to estimate timing offset and channel delay taps. After obtaining delay taps, closed-form expressions of Doppler and channel gain for each propagation path are derived. Simulation results indicate that, compared to its counterpart, JTSCE achieves better bit error rate performance, close to that with perfect time synchronization and channel state information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04192v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiazheng Sun, Peng Yang, Xianbin Cao, Zehui Xiong, Haijun Zhang, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Survey on EEG-Based Emotion Recognition: A Graph-Based Perspective</title>
      <link>https://arxiv.org/abs/2408.06027</link>
      <description>arXiv:2408.06027v2 Announce Type: replace 
Abstract: Compared to other modalities, electroencephalogram (EEG) based emotion recognition can intuitively respond to emotional patterns in the human brain and, therefore, has become one of the most focused tasks in affective computing. The nature of emotions is a physiological and psychological state change in response to brain region connectivity, making emotion recognition focus more on the dependency between brain regions instead of specific brain regions. A significant trend is the application of graphs to encapsulate such dependency as dynamic functional connections between nodes across temporal and spatial dimensions. Concurrently, the neuroscientific underpinnings behind this dependency endow the application of graphs in this field with a distinctive significance. However, there is neither a comprehensive review nor a tutorial for constructing emotion-relevant graphs in EEG-based emotion recognition. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of graph-related methods in this field from a methodological perspective. We propose a unified framework for graph applications in this field and categorize these methods on this basis. Finally, based on previous studies, we also present several open challenges and future directions in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06027v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Liu, Xinliang Zhou, Yihao Wu, Yi Ding, Liming Zhai, Kun Wang, Ziyu Jia, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Nonconvex Factorization and Manifold Formulations are Almost Equivalent in Low-rank Matrix Optimization</title>
      <link>https://arxiv.org/abs/2108.01772</link>
      <description>arXiv:2108.01772v3 Announce Type: replace-cross 
Abstract: In this paper, we consider the geometric landscape connection of the widely studied manifold and factorization formulations in low-rank positive semidefinite (PSD) and general matrix optimization. We establish a sandwich relation on the spectrum of Riemannian and Euclidean Hessians at first-order stationary points (FOSPs). As a result of that, we obtain an equivalence on the set of FOSPs, second-order stationary points (SOSPs) and strict saddles between the manifold and the factorization formulations. In addition, we show the sandwich relation can be used to transfer more quantitative geometric properties from one formulation to another. Similarities and differences in the landscape connection under the PSD case and the general case are discussed. To the best of our knowledge, this is the first geometric landscape connection between the manifold and the factorization formulations for handling rank constraints, and it provides a geometric explanation for the similar empirical performance of factorization and manifold approaches in low-rank matrix optimization observed in the literature. In the general low-rank matrix optimization, the landscape connection of two factorization formulations (unregularized and regularized ones) is also provided. By applying these geometric landscape connections, in particular, the sandwich relation, we are able to solve unanswered questions in literature and establish stronger results in the applications on geometric analysis of phase retrieval, well-conditioned low-rank matrix optimization, and the role of regularization in factorization arising from machine learning and signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.01772v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yuetian Luo, Xudong Li, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Data-Driven Nonlinear TDOA for Accurate Source Localization in Complex Signal Dynamics</title>
      <link>https://arxiv.org/abs/2308.01487</link>
      <description>arXiv:2308.01487v2 Announce Type: replace-cross 
Abstract: The complex and dynamic propagation of oscillations and waves is often triggered by sources at unknown locations. Accurate source localization enables the elimination of the rotor core in atrial fibrillation (AFib) as an effective treatment for such severe cardiac disorder; it also finds potential use in locating the spreading source in natural disasters such as forest fires and tsunamis. However, existing approaches such as time of arrival (TOA) and time difference of arrival (TDOA) do not yield accurate localization results since they tacitly assume a constant signal propagation speed whereas realistic propagation is often non-static and heterogeneous. In this paper, we develop a nonlinear TDOA (NTDOA) approach which utilizes observational data from various positions to jointly learn the propagation speed at different angles and distances as well as the location of the source itself. Through examples of simulating the complex dynamics of electrical signals along the surface of the heart and satellite imagery from forest fires and tsunamis, we show that with a small handful of measurements, NTDOA, as a data-driven approach, can successfully locate the spreading source, leading also to better forecasting of the speed and direction of subsequent propagation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01487v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chinmay Sahu, Mahesh Banavar, Jie Sun</dc:creator>
    </item>
    <item>
      <title>Deep Unfolding-Based Channel Estimation for Wideband TeraHertz Near-Field Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2308.13381</link>
      <description>arXiv:2308.13381v2 Announce Type: replace-cross 
Abstract: The combination of Terahertz (THz) and massive multiple-input multiple-output (MIMO) is promising to meet the increasing data rate demand of future wireless communication systems thanks to the huge bandwidth and spatial degrees of freedom. However, unique channel features such as the near-field beam split effect make channel estimation particularly challenging in THz massive MIMO systems. On one hand, adopting the conventional angular domain transformation dictionary designed for low-frequency far-field channels will result in degraded channel sparsity and destroyed sparsity structure in the transformed domain. On the other hand, most existing compressive sensing-based channel estimation algorithms cannot achieve high performance and low complexity simultaneously. To alleviate these issues, in this paper, we first adopt frequency-dependent near-field dictionaries to maintain good channel sparsity and sparsity structure in the transformed domain under the near-field beam split effect. Then, a deep unfolding-based wideband THz massive MIMO channel estimation algorithm is proposed. In each iteration of the unitary approximate message passing-sparse Bayesian learning algorithm, the optimal update rule is learned by a deep neural network (DNN), whose structure is customized to effectively exploit the inherent channel patterns. Furthermore, a mixed training method based on novel designs of the DNN structure and the loss function is developed to effectively train data from different system configurations. Simulation results validate the superiority of the proposed algorithm in terms of performance, complexity, and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13381v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiabao Gao, Xiaoming Cheng, Geoffrey Ye Li</dc:creator>
    </item>
    <item>
      <title>Generative AI for Semantic Communication: Architecture, Challenges, and Outlook</title>
      <link>https://arxiv.org/abs/2308.15483</link>
      <description>arXiv:2308.15483v4 Announce Type: replace-cross 
Abstract: Semantic communication (SemCom) is expected to be a core paradigm in future communication networks, yielding significant benefits in terms of spectrum resource saving and information interaction efficiency. However, the existing SemCom structure is limited by the lack of context-reasoning ability and background knowledge provisioning, which, therefore, motivates us to seek the potential of incorporating generative artificial intelligence (GAI) technologies with SemCom. Recognizing GAI's powerful capability in automating and creating valuable, diverse, and personalized multimodal content, this article first highlights the principal characteristics of the combination of GAI and SemCom along with their pertinent benefits and challenges. To tackle these challenges, we further propose a novel GAI-integrated SemCom network (GAI-SCN) framework in a cloud-edge-mobile design. Specifically, by employing global and local GAI models, our GAI-SCN enables multimodal semantic content provisioning, semantic-level joint-source-channel coding, and AIGC acquisition to maximize the efficiency and reliability of semantic reasoning and resource utilization. Afterward, we present a detailed implementation workflow of GAI-SCN, followed by corresponding initial simulations for performance evaluation in comparison with two benchmarks. Finally, we discuss several open issues and offer feasible solutions to unlock the full potential of GAI-SCN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15483v4</guid>
      <category>cs.NI</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Xia, Yao Sun, Chengsi Liang, Lei Zhang, Muhammad Ali Imran, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>3D Beamforming Through Joint Phase-Time Arrays</title>
      <link>https://arxiv.org/abs/2401.00819</link>
      <description>arXiv:2401.00819v3 Announce Type: replace-cross 
Abstract: High-frequency wideband cellular communications over mmWave and sub-THz offer the opportunity for high data rates. However, it also presents high path loss, resulting in limited coverage. High-gain beamforming from the antenna array is essential to mitigate the coverage limitations. The conventional phased antenna arrays (PAA) cause high scheduling latency owing to analog beam constraints, i.e., only one frequency-flat beam is generated. Recently introduced joint phase-time array (JPTA) architecture, which utilizes both true-time-delay (TTD) units and phase shifters (PSs), alleviates analog beam constraints by creating multiple frequency-dependent beams for scheduling multiple users at different directions in a frequency-division manner. One class of previous studies offered solutions with ``rainbow" beams, which tend to allocate a small bandwidth per beam direction. Another class focused on uniform linear array (ULA) antenna architecture, whose frequency-dependent beams were designed along a single axis of either azimuth or elevation direction. This paper presents a novel 3D beamforming design that maximizes beamforming gain toward desired azimuth and elevation directions and across sub-bands partitioned according to scheduled users' bandwidth requirements. We provide analytical solutions and iterative algorithms to design the PSs and TTD units for a desired subband beam pattern. Through simulations of the beamforming gain, we observe that our proposed solutions outperform the state-of-the-art solutions reported elsewhere.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00819v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ozlem Yildiz (Charlie), Ahmad AlAmmouri (Charlie), Jianhua Mo (Charlie), Younghan Nam (Charlie), Elza Erkip (Charlie),  Jianzhong (Charlie),  Zhang</dc:creator>
    </item>
    <item>
      <title>USDnet: Unsupervised Speech Dereverberation via Neural Forward Filtering</title>
      <link>https://arxiv.org/abs/2402.00820</link>
      <description>arXiv:2402.00820v2 Announce Type: replace-cross 
Abstract: In reverberant conditions with a single speaker, each far-field microphone records a reverberant version of the same speaker signal at a different location. In over-determined conditions, where there are multiple microphones but only one speaker, each recorded mixture signal can be leveraged as a constraint to narrow down the solutions to target anechoic speech and thereby reduce reverberation. Equipped with this insight, we propose USDnet, a novel deep neural network (DNN) approach for unsupervised speech dereverberation (USD). At each training step, we first feed an input mixture to USDnet to produce an estimate for target speech, and then linearly filter the DNN estimate to approximate the multi-microphone mixture so that the constraint can be satisfied at each microphone, thereby regularizing the DNN estimate to approximate target anechoic speech. The linear filter can be estimated based on the mixture and DNN estimate via neural forward filtering algorithms such as forward convolutive prediction. We show that this novel methodology can promote unsupervised dereverberation of single-source reverberant speech.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00820v2</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhong-Qiu Wang</dc:creator>
    </item>
    <item>
      <title>Cache-Aided MIMO Communications: DoF Analysis and Transmitter Optimization</title>
      <link>https://arxiv.org/abs/2407.15743</link>
      <description>arXiv:2407.15743v2 Announce Type: replace-cross 
Abstract: Cache-aided MIMO communications aims to jointly exploit both coded caching~(CC) and spatial multiplexing gains to enhance communication efficiency. In this paper, we first analyze the achievable degrees of freedom~(DoF) in a MIMO-CC system with CC gain \(t\), where a server with \(L\) transmit antennas communicates with \(K\) users, each equipped with \(G\) receive antennas. We demonstrate that the enhanced achievable DoF is \(\max_{\beta, \Omega} \Omega \beta\), where the number of users \(\Omega\) served in each transmission is fine-tuned to maximize DoF, and \(\beta \le \min\big(G, \nicefrac{L \binom{\Omega-1}{t}}{1 + (\Omega - t - 1)\binom{\Omega-1}{t}}\big)\) represents the number of parallel streams decoded by each user. Second, we introduce an effective transmit covariance matrix design aimed at maximizing the symmetric rate, solved iteratively via successive convex approximation. Third, we propose a new class of MIMO-CC schemes using a novel scheduling mechanism leveraging maximal multicasting opportunities to maximize delivery rates at given SNR levels while adhering to linear processing constraints. Lastly, we devise linear multicast beamforming strategies tailored for the flexible scheduling schemes in MIMO-CC systems and present an iterative solution for the efficient design of beamformers. Extensive numerical simulations are used to verify the results of the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15743v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad NaseriTehrani, MohammadJavad Salehi, Antti T\"olli</dc:creator>
    </item>
    <item>
      <title>Interpretable Pre-Trained Transformers for Heart Time-Series Data</title>
      <link>https://arxiv.org/abs/2407.20775</link>
      <description>arXiv:2407.20775v2 Announce Type: replace-cross 
Abstract: Decoder-only transformers are the backbone of the popular generative pre-trained transformer (GPT) series of large language models. In this work, we employ this framework to the analysis of clinical heart time-series data, to create two pre-trained general purpose cardiac models, termed PPG-PT and ECG-PT. We place a special emphasis on making both such pre-trained models fully interpretable. This is achieved firstly through aggregate attention maps which show that, in order to make predictions, the model focuses on similar points in previous cardiac cycles and gradually broadens its attention in deeper layers. Next, we show that tokens with the same value, which occur at different distinct points in the electrocardiography (ECG) and photoplethysmography (PPG) cycle, form separate clusters in high dimensional space. The clusters form according to phase, as the tokens propagate through the transformer blocks. Finally, we highlight that individual attention heads respond to specific physiologically relevent features, such as the dicrotic notch in PPG and the P-wave in ECG. It is also demonstrated that these pre-trained models are straightforward to fine-tune for tasks such as classification of atrial fibrillation (AF), and beat detection in photoplethysmography. For the example of AF, the fine-tuning took 11 minutes of computer time, and achieved the respective leave-one-subject-out AUCs of 0.99 and 0.93 for ECG and PPG within the MIMIC Perform AF dataset. In addition, the fine-tuned beat detector achieved a state-of-the-art F1 score of 98%, as well as uniquely providing a beat confidence level which acts as a signal quality estimator. Importantly, the fine-tuned models for AF screening are also fully explainable, with attention shifting to regions in the context that are strongly indicative of atrial fibrillation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20775v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry J. Davies, James Monsen, Danilo P. Mandic</dc:creator>
    </item>
  </channel>
</rss>
