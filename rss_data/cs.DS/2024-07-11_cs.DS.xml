<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Jul 2024 01:41:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Spectral Toolkit of Algorithms for Graphs: Technical Report (2)</title>
      <link>https://arxiv.org/abs/2407.07096</link>
      <description>arXiv:2407.07096v1 Announce Type: new 
Abstract: Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library for efficient graph algorithms. This technical report presents the newly implemented component on locality sensitive hashing, kernel density estimation, and fast spectral clustering. The report includes a user's guide to the newly implemented algorithms, experiments and demonstrations of the new functionality, and several technical considerations behind our development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07096v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Macgregor, He Sun</dc:creator>
    </item>
    <item>
      <title>Differential privacy and Sublinear time are incompatible sometimes</title>
      <link>https://arxiv.org/abs/2407.07262</link>
      <description>arXiv:2407.07262v1 Announce Type: new 
Abstract: Differential privacy and sublinear algorithms are both rapidly emerging algorithmic themes in times of big data analysis. Although recent works have shown the existence of differentially private sublinear algorithms for many problems including graph parameter estimation and clustering, little is known regarding hardness results on these algorithms. In this paper, we initiate the study of lower bounds for problems that aim for both differentially-private and sublinear-time algorithms. Our main result is the incompatibility of both the desiderata in the general case. In particular, we prove that a simple problem based on one-way marginals yields both a differentially-private algorithm, as well as a sublinear-time algorithm, but does not admit a ``strictly'' sublinear-time algorithm that is also differentially private.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07262v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremiah Blocki, Hendrik Fichtenberger, Elena Grigorescu, Tamalika Mukherjee</dc:creator>
    </item>
    <item>
      <title>A New Approach for Approximating Directed Rooted Networks</title>
      <link>https://arxiv.org/abs/2407.07543</link>
      <description>arXiv:2407.07543v1 Announce Type: new 
Abstract: We consider the k-outconnected directed Steiner tree problem (k-DST). Given a directed edge-weighted graph $G=(V,E,w)$, where $V=\{r\}\cup S \cup T$, and an integer $k$, the goal is to find a minimum cost subgraph of $G$ in which there are $k$ edge-disjoint $rt$-paths for every terminal $t\in T$. The problem is know to be NP-hard. Furthermore, the question on whether a polynomial time, subpolynomial approximation algorithm exists for $k$-DST was answered negatively by Grandoni et al. (2018), by proving an approximation hardness of $\Omega (|T|/\log |T|)$ under $NP\neq ZPP$. Inspired by modern day applications, we focus on developing efficient algorithms for $k$-DST in graphs where terminals have out-degree $0$, and furthermore constitute the vast majority in the graph. We provide the first approximation algorithm for $k$-DST on such graphs, in which the approximation ratio depends (primarily) on the size of $S$. We present a randomized algorithm that finds a solution of weight at most $\mathcal O(k|S|\log |T|)$ times the optimal weight, and with high probability runs in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07543v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarel Cohen, Lior Kamma, Aikaterini Niklanovits</dc:creator>
    </item>
    <item>
      <title>On Sampling from Ising Models with Spectral Constraints</title>
      <link>https://arxiv.org/abs/2407.07645</link>
      <description>arXiv:2407.07645v1 Announce Type: new 
Abstract: We consider the problem of sampling from the Ising model when the underlying interaction matrix has eigenvalues lying within an interval of length $\gamma$. Recent work in this setting has shown various algorithmic results that apply roughly when $\gamma&lt; 1$, notably with nearly-linear running times based on the classical Glauber dynamics. However, the optimality of the range of $\gamma$ was not clear since previous inapproximability results developed for the antiferromagnetic case (where the matrix has entries $\leq 0$) apply only for $\gamma&gt;2$.
  To this end, Kunisky (SODA'24) recently provided evidence that the problem becomes hard already when $\gamma&gt;1$ based on the low-degree hardness for an inference problem on random matrices. Based on this, he conjectured that sampling from the Ising model in the same range of $\gamma$ is NP-hard.
  Here we confirm this conjecture, complementing in particular the known algorithmic results by showing NP-hardness results for approximately counting and sampling when $\gamma&gt;1$, with strong inapproximability guarantees; we also obtain a more refined hardness result for matrices where only a constant number of entries per row are allowed to be non-zero. The main observation in our reductions is that, for $\gamma&gt;1$, Glauber dynamics mixes slowly when the interactions are all positive (ferromagnetic) for the complete and random regular graphs, due to a bimodality in the underlying distribution. While ferromagnetic interactions typically preclude NP-hardness results, here we work around this by introducing in an appropriate way mild antiferromagnetism, keeping the spectrum roughly within the same range. This allows us to exploit the bimodality of the aforementioned graphs and show the target NP-hardness by adapting suitably previous inapproximability techniques developed for antiferromagnetic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07645v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Galanis, Alkis Kalavasis, Anthimos Vardis Kandiros</dc:creator>
    </item>
    <item>
      <title>APTAS for bin packing with general cost structures</title>
      <link>https://arxiv.org/abs/2407.07677</link>
      <description>arXiv:2407.07677v1 Announce Type: new 
Abstract: We consider the following generalization of the bin packing problem. We are given a set of items each of which is associated with a rational size in the interval [0,1], and a monotone non-decreasing non-negative cost function f defined over the cardinalities of the subsets of items. A feasible solution is a partition of the set of items into bins subject to the constraint that the total size of items in every bin is at most 1. Unlike bin packing, the goal function is to minimize the total cost of the bins where the cost of a bin is the value of f applied on the cardinality of the subset of items packed into the bin. We present an APTAS for this strongly NP-hard problem. We also provide a complete complexity classification of the problem with respect to the choice of f.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07677v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Jaykrishnan, Asaf Levin</dc:creator>
    </item>
    <item>
      <title>Random Reed-Solomon Codes Achieve the Half-Singleton Bound for Insertions and Deletions over Linear-Sized Alphabets</title>
      <link>https://arxiv.org/abs/2407.07299</link>
      <description>arXiv:2407.07299v1 Announce Type: cross 
Abstract: In this paper, we prove that with high probability, random Reed-Solomon codes approach the half-Singleton bound - the optimal rate versus error tradeoff for linear insdel codes - with linear-sized alphabets. More precisely, we prove that, for any $\epsilon&gt;0$ and positive integers $n$ and $k$, with high probability, random Reed--Solomon codes of length $n$ and dimension $k$ can correct $(1-\varepsilon)n-2k+1$ adversarial insdel errors over alphabets of size $n+2^{\mathsf{poly}(1/\varepsilon)}k$. This significantly improves upon the alphabet size demonstrated in the work of Con, Shpilka, and Tamo (IEEE TIT, 2023), who showed the existence of Reed--Solomon codes with exponential alphabet size $\widetilde O\left(\binom{n}{2k-1}^2\right)$ precisely achieving the half-Singleton bound.
  Our methods are inspired by recent works on list-decoding Reed-Solomon codes. Brakensiek-Gopi-Makam (STOC 2023) showed that random Reed-Solomon codes are list-decodable up to capacity with exponential-sized alphabets, and Guo-Zhang (FOCS 2023) and Alrabiah-Guruswami-Li (STOC 2024) improved the alphabet-size to linear. We achieve a similar alphabet-size reduction by similarly establishing strong bounds on the probability that certain random rectangular matrices are full rank. To accomplish this in our insdel context, our proof combines the random matrix techniques from list-decoding with structural properties of Longest Common Subsequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07299v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roni Con, Zeyu Guo, Ray Li, Zihan Zhang</dc:creator>
    </item>
    <item>
      <title>Fast Approximation Algorithms for Euclidean Minimum Weight Perfect Matching</title>
      <link>https://arxiv.org/abs/2407.07749</link>
      <description>arXiv:2407.07749v1 Announce Type: cross 
Abstract: We study the problem of finding a Euclidean minimum weight perfect matching for $n$ points in the plane. It is known that a deterministic approximation algorithm for this problems must have at least $\Omega(n \log n)$ runtime. We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\log n)$ and show that it has approximation ratio $O(n^{0.2995})$. This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.599})$ in all fixed dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07749v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Hougardy, Karolina Tammemaa</dc:creator>
    </item>
    <item>
      <title>Ramsey Theorems for Trees and a General 'Private Learning Implies Online Learning' Theorem</title>
      <link>https://arxiv.org/abs/2407.07765</link>
      <description>arXiv:2407.07765v1 Announce Type: cross 
Abstract: This work continues to investigate the link between differentially private (DP) and online learning. Alon, Livni, Malliaris, and Moran (2019) showed that for binary concept classes, DP learnability of a given class implies that it has a finite Littlestone dimension (equivalently, that it is online learnable). Their proof relies on a model-theoretic result by Hodges (1997), which demonstrates that any binary concept class with a large Littlestone dimension contains a large subclass of thresholds. In a follow-up work, Jung, Kim, and Tewari (2020) extended this proof to multiclass PAC learning with a bounded number of labels. Unfortunately, Hodges's result does not apply in other natural settings such as multiclass PAC learning with an unbounded label space, and PAC learning of partial concept classes.
  This naturally raises the question of whether DP learnability continues to imply online learnability in more general scenarios: indeed, Alon, Hanneke, Holzman, and Moran (2021) explicitly leave it as an open question in the context of partial concept classes, and the same question is open in the general multiclass setting. In this work, we give a positive answer to these questions showing that for general classification tasks, DP learnability implies online learnability. Our proof reasons directly about Littlestone trees, without relying on thresholds. We achieve this by establishing several Ramsey-type theorems for trees, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07765v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Fioravanti, Steve Hanneke, Shay Moran, Hilla Schefler, Iska Tsubari</dc:creator>
    </item>
    <item>
      <title>Exponentially faster fixed-parameter algorithms for high-multiplicity scheduling</title>
      <link>https://arxiv.org/abs/2203.03600</link>
      <description>arXiv:2203.03600v2 Announce Type: replace 
Abstract: We consider so-called $N$-fold integer programs (IPs) of the form $\max\{c^T x : Ax = b, \ell \leq x \leq u, x \in \mathbb Z^{nt}\}, where $A \in \mathbb Z^{(r+sn)\times nt} consists of $n$ arbitrary matrices $A^{(i)} \in \mathbb Z^{r\times t}$ on a horizontal, and $n$ arbitrary matrices $B^{(j)} \in \mathbb Z^{s\times t} on a diagonal line. Several recent works design fixed-parameter algorithms for $N$-fold IPs by taking as parameters the numbers of rows and columns of the $A$- and $B$-matrices, together with the largest absolute value $\Delta$ over their entries. These advances provide fast algorithms for several well-studied combinatorial optimization problems on strings, on graphs, and in machine scheduling. In this work, we extend this research by proposing algorithms that additionally harness a partition structure of submatrices $A^{(i)}$ and $B^{(j)}$, where row indices of non-zero entries do not overlap between any two sets in the partition. Our main result is an algorithm for solving any $N$-fold IP in time $nt log(nt)L^2(S_A)^{O(r+s)}(p_Ap_B\Delta)^{O(rp_Ap_B+sp_Ap_B)}$, where $p_A$ and $p_B$ are the size of the largest set in such a partition of $A^{(i)}$ and $B^{(j)}$, respectively, $S_A$ is the number of parts in the partition of $A = (A^{(1)},..., A^{(n)}), and $L = (log(||u - \ell||_\infty)\cdot (log(max_{x:\ell \leq x \leq u} |c^Tx|))$ is a measure of the input. We show that these new structural parameters are naturally small in high-multiplicity scheduling problems, such as makespan minimization on related and unrelated machines, with and without release times, the Santa Claus objective, and the weighted sum of completion times. In essence, we obtain algorithms that are exponentially faster than previous works by Knop et al. (ESA 2017) and Eisenbrand et al./Kouteck{\'y} et al. (ICALP 2018) in terms of the number of job types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.03600v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Fischer, Julian Golak, Matthias Mnich</dc:creator>
    </item>
    <item>
      <title>SQUID: Faster Analytics via Sampled Quantile Estimation</title>
      <link>https://arxiv.org/abs/2211.01726</link>
      <description>arXiv:2211.01726v3 Announce Type: replace 
Abstract: Streaming algorithms are fundamental in the analysis of large and online datasets. A key component of many such analytic tasks is $q$-MAX, which finds the largest $q$ values in a number stream. Modern approaches attain a constant runtime by removing small items in bulk and retaining the largest $q$ items at all times. Yet, these approaches are bottlenecked by an expensive quantile calculation.
  This work introduces a quantile-sampling approach called SQUID and shows its benefits in multiple analytic tasks. Using this approach, we design a novel weighted heavy hitters data structure that is faster and more accurate than the existing alternatives. We also show SQUID's practicality for improving network-assisted caching systems with a hardware-based cache prototype that uses SQUID to implement the cache policy. The challenge here is that the switch's dataplane does not allow the general computation required to implement many cache policies, while its CPU is orders of magnitude slower. We overcome this issue by passing just SQUID's samples to the CPU, thus bridging this gap.
  In software implementations, we show that our method is up to 6.6x faster than the state-of-the-art alternatives when using real workloads. For switch-based caching, SQUID enables a wide spectrum of data-plane-based caching policies and achieves higher hit ratios than the state-of-the-art P4LRU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01726v3</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ran Ben-Basat, Gil Einziger, Wenchen Han, Bilal Tayh</dc:creator>
    </item>
    <item>
      <title>Genome-on-Diet: Taming Large-Scale Genomic Analyses via Sparsified Genomics</title>
      <link>https://arxiv.org/abs/2211.08157</link>
      <description>arXiv:2211.08157v3 Announce Type: replace 
Abstract: Searching for similar genomic sequences is an essential and fundamental step in biomedical research and an overwhelming majority of genomic analyses. State-of-the-art computational methods performing such comparisons fail to cope with the exponential growth of genomic sequencing data. We introduce the concept of sparsified genomics where we systematically exclude a large number of bases from genomic sequences and enable much faster and more memory-efficient processing of the sparsified, shorter genomic sequences, while providing similar or even higher accuracy compared to processing non-sparsified sequences. Sparsified genomics provides significant benefits to many genomic analyses and has broad applicability. We show that sparsifying genomic sequences greatly accelerates the state-of-the-art read mapper (minimap2) by 2.57-5.38x, 1.13-2.78x, and 3.52-6.28x using real Illumina, HiFi, and ONT reads, respectively, while providing up to 2.1x smaller memory footprint, 2x smaller index size, and more truly detected small and structural variations compared to minimap2. Sparsifying genomic sequences makes containment search through very large genomes and large databases 72.7-75.88x faster and 723.3x more storage-efficient than searching through non-sparsified genomic sequences (with CMash and KMC3). Sparsifying genomic sequences enables robust microbiome discovery by providing 54.15-61.88x faster and 720x more storage-efficient taxonomic profiling of metagenomic samples over the state-of-the-art tool (Metalign). We design and open-source a framework called Genome-on-Diet as an example tool for sparsified genomics, which can be freely downloaded from https://github.com/CMU-SAFARI/Genome-on-Diet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08157v3</guid>
      <category>cs.DS</category>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohammed Alser, Julien Eudine, Onur Mutlu</dc:creator>
    </item>
    <item>
      <title>Parallelising Glauber dynamics</title>
      <link>https://arxiv.org/abs/2307.07131</link>
      <description>arXiv:2307.07131v4 Announce Type: replace 
Abstract: For distributions over discrete product spaces $\prod_{i=1}^n \Omega_i'$, Glauber dynamics is a Markov chain that at each step, resamples a random coordinate conditioned on the other coordinates. We show that $k$-Glauber dynamics, which resamples a random subset of $k$ coordinates, mixes $k$ times faster in $\chi^2$-divergence, and assuming approximate tensorization of entropy, mixes $k$ times faster in KL-divergence. We apply this to obtain parallel algorithms in two settings: (1) For the Ising model $\mu_{J,h}(x)\propto \exp(\frac1 2\left\langle x,Jx \right\rangle + \langle h,x\rangle)$ with $\|J\|&lt;1-c$ (the regime where fast mixing is known), we show that we can implement each step of $\widetilde \Theta(n/\|J\|_F)$-Glauber dynamics efficiently with a parallel algorithm, resulting in a parallel algorithm with running time $\widetilde O(\|J\|_F) = \widetilde O(\sqrt n)$. (2) For the mixed $p$-spin model at high enough temperature, we show that with high probability we can implement each step of $\widetilde \Theta(\sqrt n)$-Glauber dynamics efficiently and obtain running time $\widetilde O(\sqrt n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07131v4</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Holden Lee</dc:creator>
    </item>
    <item>
      <title>Improved bounds for the zeros of the chromatic polynomial via Whitney's Broken Circuit Theorem</title>
      <link>https://arxiv.org/abs/2309.10928</link>
      <description>arXiv:2309.10928v2 Announce Type: replace-cross 
Abstract: We prove that for any graph $G$ of maximum degree at most $\Delta$, the zeros of its chromatic polynomial $\chi_G(x)$ (in $\mathbb{C}$) lie inside the disc of radius $5.94 \Delta$ centered at $0$. This improves on the previously best known bound of approximately $6.91\Delta$.
  We also obtain improved bounds for graphs of high girth. We prove that for every $g$ there is a constant $K_g$ such that for any graph $G$ of maximum degree at most $\Delta$ and girth at least $g$, the zeros of its chromatic polynomial $\chi_G(x)$ lie inside the disc of radius $K_g \Delta$ centered at $0$, where $K_g$ is the solution to a certain optimization problem. In particular, $K_g &lt; 5$ when $g \geq 5$ and $K_g &lt; 4$ when $g \geq 25$ and $K_g$ tends to approximately $3.86$ as $g \to \infty$.
  Key to the proof is a classical theorem of Whitney which allows us to relate the chromatic polynomial of a graph $G$ to the generating function of so-called broken-circuit-free forests in $G$. We also establish a zero-free disc for the generating function of all forests in $G$ (aka the partition function of the arboreal gas) which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10928v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Jenssen, Viresh Patel, Guus Regts</dc:creator>
    </item>
    <item>
      <title>Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search</title>
      <link>https://arxiv.org/abs/2402.11354</link>
      <description>arXiv:2402.11354v2 Announce Type: replace-cross 
Abstract: Approximate nearest neighbor search (ANNS) in high-dimensional spaces is a pivotal challenge in the field of machine learning. In recent years, graph-based methods have emerged as the superior approach to ANNS, establishing a new state of the art. Although various optimizations for graph-based ANNS have been introduced, they predominantly rely on heuristic methods that lack formal theoretical backing. This paper aims to enhance routing within graph-based ANNS by introducing a method that offers a probabilistic guarantee when exploring a node's neighbors in the graph. We formulate the problem as probabilistic routing and develop two baseline strategies by incorporating locality-sensitive techniques. Subsequently, we introduce PEOs, a novel approach that efficiently identifies which neighbors in the graph should be considered for exact distance calculation, thus significantly improving efficiency in practice. Our experiments demonstrate that equipping PEOs can increase throughput on commonly utilized graph indexes (HNSW and NSSG) by a factor of 1.6 to 2.5, and its efficiency consistently outperforms the leading-edge routing technique by 1.1 to 1.4 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11354v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa</dc:creator>
    </item>
    <item>
      <title>A logarithmic approximation of linearly-ordered colourings</title>
      <link>https://arxiv.org/abs/2404.19556</link>
      <description>arXiv:2404.19556v3 Announce Type: replace-cross 
Abstract: A linearly ordered (LO) $k$-colouring of a hypergraph assigns to each vertex a colour from the set $\{0,1,\ldots,k-1\}$ in such a way that each hyperedge has a unique maximum element. Barto, Batistelli, and Berg conjectured that it is NP-hard to find an LO $k$-colouring of an LO 2-colourable 3-uniform hypergraph for any constant $k\geq 2$ [STACS'21] but even the case $k=3$ is still open. Nakajima and \v{Z}ivn\'{y} gave polynomial-time algorithms for finding, given an LO 2-colourable 3-uniform hypergraph, an LO colouring with $O^*(\sqrt{n})$ colours [ICALP'22] and an LO colouring with $O^*(\sqrt[3]{n})$ colours [ACM ToCT'23]. Very recently, Louis, Newman, and Ray gave an SDP-based algorithm with $O^*(\sqrt[5]{n})$ colours. We present two simple polynomial-time algorithms that find an LO colouring with $O(\log_2(n))$ colours, which is an exponential improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19556v3</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johan H{\aa}stad, Bj\"orn Martinsson, Tamio-Vesa Nakajima, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
  </channel>
</rss>
