<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Jul 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Reinforcement Learning On Passive RRAM Crossbar Array</title>
      <link>https://arxiv.org/abs/2407.08242</link>
      <description>arXiv:2407.08242v1 Announce Type: new 
Abstract: The unprecedented growth in the field of machine learning has led to the development of deep neuromorphic networks trained on labelled dataset with capability to mimic or even exceed human capabilities. However, for applications involving continuous decision making in unknown environments, such as rovers for space exploration, robots, unmanned aerial vehicles, etc., explicit supervision and generation of labelled data set is extremely difficult and expensive. Reinforcement learning (RL) allows the agents to take decisions without any (human/external) supervision or training on labelled dataset. However, the conventional implementations of RL on advanced digital CPUs/GPUs incur a significantly large power dissipation owing to their inherent von-Neumann architecture. Although crossbar arrays of emerging non-volatile memories such as resistive (R)RAMs with their innate capability to perform energy-efficient in situ multiply-accumulate operation appear promising for Q-learning-based RL implementations, their limited endurance restricts their application in practical RL systems with overwhelming weight updates. To address this issue and realize the true potential of RRAM-based RL implementations, in this work, for the first time, we perform an algorithm-hardware co-design and propose a novel implementation of Monte Carlo (MC) RL algorithm on passive RRAM crossbar array. We analyse the performance of the proposed MC RL implementation on the classical cart-pole problem and demonstrate that it not only outperforms the prior digital and active 1-Transistor-1-RRAM (1T1R)-based implementations by more than five orders of magnitude in terms of area but is also robust against the spatial and temporal variations and endurance failure of RRAMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08242v1</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arjun Tyagi, Shubham Sahay</dc:creator>
    </item>
    <item>
      <title>OPIMA: Optical Processing-In-Memory for Convolutional Neural Network Acceleration</title>
      <link>https://arxiv.org/abs/2407.08205</link>
      <description>arXiv:2407.08205v1 Announce Type: cross 
Abstract: Recent advances in machine learning (ML) have spotlighted the pressing need for computing architectures that bridge the gap between memory bandwidth and processing power. The advent of deep neural networks has pushed traditional Von Neumann architectures to their limits due to the high latency and energy consumption costs associated with data movement between the processor and memory for these workloads. One of the solutions to overcome this bottleneck is to perform computation within the main memory through processing-in-memory (PIM), thereby limiting data movement and the costs associated with it. However, DRAM-based PIM struggles to achieve high throughput and energy efficiency due to internal data movement bottlenecks and the need for frequent refresh operations. In this work, we introduce OPIMA, a PIM-based ML accelerator, architected within an optical main memory. OPIMA has been designed to leverage the inherent massive parallelism within main memory while performing high-speed, low-energy optical computation to accelerate ML models based on convolutional neural networks. We present a comprehensive analysis of OPIMA to guide design choices and operational mechanisms. Additionally, we evaluate the performance and energy consumption of OPIMA, comparing it with conventional electronic computing systems and emerging photonic PIM architectures. The experimental results show that OPIMA can achieve 2.98x higher throughput and 137x better energy efficiency than the best-known prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08205v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Febin Sunny, Amin Shafiee, Abhishek Balasubramaniam, Mahdi Nikdast, Sudeep Pasricha</dc:creator>
    </item>
    <item>
      <title>Cyber Attacks on Maritime Assets and their Impacts on Health and Safety Aboard: A Holistic View</title>
      <link>https://arxiv.org/abs/2407.08406</link>
      <description>arXiv:2407.08406v1 Announce Type: cross 
Abstract: There has been an unprecedented digitization drive in the industrial sector, especially in the maritime industry. The profusion of intelligent electronic devices and IOT-enabled cyber-physical systems (CPS) has helped in the efficient use of resources and increased convenience. CPS has enabled real-time remote command and control of industrial assets. Unlike the relatively isolated legacy systems, the intertwined nature of Information Technology(IT) and Operations Technology(OT) brought by Industry 4.0 has increased the complexity of the systems, thereby increasing the attack surface. This work explores the possible consequences of these attacks from a more holistic view, focusing on high-risk assets such as offshore oil rigs, offshore wind farms, and autonomous vessels. The attacks have become more aggressive with the proliferation of such technologies, disrupting the physical process, causing fire and explosion hazards, and endangering human life and environmental health. The possible attack scenarios, the attack vectors, and their physical consequences have been discussed from the perspective of personnel safety and health, along with known security breaches of such nature. To the best of the authors' knowledge, seldom has any work been done that accentuates the possible human and environmental impacts of such attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08406v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohammad Ammar, Irfan Ahmad Khan</dc:creator>
    </item>
    <item>
      <title>Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility</title>
      <link>https://arxiv.org/abs/2407.08550</link>
      <description>arXiv:2407.08550v1 Announce Type: cross 
Abstract: This paper introduces a novel approach to integrating large language model (LLM) agents into automated production systems, aimed at enhancing task automation and flexibility. We organize production operations within a hierarchical framework based on the automation pyramid. Atomic operation functionalities are modeled as microservices, which are executed through interface invocation within a dedicated digital twin system. This allows for a scalable and flexible foundation for orchestrating production processes. In this digital twin system, low-level, hardware-specific data is semantically enriched and made interpretable for LLMs for production planning and control tasks. Large language model agents are systematically prompted to interpret these production-specific data and knowledge. Upon receiving a user request or identifying a triggering event, the LLM agents generate a process plan. This plan is then decomposed into a series of atomic operations, executed as microservices within the real-world automation system. We implement this overall approach on an automated modular production facility at our laboratory, demonstrating how the LLMs can handle production planning and control tasks through a concrete case study. This results in an intuitive production facility with higher levels of task automation and flexibility. Finally, we reveal the several limitations in realizing the full potential of the large language models in autonomous systems and point out promising benefits. Demos of this series of ongoing research series can be accessed at: https://github.com/YuchenXia/GPT4IndustrialAutomation</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08550v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.51202/9783181024379</arxiv:DOI>
      <dc:creator>Yuchen Xia, Jize Zhang, Nasser Jazdi, Michael Weyrich</dc:creator>
    </item>
    <item>
      <title>Superparamagnetic Tunnel Junctions for Reliable True Randomness</title>
      <link>https://arxiv.org/abs/2407.08665</link>
      <description>arXiv:2407.08665v1 Announce Type: cross 
Abstract: Stochastic devices have the potential to disrupt computing, revolutionizing low-power machine learning acceleration, probabilistic computing, and hardware security. As implemented, however, superparamagnetic tunnel junctions (sMTJs) face significant challenges including the need for external magnetic fields, and poor reliability and scalability. Here, we present experimental demonstration of three-terminal sMTJs as scalable and reliable sources of true randomness under a field-free regime. By leveraging dual-current controllability and incorporating feedback systems, we substantially enhance the stability and reliability of sMTJ-based systems under varying conditions, even in the field-free regime. Our findings demonstrate the generation of cryptographic-quality random bitstreams and the practical use of sMTJs as efficient and reliable random number generators, successfully integrated into advanced computing algorithms like generative artificial intelligence. Field-free, truly random sMTJs promise to address critical challenges in cryptography, edge computing, and beyond, significantly advancing the field of random number generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08665v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dooyong Koh, Qiuyuan Wang, Brooke C. McGoldrick, Luqiao Liu, Marc A. Baldo</dc:creator>
    </item>
    <item>
      <title>Domain wall and Magnetic Tunnel Junction Hybrid for on-chip Learning in UNet architecture</title>
      <link>https://arxiv.org/abs/2403.02863</link>
      <description>arXiv:2403.02863v2 Announce Type: replace 
Abstract: We present spintronic devices based hardware implementation of UNet for segmentation tasks. Our approach involves designing hardware for convolution, deconvolution, rectified activation function (ReLU), and max pooling layers of the UNet architecture. We designed the convolution and deconvolution layers of the network using the synaptic behavior of the domain wall MTJ. We also construct the ReLU and max pooling functions of the network utilizing the spin hall driven orthogonal current injected MTJ. To incorporate the diverse physics of spin-transport, magnetization dynamics, and CMOS elements in our UNet design, we employ a hybrid simulation setup that couples micromagnetic simulation, non-equilibrium Green's function, SPICE simulation along with network implementation. We evaluate our UNet design on the CamVid dataset and achieve segmentation accuracies of 83.71$\%$ on test data, on par with the software implementation with 821mJ of energy consumption for on-chip training over 150 epochs. We further demonstrate nearly one order $(10\times)$ improvement in the energy requirement of the network using unstable ferromagnet ($\Delta$=4.58) over the stable ferromagnet ($\Delta$=45) based ReLU and max pooling functions while maintaining the similar accuracy. The hybrid architecture comprising domain wall MTJ and unstable FM-based MTJ leads to an on-chip energy consumption of 85.79mJ during training, with a testing energy cost of 1.55 $\mu J$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02863v2</guid>
      <category>cs.ET</category>
      <category>eess.IV</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkatesh Vadde, Bhaskaran Muralidharan, Abhishek Sharma</dc:creator>
    </item>
    <item>
      <title>VR-GPT: Visual Language Model for Intelligent Virtual Reality Applications</title>
      <link>https://arxiv.org/abs/2405.11537</link>
      <description>arXiv:2405.11537v2 Announce Type: replace-cross 
Abstract: The advent of immersive Virtual Reality applications has transformed various domains, yet their integration with advanced artificial intelligence technologies like Visual Language Models remains underexplored. This study introduces a pioneering approach utilizing VLMs within VR environments to enhance user interaction and task efficiency. Leveraging the Unity engine and a custom-developed VLM, our system facilitates real-time, intuitive user interactions through natural language processing, without relying on visual text instructions. The incorporation of speech-to-text and text-to-speech technologies allows for seamless communication between the user and the VLM, enabling the system to guide users through complex tasks effectively. Preliminary experimental results indicate that utilizing VLMs not only reduces task completion times but also improves user comfort and task engagement compared to traditional VR interaction methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11537v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mikhail Konenkov, Artem Lykov, Daria Trinitatova, Dzmitry Tsetserukou</dc:creator>
    </item>
    <item>
      <title>Measurement of the Crystallization and Phase Transition of Niobium Dioxide Thin-Films for Neuromorphic Computing Applications Using a Tube Furnace Optical Transmission System</title>
      <link>https://arxiv.org/abs/2406.13523</link>
      <description>arXiv:2406.13523v2 Announce Type: replace-cross 
Abstract: Significant research has focused on low-power stochastic devices built from memristive materials. These devices foster neuromorphic approaches to computational efficiency enhancement in merged biomimetic and CMOS architectures due to their ability to phase transition from a dielectric to a metal at an increased temperature. Niobium dioxide has a volatile memristive phase change that occurs $\sim$800$^\circ$C~that makes it an ideal candidate for future neuromorphic electronics. A straightforward optical system has been developed on a horizontal tube furnace for \emph{in situ} spectral measurements as an as-grown \NbtOf\ film is annealed and ultimately crystallizes as \NbOt. The system measures the changing spectral transmissivity of \NbtOf\ as it undergoes both reduction and crystallization processes. We were also able to measure the transition from metallic-to-non-metallic \NbOt\ during the cooldown phase, which is shown to occur about 100$^\circ$C~ lower on a sapphire substrate than fused silica. After annealing, the material properties of the \NbtOf\ and \NbOt\ were assessed via X-ray photoelectron spectroscopy, X-ray diffraction, and 4-point resistivity, confirming that we have made crystalline \NbOt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13523v2</guid>
      <category>physics.app-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary R. Robinson, Karsten Beckmann, James Michels, Vincent Daviero, Elizabeth A. Street, Fiona Lorenzen, Matthew C. Sullivan, Nathaniel Cady, Alexander Kozen, Marc Currie</dc:creator>
    </item>
  </channel>
</rss>
