<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 04:00:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Graph Linear Canonical Transform Based on CM-CC-CM Decomposition</title>
      <link>https://arxiv.org/abs/2407.17513</link>
      <description>arXiv:2407.17513v1 Announce Type: new 
Abstract: The graph linear canonical transform (GLCT) is presented as an extension of the graph Fourier transform (GFT) and the graph fractional Fourier transform (GFrFT), offering more flexibility as an effective tool for graph signal processing. In this paper, we introduce a GLCT based on chirp multiplication-chirp convolution-chirp multiplication decomposition (CM-CC-CM-GLCT), which irrelevant to sampling periods and without oversampling operation. Various properties and special cases of the CM-CC-CM-GLCT are derived and discussed. In terms of computational complexity, additivity, and reversibility, we compare the CM-CC-CM-GLCT and the GLCT based on the central discrete dilated Hermite function (CDDHFs-GLCT). Theoretical analysis demonstrates that the computational complexity of the CM-CC-CM-GLCT is significantly reduced. Simulation results indicate that the CM-CC-CM-GLCT achieves similar additivity to the CDDHFs-GLCT. Notably, the CM-CC-CM-GLCT exhibits better reversibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17513v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Na Li, Zhichao Zhang, Jie Han, Yunjie Chen, Chunzheng Cao</dc:creator>
    </item>
    <item>
      <title>Time-Shifted Alternating Gelfand-Pinsker Coding for Broadcast Channels</title>
      <link>https://arxiv.org/abs/2407.17576</link>
      <description>arXiv:2407.17576v1 Announce Type: new 
Abstract: A coding scheme for broadcast channels (BCs) is proposed that shifts the users' code blocks by different amounts of time and applies alternating Gelfand-Pinsker encoding. The scheme achieves all rate tuples in Marton's region for two receiver BCs without time-sharing or rate-splitting. Simulations with short polar codes show that the method reduces the gap to capacity as compared to time-sharing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17576v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Runge, Gerhard Kramer</dc:creator>
    </item>
    <item>
      <title>Authenticated partial correction over AV-MACs: toward characterization and coding</title>
      <link>https://arxiv.org/abs/2407.17582</link>
      <description>arXiv:2407.17582v1 Announce Type: new 
Abstract: In this paper we study $\gamma$ partial correction over a $t$-user arbitrarily varying multiple-access channel (AV-MAC). We first present necessary channel conditions for the $\gamma$ partially correcting authentication capacity region to have nonempty interior. We then give a block length extension scheme which preserves positive rate tuples from a short code with zero probability of $\gamma$ partial correction error, noting that the flexibility of $\gamma$ partial correction prevents pure codeword concatenation from being successful. Finally, we offer a case study of a particular AV-MAC satisfying the necessary conditions for partial correction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17582v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duncan Koepke, Michaela Schnell, Madelyn St. Pierre, Allison Beemer</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Design for Movable Antenna Array-Enabled Multiuser Uplink Communications</title>
      <link>https://arxiv.org/abs/2407.17841</link>
      <description>arXiv:2407.17841v1 Announce Type: new 
Abstract: Movable antenna (MA) technology can flexibly reconfigure wireless channels by adjusting antenna positions in a local region, thus owing great potential for enhancing communication performance. This letter investigates MA technology enabled multiuser uplink communications over general Rician fading channels, which consist of a base station (BS) equipped with the MA array and multiple single-antenna users. Since it is practically challenging to collect all instantaneous channel state information (CSI) by traversing all possible antenna positions at the BS, we instead propose a two-timescale scheme for maximizing the ergodic sum rate. Specifically, antenna positions at the BS are first optimized using only the statistical CSI. Subsequently, the receiving beamforming at the BS (for which we consider the three typical zero-forcing (ZF), minimum mean-square error (MMSE) and MMSE with successive interference cancellation (MMSE-SIC) receivers) is designed based on the instantaneous CSI with optimized antenna positions, thus significantly reducing practical implementation complexities. The formulated problems are highly non-convex and we develop projected gradient ascent (PGA) algorithms to effectively handle them. Simulation results illustrate that compared to conventional fixed-position antenna (FPA) array, the MA array can achieve significant performance gains by reaping an additional spatial degree of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17841v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guojie Hu, Qingqing Wu, Donghui Xu, Kui Xu, Jiangbo Si, Yunlong Cai, Naofal Al-Dhahir</dc:creator>
    </item>
    <item>
      <title>On de Bruijn Arrays Codes, Part I: Nonlinear Codes</title>
      <link>https://arxiv.org/abs/2407.18122</link>
      <description>arXiv:2407.18122v1 Announce Type: new 
Abstract: A de Bruijn arrays code is a set of $r \times s$ binary doubly-periodic arrays such that each binary $n \times m$ matrix is contained exactly once as a window in one of the arrays. Such a set of arrays can be viewed as a two-dimensional generalization of a perfect factor in the de Bruijn graph. Necessary conditions for the existence of such arrays are given. Several direct constructions and recursive constructions for such arrays are given. A framework for a theory of two-dimensional feedback shift register which is akin to (one-dimensional) feedback shift registers is suggested.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18122v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tuvi Etzion</dc:creator>
    </item>
    <item>
      <title>PIR Codes, Unequal-Data-Demand Codes, and the Griesmer Bound</title>
      <link>https://arxiv.org/abs/2407.18124</link>
      <description>arXiv:2407.18124v1 Announce Type: new 
Abstract: Unequal Error-Protecting (UEP) codes are error-correcting (EC) codes designed to protect some parts of the encoded data better than other parts. Here, we introduce a similar generalization of PIR codes that we call Unequal-Data-Demand (UDD) PIR codes. These codes are PIR-type codes designed for the scenario where some parts of the encoded data are in higher demand than other parts. We generalize various results for PIR codes to UDD codes. Our main contribution is a new approach to the Griesmer bound for linear EC codes involving an Integer Linear Programming (ILP) problem that generalizes to linear UEP codes and linear UDD PIR codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18124v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings WCC 2024</arxiv:journal_reference>
      <dc:creator>Henk D. L. Hollmann, Martin Pu\v{s}kin, Ago-Erik Riet</dc:creator>
    </item>
    <item>
      <title>Transformers on Markov Data: Constant Depth Suffices</title>
      <link>https://arxiv.org/abs/2407.17686</link>
      <description>arXiv:2407.17686v1 Announce Type: cross 
Abstract: Attention-based transformers have been remarkably successful at modeling generative processes across various domains and modalities. In this paper, we study the behavior of transformers on data drawn from \kth Markov processes, where the conditional distribution of the next symbol in a sequence depends on the previous $k$ symbols observed. We observe a surprising phenomenon empirically which contradicts previous findings: when trained for sufficiently long, a transformer with a fixed depth and $1$ head per layer is able to achieve low test loss on sequences drawn from \kth Markov sources, even as $k$ grows. Furthermore, this low test loss is achieved by the transformer's ability to represent and learn the in-context conditional empirical distribution. On the theoretical side, our main result is that a transformer with a single head and three layers can represent the in-context conditional empirical distribution for \kth Markov sources, concurring with our empirical observations. Along the way, we prove that \textit{attention-only} transformers with $O(\log_2(k))$ layers can represent the in-context conditional empirical distribution by composing induction heads to track the previous $k$ symbols in the sequence. These results provide more insight into our current understanding of the mechanisms by which transformers learn to capture context, by understanding their behavior on Markov sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17686v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nived Rajaraman, Marco Bondaschi, Kannan Ramchandran, Michael Gastpar, Ashok Vardhan Makkuva</dc:creator>
    </item>
    <item>
      <title>Use-dependent Biases as Optimal Action under Information Bottleneck</title>
      <link>https://arxiv.org/abs/2407.17793</link>
      <description>arXiv:2407.17793v1 Announce Type: cross 
Abstract: Use-dependent bias is a phenomenon in human sensorimotor behavior whereby movements become biased towards previously repeated actions. Despite being well-documented, the reason why this phenomenon occurs is not year clearly understood. Here, we propose that use-dependent biases can be understood as a rational strategy for movement under limitations on the capacity to process sensory information to guide motor output. We adopt an information-theoretic approach to characterize sensorimotor information processing and determine how behavior should be optimized given limitations to this capacity. We show that this theory naturally predicts the existence of use-dependent biases. Our framework also generates two further predictions. The first prediction relates to handedness. The dominant hand is associated with enhanced dexterity and reduced movement variability compared to the non-dominant hand, which we propose relates to a greater capacity for information processing in regions that control movement of the dominant hand. Consequently, the dominant hand should exhibit smaller use-dependent biases compared to the non-dominant hand. The second prediction relates to how use-dependent biases are affected by movement speed. When moving faster, it is more challenging to correct for initial movement errors online during the movement. This should exacerbate costs associated with initial directional error and, according to our theory, reduce the extent of use-dependent biases compared to slower movements, and vice versa. We show that these two empirical predictions, the handedness effect and the speed-dependent effect, are confirmed by experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17793v1</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hokin X. Deng, Adrian M. Haith</dc:creator>
    </item>
    <item>
      <title>Bad local minima exist in the stochastic block model</title>
      <link>https://arxiv.org/abs/2407.17851</link>
      <description>arXiv:2407.17851v1 Announce Type: cross 
Abstract: We study the disassortative stochastic block model with three communities, a well-studied model of graph partitioning and Bayesian inference for which detailed predictions based on the cavity method exist [Decelle et al. (2011)]. We provide strong evidence that for a part of the phase where efficient algorithms exist that approximately reconstruct the communities, inference based on maximum a posteriori (MAP) fails. In other words, we show that there exist modes of the posterior distribution that have a vanishing agreement with the ground truth. The proof is based on the analysis of a graph colouring algorithm from [Achlioptas and Moore (2003)].</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17851v1</guid>
      <category>math.ST</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Coja-Oghlan, Lena Krieg, Johannes Christian Lawnik, Olga Scheftelowitsch</dc:creator>
    </item>
    <item>
      <title>A Novel Perception Entropy Metric for Optimizing Vehicle Perception with LiDAR Deployment</title>
      <link>https://arxiv.org/abs/2407.17942</link>
      <description>arXiv:2407.17942v1 Announce Type: cross 
Abstract: Developing an effective evaluation metric is crucial for accurately and swiftly measuring LiDAR perception performance. One major issue is the lack of metrics that can simultaneously generate fast and accurate evaluations based on either object detection or point cloud data. In this study, we propose a novel LiDAR perception entropy metric based on the probability of vehicle grid occupancy. This metric reflects the influence of point cloud distribution on vehicle detection performance. Based on this, we also introduce a LiDAR deployment optimization model, which is solved using a differential evolution-based particle swarm optimization algorithm. A comparative experiment demonstrated that the proposed PE-VGOP offers a correlation of more than 0.98 with vehicle detection ground truth in evaluating LiDAR perception performance. Furthermore, compared to the base deployment, field experiments indicate that the proposed optimization model can significantly enhance the perception capabilities of various types of LiDARs, including RS-16, RS-32, and RS-80. Notably, it achieves a 25% increase in detection Recall for the RS-32 LiDAR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17942v1</guid>
      <category>cs.RO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjiang He, Peng Cao, Zhongling Su, Xiaobo Liu</dc:creator>
    </item>
    <item>
      <title>Scaling Training Data with Lossy Image Compression</title>
      <link>https://arxiv.org/abs/2407.17954</link>
      <description>arXiv:2407.17954v1 Announce Type: cross 
Abstract: Empirically-determined scaling laws have been broadly successful in predicting the evolution of large machine learning models with training data and number of parameters. As a consequence, they have been useful for optimizing the allocation of limited resources, most notably compute time.
  In certain applications, storage space is an important constraint, and data format needs to be chosen carefully as a consequence. Computer vision is a prominent example: images are inherently analog, but are always stored in a digital format using a finite number of bits. Given a dataset of digital images, the number of bits $L$ to store each of them can be further reduced using lossy data compression. This, however, can degrade the quality of the model trained on such images, since each example has lower resolution.
  In order to capture this trade-off and optimize storage of training data, we propose a `storage scaling law' that describes the joint evolution of test error with sample size and number of bits per image. We prove that this law holds within a stylized model for image compression, and verify it empirically on two computer vision tasks, extracting the relevant parameters. We then show that this law can be used to optimize the lossy compression level. At given storage, models trained on optimally compressed images present a significantly smaller test error with respect to models trained on the original data. Finally, we investigate the potential benefits of randomizing the compression level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17954v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katherine L. Mentzer, Andrea Montanari</dc:creator>
    </item>
    <item>
      <title>A Physical-Layer Orchestration Framework for Open System Models of Autonomous RISs</title>
      <link>https://arxiv.org/abs/2304.10858</link>
      <description>arXiv:2304.10858v2 Announce Type: replace 
Abstract: To obviate the control of reconfigurable intelligent surfaces (RISs) and related overhead, recent works envisioned the concept of autonomous RISs: Intelligent devices capable of autonomously deciding their reflection states. This paradigm is enabled by hybrid RIS (HRIS), a hardware solution that integrates sensing and channel estimation (CHEST) capabilities, enabling autonomous operation. Autonomous RISs operate independently alongside other network entities, promoting open communication system models for RISs. However, this autonomy introduces a significant challenge: How to schedule the operation of the autonomous RIS over time and frequency to minimize its impact on the network? This paper introduces a physical layer (PHY) orchestration framework within a massive multiple-input multiple-output (mMIMO) network to address this challenge. Our framework highlights an engineering trade-off termed the "autonomous RIS trade-off," which examines the performance implications of autonomy. Through mathematical analysis and numerical results, we describe the HRIS feasibility region, illustrating the conditions under which autonomous RISs are viable when properly deployed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10858v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Croisfelt, Francesco Devoti, Fabio Saggese, Vincenzo Sciancalepore, Xavier Costa-P\'erez, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Information Rate-Harvested Power Tradeoff in THz SWIPT Systems Employing Resonant Tunnelling Diode-based EH Circuits</title>
      <link>https://arxiv.org/abs/2307.06036</link>
      <description>arXiv:2307.06036v2 Announce Type: replace 
Abstract: In this paper, we study THz simultaneous wireless information and power transfer (SWIPT) systems. Since coherent information detection is challenging at THz frequencies and Schottky diodes may not be efficient for THz energy harvesting (EH) and information detection, we employ unipolar amplitude shift keying (ASK) modulation at the transmitter (TX) and a resonant tunnelling diode (RTD)-based EH circuit at the receiver (RX) to extract both information and power from the RX signal. We model the dependence of the instantaneous output power at the RX on the instantaneous received power by a non-linear piecewise function, whose parameters are adjusted to fit circuit simulation results. To determine the rate-power tradeoff in THz SWIPT systems, we derive the distribution of the TX signal that maximizes the mutual information between the TX and RX signals subject to constraints on the required average harvested power at the RX and the peak signal amplitude at the TX. Since the computational complexity of maximizing the mutual information may be too high for real-time THz SWIPT systems, for high and low required average harvested powers, we also obtain the suboptimal input signal distribution that maximizes the achievable information rate numerically and in closed form, respectively. Furthermore, based on the obtained results, we propose a suboptimal closed-form TX distribution which also achieves a desired harvested power at the RX. Our simulation results show that a lower reverse current flow and a higher breakdown voltage of the employed RTD are preferable when the input signal power at the RX is low and high, respectively. Finally, we demonstrate that for low and high received signal powers, the rate-power tradeoff of THz SWIPT systems is determined by the peak amplitude of the TX signal and the maximum instantaneous harvested power, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06036v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Shanin, Simone Clochiatti, Kenneth M. Mayer, Laura Cottatellucci, Nils Weimann, Robert Schober</dc:creator>
    </item>
    <item>
      <title>Detection of Correlated Random Vectors</title>
      <link>https://arxiv.org/abs/2401.13429</link>
      <description>arXiv:2401.13429v3 Announce Type: replace 
Abstract: In this paper, we investigate the problem of deciding whether two standard normal random vectors $\mathsf{X}\in\mathbb{R}^{n}$ and $\mathsf{Y}\in\mathbb{R}^{n}$ are correlated or not. This is formulated as a hypothesis testing problem, where under the null hypothesis, these vectors are statistically independent, while under the alternative, $\mathsf{X}$ and a randomly and uniformly permuted version of $\mathsf{Y}$, are correlated with correlation $\rho$. We analyze the thresholds at which optimal testing is information-theoretically impossible and possible, as a function of $n$ and $\rho$. To derive our information-theoretic lower bounds, we develop a novel technique for evaluating the second moment of the likelihood ratio using an orthogonal polynomials expansion, which among other things, reveals a surprising connection to integer partition functions. We also study a multi-dimensional generalization of the above setting, where rather than two vectors we observe two databases/matrices, and furthermore allow for partial correlations between these two.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13429v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dor Elimelech, Wasim Huleihel</dc:creator>
    </item>
    <item>
      <title>An Information Aggregation Operator</title>
      <link>https://arxiv.org/abs/2401.15867</link>
      <description>arXiv:2401.15867v2 Announce Type: replace 
Abstract: This study explores a new mathematical operator, symbolized as $\cupplus$, for information aggregation, aimed at enhancing traditional methods by directly amalgamating probability distributions. This operator facilitates the combination of probability densities, contributing a nuanced approach to probabilistic analysis. We apply this operator to a personalized incentive scenario, illustrating its potential in a practical context. The paper's primary contribution lies in introducing this operator and elucidating its elegant mathematical properties. This exploratory work marks a step forward in the field of information fusion and probabilistic reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15867v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heyang Gong</dc:creator>
    </item>
    <item>
      <title>An Improved Viterbi Algorithm for a Class of Optimal Binary Convolutional Codes</title>
      <link>https://arxiv.org/abs/2402.01279</link>
      <description>arXiv:2402.01279v2 Announce Type: replace 
Abstract: The most famous error-decoding algorithm for convolutional codes is the Viterbi algorithm. In this paper, we present a new reduced complexity version of this algorithm which can be applied to a class of binary convolutional codes with optimum column distances called k-partial simplex convolutional codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01279v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zita Abreu, Julia Lieb, Michael Schaller</dc:creator>
    </item>
    <item>
      <title>Robust Beamforming for RIS-aided Communications: Gradient-based Manifold Meta Learning</title>
      <link>https://arxiv.org/abs/2402.10626</link>
      <description>arXiv:2402.10626v3 Announce Type: replace 
Abstract: Reconfigurable intelligent surface (RIS) has become a promising technology to realize the programmable wireless environment via steering the incident signal in fully customizable ways. However, a major challenge in RIS-aided communication systems is the simultaneous design of the precoding matrix at the base station (BS) and the phase shifting matrix of the RIS elements. This is mainly attributed to the highly non-convex optimization space of variables at both the BS and the RIS, and the diversity of communication environments. Generally, traditional optimization methods for this problem suffer from the high complexity, while existing deep learning based methods are lack of robustness in various scenarios. To address these issues, we introduce a gradient-based manifold meta learning method (GMML), which works without pre-training and has strong robustness for RIS-aided communications. Specifically, the proposed method fuses meta learning and manifold learning to improve the overall spectral efficiency, and reduce the overhead of the high-dimensional signal process. Unlike traditional deep learning based methods which directly take channel state information as input, GMML feeds the gradients of the precoding matrix and phase shifting matrix into neural networks. Coherently, we design a differential regulator to constrain the phase shifting matrix of the RIS. Numerical results show that the proposed GMML can improve the spectral efficiency by up to 7.31\%, and speed up the convergence by 23 times faster compared to traditional approaches. Moreover, they also demonstrate remarkable robustness and adaptability in dynamic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10626v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fenghao Zhu, Xinquan Wang, Chongwen Huang, Zhaohui Yang, Xiaoming Chen, Ahmed Alhammadi, Zhaoyang Zhang, Chau Yuen, M\'erouane Debbah</dc:creator>
    </item>
    <item>
      <title>Chernoff Information as a Privacy Constraint for Adversarial Classification</title>
      <link>https://arxiv.org/abs/2403.10307</link>
      <description>arXiv:2403.10307v2 Announce Type: replace 
Abstract: This work inspects a privacy metric based on Chernoff information, \textit{Chernoff differential privacy}, due to its significance in characterization of the optimal classifier's performance. Adversarial classification, as any other classification problem is built around minimization of the (average or correct detection) probability of error in deciding on either of the classes in the case of binary classification. Unlike the classical hypothesis testing problem, where the false alarm and mis-detection probabilities are handled separately resulting in an asymmetric behavior of the best error exponent, in this work, we focus on the Bayesian setting and characterize the relationship between the best error exponent of the average error probability and $\varepsilon\textrm{-}$differential privacy \cite{D06}. Accordingly, we re-derive Chernoff differential privacy in terms of $\varepsilon\textrm{-}$differential privacy using the Radon-Nikodym derivative and show that it satisfies the composition property for sequential composition. Subsequently, we present numerical evaluation results, which demonstrates that Chernoff information outperforms Kullback-Leibler divergence as a function of the privacy parameter $\varepsilon$, the impact of the adversary's attack and global sensitivity for the problem of adversarial classification in Laplace mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10307v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ay\c{s}e \"Unsal, Melek \"Onen</dc:creator>
    </item>
    <item>
      <title>PAPR Reduction with Pre-chirp Selection for Affine Frequency Division Multiplexing</title>
      <link>https://arxiv.org/abs/2406.14064</link>
      <description>arXiv:2406.14064v3 Announce Type: replace 
Abstract: Affine frequency division multiplexing (AFDM) is a promising new multicarrier technique for high-mobility communications based on discrete affine Fourier transform (DAFT). By properly tuning the pre-chirp parameter and the post-chirp parameter in the DAFT, the effective channel in the DAFT domain can completely circumvent path overlap, thereby constituting a full representation of delay-Doppler profile. However, AFDM has a crucial problem of high peak-to-average power ratio (PAPR), stemming from randomness of modulated symbols. In this letter, a novel algorithm named grouped pre-chirp selection (GPS) is proposed to reduce PAPR by strategically varying the pre-chirp parameter across subcarrier groups. Initially, it is established that key AFDM properties are maintained when implementing GPS. Next, we proceed to detail the operational procedures of the GPS algorithm, elucidating its principle for PAPR reduction and emphasizing its computational efficiency advantages. Finally, simulation results employing the complementary cumulative distribution function (CCDF) validate the effectiveness of the proposed GPS in reducing PAPR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14064v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haozhi Yuan, Yin Xu, Xinghao Guo, Yao Ge, Tianyao Ma, Haoyang Li, Dazhi He, Wenjun Zhang</dc:creator>
    </item>
    <item>
      <title>Ruminations on Matrix Convexity and the Strong Subadditivity of Quantum Entropy</title>
      <link>https://arxiv.org/abs/2210.10729</link>
      <description>arXiv:2210.10729v5 Announce Type: replace-cross 
Abstract: The familiar second derivative test for convexity, combined with resolvent calculus, is shown to yield a useful tool for the study of convex matrix-valued functions. We demonstrate the applicability of this approach on a number of theorems in this field. These include convexity principles which play an essential role in the Lieb-Ruskai proof of the strong subadditivity of quantum entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.10729v5</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11005-023-01638-2</arxiv:DOI>
      <dc:creator>Michael Aizenman, Giorgio Cipolloni</dc:creator>
    </item>
    <item>
      <title>On SAT information content, its polynomial-time solvability and fixed code algorithms</title>
      <link>https://arxiv.org/abs/2401.00947</link>
      <description>arXiv:2401.00947v3 Announce Type: replace-cross 
Abstract: The amount of information in satisfiability problem (SAT) is considered. SAT can be polynomial-time solvable when the solving algorithm holds an exponential amount of information. It is also established that SAT Kolmogorov complexity is constant. It is argued that the amount of information in SAT grows at least exponentially with the size of the input instance. The amount of information in SAT is compared with the amount of information in the fixed code algorithms and generated over runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00947v3</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Drozdowski</dc:creator>
    </item>
    <item>
      <title>Block Verification Accelerates Speculative Decoding</title>
      <link>https://arxiv.org/abs/2403.10444</link>
      <description>arXiv:2403.10444v2 Announce Type: replace-cross 
Abstract: Speculative decoding is an effective method for lossless acceleration of large language models during inference. It uses a fast model to draft a block of tokens which are then verified in parallel by the target model, and provides a guarantee that the output is distributed identically to a sample from the target model. In prior works, draft verification is performed independently token-by-token. Surprisingly, we show that this approach is not optimal. We propose Block Verification, a simple draft verification algorithm that verifies the entire block jointly and provides additional wall-clock speedup. We prove that the proposed mechanism is optimal in the expected number of tokens produced each iteration and specifically is never worse than the standard token-level verification. Empirically, block verification provides modest but consistent wall-clock speedups over the standard token verification algorithm of 5%-8% in a range of tasks and datasets. Given that block verification does not increase code complexity, maintains the strong lossless guarantee of the standard speculative decoding verification algorithm, cannot deteriorate performance, and, in fact, consistently improves it, it can be used as a good default in speculative decoding implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10444v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziteng Sun, Uri Mendlovic, Yaniv Leviathan, Asaf Aharoni, Ahmad Beirami, Jae Hun Ro, Ananda Theertha Suresh</dc:creator>
    </item>
    <item>
      <title>Orthogonal projectors of binary LCD codes</title>
      <link>https://arxiv.org/abs/2407.07689</link>
      <description>arXiv:2407.07689v2 Announce Type: replace-cross 
Abstract: We prove that binary even LCD code and some graphs are in one-to-one correspondence in a certain way. Furthermore, we show that adjacency matrices of non-isomorphic simple graphs give inequivalent binary LCD codes, and vice versa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07689v2</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keita Ishizuka</dc:creator>
    </item>
  </channel>
</rss>
