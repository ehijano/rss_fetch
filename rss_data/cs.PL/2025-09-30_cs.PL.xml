<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Oct 2025 02:06:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Cost Bounds with Linear Maps</title>
      <link>https://arxiv.org/abs/2509.22982</link>
      <description>arXiv:2509.22982v1 Announce Type: new 
Abstract: The Automatic Amortized Resource Analysis (AARA) derives program-execution cost bounds using types. To do so, AARA often makes use of cost-free types, which are critical for the composition of types and cost bounds. However, inferring cost-free types using the current state-of-the-art algorithm is expensive due to recursive dependence on additional cost-free types. Furthermore, that algorithm uses a heuristic only applicable to polynomial cost bounds, and not, e.g., exponential bounds. This paper presents a new approach to these problems by representing the cost-free types of a function in a new way: with a linear map, which can stand for infinitely many cost-free types. Such maps enable an algebraic flavor of reasoning about cost bounds (including non-polynomial bounds) via matrix inequalities. These inequalities can be solved with off-the-shelf linear-programming tools for many programs, so that types can always be efficiently checked and often be efficiently inferred. An experimental evaluation with a prototype implementation shows that-when it is applicable-the inference of linear maps is exponentially more efficient than the state-of-the-art algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22982v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M Kahn, Jan Hoffmann, Thomas Reps, Jessie Grosen</dc:creator>
    </item>
    <item>
      <title>Local Success Does Not Compose: Benchmarking Large Language Models for Compositional Formal Verification</title>
      <link>https://arxiv.org/abs/2509.23061</link>
      <description>arXiv:2509.23061v1 Announce Type: new 
Abstract: We introduce DafnyCOMP, a benchmark for evaluating large language models (LLMs) on compositional specification generation in Dafny. Unlike prior benchmarks that focus on single-function tasks, DafnyCOMP targets programs composed of multiple interacting functions with data dependencies, requiring reasoning across component boundaries. The benchmark consists of 300 automatically synthesized multi-function programs. We evaluate several state-of-the-art LLM families and find that, while they perform well on single-function verification, their performance drops sharply on compositional tasks. Analysis reveals systematic failures in cross-functional reasoning, including fragile specifications, misalignment between implementations and proofs, and unstable reasoning. DafnyCOMP thus provides a diagnostic tool for measuring progress toward reliable, verifiable, and compositional code generation with LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23061v1</guid>
      <category>cs.PL</category>
      <category>cs.AI</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xu Xu, Xin Li, Xingwei Qu, Jie Fu, Binhang Yuan</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Reasoning About Container-Internal Pointers with Logical Pinning</title>
      <link>https://arxiv.org/abs/2509.23229</link>
      <description>arXiv:2509.23229v1 Announce Type: new 
Abstract: Most separation logics hide container-internal pointers for modularity. This makes it difficult to specify container APIs that temporarily expose those pointers to the outside, and to verify programs that use these APIs. We present logical pinning, a lightweight borrowing model for sequential programs that allows users to selectively track container-internal pointers at the logical level. Our model generalizes the magic-wand operator, making it easy to write and prove precise specifications, including pointer-stability properties. Because it only changes how representation predicates and specifications are written, our approach is compatible with most separation logic variants. We demonstrate the practicality of logical pinning by verifying small but representative pointer-manipulating programs, and deriving more precise versions of common container specifications. In doing so, we show that our approach subsumes some well-known proof patterns, simplifies some complex proofs, and enables reasoning about program patterns not supported by traditional specifications. All of our results are mechanized in the Rocq proof assistant, using the CFML library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23229v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yawen Guan, Cl\'ement Pit-Claudel</dc:creator>
    </item>
    <item>
      <title>From Affine to Polynomial: Synthesizing Loops with Branches via Algebraic Geometry</title>
      <link>https://arxiv.org/abs/2509.25114</link>
      <description>arXiv:2509.25114v1 Announce Type: new 
Abstract: Ensuring software correctness remains a fundamental challenge in formal program verification. One promising approach relies on finding polynomial invariants for loops. Polynomial invariants are properties of a program loop that hold before and after each iteration. Generating such invariants is a crucial task in loop analysis, but it is undecidable in the general case. Recently, an alternative approach to this problem has emerged, focusing on synthesizing loops from invariants. However, existing methods only synthesize affine loops without guard conditions from polynomial invariants. In this paper, we address a more general problem, allowing loops to have polynomial update maps with a given structure, inequations in the guard condition, and polynomial invariants of arbitrary form.
  We use algebraic geometry tools to design and implement an algorithm that computes a finite set of polynomial equations whose solutions correspond to all nondeterministic branching loops satisfying the given invariants. Furthermore, we introduce a new class of invariants for which we present a significantly more efficient algorithm. In other words, we reduce the problem of synthesizing loops to find solutions of multivariate polynomial systems with rational entries. This final step is handled in our software using an SMT solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25114v1</guid>
      <category>cs.PL</category>
      <category>cs.SC</category>
      <category>math.AG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erdenebayar Bayarmagnai, Fatemeh Mohammadi, R\'emi Pr\'ebet</dc:creator>
    </item>
    <item>
      <title>A benchmark for vericoding: formally verified program synthesis</title>
      <link>https://arxiv.org/abs/2509.22908</link>
      <description>arXiv:2509.22908v1 Announce Type: cross 
Abstract: We present and test the largest benchmark for vericoding, LLM-generation of formally verified code from formal specifications - in contrast to vibe coding, which generates potentially buggy code from a natural language description. Our benchmark contains 12,504 formal specifications, with 3,029 in Dafny, 2,334 in Verus/Rust and 7,141 in Lean. Of these, 6,174 are new unseen problems. We find vericoding success rates of 27% in Lean, 44% in Verus/Rust and 82% in Dafny using off-the-shelf LLMs. Adding natural-language descriptions does not significantly improve performance. We also find that LLM progress has improved progress on pure Dafny verification from 68% to 96% over the past year. The benchmark and vericoding results are shared at https://github.com/Beneficial-AI-Foundation/vericoding-benchmark</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22908v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergiu Bursuc (BAIF), Theodore Ehrenborg (BAIF), Shaowei Lin (BAIF), Lacramioara Astefanoaei (BAIF), Ionel Emilian Chiosa (MIT), Jure Kukovec (BAIF), Alok Singh (BAIF), Oliver Butterley (BAIF), Adem Bizid (BAIF), Quinn Dougherty (BAIF), Miranda Zhao (MIT), Max Tan (MIT), Max Tegmark (MIT)</dc:creator>
    </item>
    <item>
      <title>TF-Bench: Evaluating Program Semantics Reasoning with Type Inference in System F</title>
      <link>https://arxiv.org/abs/2509.23686</link>
      <description>arXiv:2509.23686v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are increasingly integrated into the software engineering ecosystem. Their test-time compute (TTC) reasoning capabilities show significant potential for understanding program logic and semantics beyond mere token recognition. However, current benchmarks for code reasoning lack a formal, program-centric deductive framework to ensure sound evaluation, and are incapable of assessing whether models genuinely reason about program semantics or merely exploit superficial associations between natural language and code tokens. To bridge this gap, we introduce TF-Bench, a benchmark designed to evaluate LLM reasoning based on type inference in System F, a task we refer to as program semantics reasoning. By employing verified transformations to remove semantically irrelevant natural language, we construct TF-Bench_pure, a purely semantics-driven variant of TF-Bench. Our analysis reveals substantial limitations in state-of-the-art LLMs, with the best-performing LLM (Claude-3.7-sonnet) achieving only 55.85% accuracy on TF-Bench_pure. Additionally, we propose two novel metrics to assess robustness and the effectiveness of test-time reasoning, underscoring critical limitations in current LLM capabilities and highlighting essential directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23686v1</guid>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifeng He, Luning Yang, Christopher Castro Gaw Gonzalo, Hao Chen</dc:creator>
    </item>
    <item>
      <title>Agentic Specification Generator for Move Programs</title>
      <link>https://arxiv.org/abs/2509.24515</link>
      <description>arXiv:2509.24515v1 Announce Type: cross 
Abstract: While LLM-based specification generation is gaining traction, existing tools primarily focus on mainstream programming languages like C, Java, and even Solidity, leaving emerging and yet verification-oriented languages like Move underexplored. In this paper, we introduce MSG, an automated specification generation tool designed for Move smart contracts. MSG aims to highlight key insights that uniquely present when applying LLM-based specification generation to a new ecosystem. Specifically, MSG demonstrates that LLMs exhibit robust code comprehension and generation capabilities even for non-mainstream languages. MSG successfully generates verifiable specifications for 84% of tested Move functions and even identifies clauses previously overlooked by experts. Additionally, MSG shows that explicitly leveraging specification language features through an agentic, modular design improves specification quality substantially (generating 57% more verifiable clauses than conventional designs). Incorporating feedback from the verification toolchain further enhances the effectiveness of MSG, leading to a 30% increase in generated verifiable specifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24515v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Fu Fu, Meng Xu, Taesoo Kim</dc:creator>
    </item>
    <item>
      <title>Ranking Functions for Linear-Constraint Loops</title>
      <link>https://arxiv.org/abs/1208.4041</link>
      <description>arXiv:1208.4041v4 Announce Type: replace 
Abstract: In this paper we study the complexity of the problems: given a loop, described by linear constraints over a finite set of variables, is there a linear or lexicographical-linear ranking function for this loop? While existence of such functions implies termination, these problems are not equivalent to termination. When the variables range over the rationals (or reals), it is known that both problems are PTIME decidable. However, when they range over the integers, whether for single-path or multipath loops, the complexity has not yet been determined. We show that both problems are coNP-complete. However, we point out some special cases of importance of PTIME complexity. We also present complete algorithms for synthesizing linear and lexicographical-linear ranking functions, both for the general case and the special PTIME cases. Moreover, in the rational setting, our algorithm for synthesizing lexicographical-linear ranking functions extends existing ones, because our class of ranking functions is more general, yet it has polynomial time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:1208.4041v4</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/2629488</arxiv:DOI>
      <arxiv:journal_reference>J. ACM 61(4): 26:1-26:55 (2014)</arxiv:journal_reference>
      <dc:creator>Amir M. Ben-Amram, Samir Genaim</dc:creator>
    </item>
    <item>
      <title>An approach for modularly verifying the core of Rust's atomic reference counting algorithm against the (Y)C20 memory consistency model</title>
      <link>https://arxiv.org/abs/2505.00449</link>
      <description>arXiv:2505.00449v4 Announce Type: replace 
Abstract: We propose an approach for modular verification of programs that use relaxed-consistency atomic memory access primitives and fences. The approach is sufficient for verifying the core of Rust's Atomic Reference Counting (ARC) algorithm. We first argue its soundness, when combined with a simple static analysis and admitting an open sub-problem, with respect to the C20 memory consistency model. We then argue its soundness, even in the absence of any static analysis and without any assumptions, with respect to YC20, a minor strengthening of XC20, itself a recently proposed minor strengthening of C20 that rules out out-of-thin-air behaviors but allows load buffering. In contrast to existing work on verifying ARC, we do not assume acyclicity of the union of the program-order and reads-from relations. We define an interleaving operational semantics, prove its soundness with respect to (Y)C20's axiomatic semantics, and then apply any existing program logic for fine-grained interleaving concurrency, such as Iris.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00449v4</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart Jacobs, Justus Fasse</dc:creator>
    </item>
    <item>
      <title>Learning Randomized Reductions</title>
      <link>https://arxiv.org/abs/2412.18134</link>
      <description>arXiv:2412.18134v2 Announce Type: replace-cross 
Abstract: A self-corrector for a function $f$ takes a black-box oracle computing $f$ that is correct on most inputs and turns it into one that is correct on every input with high probability. Self-correctors exist for any function that is randomly self-reducible (RSR), where the value $f$ at a given point $x$ can be recovered by computing $f$ on random correlated points. While RSRs enable powerful self-correction capabilities and have applications in complexity theory and cryptography, their discovery has traditionally required manual derivation by experts. We present Bitween, a method and tool for automated learning of randomized self-reductions for mathematical functions. We make two key contributions: First, we demonstrate that our learning framework based on linear regression outperforms sophisticated methods including genetic algorithms, symbolic regression, and mixed-integer linear programming for discovering RSRs from correlated samples. Second, we introduce Agentic Bitween, a neuro-symbolic approach where large language models dynamically discover novel query functions for RSR property discovery, leveraging vanilla Bitween as a tool for inference and verification, moving beyond the fixed query functions ($x+r$, $x-r$, $x \cdot r$, $x$, $r$) previously used in the literature. On RSR-Bench, our benchmark suite of 80 scientific and machine learning functions, vanilla Bitween surpasses existing symbolic methods, while Agentic Bitween discovers new RSR properties using frontier models to uncover query functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18134v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ferhat Erata, Orr Paradise, Thanos Typaldos, Timos Antonopoulos, ThanhVu Nguyen, Shafi Goldwasser, Ruzica Piskac</dc:creator>
    </item>
  </channel>
</rss>
