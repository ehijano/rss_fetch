<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 05:02:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Adaptive Ch Method with Local Coupled Multiquadrics for Solving Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2511.14929</link>
      <description>arXiv:2511.14929v1 Announce Type: new 
Abstract: We present a new adaptive collocation scheme for solving partial differential equations based on Local Coupled Multiquadrics (LCMQs) within a covers-and-nodes framework. The method, referred to as the Adaptive Ch Method, automatically prioritizes adjusting the local cover size C then refines local nodal spacing h to achieve a prescribed tolerance. Numerical examples for one- and two-dimensional Poisson problems demonstrate accurate solutions across a wide range of shape parameter values, while preserving the advantages of local collocation. The proposed approximation approach is truly meshless, requiring no element, connectivity or continuity to construct trial functions or weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14929v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed E. Seleit</dc:creator>
    </item>
    <item>
      <title>Lippmann-Schwinger-Lanczos algorithm for inverse scattering problems with unknown reflectivity and loss distributions: One-dimensional Case</title>
      <link>https://arxiv.org/abs/2511.15058</link>
      <description>arXiv:2511.15058v1 Announce Type: new 
Abstract: We consider one-dimensional inverse scattering in attenuating media where both the reflectivity and loss distributions are unknown. Mathematically, this corresponds to recovering the coefficients of a damped wave operator, or equivalently, a quadratic operator pencil in the frequency domain.
  The Lippmann-Schwinger equation maps the unknown reflectivity and loss distribution to the measured scattered data. This mapping is nonlinear, as it requires knowledge of the internal wavefield, which itself depends on the reflectivity and loss distribution. The Lippmann-Schwinger-Lanczos method addresses this nonlinearity by approximating the internal solutions through the lifting of states from a reduced-order model constructed directly from the measured data.
  In this work, we extend the method to dissipative problems, enabling the approximation of internal partial differential equation (PDE) solutions in media with both reflectivity and loss distributions. We present two complementary constructions of such internal solutions: one based on spectral data and another on frequency-domain measurements over a finite interval. This development establishes a direct link between data-driven reduced-order models for inverse problems and port-Hamiltonian dynamical systems, with reduced models obtained either from the associated spectral measure or via rational approximation. Compared to the Born approximation, which replaces the internal field with the background field, our approach yields more accurate internal reconstructions and enables faster and more robust recovery of the contrast as evidenced by our numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15058v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorn Zimmerling, Mikhail Zaslavsky, Alexander V. Mamonov, Vladimir Druskin, Anarzhan Abilgazy</dc:creator>
    </item>
    <item>
      <title>Error Analysis on a Novel Class of Exponential Integrators with Local Linear Extension Techniques for Highly Oscillatory ODEs</title>
      <link>https://arxiv.org/abs/2511.15104</link>
      <description>arXiv:2511.15104v1 Announce Type: new 
Abstract: This paper studies a class of non-autonomous highly oscillatory ordinary differential equations (ODEs) featuring a linear component inversely proportional to a small parameter $\varepsilon$ with purely imaginary eigenvalues, alongside an $\varepsilon$-independent nonlinear component. When $0&lt;\varepsilon\ll 1$, the rapidly oscillatory solution constrains the step size selection and numerical accuracy, resulting in significant computational challenges. Motivated by linearization through introducing auxiliary polynomial variables, a new class of explicit exponential integrators (EIs) has recently been developed. The methods do not require the linear part to be diagonal or with all eigenvalues to be integer multiples of a fixed value - a general assumption in multiscale methods - and attain arbitrarily high convergence order without any order conditions. The main contribution of this work is to establish a rigorous error analysis for the new class of methods. To do this, we first demonstrate the equivalence between the high-dimensional system and the original problem by employing algebraic techniques. Building upon these fundamental results, we prove that the numerical schemes have a uniform convergence order of $O(h^{k+1})$ for the solution when using at most $k$-degree auxiliary polynomial variables with time step sizes smaller than $\varepsilon$. For larger step sizes under the bounded oscillatory energy condition, the methods achieve a convergence order of $O(\varepsilon h^k)$ for the solution. These theoretical results are further applied to second-order oscillatory equations, yielding improved uniform accuracy with respect to $\varepsilon$. Finally, numerical experiments confirm the optimality of the derived error estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15104v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Qi, Weibing Deng, Fuhai Zhu</dc:creator>
    </item>
    <item>
      <title>An efficient fully explicit scheme for stochastic Navier-Stokes equations driven by multiplicative noise</title>
      <link>https://arxiv.org/abs/2511.15230</link>
      <description>arXiv:2511.15230v1 Announce Type: new 
Abstract: This work proposes an efficient, linear, and fully decoupled pressure-correction scheme for the 2D stochastic Navier-Stokes equations with multiplicative noise and Dirichlet boundary condition. Leveraging the auxiliary variable approach, the scheme is fully explicit yet unconditionally stable. At each time step, it only requires solving Poisson-type equations with constant coefficients. To the best of our knowledge, this is the first application of the auxiliary variable method to stochastic Navier-Stokes equations. We provide a detailed strong convergence analysis for the linearized equation under standard assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15230v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Can Huang, Weiwen Wang, Chuanju Xu</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of the high-frequency Helmholtz equation using semiclassical analysis</title>
      <link>https://arxiv.org/abs/2511.15287</link>
      <description>arXiv:2511.15287v1 Announce Type: new 
Abstract: We consider the numerical solution of high-frequency scattering problems modeled by the Helmholtz equation with a bounded obstacle. Although the analysis of this problem dates back at least 50 years, over the past decade or so, tools and techniques from $\textit{semiclassical analysis}$ have provided a new perspective and been used to settle several long-standing open problems in this area. Semiclassical analysis works in phase space (i.e., position and frequency) and describes rigorously the extent to which solutions of high-frequency PDEs are dictated by the properties of the corresponding geometric-optic rays.
  The goals of the article are to (i) give a introduction to semiclassical analysis aimed at non-experts and (ii) showcase some of the numerical-analysis results about finite-element methods, boundary-element methods, and domain-decomposition methods obtained using semiclassical techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15287v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Galkowski, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>A Hybrid-High Order method for fracture modelling</title>
      <link>https://arxiv.org/abs/2511.15345</link>
      <description>arXiv:2511.15345v1 Announce Type: new 
Abstract: In this work, we introduce a new Hybrid High-Order method for the numerical simulation of fracture propagation based on phase-field models. The proposed method supports general meshes made of polygonal/polyhedral elements, which provides great flexibility in mesh design and adaptation, and can accommodate large variations of both the displacement and damage variables thanks to the use of fully discontinuous spaces. The resolution of the corresponding algebraic problem is based on a staggered time stepping scheme which takes advantage of static condensation for each subproblem. We provide extensive numerical validation of the method on classical two-dimensional fracture propagation problems, including a comparison with a more standard finite element scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15345v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandra Crippa, Julien Coatl\'even, Daniele A. Di Pietro, Nicolas Guy, Yousef Soleiman</dc:creator>
    </item>
    <item>
      <title>On the conditioning of histopolation</title>
      <link>https://arxiv.org/abs/2511.15395</link>
      <description>arXiv:2511.15395v1 Announce Type: new 
Abstract: Histopolation is the approximation procedure that associates a degree $ d-1 $ polynomial $ p_{d-1} \in \mathscr{P}_{d-1} (I) $ with a locally integrable function $ f $ imposing that the integral (or, equivalently, the average) of $p$ coincides with that of $f$ on a collection of $ d $ distinct segments $s_i$. In this work we discuss unisolvence and conditioning of the associated matrices, in an asymptotic linear algebra perspective, i.e., when the matrix-size $d$ tends to infinity. While the unisolvence is a rather sparse topic, the conditioning in the unisolvent setting has a uniform behavior: as for the case of standard Vandermonde matrix-sequences with real nodes, the conditioning is inherently exponential as a function of $d$ when the monomial basis is chosen. In contrast, for an appropriate selection of supports, the Chebyshev basis of second kind has a bounded conditioning. A linear behavior is also observed in the Frobenius norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15395v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovico Bruni Bruno, Stefano Serra-Capizzano</dc:creator>
    </item>
    <item>
      <title>Neural network-driven domain decomposition for efficient solutions to the Helmholtz equation</title>
      <link>https://arxiv.org/abs/2511.15445</link>
      <description>arXiv:2511.15445v1 Announce Type: new 
Abstract: Accurately simulating wave propagation is crucial in fields such as acoustics, electromagnetism, and seismic analysis. Traditional numerical methods, like finite difference and finite element approaches, are widely used to solve governing partial differential equations (PDEs) such as the Helmholtz equation. However, these methods face significant computational challenges when applied to high-frequency wave problems in complex two-dimensional domains. This work investigates Finite Basis Physics-Informed Neural Networks (FBPINNs) and their multilevel extensions as a promising alternative. These methods leverage domain decomposition, partitioning the computational domain into overlapping sub-domains, each governed by a local neural network. We assess their accuracy and computational efficiency in solving the Helmholtz equation for the homogeneous case, demonstrating their potential to mitigate the limitations of traditional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15445v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Victorita Dolean, Daria Hrebenshchykova, St\'ephane Lanteri, Victor Michel-Dansac</dc:creator>
    </item>
    <item>
      <title>Fractional Quadrature rule and using its Exactness for the M\"untz-Legendre Scaling Functions for Solving Fractional Differential Equations</title>
      <link>https://arxiv.org/abs/2511.15478</link>
      <description>arXiv:2511.15478v1 Announce Type: new 
Abstract: Fractional operators (derivatives/integrals) are defined via the integration of the functions. When the function is produced by a spanning set of fractional power functions, traditional quadrature rules often need to be revised, failing to provide exact evaluations for fractional power functions and thus introducing approximation errors. In this paper, we have formulated a fractional quadrature rule that achieves exact integration for functions within this specific set to address this issue. Some properties of the fractional quadrature rule have been proved, and the absolute error bound in the proposed fractional quadrature rule has been derived. The behavior of roots of the orthogonal M\"untz polynomial has also been observed for its application as nodes in the fractional quadrature rule. To illustrate the effectiveness of the newly proposed fractional quadrature rule, we focus on fractional differential equations that incorporate the left Caputo fractional derivative. In this context, M\"untz-Legendre scaling functions are utilized to approximate the Caputo derivative of functions involved in these equations. Additionally, we have derived an operational matrix for Riemann-Liouville integration to approximate the respective functions with the help of the fractional quadrature rule. To demonstrate the practical utility of our method, we provide illustrative examples that compare the $L_2$-error estimates in the solutions of fractional differential equations using our approach against those obtained with the Block-pulse method. These comparisons underscore the superior accuracy of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15478v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ritu Kumari, Mani Mehra, Abhishek Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Convergence and Sketching-Based Efficient Computation of Neural Tangent Kernel Weights in Physics-Based Loss</title>
      <link>https://arxiv.org/abs/2511.15530</link>
      <description>arXiv:2511.15530v1 Announce Type: new 
Abstract: In multi-objective optimization, multiple loss terms are weighted and added together to form a single objective. These weights are chosen to properly balance the competing losses according to some meta-goal. For example, in physics-informed neural networks (PINNs), these weights are often adaptively chosen to improve the network's generalization error. A popular choice of adaptive weights is based on the neural tangent kernel (NTK) of the PINN, which describes the evolution of the network in predictor space during training. The convergence of such an adaptive weighting algorithm is not clear a priori. Moreover, these NTK-based weights would be updated frequently during training, further increasing the computational burden of the learning process. In this paper, we prove that under appropriate conditions, gradient descent enhanced with adaptive NTK-based weights is convergent in a suitable sense. We then address the problem of computational efficiency by developing a randomized algorithm inspired by a predictor-corrector approach and matrix sketching, which produces unbiased estimates of the NTK up to an arbitrarily small discretization error. Finally, we provide numerical experiments to support our theoretical findings and to show the efficacy of our randomized algorithm. Code Availability: https://github.com/maxhirsch/Efficient-NTK</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15530v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Hirsch, Federico Pichi</dc:creator>
    </item>
    <item>
      <title>Numerical Stability of the Nystr\"om Method</title>
      <link>https://arxiv.org/abs/2511.15583</link>
      <description>arXiv:2511.15583v1 Announce Type: new 
Abstract: The Nystr\"om method is a widely used technique for improving the scalability of kernel-based algorithms, including kernel ridge regression, spectral clustering, and Gaussian processes. Despite its popularity, the numerical stability of the method has remained largely an unresolved problem. In particular, the pseudo-inversion of the submatrix involved in the Nystr\"om method may pose stability issues as the submatrix is likely to be ill-conditioned, resulting in numerically poor approximation. In this work, we establish conditions under which the Nystr\"om method is numerically stable. We show that stability can be achieved through an appropriate choice of column subsets and a careful implementation of the pseudoinverse. Our results and experiments provide theoretical justification and practical guidance for the stable application of the Nystr\"om method in large-scale kernel computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15583v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Bucci, Yuji Nakatsukasa, Taejun Park</dc:creator>
    </item>
    <item>
      <title>PAS-Net: Physics-informed Adaptive Scale Deep Operator Network</title>
      <link>https://arxiv.org/abs/2511.14925</link>
      <description>arXiv:2511.14925v1 Announce Type: cross 
Abstract: Nonlinear physical phenomena often show complex multiscale interactions; motivated by the principles of multiscale modeling in scientific computing, we propose PAS-Net, a physics-informed Adaptive-Scale Deep Operator Network for learning solution operators of nonlinear and singularly perturbed evolution PDEs with small parameters and localized features. Specifically, PAS-Net augments the trunk input in the physics informed Deep Operator Network (PI-DeepONet) with a prescribed (or learnable) locally rescaled coordinate transformation centered at reference points. This addition introduces a multiscale feature embedding that acts as an architecture-independent preconditioner which improves the representation of localized, stiff, and multiscale dynamics. From an optimization perspective, the adaptive-scale embedding in PAS-Net modifies the geometry of the Neural Tangent Kernel (NTK) associated with the neural network by increasing its smallest eigenvalue, which in turn improves spectral conditioning and accelerates gradient-based convergence. We further show that this adaptive-scale mechanism explicitly accelerates neural network training in approximating functions with steep transitions and strong asymptotic behavior, and we provide a rigorous proof of this function-approximation result within the finite-dimensional NTK matrix framework. We test the proposed PAS-Net on three different problems: (i) the one-dimensional viscous Burgers equation, (ii) a nonlinear diffusion-reaction system with sharp spatial gradients, and (iii) a two-dimensional eikonal equation. The numerical results show that PAS-Net consistently achieves higher accuracy and faster convergence than the standard DeepONet and PI-DeepONet models under a similar training cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14925v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changhong Mou, Yeyu Zhang, Xuewen Zhu, Qiao Zhuang</dc:creator>
    </item>
    <item>
      <title>Transformation from integral operator with separable kernel to matrix in eigenvalue problem</title>
      <link>https://arxiv.org/abs/2511.14979</link>
      <description>arXiv:2511.14979v1 Announce Type: cross 
Abstract: This paper investigates the eigenvalue problem of integral operators whose kernels can be expressed as a finite sum of pairwise products of single-variable functions, making them separable. By consdiering the matrix form of the separable kernel in the integral operator, we establish the relationship between the eigenvalues and eigenfunctions of the integral operator and the eigenpairs of a matrix. We next generalize the eigenfunction of an integral operator based on the concept of generalized eigenvectors of matrices, and show that solving the Fredholm integral equation of the second kind reduces to computing matrix eigenpairs and generalized eigenvectors. We also provide several examples to validate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14979v1</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soma Hirai, Ryoto Watanabe, Yuki Nishida, Masashi Iwasaki</dc:creator>
    </item>
    <item>
      <title>A Wave Front Tracking Scheme for Flux Reconstruction in $2\times 2$ Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2511.15261</link>
      <description>arXiv:2511.15261v1 Announce Type: cross 
Abstract: This paper introduces a novel wave front tracking framework for reconstructing unknown flux functions in $2\times 2$ hyperbolic conservation laws, extending beyond the well-studied scalar case. By analyzing Riemann solutions at fixed observation times, we develop explicit reconstruction formulas that handle arbitrary combinations of shock and rarefaction waves through a unified equivalent shock concept. Our method constructs piecewise quadratic $C^1$ flux approximations with rigorous convergence guarantees: the approximation errors decrease quadratically with the discretization parameters for function values and linearly for derivatives under $C^{1,1}$ regularity, with enhanced cubic and quadratic convergence respectively under $C^3$ regularity. Applications to the isentropic Euler equations and the mathematically equivalent p-system in compressible fluid dynamics demonstrate the method's capability to identify complete equations of state from limited dynamic measurements, providing a systematic approach to a fundamental inverse problem in continuum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15261v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaohua Duan, Yan Jiang, Hongyu Liu, Wenjian Peng</dc:creator>
    </item>
    <item>
      <title>RLS Framework with Segmentation of the Forgetting Profile and Low Rank Updates</title>
      <link>https://arxiv.org/abs/2511.15273</link>
      <description>arXiv:2511.15273v1 Announce Type: cross 
Abstract: This report describes a new regularization approach based on segmentation of the forgetting profile in sliding window least squares estimation. Each segment is designed to enforce specific desirable properties of the estimator such as rapidity, desired condition number of the information matrix, accuracy, numerical stability, etc. The forgetting profile is divided in three segments, where the speed of estimation is ensured by the first segment, which employs rapid exponential forgetting of recent data.The second segment features a decline in the profile and marks the transition to the third segment, characterized by slow exponential forgetting to reduce the condition number of the information matrix using more distant data. Condition number reduction mitigates error propagation, thereby enhancing accuracy and stability. This approach facilitates the incorporation of a priori information regarding signal characteristics (i.e., the expected behavior of the signal) into the estimator. Recursive and computationally efficient algorithm with low rank updates based on new matrix inversion lemma for moving window associated with this regularization approach is developed. New algorithms significantly improve the approximation accuracy of low resolution daily temperature measurements obtained at the Stockholm Old Astronomical Observatory, thereby enhancing the reliability of temperature predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15273v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5120/ijca2025925940</arxiv:DOI>
      <dc:creator>Alexander Stotsky</dc:creator>
    </item>
    <item>
      <title>Beyond Tchakaloff Quadrature: Positive Functionals, Frames and Widths</title>
      <link>https://arxiv.org/abs/2511.15425</link>
      <description>arXiv:2511.15425v1 Announce Type: cross 
Abstract: Tchakaloff's theorem from 1957 asserts the existence of exact quadrature rules with non-negative weights for any polynomial space of finite degree on $\mathbb{R}^d$ if the underlying measure is positive, compactly supported, and absolutely continuous with respect to the Lebesgue measure. This classical result coined the term Tchakaloff quadrature for quadrature that is exact and only uses non-negative weights. It has been a long-standing endeavor, under which conditions such rules exist. A final answer was given in 2012 by Bisgaard with the insight that, in fact, every finite-dimensional space of integrable functions on a positive measure space admits them. In this article we recall this result and provide a major extension to the question of positive discretizability of $\mathbb{C}$-linear functionals on finite-dimensional spaces. We introduce the notion of strict $S$-positivity for such functionals, where $S$ are subsets of the functional's domain, and show the equivalence of positive discretizability to being strictly $S$-positive for a suitable choice of $S$. We further investigate consequences for other discretization problems. One fundamental implication is the guaranteed existence of $L_p$-Marcinkiewicz-Zygmund equalities in finite-dimensional spaces of $p$-integrable functions in case that $p$ is an even integer, another the exact discretizability of any frame in $\mathbb{K}^n$, where $\mathbb{K}\in\{\mathbb{R},\mathbb{C}\}$, if a rescaling of the frame elements is allowed. In addition, we provide bounds for Tchakaloff quadrature widths $\kappa_n^+$ and, addressing the question of constructibility of discretization points, establish a connection to $D$-optimal design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15425v1</guid>
      <category>math.FA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Sch\"afer, Tino Ullrich</dc:creator>
    </item>
    <item>
      <title>Constrained high-index saddle dynamics for the solution landscape with equality constraints</title>
      <link>https://arxiv.org/abs/2011.13173</link>
      <description>arXiv:2011.13173v4 Announce Type: replace 
Abstract: We propose a constrained high-index saddle dynamics (CHiSD) method to search for index-$k$ saddle points of an energy functional subject to equality constraints. With Riemannian manifold tools, the CHiSD is derived in a minimax framework, and its linear stability at an index-$k$ saddle point is proved. To ensure the manifold property, the CHiSD is numerically implemented using retractions and vector transport. Then we present a numerical approach by combining CHiSD with downward and upward search algorithms to construct the solution landscape in the presence of equality constraints. We apply the Thomson problem and the Bose-Einstein condensation as numerical examples to demonstrate the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.13173v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10915-022-01838-3</arxiv:DOI>
      <arxiv:journal_reference>J Sci Comput 91, 62 (2022)</arxiv:journal_reference>
      <dc:creator>Jianyuan Yin, Zhen Huang, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>Concrete examples of the rate of convergence of Chernoff approximations: numerical results for the heat semigroup and open questions on them (with appendix: full list of pictures and Python code)</title>
      <link>https://arxiv.org/abs/2301.05284</link>
      <description>arXiv:2301.05284v3 Announce Type: replace 
Abstract: The article is devoted to the construction of examples that illustrate (using computer calculations) the rate of convergence of Chernoff approximations to the solution of the Cauchy problem for the heat equation. We are interested in the Chernoff theorem in general and select the heat semigroup as a model case because this semigroup (and solutions of the heat equations) are known, so it is easy to measure the distance between the exact solution and its Chernoff approximations. Two Chernoff functions (of the first and second order of Chernoff tangency to the generator of the heat semigroup, i.e. to the operator of taking the second derivative) and several initial conditions of different smoothness are considered. From the numerically plotted graphs, visually, it is determined that the approximations are close to the solution. For each of the two Chernoff functions, for several initial conditions of different smoothness and for approximation numbers up to 11 inclusive, the error (i.e. the supremum of the absolute value of the difference between the exact solution and the approximating function) corresponding to each approximation was numerically found. As it turned out, in all the cases studied, the dependence of the error on the number of the approximation has an approximately power-law form (we call this power the order of convergence). This follows from the fact that, as we discovered, the dependence of the logarithm of the error on the logarithm of the approximation number is approximately linear. Using the considered family of initial conditions, an empirical dependence of the order of convergence on the smoothness class of the initial condition is found. The orders of convergence for all the initial conditions studied are collected in a table.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05284v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>K. A. Katalova (Dragunova), N. Nikbakht, I. D. Remizov</dc:creator>
    </item>
    <item>
      <title>On the randomized Euler scheme for SDEs with integral-form drift</title>
      <link>https://arxiv.org/abs/2405.20481</link>
      <description>arXiv:2405.20481v2 Announce Type: replace 
Abstract: In this paper, we investigate the problem of strong approximation of the solutions of stochastic differential equations (SDEs) when the drift coefficient is given in integral form. We investigate its upper error bounds, in terms of the discretization parameter $n$ and the size $M$ of the random sample drawn at each step of the algorithm, in different subclasses of coefficients of the underlying SDE presenting various rates of convergence. Integral-form drift often appears when analyzing stochastic dynamics of optimization procedures in machine learning (ML) problems. Hence, we additionally discuss connections of the defined randomized Euler approximation scheme with the perturbed version of the stochastic gradient descent (SGD) algorithm. Finally, the results of numerical experiments performed using GPU architecture are also reported, including a comparison with other popular optimizers used in ML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20481v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pawe{\l} Przyby{\l}owicz, Micha{\l} Sobieraj</dc:creator>
    </item>
    <item>
      <title>Error estimates of physics-informed neural networks for approximating Boltzmann equation</title>
      <link>https://arxiv.org/abs/2407.08383</link>
      <description>arXiv:2407.08383v3 Announce Type: replace 
Abstract: Motivated by the recent successful application of physics-informed neural networks (PINNs) to solve Boltzmann-type equations [S. Jin, Z. Ma, and K. Wu, J. Sci. Comput., 94 (2023), pp. 57], we provide a rigorous error analysis for PINNs in approximating the solution of the Boltzmann equation near a global Maxwellian. The challenge arises from the nonlocal quadratic interaction term defined in the unbounded domain of velocity space. Analyzing this term on an unbounded domain requires the inclusion of a truncation function, which demands delicate analysis techniques. As a generalization of this analysis, we also provide proof of the asymptotic preserving property when using micro-macro decomposition-based neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08383v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elie Abdo, Lihui Chai, Ruimeng Hu, Xu Yang</dc:creator>
    </item>
    <item>
      <title>Convergence rate of Euler-Maruyama scheme for McKean-Vlasov SDEs with density-dependent drift</title>
      <link>https://arxiv.org/abs/2412.19121</link>
      <description>arXiv:2412.19121v3 Announce Type: replace 
Abstract: In this paper, we study weak well-posedness of a McKean-Vlasov stochastic differential equations (SDEs) whose drift is density-dependent and whose diffusion is constant. The existence part is due to H\"older stability estimates of the associated Euler-Maruyama scheme. The uniqueness part is due to that of the associated Fokker-Planck equation. We also obtain convergence rate in weighted $L^1$ norm for the Euler-Maruyama scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19121v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anh-Dung Le (TSE-R)</dc:creator>
    </item>
    <item>
      <title>Convergence of the non-staggered Nessyahu-Tadmor scheme for coupled systems of one-dimensional nonlocal balance laws</title>
      <link>https://arxiv.org/abs/2501.14425</link>
      <description>arXiv:2501.14425v2 Announce Type: replace 
Abstract: We derive a second-order accurate, non-staggered central scheme based on the well-known Nessyahu-Tadmor scheme to approximate solutions of coupled systems of nonlocal balance laws. We show that the approximate solutions stay bounded by an exponential $L^\infty$ bound in time. Under linearity assumptions on the flux and source terms the approximate solutions converge weakly-$*$ to weak solutions of the nonlocal balance laws. Assuming stronger regularity, in particular on the convolution kernel, we show strong convergence towards entropy weak solutions in the nonlinear case. Numerical examples validate our results and demonstrate its applicability to various systems of nonlocal problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14425v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjibanee Sudha, Jan Friedrich, Samala Rathan</dc:creator>
    </item>
    <item>
      <title>Nonlinear manifold approximation using compositional polynomial networks</title>
      <link>https://arxiv.org/abs/2502.05088</link>
      <description>arXiv:2502.05088v3 Announce Type: replace 
Abstract: We consider the problem of approximating a subset $M$ of a Hilbert space $X$ by a low-dimensional manifold $M_n$, using samples from $M$. We propose a nonlinear approximation method where $M_n $ is defined as the range of a smooth nonlinear decoder $D$ defined on $\mathbb{R}^n$ with values in a possibly high-dimensional linear space $X_N$, and a linear encoder $E$ which associates to an element from $ M$ its coefficients $E(u)$ on a basis of a $n$-dimensional subspace $X_n \subset X_N$, where $X_N$ is an optimal or near to optimal linear space, depending on the selected error measure The linearity of the encoder allows to easily obtain the parameters $E(u)$ associated with a given element $u$ in $M$. The proposed decoder is a polynomial map from $\mathbb{R}^n$ to $X_N$ which is obtained by a tree-structured composition of polynomial maps, estimated sequentially from samples in $M$. Rigorous error and stability analyses are provided, as well as an adaptive strategy for constructing the subspace $X_n$, and a decoder that guarantees an approximation of the set $M$ with controlled mean-squared or wort-case errors, and a controlled stability (Lipschitz continuity) of the encoder and decoder pair. We demonstrate the performance of our method through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05088v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Bensalah, Anthony Nouy, Joel Soffo</dc:creator>
    </item>
    <item>
      <title>Neural network methods for Neumann series problems of Perron-Frobenius operators</title>
      <link>https://arxiv.org/abs/2505.05407</link>
      <description>arXiv:2505.05407v2 Announce Type: replace 
Abstract: Problems related to Perron-Frobenius operators (or transfer operators) have been extensively studied and applied across various fields. In this work, we propose neural network methods for approximating solutions to problems involving these operators. Specifically, we focus on computing the power series of non-expansive Perron-Frobenius operators under a given $L^p$-norm with a constant damping parameter in $(0,1)$. We use PINNs and RVPINNs to approximate solutions in their strong and variational forms, respectively. We provide a priori error estimates for quasi-minimizers of the associated loss functions. We present some numerical results for 1D and 2D examples to show the performance of our methods. We also demonstrate the applicability of our methods by approximating interior densities in a two-cavity system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05407v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Udomworarat, I. Brevis, M. Richter, S. Rojas, K. G. van der Zee</dc:creator>
    </item>
    <item>
      <title>An inverse-free fixed-time stable dynamical system and its forward-Euler discretization for solving generalized absolute value equations</title>
      <link>https://arxiv.org/abs/2507.00531</link>
      <description>arXiv:2507.00531v2 Announce Type: replace 
Abstract: An inverse-free dynamical system is proposed to solve the generalized absolute value equation (GAVE) with a fixed time convergence, where the time of convergence is finite and is uniformly bounded for all initial points. Moreover, an iterative method obtained by using the forward-Euler discretization of the proposed dynamic model is developed and sufficient conditions which guarantee that the discrete iteration globally converge to an arbitrarily small neighborhood of the unique solution of GAVE within a finite number of iterative steps are given. Numerical results illustrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00531v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuehua Li, Linjie Chen, Dongmei Yu, Cairong Chen, Deren Han</dc:creator>
    </item>
    <item>
      <title>Uniform Distributions on p-Balls and the Singular Role of $p=1,2,\infty$ in p-Norm Geometry</title>
      <link>https://arxiv.org/abs/2411.13567</link>
      <description>arXiv:2411.13567v2 Announce Type: replace-cross 
Abstract: This paper studies the relationship between volume and surface uniform measures on n-dimensional p-balls under the p-norm. It is proved that for p=1, p=2 and p=infinity, and only for these values of p, radial projection maps a volumetrically uniform distribution to a surface-uniform distribution. Algorithms for uniform sampling on p-balls and p-spheres are provided, together with empirical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13567v2</guid>
      <category>math.ST</category>
      <category>cs.CR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Pinz\'on</dc:creator>
    </item>
    <item>
      <title>Ridge Regression on Riemannian Manifolds for Time-Series Prediction</title>
      <link>https://arxiv.org/abs/2411.18339</link>
      <description>arXiv:2411.18339v3 Announce Type: replace-cross 
Abstract: We propose a natural intrinsic extension of ridge regression from Euclidean spaces to general Riemannian manifolds for time-series prediction. Our approach combines Riemannian least-squares fitting via B\'ezier curves, empirical covariance on manifolds, and Mahalanobis distance regularization. A key technical contribution is an explicit formula for the gradient of the objective function using adjoint differentials, enabling efficient numerical optimization via Riemannian gradient descent. We validate our framework through synthetic spherical experiments (achieving significant error reduction over unregularized regression) and hurricane forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18339v3</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esfandiar Nava-Yazdani</dc:creator>
    </item>
    <item>
      <title>A time-dependent inverse source problem for a semilinear pseudo-parabolic equation with Neumann boundary condition</title>
      <link>https://arxiv.org/abs/2502.04821</link>
      <description>arXiv:2502.04821v2 Announce Type: replace-cross 
Abstract: In this paper, we study the inverse problem for determining an unknown time-dependent source coefficient in a semilinear pseudo-parabolic equation with variable coefficients and Neumann boundary condition. This unknown source term is recovered from the integral measurement over the domain $\Omega$. Based on Rothe's method, the existence and uniqueness of a weak solution, under suitable assumptions on the data, is established. A numerical time-discrete scheme for the unique weak solution and the unknown source coefficient is designed, and the convergence of the approximations is proven. Numerical experiments are presented to support the theoretical results. Noisy data is handled through polynomial regularisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04821v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Van Bockstal, K. Khompysh</dc:creator>
    </item>
    <item>
      <title>Deep Spectral Prior</title>
      <link>https://arxiv.org/abs/2505.19873</link>
      <description>arXiv:2505.19873v2 Announce Type: replace-cross 
Abstract: We introduce the Deep Spectral Prior (DSP), a new framework for unsupervised image reconstruction that operates entirely in the complex frequency domain. Unlike the Deep Image Prior (DIP), which optimises pixel-level errors and is highly sensitive to overfitting, DSP performs joint learning of amplitude and phase to capture the full spectral structure of images. We derive a rigorous theoretical characterisation of DSP's optimisation dynamics, proving that it follows frequency-dependent descent trajectories that separate informative low-frequency modes from stochastic high-frequency noise. This spectral mode separation explains DSP's self-regularising behaviour and, for the first time, formally establishes the elimination of DIP's major limitation-its reliance on manual early stopping. Moreover, DSP induces an implicit projection onto a frequency-consistent manifold, ensuring convergence to stable, physically plausible reconstructions without explicit priors or supervision. Extensive experiments on denoising, inpainting, and deblurring demonstrate that DSP consistently surpasses DIP and other unsupervised baselines, achieving superior fidelity, robustness, and theoretical interpretability within a unified, unsupervised data-free framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19873v2</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanqi Cheng, Xuxiang Zhao, Tieyong Zeng, Pietro Lio, Carola-Bibiane Sch\"onlieb, Angelica I Aviles-Rivero</dc:creator>
    </item>
    <item>
      <title>Global Convergence of Adjoint-Optimized Neural PDEs</title>
      <link>https://arxiv.org/abs/2506.13633</link>
      <description>arXiv:2506.13633v2 Announce Type: replace-cross 
Abstract: Many engineering and scientific fields have recently become interested in modeling terms in partial differential equations (PDEs) with neural networks, which requires solving the inverse problem of learning neural network terms from observed data in order to approximate missing or unresolved physics in the PDE model. The resulting neural-network PDE model, being a function of the neural network parameters, can be calibrated to the available ground truth data by optimizing over the PDE using gradient descent, where the gradient is evaluated in a computationally efficient manner by solving an adjoint PDE. These neural PDE models have emerged as an important research area in scientific machine learning. In this paper, we study the convergence of the adjoint gradient descent optimization method for training neural PDE models in the limit where both the number of hidden units and the training time tend to infinity. Specifically, for a general class of nonlinear parabolic PDEs with a neural network embedded in the source term, we prove convergence of the trained neural-network PDE solution to the target data (i.e., a global minimizer). The global convergence proof poses a unique mathematical challenge that is not encountered in finite-dimensional neural network convergence analyses due to (i) the neural network training dynamics involving a non-local neural network kernel operator in the infinite-width hidden layer limit where the kernel lacks a spectral gap for its eigenvalues and (ii) the nonlinearity of the limit PDE system, which leads to a non-convex optimization problem in the neural network function even in the infinite-width hidden layer limit (unlike in typical neural network training cases where the optimization problem becomes convex in the large neuron limit). The theoretical results are illustrated and empirically validated by numerical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13633v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantin Riedl, Justin Sirignano, Konstantinos Spiliopoulos</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer</title>
      <link>https://arxiv.org/abs/2508.10587</link>
      <description>arXiv:2508.10587v3 Announce Type: replace-cross 
Abstract: To bridge the temporal granularity gap in energy network design and operation based on Energy System Models, resampling of time series is required. While conventional upsampling methods are computationally efficient, they often result in significant information loss or increased noise. Advanced models such as time series generation models, Super-Resolution models and imputation models show potential, but also face fundamental challenges. The goal of time series generative models is to learn the distribution of the original data to generate high-resolution series with similar statistical characteristics. This is not entirely consistent with the definition of upsampling. Time series Super-Resolution models or imputation models can degrade the accuracy of upsampling because the input low-resolution time series are sparse and may have insufficient context. Moreover, such models usually rely on supervised learning paradigms. This presents a fundamental application paradox: their training requires the high-resolution time series that is intrinsically absent in upsampling application scenarios. To address the mentioned upsampling issue, this paper introduces a new method utilizing Generative Adversarial Transformers (GATs), which can be trained without access to any ground-truth high-resolution data. Compared with conventional interpolation methods, the introduced method can reduce the root mean square error (RMSE) of upsampling tasks by 10%, and the accuracy of a model predictive control (MPC) application scenario is improved by 13%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10587v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuanhao Mu, G\"okhan Demirel, Yuzhe Zhang, Jianlei Liu, Thorsten Schlachter, Veit Hagenmeyer</dc:creator>
    </item>
  </channel>
</rss>
