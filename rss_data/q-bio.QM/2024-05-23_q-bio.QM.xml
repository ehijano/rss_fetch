<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:03:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>HoverFast: an accurate, high-throughput, clinically deployable nuclear segmentation tool for brightfield digital pathology images</title>
      <link>https://arxiv.org/abs/2405.14028</link>
      <description>arXiv:2405.14028v1 Announce Type: new 
Abstract: In computational digital pathology, accurate nuclear segmentation of Hematoxylin and Eosin (H&amp;E) stained whole slide images (WSIs) is a critical step for many analyses and tissue characterizations. One popular deep learning-based nuclear segmentation approach, HoverNet, offers remarkably accurate results but lacks the high-throughput performance needed for clinical deployment in resource-constrained settings. Our approach, HoverFast, aims to provide fast and accurate nuclear segmentation in H&amp;E images using knowledge distillation from HoverNet. By redesigning the tool with software engineering best practices, HoverFast introduces advanced parallel processing capabilities, efficient data handling, and optimized postprocessing. These improvements facilitate scalable high-throughput performance, making HoverFast more suitable for real-time analysis and application in resource-limited environments. Using a consumer grade Nvidia A5000 GPU, HoverFast showed a 21x speed improvement as compared to HoverNet; reducing mean analysis time for 40x WSIs from ~2 hours to 6 minutes while retaining a concordant mean Dice score of 0.91 against the original HoverNet output. Peak memory usage was also reduced 71% from 44.4GB, to 12.8GB, without requiring SSD-based caching. To ease adoption in research and clinical contexts, HoverFast aligns with best-practices in terms of (a) installation, and (b) containerization, while (c) providing outputs compatible with existing popular open-source image viewing tools such as QuPath. HoverFast has been made open-source and is available at andrewjanowczyk.com/open-source-tools/hoverfast.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14028v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petros Liakopoulos, Julien Massonnet, Jonatan Bonjour, Medya Tekes Mizrakli, Simon Graham, Michel A. Cuendet, Amanda H. Seipel, Olivier Michielin, Doron Merkler, Andrew Janowczyk</dc:creator>
    </item>
    <item>
      <title>ReactXT: Understanding Molecular "Reaction-ship" via Reaction-Contextualized Molecule-Text Pretraining</title>
      <link>https://arxiv.org/abs/2405.14225</link>
      <description>arXiv:2405.14225v1 Announce Type: new 
Abstract: Molecule-text modeling, which aims to facilitate molecule-relevant tasks with a textual interface and textual knowledge, is an emerging research direction. Beyond single molecules, studying reaction-text modeling holds promise for helping the synthesis of new materials and drugs. However, previous works mostly neglect reaction-text modeling: they primarily focus on modeling individual molecule-text pairs or learning chemical reactions without texts in context. Additionally, one key task of reaction-text modeling -- experimental procedure prediction -- is less explored due to the absence of an open-source dataset. The task is to predict step-by-step actions of conducting chemical experiments and is crucial to automating chemical synthesis. To resolve the challenges above, we propose a new pretraining method, ReactXT, for reaction-text modeling, and a new dataset, OpenExp, for experimental procedure prediction. Specifically, ReactXT features three types of input contexts to incrementally pretrain LMs. Each of the three input contexts corresponds to a pretraining task to improve the text-based understanding of either reactions or single molecules. ReactXT demonstrates consistent improvements in experimental procedure prediction and molecule captioning and offers competitive results in retrosynthesis. Our code is available at https://github.com/syr-cn/ReactXT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14225v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CL</category>
      <category>cs.MM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Liu, Yaorui Shi, An Zhang, Sihang Li, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua</dc:creator>
    </item>
    <item>
      <title>Prediction of cancer dynamics under treatment using Bayesian neural networks: A simulated study</title>
      <link>https://arxiv.org/abs/2405.14508</link>
      <description>arXiv:2405.14508v1 Announce Type: new 
Abstract: Predicting cancer dynamics under treatment is challenging due to high inter-patient heterogeneity, lack of predictive biomarkers, and sparse and noisy longitudinal data. Mathematical models can summarize cancer dynamics by a few interpretable parameters per patient. Machine learning methods can then be trained to predict the model parameters from baseline covariates, but do not account for uncertainty in the parameter estimates. Instead, hierarchical Bayesian modeling can model the relationship between baseline covariates to longitudinal measurements via mechanistic parameters while accounting for uncertainty in every part of the model.
  The mapping from baseline covariates to model parameters can be modeled in several ways. A linear mapping simplifies inference but fails to capture nonlinear covariate effects and scale poorly for interaction modeling when the number of covariates is large. In contrast, Bayesian neural networks can potentially discover interactions between covariates automatically, but at a substantial cost in computational complexity.
  In this work, we develop a hierarchical Bayesian model of subpopulation dynamics that uses baseline covariate information to predict cancer dynamics under treatment, inspired by cancer dynamics in multiple myeloma (MM), where serum M protein is a well-known proxy of tumor burden. As a working example, we apply the model to a simulated dataset and compare its ability to predict M protein trajectories to a model with linear covariate effects. Our results show that the Bayesian neural network covariate effect model predicts cancer dynamics more accurately than a linear covariate effect model when covariate interactions are present. The framework can also be applied to other types of cancer or other time series prediction problems that can be described with a parametric model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14508v1</guid>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Even Moa Myklebust, Arnoldo Frigessi, Fredrik Schjesvold, Jasmine Foo, Kevin Leder, Alvaro K\"ohn-Luque</dc:creator>
    </item>
    <item>
      <title>Multilevel functional data analysis modeling of human glucose response to meal intake</title>
      <link>https://arxiv.org/abs/2405.14690</link>
      <description>arXiv:2405.14690v1 Announce Type: new 
Abstract: Glucose meal response information collected via Continuous Glucose Monitoring (CGM) is relevant to the assessment of individual metabolic status and the support of personalized diet prescriptions. However, the complexity of the data produced by CGM monitors pushes the limits of existing analytic methods. CGM data often exhibits substantial within-person variability and has a natural multilevel structure. This research is motivated by the analysis of CGM data from individuals without diabetes in the AEGIS study. The dataset includes detailed information on meal timing and nutrition for each individual over different days. The primary focus of this study is to examine CGM glucose responses following patients' meals and explore the time-dependent associations with dietary and patient characteristics. Motivated by this problem, we propose a new analytical framework based on multilevel functional models, including a new functional mixed R-square coefficient. The use of these models illustrates 3 key points: (i) The importance of analyzing glucose responses across the entire functional domain when making diet recommendations; (ii) The differential metabolic responses between normoglycemic and prediabetic patients, particularly with regards to lipid intake; (iii) The importance of including random, person-level effects when modelling this scientific problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14690v1</guid>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marcos Matabuena, Joe Sartini, Francisco Gude</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Approach to Multi-Fiber Parameter Estimation and Uncertainty Quantification in Diffusion MRI</title>
      <link>https://arxiv.org/abs/2405.13655</link>
      <description>arXiv:2405.13655v1 Announce Type: cross 
Abstract: Diffusion MRI (dMRI) is the primary imaging modality used to study brain microstructure in vivo. Reliable and computationally efficient parameter inference for common dMRI biophysical models is a challenging inverse problem, due to factors such as variable dimensionalities (reflecting the unknown number of distinct white matter fiber populations in a voxel), low signal-to-noise ratios, and non-linear forward models. These challenges have led many existing methods to use biologically implausible simplified models to stabilize estimation, for instance, assuming shared microstructure across all fiber populations within a voxel. In this work, we introduce a novel sequential method for multi-fiber parameter inference that decomposes the task into a series of manageable subproblems. These subproblems are solved using deep neural networks tailored to problem-specific structure and symmetry, and trained via simulation. The resulting inference procedure is largely amortized, enabling scalable parameter estimation and uncertainty quantification across all model parameters. Simulation studies and real imaging data analysis using the Human Connectome Project (HCP) demonstrate the advantages of our method over standard alternatives. In the case of the standard model of diffusion, our results show that under HCP-like acquisition schemes, estimates for extra-cellular parallel diffusivity are highly uncertain, while those for the intra-cellular volume fraction can be estimated with relatively high precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13655v1</guid>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Consagra, Lipeng Ning, Yogesh Rathi</dc:creator>
    </item>
    <item>
      <title>Deep Learning for Protein-Ligand Docking: Are We There Yet?</title>
      <link>https://arxiv.org/abs/2405.14108</link>
      <description>arXiv:2405.14108v1 Announce Type: cross 
Abstract: The effects of ligand binding on protein structures and their in vivo functions carry numerous implications for modern biomedical research and biotechnology development efforts such as drug discovery. Although several deep learning (DL) methods and benchmarks designed for protein-ligand docking have recently been introduced, to date no prior works have systematically studied the behavior of docking methods within the practical context of (1) predicted (apo) protein structures, (2) multiple ligands concurrently binding to a given target protein, and (3) having no prior knowledge of binding pockets. To enable a deeper understanding of docking methods' real-world utility, we introduce PoseBench, the first comprehensive benchmark for practical protein-ligand docking. PoseBench enables researchers to rigorously and systematically evaluate DL docking methods for apo-to-holo protein-ligand docking and protein-ligand structure generation using both single and multi-ligand benchmark datasets, the latter of which we introduce for the first time to the DL community. Empirically, using PoseBench, we find that all recent DL docking methods but one fail to generalize to multi-ligand protein targets and also that template-based docking algorithms perform equally well or better for multi-ligand docking as recent single-ligand DL docking methods, suggesting areas of improvement for future work. Code, data, tutorials, and benchmark results are available at https://github.com/BioinfoMachineLearning/PoseBench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14108v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Morehead, Nabin Giri, Jian Liu, Jianlin Cheng</dc:creator>
    </item>
    <item>
      <title>Motion-based video compression for resource-constrained camera traps</title>
      <link>https://arxiv.org/abs/2405.14419</link>
      <description>arXiv:2405.14419v1 Announce Type: cross 
Abstract: Field-captured video allows for detailed studies of spatiotemporal aspects of animal locomotion, decision-making, and environmental interactions. However, despite the affordability of data capture with mass-produced hardware, storage, processing, and transmission overheads pose a significant hurdle to acquiring high-resolution video from field-deployed camera traps. Therefore, efficient compression algorithms are crucial for monitoring with camera traps that have limited access to power, storage, and bandwidth. In this article, we introduce a new motion analysis-based video compression algorithm designed to run on camera trap devices. We implemented and tested this algorithm using a case study of insect-pollinator motion tracking. The algorithm identifies and stores only image regions depicting motion relevant to pollination monitoring, reducing the overall data size by an average of 84% across a diverse set of test datasets while retaining the information necessary for relevant behavioural analysis. The methods outlined in this paper facilitate the broader application of computer vision-enabled, low-powered camera trap devices for remote, in-situ video-based animal motion monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14419v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Malika Nisal Ratnayake, Lex Gallon, Adel N. Toosi, Alan Dorin</dc:creator>
    </item>
    <item>
      <title>Turing instabilities for three interacting species</title>
      <link>https://arxiv.org/abs/2405.14682</link>
      <description>arXiv:2405.14682v1 Announce Type: cross 
Abstract: In this paper, I prove necessary and sufficient conditions for the existence of Turing instabilities in a general system with three interacting species. Turing instabilities describe situations when a stable steady state of a reaction system (ordinary differential equation) becomes an unstable homogeneous steady state of the corresponding reaction-diffusion system (partial differential equation). Similarly to a well-known inequality condition for Turing instabilities in a system with two species, I find a set of inequality conditions for a system with three species. Furthermore, I distinguish conditions for the Turing instability when spatial perturbations grow steadily and the Turing-Hopf instability when spatial perturbations grow and oscillate in time simultaneously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14682v1</guid>
      <category>nlin.PS</category>
      <category>math.DS</category>
      <category>math.SP</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vit Piskovsky</dc:creator>
    </item>
    <item>
      <title>Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions</title>
      <link>https://arxiv.org/abs/2405.14796</link>
      <description>arXiv:2405.14796v1 Announce Type: cross 
Abstract: A plant growth simulation can be characterized as a reconstructed visual representation of a plant or plant system. The phenotypic characteristics and plant structures are controlled by the scene environment and other contextual attributes. Considering the temporal dependencies and compounding effects of various factors on growth trajectories, we formulate a probabilistic approach to the simulation task by solving a frame synthesis and pattern recognition problem. We introduce a Sequence-Informed Plant Growth Simulation framework (SI-PGS) that employs a conditional generative model to implicitly learn a distribution of possible plant representations within a dynamic scene from a fusion of low dimensional temporal sensor and context data. Methods such as controlled latent sampling and recurrent output connections are used to improve coherence in plant structures between frames of predictions. In this work, we demonstrate that SI-PGS is able to capture temporal dependencies and continuously generate realistic frames of a plant scene.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14796v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Debbagh, Yixue Liu, Zhouzhou Zheng, Xintong Jiang, Shangpeng Sun, Mark Lefsrud</dc:creator>
    </item>
    <item>
      <title>Hypergraph: A Unified and Uniform Definition with Application to Chemical Hypergraph</title>
      <link>https://arxiv.org/abs/2405.12235</link>
      <description>arXiv:2405.12235v2 Announce Type: replace-cross 
Abstract: The conventional definition of hypergraph has two major issues: (1) there is not a standard definition of directed hypergraph and (2) there is not a formal definition of nested hypergraph. To resolve these issues, we propose a new definition of hypergraph that unifies the concepts of undirected, directed and nested hypergraphs, and that is uniform in using hyperedge as a single construct for representing high-order correlations among things, i.e., nodes and hyperedges. Specifically, we define a hyperedge to be a simple hyperedge, a nesting hyperedge, or a directed hyperedge. With this new definition, a hypergraph is nested if it has nesting hyperedge(s), and is directed if it has directed hyperedge(s). Otherwise, a hypergraph is a simple hypergraph. The uniformity and power of this new definition, with visualization, should facilitate the use of hypergraph for representing (hierarchical) high-order correlations in general and chemical systems in particular. Graph has been widely used as a mathematical structure for machine learning on molecular structures and 3D molecular geometries. However, graph has a major limitation: it can represent only pairwise correlations between nodes. Hypergraph extends graph with high-order correlations among nodes. This extension is significant or essential for machine learning on chemical systems. For molecules, this is significant as it allows the direct, explicit representation of multicenter bonds and molecular substructures. For chemical reactions, this is essential since most chemical reactions involve multiple participants. We propose the use of chemical hypergraph, a multilevel hypergraph with simple, nesting and directed hyperedges, as a single mathematical structure for representing chemical systems. We apply the new definition of hypergraph to chemical hypergraph and, as simplified versions, molecular hypergraph and chemical reaction hypergraph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12235v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel T. Chang</dc:creator>
    </item>
  </channel>
</rss>
