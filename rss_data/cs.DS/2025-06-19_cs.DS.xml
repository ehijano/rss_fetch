<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Parallel Complexity of Depth-First-Search and Maximal path</title>
      <link>https://arxiv.org/abs/2506.14974</link>
      <description>arXiv:2506.14974v1 Announce Type: new 
Abstract: Constructing a Depth First Search (DFS) tree is a fundamental graph problem, whose parallel complexity is still not settled. Reif showed parallel intractability of lex-first DFS. In contrast, randomized parallel algorithms (and more recently, deterministic quasipolynomial parallel algorithms) are known for constructing a DFS tree in general (di)graphs. However a deterministic parallel algorithm for DFS in general graphs remains an elusive goal. Working towards this, a series of works gave deterministic NC algorithms for DFS in planar graphs and digraphs. We further extend these results to more general graph classes, by providing NC algorithms for (di)graphs of bounded genus, and for undirected H-minor-free graphs where H is a fixed graph with at most one crossing. For the case of (di)graphs of bounded tree-width, we further improve the complexity to a Logspace bound. Constructing a maximal path is a simpler problem (that reduces to DFS) for which no deterministic parallel bounds are known for general graphs. For planar graphs a bound of O(log n) parallel time on a CREW PRAM (thus in NC2) is known. We improve this bound to Logspace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14974v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Archit Chauhan, Samir Datta, M. Praveen</dc:creator>
    </item>
    <item>
      <title>Efficient space reduction techniques by optimized majority rules for the Kemeny aggregation problem</title>
      <link>https://arxiv.org/abs/2506.15097</link>
      <description>arXiv:2506.15097v1 Announce Type: new 
Abstract: The Kemeny aggregation problem consists of computing the consensus rankings of an election with respect to the Kemeny-Young voting method. These aggregated rankings are the geometric medians as well as the maximum likelihood estimators in the Mallows model of the rankings in the election under the Kendall-tau distance which counts the number of pairwise disagreements. The problem admits fundamental applications in various domains such as computational social choice, machine learning, operations research, and biology but its computational complexity is unfortunately expensive. In this paper, we establish optimized quantitative extensions of the well-known 3/4-majority rule of Betzler et al. and the Major Order Theorem of Hamel and Milosz for the Kemeny aggregation problem. By taking into account the extra information available in the problem such as the number of candidates and by considering an additional optimization of certain piecewise linear functions in one variable, our results achieve significantly more refined space reduction techniques as illustrated by experimental results on real and synthetic data without increasing the time complexity of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15097v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Kien Phung, Sylvie Hamel</dc:creator>
    </item>
    <item>
      <title>Zarr-Based Chunk-Level Cumulative Sums in Reduced Dimensions</title>
      <link>https://arxiv.org/abs/2506.14981</link>
      <description>arXiv:2506.14981v1 Announce Type: cross 
Abstract: Data analysis on massive multi-dimensional data, such as high-resolution large-region time averaging or area averaging for geospatial data, often involves calculations over a significant number of data points. While performing calculations in scalable and flexible distributed or cloud environments is a viable option, a full scan of large data volumes still serves as a computationally intensive bottleneck, leading to significant cost. This paper introduces a generic and comprehensive method to address these computational challenges. This method generates a small, size-tunable supplementary dataset that stores the cumulative sums along specific subset dimensions on top of the raw data. This minor addition unlocks rapid and cheap high-resolution large-region data analysis, making calculations over large numbers of data points feasible with small instances or even microservices in the cloud. This method is general-purpose, but is particularly well-suited for data stored in chunked, cloud-optimized formats and for services running in distributed or cloud environments. We present a Zarr extension proposal to integrate the specifications of this method and facilitate its straightforward implementation in general-purpose software applications. Benchmark tests demonstrate that this method, implemented in Amazon Web services (AWS), significantly outperforms the brute-force approach used in on-premises services. With just 5% supplemental storage, this method achieves a performance that is 3-4 orders of magnitude (~10,000 times) faster than the brute-force approach, while incurring significantly reduced computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14981v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hailiang Zhang, Dieu My T. Nguyen, Christine Smit, Mahabal Hegde</dc:creator>
    </item>
    <item>
      <title>Private Continual Counting of Unbounded Streams</title>
      <link>https://arxiv.org/abs/2506.15018</link>
      <description>arXiv:2506.15018v1 Announce Type: cross 
Abstract: We study the problem of differentially private continual counting in the unbounded setting where the input size $n$ is not known in advance. Current state-of-the-art algorithms based on optimal instantiations of the matrix mechanism cannot be directly applied here because their privacy guarantees only hold when key parameters are tuned to $n$. Using the common `doubling trick' avoids knowledge of $n$ but leads to suboptimal and non-smooth error. We solve this problem by introducing novel matrix factorizations based on logarithmic perturbations of the function $\frac{1}{\sqrt{1-z}}$ studied in prior works, which may be of independent interest. The resulting algorithm has smooth error, and for any $\alpha &gt; 0$ and $t\leq n$ it is able to privately estimate the sum of the first $t$ data points with $O(\log^{2+2\alpha}(t))$ variance. It requires $O(t)$ space and amortized $O(\log t)$ time per round, compared to $O(\log(n)\log(t))$ variance, $O(n)$ space and $O(n \log n)$ pre-processing time for the nearly-optimal bounded-input algorithm of Henzinger et al. (SODA 2023). Empirically, we find that our algorithm's performance is also comparable to theirs in absolute terms: our variance is less than $1.5\times$ theirs for $t$ as large as $2^{24}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15018v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Jacobsen, Kassem Fawaz</dc:creator>
    </item>
    <item>
      <title>Tractable Graph Structures in EFX Orientation</title>
      <link>https://arxiv.org/abs/2506.15379</link>
      <description>arXiv:2506.15379v1 Announce Type: cross 
Abstract: Since its introduction, envy-freeness up to any good (EFX) has become a fundamental solution concept in fair division of indivisible goods. Its existence remains elusive -- even for four agents with additive utility functions, it is unknown whether an EFX allocation always exists. Unsurprisingly, restricted settings to delineate tractable and intractable cases have been explored. Christadolou, Fiat et al.[EC'23] introduced the notion of EFX-orientation, where the agents form the vertices of a graph and the items correspond to edges, and an agent values only the items that are incident to it. The goal is to allocate items to one of the adjacent agents while satisfying the EFX condition.
  Building on the work of Zeng and Mehta'24, which established a sharp complexity threshold based on the structure of the underlying graph -- polynomial-time solvability for bipartite graphs and NP-hardness for graphs with chromatic number at least three -- we further explore the algorithmic landscape of EFX-orientation using parameterized graph algorithms.
  Specifically, we show that bipartiteness is a surprisingly stringent condition for tractability: EFX orientation is NP-complete even when the valuations are symmetric, binary and the graph is at most two edge-removals away from being bipartite. Moreover, introducing a single non-binary value makes the problem NP-hard even when the graph is only one edge removal away from being bipartite. We further perform a parameterized analysis to examine structures of the underlying graph that enable tractability. In particular, we show that the problem is solvable in linear time on graphs whose treewidth is bounded by a constant and that the complexity of an instance is closely tied to the sizes of acyclic connected components on its one-valued edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15379v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'aclav Bla\v{z}ej, Sushmita Gupta, M. S. Ramanujan, Peter Strulo</dc:creator>
    </item>
    <item>
      <title>Learn to Vaccinate: Combining Structure Learning and Effective Vaccination for Epidemic and Outbreak Control</title>
      <link>https://arxiv.org/abs/2506.15397</link>
      <description>arXiv:2506.15397v1 Announce Type: cross 
Abstract: The Susceptible-Infected-Susceptible (SIS) model is a widely used model for the spread of information and infectious diseases, particularly non-immunizing ones, on a graph. Given a highly contagious disease, a natural question is how to best vaccinate individuals to minimize the disease's extinction time. While previous works showed that the problem of optimal vaccination is closely linked to the NP-hard Spectral Radius Minimization (SRM) problem, they assumed that the graph is known, which is often not the case in practice. In this work, we consider the problem of minimizing the extinction time of an outbreak modeled by an SIS model where the graph on which the disease spreads is unknown and only the infection states of the vertices are observed. To this end, we split the problem into two: learning the graph and determining effective vaccination strategies. We propose a novel inclusion-exclusion-based learning algorithm and, unlike previous approaches, establish its sample complexity for graph recovery. We then detail an optimal algorithm for the SRM problem and prove that its running time is polynomial in the number of vertices for graphs with bounded treewidth. This is complemented by an efficient and effective polynomial-time greedy heuristic for any graph. Finally, we present experiments on synthetic and real-world data that numerically validate our learning and vaccination algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15397v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sepehr Elahi, Paula M\"urmann, Patrick Thiran</dc:creator>
    </item>
    <item>
      <title>Learning Algorithms in the Limit</title>
      <link>https://arxiv.org/abs/2506.15543</link>
      <description>arXiv:2506.15543v1 Announce Type: cross 
Abstract: This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \textit{computational observations} and \textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15543v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hristo Papazov, Nicolas Flammarion</dc:creator>
    </item>
    <item>
      <title>A survey of Chernoff and Hoeffding bounds</title>
      <link>https://arxiv.org/abs/2506.15612</link>
      <description>arXiv:2506.15612v1 Announce Type: cross 
Abstract: This is a survey paper that discusses the original bounds of the seminal papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative bounds in a variety of forms. Complete proofs are provided as needed. The intent is to provide a repository of reference bounds for the interested researcher.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15612v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandros V. Gerbessiotis</dc:creator>
    </item>
    <item>
      <title>A Dichotomy for Maximum PCSPs on Graphs</title>
      <link>https://arxiv.org/abs/2406.20069</link>
      <description>arXiv:2406.20069v3 Announce Type: replace 
Abstract: Fix two non-empty loopless graphs $G$ and $H$ such that $G$ maps homomorphically to $H$. The Maximum Promise Constraint Satisfaction Problem parameterised by $G$ and $H$ is the following computational problem, denoted by MaxPCSP($G$, $H$): Given an input (multi)graph $X$ that admits a map to $G$ preserving a $\rho$-fraction of the edges, find a map from $X$ to $H$ that preserves a $\rho$-fraction of the edges. As our main result, we give a complete classification of this problem under Khot's Unique Games Conjecture: The only tractable cases are when $G$ is bipartite and $H$ contains a triangle.
  Along the way, we establish several results, including an efficient approximation algorithm for the following problem: Given a (multi)graph $X$ which contains a bipartite subgraph with $\rho$ edges, what is the largest triangle-free subgraph of $X$ that can be found efficiently? We present an SDP-based algorithm that finds one with at least $0.8823 \rho$ edges, thus improving on the subgraph with $0.878 \rho$ edges obtained by the classic Max-Cut algorithm of Goemans and Williamson.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.20069v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamio-Vesa Nakajima, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>PHast -- Perfect Hashing with fast evaluation</title>
      <link>https://arxiv.org/abs/2504.17918</link>
      <description>arXiv:2504.17918v3 Announce Type: replace 
Abstract: Perfect hash functions give unique "names" to arbitrary keys requiring only a few bits per key. This is an essential building block in applications like static hash tables, databases, or bioinformatics. This paper introduces the PHast approach that has the currently fastest query time with competitive construction time and space consumption. PHast improves bucket-placement which first hashes each key k to a bucket, and then looks for the bucket seed s such that a secondary hash function maps pairs (s,k) in a collision-free way. PHast can use small-range primary hash functions with linear mapping, fixed-width encoding of seeds, and parallel construction. This is achieved using small overlapping slices of allowed values and bumping to handle unsuccessful seed assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17918v3</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.PF</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Beling, Peter Sanders</dc:creator>
    </item>
    <item>
      <title>Breaking the O(mn)-Time Barrier for Vertex-Weighted Global Minimum Cut</title>
      <link>https://arxiv.org/abs/2506.11926</link>
      <description>arXiv:2506.11926v2 Announce Type: replace 
Abstract: We consider the Global Minimum Vertex-Cut problem: given an undirected vertex-weighted graph $G$, compute a minimum-weight subset of its vertices whose removal disconnects $G$. The problem is closely related to Global Minimum Edge-Cut, where the weights are on the graph edges instead of vertices, and the goal is to compute a minimum-weight subset of edges whose removal disconnects the graph. Global Minimum Cut is one of the most basic and extensively studied problems in combinatorial optimization and graph theory. While an almost-linear time algorithm was known for the edge version of the problem for awhile (Karger, STOC 1996 and J. ACM 2000), the fastest previous algorithm for the vertex version (Henzinger, Rao and Gabow, FOCS 1996 and J. Algorithms 2000) achieves a running time of $\tilde{O}(mn)$, where $m$ and $n$ denote the number of edges and vertices in the input graph, respectively. For the special case of unit vertex weights, this bound was broken only recently (Li {et al.}, STOC 2021); their result, combined with the recent breakthrough almost-linear time algorithm for Maximum $s$-$t$ Flow (Chen {et al.}, FOCS 2022, van den Brand {et al.}, FOCS 2023), yields an almost-linear time algorithm for Global Minimum Vertex-Cut with unit vertex weights.
  In this paper we break the $28$ years old bound of Henzinger {et al.} for the general weighted Global Minimum Vertex-Cut, by providing a randomized algorithm for the problem with running time $O(\min\{mn^{0.99+o(1)},m^{1.5+o(1)}\})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11926v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Chuzhoy, Ohad Trabelsi</dc:creator>
    </item>
    <item>
      <title>Detecting null patterns in tensor data</title>
      <link>https://arxiv.org/abs/2408.17425</link>
      <description>arXiv:2408.17425v2 Announce Type: replace-cross 
Abstract: This article introduces a class of efficiently computable null patterns for tensor data. The class includes familiar patterns such as block-diagonal decompositions explored in statistics and signal processing, low-rank tensor decompositions, and Tucker decompositions. It also includes a new family of null patterns -- not known to be detectable by current methods -- that can be thought of as continuous decompositions approximating curves and surfaces. We present a general algorithm to detect null patterns in each class using a parameter we call a \textit{chisel} that tunes the search to patterns of a prescribed shape. We also show that the patterns output by the algorithm are essentially unique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17425v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter A. Brooksbank, Martin D. Kassabov, James B. Wilson</dc:creator>
    </item>
    <item>
      <title>Hiding, Shuffling, and Cycle Finding: Quantum Algorithms on Edge Lists</title>
      <link>https://arxiv.org/abs/2412.17786</link>
      <description>arXiv:2412.17786v2 Announce Type: replace-cross 
Abstract: The edge list model is arguably the simplest input model for graphs, where the graph is specified by a list of its edges. In this model, we study the quantum query complexity of three variants of the triangle finding problem. The first asks whether there exists a triangle containing a target edge and raises general questions about the hiding of a problem's input among irrelevant data. The second asks whether there exists a triangle containing a target vertex and raises general questions about the shuffling of a problem's input. The third asks whether there exists a triangle; this problem bridges the $3$-distinctness and $3$-sum problems, which have been extensively studied by both cryptographers and complexity theorists. We provide tight or nearly tight results for these problems as well as some first answers to the general questions they raise.
  Furthermore, given a graph with low maximum degree, such as a random sparse graph, we prove that the quantum query complexity of finding a length-$k$ cycle in its length-$m$ edge list is $m^{3/4-1/(2^{k+2}-4)\pm o(1)}$. We prove the lower bound in Zhandry's recording query framework [CRYPTO '19] as generalized by Hamoudi and Magniez [ToCT '23], and the upper bound by adapting Belovs's learning graph algorithm for $k$-distinctness [FOCS '12].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17786v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Shiraz Gilani, Daochen Wang, Pei Wu, Xingyu Zhou</dc:creator>
    </item>
    <item>
      <title>Improved Regret in Stochastic Decision-Theoretic Online Learning under Differential Privacy</title>
      <link>https://arxiv.org/abs/2502.10997</link>
      <description>arXiv:2502.10997v2 Announce Type: replace-cross 
Abstract: Hu and Mehta (2024) posed an open problem: what is the optimal instance-dependent rate for the stochastic decision-theoretic online learning (with $K$ actions and $T$ rounds) under $\varepsilon$-differential privacy? Before, the best known upper bound and lower bound are $O\left(\frac{\log K}{\Delta_{\min}} + \frac{\log K\log T}{\varepsilon}\right)$ and $\Omega\left(\frac{\log K}{\Delta_{\min}} + \frac{\log K}{\varepsilon}\right)$ (where $\Delta_{\min}$ is the gap between the optimal and the second actions). In this paper, we partially address this open problem by having two new results. First, we provide an improved upper bound for this problem $O\left(\frac{\log K}{\Delta_{\min}} + \frac{\log^2K}{\varepsilon}\right)$, which is $T$-independent and only has a log dependency in $K$. Second, to further understand the gap, we introduce the \textit{deterministic setting}, a weaker setting of this open problem, where the received loss vector is deterministic. At this weaker setting, a direct application of the analysis and algorithms from the original setting still leads to an extra log factor. We conduct a novel analysis which proves upper and lower bounds that match at $\Theta(\frac{\log K}{\varepsilon})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10997v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruihan Wu, Yu-Xiang Wang</dc:creator>
    </item>
    <item>
      <title>Sublinear Algorithms for Wasserstein and Total Variation Distances: Applications to Fairness and Privacy Auditing</title>
      <link>https://arxiv.org/abs/2503.07775</link>
      <description>arXiv:2503.07775v2 Announce Type: replace-cross 
Abstract: Resource-efficiently computing representations of probability distributions and the distances between them while only having access to the samples is a fundamental and useful problem across mathematical sciences. In this paper, we propose a generic framework to learn the probability and cumulative distribution functions (PDFs and CDFs) of a sub-Weibull, i.e. almost any light- or heavy-tailed, distribution while the samples from it arrive in a stream. The idea is to reduce these problems into estimating the frequency of an \textit{appropriately chosen subset} of the support of a \textit{properly discretised distribution}. We leverage this reduction to compute mergeable summaries of distributions from the stream of samples while requiring only sublinear space relative to the number of observed samples. This allows us to estimate Wasserstein and Total Variation (TV) distances between any two distributions while samples arrive in streams and from multiple sources. Our algorithms significantly improves on the existing methods for distance estimation incurring super-linear time and linear space complexities, and further extend the mergeable summaries framework to continuous distributions with possibly infinite support. Our results are tight with respect to the existing lower bounds for bounded discrete distributions. In addition, we leverage our proposed estimators of Wasserstein and TV distances to tightly audit the fairness and privacy of algorithms. We empirically demonstrate the efficiency of proposed algorithms across synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07775v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>stat.CO</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debabrota Basu, Debarshi Chanda</dc:creator>
    </item>
    <item>
      <title>Minimum Non-Obtuse Triangulations: The CG:SHOP Challenge 2025</title>
      <link>https://arxiv.org/abs/2504.04412</link>
      <description>arXiv:2504.04412v2 Announce Type: replace-cross 
Abstract: We give an overview of the 2025 Computational Geometry Challenge targeting the problem Minimum Non-Obtuse Triangulation: Given a planar straight-line graph G in the plane, defined by a set of points in the plane (representing vertices) and a set of non-crossing line segments connecting them (representing edges); the objective is to find a feasible non-obtuse triangulation that uses a minimum number of Steiner points. If no triangulation without obtuse triangles is found, the secondary objective is to minimize the number of obtuse triangles in the triangulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04412v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'andor P. Fekete, Phillip Keldenich, Dominik Krupke, Stefan Schirra</dc:creator>
    </item>
  </channel>
</rss>
