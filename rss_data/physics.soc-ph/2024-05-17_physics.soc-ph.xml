<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 May 2024 04:01:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Energy Consumption of Plant Factory with Artificial Light: Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2405.09643</link>
      <description>arXiv:2405.09643v1 Announce Type: new 
Abstract: Plant factory with artificial light (PFAL) is a promising technology for relieving the food crisis, especially in urban areas or arid regions endowed with abundant resources. However, lighting and HVAC (heating, ventilation, and air conditioning) systems of PFAL have led to much greater energy consumption than open-field and greenhouse farming, limiting the application of PFAL to a wider extent. Recent researches pay much more attention to the optimization of energy consumption in order to develop and promote the PFAL technology with reduced energy usage. This work comprehensively summarizes the current energy-saving methods on lighting, HVAC systems, as well as their coupling methods for a more energy-efficient PFAL. Besides, we offer our perspectives on further energy-saving strategies and exploit the renewable energy resources for PFAL to respond to the urgent need for energy-efficient production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09643v1</guid>
      <category>physics.soc-ph</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyi Cai, Kunlang Bu, Lingyan Zha, Jingjin Zhang, Dayi Lai, Hua Bao</dc:creator>
    </item>
    <item>
      <title>Pedestrian evacuations with imitation of cooperative behavior</title>
      <link>https://arxiv.org/abs/2405.09978</link>
      <description>arXiv:2405.09978v1 Announce Type: new 
Abstract: We analyze the dynamics of room evacuation for mixed populations that include both competitive and cooperative individuals through numerical simulations using the social force model. Cooperative agents represent well-trained individuals who know how to behave in order to reduce risks within high-density crowds. We consider that competitive agents can imitate cooperative behavior when they are in close proximity to cooperators. We study the effects of the imitation of cooperative behavior on the duration and safety of evacuations, analyzing evacuation time and other quantities of interest for varying parameters such as the proportions of mixing, the aspect ratio of the room, and the parameters characterizing individual behaviors. Our main findings reveal that the addition of a relatively small number of cooperative agents into a crowd can reduce evacuation time and the density near the exit door, making the evacuation faster and safer despite an increase in the total number of agents. In particular, for long spaces such as corridors, a small number of added cooperative agents can significantly facilitate the evacuation process. We compare our results with those of systems without imitation and also study the general role of cooperation, providing further analysis for homogeneous populations. Our main conclusions emphasize the potential relevance of training people how to behave in high-density crowds</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09978v1</guid>
      <category>physics.soc-ph</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.109.054304</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 109, 054304 (2024)</arxiv:journal_reference>
      <dc:creator>Amir Zablotsky, Marcelo N Kuperman, Sebasti\'an Bouzat</dc:creator>
    </item>
    <item>
      <title>Dynamical behavior and optimal control of a stochastic SAIRS epidemic model with two saturated incidences</title>
      <link>https://arxiv.org/abs/2405.09982</link>
      <description>arXiv:2405.09982v1 Announce Type: cross 
Abstract: Stochastic models are widely used to investigate the spread of epidemics in a complex environment. This paper extends a deterministic SAIRS epidemic model to a stochastic case with limited patient capacity and exposure. We first study the dynamical properties of the model under certain conditions, including persistence, extinction, and ergodic. Then, we introduce vaccination and isolation into the model as control variables. The optimal control strategies are obtained based on the Pontryagin minimum principle. Finally, numerical simulations are given to illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09982v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaohui Zhang,  Zhiming, Shenglong Chen, Jikai Yang</dc:creator>
    </item>
    <item>
      <title>Emergence of Cooperation in Two-agent Repeated Games with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2307.04612</link>
      <description>arXiv:2307.04612v2 Announce Type: replace 
Abstract: Cooperation is the foundation of ecosystems and the human society, and the reinforcement learning provides crucial insight into the mechanism for its emergence. However, most previous work has mostly focused on the self-organization at the population level, the fundamental dynamics at the individual level remains unclear. Here, we investigate the evolution of cooperation in a two-agent system, where each agent pursues optimal policies according to the classical Q-learning algorithm in playing the strict prisoner's dilemma. We reveal that a strong memory and long-sighted expectation yield the emergence of Coordinated Optimal Policies (COPs), where both agents act like Win-Stay, Lose-Shift (WSLS) to maintain a high level of cooperation. Otherwise, players become tolerant toward their co-player's defection and the cooperation loses stability in the end where the policy all Defection (All-D) prevails. This suggests that tolerance could be a good precursor to a crisis in cooperation. Furthermore, our analysis shows that the Coordinated Optimal Modes (COMs) for different COPs gradually lose stability as memory weakens and expectation for the future decreases, where agents fail to predict co-player's action in games and defection dominates. As a result, we give the constraint to expectations of future and memory strength for maintaining cooperation. In contrast to the previous work, the impact of exploration on cooperation is found not be consistent, but depends on composition of COMs. By clarifying these fundamental issues in this two-player system, we hope that our work could be helpful for understanding the emergence and stability of cooperation in more complex scenarios in reality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04612v2</guid>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.chaos.2023.114032</arxiv:DOI>
      <arxiv:journal_reference>Chaos, Solitons &amp; Fractals 175 (2023): 114032</arxiv:journal_reference>
      <dc:creator>Zhen-Wei Ding, Guo-Zhong Zheng, Chao-Ran Cai, Wei-Ran Cai, Li Chen, Ji-Qiang Zhang, Xu-Ming Wang</dc:creator>
    </item>
  </channel>
</rss>
