<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Estimation in linear high dimensional Hawkes processes: a Bayesian approach</title>
      <link>https://arxiv.org/abs/2510.24182</link>
      <description>arXiv:2510.24182v1 Announce Type: new 
Abstract: In this paper we study the frequentist properties of Bayesian approaches in linear high dimensional Hawkes processes in a sparse regime where the number of interaction functions acting on each component of the Hawkes process is much smaller than the dimension. We consider two types of loss function: the empirical $L_1$ distance between the intensity functions of the process and the $L_1$ norm on the parameters (background rates and interaction functions). Our results are the first results to control the $L_1$ norm on the parameters under such a framework. They are also the first results to study Bayesian procedures in high dimensional Hawkes processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24182v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Judith Rousseau, Vincent Rivoirard, D\'eborah Sulem</dc:creator>
    </item>
    <item>
      <title>Curvature-based rejection sampling</title>
      <link>https://arxiv.org/abs/2510.24537</link>
      <description>arXiv:2510.24537v1 Announce Type: new 
Abstract: The present work introduces curvature-based rejection sampling (CURS). This is a method for sampling from a general class of probability densities defined on Riemannian manifolds. It can be used to sample from any probability density which ``depends only on distance". The idea is to combine the statistical principle of rejection sampling with the geometric principle of volume comparison. CURS is an exact sampling method and (assuming the underlying Riemannian manifold satisfies certain technical conditions) it has a particularly moderate computational cost. The aim of the present work is to show that there are many applications where CURS should be the user's method of choice for dealing with relatively low-dimensional scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24537v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabella Costa Maia, Marco Congedo, Pedro L. C. Rodrigues, Salem Said</dc:creator>
    </item>
    <item>
      <title>A Frequency-Domain NonStationarity Test for dependent data</title>
      <link>https://arxiv.org/abs/2510.24319</link>
      <description>arXiv:2510.24319v1 Announce Type: cross 
Abstract: Distinguishing long-memory behaviour from nonstationarity is challenging, as both produce slowly decaying sample autocovariances. Existing stationarity tests either fail to account for long-memory processes or exhibit poor empirical size, particularly near the boundary between stationarity and nonstationarity. We propose a new, parameter-free testing procedure based on the evaluation of periodograms across multiple epochs. The limiting distributions derived here are obtained under stationarity and nonstationarity assumptions and analytically tractable, expressed as finite sums of weighted independent $\chi^2$ random variables. Simulation studies indicate that the proposed method performs favorably compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24319v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamedou Ould Haye, Anne Philippe</dc:creator>
    </item>
    <item>
      <title>Nearest Neighbor Matching as Least Squares Density Ratio Estimation and Riesz Regression</title>
      <link>https://arxiv.org/abs/2510.24433</link>
      <description>arXiv:2510.24433v1 Announce Type: cross 
Abstract: This study proves that Nearest Neighbor (NN) matching can be interpreted as an instance of Riesz regression for automatic debiased machine learning. Lin et al. (2023) shows that NN matching is an instance of density-ratio estimation with their new density-ratio estimator. Chernozhukov et al. (2024) develops Riesz regression for automatic debiased machine learning, which directly estimates the Riesz representer (or equivalently, the bias-correction term) by minimizing the mean squared error. In this study, we first prove that the density-ratio estimation method proposed in Lin et al. (2023) is essentially equivalent to Least-Squares Importance Fitting (LSIF) proposed in Kanamori et al. (2009) for direct density-ratio estimation. Furthermore, we derive Riesz regression using the LSIF framework. Based on these results, we derive NN matching from Riesz regression. This study is based on our work Kato (2025a) and Kato (2025b).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24433v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>On the large-sample limits of some Bayesian model evaluation statistics</title>
      <link>https://arxiv.org/abs/2502.03846</link>
      <description>arXiv:2502.03846v2 Announce Type: replace 
Abstract: Model selection and order selection problems frequently arise in statistical practice. A popular approach to addressing these problems in the frequentist setting involves information criteria based on penalised maxima of log-likelihoods for competing models. In the Bayesian context, similar criteria are employed, replacing the maximised log-likelihoods with posterior expectations of the log-likelihood. Despite their popularity in applications, the large-sample behaviour of these criteria -- such as the deviance information criterion (DIC), Bayesian predictive information criterion (BPIC), and widely applicable Bayesian information criterion (WBIC) -- has received relatively little attention. In this work, we investigate the almost-sure limits of these criteria and establish novel results on posterior and generalised posterior consistency, which are of independent interest. The utility of our theoretical findings is demonstrated via illustrative technical and numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03846v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hien Duy Nguyen, Mayetri Gupta, Jacob Westerhout, TrungTin Nguyen</dc:creator>
    </item>
    <item>
      <title>On the Estimation of Gaussian Moment Tensors</title>
      <link>https://arxiv.org/abs/2507.06166</link>
      <description>arXiv:2507.06166v2 Announce Type: replace 
Abstract: This paper studies two estimators for Gaussian moment tensors: the standard sample moment estimator and a plug-in estimator based on Isserlis's theorem. We establish dimension-free, non-asymptotic error bounds that demonstrate and quantify the advantage of Isserlis's estimator for tensors of even order $p&gt;2$. Our bounds hold in operator and entrywise maximum norms, and apply to symmetric and asymmetric tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06166v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Al-Ghattas, Jiaheng Chen, Daniel Sanz-Alonso</dc:creator>
    </item>
    <item>
      <title>Minimax Estimation Problem for Periodically Correlated Stochastic Processes</title>
      <link>https://arxiv.org/abs/2510.14033</link>
      <description>arXiv:2510.14033v2 Announce Type: replace 
Abstract: The problem of optimal linear estimation of linear functionals depending on the unknown values of a periodically correlated stochastic process from observations of the process with additive noise is considered. Formulas for calculating the mean square error and the spectral characteristic of the optimal linear estimate of the functionals are proposed in the case where spectral densities are exactly known and in the case where the spectral densities are unknown while a class of admissible spectral densities is given. Formulas that determine the least favorable spectral densities and the minimax (robust) spectral characteristics are proposed for a given class of admissible spectral densities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14033v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iryna Dubovets'ka, Mykhailo Moklyachuk</dc:creator>
    </item>
    <item>
      <title>Limiting Spectral Distribution of High-dimensional Multivariate Kendall-$\tau$</title>
      <link>https://arxiv.org/abs/2510.21077</link>
      <description>arXiv:2510.21077v2 Announce Type: replace 
Abstract: The multivariate Kendall-$\tau$ statistic, denoted by $K_n$, plays a significant role in robust statistical analysis. This paper establishes the limiting properties of the empirical spectral distribution (ESD) of $K_n$. We demonstrate that the ESD of $\frac{1}{2}pK_n$ converges almost surely to the Mar\v{c}enko--Pastur law with variance parameter $\frac{1}{2}$, analogous to the classical result for sample covariance matrices.
  Using Stieltjes transform techniques, we extend these results to the independent component model, deriving a fixed-point equation that characterizes the limiting spectral distribution of $\frac{1}{2}tr\Sigma K_n$. The theoretical findings are validated through comprehensive simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21077v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoyu Wu</dc:creator>
    </item>
    <item>
      <title>Sparse estimation for the drift of high-dimensional Ornstein--Uhlenbeck processes with i.i.d. paths</title>
      <link>https://arxiv.org/abs/2510.21505</link>
      <description>arXiv:2510.21505v2 Announce Type: replace 
Abstract: We study sparsity-regularized maximum likelihood estimation for the drift parameter of high-dimensional non-stationary Ornstein--Uhlenbeck processes given repeated measurements of i.i.d. paths. In particular, we show that Lasso and Slope estimators can achieve the minimax optimal rate of convergence. We exhibit numerical experiments for sparse estimation methods and show their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21505v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shogo Nakakita</dc:creator>
    </item>
    <item>
      <title>Learning Firmly Nonexpansive Operators</title>
      <link>https://arxiv.org/abs/2407.14156</link>
      <description>arXiv:2407.14156v3 Announce Type: replace-cross 
Abstract: This paper proposes a data-driven approach for constructing firmly nonexpansive operators. We demonstrate its applicability in Plug-and-Play (PnP) methods, where classical algorithms such as Forward-Backward splitting, Chambolle-Pock primal-dual iteration, Douglas-Rachford iteration or alternating directions method of multipliers (ADMM), are modified by replacing one proximal map by a learned firmly nonexpansive operator. We provide sound mathematical background to the problem of learning such an operator via expected and empirical risk minimization. We prove that, as the number of training points increases, the empirical risk minimization problem converges (in the sense of Gamma-convergence) to the expected risk minimization problem. Further, we derive a solution strategy that ensures firmly nonexpansive and piecewise affine operators within the convex envelope of the training set. We show that this operator converges to the best empirical solution as the number of points in the envelope increases in an appropriate way. Finally, the experimental section details practical implementations of the method and presents an application in image denoising, where we consider a novel, interpretable PnP Chambolle-Pock primal-dual iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14156v3</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristian Bredies, Jonathan Chirinos-Rodriguez, Emanuele Naldi</dc:creator>
    </item>
    <item>
      <title>Program Evaluation with Remotely Sensed Outcomes</title>
      <link>https://arxiv.org/abs/2411.10959</link>
      <description>arXiv:2411.10959v3 Announce Type: replace-cross 
Abstract: Economists often estimate treatment effects in experiments using remotely sensed variables (RSVs), e.g., satellite images or mobile phone activity, in place of directly measured economic outcomes. A common practice is to use an observational sample to train a predictor of the economic outcome from the RSV, and then use these predictions as the outcomes in the experiment. We show that this method is biased whenever the RSV is a post-outcome variable, meaning that variation in the economic outcome causes variation in the RSV. For example, changes in poverty or environmental quality cause changes in satellite images, but not vice versa. As our main result, we nonparametrically identify the treatment effect by formalizing the intuition underlying common practice: the conditional distribution of the RSV given the outcome and treatment is stable across samples. Our identifying formula reveals that efficient inference requires predictions of three quantities from the RSV -- the outcome, treatment, and sample indicator -- whereas common practice only predicts the outcome. Valid inference does not require any rate conditions on RSV predictions, justifying the use of complex deep learning algorithms with unknown statistical properties. We reanalyze the effect of an anti-poverty program in India using satellite images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10959v3</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ashesh Rambachan, Rahul Singh, Davide Viviano</dc:creator>
    </item>
    <item>
      <title>Regularisation of CART trees by summation of $p$-values</title>
      <link>https://arxiv.org/abs/2505.18769</link>
      <description>arXiv:2505.18769v2 Announce Type: replace-cross 
Abstract: The standard procedure to decide on the complexity of a CART regression tree is to use cross-validation with the aim of obtaining a predictor that generalises well to unseen data. The randomness in the selection of folds implies that the selected CART regression tree is not a deterministic function of the data. Moreover, the cross-validation procedure may become time consuming and result in inefficient use of training data. We propose a simple deterministic in-sample method that can be used for stopping the growing of a CART regression tree based on node-wise statistical tests. This testing procedure is derived using a connection to change point detection, where the null hypothesis corresponds to no signal. The suggested $p$-value based procedure allows us to consider covariate vectors of arbitrary dimension and allows us to bound the $p$-value of an entire tree from above. Further, we show that the test detects a not too weak signal with a high probability, given a not too small sample size.
  We illustrate our methodology and the asymptotic results on both simulated and real world data. Additionally, we illustrate how the $p$-value based method can be used to construct a deterministic piece-wise constant auto-calibrated predictor based on a given black-box predictor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18769v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nils Engler, Mathias Lindholm, Filip Lindskog, Taariq Nazar</dc:creator>
    </item>
    <item>
      <title>Optimal Spatial Anomaly Detection</title>
      <link>https://arxiv.org/abs/2510.22330</link>
      <description>arXiv:2510.22330v2 Announce Type: replace-cross 
Abstract: There has been a growing interest in anomaly detection problems recently, whilst their focuses are mostly on anomalies taking place on the time index. In this work, we investigate a new anomaly-in-mean problem in multidimensional spatial lattice, that is, to detect the number and locations of anomaly ''spatial regions'' from the baseline. In addition to the classic minimisation over the cost function with a $L_0$ penalisation, we introduce an innovative penalty on the area of the minimum convex hull that covers the anomaly regions. We show that the proposed method yields a consistent estimation of the number of anomalies, and it achieves near optimal localisation error under the minimax framework. We also propose a dynamic programming algorithm to solve the double penalised cost minimisation approximately, and carry out large-scale Monte Carlo simulations to examine its numeric performance. The method has a wide range of applications in real-world problems. As an example, we apply it to detect the marine heatwaves using the sea surface temperature data from the European Space Agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22330v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baiyu Wang, Chao Zheng</dc:creator>
    </item>
  </channel>
</rss>
