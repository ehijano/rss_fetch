<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Mar 2024 04:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Useful Compact Representations for Data-Fitting</title>
      <link>https://arxiv.org/abs/2403.12206</link>
      <description>arXiv:2403.12206v1 Announce Type: new 
Abstract: For minimization problems without 2nd derivative information, methods that estimate Hessian matrices can be very effective. However, conventional techniques generate dense matrices that are prohibitive for large problems. Limited-memory compact representations express the dense arrays in terms of a low rank representation and have become the state-of-the-art for software implementations on large deterministic problems. We develop new compact representations that are parameterized by a choice of vectors and that reduce to existing well known formulas for special choices. We demonstrate effectiveness of the compact representations for large eigenvalue computations, tensor factorizations and nonlinear regressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12206v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes J. Brust</dc:creator>
    </item>
    <item>
      <title>The Best of Many Robustness Criteria in Decision Making: Formulation and Application to Robust Pricing</title>
      <link>https://arxiv.org/abs/2403.12260</link>
      <description>arXiv:2403.12260v1 Announce Type: new 
Abstract: In robust decision-making under non-Bayesian uncertainty, different robust optimization criteria, such as maximin performance, minimax regret, and maximin ratio, have been proposed. In many problems, all three criteria are well-motivated and well-grounded from a decision-theoretic perspective, yet different criteria give different prescriptions. This paper initiates a systematic study of overfitting to robustness criteria. How good is a prescription derived from one criterion when evaluated against another criterion? Does there exist a prescription that performs well against all criteria of interest? We formalize and study these questions through the prototypical problem of robust pricing under various information structures, including support, moments, and percentiles of the distribution of values. We provide a unified analysis of three focal robust criteria across various information structures and evaluate the relative performance of mechanisms optimized for each criterion against the others. We find that mechanisms optimized for one criterion often perform poorly against other criteria, highlighting the risk of overfitting to a particular robustness criterion. Remarkably, we show it is possible to design mechanisms that achieve good performance across all three criteria simultaneously, suggesting that decision-makers need not compromise among criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12260v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jerry Anunrojwong, Santiago R. Balseiro, Omar Besbes</dc:creator>
    </item>
    <item>
      <title>Stochastic Halpern iteration in normed spaces and applications to reinforcement learning</title>
      <link>https://arxiv.org/abs/2403.12338</link>
      <description>arXiv:2403.12338v1 Announce Type: new 
Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, for the average reward, our method improves on the best-known sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12338v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Bravo, Juan Pablo Contreras</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Density Control with Wasserstein Ambiguity Sets</title>
      <link>https://arxiv.org/abs/2403.12378</link>
      <description>arXiv:2403.12378v1 Announce Type: new 
Abstract: Precise control under uncertainty requires a good understanding and characterization of the noise affecting the system. This paper studies the problem of steering state distributions of dynamical systems subject to partially known uncertainties. We model the distributional uncertainty of the noise process in terms of Wasserstein ambiguity sets, which, based on recent results, have been shown to be an effective means of capturing and propagating uncertainty through stochastic LTI systems. To this end, we propagate the distributional uncertainty of the state through the dynamical system, and, using an affine feedback control law, we steer the ambiguity set of the state to a prescribed, terminal ambiguity set. We also enforce distributionally robust CVaR constraints for the transient motion of the state so as to reside within a prescribed constraint space. The resulting optimization problem is formulated as a semi-definite program, which can be solved efficiently using standard off-the-shelf solvers. We illustrate the proposed distributionally-robust framework on a quadrotor landing problem subject to wind turbulence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12378v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pilipovsky, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>Attitude Tracking of Uncertain Flexible Spacecraft Systems Subject to Unknown External Disturbances</title>
      <link>https://arxiv.org/abs/2403.12542</link>
      <description>arXiv:2403.12542v1 Announce Type: new 
Abstract: In this paper, we investigate the attitude tracking problem of uncertain flexible spacecraft systems subject to external disturbances. In sharp contrast to existing results, the dynamics of flexible spacecraft systems and external disturbances are allowed to be unknown. To deal with the challenges by these unknown factors, we develop a class of nonlinear internal models which converts the attitude tracking problem of uncertain flexible spacecraft systems into a regulation problem of an augmented system. Furthermore, to overcome the difficulties caused by the unmeasurable modal variable, the uncertainty introduced by the internal model, and the cross-coupling of the uncertainties with the system state, we design an auxiliary dynamic system for auxiliary stabilization, a dynamic compensator for dynamic compensation, and a linearly parameterized transformation for adaptive regulation in sequence. By introducing a series of coordinate and input transformations, we propose an adaptive dynamic control law to achieve regulation of the augmented system and thus leading to the solution to the attitude tracking problem. In addition, we analyze the convergence issue of the estimated parameter to its true value by the persistently exciting condition. Finally, the effec tiveness of the developed approach is verified by its application to the attitude manoeuvre of a flexible spacecraft system in the presence of external disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12542v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zean Bao, Maobin Lu, Fang Deng, Jie Chen</dc:creator>
    </item>
    <item>
      <title>Non-coercive Neumann boundary control problems</title>
      <link>https://arxiv.org/abs/2403.12551</link>
      <description>arXiv:2403.12551v1 Announce Type: new 
Abstract: The article examines a linear-quadratic Neumann control problem that is governed by a non-coercive elliptic equation. Due to the non-self-adjoint nature of the linear control-to-state operator, it is necessary to independently study both the state and adjoint state equations. The article establishes the existence and uniqueness of solutions for both equations, with minimal assumptions made about the problem's data. Next, the regularity of these solutions is studied in three frameworks: Hilbert-Sobolev spaces, Sobolev-Slobodecki\u\i{} spaces, and weighted Sobolev spaces. These regularity results enable a numerical analysis of the finite element approximation of both the state and adjoint state equations. The results cover both convex and non-convex domains and quasi-uniform and graded meshes. Finally, the optimal control problem is analyzed and discretized. Existence and uniqueness of the solution, first-order optimality conditions, and error estimates for the finite element approximation of the control are obtained. Numerical experiments confirming these results are included. A significant highlight is that the discretization error estimates known from the literature, are improved even for the coercive case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12551v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Apel, Mariano Mateos, Arnd R\"osch</dc:creator>
    </item>
    <item>
      <title>The Smoothed Duality Gap as a Stopping Criterion</title>
      <link>https://arxiv.org/abs/2403.12579</link>
      <description>arXiv:2403.12579v1 Announce Type: new 
Abstract: We optimize the running time of the primal-dual algorithms by optimizing their stopping criteria for solving convex optimization problems under affine equality constraints, which means terminating the algorithm earlier with fewer iterations. We study the relations between four stopping criteria and show under which conditions they are accurate to detect optimal solutions. The uncomputable one: ''Optimality gap and Feasibility error'', and the computable ones: the ''Karush-Kuhn-Tucker error'', the ''Projected Duality Gap'', and the ''Smoothed Duality Gap''. Assuming metric sub-regularity or quadratic error bound, we establish that all of the computable criteria provide practical upper bounds for the optimality gap, and approximate it effectively. Furthermore, we establish comparability between some of the computable criteria under certain conditions. Numerical experiments on basis pursuit, and quadratic programs with(out) non-negative weights corroborate these findings and show the superior stability of the smoothed duality gap over the rest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12579v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iyad Walwil (S2A), Olivier Fercoq (S2A)</dc:creator>
    </item>
    <item>
      <title>A new framework for constrained optimization via feedback control of Lagrange multipliers</title>
      <link>https://arxiv.org/abs/2403.12738</link>
      <description>arXiv:2403.12738v1 Announce Type: new 
Abstract: The continuous-time analysis of existing iterative algorithms for optimization has a long history. This work proposes a novel continuous-time control-theoretic framework for equality-constrained optimization. The key idea is to design a feedback control system where the Lagrange multipliers are the control input, and the output represents the constraints. The system converges to a stationary point of the constrained optimization problem through suitable regulation. Regarding the Lagrange multipliers, we consider two control laws: proportional-integral control and feedback linearization. These choices give rise to a family of different methods. We rigorously develop the related algorithms, theoretically analyze their convergence and present several numerical experiments to support their effectiveness concerning the state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12738v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V. Cerone, S. M. Fosson, S. Pirrera, D. Regruto</dc:creator>
    </item>
    <item>
      <title>Primal Methods for Variational Inequality Problems with Functional Constraints</title>
      <link>https://arxiv.org/abs/2403.12859</link>
      <description>arXiv:2403.12859v1 Announce Type: new 
Abstract: Constrained variational inequality problems are recognized for their broad applications across various fields including machine learning and operations research. First-order methods have emerged as the standard approach for solving these problems due to their simplicity and scalability. However, they typically rely on projection or linear minimization oracles to navigate the feasible set, which becomes computationally expensive in practical scenarios featuring multiple functional constraints. Existing efforts to tackle such functional constrained variational inequality problems have centered on primal-dual algorithms grounded in the Lagrangian function. These algorithms along with their theoretical analysis often require the existence and prior knowledge of the optimal Lagrange multipliers. In this work, we propose a simple primal method, termed Constrained Gradient Method (CGM), for addressing functional constrained variational inequality problems, without necessitating any information on the optimal Lagrange multipliers. We establish a non-asymptotic convergence analysis of the algorithm for variational inequality problems with monotone operators under smooth constraints. Remarkably, our algorithms match the complexity of projection-based methods in terms of operator queries for both monotone and strongly monotone settings, while utilizing significantly cheaper oracles based on quadratic programming. Furthermore, we provide several numerical examples to evaluate the efficacy of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12859v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Zhang, Niao He, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>Markovian lifting and optimal control for integral stochastic Volterra equations with completely monotone kernels</title>
      <link>https://arxiv.org/abs/2403.12875</link>
      <description>arXiv:2403.12875v1 Announce Type: new 
Abstract: In this paper, we focus on solving the optimal control problem for integral stochastic Volterra equations in a finite dimensional setting. In our setting, the noise term is driven by a pure jump L\'evy noise and the control acts on the intensity of the jumps.
  We use recent techniques proposed by Hamaguchi, where a crucial requirement is that the convolution kernel should be a completely monotone function. This allows us to use Bernstein's representation and the machinery of Laplace transform to obtain a Markovian lift.
  It is natural that the Markovian lift, in whatever form constructed, transforms the state equation into a stochastic differential equation in an infinite-dimensional space. This space should be large enough to contain all the information about the history of the process. Hence, although the original equation is taken in a finite dimensional space, the resulting lift is always infinite dimensional.
  We solve the problem by using the forward-backward approach in the infinite-dimensional setting and prove the existence of the optimal control for the original problem. Under additional assumptions on the coefficients, we see that a control in closed-loop form can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12875v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Bonaccorsi, Fulvia Confortola</dc:creator>
    </item>
    <item>
      <title>Solving Combinatorial Pricing Problems using Embedded Dynamic Programming Models</title>
      <link>https://arxiv.org/abs/2403.12923</link>
      <description>arXiv:2403.12923v1 Announce Type: new 
Abstract: The combinatorial pricing problem (CPP) is a bilevel problem in which the leader maximizes their revenue by imposing tolls on certain items that they can control. Based on the tolls set by the leader, the follower selects a subset of items corresponding to an optimal solution of a combinatorial optimization problem. To accomplish the leader's goal, the tolls need to be sufficiently low to discourage the follower from choosing the items offered by the competitors. In this paper, we derive a single-level reformulation for the CPP by rewriting the follower's problem as a longest path problem using a dynamic programming model, and then taking its dual and applying strong duality. We proceed to solve the reformulation in a dynamic fashion with a cutting plane method. We apply this methodology to 2 distinct dynamic programming models, namely, a novel formulation designated as selection diagram and the well-known decision diagram. We also produce numerical results to evaluate their performances across 3 different specializations of the CPP and a closely related problem that is the knapsack interdiction problem. Our results showcase the potential of the 2 proposed reformulations over the natural value function approach, expanding the set of tools to solve combinatorial bilevel programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12923v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Quang Minh Bui, Margarida Carvalho, Jos\'e Neto</dc:creator>
    </item>
    <item>
      <title>Identifiability and Observability of Nonsmooth Systems via Taylor-like Approximations</title>
      <link>https://arxiv.org/abs/2403.12930</link>
      <description>arXiv:2403.12930v1 Announce Type: new 
Abstract: New sensitivity-based methods are developed for determining identifiability and observability of nonsmooth input-output systems. More specifically, lexicographic calculus is used to construct nonsmooth sensitivity rank condition (SERC) tests, which we call lexicographic SERC (L-SERC) tests. The introduced L-SERC tests are: (i) practically implementable and amenable to large-scale problems; (ii) accurate since they directly treat the nonsmoothness while avoiding, e.g., smoothing approximations; and (iii) analogous to (and indeed recover) their smooth counterparts. To accomplish this, a first-order Taylor-like approximation theory is developed using lexicographic differentiation to directly treat nonsmooth functions. A practically implementable algorithm is proposed that determines partial structural identifiability or observability, a useful characterization in the nonsmooth setting. Lastly, the theory is illustrated through an application in climate modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12930v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Stechlinski, Sameh Eisa, Hesham Abdelfattah</dc:creator>
    </item>
    <item>
      <title>Foundations of Value of Information: A Semantic Metric for Networked Control Systems Tasks</title>
      <link>https://arxiv.org/abs/2403.11927</link>
      <description>arXiv:2403.11927v1 Announce Type: cross 
Abstract: In this chapter, we present our recent invention, i.e., the notion of the value of information$\unicode{x2014}$a semantic metric that is fundamental for networked control systems tasks. We begin our analysis by formulating a causal tradeoff between the packet rate and the regulation cost, with an encoder and a decoder as two distributed decision makers, and show that the valuation of information is conceivable and quantifiable grounded on this tradeoff. More precisely, we characterize an equilibrium, and quantify the value of information there as the variation in a value function with respect to a piece of sensory measurement that can be communicated from the encoder to the decoder at each time. We prove that, in feedback control of a dynamical process over a noiseless channel, the value of information is a function of the discrepancy between the state estimates at the encoder and the decoder, and that a data packet containing a sensory measurement at each time should be exchanged only if the value of information at that time is nonnegative. Finally, we prove that the characterized equilibrium is in fact globally optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11927v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, John S. Baras, Sandra Hirche, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>A GNN Approach for Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2403.12062</link>
      <description>arXiv:2403.12062v1 Announce Type: cross 
Abstract: Beyond 5G wireless technology Cell-Free Massive MIMO (CFmMIMO) downlink relies on carefully designed precoders and power control to attain uniformly high rate coverage. Many such power control problems can be calculated via second order cone programming (SOCP). In practice, several order of magnitude faster numerical procedure is required because power control has to be rapidly updated to adapt to changing channel conditions. We propose a Graph Neural Network (GNN) based solution to replace SOCP. Specifically, we develop a GNN to obtain downlink max-min power control for a CFmMIMO with maximum ratio transmission (MRT) beamforming. We construct a graph representation of the problem that properly captures the dominant dependence relationship between access points (APs) and user equipments (UEs). We exploit a symmetry property, called permutation equivariance, to attain training simplicity and efficiency. Simulation results show the superiority of our approach in terms of computational complexity, scalability and generalizability for different system sizes and deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12062v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/GLOBECOM48099.2022.10001647</arxiv:DOI>
      <arxiv:journal_reference>GLOBECOM 2022 - 2022 IEEE Global Communications Conference, Dec 2022, Rio de Janeiro, France. pp.3053-3058</arxiv:journal_reference>
      <dc:creator>Lou Salaun, Hong Yang, Shashwat Mishra, Chung Shue Chen</dc:creator>
    </item>
    <item>
      <title>PETScML: Second-order solvers for training regression problems in Scientific Machine Learning</title>
      <link>https://arxiv.org/abs/2403.12188</link>
      <description>arXiv:2403.12188v1 Announce Type: cross 
Abstract: In recent years, we have witnessed the emergence of scientific machine learning as a data-driven tool for the analysis, by means of deep-learning techniques, of data produced by computational science and engineering applications. At the core of these methods is the supervised training algorithm to learn the neural network realization, a highly non-convex optimization problem that is usually solved using stochastic gradient methods. However, distinct from deep-learning practice, scientific machine-learning training problems feature a much larger volume of smooth data and better characterizations of the empirical risk functions, which make them suited for conventional solvers for unconstrained optimization. We introduce a lightweight software framework built on top of the Portable and Extensible Toolkit for Scientific computation to bridge the gap between deep-learning software and conventional solvers for unconstrained minimization. We empirically demonstrate the superior efficacy of a trust region method based on the Gauss-Newton approximation of the Hessian in improving the generalization errors arising from regression tasks when learning surrogate models for a wide range of scientific machine-learning techniques and test cases. All the conventional second-order solvers tested, including L-BFGS and inexact Newton with line-search, compare favorably, either in terms of cost or accuracy, with the adaptive first-order methods used to validate the surrogate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12188v1</guid>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Zampini, Umberto Zerbinati, George Turkiyyah, David Keyes</dc:creator>
    </item>
    <item>
      <title>Information Compression in Dynamic Information Disclosure Games</title>
      <link>https://arxiv.org/abs/2403.12204</link>
      <description>arXiv:2403.12204v1 Announce Type: cross 
Abstract: We consider a two-player dynamic information design problem between a principal and a receiver -- a game is played between the two agents on top of a Markovian system controlled by the receiver's actions, where the principal obtains and strategically shares some information about the underlying system with the receiver in order to influence their actions. In our setting, both players have long-term objectives, and the principal sequentially commits to their strategies instead of committing at the beginning. Further, the principal cannot directly observe the system state, but at every turn they can choose randomized experiments to observe the system partially. The principal can share details about the experiments to the receiver. For our analysis we impose the truthful disclosure rule: the principal is required to truthfully announce the details and the result of each experiment to the receiver immediately after the experiment result is revealed. Based on the received information, the receiver takes an action when its their turn, with the action influencing the state of the underlying system. We show that there exist Perfect Bayesian equilibria in this game where both agents play Canonical Belief Based (CBB) strategies using a compressed version of their information, rather than full information, to choose experiments (for the principal) or actions (for the receiver). We also provide a backward inductive procedure to solve for an equilibrium in CBB strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12204v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dengwang Tang, Vijay G. Subramanian</dc:creator>
    </item>
    <item>
      <title>Probabilistic reachable sets of stochastic nonlinear systems with contextual uncertainties</title>
      <link>https://arxiv.org/abs/2403.12379</link>
      <description>arXiv:2403.12379v1 Announce Type: cross 
Abstract: Validating and controlling safety-critical systems in uncertain environments necessitates probabilistic reachable sets of future state evolutions. The existing methods of computing probabilistic reachable sets normally assume that the uncertainties are independent of the state. However, this assumption falls short in many real-world applications, where uncertainties are state-dependent, referred to as contextual uncertainties. This paper formulates the problem of computing probabilistic reachable sets of stochastic nonlinear states with contextual uncertainties by seeking minimum-volume polynomial sublevel sets with contextual chance constraints. The formulated problem cannot be solved by the existing sample-based approximation method since the existing methods do not consider the conditional probability densities. To address this, we propose a consistent sample approximation of the original problem by leveraging the conditional density estimation and resampling. The obtained approximate problem is a tractable optimization problem. Additionally, we prove the almost uniform convergence of the proposed sample-based approximation, showing that it gives the optimal solution almost consistently with the original ones. Through a numerical example, we evaluate the effectiveness of the proposed method against existing approaches, highlighting its capability to significantly reduce the bias inherent in sample-based approximation without considering a conditional probability density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12379v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xun Shen, Ye Wang, Kazumune Hashimoto, Yuhu Wu, Sebastien Gros</dc:creator>
    </item>
    <item>
      <title>Stochastic variance reduced gradient method for linear ill-posed inverse problems</title>
      <link>https://arxiv.org/abs/2403.12460</link>
      <description>arXiv:2403.12460v1 Announce Type: cross 
Abstract: In this paper we apply the stochastic variance reduced gradient (SVRG) method, which is a popular variance reduction method in optimization for accelerating the stochastic gradient method, to solve large scale linear ill-posed systems in Hilbert spaces. Under {\it a priori} choices of stopping indices, we derive a convergence rate result when the sought solution satisfies a benchmark source condition and establish a convergence result without using any source condition. To terminate the method in an {\it a posteriori} manner, we consider the discrepancy principle and show that it terminates the method in finite many iteration steps almost surely. Various numerical results are reported to test the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12460v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinian Jin, Liuhong Chen</dc:creator>
    </item>
    <item>
      <title>Forward Gradient-Based Frank-Wolfe Optimization for Memory Efficient Deep Neural Network Training</title>
      <link>https://arxiv.org/abs/2403.12511</link>
      <description>arXiv:2403.12511v1 Announce Type: cross 
Abstract: Training a deep neural network using gradient-based methods necessitates the calculation of gradients at each level. However, using backpropagation or reverse mode differentiation, to calculate the gradients necessities significant memory consumption, rendering backpropagation an inefficient method for computing gradients. This paper focuses on analyzing the performance of the well-known Frank-Wolfe algorithm, a.k.a. conditional gradient algorithm by having access to the forward mode of automatic differentiation to compute gradients. We provide in-depth technical details that show the proposed Algorithm does converge to the optimal solution with a sub-linear rate of convergence by having access to the noisy estimate of the true gradient obtained in the forward mode of automated differentiation, referred to as the Projected Forward Gradient. In contrast, the standard Frank-Wolfe algorithm, when provided with access to the Projected Forward Gradient, fails to converge to the optimal solution. We demonstrate the convergence attributes of our proposed algorithms using a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12511v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Rostami, S. S. Kia</dc:creator>
    </item>
    <item>
      <title>Importance sampling for rare event tracking within the ensemble Kalman filtering framework</title>
      <link>https://arxiv.org/abs/2403.12793</link>
      <description>arXiv:2403.12793v1 Announce Type: cross 
Abstract: In this work we employ importance sampling (IS) techniques to track a small over-threshold probability of a running maximum associated with the solution of a stochastic differential equation (SDE) within the framework of ensemble Kalman filtering (EnKF). Between two observation times of the EnKF, we propose to use IS with respect to the initial condition of the SDE, IS with respect to the Wiener process via a stochastic optimal control formulation, and combined IS with respect to both initial condition and Wiener process. Both IS strategies require the approximation of the solution of Kolmogorov Backward equation (KBE) with boundary conditions. In multidimensional settings, we employ a Markovian projection dimension reduction technique to obtain an approximation of the solution of the KBE by just solving a one dimensional PDE. The proposed ideas are tested on two illustrative examples: Double Well SDE and Langevin dynamics, and showcase a significant variance reduction compared to the standard Monte Carlo method and another sampling-based IS technique, namely, multilevel cross entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12793v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadhir Ben Rached, Erik von Schwerin, Gaukhar Shaimerdenova, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Introducing Combi-Stations in Robotic Mobile Fulfilment Systems: A Queueing-Theory-Based Efficiency Analysis</title>
      <link>https://arxiv.org/abs/2403.12798</link>
      <description>arXiv:2403.12798v1 Announce Type: cross 
Abstract: In the era of digital commerce, the surge in online shopping and the expectation for rapid delivery have placed unprecedented demands on warehouse operations. The traditional method of order fulfilment, where human order pickers traverse large storage areas to pick items, has become a bottleneck, consuming valuable time and resources. Robotic Mobile Fulfilment Systems (RMFS) offer a solution by using robots to transport storage racks directly to human-operated picking stations, eliminating the need for pickers to travel. This paper introduces combi-stations, a novel type of station that enables both item picking and replenishment, as opposed to traditional separate stations. We analyse the efficiency of combi-stations using queueing theory and demonstrate their potential to streamline warehouse operations. Our results suggest that combi-stations can reduce the number of robots required for stability and significantly reduce order turnover time, indicating a promising direction for future warehouse automation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12798v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lin Xie, Sonja Otten</dc:creator>
    </item>
    <item>
      <title>Kinetic-type Mean Field Games with Non-separable Local Hamiltonians</title>
      <link>https://arxiv.org/abs/2403.12829</link>
      <description>arXiv:2403.12829v1 Announce Type: cross 
Abstract: We prove well-posedness of a class of kinetic-type Mean Field Games, which typically arise when agents control their acceleration. Such systems include independent variables representing the spatial position as well as velocity. We consider non-separable Hamiltonians without any structural conditions, which depend locally on the density variable. Our analysis is based on two main ingredients: an energy method for the forward-backward system in Sobolev spaces, on the one hand and on a suitable vector field method to control derivatives with respect to the velocity variable, on the other hand. The careful combination of these two techniques reveals interesting phenomena applicable for Mean Field Games involving general classes of drift-diffusion operators and nonlinearities. While many prior existence theories for general Mean Field Games systems take the final datum function to be smoothing, we can allow this function to be non-smoothing, i.e. also depending locally on the final measure. Our well-posedness results hold under an appropriate smallness condition, assumed jointly on the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12829v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David M. Ambrose, Megan Griffin-Pickering, Alp\'ar R. M\'esz\'aros</dc:creator>
    </item>
    <item>
      <title>Understanding the training of infinitely deep and wide ResNets with Conditional Optimal Transport</title>
      <link>https://arxiv.org/abs/2403.12887</link>
      <description>arXiv:2403.12887v1 Announce Type: cross 
Abstract: We study the convergence of gradient flow for the training of deep neural networks. If Residual Neural Networks are a popular example of very deep architectures, their training constitutes a challenging optimization problem due notably to the non-convexity and the non-coercivity of the objective. Yet, in applications, those tasks are successfully solved by simple optimization algorithms such as gradient descent. To better understand this phenomenon, we focus here on a ``mean-field'' model of infinitely deep and arbitrarily wide ResNet, parameterized by probability measures over the product set of layers and parameters and with constant marginal on the set of layers. Indeed, in the case of shallow neural networks, mean field models have proven to benefit from simplified loss-landscapes and good theoretical guarantees when trained with gradient flow for the Wasserstein metric on the set of probability measures. Motivated by this approach, we propose to train our model with gradient flow w.r.t. the conditional Optimal Transport distance: a restriction of the classical Wasserstein distance which enforces our marginal condition. Relying on the theory of gradient flows in metric spaces we first show the well-posedness of the gradient flow equation and its consistency with the training of ResNets at finite width. Performing a local Polyak-\L{}ojasiewicz analysis, we then show convergence of the gradient flow for well-chosen initializations: if the number of features is finite but sufficiently large and the risk is sufficiently small at initialization, the gradient flow converges towards a global minimizer. This is the first result of this type for infinitely deep and arbitrarily wide ResNets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12887v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Barboni (ENS-PSL), Gabriel Peyr\'e (CNRS,ENS-PSL), Fran\c{c}ois-Xavier Vialard (LIGM)</dc:creator>
    </item>
    <item>
      <title>Riemannian Stochastic Gradient Method for Nested Composition Optimization</title>
      <link>https://arxiv.org/abs/2207.09350</link>
      <description>arXiv:2207.09350v2 Announce Type: replace 
Abstract: This work considers optimization of composition of functions in a nested form over Riemannian manifolds where each function contains an expectation. This type of problems is gaining popularity in applications such as policy evaluation in reinforcement learning or model customization in meta-learning. The standard Riemannian stochastic gradient methods for non-compositional optimization cannot be directly applied as stochastic approximation of inner functions create bias in the gradients of the outer functions. For two-level composition optimization, we present a Riemannian Stochastic Composition Gradient Descent (R-SCGD) method that finds an approximate stationary point, with expected squared Riemannian gradient smaller than $\epsilon$, in $O(\epsilon^{-2})$ calls to the stochastic gradient oracle of the outer function and stochastic function and gradient oracles of the inner function. Furthermore, we generalize the R-SCGD algorithms for problems with multi-level nested compositional structures, with the same complexity of $O(\epsilon^{-2})$ for the first-order stochastic oracle. Finally, the performance of the R-SCGD method is numerically evaluated over a policy evaluation problem in reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.09350v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dewei Zhang, Sam Davanloo Tajbakhsh</dc:creator>
    </item>
    <item>
      <title>On convergence of a $q$-random coordinate constrained algorithm for non-convex problems</title>
      <link>https://arxiv.org/abs/2210.09665</link>
      <description>arXiv:2210.09665v4 Announce Type: replace 
Abstract: We propose a random coordinate descent algorithm for optimizing a non-convex objective function subject to one linear constraint and simple bounds on the variables. Although it is common use to update only two random coordinates simultaneously in each iteration of a coordinate descent algorithm, our algorithm allows updating arbitrary number of coordinates. We provide a proof of convergence of the algorithm. The convergence rate of the algorithm improves when we update more coordinates per iteration. Numerical experiments on large scale instances of different optimization problems show the benefit of updating many coordinates simultaneously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.09665v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Ghaffari-Hadigheh, Lennart Sinjorgo, Renata Sotirov</dc:creator>
    </item>
    <item>
      <title>Mean-field neural networks-based algorithms for McKean-Vlasov control problems *</title>
      <link>https://arxiv.org/abs/2212.11518</link>
      <description>arXiv:2212.11518v2 Announce Type: replace 
Abstract: This paper is devoted to the numerical resolution of McKean-Vlasov control problems via the class of mean-field neural networks introduced in our companion paper [25] in order to learn the solution on the Wasserstein space. We propose several algorithms either based on dynamic programming with control learning by policy or value iteration, or backward SDE from stochastic maximum principle with global or local loss functions. Extensive numerical results on different examples are presented to illustrate the accuracy of each of our eight algorithms. We discuss and compare the pros and cons of all the tested methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11518v2</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huy\^en Pham (UPD7, LPSM), Xavier Warin (EDF R\&amp;D, FiME Lab)</dc:creator>
    </item>
    <item>
      <title>Complexity of Geometric programming in the Turing model and application to nonnegative tensors</title>
      <link>https://arxiv.org/abs/2301.10637</link>
      <description>arXiv:2301.10637v2 Announce Type: replace 
Abstract: We consider a geometric programming problem consisting in minimizing a function given by the supremum of finitely many log-Laplace transforms of discrete nonnegative measures on a Euclidean space. Under a coerciveness assumption, we show that a $\varepsilon$-minimizer can be computed in a time that is polynomial in the input size and in $|\log\varepsilon|$. This is obtained by establishing bit-size estimates on approximate minimizers and by applying the ellipsoid method. We also derive polynomial iteration complexity bounds for the interior point method applied to the same class of problems. We deduce that the spectral radius of a partially symmetric, weakly irreducible nonnegative tensor can be approximated within $\varepsilon$ error in poly-time. For strongly irreducible tensors, we also show that the logarithm of the positive eigenvector is poly-time computable. Our results also yield that the the maximum of a nonnegative homogeneous $d$-form in the unit ball with respect to $d$-H\"older norm can be approximated in poly-time. In particular, the spectral radius of uniform weighted hypergraphs and some known upper bounds for the clique number of uniform hypergraphs are poly-time computable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10637v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shmuel Friedland, St\'ephane Gaubert</dc:creator>
    </item>
    <item>
      <title>Q-Learning for Continuous State and Action MDPs under Average Cost Criteria</title>
      <link>https://arxiv.org/abs/2308.07591</link>
      <description>arXiv:2308.07591v2 Announce Type: replace 
Abstract: For infinite-horizon average-cost criterion problems, there exist relatively few rigorous approximation and reinforcement learning results. In this paper, for such problems, we present several approximation and reinforcement learning results for Markov Decision Processes with standard Borel spaces. Toward this end, (i) we first provide a discretization based approximation method for fully observed Markov Decision Processes (MDPs) with continuous spaces under average cost criteria, and we provide error bounds for the approximations when the dynamics are only weakly continuous (for asymptotic convergence of errors as the grid sizes vanish) or Wasserstein continuous (with a rate in approximation as the grid sizes vanish) under certain ergodicity assumptions. In particular, we relax the total variation condition given in prior work to weak continuity as well as Wasserstein continuity conditions. (ii) We provide synchronous and asynchronous Q-learning algorithms for continuous spaces via quantization (where the quantized state is taken to be the actual state in corresponding Q-learning algorithms presented in the paper), and establish their convergence; for the former we utilize a span semi-norm approach and for the latter we use a direct contraction approach. (iii) We finally show that the convergence is to the optimal Q values of the finite approximate models constructed via quantization, which implies near optimality of the arrived solution. Our Q-learning convergence results and their convergence to near optimality are new for continuous spaces, and the proof method is new even for finite spaces, to our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07591v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Design of Coherent Passive Quantum Equalizers Using Robust Control Theory</title>
      <link>https://arxiv.org/abs/2308.15805</link>
      <description>arXiv:2308.15805v2 Announce Type: replace 
Abstract: The paper develops a methodology for the design of coherent equalizing filters for quantum communication channels. Given a linear quantum system model of a quantum communication channel, the aim is to obtain another quantum system which, when coupled with the original system, mitigates degrading effects of the environment. The main result of the paper is a systematic equalizer synthesis algorithm which relies on methods of state-space robust control design via semidefinite programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15805v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2024.111599</arxiv:DOI>
      <arxiv:journal_reference>Automatica, 163(111599), 2024</arxiv:journal_reference>
      <dc:creator>V. Ugrinovskii, M. R. James</dc:creator>
    </item>
    <item>
      <title>Hybrid Zonotope-Based Backward Reachability Analysis for Neural Feedback Systems With Nonlinear Plant Models</title>
      <link>https://arxiv.org/abs/2310.06921</link>
      <description>arXiv:2310.06921v3 Announce Type: replace 
Abstract: The increasing prevalence of neural networks in safety-critical control systems underscores the imperative need for rigorous methods to ensure the reliability and safety of these systems. This work introduces a novel approach employing hybrid zonotopes to compute the over-approximation of backward reachable sets for neural feedback systems with nonlinear plant models and general activation functions. Closed-form expressions as hybrid zonotopes are provided for the over-approximated backward reachable sets, and a refinement procedure is proposed to alleviate the potential conservatism of the approximation. Two numerical examples are provided to illustrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06921v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Zhang, Yuhao Zhang, Xiangru Xu</dc:creator>
    </item>
    <item>
      <title>Bi-Level-Based Inverse Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2311.02014</link>
      <description>arXiv:2311.02014v2 Announce Type: replace 
Abstract: In this paper, we propose a new algorithm to solve the Inverse Stochastic Optimal Control (ISOC) problem of the linear-quadratic sensorimotor (LQS) control model. The LQS model represents the current state-of-the-art in describing goal-directed human movements. The ISOC problem aims at determining the cost function and noise scaling matrices of the LQS model from measurement data since both parameter types influence the statistical moments predicted by the model and are unknown in practice. We prove global convergence for our new algorithm and at a numerical example, validate the theoretical assumptions of our method. By comprehensive simulations, the influence of the tuning parameters of our algorithm on convergence behavior and computation time is analyzed. The new algorithm computes ISOC solutions nearly 33 times faster than the single previously existing ISOC algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02014v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Karg, Manuel Hess, Balint Varga, S\"oren Hohmann</dc:creator>
    </item>
    <item>
      <title>On the quadratic convergence of Newton's method for Mean Field Games with non-separable Hamiltonian</title>
      <link>https://arxiv.org/abs/2311.05416</link>
      <description>arXiv:2311.05416v2 Announce Type: replace 
Abstract: We analyze asymptotic convergence properties of Newton's method for a class of evolutive Mean Field Games systems with non-separable Hamiltonian arising in mean field type models with congestion. We prove the well posedness of the Mean Field Game system with non-separable Hamiltonian and of the linear system giving the Newton iterations. Then, by forward induction and assuming that the initial guess is sufficiently close to the solution of problem, we show a quadratic rate of convergence for the approximation of the Mean Field Game system by Newton's method. We also consider the case of a nonlocal coupling, but with separable Hamiltonian, and we show a similar rate of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05416v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Camilli, Qing Tang</dc:creator>
    </item>
    <item>
      <title>On the Number of Degenerate Simplex Pivots</title>
      <link>https://arxiv.org/abs/2311.15799</link>
      <description>arXiv:2311.15799v2 Announce Type: replace 
Abstract: The simplex algorithm is one of the most popular algorithms to solve linear programs (LPs). Starting at an extreme point solution of an LP, it performs a sequence of basis exchanges (called pivots) that allows one to move to a better extreme point along an improving edge-direction of the underlying polyhedron. A key issue in the simplex algorithm's performance is degeneracy, which may lead to a (potentially long) sequence of basis exchanges which do not change the current extreme point solution. In this paper, we prove that it is always possible to limit the number of consecutive degenerate pivots that the simplex algorithm performs to $n-m-1$, where $n$ is the number of variables and $m$ is the number of equality constraints of a given LP in standard equality form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15799v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kirill Kukharenko, Laura Sanit\`a</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Hybrid Systems with Submersive Resets</title>
      <link>https://arxiv.org/abs/2401.14476</link>
      <description>arXiv:2401.14476v2 Announce Type: replace 
Abstract: Hybrid dynamical systems are systems which posses both continuous and discrete transitions. Assuming that the discrete transitions (resets) occur a finite number of times, the optimal control problem can be solved by gluing together the optimal arcs from the underlying continuous problem via the "Hamilton jump conditions." In most cases, it is assumed that the reset is a diffeomorphism (onto its image) and the corresponding Hamilton jump condition admits a unique solution. However, in many applications, the reset results in a drop in dimension and the corresponding Hamilton jump condition admits zero/infinitely many solutions. A geometric interpretation of this issue is explored in the case where the reset is a submersion (onto its image). Necessary conditions are presented for this case along with an accompanying numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14476v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Clark, Maria Oprea, Aden Shaw</dc:creator>
    </item>
    <item>
      <title>Tuning-Free Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2402.07793</link>
      <description>arXiv:2402.07793v2 Announce Type: replace 
Abstract: Large-scale machine learning problems make the cost of hyperparameter tuning ever more prohibitive. This creates a need for algorithms that can tune themselves on-the-fly. We formalize the notion of "tuning-free" algorithms that can match the performance of optimally-tuned optimization algorithms up to polylogarithmic factors given only loose hints on the relevant problem parameters. We consider in particular algorithms that can match optimally-tuned Stochastic Gradient Descent (SGD). When the domain of optimization is bounded, we show tuning-free matching of SGD is possible and achieved by several existing algorithms. We prove that for the task of minimizing a convex and smooth or Lipschitz function over an unbounded domain, tuning-free optimization is impossible. We discuss conditions under which tuning-free optimization is possible even over unbounded domains. In particular, we show that the recently proposed DoG and DoWG algorithms are tuning-free when the noise distribution is sufficiently well-behaved. For the task of finding a stationary point of a smooth and potentially nonconvex function, we give a variant of SGD that matches the best-known high-probability convergence rate for tuned SGD at only an additional polylogarithmic cost. However, we also give an impossibility result that shows no algorithm can hope to match the optimal expected convergence rate for tuned SGD with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07793v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Khaled, Chi Jin</dc:creator>
    </item>
    <item>
      <title>Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming</title>
      <link>https://arxiv.org/abs/2402.13224</link>
      <description>arXiv:2402.13224v3 Announce Type: replace 
Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach demonstrates robustness against early disconnections by considering a wider range of uncertainty scenarios for optimization. The algorithm prioritizing user satisfaction over electricity cost achieves a 20% and 36% improvement in two user satisfaction metrics compared to an industry-standard baseline. Additionally, the algorithm striking the best balance between cost and user satisfaction exhibits a mere 3% relative cost increase compared to the theoretically optimal baseline - for which the nonanticipativity constraint is relaxed - while attaining 94% and 84% of the user satisfaction performance in the two used satisfaction metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13224v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alban Puech, Tristan Rigaut, William Templier, Maud Tournoud</dc:creator>
    </item>
    <item>
      <title>Formalization of Complexity Analysis of the First-order Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2403.11437</link>
      <description>arXiv:2403.11437v2 Announce Type: replace 
Abstract: The convergence rate of various first-order optimization algorithms is a pivotal concern within the numerical optimization community, as it directly reflects the efficiency of these algorithms across different optimization problems. Our goal is making a significant step forward in the formal mathematical representation of optimization techniques using the Lean4 theorem prover. We first formalize the gradient for smooth functions and the subgradient for convex functions on a Hilbert space, laying the groundwork for the accurate formalization of algorithmic structures. Then, we extend our contribution by proving several properties of differentiable convex functions that have not yet been formalized in Mathlib. Finally, a comprehensive formalization of these algorithms is presented. These developments are not only noteworthy on their own but also serve as essential precursors to the formalization of a broader spectrum of numerical algorithms and their applications in machine learning as well as many other areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11437v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Li, Ziyu Wang, Wanyi He, Yuxuan Wu, Shengyang Xu, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Criterion of Internal Stability of Linear Formations</title>
      <link>https://arxiv.org/abs/2403.11605</link>
      <description>arXiv:2403.11605v2 Announce Type: replace 
Abstract: Necessary and sufficient conditions for the internal stability of formations whose dynamics are obtained is determined by linear differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11605v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. V. Lakeyev</dc:creator>
    </item>
    <item>
      <title>Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Stochastic Approach</title>
      <link>https://arxiv.org/abs/2210.12624</link>
      <description>arXiv:2210.12624v2 Announce Type: replace-cross 
Abstract: Machine learning problems with multiple objective functions appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimized jointly, sharing inductive bias between them. This problems are often tackled by the multi-objective optimization framework. However, existing stochastic multi-objective gradient methods and its variants (e.g., MGDA, PCGrad, CAGrad, etc.) all adopt a biased noisy gradient direction, which leads to degraded empirical performance. To this end, we develop a stochastic Multi-objective gradient Correction (MoCo) method for multi-objective optimization. The unique feature of our method is that it can guarantee convergence without increasing the batch size even in the non-convex setting. Simulations on multi-task supervised and reinforcement learning demonstrate the effectiveness of our method relative to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12624v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heshan Fernando, Han Shen, Miao Liu, Subhajit Chaudhury, Keerthiram Murugesan, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Optimal Robust Network Design: Formulations and Algorithms for Maximizing Algebraic Connectivity</title>
      <link>https://arxiv.org/abs/2304.08571</link>
      <description>arXiv:2304.08571v3 Announce Type: replace-cross 
Abstract: This paper focuses on designing edge-weighted networks, whose robustness is characterized by maximizing algebraic connectivity, or the second smallest eigenvalue of the Laplacian matrix. This problem is motivated by cooperative vehicle localization, where accurately estimating relative position measurements and establishing communication links are essential. We also examine an associated problem where every robot is limited by payload, budget, and communication to pick no more than a specified number of relative position measurements. The basic underlying formulation for these problems is nonlinear and is known to be NP-hard. Our approach formulates this problem as a Mixed Integer Semi-Definite Program (MISDP), later reformulated into a Mixed Integer Linear Program (MILP) for obtaining optimal solutions using cutting plane algorithms. We introduce a novel upper-bounding algorithm based on principal minor characterization of positive semi-definite matrices and discuss a degree-constrained lower bounding formulation inspired by robust network structures. In addition, we propose a maximum cost heuristic with low computational complexity to identify high-quality feasible solutions for instances involving up to one hundred nodes. We show extensive computational results corroborating our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08571v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neelkamal Somisetty, Harsha Nagarajan, Swaroop Darbha</dc:creator>
    </item>
    <item>
      <title>Adversarial Training Should Be Cast as a Non-Zero-Sum Game</title>
      <link>https://arxiv.org/abs/2306.11035</link>
      <description>arXiv:2306.11035v2 Announce Type: replace-cross 
Abstract: One prominent approach toward resolving the adversarial vulnerability of deep neural networks is the two-player zero-sum paradigm of adversarial training, in which predictors are trained against adversarially chosen perturbations of data. Despite the promise of this approach, algorithms based on this paradigm have not engendered sufficient levels of robustness and suffer from pathological behavior like robust overfitting. To understand this shortcoming, we first show that the commonly used surrogate-based relaxation used in adversarial training algorithms voids all guarantees on the robustness of trained classifiers. The identification of this pitfall informs a novel non-zero-sum bilevel formulation of adversarial training, wherein each player optimizes a different objective function. Our formulation yields a simple algorithmic framework that matches and in some cases outperforms state-of-the-art attacks, attains comparable levels of robustness to standard adversarial training algorithms, and does not suffer from robust overfitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.11035v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Robey, Fabian Latorre, George J. Pappas, Hamed Hassani, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>The Relative Gaussian Mechanism and its Application to Private Gradient Descent</title>
      <link>https://arxiv.org/abs/2308.15250</link>
      <description>arXiv:2308.15250v2 Announce Type: replace-cross 
Abstract: The Gaussian Mechanism (GM), which consists in adding Gaussian noise to a vector-valued query before releasing it, is a standard privacy protection mechanism. In particular, given that the query respects some L2 sensitivity property (the L2 distance between outputs on any two neighboring inputs is bounded), GM guarantees R\'enyi Differential Privacy (RDP). Unfortunately, precisely bounding the L2 sensitivity can be hard, thus leading to loose privacy bounds. In this work, we consider a Relative L2 sensitivity assumption, in which the bound on the distance between two query outputs may also depend on their norm. Leveraging this assumption, we introduce the Relative Gaussian Mechanism (RGM), in which the variance of the noise depends on the norm of the output. We prove tight bounds on the RDP parameters under relative L2 sensitivity, and characterize the privacy loss incurred by using output-dependent noise. In particular, we show that RGM naturally adapts to a latent variable that would control the norm of the output. Finally, we instantiate our framework to show tight guarantees for Private Gradient Descent, a problem that naturally fits our relative L2 sensitivity assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15250v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadrien Hendrikx, Paul Mangold, Aur\'elien Bellet</dc:creator>
    </item>
    <item>
      <title>A Fast and Provable Algorithm for Sparse Phase Retrieval</title>
      <link>https://arxiv.org/abs/2309.02046</link>
      <description>arXiv:2309.02046v2 Announce Type: replace-cross 
Abstract: We study the sparse phase retrieval problem, which seeks to recover a sparse signal from a limited set of magnitude-only measurements. In contrast to prevalent sparse phase retrieval algorithms that primarily use first-order methods, we propose an innovative second-order algorithm that employs a Newton-type method with hard thresholding. This algorithm overcomes the linear convergence limitations of first-order methods while preserving their hallmark per-iteration computational efficiency. We provide theoretical guarantees that our algorithm converges to the $s$-sparse ground truth signal $\mathbf{x}^{\natural} \in \mathbb{R}^n$ (up to a global sign) at a quadratic convergence rate after at most $O(\log (\Vert\mathbf{x}^{\natural} \Vert /x_{\min}^{\natural}))$ iterations, using $\Omega(s^2\log n)$ Gaussian random samples. Numerical experiments show that our algorithm achieves a significantly faster convergence rate than state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02046v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian-Feng Cai, Yu Long, Ruixue Wen, Jiaxi Ying</dc:creator>
    </item>
    <item>
      <title>Pointer Networks with Q-Learning for OP Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2311.02629</link>
      <description>arXiv:2311.02629v2 Announce Type: replace-cross 
Abstract: The Orienteering Problem (OP) presents a unique challenge in Combinatorial Optimization (CO), emphasized by its widespread use in logistics, delivery, and transportation planning. Given the NP-hard nature of OP, obtaining optimal solutions is inherently complex. While Pointer Networks (Ptr-Nets) have exhibited prowess in various combinatorial tasks, their performance in the context of OP, and duties requiring focus on future return or exploration, leaves room for improvement. Recognizing the potency combining Reinforcement Learning (RL) methods with sequence-to-sequence models, this research unveils the Pointer Q-Network (PQN). This method combines Ptr-Nets and Q-learning, which, thanks to its critic only nature, outstands in its capability of capturing relationships within an embedded graph, a fundamental requirement in order to effectively address the specific challenges presented by OP. We explore the architecture and functionality of the PQN system, while showcasing its theoretical and practical advantages in terms of efficiency for combinatorial optimization problems such as the Orienteering Problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02629v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Barro</dc:creator>
    </item>
    <item>
      <title>A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features</title>
      <link>https://arxiv.org/abs/2403.01046</link>
      <description>arXiv:2403.01046v2 Announce Type: replace-cross 
Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01046v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emi Zeger, Yifei Wang, Aaron Mishkin, Tolga Ergen, Emmanuel Cand\`es, Mert Pilanci</dc:creator>
    </item>
  </channel>
</rss>
