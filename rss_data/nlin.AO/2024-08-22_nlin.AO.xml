<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.AO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.AO</link>
    <description>nlin.AO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.AO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Aug 2024 04:02:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Self-Organization in Computation &amp; Chemistry: Return to AlChemy</title>
      <link>https://arxiv.org/abs/2408.12137</link>
      <description>arXiv:2408.12137v1 Announce Type: new 
Abstract: How do complex adaptive systems, such as life, emerge from simple constituent parts? In the 1990s Walter Fontana and Leo Buss proposed a novel modeling approach to this question, based on a formal model of computation known as $\lambda$ calculus. The model demonstrated how simple rules, embedded in a combinatorially large space of possibilities, could yield complex, dynamically stable organizations, reminiscent of biochemical reaction networks. Here, we revisit this classic model, called AlChemy, which has been understudied over the past thirty years. We reproduce the original results and study the robustness of those results using the greater computing resources available today. Our analysis reveals several unanticipated features of the system, demonstrating a surprising mix of dynamical robustness and fragility. Specifically, we find that complex, stable organizations emerge more frequently than previously expected, that these organizations are robust against collapse into trivial fixed-points, but that these stable organizations cannot be easily combined into higher order entities. We also study the role played by the random generators used in the model, characterizing the initial distribution of objects produced by two random expression generators, and their consequences on the results. Finally, we provide a constructive proof that shows how an extension of the model, based on typed $\lambda$ calculus, \textcolor{black}{could simulate transitions between arbitrary states in any possible chemical reaction network, thus indicating a concrete connection between AlChemy and chemical reaction networks}. We conclude with a discussion of possible applications of AlChemy to self-organization in modern programming languages and quantitative approaches to the origin of life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12137v1</guid>
      <category>nlin.AO</category>
      <category>cs.NE</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cole Mathis, Devansh Patel, Westley Weimer, Stephanie Forrest</dc:creator>
    </item>
    <item>
      <title>Synchronization in adaptive higher-order networks</title>
      <link>https://arxiv.org/abs/2408.12235</link>
      <description>arXiv:2408.12235v1 Announce Type: new 
Abstract: Many natural and human-made complex systems feature group interactions that adapt over time in response to their dynamic states. However, most of the existing adaptive network models fall short of capturing these group dynamics, as they focus solely on pairwise interactions. In this study, we employ adaptive higher-order networks to describe these systems by proposing a general framework incorporating both adaptivity and group interactions. We demonstrate that global synchronization can exist in those complex structures, and we provide the necessary conditions for the emergence of a stable synchronous state. Additionally, we analyzed some relevant settings, and we showed that the necessary condition is strongly related to the master stability equation, allowing to separate the dynamical and structural properties. We illustrate our theoretical findings through examples involving adaptive higher-order networks of coupled generalized Kuramoto oscillators with phase lag. We also show that the interplay of group interactions and adaptive connectivity results in the formation of stability regions that can induce transitions between synchronization and desynchronization</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12235v1</guid>
      <category>nlin.AO</category>
      <category>cond-mat.stat-mech</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Sayeed Anwar, S. Nirmala Jenifer, Paulsamy Muruganandam, Dibakar Ghosh, Timoteo Carletti</dc:creator>
    </item>
    <item>
      <title>Searching for long time scales without fine tuning</title>
      <link>https://arxiv.org/abs/2008.11674</link>
      <description>arXiv:2008.11674v3 Announce Type: replace-cross 
Abstract: Most of animal and human behavior occurs on time scales much longer than the response times of individual neurons. In many cases, it is plausible that these long time scales emerge from the recurrent dynamics of electrical activity in networks of neurons. In linear models, time scales are set by the eigenvalues of a dynamical matrix whose elements measure the strengths of synaptic connections between neurons. It is not clear to what extent these matrix elements need to be tuned in order to generate long time scales; in some cases, one needs not just a single long time scale but a whole range. Starting from the simplest case of random symmetric connections, we combine maximum entropy and random matrix theory methods to construct ensembles of networks, exploring the constraints required for long time scales to become generic. We argue that a single long time scale can emerge generically from realistic constraints, but a full spectrum of slow modes requires more tuning. Langevin dynamics that generates patterns of synaptic connections drawn from these ensembles involves a combination of Hebbian learning and activity-dependent synaptic scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.11674v3</guid>
      <category>physics.bio-ph</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaowen Chen, William Bialek</dc:creator>
    </item>
  </channel>
</rss>
