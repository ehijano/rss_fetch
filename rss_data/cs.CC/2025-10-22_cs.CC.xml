<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 01:45:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Homological Proof of $\mathbf{P} \neq \mathbf{NP}$: Computational Topology via Categorical Framework</title>
      <link>https://arxiv.org/abs/2510.17829</link>
      <description>arXiv:2510.17829v1 Announce Type: new 
Abstract: This paper establishes the separation of complexity classes $\mathbf{P}$ and $\mathbf{NP}$ through a novel homological algebraic approach grounded in category theory. We construct the computational category $\mathbf{Comp}$, embedding computational problems and reductions into a unified categorical framework. By developing computational homology theory, we associate to each problem $L$ a chain complex $C_{\bullet}(L)$ whose homology groups $H_n(L)$ capture topological invariants of computational processes. Our main result demonstrates that problems in $\mathbf{P}$ exhibit trivial computational homology ($H_n(L) = 0$ for all $n &gt; 0$), while $\mathbf{NP}$-complete problems such as SAT possess non-trivial homology ($H_1(\mathrm{SAT}) \neq 0$). This homological distinction provides the first rigorous proof of $\mathbf{P} \neq \mathbf{NP}$ using topological methods. The proof is formally verified in Lean 4, ensuring absolute mathematical rigor. Our work inaugurates computational topology as a new paradigm for complexity analysis, offering finer distinctions than traditional combinatorial approaches and establishing connections between structural complexity theory and homological invariants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17829v1</guid>
      <category>cs.CC</category>
      <category>math.AC</category>
      <category>math.CT</category>
      <category>math.RA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian-Gang Tang</dc:creator>
    </item>
    <item>
      <title>Undirected Multicast Network Coding Gaps via Locally Decodable Codes</title>
      <link>https://arxiv.org/abs/2510.18737</link>
      <description>arXiv:2510.18737v1 Announce Type: new 
Abstract: The network coding problem asks whether data throughput in a network can be increased using coding (compared to treating bits as commodities in a flow). While it is well-known that a network coding advantage exists in directed graphs, the situation in undirected graphs is much less understood -- in particular, despite significant effort, it is not even known whether network coding is helpful at all for unicast sessions.
  In this paper we study the multi-source multicast network coding problem in undirected graphs. There are $k$ sources broadcasting each to a subset of nodes in a graph of size $n$. The corresponding combinatorial problem is a version of the Steiner tree packing problem, and the network coding question asks whether the multicast coding rate exceeds the tree-packing rate.
  We give the first super-constant bound to this problem, demonstrating an example with a coding advantage of $\Omega(\log k)$. In terms of graph size, we obtain a lower bound of $2^{\tilde{\Omega}(\sqrt{\log \log n})}$. We also obtain an upper bound of $O(\log n)$ on the gap.
  Our main technical contribution is a new reduction that converts locally-decodable codes in the low-error regime into multicast coding instances. This gives rise to a new family of explicitly constructed graphs, which may have other applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18737v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Braverman, Zhongtian He</dc:creator>
    </item>
    <item>
      <title>A Simpler Exponential-Time Approximation Algorithm for MAX-k-SAT</title>
      <link>https://arxiv.org/abs/2510.18164</link>
      <description>arXiv:2510.18164v1 Announce Type: cross 
Abstract: We present an extremely simple polynomial-space exponential-time $(1-\varepsilon)$-approximation algorithm for MAX-k-SAT that is (slightly) faster than the previous known polynomial-space $(1-\varepsilon)$-approximation algorithms by Hirsch (Discrete Applied Mathematics, 2003) and Escoffier, Paschos and Tourniaire (Theoretical Computer Science, 2014). Our algorithm repeatedly samples an assignment uniformly at random until finding an assignment that satisfies a large enough fraction of clauses. Surprisingly, we can show the efficiency of this simpler approach by proving that in any instance of MAX-k-SAT (or more generally any instance of MAXCSP), an exponential number of assignments satisfy a fraction of clauses close to the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18164v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harry Buhrman, Sevag Gharibian, Zeph Landau, Fran\c{c}ois Le Gall, Norbert Schuch, Suguru Tamaki</dc:creator>
    </item>
    <item>
      <title>Coloring Graphs with Few Colors in the Streaming Model</title>
      <link>https://arxiv.org/abs/2510.18177</link>
      <description>arXiv:2510.18177v1 Announce Type: cross 
Abstract: We study graph coloring problems in the streaming model, where the goal is to process an $n$-vertex graph whose edges arrive in a stream, using a limited space that is smaller than the trivial $O(n^2)$ bound. While prior work has largely focused on coloring graphs with a large number of colors, we explore the opposite end of the spectrum: deciding whether the input graph can be colored using only a few, say, a constant number of colors. We are interested in each of the adversarial, random order, or dynamic streams.
  Our work lays the foundation for this new direction by establishing upper and lower bounds on space complexity of key variants of the problem. Some of our main results include:
  - Adversarial: for distinguishing between $q$- vs $2^{\Omega(q)}$-colorable graphs, lower bounds of $n^{2-o(1)}$ space for $q$ up to $(\log{n})^{1/2-o(1)}$, and $n^{1+\Omega(1/\log\log{n})}$ space for $q$ further up to $(\log{n})^{1-o(1)}$.
  - Random order: for distinguishing between $q$- vs $q^t$-colorable graphs for $q,t \geq 2$, an upper bound of $\tilde{O}(n^{1+1/t})$ space. Specifically, distinguishing between $q$-colorable graphs vs ones that are not even poly$(q)$-colorable can be done in $n^{1+o(1)}$ space unlike in adversarial streams. Although, distinguishing between $q$-colorable vs $\Omega(q^2)$-colorable graphs requires $\Omega(n^2)$ space even in random order streams for constant $q$.
  - Dynamic: for distinguishing between $q$- vs $q \cdot t$-colorable graphs for any $q \geq 3$ and $t \geq 1$, nearly optimal upper and lower bounds of $\tilde{\Theta}(n^2/t^2)$ space.
  We develop several new technical tools along the way: cluster packing graphs, a generalization of Ruzsa-Szemer\'edi graphs; a player elimination framework based on cluster packing graphs; and new edge and vertex sampling lemmas tailored to graph coloring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18177v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Janani Sundaresan, Helia Yazdanyar</dc:creator>
    </item>
    <item>
      <title>Predicative Ordinal Recursion on the Constructive Veblen Hierarchy</title>
      <link>https://arxiv.org/abs/2510.18497</link>
      <description>arXiv:2510.18497v1 Announce Type: cross 
Abstract: Inspired by Leivant's work on absolute predicativism, Bellantoni and Cook in 1992 introduced a structurally restricted form of recursion called predicative recursion. Using this recursion scheme on the inductive structures of natural numbers and binary strings, they provide a structural and machine-independent characterization of the classes of linear-space and polynomial-time computable functions, respectively. This recursion scheme can be applied to any well-founded or inductive structure, and its underlying principle, predicativization, extends naturally to other computational frameworks, such as higher-order functionals and nested recursion.
  In this paper, we initiate a systematic project to gauge the computational power of predicative recursion on arbitrary well-founded structures. As a natural measuring stick for well-foundedness, we use constructive ordinals. More precisely, for any downset $\mathsf{A}$ of constructive ordinals, we define a class $\mathrm{PredR}_{\mathsf{A}}$ of predicative ordinal recursive functions that are permitted to employ a suitable form of predicative recursion on the ordinals in $\mathsf{A}$. We focus on the case that $\mathsf{A}$ is a downset of constructive ordinals below ${\phi}_{{\omega}}({0}) = \bigcup_{k=0}^{\infty} {\phi}_k({0})$, where $\{{\phi}_k\}_{k=0}^{\infty}$ are the functions in the Veblen hierarchy with finite index. We give a complete classification of $\mathrm{PredR}_{\mathsf{A}}$ -- for those downsets that contain at least one infinite ordinal -- in terms of the Grzegorczyk hierarchy $\{\mathcal{E}_k\}_{k=2}^{\omega}$. In this way, we extend Bellantoni-Cook's characterization of $\mathcal{E}_2$ (the class of linear-space computable functions) to obtain a machine-independent and structural characterization of the entire Grzegorczyk hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18497v1</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirhossein Akbar Tabatabai, Vitor Greati, Revantha Ramanayake</dc:creator>
    </item>
    <item>
      <title>On Efficient Computation of DiRe Committees</title>
      <link>https://arxiv.org/abs/2402.19365</link>
      <description>arXiv:2402.19365v2 Announce Type: replace 
Abstract: Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size ${at~most}$ two and a diversity constraint that stipulates the selection of ${at~least}$ one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving ${at~most}$ two candidates and a representation constraint that stipulates the selection of ${at~least}$ one candidate from each population who has a non-null set of approved candidates.
  The DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the minimum vertex cover problem on unweighted undirected graphs) concerns the determination of the smallest size committee that satisfies the given constraints. Here, for this problem, we propose an algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization. We prove the algorithm terminates in polynomial-time. We conjecture the algorithm is an unconditional deterministic polynomial-time algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19365v2</guid>
      <category>cs.CC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kunal Relia</dc:creator>
    </item>
    <item>
      <title>Efficient derandomization of differentially private counting queries</title>
      <link>https://arxiv.org/abs/2510.16959</link>
      <description>arXiv:2510.16959v2 Announce Type: replace-cross 
Abstract: Differential privacy for the 2020 census required an estimated 90 terabytes of randomness [GL20], an amount which may be prohibitively expensive or entirely infeasible to generate. Motivated by these practical concerns, [CSV25] initiated the study of the randomness complexity of differential privacy, and in particular, the randomness complexity of $d$ counting queries. This is the task of outputting the number of entries in a dataset that satisfy predicates $\mathcal{P}_1, \dots, \mathcal{P}_d$ respectively. They showed the rather surprising fact that though any reasonably accurate, $\varepsilon$-differentially private mechanism for one counting query requires $1-O(\varepsilon)$ bits of randomness in expectation, there exists a fairly accurate mechanism for $d$ counting queries which requires only $O(\log d)$ bits of randomness in expectation.
  The mechanism of [CSV25] is inefficient (not polynomial time) and relies on a combinatorial object known as rounding schemes. Here, we give a polynomial time mechanism which achieves nearly the same randomness complexity versus accuracy tradeoff as that of [CSV25]. Our construction is based on the following simple observation: after a randomized shift of the answer to each counting query, the answer to many counting queries remains the same regardless of whether we add noise to that coordinate or not. This allows us to forgo the step of adding noise to the result of many counting queries. Our mechanism does not make use of rounding schemes. Therefore, it provides a different -- and, in our opinion, clearer -- insight into the origins of the randomness savings that can be obtained by batching $d$ counting queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16959v2</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surendra Ghentiyala</dc:creator>
    </item>
  </channel>
</rss>
