<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Feb 2025 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Kernel Estimation for Nonlinear Dynamics</title>
      <link>https://arxiv.org/abs/2502.18634</link>
      <description>arXiv:2502.18634v1 Announce Type: new 
Abstract: Many scientific problems involve data exhibiting both temporal and cross-sectional dependencies. While linear dependencies have been extensively studied, the theoretical analysis of regression estimators under nonlinear dependencies remains scarce. This work studies a kernel-based estimation procedure for nonlinear dynamics within the reproducing kernel Hilbert space framework, focusing on nonlinear vector autoregressive models. We derive nonasymptotic probabilistic bounds on the deviation between a regularized kernel estimator and the nonlinear regression function. A key technical contribution is a concentration bound for quadratic forms of stochastic matrices in the presence of dependent data, which is of independent interest. Additionally, we characterize conditions on multivariate kernels that guarantee optimal convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18634v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marie-Christine D\"uker, Adam Waterbury</dc:creator>
    </item>
    <item>
      <title>A Matsuoka-Based GARMA Model for Hydrological Forecasting: Theory, Estimation, and Applications</title>
      <link>https://arxiv.org/abs/2502.18645</link>
      <description>arXiv:2502.18645v1 Announce Type: cross 
Abstract: Time series in natural sciences, such as hydrology and climatology, and other environmental applications, often consist of continuous observations constrained to the unit interval (0,1). Traditional Gaussian-based models fail to capture these bounds, requiring more flexible approaches. This paper introduces the Matsuoka Autoregressive Moving Average (MARMA) model, extending the GARMA framework by assuming a Matsuoka-distributed random component taking values in (0,1) and an ARMA-like systematic structure allowing for random time-dependent covariates. Parameter estimation is performed via partial maximum likelihood (PMLE), for which we present the asymptotic theory. It enables statistical inference, including confidence intervals and model selection. To construct prediction intervals, we propose a novel bootstrap-based method that accounts for dependence structure uncertainty. A comprehensive Monte Carlo simulation study assesses the finite sample performance of the proposed methodologies, while an application to forecasting the useful water volume of the Guarapiranga Reservoir in Brazil showcases their practical usefulness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18645v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guilherme Pumi, Danilo Hiroshi Matsuoka, Taiane Schaedler Prass, Bruna Gregory Palm</dc:creator>
    </item>
    <item>
      <title>Set and functional prediction: randomness, exchangeability, and conformal</title>
      <link>https://arxiv.org/abs/2502.19254</link>
      <description>arXiv:2502.19254v1 Announce Type: cross 
Abstract: This paper continues the study of the efficiency of conformal prediction as compared with more general randomness prediction and exchangeability prediction. It does not restrict itself to the case of classification, and our results will also be applicable to the case of regression. The price to pay is that efficiency will be attained only on average, albeit with respect to a wide range of probability measures on the label space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19254v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Vovk</dc:creator>
    </item>
    <item>
      <title>Deep Regression for Repeated Measurements</title>
      <link>https://arxiv.org/abs/2302.13908</link>
      <description>arXiv:2302.13908v2 Announce Type: replace 
Abstract: Nonparametric mean function regression with repeated measurements serves as a cornerstone for many statistical branches, such as longitudinal/panel/functional data analysis. In this work, we investigate this problem using fully connected deep neural network (DNN) estimators with flexible shapes. A novel theoretical framework allowing arbitrary sampling frequency is established by adopting empirical process techniques to tackle clustered dependence. We then consider the DNN estimators for H\"older target function and illustrate a key phenomenon, the phase transition in the convergence rate, inherent to repeated measurements and its connection to the curse of dimensionality. Furthermore, we study several examples with low intrinsic dimensions, including the hierarchical composition model, low-dimensional support set and anisotropic H\"older smoothness. We also obtain new approximation results and matching lower bounds to demonstrate the adaptivity of the DNN estimators for circumventing the curse of dimensionality. Simulations and real data examples are provided to support our theoretical findings and practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13908v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/01621459.2025.2458344</arxiv:DOI>
      <dc:creator>Shunxing Yan, Fang Yao, Hang Zhou</dc:creator>
    </item>
    <item>
      <title>On standardness and the non-estimability of certain functionals of a set</title>
      <link>https://arxiv.org/abs/2306.16295</link>
      <description>arXiv:2306.16295v2 Announce Type: replace 
Abstract: Standardness is a popular assumption in the literature on set estimation. It also appears in statistical approaches to topological data analysis, where it is common to assume that the data were sampled from a probability measure that satisfies the standard assumption. Relevant results in this field, such as rates of convergence and confidence sets, depend on the standardness parameter, which in practice may be unknown. In this paper, we review the notion of standardness and its connection to other geometrical restrictions. We prove the almost sure consistency of a plug-in type estimator for the so-called standardness constant, already studied in the literature. We propose a method to correct the bias of the plug-in estimator and corroborate our theoretical findings through a small simulation study. We also show that it is not possible to determine, based on a finite sample, whether a probability measure satisfies the standard assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16295v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Cholaquidis, Leonardo Moreno, Beatriz Pateiro-L\'opez</dc:creator>
    </item>
    <item>
      <title>Extremal correlation coefficient for functional data</title>
      <link>https://arxiv.org/abs/2405.17318</link>
      <description>arXiv:2405.17318v2 Announce Type: replace 
Abstract: We propose a coefficient that measures dependence in paired samples of functions. It has properties similar to the Pearson correlation, but differs in significant ways: 1) it is designed to measure dependence between curves, 2) it focuses only on extreme curves. The new coefficient is derived within the framework of regular variation in Banach spaces. A consistent estimator is proposed and justified by an asymptotic analysis and a simulation study. The usefulness of the new coefficient is illustrated on financial and and climate functional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17318v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihyun Kim, Piotr Kokoszka</dc:creator>
    </item>
    <item>
      <title>Anomaly Detection based on Markov Data: A Statistical Depth Approach</title>
      <link>https://arxiv.org/abs/2406.16759</link>
      <description>arXiv:2406.16759v4 Announce Type: replace 
Abstract: The purpose of this article is to extend the notion of statistical depth to the case of sample paths of a Markov chain. Initially introduced to define a center-outward ordering of points in the support of a multivariate distribution, depth functions permit to generalize the notions of quantiles and (signed) ranks for observations in $\mathbb{R}^d$ with $d&gt;1$, as well as statistical procedures based on such quantities. Here we develop a general theoretical framework for evaluating the depth of a Markov sample path and recovering it statistically from an estimate of its transition probability with (non-) asymptotic guarantees. We also detail some of its applications, focusing particularly on unsupervised anomaly detection. Beyond the theoretical analysis carried out, numerical experiments are displayed, providing empirical evidence of the relevance of the novel concept we introduce here to quantify the degree of abnormality of Markov paths of variable length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16759v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Fern\'andez, Stephan Cl\'emen\c{c}on</dc:creator>
    </item>
    <item>
      <title>Tail Index Estimation for Discrete Heavy-Tailed Distributions</title>
      <link>https://arxiv.org/abs/2407.05281</link>
      <description>arXiv:2407.05281v3 Announce Type: replace 
Abstract: It is the purpose of this paper to investigate the issue of estimating the regularity index $\beta&gt;0$ of a discrete heavy-tailed r.v. $S$, \textit{i.e.} a r.v. $S$ valued in $\mathbb{N}^*$ such that $\mathbb{P}(S&gt;n)=L(n)\cdot n^{-\beta}$ for all $n\geq 1$, where $L:\mathbb{R}^*_+\to \mathbb{R}_+$ is a slowly varying function. As a first go, we consider the situation where inference is based on independent copies $S_1,\; \ldots,\; S_n$ of the generic variable $S$. Just like the popular Hill estimator in the continuous heavy-tail situation, the estimator $\widehat{\beta}$ we propose can be derived by means of a suitable reformulation of the regularly varying condition, replacing $S$'s survivor function by its empirical counterpart. Under mild assumptions, a non-asymptotic bound for the deviation between $\widehat{\beta}$ and $\beta$ is established, as well as limit results (consistency and asymptotic normality). Beyond the i.i.d. case, the inference method proposed is extended to the estimation of the regularity index of a regenerative $\beta$-null recurrent Markov chain. Since the parameter $\beta$ can be then viewed as the tail index of the (regularly varying) distribution of the return time of the chain $X$ to any (pseudo-) regenerative set, in this case, the estimator is constructed from the successive regeneration times. Because the durations between consecutive regeneration times are asymptotically independent, we can prove that the consistency of the estimator promoted is preserved. In addition to the theoretical analysis carried out, simulation results provide empirical evidence of the relevance of the inference technique proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05281v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrice Bertail, Stephan Cl\'emen\c{c}on, Carlos Fern\'andez</dc:creator>
    </item>
    <item>
      <title>The No-Underrun Sampler: A Locally-Adaptive, Gradient-Free MCMC Method</title>
      <link>https://arxiv.org/abs/2501.18548</link>
      <description>arXiv:2501.18548v2 Announce Type: replace 
Abstract: In this work, we introduce the No-Underrun Sampler (NURS), a locally-adaptive, gradient-free Markov chain Monte Carlo method that blends ideas from Hit-and-Run and the No-U-Turn Sampler. NURS dynamically adapts to the local scale of the target distribution without requiring gradient evaluations, making it especially suitable for applications where gradients are unavailable or costly. We establish key theoretical properties, including reversibility, formal connections to Hit-and-Run and Random Walk Metropolis, Wasserstein contraction comparable to Hit-and-Run in Gaussian targets, and bounds on the total variation distance between the transition kernels of Hit-and-Run and NURS. Empirical experiments, supported by theoretical insights, illustrate the ability of NURS to sample from Neal's funnel, a challenging multi-scale distribution from Bayesian hierarchical inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18548v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nawaf Bou-Rabee, Bob Carpenter, Sifan Liu, Stefan Oberd\"orster</dc:creator>
    </item>
    <item>
      <title>Consistency of heritability estimation from summary statistics in high-dimensional linear models</title>
      <link>https://arxiv.org/abs/2502.11144</link>
      <description>arXiv:2502.11144v2 Announce Type: replace 
Abstract: In Genome-Wide Association Studies (GWAS), heritability is defined as the fraction of variance of an outcome explained by a large number of genetic predictors in a high-dimensional polygenic linear model. This work studies the asymptotic properties of the most common estimator of heritability from summary statistics called linkage disequilibrium score (LDSC) regression, together with a simpler and closely related estimator called GWAS heritability (GWASH). These estimators are analyzed in their basic versions and under various modifications used in practice including weighting and standardization. We show that, with some variations, two conditions which we call weak dependence (WD) and bounded-kurtosis effects (BKE) are sufficient for consistency of both the basic LDSC with fixed intercept and GWASH estimators, for both Gaussian and non-Gaussian predictors. For Gaussian predictors it is shown that these conditions are also necessary for consistency of GWASH (with truncation) and simulations suggest that necessity holds too when the predictors are non-Gaussian. We also show that, with properly truncated weights, weighting does not change the consistency results, but standardization of the predictors and outcome, as done in practice, introduces bias in both LDSC and GWASH if the two essential conditions are violated. Finally, we show that, when population stratification is present, all the estimators considered are biased, and the bias is not remedied by using the LDSC regression estimator with free intercept, as originally suggested by the authors of that estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11144v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Azriel, Samuel Davenport, Armin Schwartzman</dc:creator>
    </item>
    <item>
      <title>Adaptive Smooth Non-Stationary Bandits</title>
      <link>https://arxiv.org/abs/2407.08654</link>
      <description>arXiv:2407.08654v2 Announce Type: replace-cross 
Abstract: We study a $K$-armed non-stationary bandit model where rewards change smoothly, as captured by H\"{o}lder class assumptions on rewards as functions of time. Such smooth changes are parametrized by a H\"{o}lder exponent $\beta$ and coefficient $\lambda$. While various sub-cases of this general model have been studied in isolation, we first establish the minimax dynamic regret rate generally for all $K,\beta,\lambda$. Next, we show this optimal dynamic regret can be attained adaptively, without knowledge of $\beta,\lambda$. To contrast, even with parameter knowledge, upper bounds were only previously known for limited regimes $\beta\leq 1$ and $\beta=2$ (Slivkins, 2014; Krishnamurthy and Gopalan, 2021; Manegueu et al., 2021; Jia et al.,2023). Thus, our work resolves open questions raised by these disparate threads of the literature.
  We also study the problem of attaining faster gap-dependent regret rates in non-stationary bandits. While such rates are long known to be impossible in general (Garivier and Moulines, 2011), we show that environments admitting a safe arm (Suk and Kpotufe, 2022) allow for much faster rates than the worst-case scaling with $\sqrt{T}$. While previous works in this direction focused on attaining the usual logarithmic regret bounds, as summed over stationary periods, our new gap-dependent rates reveal new optimistic regimes of non-stationarity where even the logarithmic bounds are pessimistic. We show our new gap-dependent rate is tight and that its achievability (i.e., as made possible by a safe arm) has a surprisingly simple and clean characterization within the smooth H\"{o}lder class model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08654v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joe Suk</dc:creator>
    </item>
    <item>
      <title>Low dimensional representation of multi-patient flow cytometry datasets using optimal transport for minimal residual disease detection in leukemia</title>
      <link>https://arxiv.org/abs/2407.17329</link>
      <description>arXiv:2407.17329v3 Announce Type: replace-cross 
Abstract: Representing and quantifying Minimal Residual Disease (MRD) in Acute Myeloid Leukemia (AML), a type of cancer that affects the blood and bone marrow, is essential in the prognosis and follow-up of AML patients. As traditional cytological analysis cannot detect leukemia cells below 5\%, the analysis of flow cytometry dataset is expected to provide more reliable results. In this paper, we explore statistical learning methods based on optimal transport (OT) to achieve a relevant low-dimensional representation of multi-patient flow cytometry measurements (FCM) datasets considered as high-dimensional probability distributions. Using the framework of OT, we justify the use of the K-means algorithm for dimensionality reduction of multiple large-scale point clouds through mean measure quantization by merging all the data into a single point cloud. After this quantization step, the visualization of the intra and inter-patients FCM variability is carried out by embedding low-dimensional quantized probability measures into a linear space using either Wasserstein Principal Component Analysis (PCA) through linearized OT or log-ratio PCA of compositional data. Using a publicly available FCM dataset and a FCM dataset from Bordeaux University Hospital, we demonstrate the benefits of our approach over the popular kernel mean embedding technique for statistical learning from multiple high-dimensional probability distributions. We also highlight the usefulness of our methodology for low-dimensional projection and clustering patient measurements according to their level of MRD in AML from FCM. In particular, our OT-based approach allows a relevant and informative two-dimensional representation of the results of the FlowSom algorithm, a state-of-the-art method for the detection of MRD in AML using multi-patient FCM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17329v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erell Gachon, J\'er\'emie Bigot, Elsa Cazelles, Audrey Bidet, Jean-Philippe Vial, Pierre-Yves Dumas, Aguirre Mimoun</dc:creator>
    </item>
    <item>
      <title>High-accuracy sampling from constrained spaces with the Metropolis-adjusted Preconditioned Langevin Algorithm</title>
      <link>https://arxiv.org/abs/2412.18701</link>
      <description>arXiv:2412.18701v3 Announce Type: replace-cross 
Abstract: In this work, we propose a first-order sampling method called the Metropolis-adjusted Preconditioned Langevin Algorithm for approximate sampling from a target distribution whose support is a proper convex subset of $\mathbb{R}^{d}$. Our proposed method is the result of applying a Metropolis-Hastings filter to the Markov chain formed by a single step of the preconditioned Langevin algorithm with a metric $\mathscr{G}$, and is motivated by the natural gradient descent algorithm for optimisation. We derive non-asymptotic upper bounds for the mixing time of this method for sampling from target distributions whose potentials are bounded relative to $\mathscr{G}$, and for exponential distributions restricted to the support. Our analysis suggests that if $\mathscr{G}$ satisfies stronger notions of self-concordance introduced in Kook and Vempala (2024), then these mixing time upper bounds have a strictly better dependence on the dimension than when is merely self-concordant. We also provide numerical experiments that demonstrates the practicality of our proposed method. Our method is a high-accuracy sampler due to the polylogarithmic dependence on the error tolerance in our mixing time upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18701v3</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishwak Srinivasan, Andre Wibisono, Ashia Wilson</dc:creator>
    </item>
  </channel>
</rss>
