<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 02:42:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Waiting for Dabo:A machine learning model for P4 college football coaching hires</title>
      <link>https://arxiv.org/abs/2511.14035</link>
      <description>arXiv:2511.14035v1 Announce Type: new 
Abstract: Using data on 103 recent P4 college football hires, we built a statistical model for predicting a coach's success at their new school. For each hire, we collected data about their background and experiences, the previous success as a head coach or coordinator and their success since hiring. Over 50 variables on these factors were recorded though we used 29 of these in building our predictive model. Our measure of success is based upon Bill Connelly's SP+ team ratings relative to the performance on the same metric of the school in the 15 year prior to their selection as head coach. Using a cross-validated regularized linear regression, we obtain a predictive model for coaching success. Among the important factors for predicting a successful hire are having been a previous college head coach, having won a prior conference championship as a head coach, leaving a job as an Offensive Coordinator, age and quality of the hiring school's team in the previous 15 years. While we do find these factors are important for the prediction of a successful coaching hire, the trends here are weak. With 66% accuracy, the model does identify coaching hires that will outperform team performance in the 15 years before the hire. However, no combination of these factors leads to high predictability of identifying a successful coaching hire. All of the data and code for this paper are available in a Github repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14035v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael Schuckers, Austin Hayes</dc:creator>
    </item>
    <item>
      <title>Model-Based Clustering of Football Event Sequences: A Marked Spatio-Temporal Point Process Mixture Approach</title>
      <link>https://arxiv.org/abs/2511.14297</link>
      <description>arXiv:2511.14297v1 Announce Type: new 
Abstract: We propose a novel mixture model for football event data that clusters entire possessions to reveal their temporal, sequential, and spatial structure. Each mixture component models possessions as marked spatio-temporal point processes: event types follow a finite Markov chain with an absorbing state for ball loss, event times follow a conditional Gamma process to account for dispersion, and spatial locations evolve via truncated Brownian motion. To aid interpretation, we derive summary indicators from model parameters capturing possession speed, number of events, and spatial dynamics. Parameters are estimated through maximum likelihood via Generalized Expectation-Maximization algorithm. Applied to StatsBomb data from 38 Ligue 1 matches (2020/2021), our approach uncovers distinct defensive possession patterns faced by Stade Rennais. Unlike previous approaches focusing on individual events, our mixture structure enables principled clustering of full possessions, supporting tactical analysis and the future development of realistic virtual training environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14297v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koffi Amezouwui (ENSAI), Brigitte Gelein (ENSAI), Matthieu Marbac (UBS Vannes), Anthony Sorel (UR2)</dc:creator>
    </item>
    <item>
      <title>Nonlinear Coherence for Vector Time Series: Defining Region-to-Region Functional Brain Connectivity</title>
      <link>https://arxiv.org/abs/2511.14417</link>
      <description>arXiv:2511.14417v1 Announce Type: new 
Abstract: Alterations in functional brain connectivity characterize neurodegenerative disorders such as Alzheimer's disease (AD) and frontotemporal dementia (FTD). As a non-invasive and cost-effective technique, electroencephalography (EEG) is gaining increasing attention for its potential to identify reliable biomarkers for early detection and differential diagnosis of AD and FTD. Considering the behavioral similarities of signals from adjacent EEG channels, we propose a new spectral dependence measure, the nonlinear vector coherence (NVC), to capture beyond-linear interactions between oscillations of two multivariate time series observed from distinct brain regions. This addresses the limitations of conventional channel-to-channel approaches and defines a more natural region-to-region connectivity framework in the frequency domain. As a result, the NVC measure offers a new approach to investigate dependence between brain regions, which then enables to identify altered functional connectivity dynamics associated with AD and FTD. We further introduce a rank-based inference procedure that enables fast and distribution-free estimation of the proposed measure, as well as a fully nonparametric test for spectral independence. The empirical performance of our proposed inference methodology is demonstrated through extensive numerical experiments. An application to resting-state EEG data reveals that our novel NVC measure uncovers distinct and diagnostically meaningful connectivity patterns which effectively discriminate healthy individuals from those with AD and FTD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14417v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Victor Redondo, Rapha\"el Huser, Hernando Ombao</dc:creator>
    </item>
    <item>
      <title>Darts Analysis</title>
      <link>https://arxiv.org/abs/2511.14537</link>
      <description>arXiv:2511.14537v1 Announce Type: new 
Abstract: In this paper we examine the effectiveness of five mathematical models used to predict the outcomes of amateur darts games. These models not only predict the outcomes at the start of the game, but also update their estimations as the game score changes. The models were trained and tested on a dataset consisting of games played by amateur players involving students, faculty, and staff at Roanoke College. The five models are: the null model, which is based only on the live scores, a logistic regression model, a basic simulation model, a time-adjusted simulation model, and a new variation of the Massey model which updates based on the current score. We evaluate these models using two approaches. First, we compare their Brier scores. Second, we conduct head-to-head comparisons in a betting game in which one model sets the betting odds while the other places bets. In both cases, model performance is assessed not only at the start of the game but also at the start of each round. Across both evaluation methods, the score-dependent Massey model performs the best. We conclude by illustrating how this score-dependent Massey model framework can be adapted to other competitive settings beyond darts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14537v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayham Makhamra, Yelyzaveta Satynska, Michael Weselcouch</dc:creator>
    </item>
    <item>
      <title>Decoupling Urban Food Accessibility Resilience during Disasters through Time-Series Analysis of Human Mobility and Power Outages</title>
      <link>https://arxiv.org/abs/2511.14706</link>
      <description>arXiv:2511.14706v2 Announce Type: new 
Abstract: Disaster-induced power outages create cascading disruptions across urban lifelines, yet the timed coupling between grid failure and essential service access remains poorly quantified. Focusing on Hurricane Beryl in Houston (2024), this study integrates approximately 173000 15-minute outage records with over 1.25 million visits to 3187 food facilities to quantify how infrastructure performance and human access co-evolve. We construct daily indices for outage characteristics (intensity, duration) and food access metrics (redundancy, frequency, proximity), estimate cross-system lags through lagged correlations over zero to seven days, and identify recovery patterns using DTW k-means clustering. Overlaying these clusters yields compound power-access typologies and enables facility-level criticality screening. The analysis reveals a consistent two-day lag: food access reaches its nadir on July 8 at landfall while outage severity peaks around July 10, with negative correlations strongest at a two-day lag and losing significance by day four. We identify four compound typologies from high/low outage crossed with high/low access disruption levels. Road network sparsity, more than income, determines the depth and persistence of access loss. Through this analysis, we enumerate 294 critical food facilities in the study area requiring targeted continuity measures including backup power, microgrids, and feeder prioritization. The novelty lies in measuring interdependency at daily operational resolution while bridging scales from communities to individual facilities, converting dynamic coupling patterns into actionable interventions for phase-sensitive restoration and equity-aware preparedness. The framework is transferable to other lifelines and hazards, offering a generalizable template for diagnosing and mitigating cascading effects on community access during disaster recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14706v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Junwei Ma, Bo Li, Xiangpeng Li, Ali Mostafavi</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimal Phase II design with optimised stopping boundaries and response-adaptive randomisation</title>
      <link>https://arxiv.org/abs/2511.14714</link>
      <description>arXiv:2511.14714v1 Announce Type: new 
Abstract: The Bayesian Optimal Phase II (BOP2) framework is a flexible trial design that can naturally facilitate complex adaptations due to its Bayesian setting. BOP2 uses equal randomisation and equally placed interim analyses in its design, but it is unclear whether these give the best operating characteristics. By incorporating Bayesian Response-Adaptive Randomisation (BRAR) and optimal interim analysis placement, we show that allocation to the best treatment and expected sample size can be improved with minimal impact on power. We discuss recommendations on implementing these adaptations, using simulation-based evidence, to give practical advice to practitioners. Reproducible code for the simulations is freely provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14714v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor Fitchett, Ayon Mukherjee, Sof\'ia S. Villar, David S. Robertson</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Density Shaping Model Predictive Gust Load Alleviation Control of a Compliant Wing Subjected to Atmospheric Turbulence</title>
      <link>https://arxiv.org/abs/2511.13745</link>
      <description>arXiv:2511.13745v1 Announce Type: cross 
Abstract: This study presents a novel deep learning approach aimed at enhancing stochastic Gust Load Alleviation (GLA) specifically for compliant wings. The approach incorporates the concept of smooth wing camber variation, where the camber of the wing's chord is actively adjusted during flight using a control signal to achieve the desired aerodynamic loading. The proposed method employs a deep learning-based model predictive controller designed for probability density shaping. This controller effectively solves the probability density evolution equation through a custom Physics-Informed Neural Network (PINN) and utilizes Automatic Differentiation for Model Predictive Control (MPC) optimization. Comprehensive numerical simulations were conducted on a compliant wing (CW) model, evaluating performance of the proposed approach against stochastic gust profiles. The evaluation involved stochastic aerodynamic loads generated from Band-Limited White Noise (BLWN) and Dryden gust models. The evaluation were conducted for two distinct Compliant Chord Fractions (CCF). The results demonstrate the effectiveness of the proposed probability density shaping model predictive control in alleviating stochastic gust load and reducing wing tip deflection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13745v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ast.2025.111214</arxiv:DOI>
      <arxiv:journal_reference>Pourtakdoust, S.H., &amp; Khodabakhsh, A.H. (2025). A deep learning density shaping model predictive gust load alleviation control of a compliant wing subjected to atmospheric turbulence. Aerospace Science and Technology, 111214</arxiv:journal_reference>
      <dc:creator>Seid H. Pourtakdoust, Amir H. Khodabakhsh</dc:creator>
    </item>
    <item>
      <title>Market competition and poverty dynamics: Short and long run effects across financial development levels</title>
      <link>https://arxiv.org/abs/2511.13875</link>
      <description>arXiv:2511.13875v1 Announce Type: cross 
Abstract: This paper investigates how market competition influences poverty dynamics using a functional econometric framework that captures both contemporaneous and lagged effects. Using annual data for 48 countries from 1991-2017, we estimate function-on-function regressions linking poverty headcount ratios to market concentration and other macroeconomic indicators. The results show that, based on the entire sample, stronger competition initially increased poverty during structural adjustment phases, but its adverse impact weakened after 2010 as economies adapted and efficiency gains emerged. The estimated bivariate surfaces reveal that the effect of competition on poverty often persists over multiple years (around 5 years), highlighting the importance of intertemporal transmission. Then, functional clustering based on market capitalization (MCAP) uncovers strong heterogeneity: pro-poor 5-years lagged effect of competition in low- and medium-MCAP economies, while it remains insignificant to weakly negative in high-MCAP countries. Overall, the findings underscore the value of functional data methods in uncovering evolving and lag-dependent poverty-competition linkages that static panel models fail to capture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13875v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Chaouch, Thanasis Stengos</dc:creator>
    </item>
    <item>
      <title>Uncertainty-Calibrated Prediction of Randomly-Timed Biomarker Trajectories with Conformal Bands</title>
      <link>https://arxiv.org/abs/2511.13911</link>
      <description>arXiv:2511.13911v1 Announce Type: cross 
Abstract: Despite recent progress in predicting biomarker trajectories from real clinical data, uncertainty in the predictions poses high-stakes risks (e.g., misdiagnosis) that limit their clinical deployment. To enable safe and reliable use of such predictions in healthcare, we introduce a conformal method for uncertainty-calibrated prediction of biomarker trajectories resulting from randomly-timed clinical visits of patients. Our approach extends conformal prediction to the setting of randomly-timed trajectories via a novel nonconformity score that produces prediction bands guaranteed to cover the unknown biomarker trajectories with a user-prescribed probability. We apply our method across a wide range of standard and state-of-the-art predictors for two well-established brain biomarkers of Alzheimer's disease, using neuroimaging data from real clinical studies. We observe that our conformal prediction bands consistently achieve the desired coverage, while also being tighter than baseline prediction bands. To further account for population heterogeneity, we develop group-conditional conformal bands and test their coverage guarantees across various demographic and clinically relevant subpopulations. Moreover, we demonstrate the clinical utility of our conformal bands in identifying subjects at high risk of progression to Alzheimer's disease. Specifically, we introduce an uncertainty-calibrated risk score that enables the identification of 17.5% more high-risk subjects compared to standard risk scores, highlighting the value of uncertainty calibration in real-world clinical decision making. Our code is available at github.com/vatass/ConformalBiomarkerTrajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13911v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasiliki Tassopoulou, Charis Stamouli, Haochang Shou, George J. Pappas, Christos Davatzikos</dc:creator>
    </item>
    <item>
      <title>Making Evidence Actionable in Adaptive Learning</title>
      <link>https://arxiv.org/abs/2511.14052</link>
      <description>arXiv:2511.14052v1 Announce Type: cross 
Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14052v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Mehrabi, Jason W. Morphew, Breejha Quezada, N. Sanjay Rebello</dc:creator>
    </item>
    <item>
      <title>State-Space Representation of INGARCH Models and Their Application in Insurance</title>
      <link>https://arxiv.org/abs/2511.14091</link>
      <description>arXiv:2511.14091v1 Announce Type: cross 
Abstract: Integer-valued generalized autoregressive conditional heteroskedastic (INGARCH) models are a popular framework for modeling serial dependence in count time-series. While convenient for modeling, prediction, and estimation, INGARCH models lack a clear theoretical justification for the evolution step. This limitation not only makes interpretation difficult and complicates the inclusion of covariates, but can also make the handling of missing data computationally burdensome. Consequently, applying such models in an insurance context, where covariates and missing observations are common, can be challenging. In this paper, we first introduce the marginalized state-space model (M-SSM), defined solely through the marginal distribution of the observations, and show that INGARCH models arise as special cases of this framework. The M-SSM formulation facilitates the natural incorporation of covariates and missing data mechanisms, and this representation in turn provides a coherent way to incorporate these elements within the INGARCH model as well. We then demonstrate that an M-SSM can admit an observation-driven state-space model (O-SSM) representation when suitable assumptions are imposed on the evolution of its conditional mean. This lifting from an M-SSM to an O-SSM provides a natural setting for establishing weak stationarity, even in the presence of heterogeneity and missing observations. The proposed ideas are illustrated through the Poisson and the Negative-Binomial INGARCH(1,1) models, highlighting their applicability in predictive analysis for insurance data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14091v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jae Youn Ahn, Hong Beng Lim, Mario V. W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Covariate Adjustment for the Win Odds: Application to Cardiovascular Outcomes Trials</title>
      <link>https://arxiv.org/abs/2511.14292</link>
      <description>arXiv:2511.14292v1 Announce Type: cross 
Abstract: Covariate adjustment can enhance precision and power in clinical trials, yet its application to the win odds remains unclear. The win odds is an extension of the win ratio that includes ties. In their original form, both methods rely on comparing each individual from the treatment group to each individual from the control group in pairwise manner, and count the number of wins, losses, and ties from these pairwise comparisons. A priori, it is not clear how covariate adjustment can be implemented for the win odds. To address this, we establish a connection between the win odds and the marginal probabilistic index, a measure for which covariate adjustment theory is well-developed. Using this connection, we show how covariate adjustment for the win odds is possible, leading to potentially more precise estimators and larger power as compared to the unadjusted win odds. We present the underlying theory for covariate adjustment for the win odds in an accessible way and apply the method on synthetic data based on the CANTOS trial (ClinicalTrials.gov identifier: NCT01327846) characteristics and on simulated data to study the operating characteristics of the method. We observe that there is indeed a potential gain in power when the win odds are adjusted for baseline covariates if the baseline covariates are prognostic for the outcome. This comes at the cost of a slight inflation of the type I error rate for small sample sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14292v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyrill Scheidegger, Simon Wandel, Tobias M\"utze</dc:creator>
    </item>
    <item>
      <title>Uncertainty assessment of spatial dynamic microsimulations</title>
      <link>https://arxiv.org/abs/2511.14294</link>
      <description>arXiv:2511.14294v1 Announce Type: cross 
Abstract: Spatial dynamic microsimulations probabilistically project geographically referenced units with individual characteristics over time. Like any projection method, their outcomes are inherently uncertain and sensitive to multiple factors. However, such factors are rarely addressed. Applying variance-based sensitivity analysis to both direct and indirect effects within the employment module of the MikroSim model for Germany, we show that commonly considered sources of uncertainty, namely coefficient and parameter uncertainty, are less influential than qualitative modeling choices. Because dynamic microsimulations are inherently complex and are computationally intensive, it is crucial to consider potential factors of uncertainty and their influence on simulation outputs in order to more carefully design simulation setups and better communicate results. We find, that simple summary measures insufficiently capture overall model uncertainty and urge modelers to account for these broader sources when designing microsimulations and their results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14294v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morgane Dumont, Ahmed Alsaloum, Julian Ernst, Jan Weymeirsch, Ralf M\"unnich</dc:creator>
    </item>
    <item>
      <title>Estimation of Spatial and Temporal Autoregressive Effects using LASSO - An Example of Hourly Particulate Matter Concentrations</title>
      <link>https://arxiv.org/abs/2511.14666</link>
      <description>arXiv:2511.14666v1 Announce Type: cross 
Abstract: We present an estimation procedure of spatial and temporal effects in spatiotemporal autoregressive panel data models using the Least Absolute Shrinkage and Selection Operator, LASSO (Tibshirani, 1996). We assume that the spatiotemporal panel is drawn from a univariate random process and that the data follows a spatiotemporal autoregressive process which includes a regressive term with space-/ time-varying exogenous regressor, a temporal autoregressive term and a spatial autoregressive term with an unknown weights matrix. The aim is to estimate this weight matrix alongside other parameters using a constraint penalised maximum likelihood estimator. Monte Carlo simulations showed a good performance with the accuracy increasing with an increasing number of time points. The use of the LASSO technique also consistently distinguishes between meaningful relationships (non-zeros) from those that are not (existing zeros) in both the spatial weights and other parameters. This regularised estimation procedure is applied to hourly particulate matter concentrations (PM10) in the Bavaria region, Germany for the years 2005 to 2020. Results show some stations with a high spatial dependency, resulting in a greater influence of PM10 concentrations in neighbouring monitoring stations. The LASSO technique proved to produce a sparse weights matrix by shrinking some weights to zero, hence improving the interpretability of the PM concentration dependencies across measurement stations in Bavaria</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14666v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elkanah Nyabuto, Philipp Otto, Yarema Okhrin</dc:creator>
    </item>
    <item>
      <title>Pseudo-Poisson Distributions with Nonlinear Conditional Rates</title>
      <link>https://arxiv.org/abs/2511.14741</link>
      <description>arXiv:2511.14741v1 Announce Type: cross 
Abstract: Arnold &amp; Manjunath (2021) claim that the bivariate pseudo-Poisson distribution is well suited to bivariate count data with one equidispersed and one overdispersed marginal, owing to its parsimonious structure and straightforward parameter estimation. In the formulation of Leiter &amp; Hamdan (1973), the conditional mean of $X_2$ was specified as a function of $X_1$; Arnold &amp; Manjunath (2021) subsequently augmented this specification by adding an intercept, yielding a linear conditional rate. A direct implication of this construction is that the bivariate pseudo-Poisson distribution can represent only positive correlation between the two variables. This study generalizes the conditional rate to accommodate negatively correlated datasets by introducing curvature. This augmentation provides the additional benefit of allowing the model to behave approximately linear when appropriate, while adequately handling the boundary case $(x_1,x_2)=(0,0)$. According to the Akaike Information Criterion (AIC), the models proposed in this study outperform Arnold &amp; Manjunath (2021)'s linear models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14741v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared N. Lakhani</dc:creator>
    </item>
    <item>
      <title>Forecasting Malaria in Indian States: A Time Series Approach with R Shiny Integration</title>
      <link>https://arxiv.org/abs/2412.20121</link>
      <description>arXiv:2412.20121v2 Announce Type: replace 
Abstract: Malaria remains a significant public health challenge in many regions, necessitating robust predictive models to aid in its management and prevention. This study focuses on developing and evaluating time series models for forecasting malaria cases across eight Indian states: Jharkhand, Chhattisgarh, Maharashtra, Meghalaya, Mizoram, Odisha, Tripura, and Uttar Pradesh. We employed various modeling approaches, including polynomial regression with seasonal components, log-transformed polynomial regression, lagged difference models, and ARIMA models, to capture the temporal dynamics of malaria incidence. Comprehensive model fitting, residual analysis, and performance evaluation using metrics such as Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE) indicated that the log-transformed polynomial regression model consistently outperformed other models in terms of accuracy and robustness across all states. Rolling forecast validation further confirmed the superior predictive capability of the log-transformed model over time. Additionally, an interactive R Shiny tool was developed to facilitate the use of these predictive models by researchers and public health officials. This tool allows users to input data, select modeling approaches, and visualize predictions and performance metrics, providing a practical tool for real-time malaria forecasting and decision-making support. Our findings highlight the critical role of appropriate modeling techniques in malaria prediction and offer valuable resources for enhancing malaria surveillance and response efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20121v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1186/s12936-025-05526-z</arxiv:DOI>
      <arxiv:journal_reference>Ghosh, S.K., Ananthakumar, U., Chougale, P.D. et al. Forecasting Malaria in Indian States: A Time Series Approach with R Shiny Integration. Malar J 24, 403 (2025)</arxiv:journal_reference>
      <dc:creator>Sujit K. Ghosh, Usha Ananthakumar, Praveen D. Chougale, Adithya B. Somaraj</dc:creator>
    </item>
    <item>
      <title>The Hybrid Renewable Energy Forecasting and Trading Competition 2024</title>
      <link>https://arxiv.org/abs/2507.01579</link>
      <description>arXiv:2507.01579v2 Announce Type: replace 
Abstract: The Hybrid Energy Forecasting and Trading Competition challenged participants to forecast and trade the electricity generation from a 3.6GW portfolio of wind and solar farms in Great Britain for three months in 2024. The competition mimicked operational practice with participants required to submit genuine forecasts and market bids for the day-ahead on a daily basis. Prizes were awarded for forecasting performance measured by Pinball Score, trading performance measured by total revenue, and combined performance based on rank in the other two tracks. Here we present an analysis of the participants' performance and the learnings from the competition. The forecasting track reaffirms the competitiveness of popular gradient boosted tree algorithms for day-ahead wind and solar power forecasting, though other methods also yielded strong results, with performance in all cases highly dependent on implementation. The trading track offers insight into the relationship between forecast skill and value, with trading strategy and underlying forecasts influencing performance. All competition data, including power production, weather forecasts, electricity market data, and participants' submissions are shared for further analysis and benchmarking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01579v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijforecast.2025.10.005</arxiv:DOI>
      <dc:creator>Jethro Browell, Dennis van der Meer, Henrik K\"alvegren, Sebastian Haglund, Edoardo Simioni, Ricardo J. Bessa, Yi Wang</dc:creator>
    </item>
    <item>
      <title>TacEleven: generative tactic discovery for football open play</title>
      <link>https://arxiv.org/abs/2511.13326</link>
      <description>arXiv:2511.13326v2 Announce Type: replace 
Abstract: Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13326v2</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyao Zhao, Hao Ma, Zhiqiang Pu, Jingjing Huang, Yi Pan, Shijie Wang, Zhi Ming</dc:creator>
    </item>
    <item>
      <title>A causal interactions indicator between two time series using extreme variations in the first eigenvalue of lagged correlation matrices</title>
      <link>https://arxiv.org/abs/2307.04953</link>
      <description>arXiv:2307.04953v3 Announce Type: replace-cross 
Abstract: This paper presents a method to identify causal interactions between two time series. The largest eigenvalue follows a Tracy-Widom distribution, derived from a Coulomb gas model. This defines causal interactions as the pushing and pulling of the gas, measurable by the variability of the largest eigenvalue's explanatory power. The hypothesis that this setup applies to time series interactions was validated, with causality inferred from time lags. The standard deviation of the largest eigenvalue's explanatory power in lagged correlation matrices indicated the probability of causal interaction between time series. Contrasting with traditional methods that rely on forecasting or window-based parametric controls, this approach offers a novel definition of causality based on dynamic monitoring of tail events. Experimental validation with controlled trials and historical data shows that this method outperforms Granger's causality test in detecting structural changes in time series. Applications to stock returns and financial market data show the indicator's predictive capabilities regarding average stock return and realized volatility. Further validation with brokerage data confirms its effectiveness in inferring causal relationships in liquidity flows, highlighting its potential for market and liquidity risk management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04953v3</guid>
      <category>q-fin.PM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.3934/DSFE.2024018</arxiv:DOI>
      <dc:creator>Alejandro Rodriguez Dominguez, Om Hari Yadav</dc:creator>
    </item>
    <item>
      <title>Link prediction in ecological networks under extreme taxonomic bias</title>
      <link>https://arxiv.org/abs/2506.23370</link>
      <description>arXiv:2506.23370v2 Announce Type: replace-cross 
Abstract: Ecological networks offer powerful insights into community function, but without first characterizing these networks accurately, our ability to detect and interpret changes under environmental stress is limited. We develop an approach to reduce bias in link prediction in the common scenario in which data are derived from studies focused on a small number of species. Our Extended Covariate-Informed Link Prediction (COIL+) framework employs a latent factor model that flexibly borrows information across species, incorporates species traits and phylogeny, and leverages information from multiple studies to address uncertainty in species occurrence. We also propose a trait-matching procedure that allows heterogeneity in species-level trait-interaction associations. We illustrate the approach with a literature-based dataset of 268 sources reporting Afrotropical frugivory and compare performance with and without correction for occurrence uncertainty. COIL+ substantially improves link prediction and reduces sampling bias, revealing 5637 likely but unobserved frugivory interactions (a median of nine additional interactions per frugivore). Newly predicted interactions are concentrated among poorly sampled frugivores, such as the water chevrotain (Hyemoschus aquaticus, a small forest-dwelling ungulate) and the rufous-bellied helmetshrike (Prionops rufiventris, a passerine bird of East African tropical forests). Additionally, the method improves model discrimination compared to existing methods under strong taxonomic bias and narrow study focus. This framework generalizes to diverse network contexts and provides a useful tool for link prediction in the face of biased interaction data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23370v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jennifer N. Kampe, Camille M. M. DeSisto, David B. Dunson</dc:creator>
    </item>
    <item>
      <title>A More Realistic Evaluation of Cross-Frequency Transfer Learning and Foundation Forecasting Models</title>
      <link>https://arxiv.org/abs/2509.19465</link>
      <description>arXiv:2509.19465v3 Announce Type: replace-cross 
Abstract: Cross-frequency transfer learning (CFTL) has emerged as a popular framework for curating large-scale time series datasets to pre-train foundation forecasting models (FFMs). Although CFTL has shown promise, current benchmarking practices fall short of accurately assessing its performance. This shortcoming stems from many factors: an over-reliance on small-scale evaluation datasets; inadequate treatment of sample size when computing summary statistics; reporting of suboptimal statistical models; and failing to account for non-negligible risks of overlap between pre-training and test datasets. To address these limitations, we introduce a unified reimplementation of widely-adopted neural forecasting networks, adapting them for the CFTL setup; we pre-train only on proprietary and synthetic data, being careful to prevent test leakage; and we evaluate on 15 large, diverse public forecast competition datasets. Our empirical analysis reveals that statistical models' accuracy is frequently underreported. Notably, we confirm that statistical models and their ensembles consistently outperform existing FFMs by more than 8.2% in sCRPS, and by more than 20% MASE, across datasets. However, we also find that synthetic dataset pre-training does improve the accuracy of a FFM by 7% percent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19465v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kin G. Olivares, Malcolm Wolff, Tatiana Konstantinova, Shankar Ramasubramanian, Boris Oreshkin, Andrew Gordon Wilson, Andres Potapczynski, Willa Potosnak, Michael W. Mahoney, Mengfei Cao, Dmitry Efimov</dc:creator>
    </item>
    <item>
      <title>A Bayesian Model for Multi-stage Censoring</title>
      <link>https://arxiv.org/abs/2511.11684</link>
      <description>arXiv:2511.11684v2 Announce Type: replace-cross 
Abstract: Many sequential decision settings in healthcare feature funnel structures characterized by a series of stages, such as screenings or evaluations, where the number of patients who advance to each stage progressively decreases and decisions become increasingly costly. For example, an oncologist may first conduct a breast exam, followed by a mammogram for patients with concerning exams, followed by a biopsy for patients with concerning mammograms. A key challenge is that the ground truth outcome, such as the biopsy result, is only revealed at the end of this funnel. The selective censoring of the ground truth can introduce statistical biases in risk estimation, especially in underserved patient groups, whose outcomes are more frequently censored. We develop a Bayesian model for funnel decision structures, drawing from prior work on selective labels and censoring. We first show in synthetic settings that our model is able to recover the true parameters and predict outcomes for censored patients more accurately than baselines. We then apply our model to a dataset of emergency department visits, where in-hospital mortality is observed only for those who are admitted to either the hospital or ICU. We find that there are gender-based differences in hospital and ICU admissions. In particular, our model estimates that the mortality risk threshold to admit women to the ICU is higher for women (5.1%) than for men (4.5%).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11684v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuvom Sadhuka, Sophia Lin, Emma Pierson, Bonnie Berger</dc:creator>
    </item>
  </channel>
</rss>
