<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 05:00:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reservoir Computing via Multi-Scale Random Fourier Features for Forecasting Fast-Slow Dynamical Systems</title>
      <link>https://arxiv.org/abs/2511.14775</link>
      <description>arXiv:2511.14775v1 Announce Type: new 
Abstract: Forecasting nonlinear time series with multi-scale temporal structures remains a central challenge in complex systems modeling. We present a novel reservoir computing framework that combines delay embedding with random Fourier feature (RFF) mappings to capture such dynamics. Two formulations are investigated: a single-scale RFF reservoir, which employs a fixed kernel bandwidth, and a multi-scale RFF reservoir, which integrates multiple bandwidths to represent both fast and slow temporal dependencies. The framework is applied to a diverse set of canonical systems: neuronal models such as the Rulkov map, Izhikevich model, Hindmarsh-Rose model, and Morris-Lecar model, which exhibit spiking, bursting, and chaotic behaviors arising from fast-slow interactions; and ecological models including the predator-prey dynamics and Ricker map with seasonal forcing, which display multi-scale oscillations and intermittency. Across all cases, the multi-scale RFF reservoir consistently outperforms its single-scale counterpart, achieving lower normalized root mean square error (NRMSE) and more robust long-horizon predictions. These results highlight the effectiveness of explicitly incorporating multi-scale feature mappings into reservoir computing architectures for modeling complex dynamical systems with intrinsic fast-slow interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14775v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. K. Laha</dc:creator>
    </item>
    <item>
      <title>Learning Where, What and How to Transfer: A Multi-Role Reinforcement Learning Approach for Evolutionary Multitasking</title>
      <link>https://arxiv.org/abs/2511.15199</link>
      <description>arXiv:2511.15199v1 Announce Type: new 
Abstract: Evolutionary multitasking (EMT) algorithms typically require tailored designs for knowledge transfer, in order to assure convergence and optimality in multitask optimization. In this paper, we explore designing a systematic and generalizable knowledge transfer policy through Reinforcement Learning. We first identify three major challenges: determining the task to transfer (where), the knowledge to be transferred (what) and the mechanism for the transfer (how). To address these challenges, we formulate a multi-role RL system where three (groups of) policy networks act as specialized agents: a task routing agent incorporates an attention-based similarity recognition module to determine source-target transfer pairs via attention scores; a knowledge control agent determines the proportion of elite solutions to transfer; and a group of strategy adaptation agents control transfer strength by dynamically controlling hyper-parameters in the underlying EMT framework. Through pre-training all network modules end-to-end over an augmented multitask problem distribution, a generalizable meta-policy is obtained. Comprehensive validation experiments show state-of-the-art performance of our method against representative baselines. Further in-depth analysis not only reveals the rationale behind our proposal but also provide insightful interpretations on what the system have learned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15199v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiajun Zhan, Zeyuan Ma, Yue-Jiao Gong, Kay Chen Tan</dc:creator>
    </item>
    <item>
      <title>A Quantifier-Reversal Approximation Paradigm for Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2511.15326</link>
      <description>arXiv:2511.15326v1 Announce Type: new 
Abstract: Classical neural network approximation results take the form: for every function $f$ and every error tolerance $\epsilon &gt; 0$, one constructs a neural network whose architecture and weights depend on $\epsilon$. This paper introduces a fundamentally different approximation paradigm that reverses this quantifier order. For each target function $f$, we construct a single recurrent neural network (RNN) with fixed topology and fixed weights that approximates $f$ to within any prescribed tolerance $\epsilon &gt; 0$ when run for sufficiently many time steps.
  The key mechanism enabling this quantifier reversal is temporal computation combined with weight sharing: rather than increasing network depth, the approximation error is reduced solely by running the RNN longer. This yields exponentially decaying approximation error as a function of runtime while requiring storage of only a small, fixed set of weights. Such architectures are appealing for hardware implementations where memory is scarce and runtime is comparatively inexpensive.
  To initiate the systematic development of this novel approximation paradigm, we focus on univariate polynomials. Our RNN constructions emulate the structural calculus underlying deep feed-forward ReLU network approximation theory -- parallelization, linear combinations, affine transformations, and, most importantly, a clocked mechanism that realizes function composition within a single recurrent architecture. The resulting RNNs have size independent of the error tolerance $\epsilon$ and hidden-state dimension linear in the degree of the polynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15326v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Clemens Hutter, Valentin Abadie, Helmut B\"olcskei</dc:creator>
    </item>
    <item>
      <title>Towards Evolutionary Optimization Using the Ising Model</title>
      <link>https://arxiv.org/abs/2511.15377</link>
      <description>arXiv:2511.15377v1 Announce Type: new 
Abstract: In this paper, we study the problem of finding the global minima of a given function. Specifically, we consider complicated functions with numerous local minima, as is often the case for real-world data mining losses. We do so by applying a model from theoretical physics to create an Ising model-based evolutionary optimization algorithm. Our algorithm creates stable regions of local optima and a high potential for improvement between these regions. This enables the accurate identification of global minima, surpassing comparable methods, and has promising applications to ensembles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15377v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simon Kl\"uttermann</dc:creator>
    </item>
    <item>
      <title>Meta-Black-Box Optimization with Bi-Space Landscape Analysis and Dual-Control Mechanism for SAEA</title>
      <link>https://arxiv.org/abs/2511.15551</link>
      <description>arXiv:2511.15551v1 Announce Type: new 
Abstract: Surrogate-Assisted Evolutionary Algorithms (SAEAs) are widely used for expensive Black-Box Optimization. However, their reliance on rigid, manually designed components such as infill criteria and evolutionary strategies during the search process limits their flexibility across tasks. To address these limitations, we propose Dual-Control Bi-Space Surrogate-Assisted Evolutionary Algorithm (DB-SAEA), a Meta-Black-Box Optimization (MetaBBO) framework tailored for multi-objective problems. DB-SAEA learns a meta-policy that jointly regulates candidate generation and infill criterion selection, enabling dual control. The bi-space Exploratory Landscape Analysis (ELA) module in DB-SAEA adopts an attention-based architecture to capture optimization states from both true and surrogate evaluation spaces, while ensuring scalability across problem dimensions, population sizes, and objectives. Additionally, we integrate TabPFN as the surrogate model for accurate and efficient prediction with uncertainty estimation. The framework is trained via reinforcement learning, leveraging parallel sampling and centralized training to enhance efficiency and transferability across tasks. Experimental results demonstrate that DB-SAEA not only outperforms state-of-the-art baselines across diverse benchmarks, but also exhibits strong zero-shot transfer to unseen tasks with higher-dimensional settings. This work introduces the first MetaBBO framework with dual-level control over SAEAs and a bi-space ELA that captures surrogate model information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15551v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukun Du, Haiyue Yu, Xiaotong Xie, Yan Zheng, Lixin Zhan, Yudong Du, Chongshuang Hu, Boxuan Wang, Jiang Jiang</dc:creator>
    </item>
    <item>
      <title>Teaching signal synchronization in deep neural networks with prospective neurons</title>
      <link>https://arxiv.org/abs/2511.14917</link>
      <description>arXiv:2511.14917v1 Announce Type: cross 
Abstract: Working memory requires the brain to maintain information from the recent past to guide ongoing behavior. Neurons can contribute to this capacity by slowly integrating their inputs over time, creating persistent activity that outlasts the original stimulus. However, when these slowly integrating neurons are organized hierarchically, they introduce cumulative delays that create a fundamental challenge for learning: teaching signals that indicate whether behavior was correct or incorrect arrive out-of-sync with the neural activity they are meant to instruct. Here, we demonstrate that neurons enhanced with an adaptive current can compensate for these delays by responding to external stimuli prospectively -- effectively predicting future inputs to synchronize with them. First, we show that such prospective neurons enable teaching signal synchronization across a range of learning algorithms that propagate error signals through hierarchical networks. Second, we demonstrate that this successfully guides learning in slowly integrating neurons, enabling the formation and retrieval of memories over extended timescales. We support our findings with a mathematical analysis of the prospective coding mechanism and learning experiments on motor control tasks. Together, our results reveal how neural adaptation could solve a critical timing problem and enable efficient learning in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14917v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicoas Zucchet, Qianqian Feng, Axel Laborieux, Friedemann Zenke, Walter Senn, Jo\~ao Sacramento</dc:creator>
    </item>
    <item>
      <title>NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework</title>
      <link>https://arxiv.org/abs/2511.15408</link>
      <description>arXiv:2511.15408v1 Announce Type: cross 
Abstract: Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15408v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.MA</category>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanlin Zhou (Tongji University), Xinpeng Wang (Tongji University), Jianxun Lian (Microsoft Research Asia), Zhenghao Liu (Northeastern University), Laks V. S. Lakshmanan (The University of British Columbia), Xiaoyuan Yi (Microsoft Research Asia), Yongtao Hao (Tongji University)</dc:creator>
    </item>
    <item>
      <title>SPICEMixer - Netlist-Level Circuit Evolution</title>
      <link>https://arxiv.org/abs/2506.01497</link>
      <description>arXiv:2506.01497v2 Announce Type: replace 
Abstract: We present SPICEMixer, a genetic algorithm that synthesizes circuits by directly evolving SPICE netlists. SPICEMixer operates on individual netlist lines, making it compatible with arbitrary components and subcircuits and enabling general-purpose genetic operators: crossover, mutation, and pruning, all applied directly at the netlist level. To support these operators, we normalize each netlist by enforcing consistent net naming (inputs, outputs, supplies, and internal nets) and by sorting components and nets into a fixed order, so that similar circuit structures appear at similar line positions. This normalized netlist format improves the effectiveness of crossover, mutation, and pruning. We demonstrate SPICEMixer by synthesizing standard cells (e.g., NAND2 and latch) and by designing OpAmps that meet specified targets. Across tasks, SPICEMixer matches or exceeds recent synthesis methods while requiring substantially fewer simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01497v2</guid>
      <category>cs.NE</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Uhlich, Andrea Bonetti, Arun Venkitaraman, Chia-Yu Hsieh, Ya\u{g}{\i}z Gen\c{c}er, Mustafa Emre G\"ursoy, Ryoga Matsuo, Lorenzo Servadei</dc:creator>
    </item>
    <item>
      <title>Quantitative Attractor Analysis of High-Capacity Kernel Logistic Regression Hopfield Networks</title>
      <link>https://arxiv.org/abs/2505.01218</link>
      <description>arXiv:2505.01218v2 Announce Type: replace-cross 
Abstract: Kernel-based learning methods such as Kernel Logistic Regression (KLR) can dramatically increase the storage capacity of Hopfield networks, but the principles governing their performance and stability remain largely uncharacterized. This paper presents a comprehensive quantitative analysis of the attractor landscape in KLR-trained networks to establish a solid foundation for their design and application. Through extensive, statistically validated simulations, we address critical questions of generality, scalability, and robustness. Our comparative analysis reveals that KLR and Kernel Ridge Regression (KRR) exhibit similarly high storage capacities and clean attractor landscapes, suggesting this is a general property of kernel regression methods, though KRR is computationally much faster. We uncover a non-trivial, scale-dependent scaling law for the kernel width ($\gamma$), demonstrating that optimal capacity requires gamma to be scaled such that $\gamma \times N$ increases with network size $N$. This implies that larger networks necessitate more localized kernels -- where each pattern's influence is more spatially confined--to manage inter-pattern interference. Under this optimized scaling, we provide definitive evidence that the storage capacity scales linearly with network size ($P \propto N$). Furthermore, our sensitivity analysis shows that performance is remarkably robust to the choice of the regularization parameter lambda. Collectively, these findings provide a clear set of empirical principles for designing high-capacity, robust associative memories and clarify the mechanisms that enable kernel methods to overcome the classical limitations of Hopfield-type models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01218v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akira Tamamori</dc:creator>
    </item>
    <item>
      <title>A systematic review of metaheuristics-based and machine learning-driven intrusion detection systems in IoT</title>
      <link>https://arxiv.org/abs/2506.00377</link>
      <description>arXiv:2506.00377v3 Announce Type: replace-cross 
Abstract: The widespread adoption of the Internet of Things (IoT) has raised a new challenge for developers since it is prone to known and unknown cyberattacks due to its heterogeneity, flexibility, and close connectivity. To defend against such security breaches, researchers have focused on building sophisticated intrusion detection systems (IDSs) using machine learning (ML) techniques. Although these algorithms notably improve detection performance, they require excessive computing power and resources, which are crucial issues in IoT networks considering the recent trends of decentralized data processing and computing systems. Consequently, many optimization techniques have been incorporated with these ML models. Specifically, a special category of optimizer adopted from the behavior of living creatures and different aspects of natural phenomena, known as metaheuristic algorithms, has been a central focus in recent years and brought about remarkable results. Considering this vital significance, we present a comprehensive and systematic review of various applications of metaheuristics algorithms in developing a machine learning-based IDS, especially for IoT. A significant contribution of this study is the discovery of hidden correlations between these optimization techniques and machine learning models integrated with state-of-the-art IoT-IDSs. In addition, the effectiveness of these metaheuristic algorithms in different applications, such as feature selection, parameter or hyperparameter tuning, and hybrid usages are separately analyzed. Moreover, a taxonomy of existing IoT-IDSs is proposed. Furthermore, we investigate several critical issues related to such integration. Our extensive exploration ends with a discussion of promising optimization algorithms and technologies that can enhance the efficiency of IoT-IDSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00377v3</guid>
      <category>cs.CR</category>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.swevo.2025.101984</arxiv:DOI>
      <dc:creator>Mohammad Shamim Ahsan, Salekul Islam, Swakkhar Shatabda</dc:creator>
    </item>
    <item>
      <title>Why Consciousness Should Explain Physical Phenomena: Toward a Testable Theory</title>
      <link>https://arxiv.org/abs/2511.04047</link>
      <description>arXiv:2511.04047v2 Announce Type: replace-cross 
Abstract: The reductionist approach commonly employed in scientific methods presupposes that both macro and micro phenomena can be explained by micro-level laws alone. This assumption implies intra-level causal closure, rendering all macro phenomena epiphenomenal. However, the integrative nature of consciousness suggests that it is a macro phenomenon. To ensure scientific testability and reject epiphenomenalism, the reductionist assumption of intra-level causal closure must be rejected. This implies that even neural-level behavior cannot be explained by observable neural-level laws alone. Therefore, a new methodology is necessary to acknowledge the causal efficacy of macro-level phenomena. We model the brain as operating under dual laws at different levels. This model includes hypothetical macro-level psychological laws that are not determined solely by micro-level neural laws, as well as the causal effects from macro to micro levels. In this study, we propose a constructive approach that explains both mental and physical phenomena through the interaction between these two sets of laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04047v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshiyuki Ohmura, Yasuo Kuniyoshi</dc:creator>
    </item>
  </channel>
</rss>
