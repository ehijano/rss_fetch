<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Some tractability results for multivariate integration in subspaces of the Wiener algebra</title>
      <link>https://arxiv.org/abs/2410.09060</link>
      <description>arXiv:2410.09060v1 Announce Type: new 
Abstract: In this paper, we present some new (in-)tractability results related to the integration problem in subspaces of the Wiener algebra over the $d$-dimensional unit cube. We show that intractability holds for multivariate integration in the standard Wiener algebra in the deterministic setting, in contrast to polynomial tractability in an unweighted subspace of the Wiener algebra recently shown by Goda (2023). Moreover, we prove that multivariate integration in the subspace of the Wiener algebra introduced by Goda is strongly polynomially tractable if we switch to the randomized setting. We also identify subspaces in which multivariate integration in the deterministic setting are (strongly) polynomially tractable and we compare these results with the bound which can be obtained via Hoeffding's inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09060v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josef Dick, Takashi Goda, Kosuke Suzuki</dc:creator>
    </item>
    <item>
      <title>Relative-error monotonicity testing</title>
      <link>https://arxiv.org/abs/2410.09235</link>
      <description>arXiv:2410.09235v1 Announce Type: new 
Abstract: The standard model of Boolean function property testing is not well suited for testing $\textit{sparse}$ functions which have few satisfying assignments, since every such function is close (in the usual Hamming distance metric) to the constant-0 function. In this work we propose and investigate a new model for property testing of Boolean functions, called $\textit{relative-error testing}$, which provides a natural framework for testing sparse functions.
  This new model defines the distance between two functions $f, g: \{0,1\}^n \to \{0,1\}$ to be $$\textsf{reldist}(f,g) := { \frac{|f^{-1}(1) \triangle g^{-1}(1)|} {|f^{-1}(1)|}}.$$ This is a more demanding distance measure than the usual Hamming distance ${ {|f^{-1}(1) \triangle g^{-1}(1)|}/{2^n}}$ when $|f^{-1}(1)| \ll 2^n$; to compensate for this, algorithms in the new model have access both to a black-box oracle for the function $f$ being tested and to a source of independent uniform satisfying assignments of $f$.
  In this paper we first give a few general results about the relative-error testing model; then, as our main technical contribution, we give a detailed study of algorithms and lower bounds for relative-error testing of $\textit{monotone}$ Boolean functions. We give upper and lower bounds which are parameterized by $N=|f^{-1}(1)|$, the sparsity of the function $f$ being tested. Our results show that there are interesting differences between relative-error monotonicity testing of sparse Boolean functions, and monotonicity testing in the standard model. These results motivate further study of the testability of Boolean function properties in the relative-error model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09235v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Anindya De, Yizhi Huang, Yuhao Li, Shivam Nadimpalli, Rocco A. Servedio, Tianqi Yang</dc:creator>
    </item>
    <item>
      <title>Toward Better Depth Lower Bounds: Strong Composition of XOR and a Random Function</title>
      <link>https://arxiv.org/abs/2410.10189</link>
      <description>arXiv:2410.10189v1 Announce Type: new 
Abstract: Proving formula depth lower bounds is a fundamental challenge in complexity theory, with the strongest known bound of $(3 - o(1))\log n$ established by Hastad over 25 years ago. The Karchmer--Raz--Wigderson (KRW) conjecture offers a promising approach to advance these bounds and separate P from NC$^{1}$. It suggests that the depth complexity of a function composition $f \diamond g$ approximates the sum of the depth complexities of $f$ and $g$.
  The Karchmer--Wigderson (KW) relation framework translates formula depth into communication complexity, restating the KRW conjecture as $\mathsf{CC}(\mathsf{KW}_f \diamond \mathsf{KW}_g) \approx \mathsf{CC}(\mathsf{KW}_f) + \mathsf{CC}(\mathsf{KW}_g)$. Prior work has confirmed the conjecture under various relaxations, often replacing one or both KW relations with the universal relation or constraining the communication game through strong composition.
  In this paper, we examine the strong composition $\mathsf{KW}_{\mathsf{XOR}} \circledast \mathsf{KW}_f$ of the parity function and a random Boolean function $f$. We prove that with probability $1-o(1)$, any protocol solving this composition requires at least $n^{3 - o(1)}$ leaves. This result establishes a depth lower bound of $(3 - o(1))\log n$, matching Hastad's bound, but is applicable to a broader class of inner functions, even when the outer function is simple. Though bounds for the strong composition do not translate directly to formula depth bounds, they usually help to analyze the standard composition (of the corresponding two functions) which is directly related to formula depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10189v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolai Chukhin, Alexander S. Kulikov, Ivan Mikhajlin</dc:creator>
    </item>
    <item>
      <title>On the Low Weight Polynomial Multiple Problem</title>
      <link>https://arxiv.org/abs/2410.10224</link>
      <description>arXiv:2410.10224v1 Announce Type: new 
Abstract: Finding a low-weight multiple (LWPM) of a given polynomial is very useful in the cryptanalysis of stream ciphers and arithmetic in finite fields. There is no known deterministic polynomial time complexity algorithm for solving this problem, and the most efficient algorithms are based on a time/memory trade-off. The widespread perception is that this problem is difficult. In this paper, we establish a relationship between the LWPM problem and the MAX-SAT problem of determining an assignment that maximizes the number of valid clauses of a system of affine Boolean clauses. This relationship shows that any algorithm that can compute the optimum of a MAX-SAT instance can also compute the optimum of an equivalent LWPM instance. It also confirms the perception that the LWPM problem is difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10224v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ferucio Lauren\c{t}iu \c{T}iplea, Simona-Maria L\u{a}z\u{a}rescu</dc:creator>
    </item>
    <item>
      <title>Computing eulerian magnitude homology</title>
      <link>https://arxiv.org/abs/2410.10376</link>
      <description>arXiv:2410.10376v1 Announce Type: new 
Abstract: In this paper tackle the problem of computing the ranks of certain eulerian magnitude homology groups of a graph G. First, we analyze the computational cost of our problem and prove that it is #W[1]-complete. Then we develop the first diagonal algorithm, a breadth-first-search-based algorithm parameterized by the diameter of the graph to calculate the ranks of the homology groups of interest. To do this, we leverage the close relationship between the combinatorics of the homology boundary map and the substructures appearing in the graph. We then discuss the feasibility of the presented algorithm and consider future perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10376v1</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuliamaria Menara, Luca Manzoni</dc:creator>
    </item>
    <item>
      <title>Looped ReLU MLPs May Be All You Need as Practical Programmable Computers</title>
      <link>https://arxiv.org/abs/2410.09375</link>
      <description>arXiv:2410.09375v1 Announce Type: cross 
Abstract: Previous work has demonstrated that attention mechanisms are Turing complete. More recently, it has been shown that a looped 13-layer Transformer can function as a universal programmable computer. In contrast, the multi-layer perceptrons with $\mathsf{ReLU}$ activation ($\mathsf{ReLU}$-$\mathsf{MLP}$), one of the most fundamental components of neural networks, is known to be expressive; specifically, a two-layer neural network is a universal approximator given an exponentially large number of hidden neurons. However, it remains unclear whether a $\mathsf{ReLU}$-$\mathsf{MLP}$ can be made into a universal programmable computer using a practical number of weights. In this work, we provide an affirmative answer that a looped 23-layer $\mathsf{ReLU}$-$\mathsf{MLP}$ is capable to perform the basic necessary operations, effectively functioning as a programmable computer. This indicates that simple modules have stronger expressive power than previously expected and have not been fully explored. Our work provides insights into the mechanisms of neural networks and demonstrates that complex tasks, such as functioning as a programmable computer, do not necessarily require advanced architectures like Transformers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09375v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Yufa Zhou</dc:creator>
    </item>
    <item>
      <title>Fine-grained Attention I/O Complexity: Comprehensive Analysis for Backward Passes</title>
      <link>https://arxiv.org/abs/2410.09397</link>
      <description>arXiv:2410.09397v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in processing long-context information. However, the quadratic complexity of attention computation with respect to sequence length poses significant computational challenges, and I/O aware algorithms have been proposed. This paper presents a comprehensive analysis of the I/O complexity for attention mechanisms, focusing on backward passes by categorizing into small and large cache scenarios. Using the red-blue pebble game framework, we establish tight bounds on I/O complexity across all cache sizes. We confirm that the de facto standard I/O aware algorithm FlashAttention is optimal for both forward and backward passes for the large cache size scenario. For small cache sizes, we provide an algorithm that improves over existing methods and achieves the tight bounds. Additionally, we extend our analysis to sparse attention, a mainstream speeding-up approach, deriving fine-grained lower bounds for both forward and backward passes and both small and large caches. Our findings complete the theoretical foundation for I/O complexity in attention mechanisms, offering insights for designing efficient algorithms of LLM training and inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09397v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Yufa Zhou</dc:creator>
    </item>
    <item>
      <title>Second-Order Min-Max Optimization with Lazy Hessians</title>
      <link>https://arxiv.org/abs/2410.09568</link>
      <description>arXiv:2410.09568v1 Announce Type: cross 
Abstract: This paper studies second-order methods for convex-concave minimax optimization. Monteiro and Svaiter (2012) proposed a method to solve the problem with an optimal iteration complexity of $\mathcal{O}(\epsilon^{-3/2})$ to find an $\epsilon$-saddle point. However, it is unclear whether the computational complexity, $\mathcal{O}((N+ d^2) d \epsilon^{-2/3})$, can be improved. In the above, we follow Doikov et al. (2023) and assume the complexity of obtaining a first-order oracle as $N$ and the complexity of obtaining a second-order oracle as $dN$. In this paper, we show that the computation cost can be reduced by reusing Hessian across iterations. Our methods take the overall computational complexity of $ \tilde{\mathcal{O}}( (N+d^2)(d+ d^{2/3}\epsilon^{-2/3}))$, which improves those of previous methods by a factor of $d^{1/3}$. Furthermore, we generalize our method to strongly-convex-strongly-concave minimax problems and establish the complexity of $\tilde{\mathcal{O}}((N+d^2) (d + d^{2/3} \kappa^{2/3}) )$ when the condition number of the problem is $\kappa$, enjoying a similar speedup upon the state-of-the-art method. Numerical experiments on both real and synthetic datasets also verify the efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09568v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lesi Chen, Chengchang Liu, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>How to Construct Random Unitaries</title>
      <link>https://arxiv.org/abs/2410.10116</link>
      <description>arXiv:2410.10116v1 Announce Type: cross 
Abstract: The existence of pseudorandom unitaries (PRUs) -- efficient quantum circuits that are computationally indistinguishable from Haar-random unitaries -- has been a central open question, with significant implications for cryptography, complexity theory, and fundamental physics. In this work, we close this question by proving that PRUs exist, assuming that any quantum-secure one-way function exists. We establish this result for both (1) the standard notion of PRUs, which are secure against any efficient adversary that makes queries to the unitary $U$, and (2) a stronger notion of PRUs, which are secure even against adversaries that can query both the unitary $U$ and its inverse $U^\dagger$. In the process, we prove that any algorithm that makes queries to a Haar-random unitary can be efficiently simulated on a quantum computer, up to inverse-exponential trace distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10116v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fermi Ma, Hsin-Yuan Huang</dc:creator>
    </item>
    <item>
      <title>From Donkeys to Kings in Tournaments</title>
      <link>https://arxiv.org/abs/2410.10475</link>
      <description>arXiv:2410.10475v1 Announce Type: cross 
Abstract: A tournament is an orientation of a complete graph. A vertex that can reach every other vertex within two steps is called a \emph{king}. We study the complexity of finding $k$ kings in a tournament graph.
  We show that the randomized query complexity of finding $k \le 3$ kings is $O(n)$, and for the deterministic case it takes the same amount of queries (up to a constant) as finding a single king (the best known deterministic algorithm makes $O(n^{3/2})$ queries). On the other hand, we show that finding $k \ge 4$ kings requires $\Omega(n^2)$ queries, even in the randomized case.
  We consider the RAM model for $k \geq 4$. We show an algorithm that finds $k$ kings in time $O(kn^2)$, which is optimal for constant values of $k$. Alternatively, one can also find $k \ge 4$ kings in time $n^{\omega}$ (the time for matrix multiplication). We provide evidence that this is optimal for large $k$ by suggesting a fine-grained reduction from a variant of the triangle detection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10475v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amir Abboud, Tomer Grossman, Moni Naor, Tomer Solomon</dc:creator>
    </item>
    <item>
      <title>From Chinese Postman to Salesman and Beyond: Shortest Tour $\delta$-Covering All Points on All Edges</title>
      <link>https://arxiv.org/abs/2410.10613</link>
      <description>arXiv:2410.10613v1 Announce Type: cross 
Abstract: A well-studied continuous model of graphs considers each edge as a continuous unit-length interval of points. For $\delta \geq 0$, we introduce the problem $\delta$-Tour, where the objective is to find the shortest tour that comes within a distance of $\delta$ of every point on every edge. It can be observed that 0-Tour is essentially equivalent to the Chinese Postman Problem, which is solvable in polynomial time. In contrast, 1/2-Tour is essentially equivalent to the graphic Traveling Salesman Problem (TSP), which is NP-hard but admits a constant-factor approximation in polynomial time. We investigate $\delta$-Tour for other values of $\delta$, noting that the problem's behavior and the insights required to understand it differ significantly across various $\delta$ regimes. On one hand, we examine the approximability of the problem for every fixed $\delta &gt; 0$:
  (1) For every fixed $0 &lt; \delta &lt; 3/2$, the problem $\delta$-Tour admits a constant-factor approximation and is APX-hard, while for every fixed $\delta \geq 3/2$, the problem admits an $O(\log n)$-approximation algorithm and has no polynomial-time $o(\log n)$-approximation, unless P=NP.
  Our techniques also yield a new APX-hardness result for graphic TSP on cubic bipartite graphs.
  When parameterizing by tour length, it is relatively easy to show that 3/2 is the threshold of fixed-parameter tractability:
  (2) For every fixed $0 &lt; \delta &lt; 3/2$, the problem $\delta$-Tour is FPT parameterized by tour length but is W[2]-hard for every fixed $\delta \geq 3/2$.
  On the other hand, if $\delta$ is part of the input, then an interesting phenomenon occurs when $\delta$ is a constant fraction of n:
  (3) Here, the problem can be solved in time $f(k) n^{O(k)}$, where $k = \lceil n/\delta \rceil$; however, assuming ETH, there is no algorithm that solves the problem in time $f(k) n^{o(k/\log k)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10613v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Frei, Ahmed Ghazy, Tim A. Hartmann, Florian H\"orsch, D\'aniel Marx</dc:creator>
    </item>
    <item>
      <title>Variety Evasive Subspace Families</title>
      <link>https://arxiv.org/abs/2105.02908</link>
      <description>arXiv:2105.02908v3 Announce Type: replace 
Abstract: We introduce the problem of constructing explicit variety evasive subspace families. Given a family $\mathcal{F}$ of subvarieties of a projective or affine space, a collection $\mathcal{H}$ of projective or affine $k$-subspaces is $(\mathcal{F},\epsilon)$-evasive if for every $\mathcal{V}\in\mathcal{F}$, all but at most $\epsilon$-fraction of $W\in\mathcal{H}$ intersect every irreducible component of $\mathcal{V}$ with (at most) the expected dimension. The problem of constructing such an explicit subspace family generalizes both deterministic black-box polynomial identity testing (PIT) and the problem of constructing explicit (weak) lossless rank condensers.
  Using Chow forms, we construct explicit $k$-subspace families of polynomial size that are evasive for all varieties of bounded degree in a projective or affine $n$-space. As one application, we obtain a complete derandomization of Noether's normalization lemma for varieties of low degree in a projective or affine $n$-space. In another application, we obtain a simple polynomial-time black-box PIT algorithm for depth-4 arithmetic circuits with bounded top fan-in and bottom fan-in that are not in the Sylvester-Gallai configuration, improving and simplifying a result of Gupta (ECCC TR 14-130).
  As a complement of our explicit construction, we prove a tight lower bound for the size of $k$-subspace families that are evasive for degree-$d$ varieties in a projective $n$-space. When $n-k=n^{\Omega(1)}$, the lower bound is superpolynomial unless $d$ is bounded. The proof uses a dimension-counting argument on Chow varieties that parametrize projective subvarieties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.02908v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Guo</dc:creator>
    </item>
    <item>
      <title>Fourier growth of structured $\mathbb{F}_2$-polynomials and applications</title>
      <link>https://arxiv.org/abs/2107.10797</link>
      <description>arXiv:2107.10797v2 Announce Type: replace 
Abstract: We analyze the Fourier growth, i.e. the $L_1$ Fourier weight at level $k$ (denoted $L_{1,k}$), of various well-studied classes of "structured" $\mathbb{F}_2$-polynomials. This study is motivated by applications in pseudorandomness, in particular recent results and conjectures due to [CHHL19,CHLT19,CGLSS20] which show that upper bounds on Fourier growth (even at level $k=2$) give unconditional pseudorandom generators.
  Our main structural results on Fourier growth are as follows:
  - We show that any symmetric degree-$d$ $\mathbb{F}_2$-polynomial $p$ has $L_{1,k}(p) \le \Pr[p=1] \cdot O(d)^k$, and this is tight for any constant $k$. This quadratically strengthens an earlier bound that was implicit in [RSV13].
  - We show that any read-$\Delta$ degree-$d$ $\mathbb{F}_2$-polynomial $p$ has $L_{1,k}(p) \le \Pr[p=1] \cdot (k \Delta d)^{O(k)}$.
  - We establish a composition theorem which gives $L_{1,k}$ bounds on disjoint compositions of functions that are closed under restrictions and admit $L_{1,k}$ bounds.
  Finally, we apply the above structural results to obtain new unconditional pseudorandom generators and new correlation bounds for various classes of $\mathbb{F}_2$-polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.10797v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaros{\l}aw B{\l}asiok, Peter Ivanov, Yaonan Jin, Chin Ho Lee, Rocco A. Servedio, Emanuele Viola</dc:creator>
    </item>
    <item>
      <title>NP-hard problems are not in BQP</title>
      <link>https://arxiv.org/abs/2311.05624</link>
      <description>arXiv:2311.05624v3 Announce Type: replace 
Abstract: Grover's algorithm can solve NP-complete problems on quantum computers faster than all the known algorithms on classical computers. However, Grover's algorithm still needs exponential time. Due to the BBBV theorem, Grover's algorithm is optimal for searches in the domain of a function, when the function is used as a black box.
  We analyze the NP-complete set \[\{ (\langle M \rangle, 1^n, 1^t ) \mid \text{ TM }M\text{ accepts an }x\in\{0,1\}^n\text{ within }t\text{ steps}\}.\] If $t$ is large enough, then M accepts each word in $L(M)$ with length $n$ within $t$ steps. So, one can use methods from computability theory to show that black box searching is the fastest way to find a solution. Therefore, Grover's algorithm is optimal for NP-complete problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05624v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reiner Czerwinski</dc:creator>
    </item>
    <item>
      <title>A (1.999999)-approximation ratio for vertex cover problem</title>
      <link>https://arxiv.org/abs/2403.19680</link>
      <description>arXiv:2403.19680v3 Announce Type: replace 
Abstract: Vertex cover problem is a famous combinatorial problem, which its complexity has been heavily studied over the years and while a 2-approximation for it can be trivially obtained, researchers have not been able to approximate it better than 2-o(1). In this paper, by a combination of a new semidefinite programming formulation along with satisfying new proposed properties, we introduce an approximation algorithm for the vertex cover problem with a performance ratio of 1.999999 on arbitrary graphs, en route to answering an open question about the correctness/incorrectness of the unique games conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19680v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Majid Zohrehbandian</dc:creator>
    </item>
    <item>
      <title>On the formalization of the notion of an interactive algorithm</title>
      <link>https://arxiv.org/abs/2405.19037</link>
      <description>arXiv:2405.19037v2 Announce Type: replace 
Abstract: An earlier paper gives an account of a quest for a satisfactory formalization of the classical informal notion of an algorithm. In this paper, an attempt is made to generalize the results of that quest to the informal notion of an interactive algorithm. The notion of an interactive proto-algorithm is introduced. Interactive algorithms are expected to be equivalence classes of interactive proto-algorithms under an appropriate equivalence relation. As in the non-interactive case, three equivalence relations are defined. Two of them are deemed to be bounds for an appropriate equivalence relation and the third is likely an appropriate one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19037v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>Better Boosting of Communication Oracles, or Not</title>
      <link>https://arxiv.org/abs/2410.00838</link>
      <description>arXiv:2410.00838v2 Announce Type: replace 
Abstract: Suppose we have a two-party communication protocol for $f$ which allows the parties to make queries to an oracle computing $g$; for example, they may query an Equality oracle. To translate this protocol into a randomized protocol, we must replace the oracle with a randomized subroutine for solving $g$. If $q$ queries are made, the standard technique requires that we boost the error of each subroutine down to $O(1/q)$, leading to communication complexity which grows as $q \log q$. For which oracles $g$ can this naive boosting technique be improved?
  We focus on the oracles which can be computed by constant-cost randomized protocols, and show that the naive boosting strategy can be improved for the Equality oracle but not the 1-Hamming Distance oracle. Two surprising consequences are (1) a new example of a problem where the cost of computing $k$ independent copies grows superlinear in $k$, drastically simplifying the only previous example due to Blais &amp; Brody (CCC 2019); and (2) a new proof that Equality is not complete for the class of constant-cost randomized communication (Harms, Wild, &amp; Zamaraev, STOC 2022; Hambardzumyan, Hatami, &amp; Hatami, Israel Journal of Mathematics 2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00838v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathaniel Harms, Artur Riazanov</dc:creator>
    </item>
    <item>
      <title>Transformer Encoder Satisfiability: Complexity and Impact on Formal Reasoning</title>
      <link>https://arxiv.org/abs/2405.18548</link>
      <description>arXiv:2405.18548v2 Announce Type: replace-cross 
Abstract: We analyse the complexity of the satisfiability problem (SAT) for transformer encoders (TE), naturally occurring in formal verification or interpretation tasks. We find that SAT is undecidable when considering TE as they are commonly studied in the expressiveness community. Furthermore, we identify practical scenarios where SAT is decidable and establish corresponding complexity bounds. Beyond trivial cases, we find that quantized TE -- those restricted by fixed -- width arithmetic-lead to the decidability of SAT due to their limited attention capabilities. However, the problem remains difficult, as we establish scenarios where SAT is NEXPTIME-hard and others where it is solvable in NEXPTIME for quantized TE. To complement our complexity results, we place our findings and their implications in the broader context of formal reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18548v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco S\"alzer, Eric Alsmann, Martin Lange</dc:creator>
    </item>
    <item>
      <title>A polynomial-time classical algorithm for noisy quantum circuits</title>
      <link>https://arxiv.org/abs/2407.12768</link>
      <description>arXiv:2407.12768v2 Announce Type: replace-cross 
Abstract: We provide a polynomial-time classical algorithm for noisy quantum circuits. The algorithm computes the expectation value of any observable for any circuit, with a small average error over input states drawn from an ensemble (e.g. the computational basis). Our approach is based upon the intuition that noise exponentially damps non-local correlations relative to local correlations. This enables one to classically simulate a noisy quantum circuit by only keeping track of the dynamics of local quantum information. Our algorithm also enables sampling from the output distribution of a circuit in quasi-polynomial time, so long as the distribution anti-concentrates. A number of practical implications are discussed, including a fundamental limit on the efficacy of noise mitigation strategies: for constant noise rates, any quantum circuit for which error mitigation is efficient on most input states, is also classically simulable on most input states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12768v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>physics.atom-ph</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Schuster, Chao Yin, Xun Gao, Norman Y. Yao</dc:creator>
    </item>
  </channel>
</rss>
