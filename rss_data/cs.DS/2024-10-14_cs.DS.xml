<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rapid Computation of the Assembly Index of Molecular Graphs</title>
      <link>https://arxiv.org/abs/2410.09100</link>
      <description>arXiv:2410.09100v1 Announce Type: new 
Abstract: Determining the assembly index of a molecule, which aims to find the least number of steps required to make its molecular graph by recursively using previously made structures, is a novel problem seeking to quantify the minimum number of constraints required to build a given molecular graph which has wide applications from biosignature detection to cheminformatics including drug discovery. In this article, we consider this problem from an algorithmic perspective and propose an exact algorithm to efficiently find assembly indexes of large molecules including some natural products. To achieve this, we start by identifying the largest possible duplicate sub-graphs during the sub-graph enumeration process and subsequently implement a dynamic programming strategy with a branch and bound heuristic to exploit already used duplicates and reject impossible states in the enumeration. To do so efficiently, we introduce the assembly state data-structure as an array of edge-lists that keeps track of the graph fragmentation, by keeping the last fragmented sub-graph as its first element. By a precise manipulation of this data-structure we can efficiently perform each fragmentation step and reconstruct an exact minimal pathway construction for the molecular graph. These techniques are shown to compute assembly indices of many large molecules with speed and memory efficiency. Finally, we demonstrate the strength of our approach with different benchmarks, including calculating assembly indices of hundreds of thousands molecules from the COCONUT natural product database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09100v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ian Seet, Keith Y. Patarroyo, Gage Siebert, Sara I. Walker, Leroy Cronin</dc:creator>
    </item>
    <item>
      <title>Simultaneously Approximating All Norms for Massively Parallel Correlation Clustering</title>
      <link>https://arxiv.org/abs/2410.09321</link>
      <description>arXiv:2410.09321v1 Announce Type: new 
Abstract: We revisit the simultaneous approximation model for the correlation clustering problem introduced by Davies, Moseley, and Newman[DMN24]. The objective is to find a clustering that minimizes given norms of the disagreement vector over all vertices.
  We present an efficient algorithm that produces a clustering that is simultaneously a $63.3$-approximation for all monotone symmetric norms. This significantly improves upon the previous approximation ratio of $6348$ due to Davies, Moseley, and Newman[DMN24], which works only for $\ell_p$-norms.
  To achieve this result, we first reduce the problem to approximating all top-$k$ norms simultaneously, using the connection between monotone symmetric norms and top-$k$ norms established by Chakrabarty and Swamy [CS19]. Then we develop a novel procedure that constructs a $12.66$-approximate fractional clustering for all top-$k$ norms. Our $63.3$-approximation ratio is obtained by combining this with the $5$-approximate rounding algorithm by Kalhan, Makarychev, and Zhou[KMZ19].
  We then demonstrate that with a loss of $\epsilon$ in the approximation ratio, the algorithm can be adapted to run in nearly linear time and in the MPC (massively parallel computation) model with poly-logarithmic number of rounds.
  By allowing a further trade-off in the approximation ratio to $(359+\epsilon)$, the number of MPC rounds can be reduced to a constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09321v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nairen Cao, Shi Li, Jia Ye</dc:creator>
    </item>
    <item>
      <title>Computational complexity of the recoverable robust shortest path problem in acyclic digraphs</title>
      <link>https://arxiv.org/abs/2410.09425</link>
      <description>arXiv:2410.09425v1 Announce Type: new 
Abstract: In this paper, the recoverable robust shortest path problem in acyclic digraphs is considered. The interval budgeted uncertainty representation is used to model the uncertain second-stage costs. The computational complexity of this problem has been open to date. In this paper, we prove that the problem is strongly NP-hard even for the case of layered acyclic digraphs. We also show that for the discrete budgeted uncertainty, the problem is not approximable unless P=NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09425v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Kasperski, Pawel Zielinski</dc:creator>
    </item>
    <item>
      <title>Greediness is not always a vice: Efficient Discovery Algorithms for Assignment Problems</title>
      <link>https://arxiv.org/abs/2410.09434</link>
      <description>arXiv:2410.09434v1 Announce Type: new 
Abstract: Finding a maximum-weight matching is a classical and well-studied problem in computer science, solvable in cubic time in general graphs. We consider the specialization called assignment problem where the input is a bipartite graph, and introduce in this work the ``discovery'' variant considering edge weights that are not provided as input but must be queried, requiring additional and costly computations. We develop here discovery algorithms aiming to minimize the number of queried weights while providing guarantees on the computed solution. We first show in this work the inherent challenges of designing discovery algorithms for general assignment problems. We then provide and analyze several efficient greedy algorithms that can make use of natural assumptions about the order in which the nodes are processed by the algorithms. Our motivations for exploring this problem stem from finding practical solutions to a variation of maximum-weight matching in bipartite hypergraphs, a problem recently emerging in the formation of peer-to-peer energy sharing communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09434v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romaric Duvignau, No\"el Gillet, Ralf Klasing</dc:creator>
    </item>
    <item>
      <title>Many Flavors of Edit Distance</title>
      <link>https://arxiv.org/abs/2410.09877</link>
      <description>arXiv:2410.09877v1 Announce Type: new 
Abstract: Several measures exist for string similarity, including notable ones like the edit distance and the indel distance. The former measures the count of insertions, deletions, and substitutions required to transform one string into another, while the latter specifically quantifies the number of insertions and deletions. Many algorithmic solutions explicitly address one of these measures, and frequently techniques applicable to one can also be adapted to work with the other. In this paper, we investigate whether there exists a standardized approach for applying results from one setting to another. Specifically, we demonstrate the capability to reduce questions regarding string similarity over arbitrary alphabets to equivalent questions over a binary alphabet. Furthermore, we illustrate how to transform questions concerning indel distance into equivalent questions based on edit distance. This complements an earlier result of Tiskin (2007) which addresses the inverse direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09877v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sudatta Bhattacharya, Sanjana Dey, Elazar Goldenberg, Michal Kouck\'y</dc:creator>
    </item>
    <item>
      <title>Towards a Parameterized Approximation Dichotomy of MinCSP for Linear Equations over Finite Commutative Rings</title>
      <link>https://arxiv.org/abs/2410.09932</link>
      <description>arXiv:2410.09932v1 Announce Type: new 
Abstract: We consider the MIN-r-LIN(R) problem: given a system S of length-r linear equations over a ring R, find a subset of equations Z of minimum cardinality such that S-Z is satisfiable. The problem is NP-hard and UGC-hard to approximate within any constant even when r=|R|=2, so we focus on parameterized approximability with solution size as the parameter. For a large class of infinite rings R called Euclidean domains, Dabrowski et al. [SODA-2023] obtained an FPT-algorithm for MIN-2-LIN(R) using an LP-based approach based on work by Wahlstr\"om [SODA-2017]. Here, we consider MIN-r-LIN(R) for finite commutative rings R, initiating a line of research with the ultimate goal of proving dichotomy theorems that separate problems that are FPT-approximable within a constant from those that are not. A major motivation is that our project is a promising step for more ambitious classification projects concerning finite-domain MinCSP and VCSP.
  Dabrowski et al.'s algorithm is limited to rings without zero divisors, which are only fields among finite commutative rings. Handling zero divisors seems to be an insurmountable obstacle for the LP-based approach. In response, we develop a constant-factor FPT-approximation algorithm for a large class of finite commutative rings, called Bergen rings, and thus prove approximability for chain rings, principal ideal rings, and Z_m for all m&gt;1. We complement the algorithmic result with powerful lower bounds. For r&gt;2, we show that the problem is not FPT-approximable within any constant (unless FPT=W[1]). We identify the class of non-Helly rings for which MIN-2-LIN(R) is not FPT-approximable. Under ETH, we also rule out (2-e)-approximation for every e&gt;0 for non-lineal rings, which includes e.g. rings Z_{pq} where p and q are distinct primes. Towards closing the gaps between upper and lower bounds, we lay the foundation of a geometric approach for analysing rings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09932v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konrad K. Dabrowski, Peter Jonsson, Sebastian Ordyniak, George Osipov, Magnus Wahlstroem</dc:creator>
    </item>
    <item>
      <title>A Fully-dynamic Approximation Algorithm for Maximum Weight b-Matchings in Graphs</title>
      <link>https://arxiv.org/abs/2410.09965</link>
      <description>arXiv:2410.09965v1 Announce Type: new 
Abstract: Matching nodes in a graph G = (V, E) is a well-studied algorithmic problem with many applications. The b-matching problem is a generalizati on that allows to match a node with up to b neighbors. This allows more flexible connectivity patterns whenever vertices may have multiple associations. The algorithm b-suitor [Khan et al., SISC2016] is able to compute a (1/2)-approximation of a maximum weight b-matching in O(|E|) time. Since real-world graphs often change over time, fast dynamic methods for b-matching optimization are desirable. In this work, we propose Dyn-b-suitor, a dynamic algorithm for the weighted b-matching problem. As a non-trivial extension to the dynamic Suitor algorithm for 1-matchings [Angriman et al., JEA 2022], our approach computes (1/2)-approximate b-matchings by identifying and updating affected vertices without static recomputation. Our proposed algorithm is fully-dynamic, i. e., it supports both edge insertions and deletions, and we prove that it computes the same solution as its static counterpart.
  In extensive experiments on real-world benchmark graphs and generated instances, our dynamic algorithm yields significant savings compared to the sequential b-suitor, e. g., for batch updates with $10^3$ edges with an average acceleration factor of $10^3$. When comparing our sequential dynamic algorithm with the parallel (static) b-suitor on a 128-core machine, our dynamic algorithm is still $59$x to $10^4$ faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09965v1</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Brandt-Tumescheit, Frieda Gerharz, Henning Meyerhenke</dc:creator>
    </item>
    <item>
      <title>Palindromes Compression and Retrieval</title>
      <link>https://arxiv.org/abs/2410.09984</link>
      <description>arXiv:2410.09984v1 Announce Type: new 
Abstract: This paper introduces a novel method for compressing palindromic structures in strings, establishing upper and lower bounds for their efficient representation. We uncover a unique relationship between the Lempel-Ziv parsing of palindromes and the alphabet size, leveraging this insight to propose a compression algorithm that improves space efficiency of Manacher array. Additionally, we present a data structure capable of storing all maximal palindromes (Manacher array) in sublinear space with near-optimal access time. Our approach reduces the memory overhead of storing palindromes, offering a new avenue for optimizing compression algorithms in text processing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09984v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Itzhaki</dc:creator>
    </item>
    <item>
      <title>Tight Bounds and Phase Transitions for Incremental and Dynamic Retrieval</title>
      <link>https://arxiv.org/abs/2410.10002</link>
      <description>arXiv:2410.10002v1 Announce Type: new 
Abstract: Retrieval data structures are data structures that answer key-value queries without paying the space overhead of explicitly storing keys. The problem can be formulated in four settings (static, value-dynamic, incremental, or dynamic), each of which offers different levels of dynamism to the user. In this paper, we establish optimal bounds for the final two settings (incremental and dynamic) in the case of a polynomial universe. Our results complete a line of work that has spanned more than two decades, and also come with a surprise: the incremental setting, which has long been viewed as essentially equivalent to the dynamic one, actually has a phase transition, in which, as the value size $v$ approaches $\log n$, the optimal space redundancy actually begins to shrink, going from roughly $n \log \log n$ (which has long been thought to be optimal) all the way down to $\Theta(n)$ (which is the optimal bound even for the seemingly much-easier value-dynamic setting).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10002v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Kuszmaul, Aaron Putterman, Tingqiang Xu, Hangrui Zhou, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Swift: High-Performance Sparse Tensor Contraction for Scientific Applications</title>
      <link>https://arxiv.org/abs/2410.10094</link>
      <description>arXiv:2410.10094v1 Announce Type: new 
Abstract: In scientific fields such as quantum computing, physics, chemistry, and machine learning, high dimensional data are typically represented using sparse tensors. Tensor contraction is a popular operation on tensors to exploit meaning or alter the input tensors. Tensor contraction is, however, computationally expensive and grows quadratically with the number of elements. For this reason, specialized algorithms have been created to only operate on the nonzero elements. Current sparse tensor contraction algorithms utilize sub-optimal data structures that perform unnecessary computations which increase execution time and the overall time complexity. We propose Swift, a novel algorithm for sparse tensor contraction that replaces the costly sorting with more efficient grouping, utilizes better data structures to represent tensors, and employs more memory-friendly hash table implementation. Swift is evaluated against the state-of-the-art sparse tensor contraction algorithm, demonstrating up to 20x speedup in various test cases and being able to handle imbalanced input tensors significantly better.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10094v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrew Ensinger, Gabriel Kulp, Victor Agostinelli, Dennis Lyakhov, Lizhong Chen</dc:creator>
    </item>
    <item>
      <title>Differentially Private Selection using Smooth Sensitivity</title>
      <link>https://arxiv.org/abs/2410.10187</link>
      <description>arXiv:2410.10187v1 Announce Type: new 
Abstract: With the growing volume of data in society, the need for privacy protection in data analysis also rises. In particular, private selection tasks, wherein the most important information is retrieved under differential privacy are emphasized in a wide range of contexts, including machine learning and medical statistical analysis. However, existing mechanisms use global sensitivity, which may add larger amount of perturbation than is necessary. Therefore, this study proposes a novel mechanism for differentially private selection using the concept of smooth sensitivity and presents theoretical proofs of strict privacy guarantees. Simultaneously, given that the current state-of-the-art algorithm using smooth sensitivity is still of limited use, and that the theoretical analysis of the basic properties of the noise distributions are not yet rigorous, we present fundamental theorems to improve upon them. Furthermore, new theorems are proposed for efficient noise generation. Experiments demonstrate that the proposed mechanism can provide higher accuracy than the existing global sensitivity-based methods. Finally, we show key directions for further theoretical development. Overall, this study can be an important foundational work for expanding the potential of smooth sensitivity in privacy-preserving data analysis. The Python implementation of our experiments and supplemental results are available at https://github.com/ay0408/Smooth-Private-Selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10187v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akito Yamamoto, Tetsuo Shibuya</dc:creator>
    </item>
    <item>
      <title>Quasilinear-time eccentricities computation, and more, on median graphs</title>
      <link>https://arxiv.org/abs/2410.10235</link>
      <description>arXiv:2410.10235v1 Announce Type: new 
Abstract: Computing the diameter, and more generally, all eccentricities of an undirected graph is an important problem in algorithmic graph theory and the challenge is to identify graph classes for which their computation can be achieved in subquadratic time. Using a new recursive scheme based on the structural properties of median graphs, we provide a quasilinear-time algorithm to determine all eccentricities for this well-known family of graphs. Our recursive technique manages specifically balanced and unbalanced parts of the $\Theta$-class decomposition of median graphs. The exact running time of our algorithm is O(n log^4 n). This outcome not only answers a question asked by B{\'e}n{\'e}teau et al. (2020) but also greatly improves a recent result which presents a combinatorial algorithm running in time O(n^1.6408 log^{O(1)} n) for the same problem.Furthermore we also propose a distance oracle for median graphs with both polylogarithmic size and query time. Speaking formally, we provide a combinatorial algorithm which computes for any median graph G, in quasilinear time O(n log^4 n), vertex-labels of size O(log^3 n) such that any distance of G can be retrieved in time O(log^4 n) thanks to these labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10235v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>SODA 2025, Jan 2025, Nouvelle Orl{\'e}ans (USA), United States</arxiv:journal_reference>
      <dc:creator>Pierre Berg\'e (LIMOS), Guillaume Ducoffe (UniBuc), Michel Habib (IRIF)</dc:creator>
    </item>
    <item>
      <title>Routing on Sparse Graphs with Non-metric Costs for the Prize-collecting Travelling Salesperson Problem</title>
      <link>https://arxiv.org/abs/2410.10440</link>
      <description>arXiv:2410.10440v1 Announce Type: new 
Abstract: In many real-world routing problems, decision makers must optimise over sparse graphs such as transportation networks with non-metric costs on the edges that do not obey the triangle inequality. Motivated by finding a sufficiently long running route in a city that minimises the air pollution exposure of the runner, we study the Prize-collecting Travelling Salesperson Problem (Pc-TSP) on sparse graphs with non-metric costs. Given an undirected graph with a cost function on the edges and a prize function on the vertices, the goal of Pc-TSP is to find a tour rooted at the origin that minimises the total cost such that the total prize is at least some quota. First, we introduce heuristics designed for sparse graphs with non-metric cost functions where previous work dealt with either a complete graph or a metric cost function. Next, we develop a branch &amp; cut algorithm that employs a new cut we call the disjoint-paths cost-cover (DPCC) cut. Empirical experiments on two datasets show that our heuristics can produce a feasible solution with less cost than a state-of-the-art heuristic from the literature. On datasets with non-metric cost functions, DPCC is found to solve more instances to optimality than the baseline cutting algorithm we compare against.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10440v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick O'Hara, M. S. Ramanujan, Theodoros Damoulas</dc:creator>
    </item>
    <item>
      <title>From Donkeys to Kings in Tournaments</title>
      <link>https://arxiv.org/abs/2410.10475</link>
      <description>arXiv:2410.10475v1 Announce Type: new 
Abstract: A tournament is an orientation of a complete graph. A vertex that can reach every other vertex within two steps is called a \emph{king}. We study the complexity of finding $k$ kings in a tournament graph.
  We show that the randomized query complexity of finding $k \le 3$ kings is $O(n)$, and for the deterministic case it takes the same amount of queries (up to a constant) as finding a single king (the best known deterministic algorithm makes $O(n^{3/2})$ queries). On the other hand, we show that finding $k \ge 4$ kings requires $\Omega(n^2)$ queries, even in the randomized case.
  We consider the RAM model for $k \geq 4$. We show an algorithm that finds $k$ kings in time $O(kn^2)$, which is optimal for constant values of $k$. Alternatively, one can also find $k \ge 4$ kings in time $n^{\omega}$ (the time for matrix multiplication). We provide evidence that this is optimal for large $k$ by suggesting a fine-grained reduction from a variant of the triangle detection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10475v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amir Abboud, Tomer Grossman, Moni Naor, Tomer Solomon</dc:creator>
    </item>
    <item>
      <title>From Chinese Postman to Salesman and Beyond: Shortest Tour $\delta$-Covering All Points on All Edges</title>
      <link>https://arxiv.org/abs/2410.10613</link>
      <description>arXiv:2410.10613v1 Announce Type: new 
Abstract: A well-studied continuous model of graphs considers each edge as a continuous unit-length interval of points. For $\delta \geq 0$, we introduce the problem $\delta$-Tour, where the objective is to find the shortest tour that comes within a distance of $\delta$ of every point on every edge. It can be observed that 0-Tour is essentially equivalent to the Chinese Postman Problem, which is solvable in polynomial time. In contrast, 1/2-Tour is essentially equivalent to the graphic Traveling Salesman Problem (TSP), which is NP-hard but admits a constant-factor approximation in polynomial time. We investigate $\delta$-Tour for other values of $\delta$, noting that the problem's behavior and the insights required to understand it differ significantly across various $\delta$ regimes. On one hand, we examine the approximability of the problem for every fixed $\delta &gt; 0$:
  (1) For every fixed $0 &lt; \delta &lt; 3/2$, the problem $\delta$-Tour admits a constant-factor approximation and is APX-hard, while for every fixed $\delta \geq 3/2$, the problem admits an $O(\log n)$-approximation algorithm and has no polynomial-time $o(\log n)$-approximation, unless P=NP.
  Our techniques also yield a new APX-hardness result for graphic TSP on cubic bipartite graphs.
  When parameterizing by tour length, it is relatively easy to show that 3/2 is the threshold of fixed-parameter tractability:
  (2) For every fixed $0 &lt; \delta &lt; 3/2$, the problem $\delta$-Tour is FPT parameterized by tour length but is W[2]-hard for every fixed $\delta \geq 3/2$.
  On the other hand, if $\delta$ is part of the input, then an interesting phenomenon occurs when $\delta$ is a constant fraction of n:
  (3) Here, the problem can be solved in time $f(k) n^{O(k)}$, where $k = \lceil n/\delta \rceil$; however, assuming ETH, there is no algorithm that solves the problem in time $f(k) n^{o(k/\log k)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10613v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Frei, Ahmed Ghazy, Tim A. Hartmann, Florian H\"orsch, D\'aniel Marx</dc:creator>
    </item>
    <item>
      <title>On The MCMC Performance In Bernoulli Group Testing And The Random Max-Set Problem</title>
      <link>https://arxiv.org/abs/2410.09231</link>
      <description>arXiv:2410.09231v1 Announce Type: cross 
Abstract: The group testing problem is a canonical inference task where one seeks to identify $k$ infected individuals out of a population of $n$ people, based on the outcomes of $m$ group tests. Of particular interest is the case of Bernoulli group testing (BGT), where each individual participates in each test independently and with a fixed probability. BGT is known to be an ``information-theoretically'' optimal design, as there exists a decoder that can identify with high probability as $n$ grows the infected individuals using $m^*=\log_2 \binom{n}{k}$ BGT tests, which is the minimum required number of tests among \emph{all} group testing designs.
  An important open question in the field is if a polynomial-time decoder exists for BGT which succeeds also with $m^*$ samples. In a recent paper (Iliopoulos, Zadik COLT '21) some evidence was presented (but no proof) that a simple low-temperature MCMC method could succeed. The evidence was based on a first-moment (or ``annealed'') analysis of the landscape, as well as simulations that show the MCMC success for $n \approx 1000s$.
  In this work, we prove that, despite the intriguing success in simulations for small $n$, the class of MCMC methods proposed in previous work for BGT with $m^*$ samples takes super-polynomial-in-$n$ time to identify the infected individuals, when $k=n^{\alpha}$ for $\alpha \in (0,1)$ small enough. Towards obtaining our results, we establish the tight max-satisfiability thresholds of the random $k$-set cover problem, a result of potentially independent interest in the study of random constraint satisfaction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09231v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxwell Lovig, Ilias Zadik</dc:creator>
    </item>
    <item>
      <title>Relative-error monotonicity testing</title>
      <link>https://arxiv.org/abs/2410.09235</link>
      <description>arXiv:2410.09235v1 Announce Type: cross 
Abstract: The standard model of Boolean function property testing is not well suited for testing $\textit{sparse}$ functions which have few satisfying assignments, since every such function is close (in the usual Hamming distance metric) to the constant-0 function. In this work we propose and investigate a new model for property testing of Boolean functions, called $\textit{relative-error testing}$, which provides a natural framework for testing sparse functions.
  This new model defines the distance between two functions $f, g: \{0,1\}^n \to \{0,1\}$ to be $$\textsf{reldist}(f,g) := { \frac{|f^{-1}(1) \triangle g^{-1}(1)|} {|f^{-1}(1)|}}.$$ This is a more demanding distance measure than the usual Hamming distance ${ {|f^{-1}(1) \triangle g^{-1}(1)|}/{2^n}}$ when $|f^{-1}(1)| \ll 2^n$; to compensate for this, algorithms in the new model have access both to a black-box oracle for the function $f$ being tested and to a source of independent uniform satisfying assignments of $f$.
  In this paper we first give a few general results about the relative-error testing model; then, as our main technical contribution, we give a detailed study of algorithms and lower bounds for relative-error testing of $\textit{monotone}$ Boolean functions. We give upper and lower bounds which are parameterized by $N=|f^{-1}(1)|$, the sparsity of the function $f$ being tested. Our results show that there are interesting differences between relative-error monotonicity testing of sparse Boolean functions, and monotonicity testing in the standard model. These results motivate further study of the testability of Boolean function properties in the relative-error model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09235v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Anindya De, Yizhi Huang, Yuhao Li, Shivam Nadimpalli, Rocco A. Servedio, Tianqi Yang</dc:creator>
    </item>
    <item>
      <title>The 2020 United States Decennial Census Is More Private Than You (Might) Think</title>
      <link>https://arxiv.org/abs/2410.09296</link>
      <description>arXiv:2410.09296v1 Announce Type: cross 
Abstract: The U.S. Decennial Census serves as the foundation for many high-profile policy decision-making processes, including federal funding allocation and redistricting. In 2020, the Census Bureau adopted differential privacy to protect the confidentiality of individual responses through a disclosure avoidance system that injects noise into census data tabulations. The Bureau subsequently posed an open question: Could sharper privacy guarantees be obtained for the 2020 U.S. Census compared to their published guarantees, or equivalently, had the nominal privacy budgets been fully utilized?
  In this paper, we affirmatively address this open problem by demonstrating that between 8.50% and 13.76% of the privacy budget for the 2020 U.S. Census remains unused for each of the eight geographical levels, from the national level down to the block level. This finding is made possible through our precise tracking of privacy losses using $f$-differential privacy, applied to the composition of private queries across various geographical levels. Our analysis indicates that the Census Bureau introduced unnecessarily high levels of injected noise to achieve the claimed privacy guarantee for the 2020 U.S. Census. Consequently, our results enable the Bureau to reduce noise variances by 15.08% to 24.82% while maintaining the same privacy budget for each geographical level, thereby enhancing the accuracy of privatized census statistics. We empirically demonstrate that reducing noise injection into census statistics mitigates distortion caused by privacy constraints in downstream applications of private census data, illustrated through a study examining the relationship between earnings and education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09296v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Buxin Su, Weijie J. Su, Chendi Wang</dc:creator>
    </item>
    <item>
      <title>Combinatorial optimization of the coefficient of determination</title>
      <link>https://arxiv.org/abs/2410.09316</link>
      <description>arXiv:2410.09316v1 Announce Type: cross 
Abstract: Robust correlation analysis is among the most critical challenges in statistics. Herein, we develop an efficient algorithm for selecting the $k$- subset of $n$ points in the plane with the highest coefficient of determination $\left( R^2 \right)$. Drawing from combinatorial geometry, we propose a method called the \textit{quadratic sweep} that consists of two steps: (i) projectively lifting the data points into $\mathbb R^5$ and then (ii) iterating over each linearly separable $k$-subset. Its basis is that the optimal set of outliers is separable from its complement in $\mathbb R^2$ by a conic section, which, in $\mathbb R^5$, can be found by a topological sweep in $\Theta \left( n^5 \log n \right)$ time. Although key proofs of quadratic separability remain underway, we develop strong mathematical intuitions for our conjectures, then experimentally demonstrate our method's optimality over several million trials up to $n=30$ without error. Implementations in Julia and fully seeded, reproducible experiments are available at https://github.com/marc-harary/QuadraticSweep.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09316v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Harary</dc:creator>
    </item>
    <item>
      <title>Learning Linear Attention in Polynomial Time</title>
      <link>https://arxiv.org/abs/2410.10101</link>
      <description>arXiv:2410.10101v1 Announce Type: cross 
Abstract: Previous research has explored the computational expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the learnability of these simulators from observational data has remained an open question. Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention. We show that linear attention may be viewed as a linear predictor in a suitably defined RKHS. As a consequence, the problem of learning any linear transformer may be converted into the problem of learning an ordinary linear predictor in an expanded feature space, and any such predictor may be converted back into a multiheaded linear transformer. Moving to generalization, we show how to efficiently identify training datasets for which every empirical risk minimizer is equivalent (up to trivial symmetries) to the linear Transformer that generated the data, thereby guaranteeing the learned model will correctly generalize across all inputs. Finally, we provide examples of computations expressible via linear attention and therefore polynomial-time learnable, including associative memories, finite automata, and a class of Universal Turing Machine (UTMs) with polynomially bounded computation histories. We empirically validate our theoretical findings on three tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformers, and show that flexible and general models of computation are efficiently learnable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10101v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morris Yau, Ekin Akyurek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas</dc:creator>
    </item>
    <item>
      <title>Bounding $\varepsilon$-scatter dimension via metric sparsity</title>
      <link>https://arxiv.org/abs/2410.10191</link>
      <description>arXiv:2410.10191v1 Announce Type: cross 
Abstract: A recent work of Abbasi et al. [FOCS 2023] introduced the notion of $\varepsilon$-scatter dimension of a metric space and showed a general framework for efficient parameterized approximation schemes (so-called EPASes) for a wide range of clustering problems in classes of metric spaces that admit a bound on the $\varepsilon$-scatter dimension. Our main result is such a bound for metrics induced by graphs from any fixed proper minor-closed graph class. The bound is double-exponential in $\varepsilon^{-1}$ and the Hadwiger number of the graph class and is accompanied by a nearly tight lower bound that holds even in graph classes of bounded treewidth.
  On the way to the main result, we introduce metric analogs of well-known graph invariants from the theory of sparsity, including generalized coloring numbers and flatness (aka uniform quasi-wideness), and show bounds for these invariants in proper minor-closed graph classes.
  Finally, we show the power of newly introduced toolbox by showing a coreset for $k$-Center in any proper minor-closed graph class whose size is polynomial in $k$ (but the exponent of the polynomial depends on the graph class and $\varepsilon^{-1}$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10191v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Romain Bourneuf, Marcin Pilipczuk</dc:creator>
    </item>
    <item>
      <title>Stochastic Rounding 2.0, with a View towards Complexity Analysis</title>
      <link>https://arxiv.org/abs/2410.10517</link>
      <description>arXiv:2410.10517v1 Announce Type: cross 
Abstract: Stochastic Rounding is a probabilistic rounding mode that is surprisingly effective in large-scale computations and low-precision arithmetic. Its random nature promotes error cancellation rather than error accumulation, resulting in slower growth of roundoff errors as the problem size increases, especially when compared to traditional deterministic rounding methods, such as rounding-to-nearest. We advocate for SR as a foundational tool in the complexity analysis of algorithms, and suggest several research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10517v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petros Drineas, Ilse C. F. Ipsen</dc:creator>
    </item>
    <item>
      <title>Regularized Robustly Reliable Learners and Instance Targeted Attacks</title>
      <link>https://arxiv.org/abs/2410.10572</link>
      <description>arXiv:2410.10572v1 Announce Type: cross 
Abstract: Instance-targeted data poisoning attacks, where an adversary corrupts a training set to induce errors on specific test points, have raised significant concerns. Balcan et al (2022) proposed an approach to addressing this challenge by defining a notion of robustly-reliable learners that provide per-instance guarantees of correctness under well-defined assumptions, even in the presence of data poisoning attacks. They then give a generic optimal (but computationally inefficient) robustly reliable learner as well as a computationally efficient algorithm for the case of linear separators over log-concave distributions.
  In this work, we address two challenges left open by Balcan et al (2022). The first is that the definition of robustly-reliable learners in Balcan et al (2022) becomes vacuous for highly-flexible hypothesis classes: if there are two classifiers h_0, h_1 \in H both with zero error on the training set such that h_0(x) \neq h_1(x), then a robustly-reliable learner must abstain on x. We address this problem by defining a modified notion of regularized robustly-reliable learners that allows for nontrivial statements in this case. The second is that the generic algorithm of Balcan et al (2022) requires re-running an ERM oracle (essentially, retraining the classifier) on each test point x, which is generally impractical even if ERM can be implemented efficiently. To tackle this problem, we show that at least in certain interesting cases we can design algorithms that can produce their outputs in time sublinear in training time, by using techniques from dynamic algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10572v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avrim Blum, Donya Saless</dc:creator>
    </item>
    <item>
      <title>Exact Exploration</title>
      <link>https://arxiv.org/abs/2410.10706</link>
      <description>arXiv:2410.10706v1 Announce Type: cross 
Abstract: Recent analysis of classical algorithms resulted in their axiomatization as transition systems satisfying some simple postulates, and in the formulation of the Abstract State Machine Theorem, which assures us that any classical algorithm can be emulated step-by-step by a most general model of computation, called an ``abstract state machine''. We refine that analysis to take details of intra-step behavior into account, and show that there is in fact an abstract state machine that not only has the same state transitions as does a given algorithm but also performs the exact same tests on states when determining how to proceed to the next state. This enhancement allows the inclusion -- within the abstract-state-machine framework -- of algorithms whose states only have partially-defined equality, or employ other native partial functions, as is the case, for instance, with inversion of a matrix of computable reals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10706v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>cs.SE</category>
      <category>math.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>A shorter version in CSL 2010, 19th EACSL Annual Conference on Computer Science Logic, Springer Lecture Notes in Computer Science 6247, 2010, 140--154</arxiv:journal_reference>
      <dc:creator>Andreas Blass, Nachum Dershowitz, Yuri Gurevich</dc:creator>
    </item>
    <item>
      <title>A Generalization of von Neumann's Reduction from the Assignment Problem to Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2410.10767</link>
      <description>arXiv:2410.10767v1 Announce Type: cross 
Abstract: The equivalence between von Neumann's Minimax Theorem for zero-sum games and the LP Duality Theorem connects cornerstone problems of the two fields of game theory and optimization, respectively, and has been the subject of intense scrutiny for seven decades. Yet, as observed in this paper, the proof of the difficult direction of this equivalence is unsatisfactory: It does not assign distinct roles to the two players of the game, as is natural from the definition of a zero-sum game.
  In retrospect, a partial resolution to this predicament was provided in another brilliant paper of von Neumann (1953), which reduced the assignment problem to zero-sum games. However, the underlying LP is highly specialized; all entries of its objective function vector are strictly positive and all entries of the constraint matrix and right hand side vector are equal to one.
  We generalize von Neumann's result along two directions, each allowing negative entries in certain parts of the LP. Our reductions make explicit the roles of the two players of the reduced game, namely their maximin strategies are to play optimal solutions to the primal and dual LPs. Furthermore, unlike previous reductions, the value of the reduced game reveals the value of the given LP. Our generalizations encompass several basic economic scenarios.
  We end by discussing evidence that von Neumann possessed an understanding of the notion of polynomial-time solvability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10767v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilan Adler, Martin Bullinger, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>New Concurrent Order Maintenance Data Structure</title>
      <link>https://arxiv.org/abs/2208.07800</link>
      <description>arXiv:2208.07800v2 Announce Type: replace 
Abstract: The \emph{Order-Maintenance} (OM) data structure maintains a total order list of items for insertions, deletions, and comparisons. As a basic data structure, OM has many applications, such as maintaining the topological order, core numbers, and truss in graphs, and maintaining ordered sets in Unified Modeling Language (UML) Specification. The prevalence of multicore machines suggests parallelizing such a basic data structure. This paper proposes a new parallel OM data structure that supports insertions, deletions, and comparisons in parallel. Specifically, parallel insertions and deletions are synchronized by using locks efficiently, which achieve up to $7$x and $5.6$x speedups with $64$ workers. One big advantage is that the comparisons are lock-free so that they can execute highly in parallel with other insertions and deletions, which achieve up to $34.4$x speedups with $64$ workers. Typical real applications maintain order lists that always have a much larger portion of comparisons than insertions and deletions. For example, in core maintenance, the number of comparisons is up to 297 times larger compared with insertions and deletions in certain graphs. This is why the lock-free order comparison is a breakthrough in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07800v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bin Guo, Emil Sekerinski</dc:creator>
    </item>
    <item>
      <title>A scalable clustering algorithm to approximate graph cuts</title>
      <link>https://arxiv.org/abs/2308.09613</link>
      <description>arXiv:2308.09613v2 Announce Type: replace 
Abstract: Due to their computational complexity, graph cuts for cluster detection and identification are used mostly in the form of convex relaxations. We propose to utilize the original graph cuts such as Ratio, Normalized or Cheeger Cut to detect clusters in weighted undirected graphs by restricting the graph cut minimization to $st$-MinCut partitions. Incorporating a vertex selection technique and restricting optimization to tightly connected clusters, we combine the efficient computability of $st$-MinCuts and the intrinsic properties of Gomory-Hu trees with the cut quality of the original graph cuts, leading to linear runtime in the number of vertices and quadratic in the number of edges. Already in simple scenarios, the resulting algorithm Xist is able to approximate graph cut values better empirically than spectral clustering or comparable algorithms, even for large network datasets. We showcase its applicability by segmenting images from cell biology and provide empirical studies of runtime and classification rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09613v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Suchan, Housen Li, Axel Munk</dc:creator>
    </item>
    <item>
      <title>Beyond the worst case: Distortion in impartial culture electorates</title>
      <link>https://arxiv.org/abs/2307.07350</link>
      <description>arXiv:2307.07350v4 Announce Type: replace-cross 
Abstract: {\em Distortion} is a well-established notion for quantifying the loss of social welfare that may occur in voting. As voting rules take as input only ordinal information, they are essentially forced to neglect the exact values the agents have for the alternatives. Thus, in worst-case electorates, voting rules may return low social welfare alternatives and have high distortion. Accompanying voting rules with a small number of cardinal queries per agent may reduce distortion considerably.
  To explore distortion beyond worst-case conditions, we use a simple stochastic model according to which the values the agents have for the alternatives are drawn independently from a common probability distribution. This gives rise to so-called {\em impartial culture electorates}. We refine the definition of distortion so that it is suitable for this stochastic setting and show that, rather surprisingly, all voting rules have high distortion {\em on average}. On the positive side, for the fundamental case where the agents have random {\em binary} values for the alternatives, we present a mechanism that achieves approximately optimal average distortion by making a {\em single} cardinal query per agent. This enables us to obtain slightly suboptimal average distortion bounds for general distributions using a simple randomized mechanism that makes one query per agent. We complement these results by presenting new tradeoffs between the distortion and the number of queries per agent in the traditional worst-case setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07350v4</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Karl Fehrs</dc:creator>
    </item>
    <item>
      <title>Random Multi-Type Spanning Forests for Synchronization on Sparse Graphs</title>
      <link>https://arxiv.org/abs/2403.19300</link>
      <description>arXiv:2403.19300v2 Announce Type: replace-cross 
Abstract: Random diffusions are a popular tool in Monte-Carlo estimations, with well established algorithms such as Walk-on-Spheres (WoS) going back several decades. In this work, we introduce diffusion estimators for the problems of angular synchronization and smoothing on graphs, in the presence of a rotation associated to each edge. Unlike classical WoS algorithms that are point-wise estimators, our diffusion estimators allow for global estimations by propagating along the branches of random spanning subgraphs called multi-type spanning forests. Building upon efficient samplers based on variants of Wilson's algorithm, we show that our estimators outperform standard numerical-linear-algebra solvers in challenging instances, depending on the topology and density of the graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19300v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Jaquard, Pierre-Olivier Amblard, Simon Barthelm\'e, Nicolas Tremblay</dc:creator>
    </item>
    <item>
      <title>On the formalization of the notion of an interactive algorithm</title>
      <link>https://arxiv.org/abs/2405.19037</link>
      <description>arXiv:2405.19037v2 Announce Type: replace-cross 
Abstract: An earlier paper gives an account of a quest for a satisfactory formalization of the classical informal notion of an algorithm. In this paper, an attempt is made to generalize the results of that quest to the informal notion of an interactive algorithm. The notion of an interactive proto-algorithm is introduced. Interactive algorithms are expected to be equivalence classes of interactive proto-algorithms under an appropriate equivalence relation. As in the non-interactive case, three equivalence relations are defined. Two of them are deemed to be bounds for an appropriate equivalence relation and the third is likely an appropriate one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19037v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>Adversary Resilient Learned Bloom Filters</title>
      <link>https://arxiv.org/abs/2409.06556</link>
      <description>arXiv:2409.06556v3 Announce Type: replace-cross 
Abstract: Creating an adversary resilient construction of the Learned Bloom Filter with provable guarantees is an open problem. We define a strong adversarial model for the Learned Bloom Filter. Our adversarial model extends an existing adversarial model designed for the Classical (i.e not ``Learned'') Bloom Filter by prior work and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT). Using our model, we construct an adversary resilient variant of the Learned Bloom Filter called the Downtown Bodega Filter. We show that: if pseudo-random permutations exist, then an Adversary Resilient Learned Bloom Filter may be constructed with $2\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. We construct a hybrid adversarial model for the case where a fraction of the query workload is chosen by an adversary. We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06556v3</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Allison Bishop, Hayder Tirmazi</dc:creator>
    </item>
    <item>
      <title>Compression with wildcards: All induced metric subgraphs</title>
      <link>https://arxiv.org/abs/2409.08363</link>
      <description>arXiv:2409.08363v2 Announce Type: replace-cross 
Abstract: Driven by applications in the natural, social and computer sciences several algorithms have been proposed to enumerate all sets $X\s V$ of vertices of a graph $G=(V,E)$ that induce a {\it connected} subgraph. We offer two algorithms for enumerating all $X$'s that induce (more exquisite) {\it metric} subgraphs. Specifically, the first algorithm, called {\tt AllMetricSets}, generates these $X$'s in a compressed format. The second algorithm generates all (accessible) metric sets one-by-one but is provably output-polynomial. Mutatis mutandis the same holds for the convex sets $X\s V$, where "convex" is a natural strengthening of "metric". The Mathematica command {\tt BooleanConvert} features prominently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08363v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcel Wild</dc:creator>
    </item>
    <item>
      <title>Better Boosting of Communication Oracles, or Not</title>
      <link>https://arxiv.org/abs/2410.00838</link>
      <description>arXiv:2410.00838v2 Announce Type: replace-cross 
Abstract: Suppose we have a two-party communication protocol for $f$ which allows the parties to make queries to an oracle computing $g$; for example, they may query an Equality oracle. To translate this protocol into a randomized protocol, we must replace the oracle with a randomized subroutine for solving $g$. If $q$ queries are made, the standard technique requires that we boost the error of each subroutine down to $O(1/q)$, leading to communication complexity which grows as $q \log q$. For which oracles $g$ can this naive boosting technique be improved?
  We focus on the oracles which can be computed by constant-cost randomized protocols, and show that the naive boosting strategy can be improved for the Equality oracle but not the 1-Hamming Distance oracle. Two surprising consequences are (1) a new example of a problem where the cost of computing $k$ independent copies grows superlinear in $k$, drastically simplifying the only previous example due to Blais &amp; Brody (CCC 2019); and (2) a new proof that Equality is not complete for the class of constant-cost randomized communication (Harms, Wild, &amp; Zamaraev, STOC 2022; Hambardzumyan, Hatami, &amp; Hatami, Israel Journal of Mathematics 2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00838v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathaniel Harms, Artur Riazanov</dc:creator>
    </item>
    <item>
      <title>Information Design with Unknown Prior</title>
      <link>https://arxiv.org/abs/2410.05533</link>
      <description>arXiv:2410.05533v2 Announce Type: replace-cross 
Abstract: Classical information design models (e.g., Bayesian persuasion and cheap talk) require players to have perfect knowledge of the prior distribution of the state of the world. Our paper studies repeated persuasion problems in which the information designer does not know the prior. The information designer learns to design signaling schemes from repeated interactions with the receiver. We design learning algorithms for the information designer to achieve no regret compared to using the optimal signaling scheme with known prior, under two models of the receiver's decision-making. (1) The first model assumes that the receiver knows the prior and can perform posterior update and best respond to signals. In this model, we design a learning algorithm for the information designer with $O(\log T)$ regret in the general case, and another algorithm with $\Theta(\log \log T)$ regret in the case where the receiver has only two actions. (2) The second model assumes that the receiver does not know the prior and employs a no-regret learning algorithm to take actions. We show that the information designer can achieve regret $O(\sqrt{\mathrm{rReg}(T) T})$, where $\mathrm{rReg}(T)=o(T)$ is an upper bound on the receiver's learning regret. Our work thus provides a learning foundation for the problem of information design with unknown prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05533v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Ce Li</dc:creator>
    </item>
  </channel>
</rss>
