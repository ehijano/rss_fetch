<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Mar 2025 04:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dynamic Indexing Through Learned Indices with Worst-case Guarantees</title>
      <link>https://arxiv.org/abs/2503.05007</link>
      <description>arXiv:2503.05007v1 Announce Type: new 
Abstract: Indexing data is a fundamental problem in computer science. Recently, various papers apply machine learning to this problem.
  For a fixed integer $\varepsilon$, a \emph{learned index} is a function $h : \mathcal{U} \rightarrow [0, n]$ where $\forall q \in \mathcal{U}$, $h(q) \in [\text{rank}(q) - \varepsilon, \text{rank}(q) + \varepsilon]$. These works use machine learning to compute $h$. Then, they store $S$ in a sorted array $A$ and access $A[\lfloor h(q) \rfloor]$ to answer queries in $O(k + \varepsilon + \log |h|)$ time. Here, $k$ denotes the output size and $|h|$ the complexity of $h$. Ferragina and Vinciguerra (VLDB 2020) observe that creating a learned index is a geometric problem. They define the PGM index by restricting $h$ to a piecewise linear function and show a linear-time algorithm to compute a PGM index of approximate minimum complexity.
  Since indexing queries are decomposable, the PGM index may be made dynamic through the logarithmic method. When allowing deletions, range query times deteriorate to worst-case $O(N + \sum\limits_i^{\lceil \log n \rceil } (\varepsilon + \log |h_i|))$ time (where $N$ is the largest size of $S$ seen so far).
  This paper offers a combination of theoretical insights and experiments as we apply techniques from computational geometry to dynamically maintain an approximately minimum-complexity learned index $h : \mathcal{U} \rightarrow [0, n]$ with $O(\log^2 n)$ update time.
  We also prove that if we restrict $h$ to lie in a specific subclass of piecewise-linear functions, then we can combine $h$ and hash maps to support queries in $O(k + \varepsilon + \log |h|)$ time (at the cost of increasing $|h|$). We implement our algorithm and compare it to the existing implementation. Our empirical analysis shows that our solution supports more efficient range queries whenever the update sequence contains many deletions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05007v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emil Toftegaard G{\ae}de, Ivor van der Hoog, Eva Rotenberg, Tord Stordalen</dc:creator>
    </item>
    <item>
      <title>Object Packing and Scheduling for Sequential 3D Printing: a Linear Arithmetic Model and a CEGAR-inspired Optimal Solver</title>
      <link>https://arxiv.org/abs/2503.05071</link>
      <description>arXiv:2503.05071v1 Announce Type: new 
Abstract: We address the problem of object arrangement and scheduling for sequential 3D printing. Unlike the standard 3D printing, where all objects are printed slice by slice at once, in sequential 3D printing, objects are completed one after other. In the sequential case, it is necessary to ensure that the moving parts of the printer do not collide with previously printed objects. We look at the sequential printing problem from the perspective of combinatorial optimization. We propose to express the problem as a linear arithmetic formula, which is then solved using a solver for satisfiability modulo theories (SMT). However, we do not solve the formula expressing the problem of object arrangement and scheduling directly, but we have proposed a technique inspired by counterexample guided abstraction refinement (CEGAR), which turned out to be a key innovation to efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05071v1</guid>
      <category>cs.CG</category>
      <category>cs.AI</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Surynek, Vojt\v{e}ch Bubn\'ik, Luk\'a\v{s} Mat\v{e}na, Petr Kubi\v{s}</dc:creator>
    </item>
    <item>
      <title>On Triangular Separation of Bichromatic Point Sets</title>
      <link>https://arxiv.org/abs/2503.05178</link>
      <description>arXiv:2503.05178v1 Announce Type: new 
Abstract: We address the problem of computing the minimum number of triangles to separate a set of blue points from a set of red points in $\mathbb{R}^2$. A set of triangles is a \emph{separator} of one color from the other if every point of that color is contained in some triangle and no triangle contains points of both colors. We consider several variants of the problem depending on whether the triangles are allowed to overlap or not and whether all points or just the blue points need to be contained in a triangle. We show that computing the minimum cardinality triangular separator of a set of blue points from a set of red points is NP-hard and further investigate worst case bounds on the minimum cardinality of triangular separators for a bichromatic set of $n$ points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05178v1</guid>
      <category>cs.CG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helena Bergold, Arun Kumar Das, Robert Lauff, Manfred Scheucher, Felix Schr\"oder, Marie Diana Sieper</dc:creator>
    </item>
    <item>
      <title>Chasing puppies on orthogonal straight-line plane graphs</title>
      <link>https://arxiv.org/abs/2503.05216</link>
      <description>arXiv:2503.05216v1 Announce Type: new 
Abstract: Assume that you have lost your puppy on an embedded graph. You can walk around on the graph and the puppy will run towards you at infinite speed, always locally minimizing the distance to your current position. Is it always possible for you to reunite with the puppy? We show that if the embedded graph is an orthogonal straight-line embedding the answer is yes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05216v1</guid>
      <category>cs.CG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johanna Ockenfels, Yoshio Okamoto, Patrick Schnider</dc:creator>
    </item>
    <item>
      <title>A Nonlinear Extension of the Variable Projection (VarPro) Method for NURBS-based Conformal Surface Flattening</title>
      <link>https://arxiv.org/abs/2502.19088</link>
      <description>arXiv:2502.19088v2 Announce Type: replace 
Abstract: In the field of computer graphics, conformal surface flattening has been widely studied for tasks such as texture mapping, geometry processing, and mesh generation. Typically, existing methods aim to flatten a given input geometry while preserving conformality as much as possible, meaning the result is only as conformal as possible. By contrast, this study focuses on surfaces that can be flattened conformally without singularities, making the process a coupled problem: the input (or target) surface must be recursively refined while its flattening is computed.
  Although the uniformization theorem or the Riemann mapping theorem guarantees the existence of a conformal flattening for any simply connected, orientable surface, those theorems permit singularities in the flattening. If singularities are not allowed, only a special class of surfaces can be conformally flattened-though many practical surfaces do fall into this class.
  To address this, we develop a NURBS-based approach in which both the input surface and its flattening are refined in tandem, ensuring mutual conformality. Because NURBS surfaces cannot represent singularities, the resulting pair of surfaces is naturally singularity-free. Our work is inspired by the form-finding method by [Miki and Mitchell 2022, 2024], which solves bilinear PDEs by iteratively refining two surfaces together. Building on their demonstration of the effectiveness of variable projection (VarPro), we adopt a similar strategy: VarPro alternates between a linear projection and a nonlinear iteration, leveraging a partially linear (separable) problem structure. However, since our conformal condition separates into two nonlinear subproblems, we introduce a nonlinear extension of VarPro. Although this significantly increases computational cost, the quality of the results is noteworthy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19088v2</guid>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masaaki Miki</dc:creator>
    </item>
    <item>
      <title>Improved Bound on the Number of Pseudoline Arrangements via the Zone Theorem</title>
      <link>https://arxiv.org/abs/2502.20909</link>
      <description>arXiv:2502.20909v2 Announce Type: replace 
Abstract: Pseudoline arrangements are fundamental objects in discrete and computational geometry, and different works have tackled the problem of improving the known bounds on the number of simple arrangements of $n$ pseudolines over the past decades. The lower bound in particular has seen two successive improvements in recent years (Dumitrescu and Mandal in 2020 and Cort\'es K\"uhnast et al. in 2024). Here we focus on the upper bound, and show that for large enough $n$, there are at most $2^{0.6496n^2}$ different simple arrangements of $n$ pseudolines. This follows a series of incremental improvements starting with work by Knuth in 1992 showing a bound of roughly $2^{0.7925n^2},$ then a bound of $2^{0.6975n^2}$ by Felsner in 1997, and finally the previous best known bound of $2^{0.6572n^2}$ by Felsner and Valtr in 2011. The improved bound presented here follows from a simple argument to combine the approach of this latter work with the use of the Zone Theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20909v2</guid>
      <category>cs.CG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Dallant</dc:creator>
    </item>
    <item>
      <title>A Framework for Algorithm Stability</title>
      <link>https://arxiv.org/abs/1704.08000</link>
      <description>arXiv:1704.08000v3 Announce Type: replace-cross 
Abstract: We say that an algorithm is stable if small changes in the input result in small changes in the output. This kind of algorithm stability is particularly relevant when analyzing and visualizing time-varying data. Stability in general plays an important role in a wide variety of areas, such as numerical analysis, machine learning, and topology, but is poorly understood in the context of (combinatorial) algorithms. In this paper we present a framework for analyzing the stability of algorithms. We focus in particular on the trade-off between the stability of an algorithm and the quality of the solution it computes. Our framework allows for three types of stability analysis with increasing degrees of complexity: event stability, topological stability, and Lipschitz stability. In addition, we need to refine the model of an algorithm based on how it interacts with the time-varying data, for which we consider several options. We demonstrate the use of our stability framework by applying it to kinetic Euclidean minimum spanning trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:1704.08000v3</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wouter Meulemans, Bettina Speckmann, Kevin Verbeek, Jules Wulms</dc:creator>
    </item>
    <item>
      <title>The Structural Complexity of Matrix-Vector Multiplication</title>
      <link>https://arxiv.org/abs/2502.21240</link>
      <description>arXiv:2502.21240v2 Announce Type: replace-cross 
Abstract: We consider the problem of preprocessing an $n\times n$ matrix M, and supporting queries that, for any vector v, returns the matrix-vector product Mv. This problem has been extensively studied in both theory and practice: on one side, practitioners have developed algorithms that are highly efficient in practice, whereas theoreticians have proven that the problem cannot be solved faster than naive multiplication in the worst-case. This lower bound holds even in the average-case, implying that existing average-case analyses cannot explain this gap between theory and practice. Therefore, we study the problem for structured matrices. We show that for $n\times n$ matrices of VC-dimension d, the matrix-vector multiplication problem can be solved with $\tilde{O}(n^2)$ preprocessing and $\tilde O(n^{2-1/d})$ query time. Given the low constant VC-dimensions observed in most real-world data, our results posit an explanation for why the problem can be solved so much faster in practice. Moreover, our bounds hold even if the matrix does not have a low VC-dimension, but is obtained by (possibly adversarially) corrupting at most a subquadratic number of entries of any unknown low VC-dimension matrix. Our results yield the first non-trivial upper bounds for many applications. In previous works, the online matrix-vector hypothesis (conjecturing that quadratic time is needed per query) was used to prove many conditional lower bounds, showing that it is impossible to compute and maintain high-accuracy estimates for shortest paths, Laplacian solvers, effective resistance, and triangle detection in graphs subject to node insertions and deletions in subquadratic time. Yet, via a reduction to our matrix-vector-multiplication result, we show we can maintain the aforementioned problems efficiently if the input is structured, providing the first subquadratic upper bounds in the high-accuracy regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21240v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Anand, Jan van den Brand, Rose McCarty</dc:creator>
    </item>
  </channel>
</rss>
