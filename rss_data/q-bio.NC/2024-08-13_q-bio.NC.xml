<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2024 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Testing the Brain Wave Hypothesis</title>
      <link>https://arxiv.org/abs/2408.05368</link>
      <description>arXiv:2408.05368v1 Announce Type: new 
Abstract: It has been proposed that there is a wave excitation in animal brains, whose function is to represent three-dimensional space around the animal as a working spatial memory. After surveying the evidence supporting the hypothesis, I discuss ways in which it can be tested. There are many ways to investigate it, theoretically and experimentally. They include connectome studies, computational modelling, experimental neuroscience, genomics and proteomics, studies of animal behaviour, and biophysics. If the wave exists, there is a compelling case to identify it as the source of consciousness. This would advance our understanding of one of the greatest scientific challenges of all time, while changing our view of the human mind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05368v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Worden</dc:creator>
    </item>
    <item>
      <title>Recurrence Resonance -- Noise-Enhanced Dynamics in Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2408.05579</link>
      <description>arXiv:2408.05579v1 Announce Type: new 
Abstract: In specific motifs of three recurrently connected neurons with probabilistic response, the spontaneous information flux, defined as the mutual information between subsequent states, has been shown to increase by adding ongoing white noise of some optimal strength to each of the neurons \cite{krauss2019recurrence}. However, the precise conditions for and mechanisms of this phenomenon called 'recurrence resonance' (RR) remain largely unexplored. Using Boltzmann machines of different sizes and with various types of weight matrices, we show that RR can generally occur when a system has multiple dynamical attractors, but is trapped in one or a few of them. In probabilistic networks, the phenomenon is bound to a suitable observation time scale, as the system could autonomously access its entire attractor landscape even without the help of external noise, given enough time. Yet, even in large systems, where time scales for observing RR in the full network become too long, the resonance can still be detected in small subsets of neurons. Finally, we show that short noise pulses can be used to transfer recurrent neural networks, both probabilistic and deterministic, between their dynamical attractors. Our results are relevant to the fields of reservoir computing and neuroscience, where controlled noise may turn out a key factor for efficient information processing leading to more robust and adaptable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05579v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claus Metzner, Achim Schilling, Andreas Maier, Patrick Krauss</dc:creator>
    </item>
    <item>
      <title>Geometrical determinant of nonlinear synaptic integration in human cortical pyramidal neurons</title>
      <link>https://arxiv.org/abs/2408.05633</link>
      <description>arXiv:2408.05633v1 Announce Type: new 
Abstract: Neurons integrate synaptic inputs and convert them to action potential output at electrically distant locations. The computational power of a neuron is hence enhanced by subcellular compartmentalization and nonlinear synaptic integration, but the biophysical determinants of these features in human neurons are not completely understood. By examining the synaptic input-output function of human neocortical pyramidal neurons, we found that the nonlinearity threshold at the soma was linearly determined by the shortest path distance from the synapse to the apical trunk, and the slope of this relationship was consistent throughout the dendritic arbor. Analogous rules were found from both supragranular and infragranular layers of the rodent cortex, suggesting that these represent a fundamental property of pyramidal neurons. Additionally, we found that neurons associated with tumor or epilepsy had distinct membrane properties, but the nonlinearity threshold was shifted in amplitude such that the slope of its relationship with synaptic distance remained consistent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05633v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jaeyoung Yoon</dc:creator>
    </item>
    <item>
      <title>Status epilepticus and thinning of the entorhinal cortex</title>
      <link>https://arxiv.org/abs/2408.05789</link>
      <description>arXiv:2408.05789v1 Announce Type: new 
Abstract: Status epilepticus (SE) carries risks of morbidity and mortality. Experimental studies have implicated the entorhinal cortex in prolonged seizures; however, studies in large human cohorts are limited. We hypothesised that individuals with temporal lobe epilepsy (TLE) and a history of SE would have more severe entorhinal atrophy compared to others with TLE and no history of SE.
  357 individuals with drug resistant temporal lobe epilepsy (TLE) and 100 healthy controls were scanned on a 3T MRI. For all subjects the cortex was segmented, parcellated, and the thickness calculated from the T1-weighted anatomical scan. Subcortical volumes were derived similarly. Cohen's d and Wilcoxon rank-sum tests respectively were used to capture effect sizes and significance.
  Individuals with TLE and SE had reduced entorhinal thickness compared to those with TLE and no history of SE. The entorhinal cortex was more atrophic ipsilaterally (d=0.51, p&lt;0.001) than contralaterally (d=0.37, p=0.01). Reductions in ipsilateral entorhinal thickness were present in both left TLE (n=22:176, d=0.78, p&lt;0.001), and right TLE (n=19:140, d=0.31, p=0.04), albeit with a smaller effect size in right TLE. Several other regions exhibited atrophy in individuals with TLE, but these did not relate to a history of SE.
  These findings suggest potential involvement or susceptibility of the entorhinal cortex in prolonged seizures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05789v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Horsley, Yujiang Wang, Callum Simpson, Vyte Janiukstyte, Karoline Leiberg, Beth Little, Jane de Tisi, John Duncan, Peter N. Taylor</dc:creator>
    </item>
    <item>
      <title>Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences</title>
      <link>https://arxiv.org/abs/2408.05798</link>
      <description>arXiv:2408.05798v1 Announce Type: new 
Abstract: The vertebrate hippocampus is believed to use recurrent connectivity in area CA3 to support episodic memory recall from partial cues. This brain area also contains place cells, whose location-selective firing fields implement maps supporting spatial memory. Here we show that place cells emerge in networks trained to remember temporally continuous sensory episodes. We model CA3 as a recurrent autoencoder that recalls and reconstructs sensory experiences from noisy and partially occluded observations by agents traversing simulated rooms. The agents move in realistic trajectories modeled from rodents and environments are modeled as high-dimensional sensory experience maps. Training our autoencoder to pattern-complete and reconstruct experiences with a constraint on total activity causes spatially localized firing fields, i.e., place cells, to emerge in the encoding layer. The emergent place fields reproduce key aspects of hippocampal phenomenology: a) remapping (maintenance of and reversion to distinct learned maps in different environments), implemented via repositioning of experience manifolds in the network's hidden layer, b) orthogonality of spatial representations in different arenas, c) robust place field emergence in differently shaped rooms, with single units showing multiple place fields in large or complex spaces, and d) slow representational drift of place fields. We argue that these results arise because continuous traversal of space makes sensory experience temporally continuous. We make testable predictions: a) rapidly changing sensory context will disrupt place fields, b) place fields will form even if recurrent connections are blocked, but reversion to previously learned representations upon remapping will be abolished, c) the dimension of temporally smooth experience sets the dimensionality of place fields, including during virtual navigation of abstract spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05798v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoze Wang, Ronald W. Di Tullio, Spencer Rooke, Vijay Balasubramanian</dc:creator>
    </item>
    <item>
      <title>Identifying Feedforward and Feedback Controllable Subspaces of Neural Population Dynamics</title>
      <link>https://arxiv.org/abs/2408.05875</link>
      <description>arXiv:2408.05875v1 Announce Type: new 
Abstract: There is overwhelming evidence that cognition, perception, and action rely on feedback control. However, if and how neural population dynamics are amenable to different control strategies is poorly understood, in large part because machine learning methods to directly assess controllability in neural population dynamics are lacking. To address this gap, we developed a novel dimensionality reduction method, Feedback Controllability Components Analysis (FCCA), that identifies subspaces of linear dynamical systems that are most feedback controllable based on a new measure of feedback controllability. We further show that PCA identifies subspaces of linear dynamical systems that maximize a measure of feedforward controllability. As such, FCCA and PCA are data-driven methods to identify subspaces of neural population data (approximated as linear dynamical systems) that are most feedback and feedforward controllable respectively, and are thus natural contrasts for hypothesis testing. We developed new theory that proves that non-normality of underlying dynamics determines the divergence between FCCA and PCA solutions, and confirmed this in numerical simulations. Applying FCCA to diverse neural population recordings, we find that feedback controllable dynamics are geometrically distinct from PCA subspaces and are better predictors of animal behavior. Our methods provide a novel approach towards analyzing neural population dynamics from a control theoretic perspective, and indicate that feedback controllable subspaces are important for behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05875v1</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankit Kumar, Loren M. Frank, Kristofer E. Bouchard</dc:creator>
    </item>
    <item>
      <title>Mechanical problem solving in Goffin's cockatoos -- Towards modeling complex behavior</title>
      <link>https://arxiv.org/abs/2408.05967</link>
      <description>arXiv:2408.05967v1 Announce Type: new 
Abstract: Research continues to accumulate evidence that Goffin's cockatoos (Cacatua goffiniana) can solve wide sets of mechanical problems, such as tool use, tool manufacture, and solving mechanical puzzles. However, the proximate mechanisms underlying this adaptive behavior are largely unknown. In this study, we analyze how three Goffin's cockatoos learn to solve a specific mechanical puzzle, a lockbox. The observed behavior results from the interaction between a complex environment (the lockbox) and different processes that jointly govern the animals' behavior. We thus jointly analyze the parrots' (1) engagement, (2) sensorimotor skill learning, and (3) action selection. We find that neither of these aspects could solely explain the animals' behavioral adaptation and that a plausible model of proximate mechanisms (including adaptation) should thus also jointly address these aspects. We accompany this analysis with a discussion of methods that may be used to identify such mechanisms. A major point we want to make is, that it is implausible to reliably identify a detailed model from the limited data of one or a few studies. Instead, we advocate for a more coarse approach that first establishes constraints on proximate mechanisms before specific, detailed models are formulated. We exercise this idea on the data we present in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05967v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Baum, Theresa Roessler, Antonio J. Osuna-Mascar\'o, Alice Auersperg, Oliver Brock</dc:creator>
    </item>
    <item>
      <title>Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm</title>
      <link>https://arxiv.org/abs/2408.05834</link>
      <description>arXiv:2408.05834v1 Announce Type: cross 
Abstract: Unexpected stimuli induce "error" or "surprise" signals in the brain. The theory of predictive coding promises to explain these observations in terms of Bayesian inference by suggesting that the cortex implements variational inference in a probabilistic graphical model. However, when applied to machine learning tasks, this family of algorithms has yet to perform on par with other variational approaches in high-dimensional, structured inference problems. To address this, we introduce a novel predictive coding algorithm for structured generative models, that we call divide-and-conquer predictive coding (DCPC). DCPC differs from other formulations of predictive coding, as it respects the correlation structure of the generative model and provably performs maximum-likelihood updates of model parameters, all without sacrificing biological plausibility. Empirically, DCPC achieves better numerical performance than competing algorithms and provides accurate inference in a number of problems not previously addressed with predictive coding. We provide an open implementation of DCPC in Pyro on Github.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05834v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eli Sennesh, Hao Wu, Tommaso Salvatori</dc:creator>
    </item>
    <item>
      <title>Brain-grounding of semantic vectors improves neural decoding of visual stimuli</title>
      <link>https://arxiv.org/abs/2403.15176</link>
      <description>arXiv:2403.15176v2 Announce Type: replace 
Abstract: Developing algorithms for accurate neural decoding of mental contents is a long-cherished goal in the field of neuroscience. Brain decoding is typically employed by training machine learning models to map neural data into a pretrained feature vector representation of stimuli. These vectors are usually driven from imagebased and/or text-based feature spaces. This implies that their intrinsic characteristics might be fundamentally different than those encoded in neural activity patterns, resulting in limiting the capability of brain decoders to accurately learn this mapping. To address this issue, we propose a representation learning framework, termed brain-grounding of semantic vectors, that fine-tunes pretrained feature vectors to better align with the structure of neural representation of visual stimuli in the human brain. We trained this model with functional magnetic resonance imaging (fMRI) of 150 visual stimuli categories and then performed zero-shot brain decoding on 1) fMRI, 2) magnetoencephalography (MEG), and 3) electrocorticography (ECoG) neural data of visual stimuli. Our results demonstrated that by using the fMRI-based brain-grounded vectors, the zero-shot decoding accuracy of brain data from all three neuroimaging modalities increases. These findings underscore the potential of incorporating a richer array of brain-derived features to enhance the performance of brain decoding algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15176v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shirin Vafaei, Ryohei Fukuma, Huixiang Yang, Haruhiko Kishima, Takufumi Yanagisawa</dc:creator>
    </item>
    <item>
      <title>Localising the Seizure Onset Zone from Single-Pulse Electrical Stimulation Responses with a CNN Transformer</title>
      <link>https://arxiv.org/abs/2403.20324</link>
      <description>arXiv:2403.20324v2 Announce Type: replace-cross 
Abstract: Epilepsy is one of the most common neurological disorders, often requiring surgical intervention when medication fails to control seizures. For effective surgical outcomes, precise localisation of the epileptogenic focus - often approximated through the Seizure Onset Zone (SOZ) - is critical yet remains a challenge. Active probing through electrical stimulation is already standard clinical practice for identifying epileptogenic areas. Our study advances the application of deep learning for SOZ localisation using Single-Pulse Electrical Stimulation (SPES) responses, with two key contributions. Firstly, we implement an existing deep learning model to compare two SPES analysis paradigms: divergent and convergent. These paradigms evaluate outward and inward effective connections, respectively. We assess the generalisability of these models to unseen patients and electrode placements using held-out test sets. Our findings reveal a notable improvement in moving from a divergent (AUROC: 0.574) to a convergent approach (AUROC: 0.666), marking the first application of the latter in this context. Secondly, we demonstrate the efficacy of CNN Transformers with cross-channel attention in handling heterogeneous electrode placements, increasing the AUROC to 0.730. These findings represent a significant step in modelling patient-specific intracranial EEG electrode placements in SPES. Future work will explore integrating these models into clinical decision-making processes to bridge the gap between deep learning research and practical healthcare applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20324v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamie Norris, Aswin Chari, Dorien van Blooijs, Gerald Cooray, Karl Friston, Martin Tisdall, Richard Rosch</dc:creator>
    </item>
  </channel>
</rss>
