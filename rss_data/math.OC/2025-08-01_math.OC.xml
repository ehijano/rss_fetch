<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Aug 2025 04:01:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive direct search algorithms for constrained optimization</title>
      <link>https://arxiv.org/abs/2507.23054</link>
      <description>arXiv:2507.23054v1 Announce Type: new 
Abstract: Two families of directional direct search methods have emerged in derivative-free and blackbox optimization (DFO and BBO), each based on distinct principles: Mesh Adaptive Direct Search (MADS) and Sufficient Decrease Direct Search (SDDS). MADS restricts trial points to a mesh and accepts any improvement, ensuring none are missed, but at the cost of restraining the placement of trial points. SDDS allows greater freedom by evaluating points anywhere in the space, but accepts only those yielding a sufficient decrease in the objective function value, which may lead to discarding improving points.
  This work introduces a new class of methods, Adaptive Direct Search (ADS), which uses a novel acceptance rule based on the so-called punctured space, avoiding both meshes and sufficient decrease conditions. ADS enables flexible search while addressing the limitations of MADS and SDDS, and retains the theoretical foundations of directional direct search. Computational results in constrained and unconstrained settings highlight its performance compared to both MADS and SDDS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23054v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Audet, Th\'eo Denorme, Youssef Diouane, S\'ebastien Le Digabel, Christophe Tribes</dc:creator>
    </item>
    <item>
      <title>Stability-Constrained AC Optimal Power Flow -- A Gaussian Process-Based Approach</title>
      <link>https://arxiv.org/abs/2507.23094</link>
      <description>arXiv:2507.23094v1 Announce Type: new 
Abstract: The Alternating Current Optimal Power Flow (ACOPF) problem is a core task in power system operations, aimed at determining cost-effective generation dispatch while satisfying physical and operational constraints. However, conventional ACOPF formulations rely on steady-state models and neglect the dynamic behavior of generators, which can lead to operating points that are economically optimal but dynamically unstable. This paper proposes a novel, data-driven approach to incorporate generator dynamics into the ACOPF using Gaussian Process (GP) models. Specifically, it introduces an exponential surrogate function to characterize the stability of solutions to the differential equations governing synchronous generator dynamics. The exponent, which indicates whether system trajectories decay (stable) or grow (unstable), is learned as a function of the bus voltage using GP regression. Crucially, the framework enables probabilistic stability assessment to be integrated directly into the optimization process. The resulting dynamics-aware ACOPF formulation identifies operating points that satisfy both operational safety and dynamic stability criteria. Numerical experiments on the IEEE 39-bus, 57-bus, and 118-bus systems demonstrate that the proposed method efficiently captures generator dynamics using limited training data, leading to more reliable and robust decisions across a wide range of operating conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23094v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincenzo Di Vito, Kaarthik Sundar, Ferdinando Fioretto, Deepjyoti Deka</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2507.23155</link>
      <description>arXiv:2507.23155v1 Announce Type: new 
Abstract: In this paper, we study the problem of solving a simple bilevel optimization problem, where the upper-level objective is minimized over the solution set of the lower-level problem. We focus on the general setting in which both the upper- and lower-level objectives are smooth but potentially nonconvex. Due to the absence of additional structural assumptions for the lower-level objective-such as convexity or the Polyak-{\L}ojasiewicz (PL) condition-guaranteeing global optimality is generally intractable. Instead, we introduce a suitable notion of stationarity for this class of problems and aim to design a first-order algorithm that finds such stationary points in polynomial time. Intuitively, stationarity in this setting means the upper-level objective cannot be substantially improved locally without causing a larger deterioration in the lower-level objective. To this end, we show that a simple and implementable variant of the dynamic barrier gradient descent (DBGD) framework can effectively solve the considered nonconvex simple bilevel problems up to stationarity. Specifically, to reach an $(\epsilon_f, \epsilon_g)$-stationary point-where $\epsilon_f$ and $\epsilon_g$ denote the target stationarity accuracies for the upper- and lower-level objectives, respectively-the considered method achieves a complexity of $\mathcal{O}\left(\max\left(\epsilon_f^{-\frac{3+p}{1+p}}, \epsilon_g^{-\frac{3+p}{2}}\right)\right)$, where $p \geq 0$ is an arbitrary constant balancing the terms. To the best of our knowledge, this is the first complexity result for a discrete-time algorithm that guarantees joint stationarity for both levels in general nonconvex simple bilevel problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23155v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jincheng Cao, Ruichen Jiang, Erfan Yazdandoost Hamedani, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>FMIP: Multimodal Flow Matching for Mixed Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2507.23390</link>
      <description>arXiv:2507.23390v1 Announce Type: new 
Abstract: Mixed-Integer Linear Programming (MILP) is a cornerstone of mathematical optimization, enabling the modeling of complex decision-making problems involving both integer and continuous variables. Despite its versatility, most MILP problems are NP-complete, making them challenging to solve in practice. Existing graph neural network (GNN)-based heuristics aim to reduce problem scale by predicting only the solutions on integer variables for a given instance, struggling to capture the intricate interplay between continuous and integer variables and lack sufficient representational power. To address these limitations, we propose FMIP, a novel multimodal flow-matching framework that models the joint distribution over integer and continuous variables in the mixed solution space of MILP. To enable more accurate and scalable heuristics, FMIP integrates a guidance mechanism to guide solution sampling under both objective function optimization and constraint satisfaction. We evaluate FMIP on seven standard MILP benchmarks. Our experiments show that FMIP improves solution quality by 50.04% on average over existing GNN-based predictive baselines. These results highlight FMIP's potential as a powerful new approach for developing learning based MILP solution strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23390v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongpei Li, Hui Yuan, Han Zhang, Dongdong Ge, Mengdi Wang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Popov Mirror-Prox Method for Variational Inequalities</title>
      <link>https://arxiv.org/abs/2507.23395</link>
      <description>arXiv:2507.23395v1 Announce Type: new 
Abstract: This paper establishes the convergence properties of the Popov mirror-prox algorithm for solving stochastic and deterministic variational inequalities (VIs) under a polynomial growth condition on the mapping variation. Unlike existing methods that require prior knowledge of problem-specific parameters, we propose step-size schemes that are entirely parameter-free in both constant and diminishing forms. For stochastic and deterministic monotone VIs, we establish optimal convergence rates in terms of the dual gap function over a bounded constraint set. Additionally, for deterministic VIs with H\"older continuous mapping, we prove convergence in terms of the residual function without requiring a bounded set or a monotone mapping, provided a Minty solution exists. This allows our method to address certain classes of non-monotone VIs. However, knowledge of the H\"older exponent is necessary to achieve the best convergence rates in this case. By extending mirror-prox techniques to mappings with arbitrary polynomial growth, our work bridges an existing gap in the literature. We validate our theoretical findings with empirical results on matrix games, piecewise quadratic functions, and image classification tasks using ResNet-18.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23395v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Chakraborty, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>Biobjective optimization with M-convex functions</title>
      <link>https://arxiv.org/abs/2507.23423</link>
      <description>arXiv:2507.23423v1 Announce Type: new 
Abstract: In this paper, we deal with two ingredients that, as far as we know, have not been combined until now: multiobjective optimization and discrete convex analysis. First, we show that the entire Pareto optimal value set can be obtained in polynomial time for biobjective optimization problems with discrete convex functions, in particular, involving an M$^\natural$-convex function and a linear function with binary coefficients. We also observe that a more efficient algorithm can be obtained in the special case where the M$^\natural$-convex function is M-convex. Additionally, we present a polynomial-time method for biobjective optimization problems that combine M$^\natural$-convex function minimization with lexicographic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23423v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ellen H. Fukuda, Satoru Iwata, Itsuki Nakagawa</dc:creator>
    </item>
    <item>
      <title>Convergence rates of Newton's method for strongly self-concordant minimization</title>
      <link>https://arxiv.org/abs/2507.23558</link>
      <description>arXiv:2507.23558v1 Announce Type: new 
Abstract: Newton's method has been thoroughly studied for the class of self-concordant functions. However, a local analysis specific to strongly self-concordant functions (a subclass of the former) is missing from the literature. The local quadratic rate of strongly self-concordant functions follows, of course, from the known results for self-concordant functions. However, it is not known whether strongly self-concordant functions enjoy better theoretical properties. In this paper, we study the local convergence of Newton's method for this subclass. We show that its quadratic convergence rate differs from that of general self-concordant functions. In particular, it is provably faster for a wide range of objective functions and benefits from a larger region of local convergence. Thus, the results of this paper close the gap in the theoretical understanding of Newton's method applied to strongly self-concordant functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23558v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Tsipinakis, Panos Parpas</dc:creator>
    </item>
    <item>
      <title>Combinatorial Approaches for Embedded Feature Selection in Nonlinear SVMs</title>
      <link>https://arxiv.org/abs/2507.23711</link>
      <description>arXiv:2507.23711v1 Announce Type: new 
Abstract: Embedded Feature Selection (FS) is a classical approach for interpretable machine learning, aiming to identify the most relevant features of a dataset while simultaneously training the model. We consider an approach based on a hard cardinality constraint for nonlinear SVMs. To the best of our knowledge, hard-constraint approaches have been proposed only for the primal formulation of linear SVMs. In contrast, we embed a hard cardinality constraint directly into the dual of a nonlinear SVM, guaranteeing strict control over the number of selected features while still leveraging kernelization. We formulate the problem as a Mixed-Integer Nonlinear Programming (MINLP) model. As a first contribution, we propose a local search metaheuristic applicable to general nonlinear kernels. Our second and main contribution is a decomposition framework that alternates optimization between two subproblems: one involving only continuous variables and the other involving only binary variables. For polynomial kernels, we show that the binary subproblem reduces to a submodular function maximization under a cardinality constraint, enabling the use of scalable submodular maximization algorithms within the alternating optimization process. Numerical experiments demonstrate that our algorithms significantly outperform standard methods for solving the proposed MINLPs, providing more effective solutions to the addressed feature selection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23711v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico D'Onofrio, Yuri Faenza, Laura Palagi</dc:creator>
    </item>
    <item>
      <title>Adaptive Stepsize Selection in Decentralized Convex Optimization</title>
      <link>https://arxiv.org/abs/2507.23725</link>
      <description>arXiv:2507.23725v1 Announce Type: new 
Abstract: We study decentralized optimization where multiple agents minimize the average of their (strongly) convex, smooth losses over a communication graph. Convergence of the existing decentralized methods generally hinges on an apriori, proper selection of the stepsize. Choosing this value is notoriously delicate: (i) it demands global knowledge from all the agents of the graph's connectivity and every local smoothness/strong-convexity constants--information they rarely have; (ii) even with perfect information, the worst-case tuning forces an overly small stepsize, slowing convergence in practice; and (iii) large-scale trial-and-error tuning is prohibitive. This work introduces a decentralized algorithm that is fully adaptive in the choice of the agents' stepsizes, without any global information and using only neighbor-to-neighbor communications--agents need not even know whether the problem is strongly convex. The algorithm retains strong guarantees: it converges at \emph{linear} rate when the losses are strongly convex and at \emph{sublinear} rate otherwise, matching the best-known rates of (nonadaptive) parameter-dependent methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23725v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ilya Kuruzov, Xiaokai Chen, Gesualdo Scutari, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>A Smoothing Newton Method for Rank-one Matrix Recovery</title>
      <link>https://arxiv.org/abs/2507.23017</link>
      <description>arXiv:2507.23017v1 Announce Type: cross 
Abstract: We consider the phase retrieval problem, which involves recovering a rank-one positive semidefinite matrix from rank-one measurements. A recently proposed algorithm based on Bures-Wasserstein gradient descent (BWGD) exhibits superlinear convergence, but it is unstable, and existing theory can only prove local linear convergence for higher rank matrix recovery. We resolve this gap by revealing that BWGD implements Newton's method with a nonsmooth and nonconvex objective. We develop a smoothing framework that regularizes the objective, enabling a stable method with rigorous superlinear convergence guarantees. Experiments on synthetic data demonstrate this superior stability while maintaining fast convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23017v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Maunu, Gabriel Abreu</dc:creator>
    </item>
    <item>
      <title>Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint Learned by Diffusion Models</title>
      <link>https://arxiv.org/abs/2507.23443</link>
      <description>arXiv:2507.23443v1 Announce Type: cross 
Abstract: We introduce an adjoint-based aerodynamic shape optimization framework that integrates a diffusion model trained on existing designs to learn a smooth manifold of aerodynamically viable shapes. This manifold is enforced as an equality constraint to the shape optimization problem. Central to our method is the computation of adjoint gradients of the design objectives (e.g., drag and lift) with respect to the manifold space. These gradients are derived by first computing shape derivatives with respect to conventional shape design parameters (e.g., Hicks-Henne parameters) and then backpropagating them through the diffusion model to its latent space via automatic differentiation. Our framework preserves mathematical rigor and can be integrated into existing adjoint-based design workflows with minimal modification. Demonstrated on extensive transonic RANS airfoil design cases using off-the-shelf and general-purpose nonlinear optimizers, our approach eliminates ad hoc parameter tuning and variable scaling, maintains robustness across initialization and optimizer choices, and achieves superior aerodynamic performance compared to conventional approaches. This work establishes how AI generated priors integrates effectively with adjoint methods to enable robust, high-fidelity aerodynamic shape optimization through automatic differentiation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23443v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Chen, Emre Oezkaya, Jan Rottmayer, Nicolas R. Gauger, Zebang Shen, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level</title>
      <link>https://arxiv.org/abs/2507.23512</link>
      <description>arXiv:2507.23512v1 Announce Type: cross 
Abstract: Gradient clipping is a fundamental tool in Deep Learning, improving the high-probability convergence of stochastic first-order methods like SGD, AdaGrad, and Adam under heavy-tailed noise, which is common in training large language models. It is also a crucial component of Differential Privacy (DP) mechanisms. However, existing high-probability convergence analyses typically require the clipping threshold to increase with the number of optimization steps, which is incompatible with standard DP mechanisms like the Gaussian mechanism. In this work, we close this gap by providing the first high-probability convergence analysis for DP-Clipped-SGD with a fixed clipping level, applicable to both convex and non-convex smooth optimization under heavy-tailed noise, characterized by a bounded central $\alpha$-th moment assumption, $\alpha \in (1,2]$. Our results show that, with a fixed clipping level, the method converges to a neighborhood of the optimal solution with a faster rate than the existing ones. The neighborhood can be balanced against the noise introduced by DP, providing a refined trade-off between convergence speed and privacy guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23512v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saleh Vatan Khah, Savelii Chezhegov, Shahrokh Farahmand, Samuel Horv\'ath, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Robust Nonlinear Optimal Control via System Level Synthesis</title>
      <link>https://arxiv.org/abs/2301.04943</link>
      <description>arXiv:2301.04943v3 Announce Type: replace 
Abstract: This paper addresses the problem of finite horizon constrained robust optimal control for nonlinear systems subject to norm-bounded disturbances. To this end, the underlying uncertain nonlinear system is decomposed based on a first-order Taylor series expansion into a nominal system and an error (deviation) described as an uncertain linear time-varying system. This decomposition allows us to leverage system level synthesis to jointly optimize an affine error feedback, a nominal nonlinear trajectory, and, most importantly, a dynamic linearization error over-bound used to ensure robust constraint satisfaction for the nonlinear system. The proposed approach thereby results in less conservative planning compared with state-of-the-art techniques. We demonstrate the benefits of the proposed approach to control the rotational motion of a rigid body subject to state and input constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.04943v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3929/ethz-b-000744470</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Automatic Control, Vol. 70, No. 7, 2025, pp. 4780-4787</arxiv:journal_reference>
      <dc:creator>Antoine P. Leeman, Johannes K\"ohler, Andrea Zanelli, Samir Bennani, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Momentum-based gradient descent methods for Lie groups</title>
      <link>https://arxiv.org/abs/2404.09363</link>
      <description>arXiv:2404.09363v2 Announce Type: replace 
Abstract: Polyak's Heavy Ball (PHB; Polyak, 1964), a.k.a. Classical Momentum, and Nesterov's Accelerated Gradient (NAG; Nesterov, 1983) are well-established momentum-descent methods for optimization. Although the latter generally outperforms the former, primarily, generalizations of PHB-like methods to nonlinear spaces have not been sufficiently explored in the literature. In this paper, we propose a generalization of NAG-like methods for Lie group optimization. This generalization is based on the variational one-to-one correspondence between classical and accelerated momentum methods (Campos et al., 2023). We provide numerical experiments for chosen retractions on the group of rotations based on the Frobenius norm and the Rosenbrock function to demonstrate the effectiveness of our proposed methods, and that align with results of the Euclidean case, that is, a faster convergence rate for NAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09363v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>C\'edric M. Campos, David Mart\'in de Diego, Jos\'e Torrente</dc:creator>
    </item>
    <item>
      <title>Optimal Placement and Coordinated Scheduling of Distributed Space-Based Lasers for Orbital Debris Remediation</title>
      <link>https://arxiv.org/abs/2409.03146</link>
      <description>arXiv:2409.03146v3 Announce Type: replace 
Abstract: The significant expansion of the orbital debris population poses a serious threat to the safety and sustainability of space operations. This paper investigates orbital debris remediation through a constellation of collaborative space-based lasers, leveraging the principle of momentum transfer onto debris via laser ablation. A novel delta-v vector analysis framework quantifies the cumulative effects of multiple concurrent laser-to-debris (L2D) engagements by utilizing the vector composition of the imparted delta-v vectors. The paper formulates the Concurrent Location-Scheduling Optimization Problem (CLSP) to optimize the placement of laser platforms and the scheduling of L2D engagements, aiming to maximize debris remediation capacity. Given the computational intractability of the CLSP, a decomposition strategy is employed, yielding two sequential subproblems: (1) determining optimal laser platform locations via the Maximal Covering Location Problem, and (2) scheduling L2D engagements using a novel integer linear programming approach to maximize debris remediation capacity. Computational experiments evaluate the efficacy of the proposed framework across diverse mission scenarios, demonstrating critical constellation functions such as collaborative and controlled nudging, deorbiting, and just-in-time collision avoidance. A sensitivity analysis further explores the impact of varying the number and distribution of laser platforms on debris remediation capacity, offering insights into optimizing the performance of space-based laser constellations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03146v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David O. Williams Rogers, Matthew C. Fox, Paul R. Stysley, Hang Woon Lee</dc:creator>
    </item>
    <item>
      <title>Fully Coupled Nonlinear FBS$\Delta$Es: Solvability and LQ Control Insights</title>
      <link>https://arxiv.org/abs/2410.01749</link>
      <description>arXiv:2410.01749v2 Announce Type: replace 
Abstract: This paper explores a class of fully coupled nonlinear forward-backward stochastic difference equations (FBS$\Delta$Es). Building on insights from linear quadratic optimal control problems, we introduce a more relaxed framework of domination-monotonicity conditions specifically designed for discrete systems. Utilizing these conditions, we apply the method of continuation to demonstrate the unique solvability of the fully coupled FBS$\Delta$Es and derive a set of solution estimates. Moreover, our results have considerable implications for various related linear quadratic (LQ) problems, particularly where stochastic Hamiltonian systems are aligned with the FBS$\Delta$Es meeting these introduced domination-monotonicity conditions. As a result, solving the associated stochastic Hamiltonian systems allows us to derive explicit expressions for the unique optimal controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01749v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhipeng Niu, Qingxin Meng, Xun Li, Maoning Tang</dc:creator>
    </item>
    <item>
      <title>Physics-informed Gaussian Processes as Linear Model Predictive Controller</title>
      <link>https://arxiv.org/abs/2412.04502</link>
      <description>arXiv:2412.04502v2 Announce Type: replace 
Abstract: We introduce a novel algorithm for controlling linear time invariant systems in a tracking problem. The controller is based on a Gaussian Process (GP) whose realizations satisfy a system of linear ordinary differential equations with constant coefficients. Control inputs for tracking are determined by conditioning the prior GP on the setpoints, i.e. control as inference. The resulting Model Predictive Control scheme incorporates pointwise soft constraints by introducing virtual setpoints to the posterior Gaussian process. We show theoretically that our controller satisfies open-loop stability for the optimal control problem by leveraging general results from Bayesian inference and demonstrate this result in a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04502v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\"orn Tebbe, Andreas Besginow, Markus Lange-Hegermann</dc:creator>
    </item>
    <item>
      <title>Fully stochastic trust-region methods with Barzilai-Borwein steplengths</title>
      <link>https://arxiv.org/abs/2412.12180</link>
      <description>arXiv:2412.12180v2 Announce Type: replace 
Abstract: We investigate stochastic gradient methods and stochastic counterparts of the Barzilai-Borwein steplengths and their application to finite-sum minimization problems. Our proposal is based on the Trust-Region-ish (TRish) framework introduced in [F. E. Curtis, K. Scheinberg, R. Shi, {\it A stochastic trust region algorithm based on careful step normalization}, Informs Journal on Optimization, 1, 2019]. The new framework, named TRishBB, aims to enhance the performance of TRish and at reducing the computational cost of the second-order TRish variant. We propose three different methods belonging to the TRishBB framework and present the convergence analysis for possibly nonconvex objective functions, considering biased and unbiased gradient approximations. Our analysis requires neither diminishing step-sizes nor full gradient evaluation. The numerical experiments in machine learning applications demonstrate the effectiveness of applying the Barzilai-Borwein steplength with stochastic gradients and show improved testing accuracy compared to the TRish method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12180v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Benedetta Morini, Mahsa Yousefi</dc:creator>
    </item>
    <item>
      <title>Carleman estimate for semi-discrete stochastic parabolic operators in arbitrary dimension and applications to controllability</title>
      <link>https://arxiv.org/abs/2503.03596</link>
      <description>arXiv:2503.03596v2 Announce Type: replace 
Abstract: This paper considers a semi-discrete forward stochastic parabolic operator with homogeneous Dirichlet conditions in arbitrary dimensions. We show the lack of null controllability for a spatial semi-discretization of a null-controllable stochastic parabolic system from any initial datum. However, by proving a new Carleman estimate for its semi-discrete backward stochastic adjoint system, we achieve a relaxed observability inequality, which is applied to derivative $\phi$-null controllability by duality arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03596v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Lecaros, Ariel A. P\'erez, Manuel F. Prado</dc:creator>
    </item>
    <item>
      <title>A Linear Convergence Result for the Jacobi-Proximal Alternating Direction Method of Multipliers</title>
      <link>https://arxiv.org/abs/2503.18601</link>
      <description>arXiv:2503.18601v3 Announce Type: replace 
Abstract: In this paper, we analyze the convergence rate of the Jacobi-Proximal Alternating Direction Method of Multipliers (ADMM) initially introduced by Deng et al. for the block-structured optimization problem with linear constraint. The algorithm is well-suited for parallel implementation and widely used for large-scale multi-block optimization problems. While the o(1/k) convergence of the Jacobi-Proximal ADMM for the case $N \geq 3$ has been well-established in the previous work, to the best of our knowledge, its linear convergence for $N \geq 3$ remains unproven. We establish the linear convergence of the algorithm when the cost functions are strongly convex and smooth. Numerical experiments are presented supporting the convergence result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18601v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyelin Choi, Woocheol Choi</dc:creator>
    </item>
    <item>
      <title>Line-Search Filter Differential Dynamic Programming for Optimal Control with Nonlinear Equality Constraints</title>
      <link>https://arxiv.org/abs/2504.08278</link>
      <description>arXiv:2504.08278v4 Announce Type: replace 
Abstract: We present FilterDDP, a differential dynamic programming algorithm for solving discrete-time, optimal control problems (OCPs) with nonlinear equality constraints. Unlike prior methods based on merit functions or the augmented Lagrangian class of algorithms, FilterDDP uses a step filter in conjunction with a line search to handle equality constraints. We identify two important design choices for the step filter criteria which lead to robust numerical performance: 1) we use the Lagrangian instead of the cost as one of the filter criterion and, 2) for the stopping criteria and backward pass Hessians, we replace the value function gradient with an estimated dual variable of the dynamics constraints. Both choices are rigorously justified, for 2) in particular by a formal proof of local quadratic convergence. We validate FilterDDP on three contact implicit trajectory optimisation problems which arise in robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08278v4</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Xu, Stephen Gould, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Asymptotic Optimality in Data-Driven Decision Making</title>
      <link>https://arxiv.org/abs/2507.15215</link>
      <description>arXiv:2507.15215v2 Announce Type: replace 
Abstract: Given data generated by an observable stochastic process, we study how to construct statistically optimal decisions for general stochastic optimization problems. Our setting encompasses non-standard data structures, including data originating from heterogeneous sources or from randomly evolving data-generating mechanisms. We propose a decision-making approach that identifies optimal decisions for which a specific notion of risk of shifted regret decays to zero at a prescribed exponential rate. This optimal decision arises as the solution to a multi-objective optimization problem, which reflects asymptotic behavior properties of the data-generating process. Central to our framework is a rate function that characterizes this behavior via a Laplace principle, thereby generalizing standard concepts from large deviation theory. Our general formulation enables our approach to account for data from uncertain distributions and recovers classical results in data-driven decision making under uncertainty as special cases, including distributionally robust optimization. Moreover, our method enables decision-makers to systematically balance a desired rate of asymptotic risk decay against a potential loss in statistical consistency of the resulting data-driven decision. We demonstrate the effectiveness of the proposed approach through illustrative examples from operations research, such as the newsvendor problem, under aleatoric uncertainty induced by heterogeneous data sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15215v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radek Sala\v{c}, Michael Kupper, Tobias Sutter</dc:creator>
    </item>
    <item>
      <title>Improved Convergence Factor of Windowed Anderson Acceleration for Symmetric Fixed-Point Iterations</title>
      <link>https://arxiv.org/abs/2311.02490</link>
      <description>arXiv:2311.02490v3 Announce Type: replace-cross 
Abstract: This paper studies the commonly utilized windowed Anderson acceleration (AA) algorithm for fixed-point methods, $x^{(k+1)}=q(x^{(k)})$. It provides the first proof that when the operator $q$ is linear and symmetric the windowed AA, which uses a sliding window of prior iterates, improves the root-linear convergence factor over the fixed-point iterations. When $q$ is nonlinear, yet has a symmetric Jacobian at a fixed point, a slightly modified AA algorithm is proved to have an analogous root-linear convergence factor improvement over fixed-point iterations. Simulations verify our observations. Furthermore, experiments with different data models demonstrate AA is significantly superior to the standard fixed-point methods for Tyler's M-estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02490v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Casey Garner, Gilad Lerman, Teng Zhang</dc:creator>
    </item>
    <item>
      <title>Model-Free and Real-Time Unicycle-Based Source Seeking with Differential Wheeled Robotic Experiments</title>
      <link>https://arxiv.org/abs/2501.02184</link>
      <description>arXiv:2501.02184v4 Announce Type: replace-cross 
Abstract: Many autonomous robots aimed at source-seeking are studied, and their controls designed, using unicycle modeling and formulation. This is true not only for model-based controllers, but also for model-free, real-time control methods such as extremum seeking control (ESC). In this paper, we propose a unicycle-based ESC design applicable to differential wheeled robots that: (1) is very simple design, based on one simple control-affine law, and without state integrators; (2) attenuates oscillations known to persist in ESC designs (i.e., fully stop at the source); and (3) operates in a model-free, real-time setting, tolerating environmental/sensor noise. We provide simulation and real-world robotic experimental results for fixed and moving light source seeking by a differential wheeled robot using our proposed design. Results indicate clear advantages of our proposed design when compared to the literature, including attenuation of undesired oscillations, improved convergence speed, and better handling of noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02184v4</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa, Shivam Bajpai</dc:creator>
    </item>
    <item>
      <title>Two-dimensional Parallel Tempering for Constrained Optimization</title>
      <link>https://arxiv.org/abs/2506.14781</link>
      <description>arXiv:2506.14781v2 Announce Type: replace-cross 
Abstract: Sampling Boltzmann probability distributions plays a key role in machine learning and optimization, motivating the design of hardware accelerators such as Ising machines. While the Ising model can in principle encode arbitrary optimization problems, practical implementations are often hindered by soft constraints that either slow down mixing when too strong, or fail to enforce feasibility when too weak. We introduce a two-dimensional extension of the powerful parallel tempering algorithm (PT) that addresses this challenge by adding a second dimension of replicas interpolating the penalty strengths. This scheme ensures constraint satisfaction in the final replicas, analogous to low-energy states at low temperature. The resulting two-dimensional parallel tempering algorithm (2D-PT) improves mixing in heavily constrained replicas and eliminates the need to explicitly tune the penalty strength. In a representative example of graph sparsification with copy constraints, 2D-PT achieves near-ideal mixing, with Kullback-Leibler divergence decaying as O(1/t). When applied to sparsified Wishart instances, 2D-PT yields orders of magnitude speedup over conventional PT with the same number of replicas. The method applies broadly to constrained Ising problems and can be deployed on existing Ising machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14781v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/mr2n-qqrb</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E (2025)</arxiv:journal_reference>
      <dc:creator>Corentin Delacour, M Mahmudul Hasan Sajeeb, Joao P. Hespanha, Kerem Y. Camsari</dc:creator>
    </item>
  </channel>
</rss>
