<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 01:56:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Lanczos algorithm for matrix functions: a handbook for scientists</title>
      <link>https://arxiv.org/abs/2410.11090</link>
      <description>arXiv:2410.11090v1 Announce Type: new 
Abstract: Lanczos-based methods have become standard tools for tasks involving matrix functions. Progress on these algorithms has been driven by several largely disjoint communities, resulting many innovative and important advancements which would not have been possible otherwise. However, this also has resulted in a somewhat fragmented state of knowledge and the propagation of a number of incorrect beliefs about the behavior of Lanczos-based methods in finite precision arithmetic.
  This monograph aims to provide an accessible introduction to Lanczos-based methods for matrix functions. The intended audience is scientists outside of numerical analysis, graduate students, and researchers wishing to begin work in this area. Our emphasis is on conceptual understanding, with the goal of providing a starting point to learn more about the remarkable behavior of the Lanczos algorithm. Hopefully readers will come away from this text with a better understanding of how to think about Lanczos for modern problems involving matrix functions, particularly in the context of finite precision arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11090v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen</dc:creator>
    </item>
    <item>
      <title>Randomized Iterative Solver as Iterative Refinement: A Simple Fix Towards Backward Stability</title>
      <link>https://arxiv.org/abs/2410.11115</link>
      <description>arXiv:2410.11115v1 Announce Type: new 
Abstract: Iterative sketching and sketch-and-precondition are well-established randomized algorithms for solving large-scale, over-determined linear least-squares problems. In this paper, we introduce a new perspective that interprets Iterative Sketching and Sketching-and-Precondition as forms of Iterative Refinement. We also examine the numerical stability of two distinct refinement strategies, iterative refinement and recursive refinement, which progressively improve the accuracy of a sketched linear solver. Building on this insight, we propose a novel algorithm, Sketched Iterative and Recursive Refinement (SIRR), which combines both refinement methods. SIRR demonstrates a \emph{four order of magnitude improvement} in backward error compared to iterative sketching, achieved simply by reorganizing the computational order, ensuring that the computed solution exactly solves a modified least-squares system where the coefficient matrix deviates only slightly from the original matrix. To the best of our knowledge, \emph{SIRR is the first asymptotically fast, single-stage randomized least-squares solver that achieves both forward and backward stability}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11115v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruihan Xu, Yiping Lu</dc:creator>
    </item>
    <item>
      <title>Which Spaces can be Embedded in $L_p$-type Reproducing Kernel Banach Space? A Characterization via Metric Entropy</title>
      <link>https://arxiv.org/abs/2410.11116</link>
      <description>arXiv:2410.11116v2 Announce Type: new 
Abstract: In this paper, we establish a novel connection between the metric entropy growth and the embeddability of function spaces into reproducing kernel Hilbert/Banach spaces. Metric entropy characterizes the information complexity of function spaces and has implications for their approximability and learnability. Classical results show that embedding a function space into a reproducing kernel Hilbert space (RKHS) implies a bound on its metric entropy growth. Surprisingly, we prove a \textbf{converse}: a bound on the metric entropy growth of a function space allows its embedding to a $L_p-$type Reproducing Kernel Banach Space (RKBS). This shows that the ${L}_p-$type RKBS provides a broad modeling framework for learnable function classes with controlled metric entropies. Our results shed new light on the power and limitations of kernel methods for learning complex function spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11116v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiping Lu, Daozhe Lin, Qiang Du</dc:creator>
    </item>
    <item>
      <title>Unconditionally stable, linearised IMEX schemes for incompressible flows with variable density</title>
      <link>https://arxiv.org/abs/2410.11510</link>
      <description>arXiv:2410.11510v1 Announce Type: new 
Abstract: For the incompressible Navier--Stokes system with variable density and viscosity, we propose and analyse an IMEX framework treating the convective and diffusive terms semi-implicitly. This extends to variable density and second order in time some methods previously analysed for variable viscosity and constant density. We present three new schemes, both monolithic and fractional-step. All of them share the methodological novelty that the viscous term is treated in an implicit-explicit (IMEX) fashion, which allows decoupling the velocity components. Unconditional temporal stability is proved for all three variants. Furthermore, the system to solve at each time step is linear, thus avoiding the costly solution of nonlinear problems even if the viscosity follows a non-Newtonian rheological law. Our presentation is restricted to the semi-discrete case, only considering the time discretisation. In this way, the results herein can be applied to any spatial discretisation. We validate our theory through numerical experiments considering finite element methods in space. The tests range from simple manufactured solutions to complex two-phase viscoplastic flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11510v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\'as Espinoza-Contreras, Gabriel Barrenechea, Ernesto Castillo, Douglas Pacheco</dc:creator>
    </item>
    <item>
      <title>Fully-discrete provably Lyapunov consistent discretizations for convection-diffusion-reaction PDE systems</title>
      <link>https://arxiv.org/abs/2410.11669</link>
      <description>arXiv:2410.11669v1 Announce Type: new 
Abstract: Convection-diffusion-reaction equations are a class of second-order partial differential equations widely used to model phenomena involving the change of concentration/population of one or more substances/species distributed in space. Understanding and preserving their stability properties in numerical simulation is crucial for accurate predictions, system analysis, and decision-making. This work presents a comprehensive framework for constructing fully discrete Lyapunov-consistent discretizations of any order for convection-diffusion-reaction models. We introduce a systematic methodology for constructing discretizations that mimic the stability analysis of the continuous model using Lyapunov's direct method. The spatial algorithms are based on collocated discontinuous Galerkin methods with the summation-by-parts property and the simultaneous approximation terms approach for imposing interface coupling and boundary conditions. Relaxation Runge-Kutta schemes are used to integrate in time and achieve fully discrete Lyapunov consistency. To verify the properties of the new schemes, we numerically solve a system of convection-diffusion-reaction partial differential equations governing the dynamic evolution of monomer and dimer concentrations during the dimerization process. Numerical results demonstrated the accuracy and consistency of the proposed discretizations. The new framework can enable further advancements in the analysis, control, and understanding of general convection-diffusion-reaction systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11669v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rasha Al Jahdali, David C. Del Rey Fernandez, Lisandro Dalcin, Matteo Parsani</dc:creator>
    </item>
    <item>
      <title>On energy consistent vector hysteresis operators</title>
      <link>https://arxiv.org/abs/2410.11705</link>
      <description>arXiv:2410.11705v1 Announce Type: new 
Abstract: Incremental models for magnetic vector hysteresis have been developed in previous works in accordance with basic principles of thermodynamics. In this paper, we present an equivalent representation of the associated hysteresis operator in terms of a co-energy functional which is useful for magnetic field computations based on a scalar potential. Using convex duality, we further define the corresponding energy functional and the associated inverse hysteresis operator which is required for computations based on the vector potential. The equivalence of the two representations with the energy-based hysteresis models proposed in earlier works is demonstrated and numerical results for some typical test problems are presented obtained by finite element simulation of corresponding scalar and vector potential formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11705v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Herbert Egger, Felix Engertsberger, Lukas Domenig, Klaus Roppert, Manfred Kaltenbacher</dc:creator>
    </item>
    <item>
      <title>Advancing the Understanding of Fixed Point Iterations in Deep Neural Networks: A Detailed Analytical Study</title>
      <link>https://arxiv.org/abs/2410.11279</link>
      <description>arXiv:2410.11279v1 Announce Type: cross 
Abstract: Recent empirical studies have identified fixed point iteration phenomena in deep neural networks, where the hidden state tends to stabilize after several layers, showing minimal change in subsequent layers. This observation has spurred the development of practical methodologies, such as accelerating inference by bypassing certain layers once the hidden state stabilizes, selectively fine-tuning layers to modify the iteration process, and implementing loops of specific layers to maintain fixed point iterations. Despite these advancements, the understanding of fixed point iterations remains superficial, particularly in high-dimensional spaces, due to the inadequacy of current analytical tools. In this study, we conduct a detailed analysis of fixed point iterations in a vector-valued function modeled by neural networks. We establish a sufficient condition for the existence of multiple fixed points of looped neural networks based on varying input regions. Additionally, we expand our examination to include a robust version of fixed point iterations. To demonstrate the effectiveness and insights provided by our approach, we provide case studies that looped neural networks may exist $2^d$ number of robust fixed points under exponentiation or polynomial activation functions, where $d$ is the feature dimension. Furthermore, our preliminary empirical results support our theoretical findings. Our methodology enriches the toolkit available for analyzing fixed point iterations of deep neural networks and may enhance our comprehension of neural network mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11279v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yekun Ke, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song</dc:creator>
    </item>
    <item>
      <title>Modelling advection on distance-weighted directed networks</title>
      <link>https://arxiv.org/abs/2410.11352</link>
      <description>arXiv:2410.11352v1 Announce Type: cross 
Abstract: In this paper we propose a model for describing advection dynamics on distance-weighted directed graphs. To this end we establish a set of key properties, or axioms, that a discrete advection operator should satisfy, and prove that there exists an essentially unique operator satisfying all such properties. Both infinite and finite networks are considered, as well as possible variants and extensions. We illustrate the proposed model through examples, both analytical and numerical, and we describe an application to the simulation of a traffic network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11352v1</guid>
      <category>cs.SI</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Benzi, Fabio Durastante, Francesco Zigliotto</dc:creator>
    </item>
    <item>
      <title>Point-Calibrated Spectral Neural Operators</title>
      <link>https://arxiv.org/abs/2410.11382</link>
      <description>arXiv:2410.11382v1 Announce Type: cross 
Abstract: Two typical neural models have been extensively studied for operator learning, learning in spatial space via attention mechanism or learning in spectral space via spectral analysis technique such as Fourier Transform. Spatial learning enables point-level flexibility but lacks global continuity constraint, while spectral learning enforces spectral continuity prior but lacks point-wise adaptivity. This work innovatively combines the continuity prior and the point-level flexibility, with the introduced Point-Calibrated Spectral Transform. It achieves this by calibrating the preset spectral eigenfunctions with the predicted point-wise frequency preference via neural gate mechanism. Beyond this, we introduce Point-Calibrated Spectral Neural Operators, which learn operator mappings by approximating functions with the point-level adaptive spectral basis, thereby not only preserving the benefits of spectral prior but also boasting the superior adaptability comparable to the attention mechanism. Comprehensive experiments demonstrate its consistent performance enhancement in extensive PDE solving scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11382v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xihang Yue, Linchao Zhu, Yi Yang</dc:creator>
    </item>
    <item>
      <title>Numerical computation of generalized Wasserstein distances with applications to traffic model analysis</title>
      <link>https://arxiv.org/abs/2410.11441</link>
      <description>arXiv:2410.11441v1 Announce Type: cross 
Abstract: Generalized Wasserstein distances allow to quantitatively compare two continuous or atomic mass distributions with equal or different total mass. In this paper, we propose four numerical methods for the approximation of three different generalized Wasserstein distances introduced in the last years, giving some insights about their physical meaning. After that, we explore their usage in the context of the sensitivity analysis of differential models for traffic flow. The quantification of models sensitivity is obtained by computing the generalized Wasserstein distances between two (numerical) solutions corresponding to different inputs, including different boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11441v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maya Briani, Emiliano Cristiani, Giovanni Franzina, Francesca L. Ignoto</dc:creator>
    </item>
    <item>
      <title>On $L^\infty$ stability for wave propagation and for linear inverse problems</title>
      <link>https://arxiv.org/abs/2410.11467</link>
      <description>arXiv:2410.11467v1 Announce Type: cross 
Abstract: Stability is a key property of both forward models and inverse problems, and depends on the norms considered in the relevant function spaces. For instance, stability estimates for hyperbolic partial differential equations are often based on energy conservation principles, and are therefore expressed in terms of $L^2$ norms. The focus of this paper is on stability with respect to the $L^\infty$ norm, which is more relevant to detect localized phenomena. The linear wave equation is not stable in $L^\infty$, and we design an alternative solution method based on the regularization of Fourier multipliers, which is stable in $L^\infty$. Furthermore, we show how these ideas can be extended to inverse problems, and design a regularization method for the inversion of compact operators that is stable in $L^\infty$. We also discuss the connection with the stability of deep neural networks modeled by hyperbolic PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11467v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rima Alaifari, Giovanni S. Alberti, Tandri Gauksson</dc:creator>
    </item>
    <item>
      <title>A model learning framework for inferring the dynamics of transmission rate depending on exogenous variables for epidemic forecasts</title>
      <link>https://arxiv.org/abs/2410.11545</link>
      <description>arXiv:2410.11545v1 Announce Type: cross 
Abstract: In this work, we aim to formalize a novel scientific machine learning framework to reconstruct the hidden dynamics of the transmission rate, whose inaccurate extrapolation can significantly impair the quality of the epidemic forecasts, by incorporating the influence of exogenous variables (such as environmental conditions and strain-specific characteristics). We propose an hybrid model that blends a data-driven layer with a physics-based one. The data-driven layer is based on a neural ordinary differential equation that learns the dynamics of the transmission rate, conditioned on the meteorological data and wave-specific latent parameters. The physics-based layer, instead, consists of a standard SEIR compartmental model, wherein the transmission rate represents an input. The learning strategy follows an end-to-end approach: the loss function quantifies the mismatch between the actual numbers of infections and its numerical prediction obtained from the SEIR model incorporating as an input the transmission rate predicted by the neural ordinary differential equation. We validate this original approach using both a synthetic test case and a realistic test case based on meteorological data (temperature and humidity) and influenza data from Italy between 2010 and 2020. In both scenarios, we achieve low generalization error on the test set and observe strong alignment between the reconstructed model and established findings on the influence of meteorological factors on epidemic spread. Finally, we implement a data assimilation strategy to adapt the neural equation to the specific characteristics of an epidemic wave under investigation, and we conduct sensitivity tests on the network hyperparameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11545v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Ziarelli, Stefano Pagani, Nicola Parolini, Francesco Regazzoni, Marco Verani</dc:creator>
    </item>
    <item>
      <title>Defining myocardial fiber bundle architecture in atrial digital twins</title>
      <link>https://arxiv.org/abs/2410.11601</link>
      <description>arXiv:2410.11601v1 Announce Type: cross 
Abstract: A key component in developing atrial digital twins (ADT) - virtual representations of patients' atria - is the accurate prescription of myocardial fibers which are essential for the tissue characterization. Due to the difficulty of reconstructing atrial fibers from medical imaging, a widely used strategy for fiber generation in ADT relies on mathematical models. Existing methodologies utilze semi-automatic approaches, are tailored to specific morphologies, and lack rigorous validation against imaging fiber data. In this study, we introduce a novel atrial Laplace-Dirichlet-Rule-Based Method (LDRBM) for prescribing highly detailed myofiber orientations and providing robust regional annotation in bi-atrial morphologies of any complexity. The robustness of our approach is verified in eight extremely detailed bi-atrial geometries, derived from a sub-millimiter Diffusion-Tensor-Magnetic-Resonance Imaging (DTMRI) human atrial fiber dataset. We validate the LDRBM by quantitatively recreating each of the DTMRI fiber architectures: a comprehensive comparison with DTMRI ground truth data is conducted, investigating differences between electrophysiology (EP) simulations provided by either LDRBM and DTMRI fibers. Finally, we demonstrate that the novel LDRBM outperforms current state-of-the-art fiber models, confirming the exceptional accuracy of our methodology and the critical importance of incorporating detailed fiber orientations in EP simulations. Ultimately, this work represents a fundamental step toward the development of physics-based digital twins of the human atria, establishing a new standard for prescribing fibers in ADT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11601v1</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Piersanti, Ryan Bradley, Syed Yusuf Alid, Alfio Quarteroni, Luca Dede', Natalia A. Trayanova</dc:creator>
    </item>
    <item>
      <title>Stochastic diagonal estimation with adaptive parameter selection</title>
      <link>https://arxiv.org/abs/2410.11613</link>
      <description>arXiv:2410.11613v1 Announce Type: cross 
Abstract: In this paper, we investigate diagonal estimation for large or implicit matrices, aiming to develop a novel and efficient stochastic algorithm that incorporates adaptive parameter selection. We explore the influence of different eigenvalue distributions on diagonal estimation and analyze the necessity of introducing the projection method and adaptive parameter optimization into the stochastic diagonal estimator. Based on this analysis, we derive a lower bound on the number of random query vectors needed to satisfy a given probabilistic error bound, which forms the foundation of our adaptive stochastic diagonal estimation algorithm. Finally, numerical experiments demonstrate the effectiveness of the proposed estimator for various matrix types, showcasing its efficiency and stability compared to other existing stochastic diagonal estimation methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11613v1</guid>
      <category>stat.ML</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongyuan Han, Wenhao Li, Shengxin Zhu</dc:creator>
    </item>
    <item>
      <title>Fast and Robust Hexahedral Mesh Optimization via Augmented Lagrangian, L-BFGS, and Line Search</title>
      <link>https://arxiv.org/abs/2410.11656</link>
      <description>arXiv:2410.11656v1 Announce Type: cross 
Abstract: We present a new software package, ``HexOpt,'' for improving the quality of all-hexahedral (all-hex) meshes by maximizing the minimum mixed scaled Jacobian-Jacobian energy functional, and projecting the surface points of the all-hex meshes onto the input triangular mesh. The proposed HexOpt method takes as input a surface triangular mesh and a volumetric all-hex mesh. A constrained optimization problem is formulated to improve mesh quality using a novel function that combines Jacobian and scaled Jacobian metrics which are rectified and scaled to quadratic measures, while preserving the surface geometry. This optimization problem is solved using the augmented Lagrangian (AL) method, where the Lagrangian terms enforce the constraint that surface points must remain on the triangular mesh. Specifically, corner points stay exactly at the corner, edge points are confined to the edges, and face points are free to move across the surface. To take the advantage of the Quasi-Newton method while tackling the high-dimensional variable problem, the Limited-Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is employed. The step size for each iteration is determined by the Armijo line search. Coupled with smart Laplacian smoothing, HexOpt has demonstrated robustness and efficiency, successfully applying to 3D models and hex meshes generated by different methods without requiring any manual intervention or parameter adjustment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11656v1</guid>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hua Tong, Yongjie Jessica Zhang</dc:creator>
    </item>
    <item>
      <title>l_inf-approximation of localized distributions</title>
      <link>https://arxiv.org/abs/2410.11771</link>
      <description>arXiv:2410.11771v1 Announce Type: cross 
Abstract: Distributions in spatial model often exhibit localized features. Intuitively, this locality implies a low intrinsic dimensionality, which can be exploited for efficient approximation and computation of complex distributions. However, existing approximation theory mainly considers the joint distributions, which does not guarantee that the marginal errors are small. In this work, we establish a dimension independent error bound for the marginals of approximate distributions. This $\ell_\infty$-approximation error is obtained using Stein's method, and we propose a $\delta$-locality condition that quantifies the degree of localization in a distribution. We also show how $\delta$-locality can be derived from different conditions that characterize the distribution's locality. Our $\ell_\infty$ bound motivates the localization of existing approximation methods to respect the locality. As examples, we show how to use localized likelihood-informed subspace method and localized score matching, which not only avoid dimension dependence in the approximation error, but also significantly reduce the computational cost due to the local and parallel implementation based on the localized structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11771v1</guid>
      <category>stat.ML</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiangang Cui, Shuigen Liu, Xin Tong</dc:creator>
    </item>
    <item>
      <title>One-sided discretization inequalities and sampling recovery</title>
      <link>https://arxiv.org/abs/2402.00848</link>
      <description>arXiv:2402.00848v2 Announce Type: replace 
Abstract: Recently, in a number of papers it was understood that results on sampling discretization and on the universal sampling discretization can be successfully used in the problem of sampling recovery. Moreover, it turns out that it is sufficient to only have a one-sided discretization inequality for some of those applications. This motivates us to write the present paper as a survey/research paper with the focus on the one-sided discretization inequalities and their applications in the sampling recovery. In this sense the paper complements the two existing survey papers on sampling discretization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00848v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irina Limonova, Yuri Malykhin, Vladimir Temlyakov</dc:creator>
    </item>
    <item>
      <title>Conforming virtual element method for nondivergence form linear elliptic equations with Cordes coefficients</title>
      <link>https://arxiv.org/abs/2404.08442</link>
      <description>arXiv:2404.08442v2 Announce Type: replace 
Abstract: We propose and analyze an $H^2$-conforming Virtual Element Method (VEM) for the simplest linear elliptic PDEs in nondivergence form with Cordes coefficients. The VEM hinges on a hierarchical construction valid for any dimension $d \ge 2$. The analysis relies on the continuous Miranda-Talenti estimate for convex domains $\Omega$ and is rather elementary. We prove stability and error estimates in $H^2(\Omega)$, including the effect of quadrature, under minimal regularity of the data. Numerical experiments illustrate the interplay of coefficient regularity and convergence rates in $H^2(\Omega)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08442v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Bonnet, Andrea Cangiani, Ricardo H. Nochetto</dc:creator>
    </item>
    <item>
      <title>Rational methods for abstract linear, non-homogeneous problems without order reduction</title>
      <link>https://arxiv.org/abs/2405.04195</link>
      <description>arXiv:2405.04195v4 Announce Type: replace 
Abstract: Starting from an A-stable rational approximation to $\rm{e}^z$ of order $p$, $$r(z)= 1+ z+ \cdots + z^p/ p! + O(z^{p+1}),$$ families of stable methods are proposed to time discretize abstract IVP's of the type $u'(t) = A u(t) + f(t)$. These numerical procedures turn out to be of order $p$, thus overcoming the order reduction phenomenon, and only one evaluation of $f$ per step is required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04195v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Arranz-Sim\'on, Cesar Palencia</dc:creator>
    </item>
    <item>
      <title>The Onsager principle and structure preserving numerical schemes</title>
      <link>https://arxiv.org/abs/2406.12652</link>
      <description>arXiv:2406.12652v2 Announce Type: replace 
Abstract: We present a natural framework for constructing energy-stable time discretization schemes. By leveraging the Onsager principle, we demonstrate its efficacy in formulating partial differential equation models for diverse gradient flow systems. Furthermore, this principle provides a robust basis for developing numerical schemes that uphold crucial physical properties. Within this framework, several widely used schemes emerge naturally, showing its versatility and applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12652v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huangxin Chen, Hailiang Liu, Xianmin Xu</dc:creator>
    </item>
    <item>
      <title>Mixed Precision Block-Jacobi Preconditioner: Algorithms, Performance Evaluation and Feature Analysis</title>
      <link>https://arxiv.org/abs/2407.15973</link>
      <description>arXiv:2407.15973v3 Announce Type: replace 
Abstract: In this paper, we propose two mixed precision algorithms for Block-Jacobi preconditioner(BJAC): a fixed low precision strategy and an adaptive precision strategy. We evaluate the performance improvement of the proposed mixed precision BJAC preconditioners combined with the preconditioned conjugate gradient algorithm using problems including diffusion equations and radiation hydrodynamics equations. Numerical results show that, compared to the uniform high precision PCG algorithm, the mixed precision preconditioners can achieve speedups from 1.3 to 1.8 without sacrificing accuracy. Furthermore, we observe the phenomenon of convergence delay in some test cases for the mixed precision preconditioners, and further analyse the matrix features associate with the convergence delay behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15973v3</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ningxi Tian, Silu Huang, Xiaowen Xu</dc:creator>
    </item>
    <item>
      <title>Meshfree Generalized Multiscale Exponential Integration Method for Parabolic Problems</title>
      <link>https://arxiv.org/abs/2408.05005</link>
      <description>arXiv:2408.05005v2 Announce Type: replace 
Abstract: This paper considers flow problems in multiscale heterogeneous porous media. The multiscale nature of the modeled process significantly complicates numerical simulations due to the need to compute huge and ill-conditioned sparse matrices, which negatively affect both the computational cost and the stability of the numerical solution. We propose a novel combined approach of the meshfree Generalized Multiscale Finite Element Method (MFGMsFEM) and exponential time integration for solving such problems. MFGMsFEM provides a robust and efficient spatial approximation, allowing us to consider complex heterogeneities without constructing a coarse computational grid. At the same time, exponential integration, using the cost-effective MFGMsFEM matrix, provides a robust temporal approximation for stiff multiscale problems, allowing larger time steps. For the proposed multiscale approach, we provide a rigorous convergence analysis, including the new analysis of the MFGMsFEM spatial approximation. We conduct numerical experiments to computationally verify the proposed approach by solving linear and semi-linear flow problems in multiscale media. Numerical results demonstrate that the proposed multiscale method achieves significant reductions in computational cost and improved stability, even with larger time steps, confirming the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05005v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Djulustan Nikiforov, Leonardo A. Poveda, Dmitry Ammosov, Yesy Sarmiento, Juan Galvis</dc:creator>
    </item>
    <item>
      <title>A Canonical Gauge for Computing of Eigenpairs of the Magnetic Schr\"odinger Operator</title>
      <link>https://arxiv.org/abs/2409.06023</link>
      <description>arXiv:2409.06023v2 Announce Type: replace 
Abstract: We consider the eigenvalue problem for the magnetic Schr\"odinger operator and take advantage of a property called gauge invariance to transform the given problem into an equivalent problem that is more amenable to numerical approximation. More specifically, we propose a canonical magnetic gauge that can be computed by solving a Poisson problem, that yields a new operator having the same spectrum but eigenvectors that are less oscillatory. Extensive numerical tests demonstrate that accurate computation of eigenpairs can be done more efficiently and stably with the canonical magnetic gauge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06023v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey S. Ovall, Li Zhu</dc:creator>
    </item>
    <item>
      <title>Lattice Boltzmann framework for multiphase flows by Eulerian-Eulerian Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2409.10399</link>
      <description>arXiv:2409.10399v2 Announce Type: replace 
Abstract: Although Lattice Boltzmann Method (LBM) is relatively straightforward, it demands a well-crafted framework to handle the complex partial differential equations involved in multiphase flow simulations. This document presents some potential strategies for developing an Eulerian-Eulerian LBM solver tailored for multiphase systems. The paper first states what are the starting equations governing a multiphase flow in classical CFD. Secondly, it derives a pseudo-compressible (targeting the incompressible limit) system of equations for deriving the Eulerian-Eulerian LBM framework to simulate multiphase flows. Finally, a dispersed phase volume fraction equation is provided to balance the degree of freedom less due to the pressure gradient coupling. The effectiveness of these approaches can only be confirmed through rigorous numerical experimentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10399v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Maria Piredda, Pietro Asinari</dc:creator>
    </item>
    <item>
      <title>Autonomous Orbital Correction for Nano Satellites Using J2 Perturbation and LSTM Networks</title>
      <link>https://arxiv.org/abs/2410.10240</link>
      <description>arXiv:2410.10240v2 Announce Type: replace 
Abstract: CubeSats offer a cost-effective platform for various space missions, but their limited fuel capacity and susceptibility to environmental disturbances pose significant challenges for precise orbital maneuvering. This paper presents a novel control strategy that integrates a J2-optimized sequence with an LSTM-based low-level control layer to address these issues. The J2-optimized sequence leverages the Earth's oblateness to minimize fuel consumption during orbital corrections, while the LSTM network provides real-time adjustments to compensate for external disturbances and unmodeled dynamics. The LSTM network was trained on a dataset generated from simulated orbital scenarios, including factors such as atmospheric drag, solar radiation pressure, and gravitational perturbations. The proposed system was evaluated through numerical simulations, demonstrating significant improvements in maneuver accuracy and robustness compared to traditional methods. The results show that the combined system efficiently reduces miss distances, even under conditions of high uncertainty. This hybrid approach offers a powerful and adaptive solution for CubeSat missions, balancing fuel efficiency with precise orbital control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10240v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahya Ramezani, Mohammadamin Alandihallaj, Andreas M. Hein</dc:creator>
    </item>
    <item>
      <title>Greedy Learning to Optimize with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2406.00260</link>
      <description>arXiv:2406.00260v2 Announce Type: replace-cross 
Abstract: Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant memory usage. We parameterize the update such that parameter learning corresponds to solving a convex optimization problem at each iteration. In particular, we explore preconditioned gradient descent with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithm, convergence in the training set is proven even when the preconditioner is neither symmetric nor positive definite. Convergence on a class of unseen functions is also obtained, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioner demonstrates improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00260v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Fahy, Mohammad Golbabaee, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Alternating Maximization Algorithm for Mismatch Capacity with Oblivious Relaying</title>
      <link>https://arxiv.org/abs/2409.19674</link>
      <description>arXiv:2409.19674v4 Announce Type: replace-cross 
Abstract: Reliable communication over a discrete memoryless channel with the help of a relay has aroused interest due to its widespread applications in practical scenarios. By considering the system with a mismatched decoder, previous works have provided optimization models to evaluate the mismatch capacity in these scenarios. The proposed models, however, are difficult due to the complicated structure of the mismatched decoding problem with the information flows in hops given by the relay. Existing methods, such as the grid search, become impractical as they involve finding all roots of a nonlinear system, with the growing size of the alphabet. To address this problem, we reformulate the max-min optimization model as a consistent maximization form, by considering the dual form of the inner minimization problem and the Lagrangian with a fixed multiplier. Based on the proposed formulation, an alternating maximization framework is designed, which provides the closed-form solution with simple iterations in each step by introducing a suitable variable transformation. The effectiveness of the proposed approach is demonstrated by the simulations over practical scenarios, including Quaternary and Gaussian channels. Moreover, the simulation results of the transitional probability also shed light on the promising application attribute to the quantizer design in the relay node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19674v4</guid>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinwei Li, Lingyi Chen, Shitong Wu, Huihui Wu, Hao Wu, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Anderson Acceleration in Nonsmooth Problems: Local Convergence via Active Manifold Identification</title>
      <link>https://arxiv.org/abs/2410.09420</link>
      <description>arXiv:2410.09420v2 Announce Type: replace-cross 
Abstract: Anderson acceleration is an effective technique for enhancing the efficiency of fixed-point iterations; however, analyzing its convergence in nonsmooth settings presents significant challenges. In this paper, we investigate a class of nonsmooth optimization algorithms characterized by the active manifold identification property. This class includes a diverse array of methods such as the proximal point method, proximal gradient method, proximal linear method, proximal coordinate descent method, Douglas-Rachford splitting (or the alternating direction method of multipliers), and the iteratively reweighted $\ell_1$ method, among others. Under the assumption that the optimization problem possesses an active manifold at a stationary point, we establish a local R-linear convergence rate for the Anderson-accelerated algorithm. Our extensive numerical experiments further highlight the robust performance of the proposed Anderson-accelerated methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09420v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Li, Luwei Bai, Xiao Wang, Hao Wang</dc:creator>
    </item>
  </channel>
</rss>
