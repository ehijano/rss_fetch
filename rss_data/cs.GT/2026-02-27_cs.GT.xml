<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Clarification of `Algorithmic Collusion without Threats'</title>
      <link>https://arxiv.org/abs/2602.22232</link>
      <description>arXiv:2602.22232v1 Announce Type: new 
Abstract: This brief note clarifies that the scenario described in Arunachaleswaran et al. (2025) -- titled `Algorithmic Collusion without Threats' -- is not one of collusion, but one where one player is behaving non-competitively and the other is behaving competitively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22232v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Hartline</dc:creator>
    </item>
    <item>
      <title>How Many Votes is a Lie Worth? Measuring Strategyproofness through Resource Augmentation</title>
      <link>https://arxiv.org/abs/2602.22838</link>
      <description>arXiv:2602.22838v1 Announce Type: new 
Abstract: It is well known, by the Gibbard-Satterthwaite Theorem, that when there are more than two candidates, any non-dictatorial voting rule can be manipulated by untruthful voters. But how strong is the incentive to manipulate under different voting rules? We suggest measuring the potential advantage of a strategic voter by asking how many copies of their (truthful) vote must be added to the election in order to achieve an outcome as good as their best manipulation. Intuitively, this definition quantifies what a voter can gain by manipulating in comparison to what they would have gained by finding like-minded voters to join the election. The higher the former is, the more incentive a voter will have to manipulate, even when it is computationally costly.
  Using this framework, we obtain a principled method to measure and compare the manipulation potential for different voting rules. We analyze and report this potential for well-known and broad classes of social choice functions. In particular, we show that the positional scoring rule with the smallest manipulation potential will always be either Borda Count (if the number of voters outweighs the number of candidates) or Plurality (vice versa). Further, we prove that any rule satisfying a weak form of majority consistency (and therefore any Condorcet-consistent rule) cannot outperform Plurality, and that any majoritarian Condorcet rule will perform significantly worse. Consequently, out of the voting rules we analyze, Borda Count stands out as the only one with a manipulation potential that does not grow with the number of voters. By establishing a clear separation between different rules in terms of manipulation potential, our work paves the way for the search for rules that provide voters with minimal incentive to manipulate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22838v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ratip Emin Berker, Vincent Conitzer, Eden Hartman, Jiayuan Liu, Caspar Oesterheld</dc:creator>
    </item>
    <item>
      <title>Robust Information Design for Multi-Agent Systems with Complementarities: Smallest-Equilibrium Threshold Policies</title>
      <link>https://arxiv.org/abs/2602.22915</link>
      <description>arXiv:2602.22915v1 Announce Type: new 
Abstract: We study information design in multi-agent systems (MAS) with binary actions and strategic complementarities, where an external designer influences behavior only through signals. Agents play the smallest-equilibrium of the induced Bayesian game, reflecting conservative, coordination-averse behavior typical in distributed systems. We show that when utilities admit a convex potential and welfare is convex, the robustly implementable optimum has a remarkably simple form: perfect coordination at each state: either everyone acts or no one does. We provide a constructive threshold rule: compute a one-dimensional score for each state, sort states, and pick a single threshold (with a knife-edge lottery for at most one state). This rule is an explicit optimal vertex of a linear program (LP) characterized by feasibility and sequential obedience constraints. Empirically, in both vaccination and technology-adoption domains, our constructive policy matches LP optima, scales as $O(|\Theta|\log|\Theta|)$, and avoids the inflated welfare predicted by obedience-only designs that assume the designer can dictate the (best) equilibrium. The result is a general, scalable recipe for robust coordination in MAS with complementarities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22915v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farzaneh Farhadi, Maria Chli</dc:creator>
    </item>
    <item>
      <title>Social Welfare in Budget Aggregation</title>
      <link>https://arxiv.org/abs/2602.23027</link>
      <description>arXiv:2602.23027v1 Announce Type: new 
Abstract: We study budget aggregation under $\ell_1$-utilities, a model for collective decision making in which agents with heterogeneous preferences must allocate a public budget across a set of alternatives. Each agent reports their preferred allocation, and a mechanism selects an allocation. Early work focused on social welfare maximization, which in this setting admits truthful mechanisms, but may underrepresent minority groups, motivating the study of proportional mechanisms. However, the dominant proportionality notion, single-minded proportionality, is weak, as it only constrains outcomes when agents hold extreme preferences. To better understand proportionality and its interaction with welfare and truthfulness, we address three questions. First, how much welfare must be sacrificed to achieve proportionality? We formalize this via the price of proportionality, the best worst-case welfare ratio between a proportional mechanism and Util, the welfare-maximizing mechanism. We introduce a new single-minded proportional and truthful mechanism, UtilProp, and show that it achieves the optimal worst-case ratio. Second, how do proportional mechanisms compare in terms of welfare? We define an instance-wise welfare dominance relation and use it to compare mechanisms from the literature. In particular, we show that UtilProp welfare-dominates all previously known single-minded proportional and truthful mechanisms. Third, can stronger notions of proportionality be achieved without compromising welfare guarantees? We answer this question in the affirmative by studying decomposability and proposing GreedyDecomp, a decomposable mechanism with optimal worst-case welfare ratio. We further show that computing the welfare-dominant decomposable mechanism, UtilDecomp, is NP-hard, and that GreedyDecomp provides a 2-approximation to UtilDecomp in terms of welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23027v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Rupert Freeman, Ulrike Schmidt-Kraepelin, Markus Utke</dc:creator>
    </item>
    <item>
      <title>Approximately Solving Continuous-Time Mean Field Games with Finite State Spaces</title>
      <link>https://arxiv.org/abs/2602.23174</link>
      <description>arXiv:2602.23174v1 Announce Type: new 
Abstract: Mean field games (MFGs) offer a powerful framework for modeling large-scale multi-agent systems. This paper addresses MFGs formulated in continuous time with discrete state spaces, where agents' dynamics are governed by continuous-time Markov chains -- relevant to applications like population dynamics and queueing networks. While prior research has largely focused on theoretical aspects of continuous-time discrete-state MFGs, efficient computational methods for determining equilibria remain underdeveloped. Inspired by discrete-time approaches, we approximate the classical Nash equilibria by regularization methods, enabling more computationally tractable solution algorithms. Specifically, we define regularized equilibria for continuous-time MFGs and extend the classical fixed-point iteration and fictitious play algorithm to these equilibria. We validate the effectiveness and practicality of our approach via illustrative numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23174v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannick Eich, Christian Fabian, Kai Cui, Heinz Koeppl</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Stackelberg Control in Combinatorial Congestion Games</title>
      <link>https://arxiv.org/abs/2602.23277</link>
      <description>arXiv:2602.23277v1 Announce Type: new 
Abstract: We study Stackelberg (leader--follower) tuning of network parameters (tolls, capacities, incentives) in combinatorial congestion games, where selfish users choose discrete routes (or other combinatorial strategies) and settle at a congestion equilibrium. The leader minimizes a system-level objective (e.g., total travel time) evaluated at equilibrium, but this objective is typically nonsmooth because the set of used strategies can change abruptly. We propose ZO-Stackelberg, which couples a projection-free Frank--Wolfe equilibrium solver with a zeroth-order outer update, avoiding differentiation through equilibria. We prove convergence to generalized Goldstein stationary points of the true equilibrium objective, with explicit dependence on the equilibrium approximation error, and analyze subsampled oracles: if an exact minimizer is sampled with probability $\kappa_m$, then the Frank--Wolfe error decays as $\mathcal{O}(1/(\kappa_m T))$. We also propose stratified sampling as a practical way to avoid a vanishing $\kappa_m$ when the strategies that matter most for the Wardrop equilibrium concentrate in a few dominant combinatorial classes (e.g., short paths). Experiments on real-world networks demonstrate that our method achieves orders-of-magnitude speedups over a differentiation-based baseline while converging to follower equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23277v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saeed Masiha, Sepehr Elahi, Negar Kiyavash, Patrick Thiran</dc:creator>
    </item>
    <item>
      <title>Impacts of Aggregation on Model Diversity and Consumer Utility</title>
      <link>https://arxiv.org/abs/2602.23293</link>
      <description>arXiv:2602.23293v1 Announce Type: new 
Abstract: Consider a marketplace of AI tools, each with slightly different strengths and weaknesses. By selecting the right model for the task at hand, a user can do better than simply committing to a single model for everything. Routers operate under a similar principle, where sophisticated model selection can increase overall performance. However, aggregation is often noisy, reflecting in imperfect user choices or routing decisions. This leads to two main questions: first, what does a "healthy marketplace" of models look like for maximizing consumer utility? Secondly, how can we incentivize producers to create such models? Here, we study two types of model changes: market entry (where an entirely new model is created and added to the set of available models), and model replacement (where an existing model has its strengths and weaknesses changed). We show that winrate, a standard benchmark in LLM evaluation, can incentivize model creators to homogenize for both types of model changes, reducing consumer welfare. We propose a new mechanism, weighted winrate, which rewards models for answers that are higher quality, and show that it provably improves incentives for producers to specialize and increases consumer welfare. We conclude by demonstrating that our theoretical results generalize to empirical benchmark datasets and discussing implications for evaluation design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23293v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kate Donahue, Manish Raghavan</dc:creator>
    </item>
    <item>
      <title>An Adaptive Multichain Blockchain: A Multiobjective Optimization Approach</title>
      <link>https://arxiv.org/abs/2602.22230</link>
      <description>arXiv:2602.22230v1 Announce Type: cross 
Abstract: Blockchains are widely used for secure transaction processing, but their scalability remains limited, and existing multichain designs are typically static even as demand and capacity shift. We cast blockchain configuration as a multiagent resource-allocation problem: applications and operators declare demand, capacity, and price bounds; an optimizer groups them into ephemeral chains each epoch and sets a chain-level clearing price. The objective maximizes a governance-weighted combination of normalized utilities for applications, operators, and the system. The model is modular -- accommodating capability compatibility, application-type diversity, and epoch-to-epoch stability -- and can be solved off-chain with outcomes verifiable on-chain. We analyze fairness and incentive issues and present simulations that highlight trade-offs among throughput, decentralization, operator yield, and service stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22230v1</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nimrod Talmon, Haim Zysberg</dc:creator>
    </item>
    <item>
      <title>Transaction Ordering Auctions</title>
      <link>https://arxiv.org/abs/2312.02055</link>
      <description>arXiv:2312.02055v2 Announce Type: replace 
Abstract: We study equilibrium investment into bidding and latency reduction for different sequencing policies. For a batch auction design, we observe that bidders shade bids according to the likelihood that competing bidders land in the current batch. Moreover, in equilibrium, in the ex-ante investment stage before the auction, bidders invest into latency until they make zero profit in expectation.
  We compare the batch auction design to continuous time bidding policies (time boost) and observe that (depending on the choice of parameters) they obtain similar revenue and welfare guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02055v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Schlegel</dc:creator>
    </item>
    <item>
      <title>Fair Division via Resource Augmentation</title>
      <link>https://arxiv.org/abs/2502.09377</link>
      <description>arXiv:2502.09377v3 Announce Type: replace 
Abstract: We introduce and formalize the notion of resource augmentation for maximin share (MMS) fairness for the allocation of indivisible goods. Given an instance with $n$ agents and $m$ goods, we ask how many copies of the goods should be added in order to guarantee that each agent receives at least their original MMS value, or a meaningful approximation thereof.
  For general monotone valuations, we establish a tight bound: an exact MMS allocation can be guaranteed using at most $\Theta(m/e)$ total copies, and this bound is tight even for XOS valuations. We further show that it is unavoidable to duplicate some goods $\Omega(\ln m / \ln \ln m)$ times, and provide matching upper bounds. For additive valuations, we show that at most $\min\{n-2,\lfloor\frac{m}{3}\rfloor(1+o(1))\}$ distinct copies suffice. This separates additive valuations from submodular valuations, for which we show that $n-1$ copies may be necessary.
  We also study approximate MMS guarantees for additive valuations and establish new tradeoffs between the number of copies needed and the approximation guaratee. In particular, we prove that $\lfloor{n/2}\rfloor$ copies suffice to guarantee a $6/7$-approximation to the original MMS, and $\lfloor{n/3}\rfloor$ copies suffice for a $4/5$-approximation. Both results improve upon the best-known approximation guarantees for additive valuations in the absence of copies.
  Finally, we relate MMS with copies to the relaxed notion of 1-out-of-$d$ MMS, showing that improvements in either framework translate directly to the other. In particular, we establish the first impossibility results for 1-out-of-$d$ MMS. Our results highlight the power and limits of resource augmentation for achieving MMS fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09377v3</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Siddharth Barman, Alon Eden, Michal Feldman, Amos Fiat, Yoav Gal-Tzur, Satyanand Rammohan, Aditi Sethia</dc:creator>
    </item>
    <item>
      <title>Succinct Ambiguous Contracts</title>
      <link>https://arxiv.org/abs/2503.02592</link>
      <description>arXiv:2503.02592v2 Announce Type: replace 
Abstract: Real-world contracts are often ambiguous. While recent work by D\"utting, Feldman, Peretz, and Samuelson (EC 2023, Econometrica 2024) demonstrates that ambiguous contracts can yield large gains for the principal, their optimal solutions often require deploying an impractically large menu of contracts. This paper investigates \emph{succinct} ambiguous contracts, which are restricted to consist of at most $k$ classic contracts. By letting $k$ range from $1$ to $n-1$, this yields an interpolation between classic contracts ($k=1$) and unrestricted ambiguous contracts ($k=n-1$). This perspective enables important structural and algorithmic results. First, we establish a fundamental separability property: for any number of actions $n$ and any succinctness level $k$, computing an optimal $k$-ambiguous contract reduces to finding optimal classic contracts over a suitable partition of the actions, up to an additive balancing shift acting as a base payment. Second, we show bounds on the principal's loss from using a $k$-ambiguous rather than an unrestricted ambiguous contract, which uncover a striking discontinuity in the principal's utility regarding contract size: lacking even a single contract option may cause the principal's utility to drop sharply by a multiplicative factor of $2$, a bound we prove to be tight. Finally, we characterize the tractability frontier of the optimal $k$-ambiguous contract problem. Our separability result yields a poly-time algorithm whenever the number of partitions of $n-1$ actions into $k$ sets is polynomial, recovering and extending known results for classic and unrestricted ambiguous contracts. We complement this with a tight hardness result, showing that the problem is \textsf{NP}-hard whenever the number of partitions is super-polynomial. Moreover, when $k \approx n/3$, the problem is even hard to approximate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02592v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Duetting, Michal Feldman, Yarden Rashti</dc:creator>
    </item>
    <item>
      <title>Autobidding Equilibria in Sponsored Shopping</title>
      <link>https://arxiv.org/abs/2602.21966</link>
      <description>arXiv:2602.21966v2 Announce Type: replace 
Abstract: As commerce shifts to digital marketplaces, platforms increasingly monetize traffic through Sponsored Shopping auctions. Unlike classic ``Sponsored Search", where an advertiser typically bids for a single link, these settings involve advertisers with broad catalogs of distinct products. In these auctions, a single advertiser can secure multiple slots simultaneously to promote different items within the same query. This creates a fundamental complexity: the allocation is combinatorial, as advertisers simultaneously win a bundle of slots rather than a single position.
  We study this setting through the lens of autobidding, where value-maximizing agents employ uniform bidding strategies to optimize total value subject to Return-on-Investment (ROI) constraints. We analyze two prevalent auction formats: Generalized Second-Price (GSP) and Vickrey-Clarke-Groves (VCG). Our first main contribution is establishing the universal existence of an Autobidding Equilibrium for both settings. Second, we prove a tight Price of Anarchy (PoA) of 2 for both mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21966v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul D\"utting, Yuhao Li, Renato Paes Leme, Kelly Spendlove, Yifeng Teng</dc:creator>
    </item>
  </channel>
</rss>
