<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Entry Deterrence with Partial Reputation Spillovers</title>
      <link>https://arxiv.org/abs/2510.21759</link>
      <description>arXiv:2510.21759v1 Announce Type: new 
Abstract: We analyze a two-period, two-market chain-store game in which an incumbent's conduct in one market is only sometimes seen in the other. This partial observability generates reputational spillovers across markets. We characterize equilibrium behavior by prior reputation: at high priors the strategic incumbent fights a lone early entrant (and mixes when both arrive together); at low priors it mixes against a single entrant and accommodates coordinated entry. Greater observability increases early fighting yet, because any accommodation is more widely noticed, raises the incidence of later entry. The results are robust to noisy signals and endogenous information acquisition, and extend naturally to many markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21759v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rubik Khachatryan, Georgy Lukyanov</dc:creator>
    </item>
    <item>
      <title>Social preferences or moral concerns: What drives rejections in the Ultimatum game?</title>
      <link>https://arxiv.org/abs/2510.22086</link>
      <description>arXiv:2510.22086v1 Announce Type: new 
Abstract: Rejections of positive offers in the Ultimatum Game have been attributed to different motivations. We show that a model combining social preferences and moral concerns provides a unifying explanation for these rejections while accounting for additional evidence. Under the preferences considered, a positive degree of spite is a necessary and sufficient condition for rejecting positive offers. This indicates that social preferences, rather than moral concerns, drive rejection behavior. This does not imply that moral concerns do not matter. We show that rejection thresholds increase with individuals' moral concerns, suggesting that morality acts as an amplifier of social preferences. Using data from van Leeuwen and Alger (2024), we estimate individuals' social preferences and moral concerns using a finite mixture approach. Consistent with previous evidence, we identify two types of individuals who reject positive offers in the Ultimatum Game, but that differ in their Dictator Game behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22086v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pau Juan-Bartroli, Jos\'e Ignacio Rivero-Wildemauwe</dc:creator>
    </item>
    <item>
      <title>Politics, Inequality, and the Robustness of Shared Infrastructure Systems</title>
      <link>https://arxiv.org/abs/2510.22411</link>
      <description>arXiv:2510.22411v1 Announce Type: new 
Abstract: Our infrastructure systems enable our well-being by allowing us to move, store, and transform materials and information given considerable social and environmental variation. Critically, this ability is shaped by the degree to which society invests in infrastructure, a fundamentally political question in large public systems. There, infrastructure providers are distinguished from users through political processes, such as elections, and there is considerable heterogeneity among users. Previous political economic models have not taken into account (i) dynamic infrastructures, (ii) dynamic user preferences, and (iii) alternatives to rational actor theory. Meanwhile, engineering often neglects politics. We address these gaps with a general dynamic model of shared infrastructure systems that incorporates theories from political economy, social-ecological systems, and political psychology. We use the model to develop propositions on how multiple characteristics of the political process impact the robustness of shared infrastructure systems to capacity shocks and unequal opportunity for private infrastructure investment. Under user fees, inequality decreases robustness, but taxing private infrastructure use can increase robustness if non-elites have equal political influence. Election cycle periods have a nonlinear effect where increasing them increases robustness up to a point but decreases robustness beyond that point. Further, there is a negative relationship between the ideological sensitivity of candidates and robustness. Overall, the biases of voters and candidates (whether they favor tax increases or decreases) mediate these political-economic effects on robustness because biases may or may not match the reality of system needs (whether system recovery requires tax increases).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22411v1</guid>
      <category>econ.TH</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adam Wiechman, John M. Anderies, Margaret Garcia</dc:creator>
    </item>
    <item>
      <title>Information-Credible Stability in Matching with Incomplete Information</title>
      <link>https://arxiv.org/abs/2510.22750</link>
      <description>arXiv:2510.22750v1 Announce Type: new 
Abstract: In this paper, I develop a refinement of stability for matching markets with incomplete information. I introduce Information-Credible Pairwise Stability (ICPS), a solution concept in which deviating pairs can use credible, costly tests to reveal match-relevant information before deciding whether to block. By leveraging the option value of information, ICPS strictly refines Bayesian stability, rules out fear-driven matchings, and connects belief-based and information-based notions of stability. ICPS collapses to Bayesian stability when testing is uninformative or infeasible and coincides with complete-information stability when testing is perfect and free. I show that any ICPS-blocking deviation strictly increases total expected surplus, ensuring welfare improvement. I also prove that ICPS-stable allocations always exist, promote positive assortative matching, and are unique when the test power is sufficiently strong. The framework extends to settings with non-transferable utility, correlated types, and endogenous or sequential testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22750v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaibalyapati Mishra</dc:creator>
    </item>
    <item>
      <title>Feedback in Dynamic Contests: Theory and Experiment</title>
      <link>https://arxiv.org/abs/2510.23178</link>
      <description>arXiv:2510.23178v1 Announce Type: new 
Abstract: We study the effect of interim feedback policies in a dynamic all-pay auction where two players bid over two stages to win a common-value prize. We show that sequential equilibrium outcomes are characterized by Cheapest Signal Equilibria, wherein stage 1 bids are such that one player bids zero while the other chooses a cheapest bid consistent with some signal. Equilibrium payoffs for both players are always zero, and the sum of expected total bids equals the value of the prize. We conduct an experiment with four natural feedback policy treatments -- full, rank, and two cutoff policies -- and while the bidding behavior deviates from equilibrium, we fail to reject the hypothesis of no treatment effect on total bids. Further, stage 1 bids induce sunk costs and head starts, and we test for the resulting sunk cost and discouragement effects in stage 2 bidding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23178v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Goel, Yiqing Yan, Jeffrey Zeidel</dc:creator>
    </item>
    <item>
      <title>Nonparametric Identification and Estimation of Spatial Treatment Effect Boundaries: Evidence from 42 Million Pollution Observations</title>
      <link>https://arxiv.org/abs/2510.12289</link>
      <description>arXiv:2510.12289v2 Announce Type: cross 
Abstract: This paper develops a nonparametric framework for identifying and estimating spatial boundaries of treatment effects in settings with geographic spillovers. While atmospheric dispersion theory predicts exponential decay of pollution under idealized assumptions, these assumptions -- steady winds, homogeneous atmospheres, flat terrain -- are systematically violated in practice. I establish nonparametric identification of spatial boundaries under weak smoothness and monotonicity conditions, propose a kernel-based estimator with data-driven bandwidth selection, and derive asymptotic theory for inference. Using 42 million satellite observations of NO$_2$ concentrations near coal plants (2019-2021), I find that nonparametric kernel regression reduces prediction errors by 1.0 percentage point on average compared to parametric exponential decay assumptions, with largest improvements at policy-relevant distances: 2.8 percentage points at 10 km (near-source impacts) and 3.7 percentage points at 100 km (long-range transport). Parametric methods systematically underestimate near-source concentrations while overestimating long-range decay. The COVID-19 pandemic provides a natural experiment validating the framework's temporal sensitivity: NO$_2$ concentrations dropped 4.6\% in 2020, then recovered 5.7\% in 2021. These results demonstrate that flexible, data-driven spatial methods substantially outperform restrictive parametric assumptions in environmental policy applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12289v2</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Nonparametric Identification of Spatial Treatment Effect Boundaries: Evidence from Bank Branch Consolidation</title>
      <link>https://arxiv.org/abs/2510.13148</link>
      <description>arXiv:2510.13148v2 Announce Type: cross 
Abstract: I develop a nonparametric framework for identifying spatial boundaries of treatment effects without imposing parametric functional form restrictions. The method employs local linear regression with data-driven bandwidth selection to flexibly estimate spatial decay patterns and detect treatment effect boundaries. Monte Carlo simulations demonstrate that the nonparametric approach exhibits lower bias and correctly identifies the absence of boundaries when none exist, unlike parametric methods that may impose spurious spatial patterns. I apply this framework to bank branch openings during 2015--2020, matching 5,743 new branches to 5.9 million mortgage applications across 14,209 census tracts. The analysis reveals that branch proximity significantly affects loan application volume (8.5\% decline per 10 miles) but not approval rates, consistent with branches stimulating demand through local presence while credit decisions remain centralized. Examining branch survival during the digital transformation era (2010--2023), I find a non-monotonic relationship with area income: high-income areas experience more closures despite conventional wisdom. This counterintuitive pattern reflects strategic consolidation of redundant branches in over-banked wealthy urban areas rather than discrimination against poor neighborhoods. Controlling for branch density, urbanization, and competition, the direct income effect diminishes substantially, with branch density emerging as the primary determinant of survival. These findings demonstrate the necessity of flexible nonparametric methods for detecting complex spatial patterns that parametric models would miss, and challenge simplistic narratives about banking deserts by revealing the organizational complexity underlying spatial consolidation decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13148v2</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Dynamic Spatial Treatment Effect Boundaries: A Continuous Functional Framework from Navier-Stokes Equations</title>
      <link>https://arxiv.org/abs/2510.14409</link>
      <description>arXiv:2510.14409v2 Announce Type: cross 
Abstract: I develop a comprehensive theoretical framework for dynamic spatial treatment effect boundaries using continuous functional definitions grounded in Navier-Stokes partial differential equations. Rather than discrete treatment effect estimators, the framework characterizes treatment intensity as a continuous function $\tau(\mathbf{x}, t)$ over space-time, enabling rigorous analysis of propagation dynamics, boundary evolution, and cumulative exposure patterns. Building on exact self-similar solutions expressible through Kummer confluent hypergeometric and modified Bessel functions, I establish that treatment effects follow scaling laws $\tau(d, t) = t^{-\alpha} f(d/t^\beta)$ where exponents characterize diffusion mechanisms. Empirical validation using 42 million TROPOMI satellite observations of NO$_2$ pollution from U.S. coal-fired power plants demonstrates strong exponential spatial decay ($\kappa_s = 0.004$ per km, $R^2 = 0.35$) with detectable boundaries at 572 km. Monte Carlo simulations confirm superior performance over discrete parametric methods in boundary detection and false positive avoidance (94\% vs 27\% correct rejection). Regional heterogeneity analysis validates diagnostic capability: positive decay parameters within 100 km confirm coal plant dominance; negative parameters beyond 100 km correctly signal when urban sources dominate. The continuous functional perspective unifies spatial econometrics with mathematical physics, providing theoretically grounded methods for boundary detection, exposure quantification, and policy evaluation across environmental economics, banking, and healthcare applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14409v2</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access</title>
      <link>https://arxiv.org/abs/2510.15324</link>
      <description>arXiv:2510.15324v3 Announce Type: cross 
Abstract: I develop a continuous functional framework for spatial treatment effects grounded in Navier-Stokes partial differential equations. Rather than discrete treatment parameters, the framework characterizes treatment intensity as continuous functions $\tau(\mathbf{x}, t)$ over space-time, enabling rigorous analysis of boundary evolution, spatial gradients, and cumulative exposure. Empirical validation using 32,520 U.S. ZIP codes demonstrates exponential spatial decay for healthcare access ($\kappa = 0.002837$ per km, $R^2 = 0.0129$) with detectable boundaries at 37.1 km. The framework successfully diagnoses when scope conditions hold: positive decay parameters validate diffusion assumptions near hospitals, while negative parameters correctly signal urban confounding effects. Heterogeneity analysis reveals 2-13 $\times$ stronger distance effects for elderly populations and substantial education gradients. Model selection strongly favors logarithmic decay over exponential ($\Delta \text{AIC} &gt; 10,000$), representing a middle ground between exponential and power-law decay. Applications span environmental economics, banking, and healthcare policy. The continuous functional framework provides predictive capability ($d^*(t) = \xi^* \sqrt{t}$), parameter sensitivity ($\partial d^*/\partial \nu$), and diagnostic tests unavailable in traditional difference-in-differences approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15324v3</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Network Contagion Dynamics in European Banking: A Navier-Stokes Framework for Systemic Risk Assessment</title>
      <link>https://arxiv.org/abs/2510.19630</link>
      <description>arXiv:2510.19630v2 Announce Type: cross 
Abstract: This paper develops a continuous functional framework for analyzing contagion dynamics in financial networks, extending the Navier-Stokes-based approach to network-structured spatial processes. We model financial distress propagation as a diffusion process on weighted networks, deriving a network diffusion equation from first principles that predicts contagion decay depends on the network's algebraic connectivity through the relation $\kappa = \sqrt{\lambda_2/D}$, where $\lambda_2$ is the second-smallest eigenvalue of the graph Laplacian and $D$ is the diffusion coefficient. Applying this framework to European banking data from the EBA stress tests (2018, 2021, 2023), we estimate interbank exposure networks using maximum entropy methods and track the evolution of systemic risk through the COVID-19 crisis. Our key finding is that network connectivity declined by 45\% from 2018 to 2023, implying a 26\% reduction in the contagion decay parameter. Difference-in-differences analysis reveals this structural change was driven by regulatory-induced deleveraging of systemically important banks, which experienced differential asset reductions of 17\% relative to smaller institutions. The networks exhibit lognormal rather than scale-free degree distributions, suggesting greater resilience than previously assumed in the literature. Extensive robustness checks across parametric and non-parametric estimation methods confirm declining systemic risk, with cross-method correlations exceeding 0.95. These findings demonstrate that post-COVID-19 regulatory reforms effectively reduced network interconnectedness and systemic vulnerability in the European banking system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19630v2</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Rational Adversaries and the Maintenance of Fragility: A Game-Theoretic Theory of Rational Stagnation</title>
      <link>https://arxiv.org/abs/2510.22232</link>
      <description>arXiv:2510.22232v1 Announce Type: cross 
Abstract: Cooperative systems often remain in persistently suboptimal yet stable states. This paper explains such "rational stagnation" as an equilibrium sustained by a rational adversary whose utility follows the principle of potential loss, $u_{D} = U_{ideal} - U_{actual}$. Starting from the Prisoner's Dilemma, we show that the transformation $u_{i}' = a\,u_{i} + b\,u_{j}$ and the ratio of mutual recognition $w = b/a$ generate a fragile cooperation band $[w_{\min},\,w_{\max}]$ where both (C,C) and (D,D) are equilibria. Extending to a dynamic model with stochastic cooperative payoffs $R_{t}$ and intervention costs $(C_{c},\,C_{m})$, a Bellman-style analysis yields three strategic regimes: immediate destruction, rational stagnation, and intervention abandonment. The appendix further generalizes the utility to a reference-dependent nonlinear form and proves its stability under reference shifts, ensuring robustness of the framework. Applications to social-media algorithms and political trust illustrate how adversarial rationality can deliberately preserve fragility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22232v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisuke Hirota</dc:creator>
    </item>
    <item>
      <title>Efficiently Learning Synthetic Control Models for High-dimensional Disaggregated Data</title>
      <link>https://arxiv.org/abs/2510.22828</link>
      <description>arXiv:2510.22828v1 Announce Type: cross 
Abstract: The Synthetic Control method (SC) has become a valuable tool for estimating causal effects. Originally designed for single-treated unit scenarios, it has recently found applications in high-dimensional disaggregated settings with multiple treated units. However, challenges in practical implementation and computational efficiency arise in such scenarios. To tackle these challenges, we propose a novel approach that integrates the Multivariate Square-root Lasso method into the synthetic control framework. We rigorously establish the estimation error bounds for fitting the Synthetic Control weights using Multivariate Square-root Lasso, accommodating high-dimensionality and time series dependencies. Additionally, we quantify the estimation error for the Average Treatment Effect on the Treated (ATT). Through simulation studies, we demonstrate that our method offers superior computational efficiency without compromising estimation accuracy. We apply our method to assess the causal impact of COVID-19 Stay-at-Home Orders on the monthly unemployment rate in the United States at the county level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22828v1</guid>
      <category>stat.ME</category>
      <category>econ.TH</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Shen, Rui Song, Alberto Abadie</dc:creator>
    </item>
    <item>
      <title>Game Intelligence: Theory and Computation</title>
      <link>https://arxiv.org/abs/2302.13937</link>
      <description>arXiv:2302.13937v5 Announce Type: replace 
Abstract: In this paper, I formalize intelligence measurement in games by introducing mechanisms that assign a real number -- interpreted as an intelligence score -- to each player in a game. This score quantifies the ex-post strategic ability of the players based on empirically observable information, such as the actions of the players, the game's outcome, strength of the players, and a reference oracle machine such as a chess-playing artificial intelligence system. Specifically, I introduce two main concepts: first, the Game Intelligence (GI) mechanism, which quantifies a player's intelligence in a game by considering not only the game's outcome but also the "mistakes" made during the game according to the reference machine's intelligence. Second, I define gamingproofness, a practical and computational concept of strategyproofness. To illustrate the GI mechanism, I apply it to an extensive dataset comprising over a billion chess moves, including over a million moves made by top 20 grandmasters in history. Notably, Magnus Carlsen emerges with the highest GI score among all world championship games included in the dataset. In machine-vs-machine games, the well-known chess engine Stockfish comes out on top.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13937v5</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehmet Mars Seven</dc:creator>
    </item>
    <item>
      <title>A Constructive Characterization of Optimal Bundling</title>
      <link>https://arxiv.org/abs/2502.07863</link>
      <description>arXiv:2502.07863v3 Announce Type: replace 
Abstract: This paper studies a monopolist selling multiple goods to a consumer with one-dimensional private types. I provide a sufficient condition under which the monopolist's problem is equivalent to finding the upper envelope of the marginal revenue curves. This approach guarantees that the optimal mechanism is deterministic and can be implemented via a menu of bundles. I further characterize this upper envelope using a dominance notion. This characterization yields a constructive algorithm to compute the optimal menu by iteratively eliminating dominated bundles. As my main application, I use this framework to introduce and provide sufficient conditions for the optimality of tree bundling, a common but previously unmodeled sales strategy where the optimal menu contains a root bundle but features distinct upgrade paths. This structure captures prevalent sales practices across industries, from automobile manufacturers offering base models with customizable upgrade packages, to software companies allowing modular feature additions. This structure captures prevalent sales practices across industries, from automobile manufacturers offering base models with customizable upgrade packages, to software companies allowing modular feature additions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07863v3</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiming Feng</dc:creator>
    </item>
    <item>
      <title>Berk-Nash Rationalizability</title>
      <link>https://arxiv.org/abs/2505.20708</link>
      <description>arXiv:2505.20708v3 Announce Type: replace 
Abstract: We study learning in complete-information games, allowing the players' models of their environment to be misspecified. We introduce Berk--Nash rationalizability: the largest self-justified set of actions -- meaning each action in the set is optimal under some belief that is a best fit to outcomes generated by joint play within the set. We show that, in a model where players learn from past actions, every action played (or approached) infinitely often lies in this set. When players have a correct model of their environment, Berk--Nash rationalizability refines (correlated) rationalizability and coincides with it in two-player games. The concept delivers predictions on long-run behavior regardless of whether actions converge or not, thereby providing a practical alternative to proving convergence or solving complex stochastic learning dynamics. For example, if the rationalizable set is a singleton, actions converge almost surely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20708v3</guid>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ignacio Esponda, Demian Pouzo</dc:creator>
    </item>
    <item>
      <title>Token Is All You Price</title>
      <link>https://arxiv.org/abs/2510.09859</link>
      <description>arXiv:2510.09859v2 Announce Type: replace 
Abstract: We build a mechanism design framework where a platform designs GenAI models to screen users who obtain instrumental value from the generated conversation and privately differ in their preference for latency. We show that the revenue-optimal mechanism is simple: deploy a single aligned (user-optimal) model and use token cap as the only instrument to screen the user. The design decouples model training from pricing, is readily implemented with token metering, and mitigates misalignment pressures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09859v2</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weijie Zhong</dc:creator>
    </item>
    <item>
      <title>Game Theory Analysis of Third-Party Regulation in Organic Supply Chains</title>
      <link>https://arxiv.org/abs/2510.12420</link>
      <description>arXiv:2510.12420v2 Announce Type: replace 
Abstract: As people become more conscious of their health and the environment, the demand for organic food is expected to increase. However, distinguishing organic products from conventionally produced ones can be hard, creating a problem where producers may have the incentive to label their conventional products as organic to sell them at a higher price. Game theory can help to analyze the strategic interactions between producers and consumers in order to help consumers verifying these claims. Through a game theory analysis approach, this paper provides evidence of the need for a third party to equalize markets and foster trust in organic supply chains. Therefore, government regulation, including regular and random monitoring and certification requirements, plays a crucial role in achieving the desired level of trust and information exchange among supply chain agents, which ultimately determines the growth trajectory of the sector.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12420v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joao Zambujal-Oliveira, Andre Silva, Rui Vasconcelos</dc:creator>
    </item>
    <item>
      <title>Learning to Coordinate Bidders in Non-Truthful Auctions</title>
      <link>https://arxiv.org/abs/2507.02801</link>
      <description>arXiv:2507.02801v2 Announce Type: replace-cross 
Abstract: In non-truthful auctions such as first-price and all-pay auctions, the independent strategic behaviors of bidders, with the corresponding Bayes-Nash equilibrium notion, are notoriously difficult to characterize and can cause undesirable outcomes. An alternative approach to achieve better outcomes in non-truthful auctions is to coordinate the bidders: let a mediator make incentive-compatible recommendations of correlated bidding strategies to the bidders, namely, implementing a Bayes correlated equilibrium (BCE). The implementation of BCE, however, requires knowledge of the distributions of bidders' private valuations, which is often unavailable. We initiate the study of the sample complexity of learning Bayes correlated equilibria in non-truthful auctions. We prove that the set of strategic-form BCEs in a large class of non-truthful auctions, including first-price and all-pay auctions, can be learned with a polynomial number $\tilde O(\frac{n}{\varepsilon^2})$ of samples of bidders' values. This moderate number of samples demonstrates the statistical feasibility of learning to coordinate bidders. Our technique is a reduction to the problem of estimating bidders' expected utility from samples, combined with an analysis of the pseudo-dimension of the class of all monotone bidding strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02801v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hu Fu, Tao Lin</dc:creator>
    </item>
    <item>
      <title>From tug-of-war to Brownian Boost: explicit ODE solutions for player-funded stochastic-differential games</title>
      <link>https://arxiv.org/abs/2510.07682</link>
      <description>arXiv:2510.07682v3 Announce Type: replace-cross 
Abstract: Brownian Boost is a one-parameter family of stochastic differential games played on the real line in which players spend at rates of their choosing in an ongoing effort to influence the drift of a randomly diffusing point particle~$X$. One or other player is rewarded, at time infinity, according to whether~$X$ tends to plus or minus infinity. Each player's net receipt is the final reward (only for the victor) minus the player's total spend. We characterise and explicitly compute the time-homogeneous Markov-perfect Nash equilibria of Brownian Boost, finding the derivatives of the players' expected payoffs to solve a pair of coupled first-order non-linear ODE. Brownian Boost is a high-noise limit of a two-dimensional family of player-funded tug-of-war games, one of which was studied in~\cite{LostPennies}. We analyse the discrete games, finding them, and Brownian Boost, to exemplify key features studied in the economics literature of tug-of-war initiated by~\cite{HarrisVickers87}: a battlefield region where players spend heavily;
  stakes that decay rapidly but asymmetrically in distance to the battlefield; and an effect of discouragement that makes equilibria fragile under asymmetric perturbation of incentive.
  Tug-of-war has a parallel mathematical literature derived from~\cite{PSSW09}, which solved the scaled fair-coin game in a Euclidean domain via the infinity Laplacian PDE. By offering an analytic solution to Brownian Boost, a game that models strategic interaction and resource allocation, we seek to build a bridge between the two tug-of-war literatures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07682v3</guid>
      <category>math.PR</category>
      <category>econ.TH</category>
      <category>math.CA</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan Hammond</dc:creator>
    </item>
  </channel>
</rss>
