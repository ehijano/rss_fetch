<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 May 2024 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Shape of Brainscores for Large Language Models (LLMs)</title>
      <link>https://arxiv.org/abs/2405.06725</link>
      <description>arXiv:2405.06725v1 Announce Type: new 
Abstract: With the rise of Large Language Models (LLMs), the novel metric "Brainscore" emerged as a means to evaluate the functional similarity between LLMs and human brain/neural systems. Our efforts were dedicated to mining the meaning of the novel score by constructing topological features derived from both human fMRI data involving 190 subjects, and 39 LLMs plus their untrained counterparts. Subsequently, we trained 36 Linear Regression Models and conducted thorough statistical analyses to discern reliable and valid features from our constructed ones. Our findings reveal distinctive feature combinations conducive to interpreting existing brainscores across various brain regions of interest (ROIs) and hemispheres, thereby significantly contributing to advancing interpretable machine learning (iML) studies. The study is enriched by our further discussions and analyses concerning existing brainscores. To our knowledge, this study represents the first attempt to comprehend the novel metric brainscore within this interdisciplinary domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06725v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingkai Li</dc:creator>
    </item>
    <item>
      <title>A Global Data-Driven Model for The Hippocampus and Nucleus Accumbens of Rat From The Local Field Potential Recordings (LFP)</title>
      <link>https://arxiv.org/abs/2405.06732</link>
      <description>arXiv:2405.06732v1 Announce Type: new 
Abstract: In brain neural networks, Local Field Potential (LFP) signals represent the dynamic flow of information. Analyzing LFP clinical data plays a critical role in improving our understanding of brain mechanisms. One way to enhance our understanding of these mechanisms is to identify a global model to predict brain signals in different situations. This paper identifies a global data-driven based on LFP recordings of the Nucleus Accumbens and Hippocampus regions in freely moving rats. The LFP is recorded from each rat in two different situations: before and after the process of getting a reward which can be either a drug (Morphine) or natural food (like popcorn or biscuit). A comparison of five machine learning methods including Long Short Term Memory (LSTM), Echo State Network (ESN), Deep Echo State Network (DeepESN), Radial Basis Function (RBF), and Local Linear Model Tree (LLM) is conducted to develop this model. LoLiMoT was chosen with the best performance among all methods. This model can predict the future states of these regions with one pre-trained model. Identifying this model showed that Morphine and natural rewards do not change the dynamic features of neurons in these regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06732v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maedeh Sadeghi (Fault Detection and Identification), Mahdi Aliyari Shoorehdeli (Fault Detection and Identification), Shole jamali (Neuroscience Research Center, School of Medicine, Shahid Beheshti University of Medical Sciences, Tehran, Iran), Abbas Haghparast (Neuroscience Research Center, School of Medicine, Shahid Beheshti University of Medical Sciences, Tehran, Iran)</dc:creator>
    </item>
    <item>
      <title>Nonlinear classification of neural manifolds with contextual information</title>
      <link>https://arxiv.org/abs/2405.06851</link>
      <description>arXiv:2405.06851v1 Announce Type: new 
Abstract: Understanding how neural systems efficiently process information through distributed representations is a fundamental challenge at the interface of neuroscience and machine learning. Recent approaches analyze the statistical and geometrical attributes of neural representations as population-level mechanistic descriptors of task implementation. In particular, manifold capacity has emerged as a promising framework linking population geometry to the separability of neural manifolds. However, this metric has been limited to linear readouts. Here, we propose a theoretical framework that overcomes this limitation by leveraging contextual input information. We derive an exact formula for the context-dependent capacity that depends on manifold geometry and context correlations, and validate it on synthetic and real data. Our framework's increased expressivity captures representation untanglement in deep networks at early stages of the layer hierarchy, previously inaccessible to analysis. As context-dependent nonlinearity is ubiquitous in neural systems, our data-driven and theoretically grounded approach promises to elucidate context-dependent computation across scales, datasets, and models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06851v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Mignacco, Chi-Ning Chou, SueYeon Chung</dc:creator>
    </item>
    <item>
      <title>Environmental enrichment: a biological model of forward transfer in continual learning</title>
      <link>https://arxiv.org/abs/2405.07295</link>
      <description>arXiv:2405.07295v1 Announce Type: new 
Abstract: Continual learning (CL) refers to an agent's capability to learn from a continuous stream of data and transfer knowledge without forgetting old information. One crucial aspect of CL is forward transfer, i.e., improved and faster learning on a new task by leveraging information from prior knowledge. While this ability comes naturally to biological brains, it poses a significant challenge for artificial intelligence (AI). Here, we suggest that environmental enrichment (EE) can be used as a biological model for studying forward transfer, inspiring human-like AI development. EE refers to animal studies that enhance cognitive, social, motor, and sensory stimulation and is a model for what, in humans, is referred to as 'cognitive reserve'. Enriched animals show significant improvement in learning speed and performance on new tasks, typically exhibiting forward transfer. We explore anatomical, molecular, and neuronal changes post-EE and discuss how artificial neural networks (ANNs) can be used to predict neural computation changes after enriched experiences. Finally, we provide a synergistic way of combining neuroscience and AI research that paves the path toward developing AI capable of rapid and efficient new task learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07295v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rajat Saxena, Bruce L. McNaughton</dc:creator>
    </item>
    <item>
      <title>Topological Embedding of Human Brain Networks with Applications to Dynamics of Temporal Lobe Epilepsy</title>
      <link>https://arxiv.org/abs/2405.07835</link>
      <description>arXiv:2405.07835v1 Announce Type: new 
Abstract: We introduce a novel, data-driven topological data analysis (TDA) approach for embedding brain networks into a lower-dimensional space in quantifying the dynamics of temporal lobe epilepsy (TLE) obtained from resting-state functional magnetic resonance imaging (rs-fMRI). This embedding facilitates the orthogonal projection of 0D and 1D topological features, allowing for the visualization and modeling of the dynamics of functional human brain networks in a resting state. We then quantify the topological disparities between networks to determine the coordinates for embedding. This framework enables us to conduct a coherent statistical inference within the embedded space. Our results indicate that brain network topology in TLE patients exhibits increased rigidity in 0D topology but more rapid flections compared to that of normal controls in 1D topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07835v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moo K. Chung, Ji Bi Che, Veena A. Nair, Camille Garcia Ramos, Jedidiah Ray Mathis, Vivek Prabhakaran, Elizabeth Meyerand, Bruce P. Hermann, Jeffrey R. Binder, Aaron F. Struck</dc:creator>
    </item>
    <item>
      <title>Why Decussate? Topological Constraints on 3D Wiring</title>
      <link>https://arxiv.org/abs/2405.07837</link>
      <description>arXiv:2405.07837v1 Announce Type: new 
Abstract: Many vertebrate motor and sensory systems decussate, or cross the midline to the opposite side of the body. The successful crossing of millions of axons during development requires a complex of tightly controlled regulatory processes. Because these processes have evolved in many distinct systems and organisms, it seems reasonable to presume that decussation confers a significant functional advantage. Yet if this is so, the nature of this advantage is not understood. In this article, we examine constraints imposed by topology on the ways that a three-dimensional processor and environment can be wired together in a continuous, somatotopic, way. We show that as the number of wiring connections grows, decussated arrangements become overwhelmingly more robust against wiring errors than seemingly simpler same-sided wiring schemes. These results provide a predictive approach for understanding how 3D networks must be wired if they are to be robust, and therefore have implications both for future large-scale computational networks and for complex bio-medical devices</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07837v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>math.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1002/ar.20731</arxiv:DOI>
      <arxiv:journal_reference>The Anatomical Record 291.10 (2008) 1278-1292</arxiv:journal_reference>
      <dc:creator>Troy Shinbrot, Wise Young</dc:creator>
    </item>
    <item>
      <title>Using GANs for De Novo Protein Design Targeting Microglial IL-3R$\alpha$ to Inhibit Alzheimer's Progression</title>
      <link>https://arxiv.org/abs/2405.06651</link>
      <description>arXiv:2405.06651v1 Announce Type: cross 
Abstract: IL-3 is a hemopoietic growth factor that usually targets blood cell precursors; IL-3R is a cytokine receptor that binds to IL-3. However, IL-3 takes on a different role in the context of glial cells in the nervous system, where studies show that the protein IL-3 protects against Alzheimer's disease by activating microglia at their IL-3R receptors, causing the microglia to clear out the tangles caused by the build-up of misfolded Tau proteins. In this study, we seek to ascertain what role the secondary structure of IL-3 plays in its binding with the receptor. The motivation behind this study is to learn more about the mechanism and identify possible drugs that might be able to activate it, in hopes of inhibiting the spread of Alzheimer's Disease. From a preliminary analysis of complexes containing IL-3 and IL-3R, we hypothesized that the binding is largely due to the interactions of three alpha helix structures stretching towards the active site on the receptor. The original Il-3 protein serves as the control in this experiment; the other proteins being tested are generated through several types of computational de novo protein design, where machine learning allows for the production of entirely novel structures. The efficacy of the generated proteins is assessed through docking simulations with the IL-3R receptor, and the binding poses are also qualitatively examined to gain insight into the function of the binding. From the docking data and poses, the most successful proteins were those with similar secondary structure to IL-3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06651v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnav Swaroop</dc:creator>
    </item>
    <item>
      <title>A Demographic-Conditioned Variational Autoencoder for fMRI Distribution Sampling and Removal of Confounds</title>
      <link>https://arxiv.org/abs/2405.07977</link>
      <description>arXiv:2405.07977v1 Announce Type: cross 
Abstract: Objective: fMRI and derived measures such as functional connectivity (FC) have been used to predict brain age, general fluid intelligence, psychiatric disease status, and preclinical neurodegenerative disease. However, it is not always clear that all demographic confounds, such as age, sex, and race, have been removed from fMRI data. Additionally, many fMRI datasets are restricted to authorized researchers, making dissemination of these valuable data sources challenging. Methods: We create a variational autoencoder (VAE)-based model, DemoVAE, to decorrelate fMRI features from demographics and generate high-quality synthetic fMRI data based on user-supplied demographics. We train and validate our model using two large, widely used datasets, the Philadelphia Neurodevelopmental Cohort (PNC) and Bipolar and Schizophrenia Network for Intermediate Phenotypes (BSNIP). Results: We find that DemoVAE recapitulates group differences in fMRI data while capturing the full breadth of individual variations. Significantly, we also find that most clinical and computerized battery fields that are correlated with fMRI data are not correlated with DemoVAE latents. An exception are several fields related to schizophrenia medication and symptom severity. Conclusion: Our model generates fMRI data that captures the full distribution of FC better than traditional VAE or GAN models. We also find that most prediction using fMRI data is dependent on correlation with, and prediction of, demographics. Significance: Our DemoVAE model allows for generation of high quality synthetic data conditioned on subject demographics as well as the removal of the confounding effects of demographics. We identify that FC-based prediction tasks are highly influenced by demographic confounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07977v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Orlichenko, Gang Qu, Ziyu Zhou, Anqi Liu, Hong-Wen Deng, Zhengming Ding, Julia M. Stephen, Tony W. Wilson, Vince D. Calhoun, Yu-Ping Wang</dc:creator>
    </item>
    <item>
      <title>Estimating the contribution of early and late noise in vision from psychophysical data</title>
      <link>https://arxiv.org/abs/2012.06608</link>
      <description>arXiv:2012.06608v2 Announce Type: replace 
Abstract: In many psychophysical detection and discrimination tasks human performance is thought to be limited by internal or inner noise when neuronal activity is converted into an overt behavioural response. It is unclear, however, to what extent the behaviourally limiting inner noise arises from early noise in the photoreceptors and the retina, or from late noise in cortex at or immediately prior to the decision stage. Presumably, the behaviourally limiting inner noise is a non-trivial combination of both early and late noises. Here we propose a method to quantify the contributions of early and late noise purely from psychophysical data. Our analysis generalizes classical results for linear systems (Burgess and Colborne, 1988) by combining the theory of noise propagation through a nonlinear network (Ahumada, 1987) with the expressions to obtain the perceptual metric along the nonlinear network (Malo and Simoncelli, 2006; Laparra et al., 2010). We show that from threshold-only data the relative contribution of early and late noise can only be determined if the experiments include substantial external noise in some of the stimuli used during experiments. If experimenters collected full psychometric functions, however, then early and late noise sources can be quantified even in the absence of external noise. Our psychophysical estimate of the magnitude of the early noise assuming a standard cascade of linear and nonlinear model stages is substantially lower than the noise in cone photocurrents computed via an accurate model of retinal physiology (Brainard and Wandell, 2020, ISETBIO). This is consistent with the idea that one of the fundamental tasks of early vision is to reduce the comparatively large retinal noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.06608v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jesus Malo, Jose Juan Esteve-Taboada, Guillermo Aguilar, Marianne Maertens, Felix A. Wichmann</dc:creator>
    </item>
    <item>
      <title>Comparison and Analysis of Cognitive Load under 2D/3D Visual Stimuli</title>
      <link>https://arxiv.org/abs/2302.12968</link>
      <description>arXiv:2302.12968v4 Announce Type: replace 
Abstract: With the increasing prevalence of 3D videos, investigating the differences of viewing experiences between 2D and 3D videos has become an important issue. In this study, we explored the cognitive load induced by 2D and 3D video stimuli under various cognitive tasks utilizing electroencephalogram (EEG) data. We also introduced the Cognitive Load Index (CLI), a metric which combines {\theta} and {\alpha} oscillations to evaluate the cognitive differences. Four video stimuli, each associated with typical cognitive tasks were adopted in our experiments. Subjects were exposed to both 2D and 3D video stimuli, and the corresponding EEG data were recorded. Then, we analyzed the power within the 0.5-45 Hz frequency of EEG data, and CLI was utilized to evaluate the brain activity of different subjects. According to our experiments and analysis, videos that involve simple observational tasks (P &lt;0.05) consistently induced a higher cognitive load in subjects when they were viewing 3D videos. However, for videos that involve calculation tasks (P &gt;0.05), the differences in cognitive load induced by 2D and 3D video were not obvious. Thus, we concluded that 3D videos could generally induce a higher cognitive load, but the extent of the differences also depended on the contents of the video stimuli and the viewing purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12968v4</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yu Liu, Chen Song, Yunpeng Yin, Herui Shi, Jinglin Sun, Han Wang, Peiguang Jing</dc:creator>
    </item>
    <item>
      <title>Emergent rate-based dynamics in duplicate-free populations of spiking neurons</title>
      <link>https://arxiv.org/abs/2303.05174</link>
      <description>arXiv:2303.05174v4 Announce Type: replace 
Abstract: Can Spiking Neural Networks (SNNs) approximate the dynamics of Recurrent Neural Networks (RNNs)? Arguments in classical mean-field theory based on laws of large numbers provide a positive answer when each neuron in the network has many "duplicates", i.e. other neurons with almost perfectly correlated inputs. Using a disordered network model that guarantees the absence of duplicates, we show that duplicate-free SNNs can converge to RNNs, thanks to the concentration of measure phenomenon. This result reveals a general mechanism underlying the emergence of rate-based dynamics in large SNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05174v4</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Valentin Schmutz, Johanni Brea, Wulfram Gerstner</dc:creator>
    </item>
    <item>
      <title>Node-layer duality in networked systems</title>
      <link>https://arxiv.org/abs/2306.12136</link>
      <description>arXiv:2306.12136v2 Announce Type: replace-cross 
Abstract: Real-world networks typically exhibit several aspects, or layers, of interactions among their nodes. By permuting the role of the nodes and the layers, we establish a new criterion to construct the dual of a network. This approach allows to examine information from either a node-centric or layer-centric viewpoint. Through rigorous analytical methods and extensive simulations, we demonstrate that nodewise and layerwise connectivity measure different but related aspects of the same system. Leveraging node-layer duality provides complementary insights, enabling a deeper comprehension of diverse networks across social science, technology and biology. Taken together, these findings reveal previously unappreciated features of complex systems and provide a fresh tool for delving into their structure and dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12136v2</guid>
      <category>physics.soc-ph</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charley Presigny, Marie-Constance Corsi, Fabrizio De Vico Fallani</dc:creator>
    </item>
    <item>
      <title>Quantum Universe and its Elusive Classicality</title>
      <link>https://arxiv.org/abs/2401.17336</link>
      <description>arXiv:2401.17336v2 Announce Type: replace-cross 
Abstract: The article explores challenges presented by revelations in physics and the questions they provoke concerning reality. It sheds light on the disparity between the indefinite nature of quantum reality and our perception of classical reality. The necessity for transition from the quantum to classical reality is underscored, alongside difficulties of observer intervention and the complexities introduced by the objective collapse theory. The work introduces a pioneering approach of decoherence within the framework of universal wave function density matrices. It deploys entanglement among three primary quantum subsystems: mass particles, massless particles, and the human body system. This gives rise to a Von Neumann chain of correlated systems, wherein neglecting one system renders the other two in mixed states. Here the cohered massless system and the animate being constitute subjects of our perceptions. Within the body, the distributions of quantum particle wave packets are highly localized due to entanglement and chemical potential, satisfying the Ehrenfest condition, wherein the thermal deBroglie wavelength scale is considerably smaller than their domain in the body. Thus, each microstate of the body quantum particle ensemble can be analogously represented as a statistical mechanics particle ensemble or likened to microstates in the Debye statistical model. In the statistical mechanics perspective, life represents a macrostate characterized by thermodynamics parameters, and chemical potential. The life macrostate autonomously processes an environment corresponding to a mixed state alternative of its entangled quantum world counterpart, which appears in the stream of consciousness. The quantum universe persists, evolving deterministically, and the classical (macroscopic) universe is its realization statistical by the fundamental predicate of life discerned by the brain; our elusive world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17336v2</guid>
      <category>physics.gen-ph</category>
      <category>q-bio.NC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jahan N. Schad</dc:creator>
    </item>
    <item>
      <title>Human Curriculum Effects Emerge with In-Context Learning in Neural Networks</title>
      <link>https://arxiv.org/abs/2402.08674</link>
      <description>arXiv:2402.08674v2 Announce Type: replace-cross 
Abstract: Human learning is sensitive to rule-like structure and the curriculum of examples used for training. In tasks governed by succinct rules, learning is more robust when related examples are blocked across trials, but in the absence of such rules, interleaving is more effective. To date, no neural model has simultaneously captured these seemingly contradictory effects. Here we show that this same tradeoff spontaneously emerges with ``in-context learning'' (ICL) both in neural networks trained with metalearning and in large language models (LLMs). ICL is the ability to learn new tasks ``in context'' -- without weight changes -- via an inner-loop algorithm implemented in activation dynamics. Experiments with pretrained LLMs and metalearning transformers show that ICL exhibits the blocking advantage demonstrated in humans on a task involving rule-like structure, and conversely, that concurrent in-weight learning reproduces the interleaving advantage observed in humans on tasks lacking such structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08674v2</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Russin, Ellie Pavlick, Michael J. Frank</dc:creator>
    </item>
    <item>
      <title>A rank decomposition for the topological classification of neural representations</title>
      <link>https://arxiv.org/abs/2404.19710</link>
      <description>arXiv:2404.19710v2 Announce Type: replace-cross 
Abstract: Neural networks can be thought of as applying a transformation to an input dataset. The way in which they change the topology of such a dataset often holds practical significance for many tasks, particularly those demanding non-homeomorphic mappings for optimal solutions, such as classification problems. In this work, we leverage the fact that neural networks are equivalent to continuous piecewise-affine maps, whose rank can be used to pinpoint regions in the input space that undergo non-homeomorphic transformations, leading to alterations in the topological structure of the input dataset. Our approach enables us to make use of the relative homology sequence, with which one can study the homology groups of the quotient of a manifold $\mathcal{M}$ and a subset $A$, assuming some minimal properties on these spaces.
  As a proof of principle, we empirically investigate the presence of low-rank (topology-changing) affine maps as a function of network width and mean weight. We show that in randomly initialized narrow networks, there will be regions in which the (co)homology groups of a data manifold can change. As the width increases, the homology groups of the input manifold become more likely to be preserved. We end this part of our work by constructing highly non-random wide networks that do not have this property and relating this non-random regime to Dale's principle, which is a defining characteristic of biological neural networks.
  Finally, we study simple feedforward networks trained on MNIST, as well as on toy classification and regression tasks, and show that networks manipulate the topology of data differently depending on the continuity of the task they are trained on.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19710v2</guid>
      <category>cs.LG</category>
      <category>math.AT</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kosio Beshkov, Gaute T. Einevoll</dc:creator>
    </item>
  </channel>
</rss>
