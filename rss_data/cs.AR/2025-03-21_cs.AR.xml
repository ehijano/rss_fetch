<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CATCH: a Cost Analysis Tool for Co-optimization of chiplet-based Heterogeneous systems</title>
      <link>https://arxiv.org/abs/2503.15753</link>
      <description>arXiv:2503.15753v1 Announce Type: new 
Abstract: With the increasing prevalence of chiplet systems in high-performance computing applications, the number of design options has increased dramatically. Instead of chips defaulting to a single die design, now there are options for 2.5D and 3D stacking along with a plethora of choices regarding configurations and processes. For chiplet-based designs, high-impact decisions such as those regarding the number of chiplets, the design partitions, the interconnect types, and other factors must be made early in the development process. In this work, we describe an open-source tool, CATCH, that can be used to guide these early design choices. We also present case studies showing some of the insights we can draw by using this tool. We look at case studies on optimal chip size, defect density, test cost, IO types, assembly processes, and substrates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15753v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Graening, Jonti Talukdar, Saptadeep Pal, Krishnendu Chakrabarty, Puneet Gupta</dc:creator>
    </item>
    <item>
      <title>DSLUT: An Asymmetric LUT and its Automatic Design Flow Based on Practical Functions</title>
      <link>https://arxiv.org/abs/2503.16109</link>
      <description>arXiv:2503.16109v1 Announce Type: new 
Abstract: The conventional LUT is redundant since practical functions in real-world benchmarks only occupy a small proportion of all the functions. For example, there are only 3881 out of more than $10^{14}$ NPN classes of 6-input functions occurring in the mapped netlists of the VTR8 and Koios benchmarks. Therefore, we propose a novel LUT-like architecture, named DSLUT, with asymmetric inputs and programmable bits to efficiently implement the practical functions in domain-specific benchmarks instead of all the functions. The compact structure of the MUX Tree in the conventional LUT is preserved, while fewer programmable bits are connected to the MUX Tree according to the bit assignment generated by the proposed algorithm. A 6-input DSLUT with 26 SRAM bits is generated for evaluation, which is based on the practical functions of 39 circuits from the VTR8 and Koios benchmarks. After the synthesis flow of ABC, the post-synthesis results show that the proposed DSLUT6 architecture reduces the number of levels by 10.98% at a cost of 7.25% area overhead compared to LUT5 architecture, while LUT6 reduces 15.16% levels at a cost of 51.73% more PLB area. After the full VTR flow, the post-implementation results show that the proposed DSLUT6 can provide performance improvement by 4.59% over LUT5, close to 5.42% of LUT6 over LUT5, causing less area overhead (6.81% of DSLUT6 and 10.93% of LUT6).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16109v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICFPT59805.2023.00044</arxiv:DOI>
      <arxiv:journal_reference>2023 International Conference on Field Programmable Technology (ICFPT), Yokohama, Japan, 2023, pp. 278-279</arxiv:journal_reference>
      <dc:creator>Moucheng Yang, Kaixiang Zhu, Lingli Wang, Xuegong Zhou</dc:creator>
    </item>
    <item>
      <title>A Scalable and Robust Compilation Framework for Emitter-Photonic Graph State</title>
      <link>https://arxiv.org/abs/2503.16346</link>
      <description>arXiv:2503.16346v1 Announce Type: new 
Abstract: Quantum graph states are critical resources for various quantum algorithms, and also determine essential interconnections in distributed quantum computing. There are two schemes for generating graph states probabilistic scheme and deterministic scheme. While the all-photonic probabilistic scheme has garnered significant attention, the emitter-photonic deterministic scheme has been proved to be more scalable and feasible across several hardware platforms.
  This paper studies the GraphState-to-Circuit compilation problem in the context of the deterministic scheme. Previous research has primarily focused on optimizing individual circuit parameters, often neglecting the characteristics of quantum hardware, which results in impractical implementations. Additionally, existing algorithms lack scalability for larger graph sizes. To bridge these gaps, we propose a novel compilation framework that partitions the target graph state into subgraphs, compiles them individually, and subsequently combines and schedules the circuits to maximize emitter resource utilization. Furthermore, we incorporate local complementation to transform graph states and minimize entanglement overhead. Evaluation of our framework on various graph types demonstrates significant reductions in CNOT gates and circuit duration, up to 52% and 56%. Moreover, it enhances the suppression of photon loss, achieving improvements of up to x1.9.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16346v1</guid>
      <category>cs.AR</category>
      <category>quant-ph</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangyu Ren, Yuexun Huang, Zhiding Liang, Antonio Barbalace</dc:creator>
    </item>
    <item>
      <title>Nano-3D: Metasurface-Based Neural Depth Imaging</title>
      <link>https://arxiv.org/abs/2503.15770</link>
      <description>arXiv:2503.15770v1 Announce Type: cross 
Abstract: Depth imaging is a foundational building block for broad applications, such as autonomous driving and virtual/augmented reality. Traditionally, depth cameras have relied on time-of-flight sensors or multi-lens systems to achieve physical depth measurements. However, these systems often face a trade-off between a bulky form factor and imprecise approximations, limiting their suitability for spatially constrained scenarios. Inspired by the emerging advancements of nano-optics, we present Nano-3D, a metasurface-based neural depth imaging solution with an ultra-compact footprint. Nano-3D integrates our custom-fabricated 700 nm thick TiO2 metasurface with a multi-module deep neural network to extract precise metric depth information from monocular metasurface-polarized imagery. We demonstrate the effectiveness of Nano-3D with both simulated and physical experiments. We hope the exhibited success paves the way for the community to bridge future graphics systems with emerging nanomaterial technologies through novel computational approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15770v1</guid>
      <category>physics.optics</category>
      <category>cs.AR</category>
      <category>cs.CV</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingxuan Li, Jiahao Wu, Yuan Xu, Yunxiang Zhang, Zezheng Zhu, Nanfang Yu, Qi Sun</dc:creator>
    </item>
    <item>
      <title>ALLMod: Exploring $\underline{\mathbf{A}}$rea-Efficiency of $\underline{\mathbf{L}}$UT-based $\underline{\mathbf{L}}$arge Number $\underline{\mathbf{Mod}}$ular Reduction via Hybrid Workloads</title>
      <link>https://arxiv.org/abs/2503.15916</link>
      <description>arXiv:2503.15916v1 Announce Type: cross 
Abstract: Modular arithmetic, particularly modular reduction, is widely used in cryptographic applications such as homomorphic encryption (HE) and zero-knowledge proofs (ZKP). High-bit-width operations are crucial for enhancing security; however, they are computationally intensive due to the large number of modular operations required. The lookup-table-based (LUT-based) approach, a ``space-for-time'' technique, reduces computational load by segmenting the input number into smaller bit groups, pre-computing modular reduction results for each segment, and storing these results in LUTs. While effective, this method incurs significant hardware overhead due to extensive LUT usage. In this paper, we introduce ALLMod, a novel approach that improves the area efficiency of LUT-based large-number modular reduction by employing hybrid workloads. Inspired by the iterative method, ALLMod splits the bit groups into two distinct workloads, achieving lower area costs without compromising throughput. We first develop a template to facilitate workload splitting and ensure balanced distribution. Then, we conduct design space exploration to evaluate the optimal timing for fusing workload results, enabling us to identify the most efficient design under specific constraints. Extensive evaluations show that ALLMod achieves up to $1.65\times$ and $3\times$ improvements in area efficiency over conventional LUT-based methods for bit-widths of $128$ and $8,192$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15916v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangxin Liu, Haomin Li, Zongwu Wang, Bo Zhang, Mingzhe Zhang, Shoumeng Yan, Li Jiang, Haibing Guan</dc:creator>
    </item>
    <item>
      <title>Efficient Multi-Cycle Folded Integer Multipliers</title>
      <link>https://arxiv.org/abs/2301.13332</link>
      <description>arXiv:2301.13332v3 Announce Type: replace 
Abstract: Fast combinational multipliers with large bit widths can occupy significant silicon area, which also drives up power consumption. Area can be reduced through resource sharing (i.e., folding) at the expense of lower throughput, which is acceptable for some applications. This work explores multiple architectures for Multi-Cycle folded Integer Multiplier (MCIM) designs, which are based on Schoolbook and Karatsuba approaches. Applications sometimes require a fractional number of multiplications to be performed per cycle. For example, an algorithm may only require 3.5 multiplications per cycle. In such a case, 3 multipliers with a throughput of 1 plus an additional smaller multiplier with a throughput of $1/2$ would be sufficient to maintain the algorithm's throughput. Our MCIM design generator offers customization in terms of throughput, latency, and clock frequency. MCIM designs were synthesized and verified for various parameter values using scripts. ASIC synthesis results show that MCIM designs with a throughput of $1/2$ offer area savings of up to 44% for bit widths of 8 to 128 with respect to directly synthesizing the * operator. Additionally, MCIM designs can offer up to 33% energy savings and 65% average peak power reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13332v3</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Houraniah, H. Fatih Ugurdag, C. Emre Dedeagac</dc:creator>
    </item>
    <item>
      <title>Approximate Computing Survey, Part I: Terminology and Software &amp; Hardware Approximation Techniques</title>
      <link>https://arxiv.org/abs/2307.11124</link>
      <description>arXiv:2307.11124v2 Announce Type: replace 
Abstract: The rapid growth of demanding applications in domains applying multimedia processing and machine learning has marked a new era for edge and cloud computing. These applications involve massive data and compute-intensive tasks, and thus, typical computing paradigms in embedded systems and data centers are stressed to meet the worldwide demand for high performance. Concurrently, over the last 15 years, the semiconductor industry has established power efficiency as a first-class design concern. As a result, the community of computing systems is forced to find alternative design approaches to facilitate high-performance and power-efficient computing. Among the examined solutions, Approximate Computing has attracted an ever-increasing interest, which has resulted in novel approximation techniques for all the layers of the traditional computing stack. More specifically, during the last decade, a plethora of approximation techniques in software (programs, frameworks, compilers, runtimes, languages), hardware (circuits, accelerators), and architectures (processors, memories) have been proposed in the literature. The current article is Part I of a comprehensive survey on Approximate Computing. It reviews its motivation, terminology and principles, as well it classifies the state-of-the-art software &amp; hardware approximation techniques, presents their technical details, and reports a comparative quantitative analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11124v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.PL</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3716845</arxiv:DOI>
      <arxiv:journal_reference>ACM Computing Surveys, Volume 57, Issue 7, Article 185, 2025</arxiv:journal_reference>
      <dc:creator>Vasileios Leon, Muhammad Abdullah Hanif, Giorgos Armeniakos, Xun Jiao, Muhammad Shafique, Kiamal Pekmestzi, Dimitrios Soudris</dc:creator>
    </item>
    <item>
      <title>Approximate Computing Survey, Part II: Application-Specific &amp; Architectural Approximation Techniques and Applications</title>
      <link>https://arxiv.org/abs/2307.11128</link>
      <description>arXiv:2307.11128v2 Announce Type: replace 
Abstract: The challenging deployment of compute-intensive applications from domains such as Artificial Intelligence (AI) and Digital Signal Processing (DSP), forces the community of computing systems to explore new design approaches. Approximate Computing appears as an emerging solution, allowing to tune the quality of results in the design of a system in order to improve the energy efficiency and/or performance. This radical paradigm shift has attracted interest from both academia and industry, resulting in significant research on approximation techniques and methodologies at different design layers (from system down to integrated circuits). Motivated by the wide appeal of Approximate Computing over the last 10 years, we conduct a two-part survey to cover key aspects (e.g., terminology and applications) and review the state-of-the art approximation techniques from all layers of the traditional computing stack. Part II of the survey classifies and presents the technical details of application-specific and architectural approximation techniques, which both target the design of resource-efficient processors/accelerators and systems. Moreover, it reports a quantitative analysis of the techniques and a detailed analysis of the application spectrum of Approximate Computing, and finally, it discusses open challenges and future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11128v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.PL</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3711683</arxiv:DOI>
      <arxiv:journal_reference>ACM Computing Surveys, Volume 57, Issue 7, Article 177, 2025</arxiv:journal_reference>
      <dc:creator>Vasileios Leon, Muhammad Abdullah Hanif, Giorgos Armeniakos, Xun Jiao, Muhammad Shafique, Kiamal Pekmestzi, Dimitrios Soudris</dc:creator>
    </item>
    <item>
      <title>Cool-3D: An End-to-End Thermal-Aware Framework for Early-Phase Design Space Exploration of Microfluidic-Cooled 3DICs</title>
      <link>https://arxiv.org/abs/2503.07297</link>
      <description>arXiv:2503.07297v2 Announce Type: replace 
Abstract: The rapid advancement of three-dimensional integrated circuits (3DICs) has heightened the need for early-phase design space exploration (DSE) to minimize design iterations and unexpected challenges. Emphasizing the pre-register-transfer level (Pre-RTL) design phase is crucial for reducing trial-and-error costs. However, 3DIC design introduces additional complexities due to thermal constraints and an expanded design space resulting from vertical stacking and various cooling strategies. Despite this need, existing Pre-RTL DSE tools for 3DICs remain scarce, with available solutions often lacking comprehensive design options and full customization support. To bridge this gap, we present Cool-3D, an end-to-end, thermal-aware framework for 3DIC design that integrates mainstream architectural-level simulators, including gem5, McPAT, and HotSpot 7.0, with advanced cooling models. Cool-3D enables broad and fine-grained design space exploration, built-in microfluidic cooling support for thermal analysis, and an extension interface for non-parameterizable customization, allowing designers to model and optimize 3DIC architectures with greater flexibility and accuracy. To validate the Cool-3D framework, we conduct three case studies demonstrating its ability to model various hardware design options and accurately capture thermal behaviors. Cool-3D serves as a foundational framework that not only facilitates comprehensive 3DIC design space exploration but also enables future innovations in 3DIC architecture, cooling strategies, and optimization techniques. The entire framework, along with the experimental data, is in the process of being released on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07297v2</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Runxi Wang, Ziheng Wang, Ting Lin, Jacob M. Raby, Mircea R. Stan, Xinfei Guo</dc:creator>
    </item>
  </channel>
</rss>
