<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Queue occupancy and server size distribution of a queue length dependent vacation queue with an optional service</title>
      <link>https://arxiv.org/abs/2602.22295</link>
      <description>arXiv:2602.22295v1 Announce Type: new 
Abstract: The discrete time queueing system is highly applicable to modern telecommunication systems, where it provides adaptive packet handling, congestion controlled security/inspection, energy efficient operation, and supports bursty traffic common in 5G, Internet of Things (IoT), and edge computing environments. In this article, we analyze an infinite-buffer discrete-time batch-arrival queue with single and multiple vacation policy where customers are served in batches, in two phases, namely first essential service (FES) and second optional service (SOS). In such systems, the FES corresponds to basic data processing or packet routing, while SOS represents secondary tasks such as encryption, error checking, data compression, or deep packet inspection that may not be necessary for every packet. Here, we derive the bivariate probability generating functions for the joint distribution of the number of packets waiting for transmission and the number are being processed immediately after the completion of both the FES and SOS. Furthermore, the complete joint distribution at arbitrary time slots, including vacation completion states, is established. Numerical illustrations demonstrate the applicability of the proposed framework, including an example with discrete phase type service time distribution. Finally, the sensitivity analysis of the key parameters on marginal system's probabilities and different performance measures have been investigated through several graphical representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22295v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashish Verma, Sourav Pradhan</dc:creator>
    </item>
    <item>
      <title>On the Computation Rate of All-Reduce</title>
      <link>https://arxiv.org/abs/2602.22482</link>
      <description>arXiv:2602.22482v1 Announce Type: new 
Abstract: In the All-Reduce problem, each one of the K nodes holds an input and wishes to compute the sum of all K inputs through a communication network where each pair of nodes is connected by a parallel link with arbitrary bandwidth. The computation rate of All-Reduce is defined as the number of sum instances that can be computed over each network use. For the computation rate, we provide a cut-set upper bound and a linear programming lower bound based on time (bandwidth) sharing over all schemes that first perform Reduce (aggregating all inputs at one node) and then perform Broadcast (sending the sum from that node to all other nodes). Specializing the two general bounds gives us the optimal computation rate for a class of communication networks and the best-known rate bounds (where the upper bound is no more than twice of the lower bound) for cyclic, complete, and hypercube networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22482v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufeng Zhou, Hua Sun</dc:creator>
    </item>
    <item>
      <title>A Thermodynamic Structure of Asymptotic Inference</title>
      <link>https://arxiv.org/abs/2602.22605</link>
      <description>arXiv:2602.22605v1 Announce Type: new 
Abstract: A thermodynamic framework for asymptotic inference is developed in which sample size and parameter variance define a state space. Within this description, Shannon information plays the role of entropy, and an integrating factor organizes its variation into a first-law-type balance equation. The framework supports a cyclic inequality analogous to a reversed second law, derived for the estimation of the mean. A non-trivial third-law-type result emerges as a lower bound on entropy set by representation noise. Optimal inference paths, global bounds on information gain, and a natural Carnot-like information efficiency follow from this structure, with efficiency fundamentally limited by a noise floor. Finally, de Bruijn's identity and the I-MMSE relation in the Gaussian-limit case appear as coordinate projections of the same underlying thermodynamic structure. This framework suggests that ensemble physics and inferential physics constitute shadow processes evolving in opposite directions within a unified thermodynamic description.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22605v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>stat.TH</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Willy Wong</dc:creator>
    </item>
    <item>
      <title>Multi-modal Data Driven Virtual Base Station Construction for Massive MIMO Beam Alignment</title>
      <link>https://arxiv.org/abs/2602.22796</link>
      <description>arXiv:2602.22796v1 Announce Type: new 
Abstract: Massive multiple-input multiple-output (MIMO) is a key enabler for the high data rates required by the sixth-generation networks, yet its performance hinges on effective beam management with low training overhead. This paper proposes an interpretable framework to tackle beam alignment in mixed line-of-sight (LoS) and non-line-of-sight (NLoS) propagation environments. Our approach utilizes multi-modal data to construct virtual base stations (VBSs), which are geometrically defined as mirror images of the base station across reflecting surfaces reconstructed from 3D LiDAR points. These VBSs provide a sparse and spatial representation of the dominant features of the wireless environment. Based on the constructed VBSs, we develop a VBS-assisted beam alignment scheme comprising coarse channel reconstruction followed by partial beam training. Numerical results demonstrate that the proposed method achieves near-optimal performance in terms of spectral efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22796v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijie Bian, Wei Guo, Jie Yang, Shenghui Song, Jun Zhang, Shi Jin, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Semantic Communication Through the Lens of Context-Dependent Channel Modeling</title>
      <link>https://arxiv.org/abs/2602.22934</link>
      <description>arXiv:2602.22934v1 Announce Type: new 
Abstract: Semantic communication has emerged as a promising paradigm for next-generation networks, yet several fundamental challenges remain unresolved. Building on the probabilistic model of semantic communication and leveraging the concept of context, this paper examines a specific subclass of semantic communication problems, where semantic noise originates solely from the semantic channel, assuming an ideal physical channel. To model this system, we introduce a virtual state-dependent channel, where the state-representing context-plays a crucial role in shaping communication. We further analyze the representational capability of the semantic encoder and explore various semantic communication scenarios in the presence of semantic noise, deriving capacity results for some cases and achievable rates for others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22934v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad Gholipour, Rafael F. Schaefer, Gerhard P. Fettweis</dc:creator>
    </item>
    <item>
      <title>Frequency-Ordered Tokenization for Better Text Compression</title>
      <link>https://arxiv.org/abs/2602.22958</link>
      <description>arXiv:2602.22958v1 Announce Type: new 
Abstract: We present frequency-ordered tokenization, a simple preprocessing technique that improves lossless text compression by exploiting the power-law frequency distribution of natural language tokens (Zipf's law). The method tokenizes text with Byte Pair Encoding (BPE), reorders the vocabulary so that frequent tokens receive small integer identifiers, and encodes the result with variable-length integers before passing it to any standard compressor. On enwik8 (100 MB Wikipedia), this yields improvements of 7.08 percentage points (pp) for zlib, 1.69 pp for LZMA, and 0.76 pp for zstd (all including vocabulary overhead), outperforming the classical Word Replacing Transform. Gains are consistent at 1 GB scale (enwik9) and across Chinese and Arabic text. We further show that preprocessing accelerates compression for computationally expensive algorithms: the total wall-clock time including preprocessing is 3.1x faster than raw zstd-22 and 2.4x faster than raw LZMA, because the preprocessed input is substantially smaller. The method can be implemented in under 50 lines of code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22958v1</guid>
      <category>cs.IT</category>
      <category>cs.CL</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Kalcher</dc:creator>
    </item>
    <item>
      <title>Secure Transmission for Fluid Antenna-Aided ISAC Systems</title>
      <link>https://arxiv.org/abs/2602.23241</link>
      <description>arXiv:2602.23241v1 Announce Type: new 
Abstract: Fluid antenna (FA) has become a highly promising technology and has recently been used to enhance the integrated sensing and communication (ISAC) system. However, the scenario where sensing targets act as eavesdroppers in ISAC and how to maximize the sum secrecy rate has not been addressed. This letter investigates secure transmission in FA-aided ISAC systems, where the spatial agility of FAs enables enhanced physical layer security. We jointly optimize antenna position vector (APV) and beamforming to maximize the multiuser sum secrecy rate, which complicates the solution process. To solve the resulting non-convex problem, we use a block successive upper-bound minimization (BSUM) algorithm, which incorporates the proximal distance algorithm (PDA) for closed-form beamformer updates and extrapolated projected gradient (EPG) for APV optimization. Simulation results show that the proposed FA-ISAC scheme achieves over 20$\%$ sum secrecy rate gain compared to fixed-position antenna (FPA) systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23241v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Wireless Communications Letters Review Process, 2026</arxiv:journal_reference>
      <dc:creator>Yunxiao Li, Qian Zhang, Xuejun Cheng, Zhiguo Wang, Xiaoyan Wang, Hongji Xu, Ju Liu</dc:creator>
    </item>
    <item>
      <title>BeamVLM for Low-altitude Economy: Generative Beam Prediction via Vision-language Models</title>
      <link>https://arxiv.org/abs/2602.19929</link>
      <description>arXiv:2602.19929v1 Announce Type: cross 
Abstract: For low-altitude economy (LAE), fast and accurate beam prediction between high-mobility unmanned aerial vehicles (UAVs) and ground base stations is of paramount importance, which ensures seamless coverage and reliable communications. However, existing deep learning-based beam prediction methods lack high-level semantic understanding of dynamic environments, resulting in poor generalization. On the other hand, the emerging large language model (LLM) based approaches show promise in enhancing generalization, but they typically lack rich environmental perception, thereby failing to capture fine-grained spatial semantics essential for precise beam alignment. To tackle these limitations, we propose in this correspondence a novel end-to-end generative framework for beam prediction, called BeamVLM, which treats beam prediction as a vision question answering task capitalizing on powerful existing vision-language models (VLMs). By projecting raw visual patches directly into the language domain and judiciously designing an instructional prompt, the proposed BeamVLM enables the VLM to jointly reason over UAV trajectories and environmental context. Last, experimental results on real-world datasets demonstrate that the proposed BeamVLM outperforms state-of-the-art methods in prediction accuracy and also exhibits superior generalization for other scenarios such as vehicle-to-infrastructure (V2I) beam prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19929v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenran Kou, Changsheng You, Mingjiang Wu, Dingzhu Wen, Zezhong Zhang, Chengwen Xing</dc:creator>
    </item>
    <item>
      <title>OmniZip: Learning a Unified and Lightweight Lossless Compressor for Multi-Modal Data</title>
      <link>https://arxiv.org/abs/2602.22286</link>
      <description>arXiv:2602.22286v1 Announce Type: cross 
Abstract: Lossless compression is essential for efficient data storage and transmission. Although learning-based lossless compressors achieve strong results, most of them are designed for a single modality, leading to redundant compressor deployments in multi-modal settings. Designing a unified multi-modal compressor is critical yet challenging, as different data types vary largely in format, dimension, and statistics. Multi-modal large language models offer a promising resolution but remain too complex for practical use. Thus, we propose \textbf{OmniZip}, \textbf{a unified and lightweight lossless compressor for multi-modal data (like image, text, speech, tactile, database, and gene sequence)}. Built on a lightweight backbone, OmniZip incorporates three key components to enable efficient multi-modal lossless compression: a modality-unified tokenizer that reversibly transforms diverse data into tokens, a modality-routing context learning mechanism that enables flexible multi-modal context modeling, and a modality-routing feedforward design that further enhances the model's nonlinear representation flexibility. A reparameterization training strategy is used to enhance model capacity. OmniZip outperforms or matches other state-of-the-art compressors on multiple modalities, achieving 42\%, 57\%, 62\% and 42\%, 53\% higher compression efficiency than gzip on CLIC-M, TouchandGo, enwik9, LibriSpeech, and WikiSQL datasets, respectively. It also supports near real-time inference on resource-constrained edge devices, reaching about 1MB/s on MacBook CPUs and iPhone NPUs. Our code is released at https://github.com/adminasmi/OmniZip-CVPR2026.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22286v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Zhao, Zhengxue Cheng, Junxuan Zhang, Dajiang Zhou, Qunshan Gu, Qi Wang, Li Song</dc:creator>
    </item>
    <item>
      <title>A Learning-Based Hybrid Decision Framework for Matching Systems with User Departure Detection</title>
      <link>https://arxiv.org/abs/2602.22412</link>
      <description>arXiv:2602.22412v1 Announce Type: cross 
Abstract: In matching markets such as kidney exchanges and freight exchanges, delayed matching has been shown to improve overall market efficiency. The benefits of delay are highly sensitive to participants' sojourn times and departure behavior, and delaying matches can impose significant costs, including longer waiting times and increased market congestion. These competing effects make fixed matching policies inherently inflexible in dynamic environments. We propose a learning-based Hybrid framework that adaptively combines immediate and delayed matching. The framework continuously collects data on user departures over time, estimates the underlying departure distribution via regression, and determines whether to delay matching in the subsequent period based on a decision threshold that governs the system's tolerance for matching efficiency loss. The proposed framework can substantially reduce waiting times and congestion while sacrificing only a limited amount of matching efficiency. By dynamically adjusting its matching strategy, the Hybrid framework enables system performance to flexibly interpolate between purely greedy and purely patient policies, offering a robust and adaptive alternative to static matching mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22412v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>econ.GN</category>
      <category>math.IT</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiqi Zhou, Donghao Zhu, Houcai Shen</dc:creator>
    </item>
    <item>
      <title>A Mathematical Theory of Agency and Intelligence</title>
      <link>https://arxiv.org/abs/2602.22519</link>
      <description>arXiv:2602.22519v1 Announce Type: cross 
Abstract: To operate reliably under changing conditions, complex systems require feedback on how effectively they use resources, not just whether objectives are met. Current AI systems process vast information to produce sophisticated predictions, yet predictions can appear successful while the underlying interaction with the environment degrades. What is missing is a principled measure of how much of the total information a system deploys is actually shared between its observations, actions, and outcomes. We prove this shared fraction, which we term bipredictability, P, is intrinsic to any interaction, derivable from first principles, and strictly bounded: P can reach unity in quantum systems, P equal to, or smaller than 0.5 in classical systems, and lower once agency (action selection) is introduced. We confirm these bounds in a physical system (double pendulum), reinforcement learning agents, and multi turn LLM conversations. These results distinguish agency from intelligence: agency is the capacity to act on predictions, whereas intelligence additionally requires learning from interaction, self-monitoring of its learning effectiveness, and adapting the scope of observations, actions, and outcomes to restore effective learning. By this definition, current AI systems achieve agency but not intelligence. Inspired by thalamocortical regulation in biological systems, we demonstrate a feedback architecture that monitors P in real time, establishing a prerequisite for adaptive, resilient AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22519v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wael Hafez, Chenan Wei, Rodrigo Felipe, Amir Nazeri, Cameron Reid</dc:creator>
    </item>
    <item>
      <title>Kernel Integrated $R^2$: A Measure of Dependence</title>
      <link>https://arxiv.org/abs/2602.22985</link>
      <description>arXiv:2602.22985v1 Announce Type: cross 
Abstract: We introduce kernel integrated $R^2$, a new measure of statistical dependence that combines the local normalization principle of the recently introduced integrated $R^2$ with the flexibility of reproducing kernel Hilbert spaces (RKHSs). The proposed measure extends integrated $R^2$ from scalar responses to responses taking values on general spaces equipped with a characteristic kernel, allowing to measure dependence of multivariate, functional, and structured data, while remaining sensitive to tail behaviour and oscillatory dependence structures. We establish that (i) this new measure takes values in $[0,1]$, (ii) equals zero if and only if independence holds, and (iii) equals one if and only if the response is almost surely a measurable function of the covariates. Two estimators are proposed: a graph-based method using $K$-nearest neighbours and an RKHS-based method built on conditional mean embeddings. We prove consistency and derive convergence rates for the graph-based estimator, showing its adaptation to intrinsic dimensionality. Numerical experiments on simulated data and a real data experiment in the context of dependency testing for media annotations demonstrate competitive power against state-of-the-art dependence measures, particularly in settings involving non-linear and structured relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22985v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Roudaki, Shakeel Gavioli-Akilagun, Florian Kalinke, Mona Azadkia, Zolt\'an Szab\'o</dc:creator>
    </item>
    <item>
      <title>On pseudo-arcs from normal rational curve and additive MDS codes</title>
      <link>https://arxiv.org/abs/2602.23130</link>
      <description>arXiv:2602.23130v1 Announce Type: cross 
Abstract: Let $\mathrm{PG}(k-1,q)$ be the $(k-1)$-dimensional projective space over the finite field $\mathbb{F}_q$. An arc in $\mathrm{PG}(k-1,q)$ is a set of points with the property that any $k$ of them span the entire space. The notion of pseudo-arc generalizes that of an arc by replacing points with higher-dimensional subspaces. Constructions of pseudo-arcs can be obtained from arcs defined over extension fields; such pseudo-arcs are necessarily Desarguesian, in the sense that all their elements belong to a Desarguesian spread. In contrast, genuinely non-Desarguesian pseudo-arcs are far less understood and have previously been known only in a few sporadic cases. In this paper, we introduce a new infinite family of non-Desarguesian pseudo-arcs consisting of $(h-1)$-dimensional subspaces of $\mathrm{PG}(k-1,q)$ based on the imaginary spaces of a normal rational curve. We determine the size of the constructed pseudo-arcs explicitly and show that, by adding suitable osculating spaces of a normal rational curve defined over a subgeometry, we obtain pseudo-arcs of size $O(q^h)$. As $q$ grows, these sizes asymptotically attain the classical upper bound for pseudo-arcs established in 1971 by J.~A.~Thas, thereby showing that this bound is essentially sharp also in the non-Desarguesian setting. We further investigate the interaction between these new pseudo-arcs and quadrics. While Desarguesian pseudo-arcs from normal rational curve are complete intersections of quadrics, we prove that the new pseudo-arcs are not contained in any quadric of the ambient projective space. Finally, we translate our geometric results into coding theory. We show that the new pseudo-arcs correspond precisely to recent families of additive MDS codes introduced via a polynomial framework. As a consequence of their non-Desarguesian nature, we prove that these codes are not equivalent to linear MDS codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23130v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Pavese, Paolo Santonastaso</dc:creator>
    </item>
    <item>
      <title>A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring</title>
      <link>https://arxiv.org/abs/2602.23163</link>
      <description>arXiv:2602.23163v1 Announce Type: cross 
Abstract: Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this otherwise latent asymmetry can be inferred from the agents' observable actions. To formalise this perspective, we introduce generalised $\mathcal{V}$-information: a utilitarian framework for measuring the amount of usable information within some input. We use this to define the \textbf{steganographic gap} -- a measure that quantifies steganography by comparing the downstream utility of the steganographic signal to agents that can and cannot decode the hidden content. We empirically validate our formalism, and show that it can be used to detect, quantify, and mitigate steganographic reasoning in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23163v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Usman Anwar, Julianna Piskorz, David D. Baek, David Africa, Jim Weatherall, Max Tegmark, Christian Schroeder de Witt, Mihaela van der Schaar, David Krueger</dc:creator>
    </item>
    <item>
      <title>A Scaling Law for Bandwidth Under Quantization</title>
      <link>https://arxiv.org/abs/2602.23252</link>
      <description>arXiv:2602.23252v1 Announce Type: cross 
Abstract: We derive a scaling law relating ADC bit depth to effective bandwidth for signals with $1/f^\alpha$ power spectra. Quantization introduces a flat noise floor whose intersection with the declining signal spectrum defines an effective cutoff frequency $f_c$. We show that each additional bit extends this cutoff by a factor of $2^{2/\alpha}$, approximately doubling bandwidth per bit for $\alpha = 2$. The law requires that quantization noise be approximately white, a condition whose minimum bit depth $N_{\min}$ we show to be $\alpha$-dependent. Validation on synthetic $1/f^\alpha$ signals for $\alpha \in \{1.5, 2.0, 2.5\}$ yields prediction errors below 3\% using the theoretical noise floor $\Delta^2/(6f_s)$, and approximately 14\% when the noise floor is estimated empirically from the quantized signal's spectrum. We illustrate practical implications on real EEG data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.23252v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Kalcher, Tena Dubcek</dc:creator>
    </item>
    <item>
      <title>A Framework for Robust Lossy Compression of Heavy-Tailed Sources</title>
      <link>https://arxiv.org/abs/2411.08549</link>
      <description>arXiv:2411.08549v2 Announce Type: replace 
Abstract: We study the rate-distortion problem for both scalar and vector memoryless heavy-tailed $\alpha$-stable sources ($0 &lt; \alpha &lt; 2$). Using a recently defined notion of ``strength" as a power measure, we derive the rate-distortion function for $\alpha$-stable sources subject to a constraint on the strength of the error and show it to be logarithmic in the strength-to-distortion ratio. We show how our framework paves the way for finding optimal quantizers for $\alpha$-stable sources and other general heavy-tailed ones. In addition, we study high-rate scalar quantizers and show that uniform ones are asymptotically optimal under the error-strength distortion measure. We compare uniform Gaussian and Cauchy quantizers and show that more representation points for the Cauchy source are required to guarantee the same quantization quality. Our findings generalize the well-known results of rate-distortion and quantization of Gaussian sources ($\alpha = 2$) under a quadratic distortion measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08549v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karim Ezzeddine, Jihad Fahs, Ibrahim Abou-Faycal</dc:creator>
    </item>
    <item>
      <title>Recursive decoding of projective Reed-Muller codes</title>
      <link>https://arxiv.org/abs/2501.01692</link>
      <description>arXiv:2501.01692v2 Announce Type: replace 
Abstract: We give a recursive decoding algorithm for projective Reed-Muller codes making use of a decoder for affine Reed-Muller codes. We determine the number of errors that can be corrected in this way, which is the current highest for decoders of projective Reed-Muller codes. We show when we can decode up to the error correction capability of these codes, and we compute the order of complexity of the algorithm, which is given by that of the chosen decoder for affine Reed-Muller codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01692v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2026.3667436</arxiv:DOI>
      <dc:creator>Rodrigo San-Jos\'e</dc:creator>
    </item>
    <item>
      <title>Optimum Spectrum Extension for PAPR Reduction of DFT-s-OFDM</title>
      <link>https://arxiv.org/abs/2509.19064</link>
      <description>arXiv:2509.19064v2 Announce Type: replace 
Abstract: Uplink coverage in cellular networks is constrained by the maximum UE transmit power, making peak-to-average power ratio (PAPR) reduction essential. While DFT-s-OFDM with frequency-domain spectral shaping (FDSS) achieves significantly lower PAPR than OFDM, especially with pi/2-BPSK, the PAPR remains too high for higher-rate transmission. Spectrum extension (SE) combined with FDSS (FDSS-SE) can further reduce the PAPR for higher-order QAM. This paper considers FDSS-SE with parametrized FDSS windows spanning a range of possible power ripples, as well as arbitrary circular shifts of the subcarrier coefficients. We optimize both the frequency shift and the SE size, and show that there exists an optimal SE size for reducing the PAPR and another one for increasing the rate. Analysis and simulations reveal that both optima largely depend on the window attenuation but are nearly invariant in proportion to the bandwidth. While the PAPR-optimal SE size is nearly invariant to the constellation order of regular QAM, the rate-optimal SE size depends also on the SNR. These insights provide practical guidelines for beyond-5G uplink coverage enhancement, highlighting that SE size should be individually configured according to the user's FDSS window and link quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19064v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renaud-Alexandre Pitaval, Fredrik Berggren, Branislav M. Popovic</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Cell-Free Massive MIMO under Imperfect LoS Phase Tracking</title>
      <link>https://arxiv.org/abs/2601.11179</link>
      <description>arXiv:2601.11179v2 Announce Type: replace 
Abstract: We study the impact of imperfect line-of-sight (LoS) phase tracking on the uplink performance of cell-free massive MIMO networks. Unlike prior works that assume perfectly known or completely unknown phases, we consider a realistic regime where LoS phases are estimated with residual uncertainty due to hardware impairments, mobility, and synchronization errors. To this end, we propose a Rician fading model where LoS components are rotated by imperfect phase estimates and attenuated by a deterministic \textit{phase-error penalty factor}.
  We derive a linear MMSE channel estimator that accounts for statistical phase errors and unifies prior results, reducing to the Bayesian MMSE estimator when phase is perfectly known and to a zero-mean model when no phase information is available. To address the non-Gaussian setting, we introduce a virtual uplink model that preserves second-order statistics of channel estimation, enabling the derivation of tractable virtual centralized and distributed MMSE beamformers. To ensure fair assessment of network performance, we apply these virtual beamformers to the operational uplink model that reflects the actual physical channel and compute the spectral efficiency bounds available in the literature.
  Numerical results show that our framework bridges idealized assumptions and practical tracking limitations, providing rigorous performance benchmarks and design insights for 6G cell-free networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11179v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noor Ul Ain, Lorenzo Miretti, Renato L. G. Cavalcante, Slawomir Stanczak</dc:creator>
    </item>
    <item>
      <title>Enabling Large-Scale Channel Sounding for 6G: A Framework for Sparse Sampling and Multipath Component Extraction</title>
      <link>https://arxiv.org/abs/2602.05405</link>
      <description>arXiv:2602.05405v3 Announce Type: replace 
Abstract: Realizing the 6G vision of artificial intelligence (AI) and integrated sensing and communication (ISAC) critically requires large-scale real-world channel datasets for channel modeling and data-driven AI models. However, traditional frequency-domain channel sounding methods suffer from low efficiency due to a prohibitive number of frequency points to avoid delay ambiguity. This paper proposes a novel channel sounding framework involving sparse nonuniform sampling along with a likelihood-rectified space-alternating generalized expectation-maximization (LR-SAGE) algorithm for multipath component extraction. This framework enables the acquisition of channel datasets that are tens or even hundreds of times larger within the same channel measurement duration, thereby providing the massive data required to harness the full potential of AI scaling laws. Specifically, we propose a Parabolic Frequency Sampling (PFS) strategy that non-uniformly distributes frequency points, effectively eliminating delay ambiguity while reducing sampling overhead by orders of magnitude. To efficiently extract multipath components (MPCs) from the channel data measured by PFS, we develop a LR-SAGE algorithm, rectifying the likelihood distortion caused by nonuniform sampling and molecular absorption effect. Simulation results and experimental validation at 280--300~GHz confirm that the proposed PFS and LR-SAGE algorithm not only achieve 50$\times$ faster measurement, a 98\% reduction in data volume and a 99.96\% reduction in post-processing computational complexity, but also successfully captures MPCs and channel characteristics consistent with traditional exhaustive measurements, demonstrating its potential as a fundamental enabler for constructing the massive ISAC datasets required by AI-native 6G systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05405v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Chen, Ming Li, Chong Han</dc:creator>
    </item>
    <item>
      <title>Physics-Aware, Shannon-Optimal Compression via Arithmetic Coding for Distributional Fidelity</title>
      <link>https://arxiv.org/abs/2602.19476</link>
      <description>arXiv:2602.19476v2 Announce Type: replace 
Abstract: Assessing whether two datasets are distributionally consistent has become a central theme in modern scientific analysis, particularly as generative artificial intelligence is increasingly used to produce synthetic datasets whose fidelity must be rigorously validated against the original data on which they are trained, a task made more challenging by the continued growth in data volume and problem dimensionality. In this work, we propose the use of arithmetic coding to provide a lossless and invertible compression of datasets under a physics-informed probabilistic representation. Datasets that share the same underlying physical correlations admit comparable optimal descriptions, while discrepancies in those correlations-arising from miscalibration, mismodeling, or bias-manifest as an irreducible excess in code length. This excess codelength defines an operational fidelity metric, quantified directly in bits through differences in achievable compression length relative to a physics-inspired reference distribution. We demonstrate that this metric is global, interpretable, additive across components, and asymptotically optimal in the Shannon sense. Moreover, we show that differences in codelength correspond to differences in expected negative log-likelihood evaluated under the same physics-informed reference model. As a byproduct, we also demonstrate that our compression approach achieves a higher compression ratio than traditional general-purpose algorithms such as gzip. Our results establish lossless, physics-aware compression based on arithmetic coding not as an end in itself, but as a measurement instrument for testing the fidelity between datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19476v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristiano Fanelli</dc:creator>
    </item>
    <item>
      <title>LLM-Text Watermarking based on Lagrange Interpolation</title>
      <link>https://arxiv.org/abs/2505.05712</link>
      <description>arXiv:2505.05712v4 Announce Type: replace-cross 
Abstract: The rapid advancement of LLMs (Large Language Models) has established them as a foundational technology for many AI and ML-powered human computer interactions. A critical challenge in this context is the attribution of LLM-generated text -- either to the specific language model that produced it or to the individual user who embedded their identity via a so-called multi-bit watermark. This capability is essential for combating misinformation, fake news, misinterpretation, and plagiarism. One of the key techniques for addressing this challenge is digital watermarking.
  This work presents a watermarking scheme for LLM-generated text based on Lagrange interpolation, enabling the recovery of a multi-bit author identity even when the text has been heavily redacted by an adversary. The core idea is to embed a continuous sequence of points $(x, f(x))$ that lie on a single straight line. The $x$-coordinates are computed pseudorandomly using a cryptographic hash function $H$ applied to the concatenation of the previous token's identity and a secret key $s_k$. Crucially, the $x$-coordinates do not need to be embedded into the text -- only the corresponding $f(x)$ values are embedded. During extraction, the algorithm recovers the original points along with many spurious ones, forming an instance of the Maximum Collinear Points (MCP) problem, which can be solved efficiently. Experimental results demonstrate that the proposed method is highly effective, allowing the recovery of the author identity even when as few as three genuine points remain after adversarial manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05712v4</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaros{\l}aw Janas, Pawe{\l} Morawiecki, Josef Pieprzyk</dc:creator>
    </item>
    <item>
      <title>Representative, Informative, and De-Amplifying: Requirements for Robust Bayesian Active Learning under Model Misspecification</title>
      <link>https://arxiv.org/abs/2506.07805</link>
      <description>arXiv:2506.07805v2 Announce Type: replace-cross 
Abstract: In many settings in science and industry, such as drug discovery and clinical trials, a central challenge is designing experiments under time and budget constraints. Bayesian Optimal Experimental Design (BOED) is a paradigm to pick maximally informative designs that has been increasingly applied to such problems. During training, BOED selects inputs according to a pre-determined acquisition criterion to target informativeness. During testing, the model learned during training encounters a naturally occurring distribution of test samples. This leads to an instance of covariate shift, where the train and test samples are drawn from different distributions (the training samples are not representative of the test distribution). Prior work has shown that in the presence of model misspecification, covariate shift amplifies generalization error. Our first contribution is to provide a mathematical analysis of generalization error that reveals key contributors to generalization error in the presence of model misspecification. We show that generalization error under misspecification is the result of, in addition to covariate shift, a phenomenon we term error (de-)amplification which has not been identified or studied in prior work. We then develop a new acquisition function that mitigates the effects of model misspecification by including terms for representativeness, informativeness, and de-amplification (R-IDeA). Our experimental results demonstrate that the proposed method performs better than methods that target either only informativeness, representativeness, or both.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07805v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 27 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roubing Tang, Sabina J. Sloman, Samuel Kaski</dc:creator>
    </item>
  </channel>
</rss>
