<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Local L2-bounded commuting projections using discrete local problems on Alfeld splits</title>
      <link>https://arxiv.org/abs/2502.03601</link>
      <description>arXiv:2502.03601v1 Announce Type: new 
Abstract: We construct projections onto the classical finite element spaces based on Lagrange, N\'ed\'elec, Raviart--Thomas, and discontinuous elements on shape-regular simplicial meshes. Our projections are defined locally, are bounded in the L2-norm, and commute with the corresponding differential operators. The cornerstone of the construction are local weight functions which are piecewise polynomials built using the Alfeld split of local patches from the original simplicial mesh. This way, the L2-stability of the projections is established by invoking discrete Poincar\'e inequalities on these local stars, for which we provide constructive proofs. We also show how to modify the construction to preserve homogeneous boundary conditions. The material is presented using the language of vector calculus, and links to the formalism of finite element exterior calculus are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03601v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexandre Ern, Johnny Guzman, Pratyush Potu, Martin Vohralik</dc:creator>
    </item>
    <item>
      <title>An Efficient Quasi-Newton Method with Tensor Product Implementation for Solving Quasi-Linear Elliptic Equations and Systems</title>
      <link>https://arxiv.org/abs/2502.03611</link>
      <description>arXiv:2502.03611v1 Announce Type: new 
Abstract: In this paper, we introduce a quasi-Newton method optimized for efficiently solving quasi-linear elliptic equations and systems, with a specific focus on GPU-based computation. By approximating the Jacobian matrix with a combination of linear Laplacian and simplified nonlinear terms, our method reduces the computational overhead typical of traditional Newton methods while handling the large, sparse matrices generated from discretized PDEs. We also provide a convergence analysis demonstrating local convergence to the exact solution under optimal choices for the regularization parameter, ensuring stability and efficiency in each iteration. Numerical experiments in two- and three-dimensional domains validate the proposed method's robustness and computational gains with tensor-product implementation. This approach offers a promising pathway for accelerating quasi-linear elliptic equation and system solvers, expanding the feasibility of complex simulations in physics, engineering, and other fields leveraging advanced hardware capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03611v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenrui Hao, Sun Lee, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo Methods: What, Why, and How?</title>
      <link>https://arxiv.org/abs/2502.03644</link>
      <description>arXiv:2502.03644v1 Announce Type: new 
Abstract: Many questions in quantitative finance, uncertainty quantification, and other disciplines are answered by computing the population mean, $\mu := \mathbb{E}(Y)$, where instances of $Y:=f(\boldsymbol{X})$ may be generated by numerical simulation and $\boldsymbol{X}$ has a simple probability distribution. The population mean can be approximated by the sample mean, $\hat{\mu}_n := n^{-1} \sum_{i=0}^{n-1} f(\boldsymbol{x}_i)$ for a well chosen sequence of nodes, $\{\boldsymbol{x}_0, \boldsymbol{x}_1, \ldots\}$ and a sufficiently large sample size, $n$. Computing $\mu$ is equivalent to computing a $d$-dimensional integral, $\int f(\boldsymbol{x}) \varrho(\boldsymbol{x}) \, \mathrm{d} \boldsymbol{x}$, where $\varrho$ is the probability density for $\boldsymbol{X}$.
  Quasi-Monte Carlo methods replace independent and identically distributed sequences of random vector nodes, $\{\boldsymbol{x}_i \}_{i = 0}^{\infty}$, by low discrepancy sequences. This accelerates the convergence of $\hat{\mu}_n$ to $\mu$ as $n \to \infty$.
  This tutorial describes low discrepancy sequences and their quality measures. We demonstrate the performance gains possible with quasi-Monte Carlo methods. Moreover, we describe how to formulate problems to realize the greatest performance gains using quasi-Monte Carlo. We also briefly describe the use of quasi-Monte Carlo methods for problems beyond computing the mean, $\mu$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03644v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fred J. Hickernell, Nathan Kirk, Aleksei G. Sorokin</dc:creator>
    </item>
    <item>
      <title>MNE: overparametrized neural evolution with applications to diffusion processes and sampling</title>
      <link>https://arxiv.org/abs/2502.03645</link>
      <description>arXiv:2502.03645v1 Announce Type: new 
Abstract: We propose a framework for solving evolution equations within parametric function classes, especially ones that are specified by neural networks. We call this framework the minimal neural evolution (MNE) because it is motivated by the goal of seeking the smallest instantaneous change in the neural network parameters that is compatible with exact solution of the evolution equation at a set of evolving collocation points. Formally, the MNE is quite similar to the recently introduced Neural Galerkin framework, but a difference in perspective motivates an alternative sketching procedure that effectively reduces the linear systems solved within the integrator to a size that is interpretable as an effective rank of the evolving neural tangent kernel, while maintaining a smooth evolution equation for the neural network parameters. We focus specifically on the application of this framework to diffusion processes, where the score function allows us to define intuitive dynamics for the collocation points. These can in turn be propagated jointly with the neural network parameters using a high-order adaptive integrator. In particular, we demonstrate how the Ornstein-Uhlenbeck diffusion process can be used for the task of sampling from a probability distribution given a formula for the density but no training data. This framework extends naturally to allow for conditional sampling and marginalization, and we show how to systematically remove the sampling bias due to parametric approximation error. We validate the efficiency, systematic improvability, and scalability of our approach on illustrative examples in low and high spatial dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03645v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lindsey</dc:creator>
    </item>
    <item>
      <title>Improved high-index saddle dynamics for finding saddle points and solution landscape</title>
      <link>https://arxiv.org/abs/2502.03694</link>
      <description>arXiv:2502.03694v1 Announce Type: new 
Abstract: We present an improved high-index saddle dynamics (iHiSD) for finding saddle points and constructing solution landscapes, which is a crossover dynamics from gradient flow to traditional HiSD such that the Morse theory for gradient flow could be involved. We propose analysis for the reflection manifold in iHiSD, and then prove its stable and nonlocal convergence from outside of the region of attraction to the saddle point, which resolves the dependence of the convergence of HiSD on the initial value. We then present and analyze a discretized iHiSD that inherits these convergence properties. Furthermore, based on the Morse theory, we prove that any two saddle points could be connected by a sequence of trajectories of iHiSD. Theoretically, this implies that a solution landscape with a finite number of stationary points could be completely constructed by means of iHiSD, which partly answers the completeness issue of the solution landscape for the first time and indicates the necessity of integrating the gradient flow in HiSD. Different methods are compared by numerical experiments to substantiate the effectiveness of the iHiSD method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03694v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hua Su, Haoran Wang, Lei Zhang, Jin Zhao, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>A discrete Perfectly Matched Layer for peridynamic scalar waves in two-dimensional viscous media</title>
      <link>https://arxiv.org/abs/2502.03713</link>
      <description>arXiv:2502.03713v1 Announce Type: new 
Abstract: In this paper, we propose a discrete perfectly matched layer (PML) for the peridynamic scalar wave-type problems in viscous media. Constructing PMLs for nonlocal models is often challenging, mainly due to the fact that nonlocal operators are usually associated with various kernels. We first convert the continua model to a spatial semi-discretized version by adopting quadrature-based finite difference scheme, and then derive the PML equations from the semi-discretized equations using discrete analytic continuation. The harmonic exponential fundamental solutions (plane wave modes) of the semi-discretized equations are absorbed by the PML layer without reflection and are exponentially damped. The excellent efficiency and stability of discrete PML are demonstrated in numerical tests by comparison with exact absorbing boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03713v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Du, Yonglin Li, Jiwei Zhang</dc:creator>
    </item>
    <item>
      <title>A high order correction to the Lax-Friedrich's method for approximating stationary Hamilton-Jacobi equations</title>
      <link>https://arxiv.org/abs/2502.03728</link>
      <description>arXiv:2502.03728v1 Announce Type: new 
Abstract: A new class of non-monotone finite difference (FD) approximation methods for approximating solutions to non-degenerate stationary Hamilton-Jacobi problems with Dirichlet boundary conditions is proposed and analyzed. The new FD methods add a high order correction to the Lax-Friedrich's method while utilizing a novel cutoff to preserve the convergence properties of the Lax-Friedrich's approximation. Since monotone methods are limited to first order accuracy by the Godunov barrier, the proposed approach provides a template for boosting the accuracy of a monotone method using a modified numerical moment stabilizer with a high-order auxiliary boundary condition. Numerical tests are provided to test the utility of the approach while a novel admissibility and stability analysis technique lays a foundation for analyzing non-monotone methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03728v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. Lewis, X. Xue</dc:creator>
    </item>
    <item>
      <title>Interpolation and inverse problems in spectral Barron spaces</title>
      <link>https://arxiv.org/abs/2502.03819</link>
      <description>arXiv:2502.03819v1 Announce Type: new 
Abstract: Spectral Barron spaces, which quantify the absolute value of weighted Fourier coefficients of a function, have gained considerable attention due to their capability for universal approximation across certain function classes. By establishing a connection between these spaces and a specific positive linear operator, we investigate the interpolation and scaling relationships among diverse spectral Barron spaces. Furthermore, we introduce a link condition by relating the spectral Barron space to inverse problems, illustrating this with three exemplary cases. We revisit the notion of universal approximation within the context of spectral Barron spaces and validate an error bound for Tikhonov regularization, penalized by the spectral Barron norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03819v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuai Lu, Peter Math\'e</dc:creator>
    </item>
    <item>
      <title>Error estimates for full discretization by an almost mass conservation technique for Cahn--Hilliard systems with dynamic boundary conditions</title>
      <link>https://arxiv.org/abs/2502.03847</link>
      <description>arXiv:2502.03847v1 Announce Type: new 
Abstract: A proof of optimal-order error estimates is given for the full discretization of the bulk--surface Cahn--Hilliard system with dynamic boundary conditions in a smooth domain. The numerical method combines a linear bulk--surface finite element discretization in space and linearly implicit backward difference formulae of order one to five in time. The error estimates are obtained by a consistency and stability analysis, based on energy estimates and the novel approach of exploiting the almost mass conservation of the error equations to derive a Poincar\'e-type inequality. We also outline how this approach can be generalized to other mass conserving problems and illustrate our findings by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03847v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nils Bullerjahn</dc:creator>
    </item>
    <item>
      <title>Numerical Aspects of the Tensor Product Multilevel Method for High-dimensional, Kernel-based Reconstruction on Sparse Grids</title>
      <link>https://arxiv.org/abs/2502.03881</link>
      <description>arXiv:2502.03881v1 Announce Type: new 
Abstract: This paper investigates the approximation of functions with finite smoothness defined on domains with a Cartesian product structure. The recently proposed tensor product multilevel method (TPML) combines Smolyak's sparse grid method with a kernel-based residual correction technique. The contributions of this paper are twofold. First, we present two improvements on the TPML that reduce the computational cost of point evaluations compared to a naive implementation. Second, we provide numerical examples that demonstrate the effectiveness and innovation of the TPML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03881v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus B\"uttner, R\"udiger Kempf, Holger Wendland</dc:creator>
    </item>
    <item>
      <title>Adaptive Cross Approximation with a Geometrical Pivot Choice: ACA-GP Method</title>
      <link>https://arxiv.org/abs/2502.03886</link>
      <description>arXiv:2502.03886v1 Announce Type: new 
Abstract: The Adaptive Cross Approximation (ACA) method is widely used to approximate admissible blocks of hierarchical matrices, or H-matrices, from discretized operators in the boundary integral method. These matrices are fully populated, making their storage and manipulation resource-intensive. ACA constructs a low-rank approximation by evaluating only a few rows and columns of the original operator, significantly reducing computational costs. A key aspect of ACA's effectiveness is the selection of pivots, which are entries common to the evaluated row and column of the original matrix. This paper proposes combining the classical, purely algebraic ACA method with a geometrical pivot selection based on the central subsets and extreme property subsets. The method is named ACA-GP, GP stands for Geometrical Pivots. The superiority of the ACA-GP compared to the classical ACA is demonstrated using a classical Green operator for two clouds of interacting points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03886v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladislav A. Yastrebov, Camille No\^us</dc:creator>
    </item>
    <item>
      <title>A class of positive-preserving,energy stable and high order numerical schemes for the Poission-Nernst-Planck system</title>
      <link>https://arxiv.org/abs/2502.03892</link>
      <description>arXiv:2502.03892v1 Announce Type: new 
Abstract: In this paper, we introduce and analyze a class of numerical schemes that demonstrate remarkable superiority in terms of efficiency, the preservation of positivity, energy stability, and high-order precision to solve the time-dependent Poisson-Nernst-Planck (PNP) system, which is
  as a highly versatile and sophisticated model and accommodates a plenitude of applications in the emulation of the translocation of charged particles across a multifarious expanse of physical and biological systems. The numerical schemes presented here are based on the energy variational formulation. It allows the PNP system to be reformulated as a non-constant mobility $H^{-1}$ gradient flow, incorporating singular logarithmic energy potentials. To achieve a fully discrete numerical scheme, we employ a combination of first/second-order semi-implicit time discretization methods, coupled with either the $k$-th order direct discontinuous Galerkin (DDG) method or the finite element (FE) method for spatial discretization. The schemes are verified to possess positivity preservation and energy stability. Optimal error estimates and particular superconvergence results for the fully-discrete numerical solution are established. Numerical experiments are provided to showcase the accuracy, efficiency, and robustness of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03892v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Waixiang Cao, Yuzhe Qin, Minqiang Xu</dc:creator>
    </item>
    <item>
      <title>Two-step parameterized tensor-based iterative methods for solving $\mathcal{A}_{*M}\mathcal{X}_{*M}\mathcal{B}=\mathcal{C}$</title>
      <link>https://arxiv.org/abs/2502.03921</link>
      <description>arXiv:2502.03921v1 Announce Type: new 
Abstract: Iterative methods based on tensors have emerged as powerful tools for solving tensor equations, and have significantly advanced across multiple disciplines. In this study, we propose two-step tensor-based iterative methods to solve the tensor equations $\mathcal{A}_{*M}\mathcal{X}_{*M}\mathcal{B}=\mathcal{C}$ by incorporating preconditioning techniques and parametric optimization to enhance convergence properties. The theoretical results were complemented by comprehensive numerical experiments that demonstrated the computational efficiency of the proposed two-step parametrized iterative methods. The convergence criterion for parameter selection has been studied and a few numerical experiments have been conducted for optimal parameter selection. Effective algorithms were proposed to compute iterative methods based on two-step parameterized tensors, and the results are promising. In addition, we discuss the solution of the Sylvester equations and a regularized least-squares solution for image deblurring problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03921v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ratikanta Behera, Saroja Kumar Panda, Jajati Keshari Sahoo</dc:creator>
    </item>
    <item>
      <title>Numerical moment stabilization of central difference approximations for linear stationary reaction-convection-diffusion equations with applications to stationary Hamilton-Jacobi equations</title>
      <link>https://arxiv.org/abs/2502.04142</link>
      <description>arXiv:2502.04142v1 Announce Type: new 
Abstract: Linear stationary reaction-convection-diffusion equations with Dirichlet boundary conditions are approximated using a simple finite difference method corresponding to central differences and the addition of a high-order stabilization term called a numerical moment. The focus is on convection-dominated equations, and the formulation for the method is motivated by various results for fully nonlinear problems. The method features higher-order local truncation errors than monotone methods consistent with the use of the central difference approximation for the gradient. Stability and rates of convergence are derived in the $\ell^2$ norm for the constant-coefficient case. Numerical tests are provided to compare the new methods to monotone methods. The methods are also tested for stationary Hamilton-Jacobi equations where they demonstrate higher rates of convergence than the Lax-Friedrich's method when the underlying viscosity solution is smooth and comparable performance when the underlying viscosity solution is not smooth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04142v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. Lewis, X. Xue</dc:creator>
    </item>
    <item>
      <title>Electrical Impedance Tomography for Anisotropic Media: a Machine Learning Approach to Classify Inclusions</title>
      <link>https://arxiv.org/abs/2502.04273</link>
      <description>arXiv:2502.04273v1 Announce Type: new 
Abstract: We consider the problem in Electrical Impedance Tomography (EIT) of identifying one or multiple inclusions in a background-conducting body $\Omega\subset\mathbb{R}^2$, from the knowledge of a finite number of electrostatic measurements taken on its boundary $\partial\Omega$ and modelled by the Dirichlet-to-Neumann (D-N) matrix. Once the presence of one inclusion in $\Omega$ is established, our model, combined with the machine learning techniques of Artificial Neural Networks (ANN) and Support Vector Machines (SVM), may be used to determine the size of the inclusion, the presence of multiple inclusions, and also that of anisotropy within the inclusion(s). Utilising both real and simulated datasets within a 16-electrode setup, we achieve a high rate of inclusion detection and show that two measurements are sufficient to achieve a good level of accuracy when predicting the size of an inclusion. This underscores the substantial potential of integrating machine learning approaches with the more classical analysis of EIT and the inverse inclusion problem to extract critical insights, such as the presence of anisotropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04273v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Romina Gaburro, Patrick Healy, Shraddha Naidu, Clifford Nolan</dc:creator>
    </item>
    <item>
      <title>Physically consistent predictive reduced-order modeling by enhancing Operator Inference with state constraints</title>
      <link>https://arxiv.org/abs/2502.03672</link>
      <description>arXiv:2502.03672v1 Announce Type: cross 
Abstract: Numerical simulations of complex multiphysics systems, such as char combustion considered herein, yield numerous state variables that inherently exhibit physical constraints. This paper presents a new approach to augment Operator Inference -- a methodology within scientific machine learning that enables learning from data a low-dimensional representation of a high-dimensional system governed by nonlinear partial differential equations -- by embedding such state constraints in the reduced-order model predictions. In the model learning process, we propose a new way to choose regularization hyperparameters based on a key performance indicator. Since embedding state constraints improves the stability of the Operator Inference reduced-order model, we compare the proposed state constraints-embedded Operator Inference with the standard Operator Inference and other stability-enhancing approaches. For an application to char combustion, we demonstrate that the proposed approach yields state predictions superior to the other methods regarding stability and accuracy. It extrapolates over 200\% past the training regime while being computationally efficient and physically consistent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03672v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyeonghun Kim, Boris Kramer</dc:creator>
    </item>
    <item>
      <title>A necessary condition for the guarantee of the superiorization method</title>
      <link>https://arxiv.org/abs/2502.03867</link>
      <description>arXiv:2502.03867v1 Announce Type: cross 
Abstract: We study a method that involves principally convex feasibility-seeking and makes secondary efforts of objective function value reduction. This is the well-known superiorization method (SM), where the iterates of an asymptotically convergent iterative feasibility-seeking algorithm are perturbed by objective function nonascent steps. We investigate the question under what conditions a sequence generated by an SM algorithm asymptotically converges to a feasible point whose objective function value is superior (meaning smaller or equal) to that of a feasible point reached by the corresponding unperturbed one (i.e., the exactly same feasibility-seeking algorithm that the SM algorithm employs.) This question is yet only partially answered in the literature. We present a condition under which an SM algorithm that uses negative gradient descent steps in its perturbations fails to yield such a superior outcome. The significance of the discovery of this negative condition is that it necessitates that the inverse of this condition will have to be assumed to hold in any future guarantee result for the SM. The condition is important for practitioners who use the SM because it is avoidable in experimental work with the SM, thus increasing the success rate of the method in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03867v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kay Barshad, Yair Censor, Walaa Moursi, Tyler Weames, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>Quantifying Correlations of Machine Learning Models</title>
      <link>https://arxiv.org/abs/2502.03937</link>
      <description>arXiv:2502.03937v1 Announce Type: cross 
Abstract: Machine Learning models are being extensively used in safety critical applications where errors from these models could cause harm to the user. Such risks are amplified when multiple machine learning models, which are deployed concurrently, interact and make errors simultaneously. This paper explores three scenarios where error correlations between multiple models arise, resulting in such aggregated risks. Using real-world data, we simulate these scenarios and quantify the correlations in errors of different models. Our findings indicate that aggregated risks are substantial, particularly when models share similar algorithms, training datasets, or foundational models. Overall, we observe that correlations across models are pervasive and likely to intensify with increased reliance on foundational models and widely used public datasets, highlighting the need for effective mitigation strategies to address these challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03937v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanyuan Li, Neeraj Sarna, Yang Lin</dc:creator>
    </item>
    <item>
      <title>A New Approach for Designing Well-Balanced Schemes for the Shallow Water Equations: A Combination of Conservative and Primitive Formulations</title>
      <link>https://arxiv.org/abs/2304.07809</link>
      <description>arXiv:2304.07809v4 Announce Type: replace 
Abstract: In this paper, we introduce a new approach for constructing robust well-balanced numerical methods for the one-dimensional Saint-Venant system with and without the Manning friction term. Following the idea presented in [R. Abgrall, Commun. Appl. Math. Comput. 5(2023), pp. 370-402], we first combine the conservative and non-conservative (primitive) formulations of the studied conservative hyperbolic system in a natural way. The solution is globally continuous and described by a combination of point values and average values. The point values and average values will then be evolved by two different forms of PDEs: a conservative version of the cell averages and a possibly non-conservative one for the points. We show how to deal with both the conservative and non-conservative forms of PDEs in a well-balanced manner. The developed schemes are capable of exactly preserving both the still-water and moving-water equilibria. Compared with existing well-balanced methods, this new class of scheme is nonlinear-equations-solver-free. This makes the developed schemes less computationally costly and easier to extend to other models. We demonstrate the behavior of the proposed new scheme on several challenging examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07809v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Remi Abgrall, Yongle Liu</dc:creator>
    </item>
    <item>
      <title>Clustering based Multiple Anchors High-Dimensional Model Representation</title>
      <link>https://arxiv.org/abs/2310.19277</link>
      <description>arXiv:2310.19277v3 Announce Type: replace 
Abstract: In this work, a cut high-dimensional model representation (cut-HDMR) expansion based on multiple anchors is constructed via the clustering method. Specifically, a set of random input realizations is drawn from the parameter space and grouped by the centroidal Voronoi tessellation (CVT) method. Then for each cluster, the centroid is set as the reference, thereby the corresponding zeroth-order term can be determined directly. While for non-zero order terms of each cut-HDMR, a set of discrete points is selected for each input component, and the Lagrange interpolation method is applied. For a new input, the cut-HDMR corresponding to the nearest centroid is used to compute its response. Numerical experiments with high-dimensional integral and elliptic stochastic partial differential equation as backgrounds show that the CVT based multiple anchors cut-HDMR can alleviate the negative impact of a single inappropriate anchor point, and has higher accuracy than the average of several expansions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19277v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meixin Xiong, Liuhong Chen, Ju Ming, Xingchen Pan, Xinyu Yan</dc:creator>
    </item>
    <item>
      <title>A frame approach for equations involving the fractional Laplacian</title>
      <link>https://arxiv.org/abs/2311.12451</link>
      <description>arXiv:2311.12451v3 Announce Type: replace 
Abstract: Exceptionally elegant formulae exist for the fractional Laplacian operator applied to weighted classical orthogonal polynomials. We utilize these results to construct a solver, based on frame properties, for equations involving the fractional Laplacian of any power, $s \in (0,1)$, on an unbounded domain in one or two dimensions. The numerical method represents solutions in an expansion of weighted classical orthogonal polynomials as well as their unweighted counterparts with a specific extension to $\mathbb{R}^d$, $d \in \{1,2\}$. We examine the frame properties of this family of functions for the solution expansion and, under standard frame conditions, derive an a priori estimate for the stationary equation. Moreover, we prove one achieves the expected order of convergence when considering an implicit Euler discretization in time for the fractional heat equation. We apply our solver to numerous examples including the fractional heat equation (utilizing up to a $6^\text{th}$-order Runge--Kutta time discretization), a fractional heat equation with a time-dependent exponent $s(t)$, and a two-dimensional problem, observing spectral convergence in the spatial dimension for sufficiently smooth data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12451v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis P. A. Papadopoulos, Timon S. Gutleb, Jos\'e A. Carrillo, Sheehan Olver</dc:creator>
    </item>
    <item>
      <title>An Arbitrarily High-Order Fully Well-balanced Hybrid Finite Element-Finite Volume Method for a One-dimensional Blood Flow Model</title>
      <link>https://arxiv.org/abs/2404.18124</link>
      <description>arXiv:2404.18124v2 Announce Type: replace 
Abstract: We propose an arbitrarily high-order accurate, fully well-balanced numerical method for the one-dimensional blood flow model. The developed method employs a continuous solution representation, combining conservative and primitive formulations. Degrees of freedom are point values at cell interfaces and moments of conservative variables within cells. \bla{The well-balanced property -- ensuring exact preservation of zero and non-zero velocity steady-state solutions while accurately capturing small perturbations -- is achieved through two key components. First, in the evolution of the moments, a local reference steady-state solution is obtained and subtracted. Second, the point value update happens in equilibrium variables. Extensive numerical tests are conducted to validate the preservation of various steady-state solutions, robust capturing small perturbations to such solutions, and high-order accuracy for both smooth and discontinuous solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18124v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongle Liu, Wasilij Barsukow</dc:creator>
    </item>
    <item>
      <title>Challenges in numerical integration in physics-informed neural networks modelling</title>
      <link>https://arxiv.org/abs/2408.05172</link>
      <description>arXiv:2408.05172v2 Announce Type: replace 
Abstract: In this paper, we numerically examine the challenges that emerge in numerical integration for various tasks now tackled by physics-informed neural networks. Specifically, we illustrate how inaccurately computed integrands can cause serious precision issues. A major difficulty lies in detecting these problems, since a simple large-scale view of the integrand may not reveal any potential errors, and the resulting outcomes are often mistakenly considered correct. To address this, it is critical to determine whether standard double-precision arithmetic suffices for evaluating the integrand or if higher precision is necessary. We evaluate and suggest numerical quadrature methods for selected examples and parameter values, particularly focusing on challenging scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05172v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josef Dan\v{e}k, Jan Posp\'i\v{s}il</dc:creator>
    </item>
    <item>
      <title>Composite B-Spline Regularized Delta Functions for the Immersed Boundary Method: Divergence-Free Interpolation and Gradient-Preserving Force Spreading</title>
      <link>https://arxiv.org/abs/2408.08280</link>
      <description>arXiv:2408.08280v3 Announce Type: replace 
Abstract: This paper presents an approach to enhance volume conservation in the immersed boundary (IB) method by using regularized delta functions derived from composite B-splines. The conventional IB method, while effective for fluid-structure interaction applications, has long been challenged by poor volume conservation, particularly evident in simulations of pressurized, closed membranes. We demonstrate that composite B-spline regularized delta functions significantly enhance volume conservation through two complementary properties: they provide continuously divergence-free velocity interpolants and maintain the gradient character of forces corresponding to mean pressure jumps across interfaces. By correctly representing these forces as discrete gradients, they eliminate a key source of spurious flows that typically plague immersed boundary computations. Our approach maintains the local nature of the classical IB method, avoiding the computational overhead associated with the non-local Divergence-Free Immersed Boundary (DFIB) method's construction of an explicit velocity potential which requires additional Poisson solves for interpolation and force spreading operations. We show that sufficiently regular composite B-spline kernels maintain initial volumes to within machine precision. We provide a detailed analysis of the relationship between kernel regularity and the accuracy of force spreading and velocity interpolation operations. Our findings indicate that composite B-splines of at least $C^1$ regularity produce results comparable to the DFIB method in dynamic simulations, with errors in volume conservation dominated by truncation error of the time-stepping scheme. The proposed approach requires minimal modifications to an existing IB code, making it an accessible improvement for a wide range of applications in computational fluid dynamics and fluid-structure interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08280v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cole Gruninger, Boyce E. Griffith</dc:creator>
    </item>
    <item>
      <title>Higher-Order Transformer Derivative Estimates for Explicit Pathwise Learning Guarantees</title>
      <link>https://arxiv.org/abs/2405.16563</link>
      <description>arXiv:2405.16563v2 Announce Type: replace-cross 
Abstract: An inherent challenge in computing fully-explicit generalization bounds for transformers involves obtaining covering number estimates for the given transformer class $T$. Crude estimates rely on a uniform upper bound on the local-Lipschitz constants of transformers in $T$, and finer estimates require an analysis of their higher-order partial derivatives. Unfortunately, these precise higher-order derivative estimates for (realistic) transformer models are not currently available in the literature as they are combinatorially delicate due to the intricate compositional structure of transformer blocks.
  This paper fills this gap by precisely estimating all the higher-order derivatives of all orders for the transformer model. We consider realistic transformers with multiple (non-linearized) attention heads per block and layer normalization. We obtain fully-explicit estimates of all constants in terms of the number of attention heads, the depth and width of each transformer block, and the number of normalization layers. Further, we explicitly analyze the impact of various standard activation function choices (e.g. SWISH and GeLU). As an application, we obtain explicit pathwise generalization bounds for transformers on a single trajectory of an exponentially-ergodic Markov process valid at a fixed future time horizon. We conclude that real-world transformers can learn from $N$ (non-i.i.d.) samples of a single Markov process's trajectory at a rate of ${O}(\operatorname{polylog}(N)/\sqrt{N})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16563v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yannick Limmer, Anastasis Kratsios, Xuwei Yang, Raeid Saqur, Blanka Horvath</dc:creator>
    </item>
    <item>
      <title>G-Adaptivity: optimised graph-based mesh relocation for finite element methods</title>
      <link>https://arxiv.org/abs/2407.04516</link>
      <description>arXiv:2407.04516v2 Announce Type: replace-cross 
Abstract: We present a novel, and effective, approach to achieve optimal mesh relocation in finite element methods (FEMs). The cost and accuracy of FEMs is critically dependent on the choice of mesh points. Mesh relocation (r-adaptivity) seeks to optimise the mesh geometry to obtain the best solution accuracy at given computational budget. Classical r-adaptivity relies on the solution of a separate nonlinear "meshing" PDE to determine mesh point locations. This incurs significant cost at remeshing, and relies on estimates that relate interpolation- and FEM-error. Recent machine learning approaches have focused on the construction of fast surrogates for such classical methods. Instead, our new approach trains a graph neural network (GNN) to determine mesh point locations by directly minimising the FE solution error from the PDE system Firedrake to achieve higher solution accuracy. Our GNN architecture closely aligns the mesh solution space to that of classical meshing methodologies, thus replacing classical estimates for optimality with a learnable strategy. This allows for rapid and robust training and results in an extremely efficient and effective GNN approach to online r-adaptivity. Our method outperforms both classical, and prior ML, approaches to r-adaptive meshing. In particular, it achieves lower FE solution error, whilst retaining the significant speed-up over classical methods observed in prior ML work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04516v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Rowbottom, Georg Maierhofer, Teo Deveney, Eike Mueller, Alberto Paganini, Katharina Schratz, Pietro Li\`o, Carola-Bibiane Sch\"onlieb, Chris Budd</dc:creator>
    </item>
    <item>
      <title>VICON: A Foundation Model for Multi-Physics Fluid Dynamics via Vision In-Context Operator Networks</title>
      <link>https://arxiv.org/abs/2411.16063</link>
      <description>arXiv:2411.16063v2 Announce Type: replace-cross 
Abstract: In-Context Operator Networks (ICONs) are models that learn operators across different types of PDEs using a few-shot, in-context approach. Although they show successful generalization to various PDEs, existing methods treat each data point as a single token, and suffer from computational inefficiency when processing dense data, limiting their application in higher spatial dimensions. In this work, we propose \textit{Vision In-Context Operator Networks} (VICON), incorporating a vision transformer architecture that efficiently processes 2D functions through patch-wise operations. We evaluated our method on three fluid dynamics datasets, demonstrating both superior performance (reducing the rescaled $L^2$ error by $40\%$ and $61.6\%$ for two benchmark datasets for compressible flows, respectively) and computational efficiency (requiring only one-third of the inference time per frame) in long-term rollout predictions compared to the current state-of-the-art sequence-to-sequence model with fixed timestep prediction: Multiple Physics Pretraining (MPP). Compared to MPP, our method preserves the benefits of in-context operator learning, enabling flexible context formation when dealing with insufficient frame counts or varying timestep values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16063v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yadi Cao, Yuxuan Liu, Liu Yang, Rose Yu, Hayden Schaeffer, Stanley Osher</dc:creator>
    </item>
  </channel>
</rss>
