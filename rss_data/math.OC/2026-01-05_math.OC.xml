<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 03:17:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Designing Information Delays in Supply Chains</title>
      <link>https://arxiv.org/abs/2601.00265</link>
      <description>arXiv:2601.00265v1 Announce Type: new 
Abstract: This paper studies how a downstream retailer in a decentralized two-tier supply chain can implicitly transmit demand information to an upstream supplier through the structure of its order stream in the absence of an explicit information-sharing mechanism. We distinguish our work from prior work by introducing the notion of information delay and by linking optimal implicit information sharing to the group delay of the retailer's ordering transfer function. We show that pure delay is strictly suboptimal, while fractional-delay mechanisms can reshape the order autocorrelation to improve supplier forecastability and reduce system-wide inventory costs. Using Hardy-space factorization, we develop a tractable family of invertible ARMA policies that approximates the theoretically optimal (but non-rational) limiting filter derived by Caldentey et al. (2025) and preserves its informational delay properties. This construction yields sharp guidance on how policy complexity, as measured by the degrees of the ARMA policies, impacts supply chain costs. We further extend the analysis to memory-constrained suppliers and characterize how the complexity of the retailer's policy should scale with the supplier's finite forecasting window, highlighting when, perhaps counterintuitively, increasing policy complexity can become counterproductive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00265v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prem Talwai, Rene Caldentey, Avi Giloni, Clifford Hurvich, David Simchi-Levi, Yichen Zhang</dc:creator>
    </item>
    <item>
      <title>The true detection probability versus the subjective detection probability of a uniformly optimal search plan</title>
      <link>https://arxiv.org/abs/2601.00350</link>
      <description>arXiv:2601.00350v1 Announce Type: new 
Abstract: This article investigates the difference between the true detection probability and the subjective probability of a uniformly optimal search plan. Its main contributions are multi-fold. First, it provides a set of examples to show that, in terms of the true detection probability, the uniformly optimal search plan may or may not be optimal. Secondly, it establishes that the true detection probability of the uniformly optimal search plan based on a composite prior can be less than that of the composite uniformly search plan based on different priors. Next, it argues that an open problem is unsolvable. Finally, it shows that the true detection probability of the uniformly optimal search plan converges to one as the search time approaches infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00350v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Hong</dc:creator>
    </item>
    <item>
      <title>Completely Positive Reformulations of Polynomial Optimization Problems with Linear Inequality Constraints</title>
      <link>https://arxiv.org/abs/2601.00375</link>
      <description>arXiv:2601.00375v1 Announce Type: new 
Abstract: Polynomial optimization encompasses a broad class of problems in which both the objective function and constraints are polynomial functions of the decision variables. In recent years, a substantial body of research has focused on reformulating polynomial optimization problems (POPs) as conic programs over the cone of completely positive tensors (CPTs). In this article, we propose several new completely positive reformulations for a class of POPs with linear inequality constraints. Our approach begins by lifting these problems into a novel convex optimization framework, wherein the variables are represented as combinations of symmetric rank-one tensors. Based on this lifted formulation, we present a general characterization of POPs with linear inequality constraints that can be reformulated as conic programs over the CPT cone. Additionally, we construct the dual formulations of the resulting completely positive programs. Under mild assumptions, we prove that these dual problems are strictly feasible and strong duality holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00375v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haibin Chen, Hong Yan, Guanglu Zhou</dc:creator>
    </item>
    <item>
      <title>Quadratic Unconstrained Binary Optimisation for Training and Regularisation of Binary Neural Networks</title>
      <link>https://arxiv.org/abs/2601.00449</link>
      <description>arXiv:2601.00449v1 Announce Type: new 
Abstract: Advances in artificial intelligence (AI) and deep learning have raised concerns about its increasing energy consumption, while demand for deploying AI in mobile devices and machines at the edge is growing. Binary neural networks (BNNs) have recently gained attention as energy and memory efficient models suitable for resource constrained environments; however, training BNNs exactly is computationally challenging because of its discrete characteristics. Recent work proposing a framework for training BNNs based on quadratic unconstrained binary optimisation (QUBO) and progress in the design of Ising machines for solving QUBO problems suggest a potential path to efficiently optimising discrete neural networks. In this work, we extend existing QUBO models for training BNNs to accommodate arbitrary network topologies and propose two novel methods for regularisation. The first method maximises neuron margins biasing the training process toward parameter configurations that yield larger pre-activation magnitudes. The second method employs a dropout-inspired iterative scheme in which reduced subnetworks are trained and used to adjust linear penalties on network parameters. We apply the proposed QUBO formulation to a small binary image classification problem and conduct computational experiments on a GPU-based Ising machine. The numerical results indicate that the proposed regularisation terms modify training behaviour and yield improvements in classification accuracy on data not present in the training set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00449v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonas Christoffer Villumsen, Yusuke Sugita</dc:creator>
    </item>
    <item>
      <title>Safe Adaptive Feedback Control via Barrier States</title>
      <link>https://arxiv.org/abs/2601.00476</link>
      <description>arXiv:2601.00476v1 Announce Type: new 
Abstract: This paper presents a safe feedback control framework for nonlinear control-affine systems with parametric uncertainty by leveraging adaptive dynamic programming (ADP) with barrier-state augmentation. The developed ADP-based controller enforces control invariance by optimizing a value function that explicitly penalizes the barrier state, thereby embedding safety directly into the Bellman structure. The near-optimal control policy computed using model-based reinforcement learning is combined with a concurrent learning estimator to identify the unknown parameters and guarantee uniform convergence without requiring persistency of excitation. Using a barrier-state Lyapunov function, we establish boundedness of the barrier dynamics and prove closed-loop stability and safety. Numerical simulations on an optimal obstacle-avoidance problem validate the effectiveness of the developed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00476v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Trivikram Satharasi, Tochukwu E. Ogri, Muzaffar Qureshi, Kyle Volle, Rushikesh Kamalapurkar</dc:creator>
    </item>
    <item>
      <title>Variational inference via Gaussian interacting particles in the Bures-Wasserstein geometry</title>
      <link>https://arxiv.org/abs/2601.00632</link>
      <description>arXiv:2601.00632v1 Announce Type: new 
Abstract: Motivated by variational inference methods, we propose a zeroth-order algorithm for solving optimization problems in the space of Gaussian probability measures. The algorithm is based on an interacting system of Gaussian particles that stochastically explore the search space and self-organize around global minima via a consensus-based optimization (CBO) mechanism. Its construction relies on the Linearized Bures-Wasserstein (LBW) space, a novel parametrization of Gaussian measures we introduce for efficient computations. LBW is inspired by linearized optimal transport and preserves key geometric features while enabling computational tractability. We establish well-posedness and study the convergence properties of the particle dynamics via a mean-field approximation. Numerical experiments on variational inference tasks demonstrate the algorithm's robustness and superior performance with respect to gradient-based method in presence of non log-concave targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00632v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Borghi, Jos\'e A. Carrillo</dc:creator>
    </item>
    <item>
      <title>Stability of vehicular admission control schemes in urban traffic networks under modelling uncertainty</title>
      <link>https://arxiv.org/abs/2601.00732</link>
      <description>arXiv:2601.00732v1 Announce Type: new 
Abstract: Urban transportation networks face significant challenges due to traffic congestion, leading to adverse environmental and socioeconomic impacts. Vehicular admission control (VAC) strategies have emerged as a promising solution to alleviate congestion. By leveraging information and communication technologies, VAC strategies regulate vehicle entry into the network to optimize different traffic metrics of interest over space and time. Despite the significant development of VAC strategies, their stability at the presence of modelling uncertainty remains under-explored. This paper investigates the stability properties of a class of decentralized VAC schemes under modelling uncertainty. Specifically, we consider large-scale, heterogeneous urban traffic networks characterised by nonlinear dynamics and concave macroscopic fundamental diagrams with bounded uncertainty between flow, density, and speed. In this context, we examine a broad class of decentralized VAC dynamics, described by general nonlinear forms. Using passivity theory, we derive scalable, locally verifiable conditions on the design of VAC schemes, that enable stability guarantees in the presence of modelling uncertainty. Several examples are presented to illustrate the applicability of the proposed design framework. Our analytical results are validated through numerical simulations on a 6-region system, demonstrating their effectiveness and practical relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00732v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Michalis Ramp, Andreas Kasis, Stelios Timotheou</dc:creator>
    </item>
    <item>
      <title>Causal LLM Routing: End-to-End Regret Minimization from Observational Data</title>
      <link>https://arxiv.org/abs/2505.16037</link>
      <description>arXiv:2505.16037v2 Announce Type: cross 
Abstract: LLM routing aims to select the most appropriate model for each query, balancing competing performance metrics such as accuracy and cost across a pool of language models. Prior approaches typically adopt a decoupled strategy, where the metrics are first predicted and the model is then selected based on these estimates. This setup is prone to compounding errors and often relies on full-feedback data, where each query is evaluated by all candidate models, which is costly to obtain and maintain in practice. In contrast, we learn from observational data, which records only the outcome of the model actually deployed. We propose a causal end-to-end framework that learns routing policies by minimizing decision-making regret from observational data. To enable efficient optimization, we introduce two theoretically grounded surrogate objectives: a classification-based upper bound, and a softmax-weighted regret approximation shown to recover the optimal policy at convergence. We further extend our framework to handle heterogeneous cost preferences via an interval-conditioned architecture. Experiments on public benchmarks show that our method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16037v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asterios Tsiourvas, Wei Sun, Georgia Perakis</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Function Approximation for Non-Markov Processes</title>
      <link>https://arxiv.org/abs/2601.00151</link>
      <description>arXiv:2601.00151v1 Announce Type: cross 
Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00151v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara</dc:creator>
    </item>
    <item>
      <title>Unmixing highly mixed grain size distribution data via maximum volume constrained end member analysis</title>
      <link>https://arxiv.org/abs/2601.00154</link>
      <description>arXiv:2601.00154v1 Announce Type: cross 
Abstract: End member analysis (EMA) unmixes grain size distribution (GSD) data into a mixture of end members (EMs), thus helping understand sediment provenance and depositional regimes and processes. In highly mixed data sets, however, many EMA algorithms find EMs which are still a mixture of true EMs. To overcome this, we propose maximum volume constrained EMA (MVC-EMA), which finds EMs as different as possible. We provide a uniqueness theorem and a quadratic programming algorithm for MVC-EMA. Experimental results show that MVC-EMA can effectively find true EMs in highly mixed data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00154v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianqian Qi, Zhongming Chen, Peter G. M. van der Heijden</dc:creator>
    </item>
    <item>
      <title>Impact of Clustering on the Observability and Controllability of Complex Networks</title>
      <link>https://arxiv.org/abs/2601.00221</link>
      <description>arXiv:2601.00221v1 Announce Type: cross 
Abstract: The increasing complexity and interconnectedness of systems across various fields have led to a growing interest in studying complex networks, particularly Scale-Free (SF) networks, which best model real-world systems. This paper investigates the influence of clustering on the observability and controllability of complex SF networks, framing these characteristics in the context of structured systems theory. In this paper, we show that densely clustered networks require fewer driver and observer nodes due to better information propagation within clusters. This relationship is of interest for optimizing network design in applications such as social networks and intelligent transportation systems. We first quantify the network observability/controllability requirements, and then, through Monte-Carlo simulations and different case studies, we show how clustering affects these metrics. Our findings offer practical insights into reducing control and observer nodes for sensor/actuator placement, particularly in resource-constrained setups. This work contributes to the understanding of network observability/controllability and presents techniques for improving these features through alterations in network structure and clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00221v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Solar Cruiser Disturbance Torque Estimation and Predictive Momentum Management</title>
      <link>https://arxiv.org/abs/2601.00532</link>
      <description>arXiv:2601.00532v1 Announce Type: cross 
Abstract: This paper presents a novel disturbance-torque-estimation-augmented model predictive control (MPC) framework to perform momentum management on NASA's Solar Cruiser solar sail mission. Solar Cruiser represents a critical step in the advancement of large-scale solar sail technology and includes the innovative use of an active mass translator (AMT) and reflectivity control devices (RCDs) as momentum management actuators. The coupled nature of these actuators has proven challenging in the development of a robust momentum management controller. Recent literature has explored the use of MPC for solar sail momentum management with promising results, although exact knowledge of the disturbance torques acting on the solar sail was required. This paper amends this issue through the use of a Kalman filter to provide real-time estimation of unmodeled disturbance torques. Furthermore, the dynamic model used in this paper incorporates key fidelity enhancements compared to prior work, including the Solar Cruiser's four-reaction-wheel assembly and the offset between its center of mass and center of pressure. Simulation results demonstrate that the proposed policy successfully manages angular momentum growth under slew maneuvers that exceed the operational envelope of the current state-of-the-art method. The inclusion of the disturbance torque estimate is shown to greatly improve the reliability and performance of the proposed MPC approach. This work establishes a new benchmark for Solar Cruiser's momentum management capabilities and paves the way for MPC-based momentum management of other solar sails making use of an AMT and/or RCDs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00532v1</guid>
      <category>physics.space-ph</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ping-Yen Shen, Ryan J. Caverly</dc:creator>
    </item>
    <item>
      <title>Stronger Approximation Guarantees for Non-Monotone {\gamma}-Weakly DR-Submodular Maximization</title>
      <link>https://arxiv.org/abs/2601.00611</link>
      <description>arXiv:2601.00611v1 Announce Type: cross 
Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $\gamma$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $\gamma$; in particular, when $\gamma=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $\gamma&lt;1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $\gamma$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $\gamma$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $\gamma$-weakly DR-submodular maximization over down-closed convex bodies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00611v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hareshkumar Jadav, Ranveer Singh, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming</title>
      <link>https://arxiv.org/abs/2601.00780</link>
      <description>arXiv:2601.00780v1 Announce Type: cross 
Abstract: This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00780v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Kuku Fotock, Alessio Zappone, Agbotiname Lucky Imoize, Marco Di Renzo</dc:creator>
    </item>
    <item>
      <title>Second-Order Constrained Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2409.11649</link>
      <description>arXiv:2409.11649v4 Announce Type: replace 
Abstract: This paper provides an overview, analysis, and comparison of second-order dynamic optimization algorithms, i.e., constrained Differential Dynamic Programming (DDP) and Sequential Quadratic Programming (SQP). Although a variety of these algorithms have been proposed and used successfully, there exists a gap in understanding the key differences and advantages, which we aim to provide in this work. For constrained DDP, we choose methods that incorporate nonlinear programming techniques to handle state and control constraints, including Augmented Lagrangian (AL), Interior Point, Primal-Dual Augmented Lagrangian (PDAL), and Alternating Direction Method of Multipliers (ADMM). Both DDP and SQP are provided in single- and multiple-shooting formulations, where constraints that arise from dynamics are encoded implicitly and explicitly, respectively. As a byproduct of the review, we propose a single-shooting PDAL DDP that has more favorable properties than the standard AL variant, such as the robustness to the growth of penalty parameters. We perform extensive numerical experiments on a variety of systems with increasing complexity to investigate the quality of the solutions, the levels of constraint violation, and the sensitivity of final solutions with respect to initialization, as well as targets. The results show that single-shooting PDAL DDP and multiple-shooting SQP are the most robust methods. For multiple-shooting formulation, both DDP and SQP can enjoy informed initial guesses, while the latter appears to be more advantageous in complex systems. It is also worth highlighting that DDP provides favorable computational complexity and feedback gains as a byproduct of optimization as is.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11649v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuichiro Aoyama, Oswin So, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Mitigating optimistic bias in entropic risk estimation and optimization</title>
      <link>https://arxiv.org/abs/2409.19926</link>
      <description>arXiv:2409.19926v4 Announce Type: replace 
Abstract: The entropic risk measure is widely used in high-stakes decision-making across economics, management science, finance, and safety-critical control systems because it captures tail risks associated with uncertain losses. However, when data are limited, the empirical entropic risk estimator, formed by replacing the expectation in the risk measure with a sample average, underestimates true risk. We show that this negative bias grows superlinearly with the standard deviation of the loss for distributions with unbounded right tails. We further demonstrate that several existing bias reduction techniques developed for empirical risk either continue to underestimate entropic risk or substantially overestimate it, potentially leading to overly risky or overly conservative decisions. To address this issue, we develop a parametric bootstrap procedure that is strongly asymptotically consistent and provides a controlled overestimation of entropic risk under mild assumptions. The method first fits a distribution to the data and then estimates the empirical estimator's bias via bootstrapping. We show that the fitted distribution must satisfy only weak regularity conditions, and Gaussian mixture models offer a convenient and flexible choice within this class. As an application, we introduce a distributionally robust optimization model for an insurance contract design problem that incorporates correlations in household losses. We show that selecting regularization parameters using standard cross-validation can lead to substantially higher out-of-sample risk for the insurer if the validation bias is not corrected. Our approach improves performance by recommending higher and more accurate premiums, thereby better reflecting the underlying tail risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19926v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Utsav Sadana, Erick Delage, Angelos Georghiou</dc:creator>
    </item>
    <item>
      <title>Deep Learning for Energy Market Contracts: Dynkin Game with Doubly RBSDEs</title>
      <link>https://arxiv.org/abs/2503.00880</link>
      <description>arXiv:2503.00880v3 Announce Type: replace 
Abstract: We formulate a Contract for Difference (CfD) with early exit options as a two-player zero-sum Dynkin game, reflecting the strategic interaction between an electricity producer and a regulatory entity. The game incorporates penalties for early termination and mean-reverting price dynamics, with the value characterized through a doubly reflected backward stochastic differential equation (DRBSDE).
  To compute the contract value and optimal stopping strategies, we develop a neural solver that approximates the DRBSDE solution using a sequence of neural networks trained on simulated trajectories. The method avoids discretizing the state space, supports time-dependent barriers, and scales to high-dimensional settings. We establish a convergence result and test the method on two scenarios: a benchmark symmetric game in 20 dimensions, and a CfD model with 24-dimensional electricity prices representing multiple European zones.
  The results demonstrate that the proposed solver accurately captures the contract's value and optimal stopping regions, with consistent performance across dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00880v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nacira Agram, Ihsan Arharas, Giulia Pucci, Jan Rems</dc:creator>
    </item>
    <item>
      <title>First-Order Projected Algorithms With the Same Linear Convergence Rate Bounds as Their Unconstrained Counterparts</title>
      <link>https://arxiv.org/abs/2503.13965</link>
      <description>arXiv:2503.13965v4 Announce Type: replace 
Abstract: In this paper, we propose a systematic approach for extending first-order optimization algorithms, originally designed for unconstrained strongly convex problems, to handle closed and convex set constraints. We show that the resulting projected algorithms retain the same linear convergence rate bounds, provided that the underlying unconstrained optimization algorithms admit a quadratic Lyapunov function obtained from integral quadratic constraint (IQC) analysis. The projected algorithms are constructed by applying a projection in the norm induced by the Lyapunov matrix, ensuring both constraint satisfaction and optimality at the fixed point. Furthermore, under a linear transformation associated with this matrix, the projection becomes non-expansive in the Euclidean norm, allowing the use of the contraction mapping theorem to establish convergence. Our results indicate that, when analyzing worst-case convergence rates or when synthesizing first-order optimization algorithms with potentially higher-order dynamics, it suffices to focus solely on the unconstrained dynamics, since the same parameters or stepsizes can be employed without retuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13965v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Ioannis Lestas, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Superquantile-Gibbs Relaxation for Minima-selection in Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2505.05991</link>
      <description>arXiv:2505.05991v3 Announce Type: replace 
Abstract: Bilevel optimization (BLO) becomes fundamentally more challenging when the lower-level objective admits multiple minimizers. Beyond the unique-minimizer setting, two difficulties arise: (1) evaluating the hyper-objective $F_{\max}$ requires minima selection, i.e., optimizing over a potentially topologically disconnected set; (2) $F_{\max}$ can be discontinuous without structural assumptions. We show both can be circumvented under a local Polyak--Lojasiewicz (PL) condition (PL$^\circ$) on the lower-level objective. Under PL$^\circ$, $F_{\max}$ is Lipschitz continuous and, for every upper-level variable, the set of lower-level minimizers is topologically connected and a closed embedded submanifold of common intrinsic dimension $k$. This intrinsic dimension $k$, rather than the ambient one, governs BLO complexity. We give a method that finds an $(\epsilon,\rho)$-Goldstein stationary point of $F_{\max}$ with at most $\mathcal{O}(m^{8k+9}(\epsilon\rho)^{-8k-10})$ gradient-oracle queries, where $m$ is the upper-level dimension. The key is a Superquantile--Gibbs relaxation that turns minima selection into a sampling problem solvable via Langevin dynamics. To our knowledge, this is the first work to rigorously treat minima selection in BLO and quantify how its complexity scales with the intrinsic dimensionality of the lower-level problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05991v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saeed Masiha, Zebang Shen, Negar Kiyavash, Niao He</dc:creator>
    </item>
    <item>
      <title>Enhancing Accuracy in Differentially Private Distributed Optimization Through Sensitivity Reduction</title>
      <link>https://arxiv.org/abs/2505.07482</link>
      <description>arXiv:2505.07482v2 Announce Type: replace 
Abstract: In this paper, we investigate the problem of differentially private distributed optimization. Recognizing that lower sensitivity leads to higher accuracy, we analyze the key factors influencing the sensitivity of differentially private distributed algorithms. Building on these insights, we propose a novel differentially private distributed algorithm for undirected graphs that enhances optimization accuracy by reducing sensitivity. To ensure practical applicability, we derive an explicit closed-form expression for the noise parameter as a function of the privacy budget. Moreover, we rigorously prove that the proposed algorithm can achieve arbitrarily rigorous $\epsilon$-differential privacy, establish its convergence in the mean square sense, and provide an upper bound on its optimization accuracy. Finally, extensive comparisons with various privacy-preserving methods validate the effectiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07482v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Furan Xie, Bing Liu, Li Chai</dc:creator>
    </item>
    <item>
      <title>PolarGrad: A Class of Matrix-Gradient Optimizers from a Unifying Preconditioning Perspective</title>
      <link>https://arxiv.org/abs/2505.21799</link>
      <description>arXiv:2505.21799v3 Announce Type: replace 
Abstract: The ever-growing scale of deep learning models and training data underscores the critical importance of efficient optimization methods. While preconditioned gradient methods such as Adam and AdamW are the de facto optimizers for training neural networks and large language models, structure-aware preconditioned optimizers like Shampoo and Muon, which utilize the matrix structure of gradients, have demonstrated promising evidence of faster convergence. In this paper, we introduce a unifying framework for analyzing "matrix-aware" preconditioned methods, which not only sheds light on the effectiveness of Muon and related optimizers but also leads to a class of new structure-aware preconditioned methods. A key contribution of this framework is its precise distinction between preconditioning strategies that treat neural network weights as vectors (addressing curvature anisotropy) versus those that consider their matrix structure (addressing gradient anisotropy). This perspective provides new insights into several empirical phenomena in language model pre-training, including Adam's training instabilities, Muon's accelerated convergence, and the necessity of learning rate warmup for Adam. Building upon this framework, we introduce PolarGrad, a new class of preconditioned optimization methods based on the polar decomposition of matrix-valued gradients. As a special instance, PolarGrad includes Muon with updates scaled by the nuclear norm of the gradients. We provide numerical implementations of these methods, leveraging efficient numerical polar decomposition algorithms for enhanced convergence. Our extensive evaluations across diverse matrix optimization problems and language model pre-training tasks demonstrate that PolarGrad outperforms both Adam and Muon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21799v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Qi Long, Weijie Su</dc:creator>
    </item>
    <item>
      <title>Computer-aided analyses of stochastic first-order methods, via interpolation conditions for stochastic optimization</title>
      <link>https://arxiv.org/abs/2507.05466</link>
      <description>arXiv:2507.05466v5 Announce Type: replace 
Abstract: This work proposes a framework, embedded within the Performance Estimation framework (PEP), for obtaining worst-case performance guarantees on stochastic first-order methods. Given a first-order method, a function class, and a noise model with prescribed expectation and variance properties, we present a semidefinite program (SDP), whose size grows linearly with $N$, the number of iterations analyzed, and whose solution yields a convergence guarantee on the problem.
  The framework accommodates a wide range of stochastic settings, with finite or infinite support, including the unstructured noise model with bounded variance, finite-sum optimization, and block-coordinate methods, in a unified manner, as guarantees apply to any setting consistent with the noise model, i.e., its expectation and variance. It covers both non-variance-reduced and variance-reduced methods. Using the framework, we analyze the stochastic gradient method under several noise models, and illustrate how the resulting numerical and analytical convergence rates connect with existing results. In particular, we provide improved convergence rates on the unstructured noise model with bounded variance and in the block-coordinate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05466v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Rubbens, S\'ebastien Colla, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>Clique Probing for Mixed-Integer Programs</title>
      <link>https://arxiv.org/abs/2512.17551</link>
      <description>arXiv:2512.17551v2 Announce Type: replace 
Abstract: Probing is an important presolving technique in mixed-integer programming solvers. It selects binary variables, tentatively fixes them to 0 and 1, and performs propagation to deduce additional variable fixings, bound tightenings, substitutions, and implications. In this work, we propose clique probing instead of probing on individual variables, we select cliques, a set of binary variables of which at most one can be set to one, and systematically probe on all variables of a clique. Experiments with our implementation in the open-source presolve library PaPILO demonstrate that exploiting clique information in this form significantly increases the number of reductions. When integrated into the MIP solver SCIP, we observe a 3% performance improvement on MIPLIB instances containing cliques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17551v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob von Holly-Ponientzietz, Alexander Hoen, Mark Turner, Ambros Gleixner</dc:creator>
    </item>
    <item>
      <title>Stochastic dual coordinate descent with adaptive heavy ball momentum for linearly constrained convex optimization</title>
      <link>https://arxiv.org/abs/2307.16702</link>
      <description>arXiv:2307.16702v4 Announce Type: replace-cross 
Abstract: The problem of finding a solution to the linear system $Ax = b$ with certain minimization properties arises in numerous scientific and engineering areas. In the era of big data, the stochastic optimization algorithms become increasingly significant due to their scalability for problems of unprecedented size. This paper focuses on the problem of minimizing a strongly convex function subject to linear constraints. We consider the dual formulation of this problem and adopt the stochastic coordinate descent to solve it. The proposed algorithmic framework, called adaptive stochastic dual coordinate descent, utilizes sampling matrices sampled from user-defined distributions to extract gradient information. Moreover, it employs Polyak's heavy ball momentum acceleration with adaptive parameters learned through iterations, overcoming the limitation of the heavy ball momentum method that it requires prior knowledge of certain parameters, such as the singular values of a matrix. With these extensions, the framework is able to recover many well-known methods in the context, including the randomized sparse Kaczmarz method, the randomized regularized Kaczmarz method, the linearized Bregman iteration, and a variant of the conjugate gradient (CG) method. Additionally, we introduce an equivalent formulation that, in certain cases, substantially reduces the need for full-dimensional vector operations introduced by the momentum term. We prove that, with strongly admissible objective function, the proposed method converges linearly in expectation. Numerical experiments are provided to confirm our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16702v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Zeng, Deren Han, Yansheng Su, Jiaxin Xie</dc:creator>
    </item>
    <item>
      <title>Tannenbaum's gain-margin optimization meets Polyak's heavy-ball algorithm</title>
      <link>https://arxiv.org/abs/2409.19882</link>
      <description>arXiv:2409.19882v3 Announce Type: replace-cross 
Abstract: This paper highlights an apparent, yet relatively unknown link between algorithm design in optimization theory and controller synthesis in robust control. Specifically, quadratic optimization can be recast as a regulation problem within the framework of $\mathcal{H}_\infty$ control. From this vantage point, the optimality of Polyak's fastest heavy-ball algorithm can be ascertained as a solution to a gain margin optimization problem. The approach is independent of Polyak's original and brilliant argument, and relies on foundational work by Tannenbaum, who introduced and solved gain margin optimization via Nevanlinna--Pick interpolation theory. The link between first-order optimization methods and robust control sheds new light on the limits of algorithmic performance of such methods, and suggests a framework where similar computational tasks can be systematically studied and algorithms optimized. In particular, it raises the question as to whether periodically scheduled algorithms can achieve faster rates for quadratic optimization, in a manner analogous to periodic control that extends the gain margin beyond that of time-invariant control. This turns out not to be the case, due to the analytic obstruction of a transmission zero that is inherent in causal schemes. Interestingly, this obstruction can be removed with implicit algorithms, cast as feedback regulation problems with causal, but not strictly causal dynamics, thereby devoid of the transmission zero at infinity and able to achieve superior convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19882v3</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuwei Wu, Jie Chen, Mihailo R. Jovanovi\'c, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Sampled-data Systems: Stability, Contractivity and Single-iteration Suboptimal MPC</title>
      <link>https://arxiv.org/abs/2505.18336</link>
      <description>arXiv:2505.18336v3 Announce Type: replace-cross 
Abstract: This paper analyzes the stability of interconnected continuous-time (CT) and discrete-time (DT) systems coupled through sampling and zero-order hold mechanisms. The DT system updates its output at regular intervals $T&gt;0$ by applying an $n$-fold composition of a given map. This setup is motivated by online and sampled-data implementations of optimization-based controllers - particularly model predictive control (MPC) - where the DT system models $n$ iterations of an algorithm approximating the solution of an optimization problem.
  We introduce the concept of a reduced model, defined as the limiting behavior of the sampled-data system as $T \to 0^+$ and $n \to +\infty$. Our main theoretical contribution establishes that when the reduced model is contractive, there exists a threshold duration $T(n)$ for each iteration count $n$ such that the CT-DT interconnection achieves exponential stability for all sampling periods $T &lt; T(n)$. Finally, under the stronger condition that both the CT and DT systems are contractive, we show exponential stability of their interconnection using a small-gain argument. Our theoretical results provide new insights into suboptimal MPC stability, showing that convergence guarantees hold even when using a single iteration of the optimization algorithm - a practically significant finding for real-time control applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18336v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiting Chen, Francesco Bullo, Emiliano Dall'Anese</dc:creator>
    </item>
    <item>
      <title>Classical and Quantum Heuristics for the Binary Paint Shop Problem</title>
      <link>https://arxiv.org/abs/2509.15294</link>
      <description>arXiv:2509.15294v2 Announce Type: replace-cross 
Abstract: The Binary Paint Shop Problem (BPSP) is an $\mathsf{APX}$-hard optimisation problem in automotive manufacturing: given a sequence of $2n$ cars, comprising $n$ distinct models each appearing twice, the task is to decide which of two colours to paint each car so that the two occurrences of each model are painted differently, while minimising consecutive colour swaps. The key performance metric is the paint swap ratio, the average number of colour changes per car, which directly impacts production efficiency and cost. Prior work showed that the Quantum Approximate Optimisation Algorithm (QAOA) at depth $p=7$ achieves a paint swap ratio of $0.393$, outperforming the classical Recursive Greedy (RG) heuristic with an expected ratio of $0.4$ [Phys. Rev. A 104, 012403 (2021)]. More recently, the classical Recursive Star Greedy (RSG) heuristic was conjectured to achieve an expected ratio of $0.361$. In this study, we develop the theoretical foundations for applying QAOA to BPSP through a reduction of BPSP to weighted MaxCut, and use this framework to benchmark two state-of-the-art low-depth QAOA variants, eXpressive QAOA (XQAOA) and Recursive QAOA (RQAOA), at $p=1$ (denoted XQAOA$_1$ and RQAOA$_1$), against the strongest classical heuristics known to date. Across instances ranging from $2^7$ to $2^{12}$ cars, XQAOA$_1$ achieves an average ratio of $0.357$, surpassing RQAOA$_1$ and all classical heuristics, including the conjectured performance of RSG. Surprisingly, RQAOA$_1$ shows diminishing performance as size increases: despite using provably optimal QAOA$_1$ parameters at each recursion, it is outperformed by RSG on most $2^{11}$-car instances and all $2^{12}$-car instances. To our knowledge, this is the first study to report RQAOA$_1$'s performance degradation at scale. In contrast, XQAOA$_1$ remains robust, indicating strong potential to asymptotically surpass all known heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15294v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V Vijendran, Dax Enshan Koh, Ping Koy Lam, Syed M Assad</dc:creator>
    </item>
    <item>
      <title>A reconstructed discontinuous approximation for distributed elliptic control problems</title>
      <link>https://arxiv.org/abs/2512.08353</link>
      <description>arXiv:2512.08353v2 Announce Type: replace-cross 
Abstract: In this paper, we present and analyze an interior penalty discontinuous Galerkin method for the distributed elliptic optimal control problems. It is based on a reconstructed discontinuous approximation which admits arbitrarily high-order approximation space with only one unknown per element. Applying this method, we develop a proper discretization scheme that approximates the state and adjoint variables in the approximation space. Our main contributions are twofold: (1) the derivation of both a priori and a posteriori error estimates of the $L^2$-norm and the energy norms, and (2) the implementation of an efficiently solvable discrete system, which is solved via a linearly convergent projected gradient descent method. Numerical experiments are provided to verify the convergence order in a priori error estimate and the efficiency of a posteriori error estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08353v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ruo Li, Haoyang Liu, Jun Yin</dc:creator>
    </item>
    <item>
      <title>Iterative Tuning of Nonlinear Model Predictive Control for Robotic Manufacturing Tasks</title>
      <link>https://arxiv.org/abs/2512.13170</link>
      <description>arXiv:2512.13170v2 Announce Type: replace-cross 
Abstract: Manufacturing processes are often perturbed by drifts in the environment and wear in the system, requiring control re-tuning even in the presence of repetitive operations. This paper presents an iterative learning framework for automatic tuning of Nonlinear Model Predictive Control (NMPC) weighting matrices based on task-level performance feedback. Inspired by norm-optimal Iterative Learning Control (ILC), the proposed method adaptively adjusts NMPC weights Q and R across task repetitions to minimize key performance indicators (KPIs) related to tracking accuracy, control effort, and saturation. Unlike gradient-based approaches that require differentiating through the NMPC solver, we construct an empirical sensitivity matrix, enabling structured weight updates without analytic derivatives. The framework is validated through simulation on a UR10e robot performing carbon fiber winding on a tetrahedral core. Results demonstrate that the proposed approach converges to near-optimal tracking performance (RMSE within 0.3% of offline Bayesian Optimization (BO)) in just 4 online repetitions, compared to 100 offline evaluations required by BO algorithm. The method offers a practical solution for adaptive NMPC tuning in repetitive robotic tasks, combining the precision of carefully optimized controllers with the flexibility of online adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13170v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Deepak Ingole, Valentin Bhend, Shiva Ganesh Murali, Oliver Dobrich, Alisa Rupenyan</dc:creator>
    </item>
    <item>
      <title>Dynamic response phenotypes and model discrimination in systems and synthetic biology</title>
      <link>https://arxiv.org/abs/2512.24945</link>
      <description>arXiv:2512.24945v2 Announce Type: replace-cross 
Abstract: Biological systems encode function not primarily in steady states, but in the structure of transient responses elicited by time-varying stimuli. Overshoots, biphasic dynamics, adaptation kinetics, fold-change detection, entrainment, and cumulative exposure effects often determine phenotypic outcomes, yet are poorly captured by classical steady-state or dose-response analyses. This paper develops an input-output perspective on such "dynamic phenotypes," emphasizing how qualitative features of transient behavior constrain underlying network architectures independently of detailed parameter values. A central theme is the role of sign structure and interconnection logic, particularly the contrast between monotone systems and architectures containing antagonistic pathways. We show how incoherent feedforward (IFF) motifs provide a simple and recurrent mechanism for generating non-monotonic and adaptive responses across multiple levels of biological organization, from molecular signaling to immune regulation and population dynamics. Conversely, monotonicity imposes sharp impossibility results that can be used to falsify entire classes of models from transient data alone. Beyond step inputs, we highlight how periodic forcing, ramps, and integral-type readouts such as cumulative dose responses offer powerful experimental probes that reveal otherwise hidden structure, separate competing motifs, and expose invariances such as fold-change detection. Throughout, we illustrate how control-theoretic concepts, including monotonicity, equivariance, and input-output analysis, can be used not as engineering metaphors, but as precise mathematical tools for biological model discrimination. Thus we argue for a shift in emphasis from asymptotic behavior to transient and input-driven dynamics as a primary lens for understanding, testing, and reverse-engineering biological networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24945v2</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo D. Sontag</dc:creator>
    </item>
  </channel>
</rss>
