<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 02:22:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Ransomware Negotiation: Dynamics and Privacy-Preserving Mechanism Design</title>
      <link>https://arxiv.org/abs/2508.15844</link>
      <description>arXiv:2508.15844v1 Announce Type: new 
Abstract: Ransomware attacks have become a pervasive and costly form of cybercrime, causing tens of millions of dollars in losses as organizations increasingly pay ransoms to mitigate operational disruptions and financial risks. While prior research has largely focused on proactive defenses, the post-infection negotiation dynamics between attackers and victims remains underexplored. This paper presents a formal analysis of attacker-victim interactions in modern ransomware incidents using a finite-horizon alternating-offers bargaining game model. Our analysis demonstrates how bargaining alters the optimal strategies of both parties. In practice, incomplete information-attackers lacking knowledge of victims' data valuations and victims lacking knowledge of attackers' reservation ransoms-can prolong negotiations and increase victims' business interruption costs. To address this, we design a Bayesian incentive-compatible mechanism that facilitates rapid agreement on a fair ransom without requiring either party to disclose private valuations. We further implement this mechanism using secure two-party computation based on garbled circuits, thereby eliminating the need for trusted intermediaries and preserving the privacy of both parties throughout the negotiation. To the best of our knowledge, this is the first automated, privacy-preserving negotiation mechanism grounded in a formal analysis of ransomware negotiation dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15844v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haohui Zhang, Sirui Shen, Xinyu Hu, Chenglu Jin</dc:creator>
    </item>
    <item>
      <title>Data Auctions for Retrieval Augmented Generation</title>
      <link>https://arxiv.org/abs/2508.16007</link>
      <description>arXiv:2508.16007v1 Announce Type: new 
Abstract: We study the problem of data selling for Retrieval Augmented Generation (RAG) tasks in Generative AI applications. We model each buyer's valuation of a dataset with a natural coverage-based valuation function that increases with the inclusion of more relevant data points that would enhance responses to anticipated queries. Motivated by issues such as data control and prior-free revenue maximization, we focus on the scenario where each data point can be allocated to only one buyer. We show that the problem of welfare maximization in this setting is NP-hard even with two bidders, but design a polynomial-time $(1-1/e)$ approximation algorithm for any number of bidders. Unfortunately, however, this efficient allocation algorithm fails to be incentive compatible. The crux of our approach is a carefully tailored post-processing step called \emph{data burning} which retains the $(1-1/e)$ approximation factor but achieves incentive compatibility. Our thorough experiments on synthetic and real-world image and text datasets demonstrate the practical effectiveness of our algorithm compared to popular baseline algorithms for combinatorial auctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16007v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minbiao Han, Seyed A. Esmaeili, Michael Albert, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Proportional Representation in Rank Aggregation</title>
      <link>https://arxiv.org/abs/2508.16177</link>
      <description>arXiv:2508.16177v1 Announce Type: new 
Abstract: In rank aggregation, the task is to aggregate multiple weighted input rankings into a single output ranking. While numerous methods, so-called social welfare functions (SWFs), have been suggested for this problem, all of the classical SWFs tend to be majoritarian and are thus not acceptable when a proportional ranking is required. Motivated by this observation, we will design SWFs that guarantee that every input ranking is proportionally represented by the output ranking. Specifically, our central fairness condition requires that the number of pairwise comparisons between candidates on which an input ranking and the output ranking agree is proportional to the weight of the input ranking. As our main contribution, we present a simple SWF called the Proportional Sequential Borda rule, which satisfies this condition. Moreover, we introduce two variants of this rule: the Ranked Method of Equal Shares, which has a more utilitarian flavor while still satisfying our fairness condition, and the Flow-adjusting Borda rule, which satisfies an even stronger fairness condition. Many of our axioms and techniques are inspired by results on approval-based committee voting and participatory budgeting, where the concept of proportional representation has been studied in depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16177v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Lederer</dc:creator>
    </item>
    <item>
      <title>Strategyproof Randomized Social Choice for Restricted Sets of Utility Functions</title>
      <link>https://arxiv.org/abs/2508.16195</link>
      <description>arXiv:2508.16195v1 Announce Type: new 
Abstract: Social decision schemes (SDSs) map the voters' preferences over multiple alternatives to a probability distribution over these alternatives. In a seminal result, Gibbard (1977) has characterized the set of SDSs that are strategyproof with respect to all utility functions and his result implies that all such SDSs are either unfair to the voters or alternatives, or they require a significant amount of randomization. To circumvent this negative result, we propose the notion of $U$-strategyproofness which postulates that only voters with a utility function in a predefined set $U$ cannot manipulate. We then analyze the tradeoff between $U$-strategyproofness and various decisiveness notions that restrict the amount of randomization of SDSs. In particular, we show that if the utility functions in the set $U$ value the best alternative much more than other alternatives, there are $U$-strategyproof SDSs that choose an alternative with probability $1$ whenever all but $k$ voters rank it first. On the negative side, we demonstrate that $U$-strategyproofness is incompatible with Condorcet-consistency if the set $U$ satisfies minimal symmetry conditions. Finally, we show that no ex post efficient and $U$-strategyproof SDS can be significantly more decisive than the uniform random dictatorship if the voters are close to indifferent between their two favorite alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16195v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Lederer</dc:creator>
    </item>
    <item>
      <title>Limit-Computable Grains of Truth for Arbitrary Computable Extensive-Form (Un)Known Games</title>
      <link>https://arxiv.org/abs/2508.16245</link>
      <description>arXiv:2508.16245v1 Announce Type: new 
Abstract: A Bayesian player acting in an infinite multi-player game learns to predict the other players' strategies if his prior assigns positive probability to their play (or contains a grain of truth). Kalai and Lehrer's classic grain of truth problem is to find a reasonably large class of strategies that contains the Bayes-optimal policies with respect to this class, allowing mutually-consistent beliefs about strategy choice that obey the rules of Bayesian inference. Only small classes are known to have a grain of truth and the literature contains several related impossibility results. In this paper we present a formal and general solution to the full grain of truth problem: we construct a class of strategies wide enough to contain all computable strategies as well as Bayes-optimal strategies for every reasonable prior over the class. When the "environment" is a known repeated stage game, we show convergence in the sense of [KL93a] and [KL93b]. When the environment is unknown, agents using Thompson sampling converge to play $\varepsilon$-Nash equilibria in arbitrary unknown computable multi-agent environments. Finally, we include an application to self-predictive policies that avoid planning. While these results use computability theory only as a conceptual tool to solve a classic game theory problem, we show that our solution can naturally be computationally approximated arbitrarily closely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16245v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cole Wyeth, Marcus Hutter, Jan Leike, Jessica Taylor</dc:creator>
    </item>
    <item>
      <title>A QoE-Driven Personalized Incentive Mechanism Design for AIGC Services in Resource-Constrained Edge Networks</title>
      <link>https://arxiv.org/abs/2508.16251</link>
      <description>arXiv:2508.16251v1 Announce Type: new 
Abstract: With rapid advancements in large language models (LLMs), AI-generated content (AIGC) has emerged as a key driver of technological innovation and economic transformation. Personalizing AIGC services to meet individual user demands is essential but challenging for AIGC service providers (ASPs) due to the subjective and complex demands of mobile users (MUs), as well as the computational and communication resource constraints faced by ASPs. To tackle these challenges, we first develop a novel multi-dimensional quality-of-experience (QoE) metric. This metric comprehensively evaluates AIGC services by integrating accuracy, token count, and timeliness. We focus on a mobile edge computing (MEC)-enabled AIGC network, consisting of multiple ASPs deploying differentiated AIGC models on edge servers and multiple MUs with heterogeneous QoE requirements requesting AIGC services from ASPs. To incentivize ASPs to provide personalized AIGC services under MEC resource constraints, we propose a QoE-driven incentive mechanism. We formulate the problem as an equilibrium problem with equilibrium constraints (EPEC), where MUs as leaders determine rewards, while ASPs as followers optimize resource allocation. To solve this, we develop a dual-perturbation reward optimization algorithm, reducing the implementation complexity of adaptive pricing. Experimental results demonstrate that our proposed mechanism achieves a reduction of approximately $64.9\%$ in average computational and communication overhead, while the average service cost for MUs and the resource consumption of ASPs decrease by $66.5\%$ and $76.8\%$, respectively, compared to state-of-the-art benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16251v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjia Wu, Minrui Xu, Zehui Xiong, Lin Gao, Haoyuan Pan, Dusit Niyato, Tse-Tin Chan</dc:creator>
    </item>
    <item>
      <title>A Social Choice Analysis of Optimism's Retroactive Project Funding</title>
      <link>https://arxiv.org/abs/2508.16285</link>
      <description>arXiv:2508.16285v1 Announce Type: new 
Abstract: The Optimism Retroactive Project Funding (RetroPGF) is a key initiative within the blockchain ecosystem that retroactively rewards projects deemed valuable to the Ethereum and Optimism communities. Managed by the Optimism Collective, a decentralized autonomous organization (DAO), RetroPGF represents a large-scale experiment in decentralized governance. Funding rewards are distributed in OP tokens, the native digital currency of the ecosystem. As of this writing, four funding rounds have been completed, collectively allocating over 100M dollars, with an additional 1.3B dollars reserved for future rounds. However, we identify significant shortcomings in the current allocation system, underscoring the need for improved governance mechanisms given the scale of funds involved.
  Leveraging computational social choice techniques and insights from multiagent systems, we propose improvements to the voting process by recommending the adoption of a utilitarian moving phantoms mechanism. This mechanism, originally introduced by Freeman et al. in 2019, is designed to enhance social welfare (using the L1 norm) while satisfying strategyproofness -- two key properties aligned with the application's governance requirements. Our analysis provides a formal framework for designing improved funding mechanisms for DAOs, contributing to the broader discourse on decentralized governance and public goods allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16285v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eyal Briman, Nimrod Talmon, Angela Kreitenweis, Muhammad Idrees</dc:creator>
    </item>
    <item>
      <title>Safeguarding ISAC Performance in Low-Altitude Wireless Networks Under Channel Access Attack</title>
      <link>https://arxiv.org/abs/2508.15838</link>
      <description>arXiv:2508.15838v1 Announce Type: cross 
Abstract: The increasing saturation of terrestrial resources has driven the exploration of low-altitude applications such as air taxis. Low altitude wireless networks (LAWNs) serve as the foundation for these applications, and integrated sensing and communication (ISAC) constitutes one of the core technologies within LAWNs. However, the openness nature of low-altitude airspace makes LAWNs vulnerable to malicious channel access attacks, which degrade the ISAC performance. Therefore, this paper develops a game-based framework to mitigate the influence of the attacks on LAWNs. Concretely, we first derive expressions of communication data's signal-to-interference-plus-noise ratio and the age of information of sensing data under attack conditions, which serve as quality of service metrics. Then, we formulate the ISAC performance optimization problem as a Stackelberg game, where the attacker acts as the leader, and the legitimate drone and the ground ISAC base station act as second and first followers, respectively. On this basis, we design a backward induction algorithm that achieves the Stackelberg equilibrium while maximizing the utilities of all participants, thereby mitigating the attack-induced degradation of ISAC performance in LAWNs. We further prove the existence and uniqueness of the equilibrium. Simulation results show that the proposed algorithm outperforms existing baselines and a static Nash equilibrium benchmark, ensuring that LAWNs can provide reliable service for low-altitude applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15838v1</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiacheng Wang, Jialing He, Geng Sun, Zehui Xiong, Dusit Niyato, Shiwen Mao, Dong In Kim, Tao Xiang</dc:creator>
    </item>
    <item>
      <title>A Bayesian framework for opinion dynamics models</title>
      <link>https://arxiv.org/abs/2508.16539</link>
      <description>arXiv:2508.16539v1 Announce Type: cross 
Abstract: This work introduces a Bayesian framework that unifies a wide class of opinion dynamics models. In this framework, an individual's opinion on a topic is the expected value of their belief, represented as a random variable with a prior distribution. Upon receiving a signal, modeled as the prior belief plus a bias term and subject to zero-mean noise with a known distribution, the individual updates their belief distribution via Bayes' rule. By systematically varying the prior, bias, and noise distributions, this approach recovers a broad array of opinion dynamics models, including DeGroot, bounded confidence, bounded shift, and models exhibiting overreaction or backfire effects. Our analysis shows that the signal score is the key determinant of each model's mathematical structure, governing both small- and large-signal behavior. All models converge to DeGroot's linear update rule for small signals, but diverge in their tail behavior for large signals. This unification not only reveals theoretical linkages among previously disconnected models but also provides a systematic method for generating new ones, offering insights into the rational foundations of opinion formation under cognitive constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16539v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yen-Shao Chen, Tauhid Zaman</dc:creator>
    </item>
    <item>
      <title>Asymmetries of Service: Interdependence and Synchronicity</title>
      <link>https://arxiv.org/abs/2402.15533</link>
      <description>arXiv:2402.15533v3 Announce Type: replace 
Abstract: On many dimensions, services can be seen to exist along spectra measuring the degree of interaction between customer and agent. For instance, every interaction features some number of contributions by each of those two sides, creating a spectrum of interdependence. Additionally, each interaction is further characterized by the relative pacing of these contributions, implying a spectrum of synchronicity. Where a service falls on such spectra can be a consequence of its design, but it can also be a function of its state. For instance, as broadly evidenced empirically, an agent with several concurrent interactions will be slowed in each individual interaction, altering the service's synchronicity. Here, we study a Hawkes cluster model of the service interaction, which we show captures the interdependence and synchronicity spectra and their resulting customer-agent (a)symmetries. We find insightful connections to behavioral operations, such as proving the occurrence of non-monotonic performance (e.g., inverted-U throughput) from concurrency-driven asynchrony. Hence, we can prescribe the agent's optimal concurrency level. Furthermore, we show how the service design dictates the efficacy of these operational improvements, proving that the concurrency-optimized throughput is itself non-monotonic as a function of the interdependence. Of possible independent interest methodologically, we establish an interpretable temporal decomposition for Hawkes clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15533v3</guid>
      <category>cs.GT</category>
      <category>cs.PF</category>
      <category>math.PR</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Daw, Galit B. Yom-Tov</dc:creator>
    </item>
    <item>
      <title>Static Pricing for Single Sample Multi-unit Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2409.07719</link>
      <description>arXiv:2409.07719v2 Announce Type: replace 
Abstract: In this paper, we study $k$-unit single sample prophet inequalities. A seller has $k$ identical, indivisible items to sell. A sequence of buyers arrive one-by-one, with each buyer's private value for the item, $X_i$, revealed to the seller when they arrive. While the seller is unaware of the distribution from which $X_i$ is drawn, they have access to a single sample, $Y_i$ drawn from the same distribution as $X_i$. What strategies can the seller adopt for selling items so as to maximize social welfare?
  Previous work has demonstrated that when $k = 1$, if the seller sets a price equal to the maximum of the samples, they can achieve a competitive ratio of $\frac{1}{2}$ of the social welfare, and recently Pashkovich and Sayutina established an analogous result for $k = 2$. In this paper, we prove that for $k \geq 3$, setting a (static) price equal to the $k^{\text{th}}$ largest sample also obtains a competitive ratio of $\frac{1}{2}$, resolving a conjecture Pashkovich and Sayutina pose.
  We also consider the situation where $k$ is large. We demonstrate that setting a price equal to the $(k-\sqrt{2k\log k})^{\text{th}}$ largest sample obtains a competitive ratio of $1 - \sqrt{\frac{2\log k}{k}} - o\left(\sqrt{\frac{\log k}{k}}\right)$, and that this is the optimal possible ratio achievable with a static pricing scheme with access to a single sample. This should be compared against a competitive ratio $1 - \sqrt{\frac{\log k}{k}} - o\left(\sqrt{\frac{\log k}{k}}\right)$, which is the optimal possible ratio achievable with a static pricing scheme with knowledge of the distributions of the values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07719v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pranav Nuti, Peter Westbrook</dc:creator>
    </item>
    <item>
      <title>The Role of Prescreening in Auctions with Predictions</title>
      <link>https://arxiv.org/abs/2502.12117</link>
      <description>arXiv:2502.12117v3 Announce Type: replace 
Abstract: Sellers often prescreen potential bidders, restricting participation to a select group of capable participants. Recent advances in machine learning and generative AI make this strategy increasingly viable by enabling the cost-effective identification of high-quality bidders. However, the practice departs from classic auction theory, which usually favors broad competition over selective exclusion. In this paper, we examine whether and under what conditions bidder prescreening can be justified. We analyze a setting in which bidders have independent and identically distributed private valuations, and the seller observes noisy signals generated by a valuation predictor. The seller determines how many top bidders to admit and, after receiving signals, selects exactly that many with the highest signal-based rankings. We demonstrate that an auction with prescreening is equivalent to a standard auction (i.e., without prescreening) but with correlated valuations. Our analysis shows that, although admitting fewer bidders leads to revenue losses in both second-price and first-price auctions, a more accurate predictor can mitigate or even fully offset these losses. In contrast, prescreening can significantly boost revenue in all-pay auctions; notably, when the predictor is perfect, admitting only two bidders is optimal. All results remain valid in the presence of reserve prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12117v3</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanwei Sun, Fupeng Sun, Chiwei Yan, Jiahua Wu</dc:creator>
    </item>
    <item>
      <title>An $O(\log \log n)$-approximate budget feasible mechanism for subadditive valuations</title>
      <link>https://arxiv.org/abs/2506.04665</link>
      <description>arXiv:2506.04665v4 Announce Type: replace 
Abstract: In budget-feasible mechanism design, there is a set of items $U$, each owned by a distinct seller. The seller of item $e$ incurs a private cost $\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of items from the sellers of maximum value, where the value of a set $S\subseteq U$ of items is given by a valuation function $v:2^U\to \mathbb{R}_+$. The buyer has a budget of $B \in \mathbb{R}_+$ for the total payments made to the sellers. We wish to design a mechanism that is truthful, that is, sellers are incentivized to report their true costs, budget-feasible, that is, the sum of the payments made to the sellers is at most the budget $B$, and that outputs a set whose value is large compared to $\text{OPT}:=\max\{v(S):\overline{c}(S)\le B,S\subseteq U\}$.
  Budget-feasible mechanism design has been extensively studied, with the literature focussing on (classes of) subadditive valuation functions, and various polytime, budget-feasible mechanisms, achieving constant-factor approximation, have been devised for the special cases of additive, submodular, and XOS valuations. However, for general subadditive valuations, the best-known approximation factor achievable by a polytime budget-feasible mechanism (given access to demand oracles) was only $O(\log n / \log \log n)$, where $n$ is the number of items.
  We improve this state-of-the-art significantly by designing a randomized budget-feasible mechanism for subadditive valuations that achieves a substantially-improved approximation factor of $O(\log\log n)$ and runs in polynomial time, given access to demand oracles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04665v4</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rian Neogi, Kanstantsin Pashkovich, Chaitanya Swamy</dc:creator>
    </item>
  </channel>
</rss>
