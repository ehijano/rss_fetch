<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Nov 2025 05:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Complexity of Stackelberg Pricing Games</title>
      <link>https://arxiv.org/abs/2511.05700</link>
      <description>arXiv:2511.05700v1 Announce Type: new 
Abstract: We consider Stackelberg pricing games, which are also known as bilevel pricing problems, or combinatorial price-setting problems. This family of problems consists of games between two players: the leader and the follower. There is a market that is partitioned into two parts: the part of the leader and the part of the leader's competitors. The leader controls one part of the market and can freely set the prices for products. By contrast, the prices of the competitors' products are fixed and known in advance. The follower, then, needs to solve a combinatorial optimization problem in order to satisfy their own demands, while comparing the leader's offers to the offers of the competitors. Therefore, the leader has to hit the intricate balance of making an attractive offer to the follower, while at the same time ensuring that their own profit is maximized.
  Pferschy, Nicosia, Pacifici, and Schauer considered the Stackelberg pricing game where the follower solves a knapsack problem. They raised the question whether this problem is complete for the second level of the polynomial hierarchy, i.e., $\Sigma^p_2$-complete. The same conjecture was also made by B\"ohnlein, Schaudt, and Schauer. In this paper, we positively settle this conjecture. Moreover, we show that this result holds actually in a much broader context: The Stackelberg pricing game is $\Sigma^p_2$-complete for over 50 NP-complete problems, including most classics such as TSP, vertex cover, clique, subset sum, etc. This result falls in line of recent meta-theorems about higher complexity in the polynomial hierarchy by Gr\"une and Wulf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05700v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Gr\"une, Dorothee Henke, Eva Rotenberg, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>Fair Allocation of Indivisible Goods with Variable Groups</title>
      <link>https://arxiv.org/abs/2511.06218</link>
      <description>arXiv:2511.06218v1 Announce Type: new 
Abstract: We study the fair allocation of indivisible goods with variable groups. In this model, the goal is to partition the agents into groups of given sizes and allocate the goods to the groups in a fair manner. We show that for any number of groups and corresponding sizes, there always exists an envy-free up to one good (EF1) outcome, thereby generalizing an important result from the individual setting. Our result holds for arbitrary monotonic utilities and comes with an efficient algorithm. We also prove that an EF1 outcome is guaranteed to exist even when the goods lie on a path and each group must receive a connected bundle. In addition, we consider a probabilistic model where the utilities are additive and drawn randomly from a distribution. We show that if there are $n$ agents, the number of goods $m$ is divisible by the number of groups $k$, and all groups have the same size, then an envy-free outcome exists with high probability if $m = \omega(\log n)$, and this bound is tight. On the other hand, if $m$ is not divisible by $k$, then an envy-free outcome is unlikely to exist as long as $m = o(\sqrt{n})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06218v1</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul G\"olz, Ayumi Igarashi, Pasin Manurangsi, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling</title>
      <link>https://arxiv.org/abs/2511.06260</link>
      <description>arXiv:2511.06260v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models. Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler. Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics. To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions. Each day, the LLM reviews the travel experience and flags routes with positive reinforcement that they hope to use more often, and an interpretable update rule then converts this judgment into strategy adjustments using a tunable (progressively decaying) step size. The representative-agent design improves scalability, while the separation of reasoning from updating clarifies the decision logic while stabilizing learning. In classic traffic assignment settings, we find that the proposed approach converges rapidly to the user equilibrium. In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06260v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanlin Sun, Jiayang Li</dc:creator>
    </item>
    <item>
      <title>Colonel Blotto with Battlefield Games</title>
      <link>https://arxiv.org/abs/2511.06518</link>
      <description>arXiv:2511.06518v1 Announce Type: new 
Abstract: We study a class of two-player zero-sum Colonel Blotto games in which, after allocating soldiers across battlefields, players engage in (possibly distinct) normal-form games on each battlefield. Per-battlefield payoffs are parameterized by the soldier allocations. This generalizes the classical Blotto setting, where outcomes depend only on relative soldier allocations. We consider both discrete and continuous allocation models and examine two types of aggregate objectives: linear aggregation and worst-case battlefield value. For each setting, we analyze the existence and computability of Nash equilibrium. The general problem is not convex-concave, which limits the applicability of standard convex optimization techniques. However, we show that in several settings it is possible to reformulate the strategy space in a way where convex-concave structure is recovered. We evaluate the proposed methods on synthetic and real-world instances inspired by security applications, suggesting that our approaches scale well in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06518v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salam Afiouni, Jakub Cerny, Chun Kai Ling, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>GenAI vs. Human Creators: Procurement Mechanism Design in Two-/Three-Layer Markets</title>
      <link>https://arxiv.org/abs/2511.06559</link>
      <description>arXiv:2511.06559v1 Announce Type: new 
Abstract: With the rapid advancement of generative AI (GenAI), mechanism design adapted to its unique characteristics poses new theoretical and practical challenges. Unlike traditional goods, content from one domain can enhance the training and performance of GenAI models in other domains. For example, OpenAI's video generation model Sora (Liu et al., 2024b) relies heavily on image data to improve video generation quality. In this work, we study nonlinear procurement mechanism design under data transferability, where online platforms employ both human creators and GenAI to satisfy cross-domain content demand. We propose optimal mechanisms that maximize either platform revenue or social welfare and identify the specific properties of GenAI that make such high-dimensional design problems tractable. Our analysis further reveals which domains face stronger competitive pressure and which tend to experience overproduction. Moreover, the growing role of data intermediaries, including labeling companies such as Scale AI and creator organizations such as The Wall Street Journal, introduces a third layer into the traditional platform-creator structure. We show that this three-layer market can result in a lose-lose outcome, reducing both platform revenue and social welfare, as large pre-signed contracts distort creators' incentives and lead to inefficiencies in the data market. These findings suggest a need for government regulation of the GenAI data ecosystem, and our theoretical insights are further supported by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06559v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Ai, David Simchi-Levi, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Transforming Strategic Games into Biform Games: Applications in Allocation Mechanisms and Green Technology Investment</title>
      <link>https://arxiv.org/abs/2511.06858</link>
      <description>arXiv:2511.06858v1 Announce Type: new 
Abstract: As Aumann stated, cooperation and non-cooperation are different ways of viewing the same game, with the main difference being whether players can reach a binding cooperative agreement. In the real world, many games often coexist competition and cooperation. Based on the above reasons, we propose a method to transform strategic games into a biform game model, which retains the characteristics of cooperative games while considering the ultimate goal of players to maximize their own interests. Furthermore, based on this biform game model, we analyze the impact of two different distribution methods, namely marginalism and egalitarianism, on the game results. As an application, we analyze how food producers seek maximum profits through cooperative pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06858v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang Shuwen, Luo Enquan, Yang Yanlong</dc:creator>
    </item>
    <item>
      <title>Sequential Causal Normal Form Games: Theory, Computation, and Strategic Signaling</title>
      <link>https://arxiv.org/abs/2511.06934</link>
      <description>arXiv:2511.06934v1 Announce Type: new 
Abstract: Can classical game-theoretic frameworks be extended to capture the bounded rationality and causal reasoning of AI agents? We investigate this question by extending Causal Normal Form Games (CNFGs) to sequential settings, introducing Sequential Causal Multi-Agent Systems (S-CMAS) that incorporate Pearl's Causal Hierarchy across leader-follower interactions. While theoretically elegant -- we prove PSPACE-completeness, develop equilibrium refinements, and establish connections to signaling theory -- our comprehensive empirical investigation reveals a critical limitation: S-CNE provides zero welfare improvement over classical Stackelberg equilibrium across all tested scenarios. Through 50+ Monte Carlo simulations and hand-crafted synthetic examples, we demonstrate that backward induction with rational best-response eliminates any strategic advantage from causal layer distinctions. We construct a theoretical example illustrating conditions where benefits could emerge ($\epsilon$-rational satisficing followers), though implementation confirms that even relaxed rationality assumptions prove insufficient when good instincts align with optimal play. This negative result provides valuable insight: classical game-theoretic extensions grounded in rational choice are fundamentally incompatible with causal reasoning advantages, motivating new theoretical frameworks beyond standard Nash equilibrium for agentic AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06934v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>stat.OT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Thumm</dc:creator>
    </item>
    <item>
      <title>Fair Societies: Algorithms for House Allocations</title>
      <link>https://arxiv.org/abs/2511.07022</link>
      <description>arXiv:2511.07022v1 Announce Type: new 
Abstract: House Allocations concern with matchings involving one-sided preferences, where houses serve as a proxy encoding valuable indivisible resources (e.g. organs, course seats, subsidized public housing units) to be allocated among the agents. Every agent must receive exactly one resource. We study algorithmic approaches towards ensuring fairness in such settings. Minimizing the number of envious agents is known to be NP-complete (Kamiyama et al. 2021). We present two tractable approaches to deal with the computational hardness. When the agents are presented with an initial allocation of houses, we aim to refine this allocation by reallocating a bounded number of houses to reduce the number of envious agents. We show an efficient algorithm when the agents express preference for a bounded number of houses. Next, we consider single peaked preference domain and present a polynomial time algorithm for finding an allocation that minimize the number of envious agents. We further extend it to satisfy Pareto efficiency. Our former algorithm works for other measures of envy such as total envy, or maximum envy, with suitable modifications. Finally, we present an empirical analysis recording the fairness-welfare trade-off of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07022v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Sanjukta Roy, Aditi Sethia</dc:creator>
    </item>
    <item>
      <title>The Landscape of Almost Equitable Allocations</title>
      <link>https://arxiv.org/abs/2511.07395</link>
      <description>arXiv:2511.07395v1 Announce Type: new 
Abstract: Equitability is a fundamental notion in fair division which requires that all agents derive equal value from their allocated bundles. We study, for general (possibly non-monotone) valuations, a popular relaxation of equitability known as equitability up to one item (EQ1). An EQ1 allocation may fail to exist even with additive non-monotone valuations; for instance, when there are two agents, one valuing every item positively and the other negatively. This motivates a mild and natural assumption: all agents agree on the sign of their value for the grand bundle. Under this assumption, we prove the existence and provide an efficient algorithm for computing EQ1 allocations for two agents with general valuations. When there are more than two agents, we show the existence and polynomial-time computability of EQ1 allocations for valuation classes beyond additivity and monotonicity, in particular for (1) doubly monotone valuations and (2) submodular (resp. supermodular) valuations where the value for the grand bundle is nonnegative (resp. nonpositive) for all agents. Furthermore, we settle an open question of Bil`o et al. by showing that an EQ1 allocation always exists for nonnegative(resp. nonpositive) valuations, i.e., when every agent values each subset of items nonnegatively (resp. nonpositively). Finally, we complete the picture by showing that for general valuations with more than two agents, EQ1 allocations may not exist even when agents agree on the sign of the grand bundle, and that deciding the existence of an EQ1 allocation is computationally intractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07395v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Vishwa Prakash HV, Aditi Sethia, Jatin Yadav</dc:creator>
    </item>
    <item>
      <title>Distillation-Accelerated Uncertainty Modeling for Multi-Objective RTA Interception</title>
      <link>https://arxiv.org/abs/2511.05582</link>
      <description>arXiv:2511.05582v1 Announce Type: cross 
Abstract: Real-Time Auction (RTA) Interception aims to filter out invalid or irrelevant traffic to enhance the integrity and reliability of downstream data. However, two key challenges remain: (i) the need for accurate estimation of traffic quality together with sufficiently high confidence in the model's predictions, typically addressed through uncertainty modeling, and (ii) the efficiency bottlenecks that such uncertainty modeling introduces in real-time applications due to repeated inference. To address these challenges, we propose DAUM, a joint modeling framework that integrates multi-objective learning with uncertainty modeling, yielding both traffic quality predictions and reliable confidence estimates. Building on DAUM, we further apply knowledge distillation to reduce the computational overhead of uncertainty modeling, while largely preserving predictive accuracy and retaining the benefits of uncertainty estimation. Experiments on the JD advertisement dataset demonstrate that DAUM consistently improves predictive performance, with the distilled model delivering a tenfold increase in inference speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05582v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gaoxiang Zhao, Ruina Qiu, Pengpeng Zhao, Rongjin Wang, Zhangang Lin, Xiaoqiang Wang</dc:creator>
    </item>
    <item>
      <title>Blind Inverse Game Theory: Jointly Decoding Rewards and Rationality in Entropy-Regularized Competitive Games</title>
      <link>https://arxiv.org/abs/2511.05640</link>
      <description>arXiv:2511.05640v1 Announce Type: cross 
Abstract: Inverse Game Theory (IGT) methods based on the entropy-regularized Quantal Response Equilibrium (QRE) offer a tractable approach for competitive settings, but critically assume the agents' rationality parameter (temperature $\tau$) is known a priori. When $\tau$ is unknown, a fundamental scale ambiguity emerges that couples $\tau$ with the reward parameters ($\theta$), making them statistically unidentifiable. We introduce Blind-IGT, the first statistical framework to jointly recover both $\theta$ and $\tau$ from observed behavior. We analyze this bilinear inverse problem and establish necessary and sufficient conditions for unique identification by introducing a normalization constraint that resolves the scale ambiguity. We propose an efficient Normalized Least Squares (NLS) estimator and prove it achieves the optimal $\mathcal{O}(N^{-1/2})$ convergence rate for joint parameter recovery. When strong identifiability conditions fail, we provide partial identification guarantees through confidence set construction. We extend our framework to Markov games and demonstrate optimal convergence rates with strong empirical performance even when transition dynamics are unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05640v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamza Virk, Sandro Amaglobeli, Zuhayr Syed</dc:creator>
    </item>
    <item>
      <title>CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference</title>
      <link>https://arxiv.org/abs/2511.06175</link>
      <description>arXiv:2511.06175v1 Announce Type: cross 
Abstract: In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary "reasoning tool." Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06175v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaijie Xu, Fandi Meng, Clark Verbrugge, Simon Lucas</dc:creator>
    </item>
    <item>
      <title>Stackelberg Game-Driven Defense for ISAC Against Channel Attacks in Low-Altitude Networks</title>
      <link>https://arxiv.org/abs/2511.06359</link>
      <description>arXiv:2511.06359v1 Announce Type: cross 
Abstract: The increasing saturation of terrestrial resources has driven economic activities into low-altitude airspace. These activities, such as air taxis, rely on low-altitude wireless networks, and one key enabling technology is integrated sensing and communication (ISAC). However, in low-altitude airspace, ISAC is vulnerable to channel-access attacks, thereby degrading performance and threatening safety. To address this, we propose a defense framework based on a Stackelberg game. Specifically, we first model the system under attack, deriving metrics for the communication and the sensing to quantify performance. Then, we formulate the interaction as a three-player game where a malicious attacker acts as the leader, while the legitimate drone and ground base station act as followers. Using a backward induction algorithm, we obtain the Stackelberg equilibrium, allowing the defenders to dynamically adjust their strategies to mitigate the attack. Simulation results verify that the proposed algorithm converges to a stable solution and outperforms existing baselines, ensuring reliable ISAC performance for critical low-altitude applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06359v1</guid>
      <category>eess.SP</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiacheng Wang, Changyuan Zhao, Dusit Niyato, Geng Sun, Weijie Yuan, Abbas Jamalipour, Tao Xiang</dc:creator>
    </item>
    <item>
      <title>A Graph-Theoretical Perspective on Law Design for Multiagent Systems</title>
      <link>https://arxiv.org/abs/2511.06361</link>
      <description>arXiv:2511.06361v1 Announce Type: cross 
Abstract: A law in a multiagent system is a set of constraints imposed on agents' behaviours to avoid undesirable outcomes. The paper considers two types of laws: useful laws that, if followed, completely eliminate the undesirable outcomes and gap-free laws that guarantee that at least one agent can be held responsible each time an undesirable outcome occurs. In both cases, we study the problem of finding a law that achieves the desired result by imposing the minimum restrictions.
  We prove that, for both types of laws, the minimisation problem is NP-hard even in the simple case of one-shot concurrent interactions. We also show that the approximation algorithm for the vertex cover problem in hypergraphs could be used to efficiently approximate the minimum laws in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06361v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Shi, Pavel Naumov</dc:creator>
    </item>
    <item>
      <title>Breaking the Gradient Barrier: Unveiling Large Language Models for Strategic Classification</title>
      <link>https://arxiv.org/abs/2511.06979</link>
      <description>arXiv:2511.06979v1 Announce Type: cross 
Abstract: Strategic classification~(SC) explores how individuals or entities modify their features strategically to achieve favorable classification outcomes. However, existing SC methods, which are largely based on linear models or shallow neural networks, face significant limitations in terms of scalability and capacity when applied to real-world datasets with significantly increasing scale, especially in financial services and the internet sector. In this paper, we investigate how to leverage large language models to design a more scalable and efficient SC framework, especially in the case of growing individuals engaged with decision-making processes. Specifically, we introduce GLIM, a gradient-free SC method grounded in in-context learning. During the feed-forward process of self-attention, GLIM implicitly simulates the typical bi-level optimization process of SC, including both the feature manipulation and decision rule optimization. Without fine-tuning the LLMs, our proposed GLIM enjoys the advantage of cost-effective adaptation in dynamic strategic environments. Theoretically, we prove GLIM can support pre-trained LLMs to adapt to a broad range of strategic manipulations. We validate our approach through experiments with a collection of pre-trained LLMs on real-world and synthetic datasets in financial and internet domains, demonstrating that our GLIM exhibits both robustness and efficiency, and offering an effective solution for large-scale SC tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06979v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xinpeng Lv, Yunxin Mao, Haoxuan Li, Ke Liang, Jinxuan Yang, Wanrong Huang, Haoang Chi, Huan Chen, Long Lan, Yuanlong Chen, Wenjing Yang, Haotian Wang</dc:creator>
    </item>
    <item>
      <title>When the Correct Model Fails: The Optimality of Stackelberg Equilibria with Follower Intention Updates</title>
      <link>https://arxiv.org/abs/2511.07363</link>
      <description>arXiv:2511.07363v1 Announce Type: cross 
Abstract: We study a two-player dynamic Stackelberg game between a leader and a follower. Classical formulations of the Stackelberg equilibrium (SE) assume that the follower's best response (BR) mapping is known to the leader. However, this is not always true in practice. In those cases the leader needs to simultaneously infer this BR function while fulfilling an internal objective. We study a setting in which the leader selects a control strategy that optimizes an objective given an initial belief about the follower's best response. This belief is updated during the finite decision horizon, prompting the leader to reoptimize its control. We characterize the optimality guarantees of the SE solutions under this belief update for both open loop (OL) and feedback (FB) information structures. In particular, we show that it is possible that assuming an incorrect follower BR map obtains a lower cost over the game horizon than knowing the true BR. We support these claims with numerical examples in a linear quadratic (LQ) Stackelberg game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07363v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cayetana Salinas Rodriguez, Jonathan Rogers, Sarah H. Q. Li</dc:creator>
    </item>
    <item>
      <title>From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications</title>
      <link>https://arxiv.org/abs/2506.03464</link>
      <description>arXiv:2506.03464v2 Announce Type: replace 
Abstract: The convergence of online learning algorithms in games under self-play is a fundamental question in game theory and machine learning. Among various notions of convergence, last-iterate convergence is particularly desirable, as it reflects the actual decisions made by the learners and captures the day-to-day behavior of the learning dynamics. While many algorithms are known to converge in the average-iterate, achieving last-iterate convergence typically requires considerably more effort in both the design and the analysis of the algorithm. Somewhat surprisingly, we show in this paper that for a large family of games, there exists a simple black-box reduction that transforms the average iterates of an uncoupled learning dynamics into the last iterates of a new uncoupled learning dynamics, thus also providing a reduction from last-iterate convergence to average-iterate convergence. Our reduction applies to games where each player's utility is linear in both their own strategy and the joint strategy of all opponents. This family includes two-player bimatrix games and generalizations such as multi-player polymatrix games. By applying our reduction to the Optimistic Multiplicative Weights Update algorithm, we obtain new state-of-the-art last-iterate convergence rates for uncoupled learning dynamics in multi-player zero-sum polymatrix games: (1) an $O(\frac{\log d}{T})$ last-iterate convergence rate under gradient feedback, representing an exponential improvement in the dependence on the dimension $d$ (i.e., the maximum number of actions available to either player); and (2) an $\widetilde{O}(d^{\frac{1}{5}} T^{-\frac{1}{5}})$ last-iterate convergence rate under bandit feedback, improving upon the previous best rates of $\widetilde{O}(\sqrt{d} T^{-\frac{1}{8}})$ and $\widetilde{O}(\sqrt{d} T^{-\frac{1}{6}})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03464v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Inequality in the Age of Pseudonymity</title>
      <link>https://arxiv.org/abs/2508.04668</link>
      <description>arXiv:2508.04668v5 Announce Type: replace 
Abstract: Inequality measures such as the Gini coefficient are used to inform and motivate policymaking, and are increasingly applied to digital platforms. We analyze how measures fare in pseudonymous settings that are common in the digital age. One key challenge of such environments is the ability of actors to create fake identities under fictitious false names, also known as ``Sybils.'' While some actors may do so to preserve their privacy, we show that this can inadvertently hamper inequality measurements. As we prove, it is impossible for measures satisfying the literature's canonical set of desired properties to assess the inequality of an economy that may harbor Sybils. We characterize the class of all Sybil-proof measures, and prove that they must satisfy relaxed version of the aforementioned properties. Furthermore, we show that the structure imposed restricts the ability to assess inequality at a fine-grained level. By applying our results, we prove that large classes of popular measures are not Sybil-proof, with the famous Gini coefficient being but one example out of many. Finally, we examine the dynamics leading to the creation of Sybils in digital and traditional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04668v5</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aviv Yaish, Nir Chemaya, Lin William Cong, Dahlia Malkhi</dc:creator>
    </item>
    <item>
      <title>The Curse of Shared Knowledge: Recursive Belief Reasoning in a Coordination Game with Imperfect Information</title>
      <link>https://arxiv.org/abs/2008.08849</link>
      <description>arXiv:2008.08849v2 Announce Type: replace-cross 
Abstract: Common knowledge is a necessary condition for safe group coordination. When common knowledge can not be obtained, humans routinely use their ability to attribute beliefs and intentions in order to infer what is known. But such shared knowledge attributions are limited in depth and therefore prone to coordination failures, because any finite-order knowledge attribution allows for an even higher order attribution that may change what is known by whom. In three separate experiments we investigate to which degree human participants (N=802) are able to recognize the difference between common knowledge and nth-order shared knowledge. We use a new two-person coordination game with imperfect information that is able to cast the recursive game structure and higher-order uncertainties into a simple, everyday-like setting. Our results show that participants have a very hard time accepting the fact that common knowledge is not reducible to shared knowledge. Instead, participants try to coordinate even at the shallowest depths of shared knowledge and in spite of huge payoff penalties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.08849v2</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Bolander, Robin Engelhardt, Thomas S. Nicolet</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence of Adaptive Riemannian Gradient Descent for Equilibrium Computation</title>
      <link>https://arxiv.org/abs/2306.16617</link>
      <description>arXiv:2306.16617v2 Announce Type: replace-cross 
Abstract: Equilibrium computation on Riemannian manifolds provides a unifying framework for numerous problems in machine learning and data analytics. One of the simplest yet most fundamental methods is Riemannian gradient descent (RGD). While its Euclidean counterpart has been extensively studied, it remains unclear how the manifold curvature affects RGD in game-theoretic settings. This paper addresses this gap by establishing new convergence results for \textit{geodesic strongly monotone} games. Our key result shows that RGD attains last-iterate linear convergence in a \textit{geometry-agnostic} fashion, a key property for applications in machine learning. We extend this guarantee to stochastic and adaptive variants -- SRGD and FARGD -- and establish that: (i) the sample complexity of SRGD is geometry-agnostic and optimal with respect to noise; (ii) FARGD matches the convergence rate of its non-adaptive counterpart up to constant factors, while avoiding reliance on the condition number. Overall, this paper presents the first geometry-agnostic last-iterate convergence analysis for games beyond the Euclidean settings, underscoring the surprising power of RGD -- despite its simplicity -- in solving a wide spectrum of machine learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16617v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Michael I. Jordan, Tianyi Lin, Argyris Oikonomou, Emmanouil-Vasileios Vlatakis-Gkaragkounis</dc:creator>
    </item>
    <item>
      <title>Optimal Strategy Revision in Population Games: A Mean Field Game Theory Perspective</title>
      <link>https://arxiv.org/abs/2501.01389</link>
      <description>arXiv:2501.01389v2 Announce Type: replace-cross 
Abstract: This paper investigates the design of optimal strategy revision in Population Games (PG) by establishing its connection to finite-state Mean Field Games (MFG). Specifically, by linking Evolutionary Dynamics (ED) -- which models agent decision-making in PG -- to the MFG framework, we demonstrate that optimal strategy revision can be derived by solving the forward Fokker-Planck (FP) equation and the backward Hamilton-Jacobi (HJ) equation, both central components of the MFG framework. Furthermore, we show that the resulting optimal strategy revision, which maximizes each agent's payoffs over a finite time horizon, satisfies two key properties: positive correlation and Nash stationarity, which are essential for ensuring convergence to the Nash equilibrium. This convergence is then rigorously analyzed and established. Additionally, we discuss how different design objectives for the optimal strategy revision can recover existing ED models previously reported in the PG literature. Numerical examples are provided to illustrate the effectiveness and improved convergence properties of the optimal strategy revision design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01389v2</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Barreiro-Gomez, Shinkyu Park</dc:creator>
    </item>
    <item>
      <title>Properties of zero-determinant strategies in multichannel games</title>
      <link>https://arxiv.org/abs/2505.21952</link>
      <description>arXiv:2505.21952v2 Announce Type: replace-cross 
Abstract: Controlling payoffs in repeated games is one of the important topics in control theory of multi-agent systems. Recently proposed zero-determinant strategies enable players to unilaterally enforce linear relations between payoffs. Furthermore, based on the mathematics of zero-determinant strategies, regional payoff control, in which payoffs are enforced into some feasible regions, has been discovered in social dilemma situations. More recently, theory of payoff control was extended to multichannel games, where players parallelly interact with each other in multiple channels. However, the existence of payoff-controlling strategies in multichannel games seems to require the existence of payoff-controlling strategies in some channels, and properties of zero-determinant strategies specific to multichannel games are still not clear. In this paper, we elucidate properties of zero-determinant strategies in multichannel games. First, we relate the existence condition of zero-determinant strategies in multichannel games to that of zero-determinant strategies in each channel. We then show that the existence of zero-determinant strategies in multichannel games requires the existence of zero-determinant strategies in some channels. This result implies that the existence of zero-determinant strategies in multichannel games is tightly restricted by structure of games played in each channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21952v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiko Ueda</dc:creator>
    </item>
    <item>
      <title>Matchings Under Biased and Correlated Evaluations</title>
      <link>https://arxiv.org/abs/2510.23628</link>
      <description>arXiv:2510.23628v2 Announce Type: replace-cross 
Abstract: We study a two-institution stable matching model in which candidates from two distinct groups are evaluated using partially correlated signals that are group-biased. This extends prior work (which assumes institutions evaluate candidates in an identical manner) to a more realistic setting in which institutions rely on overlapping, but independently processed, criteria. These evaluations could consist of a variety of informative tools such as standardized tests, shared recommendation systems, or AI-based assessments with local noise. Two key parameters govern evaluations: the bias parameter $\beta \in (0,1]$, which models systematic disadvantage faced by one group, and the correlation parameter $\gamma \in [0,1]$, which captures the alignment between institutional rankings. We study the representation ratio, i.e., the ratio of disadvantaged to advantaged candidates selected by the matching process in this setting. Focusing on a regime in which all candidates prefer the same institution, we characterize the large-market equilibrium and derive a closed-form expression for the resulting representation ratio. Prior work shows that when $\gamma = 1$, this ratio scales linearly with $\beta$. In contrast, we show that the representation ratio increases nonlinearly with $\gamma$ and even modest losses in correlation can cause sharp drops in the representation ratio. Our analysis identifies critical $\gamma$-thresholds where institutional selection behavior undergoes discrete transitions, and reveals structural conditions under which evaluator alignment or bias mitigation are most effective. Finally, we show how this framework and results enable interventions for fairness-aware design in decentralized selection systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23628v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Kumar, Nisheeth K. Vishnoi</dc:creator>
    </item>
  </channel>
</rss>
