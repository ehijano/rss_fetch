<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Apr 2025 04:01:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Double Machine Learning for Causal Inference under Shared-State Interference</title>
      <link>https://arxiv.org/abs/2504.08836</link>
      <description>arXiv:2504.08836v1 Announce Type: cross 
Abstract: Researchers and practitioners often wish to measure treatment effects in settings where units interact via markets and recommendation systems. In these settings, units are affected by certain shared states, like prices, algorithmic recommendations or social signals. We formalize this structure, calling it shared-state interference, and argue that our formulation captures many relevant applied settings. Our key modeling assumption is that individuals' potential outcomes are independent conditional on the shared state. We then prove an extension of a double machine learning (DML) theorem providing conditions for achieving efficient inference under shared-state interference. We also instantiate our general theorem in several models of interest where it is possible to efficiently estimate the average direct effect (ADE) or global average treatment effect (GATE).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08836v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Hays, Manish Raghavan</dc:creator>
    </item>
    <item>
      <title>Ordinary Least Squares as an Attention Mechanism</title>
      <link>https://arxiv.org/abs/2504.09663</link>
      <description>arXiv:2504.09663v1 Announce Type: cross 
Abstract: I show that ordinary least squares (OLS) predictions can be rewritten as the output of a restricted attention module, akin to those forming the backbone of large language models. This connection offers an alternative perspective on attention beyond the conventional information retrieval framework, making it more accessible to researchers and analysts with a background in traditional statistics. It falls into place when OLS is framed as a similarity-based method in a transformed regressor space, distinct from the standard view based on partial correlations. In fact, the OLS solution can be recast as the outcome of an alternative problem: minimizing squared prediction errors by optimizing the embedding space in which training and test vectors are compared via inner products. Rather than estimating coefficients directly, we equivalently learn optimal encoding and decoding operations for predictors. From this vantage point, OLS maps naturally onto the query-key-value structure of attention mechanisms. Building on this foundation, I discuss key elements of Transformer-style attention and draw connections to classic ideas from time series econometrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09663v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Goulet Coulombe</dc:creator>
    </item>
    <item>
      <title>Structural breaks detection and variable selection in dynamic linear regression via the Iterative Fused LASSO in high dimension</title>
      <link>https://arxiv.org/abs/2502.20816</link>
      <description>arXiv:2502.20816v2 Announce Type: replace 
Abstract: We aim to develop a time series modeling methodology tailored to high-dimensional environments, addressing two critical challenges: variable selection from a large pool of candidates, and the detection of structural break points, where the model's parameters shift. This effort centers on formulating a least squares estimation problem with regularization constraints, drawing on techniques such as Fused LASSO and AdaLASSO, which are well-established in machine learning. Our primary achievement is the creation of an efficient algorithm capable of handling high-dimensional cases within practical time limits. By addressing these pivotal challenges, our methodology holds the potential for widespread adoption. To validate its effectiveness, we detail the iterative algorithm and benchmark its performance against the widely recognized Path Algorithm for Generalized Lasso. Comprehensive simulations and performance analyses highlight the algorithm's strengths. Additionally, we demonstrate the methodology's applicability and robustness through simulated case studies and a real-world example involving a stock portfolio dataset. These examples underscore the methodology's practical utility and potential impact across diverse high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20816v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angelo Milfont, Alvaro Veiga</dc:creator>
    </item>
  </channel>
</rss>
