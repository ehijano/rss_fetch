<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Nov 2024 02:48:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Wasserstein Spatial Depth</title>
      <link>https://arxiv.org/abs/2411.10646</link>
      <description>arXiv:2411.10646v1 Announce Type: new 
Abstract: Modeling observations as random distributions embedded within Wasserstein spaces is becoming increasingly popular across scientific fields, as it captures the variability and geometric structure of the data more effectively. However, the distinct geometry and unique properties of Wasserstein space pose challenges to the application of conventional statistical tools, which are primarily designed for Euclidean spaces. Consequently, adapting and developing new methodologies for analysis within Wasserstein spaces has become essential. The space of distributions on $\mathbb{R}^d$ with $d&gt;1$ is not linear, and ''mimic'' the geometry of a Riemannian manifold. In this paper, we extend the concept of statistical depth to distribution-valued data, introducing the notion of {\it Wasserstein spatial depth}. This new measure provides a way to rank and order distributions, enabling the development of order-based clustering techniques and inferential tools. We show that Wasserstein spatial depth (WSD) preserves critical properties of conventional statistical depths, notably, ranging within $[0,1]$, transformation invariance, vanishing at infinity, reaching a maximum at the geometric median, and continuity. Additionally, the population WSD has a straightforward plug-in estimator based on sampled empirical distributions. We establish the estimator's consistency and asymptotic normality. Extensive simulation and real-data application showcase the practical efficacy of WSD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10646v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc, Alberto Gonz\'alez-Sanz, Jean-Michel Loubes, Yisha Yao</dc:creator>
    </item>
    <item>
      <title>Variance bounds and robust tuning for pseudo-marginal Metropolis--Hastings algorithms</title>
      <link>https://arxiv.org/abs/2411.10785</link>
      <description>arXiv:2411.10785v1 Announce Type: new 
Abstract: The general applicability and ease of use of the pseudo-marginal Metropolis--Hastings (PMMH) algorithm, and particle Metropolis--Hastings in particular, makes it a popular method for inference on discretely observed Markovian stochastic processes. The performance of these algorithms and, in the case of particle Metropolis--Hastings, the trade off between improved mixing through increased accuracy of the estimator and the computational cost were investigated independently in two papers, both published in 2015. Each suggested choosing the number of particles so that the variance of the logarithm of the estimator of the posterior at a fixed sensible parameter value is approximately 1. This advice has been widely and successfully adopted. We provide new, remarkably simple upper and lower bounds on the asymptotic variance of PMMH algorithms. The bounds explain how blindly following the 2015 advice can hide serious issues with the algorithm and they strongly suggest an alternative criterion. In most situations our guidelines and those from 2015 closely coincide; however, when the two differ it is safer to follow the new guidance. An extension of one of our bounds shows how the use of correlated proposals can fundamentally shift the properties of pseudo-marginal algorithms, so that asymptotic variances that were infinite under the PMMH kernel become finite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10785v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Sherlock</dc:creator>
    </item>
    <item>
      <title>Mean Estimation in Banach Spaces Under Infinite Variance and Martingale Dependence</title>
      <link>https://arxiv.org/abs/2411.11271</link>
      <description>arXiv:2411.11271v1 Announce Type: new 
Abstract: We consider estimating the shared mean of a sequence of heavy-tailed random variables taking values in a Banach space. In particular, we revisit and extend a simple truncation-based mean estimator by Catoni and Giulini. While existing truncation-based approaches require a bound on the raw (non-central) second moment of observations, our results hold under a bound on either the central or non-central $p$th moment for some $p &gt; 1$. In particular, our results hold for distributions with infinite variance. The main contributions of the paper follow from exploiting connections between truncation-based mean estimation and the concentration of martingales in 2-smooth Banach spaces. We prove two types of time-uniform bounds on the distance between the estimator and unknown mean: line-crossing inequalities, which can be optimized for a fixed sample size $n$, and non-asymptotic law of the iterated logarithm type inequalities, which match the tightness of line-crossing inequalities at all points in time up to a doubly logarithmic factor in $n$. Our results do not depend on the dimension of the Banach space, hold under martingale dependence, and all constants in the inequalities are known and small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11271v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Whitehouse, Ben Chugg, Diego Martinez-Taboada, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>PALMS: Parallel Adaptive Lasso with Multi-directional Signals for Latent Networks Reconstruction</title>
      <link>https://arxiv.org/abs/2411.11464</link>
      <description>arXiv:2411.11464v1 Announce Type: new 
Abstract: Large-scale networks exist in many field and play an important role in real-world dynamics. However, the networks are usually latent and expensive to detect, which becomes the main challenging for many applications and empirical analysis. Several statistical methods were proposed to infer the edges, but the complexity of algorithms make them hard to be applied for large-scale networks. In this paper, we proposed a general distributed and parallel computing framework for network reconstruction methods via compressive sensing technical, to make them feasible for inferring the super large networks in practice. Combining with the CALMS, we proposed for those estimators enjoy additional theoretical properties, such as the consistency and asymptotic normality, we prove that the approximate estimation utilizing the distributed algorithm can keep the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11464v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoyu Xing, Wei Zhong</dc:creator>
    </item>
    <item>
      <title>Theoretical Foundations of Conformal Prediction</title>
      <link>https://arxiv.org/abs/2411.11824</link>
      <description>arXiv:2411.11824v1 Announce Type: new 
Abstract: This book is about conformal prediction and related inferential techniques that build on permutation tests and exchangeability. These techniques are useful in a diverse array of tasks, including hypothesis testing and providing uncertainty quantification guarantees for machine learning systems. Much of the current interest in conformal prediction is due to its ability to integrate into complex machine learning workflows, solving the problem of forming prediction sets without any assumptions on the form of the data generating distribution. Since contemporary machine learning algorithms have generally proven difficult to analyze directly, conformal prediction's main appeal is its ability to provide formal, finite-sample guarantees when paired with such methods.
  The goal of this book is to teach the reader about the fundamental technical arguments that arise when researching conformal prediction and related questions in distribution-free inference. Many of these proof strategies, especially the more recent ones, are scattered among research papers, making it difficult for researchers to understand where to look, which results are important, and how exactly the proofs work. We hope to bridge this gap by curating what we believe to be some of the most important results in the literature and presenting their proofs in a unified language, with illustrations, and with an eye towards pedagogy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11824v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasios N. Angelopoulos, Rina Foygel Barber, Stephen Bates</dc:creator>
    </item>
    <item>
      <title>A Geometric Perspective on the Injective Norm of Sums of Random Tensors</title>
      <link>https://arxiv.org/abs/2411.10633</link>
      <description>arXiv:2411.10633v1 Announce Type: cross 
Abstract: Matrix concentration inequalities, intimately connected to the Non-Commutative Khintchine inequality, have been an important tool in both applied and pure mathematics. We study tensor versions of these inequalities, and establish non-asymptotic inequalities for the $\ell_p$ injective norm of random tensors with correlated entries. In certain regimes of $p$ and the tensor order, our tensor concentration inequalities are nearly optimal in their dimension dependencies. We illustrate our result with applications to problems including structured models of random tensors and matrices, tensor PCA, and connections to lower bounds in coding theory.
  Our techniques are based on covering number estimates as opposed to operator theoretic tools, which also provide a geometric proof of a weaker version of the Non-Commutative Khintchine inequality, motivated by a question of Talagrand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10633v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Afonso S. Bandeira, Sivakanth Gopi, Haotian Jiang, Kevin Lucca, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>False Discovery Control in Multiple Testing: A Brief Overview of Theories and Methodologies</title>
      <link>https://arxiv.org/abs/2411.10647</link>
      <description>arXiv:2411.10647v1 Announce Type: cross 
Abstract: As the volume and complexity of data continue to expand across various scientific disciplines, the need for robust methods to account for the multiplicity of comparisons has grown widespread. A popular measure of type 1 error rate in multiple testing literature is the false discovery rate (FDR). The FDR provides a powerful and practical approach to large-scale multiple testing and has been successfully used in a wide range of applications. The concept of FDR has gained wide acceptance in the statistical community and various methods has been proposed to control the FDR. In this work, we review the latest developments in FDR control methodologies. We also develop a conceptual framework to better describe this vast literature; understand its intuition and key ideas; and provide guidance for the researcher interested in both the application and development of the methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10647v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jianliang He, Bowen Gang, Luella Fu</dc:creator>
    </item>
    <item>
      <title>The Conflict Graph Design: Estimating Causal Effects under Arbitrary Neighborhood Interference</title>
      <link>https://arxiv.org/abs/2411.10908</link>
      <description>arXiv:2411.10908v1 Announce Type: cross 
Abstract: A fundamental problem in network experiments is selecting an appropriate experimental design in order to precisely estimate a given causal effect of interest. In fact, optimal rates of estimation remain unknown for essentially all causal effects in network experiments. In this work, we propose a general approach for constructing experiment designs under network interference with the goal of precisely estimating a pre-specified causal effect. A central aspect of our approach is the notion of a conflict graph, which captures the fundamental unobservability associated with the casual effect and the underlying network. We refer to our experimental design as the Conflict Graph Design. In order to estimate effects, we propose a modified Horvitz--Thompson estimator. We show that its variance under the Conflict Graph Design is bounded as $O(\lambda(H) / n )$, where $\lambda(H)$ is the largest eigenvalue of the adjacency matrix of the conflict graph. These rates depend on both the underlying network and the particular causal effect under investigation. Not only does this yield the best known rates of estimation for several well-studied causal effects (e.g. the global and direct effects) but it also provides new methods for effects which have received less attention from the perspective of experiment design (e.g. spill-over effects). Our results corroborate two implicitly understood points in the literature: (1) that in order to increase precision, experiment designs should be tailored to specific causal effects of interest and (2) that "more local" effects are easier to estimate than "more global" effects. In addition to point estimation, we construct conservative variance estimators which facilitate the construction of asymptotically valid confidence intervals for the casual effect of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10908v1</guid>
      <category>stat.ME</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vardis Kandiros, Charilaos Pipis, Constantinos Daskalakis, Christopher Harshaw</dc:creator>
    </item>
    <item>
      <title>Program Evaluation with Remotely Sensed Outcomes</title>
      <link>https://arxiv.org/abs/2411.10959</link>
      <description>arXiv:2411.10959v1 Announce Type: cross 
Abstract: While traditional program evaluations typically rely on surveys to measure outcomes, certain economic outcomes such as living standards or environmental quality may be infeasible or costly to collect. As a result, recent empirical work estimates treatment effects using remotely sensed variables (RSVs), such mobile phone activity or satellite images, instead of ground-truth outcome measurements. Common practice predicts the economic outcome from the RSV, using an auxiliary sample of labeled RSVs, and then uses such predictions as the outcome in the experiment. We prove that this approach leads to biased estimates of treatment effects when the RSV is a post-outcome variable. We nonparametrically identify the treatment effect, using an assumption that reflects the logic of recent empirical research: the conditional distribution of the RSV remains stable across both samples, given the outcome and treatment. Our results do not require researchers to know or consistently estimate the relationship between the RSV, outcome, and treatment, which is typically mis-specified with unstructured data. We form a representation of the RSV for downstream causal inference by predicting the outcome and predicting the treatment, with better predictions leading to more precise causal estimates. We re-evaluate the efficacy of a large-scale public program in India, showing that the program's measured effects on local consumption and poverty can be replicated using satellite</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10959v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ashesh Rambachan, Rahul Singh, Davide Viviano</dc:creator>
    </item>
    <item>
      <title>Variational Bayesian Bow tie Neural Networks with Shrinkage</title>
      <link>https://arxiv.org/abs/2411.11132</link>
      <description>arXiv:2411.11132v2 Announce Type: cross 
Abstract: Despite the dominant role of deep models in machine learning, limitations persist, including overconfident predictions, susceptibility to adversarial attacks, and underestimation of variability in predictions. The Bayesian paradigm provides a natural framework to overcome such issues and has become the gold standard for uncertainty estimation with deep models, also providing improved accuracy and a framework for tuning critical hyperparameters. However, exact Bayesian inference is challenging, typically involving variational algorithms that impose strong independence and distributional assumptions. Moreover, existing methods are sensitive to the architectural choice of the network. We address these issues by constructing a relaxed version of the standard feed-forward rectified neural network, and employing Polya-Gamma data augmentation tricks to render a conditionally linear and Gaussian model. Additionally, we use sparsity-promoting priors on the weights of the neural network for data-driven architectural design. To approximate the posterior, we derive a variational inference algorithm that avoids distributional assumptions and independence across layers and is a faster alternative to the usual Markov Chain Monte Carlo schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11132v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alisa Sheinkman, Sara Wade</dc:creator>
    </item>
    <item>
      <title>Learning the Sherrington-Kirkpatrick Model Even at Low Temperature</title>
      <link>https://arxiv.org/abs/2411.11174</link>
      <description>arXiv:2411.11174v1 Announce Type: cross 
Abstract: We consider the fundamental problem of learning the parameters of an undirected graphical model or Markov Random Field (MRF) in the setting where the edge weights are chosen at random. For Ising models, we show that a multiplicative-weight update algorithm due to Klivans and Meka learns the parameters in polynomial time for any inverse temperature $\beta \leq \sqrt{\log n}$.
  This immediately yields an algorithm for learning the Sherrington-Kirkpatrick (SK) model beyond the high-temperature regime of $\beta &lt; 1$. Prior work breaks down at $\beta = 1$ and requires heavy machinery from statistical physics or functional inequalities. In contrast, our analysis is relatively simple and uses only subgaussian concentration.
  Our results extend to MRFs of higher order (such as pure $p$-spin models), where even results in the high-temperature regime were not known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11174v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautam Chandrasekaran, Adam Klivans</dc:creator>
    </item>
    <item>
      <title>On the physics of nested Markov models: a generalized probabilistic theory perspective</title>
      <link>https://arxiv.org/abs/2411.11614</link>
      <description>arXiv:2411.11614v1 Announce Type: cross 
Abstract: Determining potential probability distributions with a given causal graph is vital for causality studies. To bypass the difficulty in characterizing latent variables in a Bayesian network, the nested Markov model provides an elegant algebraic approach by listing exactly all the equality constraints on the observed variables. However, this algebraically motivated causal model comprises distributions outside Bayesian networks, and its physical interpretation remains vague. In this work, we inspect the nested Markov model through the lens of generalized probabilistic theory, an axiomatic framework to describe general physical theories. We prove that all the equality constraints defining the nested Markov model hold valid theory-independently. Yet, we show this model generally contains distributions not implementable even within such relaxed physical theories subjected to merely the relativity principles and mild probabilistic rules. To interpret the origin of such a gap, we establish a new causal model that defines valid distributions as projected from a high-dimensional Bell-type causal structure. The new model unveils inequality constraints induced by relativity principles, or equivalently high-dimensional conditional independences, which are absent in the nested Markov model. Nevertheless, we also notice that the restrictions on states and measurements introduced by the generalized probabilistic theory framework can pose additional inequality constraints beyond the new causal model. As a by-product, we discover a new causal structure exhibiting strict gaps between the distribution sets of a Bayesian network, generalized probabilistic theories, and the nested Markov model. We anticipate our results will enlighten further explorations on the unification of algebraic and physical perspectives of causality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11614v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingjian Zhang, Yuhao Wang</dc:creator>
    </item>
    <item>
      <title>Block Coordinate DC Programming</title>
      <link>https://arxiv.org/abs/2411.11664</link>
      <description>arXiv:2411.11664v1 Announce Type: cross 
Abstract: We introduce an extension of the Difference of Convex Algorithm (DCA) in the form of a block coordinate approach for problems with separable structure. For $n$ coordinate-blocks and $k$ iterations, our main result proves a non-asymptotic convergence rate of $O(n/k)$ for the proposed method. Furthermore, leveraging the connection between DCA and Expectation Maximization (EM), we propose a block coordinate EM algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11664v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoomaan Maskan, Paniz Halvachi, Suvrit Sra, Alp Yurtsever</dc:creator>
    </item>
    <item>
      <title>Randomization-based Z-estimation for evaluating average and individual treatment effects</title>
      <link>https://arxiv.org/abs/2411.11737</link>
      <description>arXiv:2411.11737v1 Announce Type: cross 
Abstract: Randomized experiments have been the gold standard for drawing causal inference. The conventional model-based approach has been one of the most popular ways for analyzing treatment effects from randomized experiments, which is often carried through inference for certain model parameters. In this paper, we provide a systematic investigation of model-based analyses for treatment effects under the randomization-based inference framework. This framework does not impose any distributional assumptions on the outcomes, covariates and their dependence, and utilizes only randomization as the "reasoned basis". We first derive the asymptotic theory for Z-estimation in completely randomized experiments, and propose sandwich-type conservative covariance estimation. We then apply the developed theory to analyze both average and individual treatment effects in randomized experiments. For the average treatment effect, we consider three estimation strategies: model-based, model-imputed, and model-assisted, where the first two can be sensitive to model misspecification or require specific ways for parameter estimation. The model-assisted approach is robust to arbitrary model misspecification and always provides consistent average treatment effect estimation. We propose optimal ways to conduct model-assisted estimation using generally nonlinear least squares for parameter estimation. For the individual treatment effects, we propose to directly model the relationship between individual effects and covariates, and discuss the model's identifiability, inference and interpretation allowing model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11737v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Qu, Jiangchuan Du, Xinran Li</dc:creator>
    </item>
    <item>
      <title>Debiased Regression for Root-N-Consistent Conditional Mean Estimation</title>
      <link>https://arxiv.org/abs/2411.11748</link>
      <description>arXiv:2411.11748v2 Announce Type: cross 
Abstract: This study introduces a debiasing method for regression estimators, including high-dimensional and nonparametric regression estimators. For example, nonparametric regression methods allow for the estimation of regression functions in a data-driven manner with minimal assumptions; however, these methods typically fail to achieve $\sqrt{n}$-consistency in their convergence rates, and many, including those in machine learning, lack guarantees that their estimators asymptotically follow a normal distribution. To address these challenges, we propose a debiasing technique for nonparametric estimators by adding a bias-correction term to the original estimators, extending the conventional one-step estimator used in semiparametric analysis. Specifically, for each data point, we estimate the conditional expected residual of the original nonparametric estimator, which can, for instance, be computed using kernel (Nadaraya-Watson) regression, and incorporate it as a bias-reduction term. Our theoretical analysis demonstrates that the proposed estimator achieves $\sqrt{n}$-consistency and asymptotic normality under a mild convergence rate condition for both the original nonparametric estimator and the conditional expected residual estimator. Notably, this approach remains model-free as long as the original estimator and the conditional expected residual estimator satisfy the convergence rate condition. The proposed method offers several advantages, including improved estimation accuracy and simplified construction of confidence intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11748v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Clustering and Classification Risks in Non-parametric Hidden Markov and I.I.D. Models</title>
      <link>https://arxiv.org/abs/2309.12238</link>
      <description>arXiv:2309.12238v3 Announce Type: replace 
Abstract: We provide an in-depth analysis of the Bayes risk of clustering and the Bayes risk of classification in the context of Hidden Markov and i.i.d. models. In both settings, we identify the situations where the two risks are comparable or not and those where the associated minimizers are related or not, as well as the key quantity measuring the difficulty of both tasks. Then, leveraging the nonparametric identifiability of HMMs, we control the excess risk of a plug-in clustering procedure. Simulations illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12238v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elisabeth Gassiat, Ibrahim Kaddouri, Zacharie Naulet</dc:creator>
    </item>
    <item>
      <title>Likelihood Correspondence of Toric Statistical Models</title>
      <link>https://arxiv.org/abs/2312.08501</link>
      <description>arXiv:2312.08501v3 Announce Type: replace 
Abstract: Maximum likelihood estimation (MLE) is a fundamental problem in statistics. Characteristics of the MLE problem for discrete algebraic statistical models are reflected in the geometry of the $\textit{likelihood correspondence}$, a variety that ties together data and their maximum likelihood estimators. We construct this ideal for the large class of toric models and find a Gr\"{o}bner basis in the case of complete and joint independence models arising from multi-way contingency tables. All of our constructions are implemented in $\textit{Macaulay2}$ in a package $\texttt{LikelihoodGeometry}$ along with other tools of use in algebraic statistics. We end with an experimental section using these implementations on several interesting examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08501v3</guid>
      <category>math.ST</category>
      <category>math.AC</category>
      <category>math.AG</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Barnhill, John Cobb, Matthew Faust</dc:creator>
    </item>
    <item>
      <title>Spectral gap bounds for reversible hybrid Gibbs chains</title>
      <link>https://arxiv.org/abs/2312.12782</link>
      <description>arXiv:2312.12782v3 Announce Type: replace 
Abstract: Hybrid Gibbs samplers represent a prominent class of approximated Gibbs algorithms that utilize Markov chains to approximate conditional distributions, with the Metropolis-within-Gibbs algorithm standing out as a well-known example. Despite their widespread use in both statistical and non-statistical applications, little is known about their convergence properties. This article introduces novel methods for establishing bounds on the convergence rates of certain reversible hybrid Gibbs samplers. In particular, we examine the convergence characteristics of hybrid random-scan Gibbs algorithms. Our analysis reveals that the absolute spectral gap of a hybrid Gibbs chain can be bounded based on the absolute spectral gap of the exact Gibbs chain and the absolute spectral gaps of the Markov chains employed for conditional distribution approximations. We also provide a convergence bound of similar flavors for hybrid data augmentation algorithms, extending existing works on the topic. The general bounds are applied to three examples: a random-scan Metropolis-within-Gibbs sampler, random-scan Gibbs samplers with block updates, and a hybrid slice sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12782v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Qin, Nianqiao Ju, Guanyang Wang</dc:creator>
    </item>
    <item>
      <title>Optimal Estimation of Parameters in Degree Corrected Mixed Membership Models</title>
      <link>https://arxiv.org/abs/2410.07621</link>
      <description>arXiv:2410.07621v2 Announce Type: replace 
Abstract: With the rise of big data, networks have pervaded many aspects of our daily lives, with applications ranging from the social to natural sciences. Understanding the latent structure of the network is thus an important question. In this paper, we model the network using a Degree-Corrected Mixed Membership (DCMM) model, in which every node $i$ has an affinity parameter $\theta_i$, measuring the degree of connectivity, and an intrinsic membership probability vector $\pi_i = (\pi_1, \cdots \pi_K)$, measuring its belonging to one of $K$ communities, and a probability matrix $P$ that describes the average connectivity between two communities. Our central question is to determine the optimal estimation rates for the probability matrix and degree parameters $P$ and $\Theta$ of the DCMM, an often overlooked question in the literature. By providing new lower bounds, we show that simple extensions of existing estimators in the literature indeed achieve the optimal rate. Simulations lend further support to our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07621v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephen Jiang, Jianqing Fan</dc:creator>
    </item>
    <item>
      <title>Smooth Non-Stationary Bandits</title>
      <link>https://arxiv.org/abs/2301.12366</link>
      <description>arXiv:2301.12366v3 Announce Type: replace-cross 
Abstract: In many applications of online decision making, the environment is non-stationary and it is therefore crucial to use bandit algorithms that handle changes. Most existing approaches are designed to protect against non-smooth changes, constrained only by total variation or Lipschitzness over time. However, in practice, environments often change {\em smoothly}, so such algorithms may incur higher-than-necessary regret. We study a non-stationary bandits problem where each arm's mean reward sequence can be embedded into a $\beta$-H\"older function, i.e., a function that is $(\beta-1)$-times Lipschitz-continuously differentiable. The non-stationarity becomes more smooth as $\beta$ increases. When $\beta=1$, this corresponds to the non-smooth regime, where \cite{besbes2014stochastic} established a minimax regret of $\tilde \Theta(T^{2/3})$. We show the first separation between the smooth (i.e., $\beta\ge 2$) and non-smooth (i.e., $\beta=1$) regimes by presenting a policy with $\tilde O(k^{4/5} T^{3/5})$ regret on any $k$-armed, $2$-H\"older instance. We complement this result by showing that the minimax regret on the $\beta$-H\"older family of instances is $\Omega(T^{(\beta+1)/(2\beta+1)})$ for any integer $\beta\ge 1$. This matches our upper bound for $\beta=2$ up to logarithmic factors. Furthermore, we validated the effectiveness of our policy through a comprehensive numerical study using real-world click-through rate data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12366v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Su Jia, Qian Xie, Nathan Kallus, Peter I. Frazier</dc:creator>
    </item>
    <item>
      <title>Model-Agnostic Covariate-Assisted Inference on Partially Identified Causal Effects</title>
      <link>https://arxiv.org/abs/2310.08115</link>
      <description>arXiv:2310.08115v2 Announce Type: replace-cross 
Abstract: Many causal estimands are only partially identifiable since they depend on the unobservable joint distribution between potential outcomes. Stratification on pretreatment covariates can yield sharper bounds; however, unless the covariates are discrete with relatively small support, this approach typically requires binning covariates or estimating the conditional distributions of the potential outcomes given the covariates. Binning can result in substantial efficiency loss and become challenging to implement, even with a moderate number of covariates. Estimating conditional distributions, on the other hand, may yield invalid inference if the distributions are inaccurately estimated, such as when a misspecified model is used or when the covariates are high-dimensional. In this paper, we propose a unified and model-agnostic inferential approach for a wide class of partially identified estimands. Our method, based on duality theory for optimal transport problems, has four key properties. First, in randomized experiments, our approach can wrap around any estimates of the conditional distributions and provide uniformly valid inference, even if the initial estimates are arbitrarily inaccurate. A simple extension of our method to observational studies is doubly robust in the usual sense. Second, if nuisance parameters are estimated at semiparametric rates, our estimator is asymptotically unbiased for the sharp partial identification bound. Third, we can apply the multiplier bootstrap to select covariates and models without sacrificing validity, even if the true model is not selected. Finally, our method is computationally efficient. Overall, in three empirical applications, our method consistently reduces the width of estimated identified sets and confidence intervals without making additional structural assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08115v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Ji, Lihua Lei, Asher Spector</dc:creator>
    </item>
    <item>
      <title>Bayesian Quantile Regression with Subset Selection: A Decision Analysis Perspective</title>
      <link>https://arxiv.org/abs/2311.02043</link>
      <description>arXiv:2311.02043v4 Announce Type: replace-cross 
Abstract: Quantile regression is a powerful tool for inferring how covariates affect specific percentiles of the response distribution. Existing methods either estimate conditional quantiles separately for each quantile of interest or estimate the entire conditional distribution using semi- or non-parametric models. The former often produce inadequate models for real data and do not share information across quantiles, while the latter are characterized by complex and constrained models that can be difficult to interpret and computationally inefficient. Neither approach is well-suited for quantile-specific subset selection. Instead, we pose the fundamental problems of linear quantile estimation, uncertainty quantification, and subset selection from a Bayesian decision analysis perspective. For any Bayesian regression model -- including, but not limited to existing Bayesian quantile regression models -- we derive optimal point estimates, interpretable uncertainty quantification, and scalable subset selection techniques for all model-based conditional quantiles. Our approach introduces a quantile-focused squared error loss that enables efficient, closed-form computing and maintains a close relationship with Wasserstein-based density estimation. In an extensive simulation study, our methods demonstrate substantial gains in quantile estimation accuracy, inference, and variable selection over frequentist and Bayesian competitors. We use these tools to identify and quantify the heterogeneous impacts of multiple social stressors and environmental exposures on educational outcomes across the full spectrum of low-, medium-, and high-achieving students in North Carolina.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02043v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Feldman, Daniel Kowal</dc:creator>
    </item>
    <item>
      <title>Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Linear Regression</title>
      <link>https://arxiv.org/abs/2403.13565</link>
      <description>arXiv:2403.13565v2 Announce Type: replace-cross 
Abstract: We consider the transfer learning problem in the high dimensional linear regression setting, where the feature dimension is larger than the sample size. To learn transferable information, which may vary across features or the source samples, we propose an adaptive transfer learning method that can detect and aggregate the feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable structures. We achieve this by employing a fused-penalty, coupled with weights that can adapt according to the transferable structure. To choose the weight, we propose a theoretically informed, data-driven procedure, enabling F-AdaTrans to selectively fuse the transferable signals with the target while filtering out non-transferable signals, and S-AdaTrans to obtain the optimal combination of information transferred from each source sample. We show that, with appropriately chosen weights, F-AdaTrans achieves a convergence rate close to that of an oracle estimator with a known transferable structure, and S-AdaTrans recovers existing near-minimax optimal rates as a special case. The effectiveness of the proposed method is validated using both simulation and real data, demonstrating favorable performance compared to the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13565v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zelin He, Ying Sun, Jingyuan Liu, Runze Li</dc:creator>
    </item>
    <item>
      <title>Robust Learning for Optimal Dynamic Treatment Regimes with Observational Data</title>
      <link>https://arxiv.org/abs/2404.00221</link>
      <description>arXiv:2404.00221v3 Announce Type: replace-cross 
Abstract: Public policies and medical interventions often involve dynamics in their treatment assignments, where individuals receive a series of interventions over multiple stages. We study the statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's evolving history. We propose a doubly robust, classification-based approach to learning the optimal DTR using observational data under the assumption of sequential ignorability. This approach learns the optimal DTR through backward induction. At each step, it constructs an augmented inverse probability weighting (AIPW) estimator of the policy value function and maximizes it to learn the optimal policy for the corresponding stage. We show that the resulting DTR can achieve an optimal convergence rate of $n^{-1/2}$ for welfare regret under mild convergence conditions on estimators of the nuisance components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00221v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shosei Sakaguchi</dc:creator>
    </item>
    <item>
      <title>4+3 Phases of Compute-Optimal Neural Scaling Laws</title>
      <link>https://arxiv.org/abs/2405.15074</link>
      <description>arXiv:2405.15074v2 Announce Type: replace-cross 
Abstract: We consider the solvable neural scaling model with three parameters: data complexity, target complexity, and model-parameter-count. We use this neural scaling model to derive new predictions about the compute-limited, infinite-data scaling law regime. To train the neural scaling model, we run one-pass stochastic gradient descent on a mean-squared loss. We derive a representation of the loss curves which holds over all iteration counts and improves in accuracy as the model parameter count grows. We then analyze the compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in the data-complexity/target-complexity phase-plane. The phase boundaries are determined by the relative importance of model capacity, optimizer noise, and embedding of the features. We furthermore derive, with mathematical proof and extensive numerical evidence, the scaling-law exponents in all of these phases, in particular computing the optimal model-parameter-count as a function of floating point operation budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15074v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elliot Paquette, Courtney Paquette, Lechao Xiao, Jeffrey Pennington</dc:creator>
    </item>
    <item>
      <title>From Optimization to Sampling via Lyapunov Potentials</title>
      <link>https://arxiv.org/abs/2410.02979</link>
      <description>arXiv:2410.02979v2 Announce Type: replace-cross 
Abstract: We study the problem of sampling from high-dimensional distributions using Langevin Dynamics, a natural and popular variant of Gradient Descent where at each step, appropriately scaled Gaussian noise is added. The similarities between Langevin Dynamics and Gradient Flow and Gradient Descent leads to the natural question: if the distribution's log-density can be optimized from all initializations via Gradient Flow and Gradient Descent, given oracle access to the gradients, can we efficiently sample from the distribution using discrete-time Langevin Dynamics? We answer this question in the affirmative for distributions that are unimodal in a particular sense, at low but appropriate temperature levels natural in the context of both optimization and real-world applications, under mild regularity assumptions on the measure and the convergence rate of Gradient Flow. We do so by using the results of De Sa, Kale, Lee, Sekhari, and Sridharan (2022) that the success of optimization implies particular geometric properties involving a \textit{Lyapunov Potential}. These geometric properties from optimization in turn give us strong quantitative control over isoperimetric constants of the measure. As a corollary, we show we can efficiently sample from several new natural and interesting classes of non-log-concave densities, an important setting where we have relatively few examples. Another corollary is efficient discrete-time sampling results for log-concave measures satisfying milder regularity conditions than smoothness, results similar to the work of Lehec (2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02979v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>August Y. Chen, Karthik Sridharan</dc:creator>
    </item>
  </channel>
</rss>
