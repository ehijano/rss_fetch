<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 01:46:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fundamental Limits of Coded Caching with Fixed Subpacketization</title>
      <link>https://arxiv.org/abs/2510.22145</link>
      <description>arXiv:2510.22145v1 Announce Type: new 
Abstract: Coded caching is a promising technique to create coded multicast opportunities for cache-aided networks. By splitting each file into $F$ equal packets (i.e., the subpacketization level $F$) and letting each user cache a set of packets, the transmission load can be significantly reduced via coded multicasting. It has been shown that a higher subpacketization level could potentially lead to a lower transmission load, as more packets can be combined for efficient transmission. On the other hand, a larger $F$ indicates a higher coding complexity and is problematic from a practical perspective when $F$ is extremely large. Despite many works attempting to design coded caching schemes with low subpacketization levels, a fundamental problem remains open: What is the minimum transmission load given any fixed subpacketization level? In this paper, we consider the classical cache-aided networks with identically uncoded placement and one-shot delivery strategy, and investigate the fundamental trade-off between the transmission load and the subpacketization level. We propose a \emph{general} lower bound on the transmission load for any fixed subpacketization by reformulating the centralized coded caching schemes via the combinatorial structure of the corresponding placement delivery array. The lower bound also recovers existing optimality results for the bipartite graph scheme (including the well-known Maddah-Ali and Niesen (MN) scheme and the conjugate MN scheme) as well as the grouping bipartite graph scheme. Furthermore, by carefully exploiting the combinatorial structure and computing the union size of sorted sets, we establish a new optimality result, i.e., the partition scheme can achieve the optimal rate-subpacketization trade-off.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22145v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minquan Cheng, Yifei Huang, Youlong Wu, Jinyan Wang</dc:creator>
    </item>
    <item>
      <title>Robust MIMO Channel Estimation Using Energy-Based Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2510.22230</link>
      <description>arXiv:2510.22230v1 Announce Type: new 
Abstract: Channel estimation for massive multiple-input multiple-output (MIMO) systems is fundamentally constrained by excessive pilot overhead and high estimation latency. To overcome these obstacles, recent studies have leveraged deep generative networks to capture the prior distribution of wireless channels. In this paper, we propose a novel estimation framework that integrates an energy-based generative diffusion model (DM) with the Metropolis-Hastings (MH) principle. By reparameterizing the diffusion process with an incorporated energy function, the framework explicitly estimates the unnormalized log-prior, while MH corrections refine the sampling trajectory, mitigate deviations, and enhance robustness, ultimately enabling accurate posterior sampling for high-fidelity channel estimation. Numerical results reveal that the proposed approach significantly improves estimation accuracy compared with conventional parameterized DMs and other baseline methods, particularly in cases with limited pilot overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22230v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqi Diao, Xingyu Zhou, Le Liang, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Infinitely many families of distance-optimal binary linear codes with respect to the sphere packing bound</title>
      <link>https://arxiv.org/abs/2510.22259</link>
      <description>arXiv:2510.22259v1 Announce Type: new 
Abstract: R. W. Hamming published the Hamming codes and the sphere packing bound in 1950. In the past 75 years, infinite families of distance-optimal linear codes over finite fields with minimum distance at most 8 with respect to the sphere packing bound have been reported in the literature. However, it is a 75-year-old open problem in coding theory whether there is an infinite family of distance-optimal linear codes over finite fields with arbitrarily large minimum distance with respect to the sphere packing bound. This main objective of this paper is to settle this long-standing open problem in coding theory.
  As by-products, several infinite families of distance-optimal binary codes with small minimum distances are presented. Two infinite families of binary five-weight codes are reported. Some open problems are also proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22259v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hao Chen, Conghui Xie, Cunsheng Ding</dc:creator>
    </item>
    <item>
      <title>Optimal Sampling and Scheduling for Remote Fusion Estimation of Correlated Wiener Processes</title>
      <link>https://arxiv.org/abs/2510.22288</link>
      <description>arXiv:2510.22288v1 Announce Type: new 
Abstract: In distributed sensor networks, sensors often observe a dynamic process within overlapping regions. Due to random delays, these correlated observations arrive at the fusion center asynchronously, raising a central question: How can one fuse asynchronous yet correlated information for accurate remote fusion estimation? This paper addresses this challenge by studying the joint design of sampling, scheduling, and estimation policies for monitoring a correlated Wiener process. Though this problem is coupled, we establish a separation principle and identify the joint optimal policy: the optimal fusion estimator is a weighted-sum fusion estimator conditioned on Age of Information (AoI), the optimal scheduler is a Maximum Age First (MAF) scheduler that prioritizes the most stale source, and the optimal sampling can be designed given the optimal estimator and the MAF scheduler. To design the optimal sampling, we show that, under the infinite-horizon average-cost criterion, optimizing AoI is equivalent to optimizing MSE under pull-based communications, despite the presence of strong inter-sensor correlations. This structural equivalence allows us to identify the MSE-optimal sampler as one that is AoI-optimal. This result underscores an insight: information freshness can serve as a design surrogate for optimal estimation in correlated sensing environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22288v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aimin Li, Elif Uysal</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient UAV-Enabled MEC Systems: NOMA, FDMA, or TDMA Offloading?</title>
      <link>https://arxiv.org/abs/2510.22306</link>
      <description>arXiv:2510.22306v1 Announce Type: new 
Abstract: Unmanned aerial vehicle (UAV)-enabled mobile edge computing (MEC) systems can use different multiple access schemes to coordinate multi-user task offloading. However, it is still unknown which scheme is the most energy-efficient, especially when the offloading blocklength is finite. To answer this question, this paper minimizes and compares the MEC-related energy consumption of non-orthogonal multiple access (NOMA), frequency division multiple access (FDMA), and time division multiple access (TDMA)-based offloading schemes within UAV-enabled MEC systems, considering both infinite and finite blocklength scenarios. Through theoretically analysis of the minimum energy consumption required by these three schemes, two novel findings are presented. First, TDMA consistently achieves lower energy consumption than FDMA in both infinite and finite blocklength cases, due to the degrees of freedom afforded by sequential task offloading. Second, NOMA does not necessarily achieve lower energy consumption than FDMA when the offloading blocklength is finite, especially when the channel conditions and the offloaded task data sizes of two user equipments (UEs) are relatively symmetric. Furthermore, an alternating optimization algorithm that jointly optimizes the portions of task offloaded, the offloading times of all UEs, and the UAV location is proposed to solve the formulated energy consumption minimization problems. Simulation results verify the correctness of our analytical findings and demonstrate that the proposed algorithm effectively reduces MEC-related energy consumption compared to benchmark schemes that do not optimize task offloading portions and/or offloading times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22306v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingjie Wu, Miao Cui, Guangchi Zhang, Beixiong Zheng, Xiaoli Chu, Qingqing Wu</dc:creator>
    </item>
    <item>
      <title>Resource Allocation for XR with Edge Offloading: A Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2510.22505</link>
      <description>arXiv:2510.22505v1 Announce Type: new 
Abstract: Future immersive XR applications will require energy-efficient, high data rate, and low-latency wireless communications in uplink and downlink. One of the key considerations for supporting such XR applications is intelligent and adaptive resource allocation with edge offloading. To address these demands, this paper proposes a reinforcement learning-based resource allocation framework that dynamically allocates uplink and downlink slots while making offloading decisions based on the XR headset's capabilities and network conditions. The paper presents a numerical analysis of the tradeoff between frame loss rate (FLR) and energy efficiency, identifying decision regions for partial offloading to optimize performance. Results show that for the used set of system parameters, partial offloading can extend the coverage area by 55% and reduce energy consumption by up to 34%, compared to always or never offloading. The results demonstrate that the headset's local computing capability plays a crucial role in offloading decisions. Higher computing abilities enable more efficient local processing, reduce the need for offloading, and enhance energy savings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22505v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alperen Duru, Mohammad Mozaffari, Ticao Zhang, Mehrnaz Afshang</dc:creator>
    </item>
    <item>
      <title>End-to-end Learning of Probabilistic and Geometric Constellation Shaping with Iterative Receivers</title>
      <link>https://arxiv.org/abs/2510.22608</link>
      <description>arXiv:2510.22608v1 Announce Type: new 
Abstract: An end-to-end learning method for constellation shaping with a shaping-encoder assisted transceiver architecture is presented. The shaping encoder, which produces shaping bits with a higher probability of zeros, is used to produce an efficient symbol probability distribution. Both the probability distribution and the constellation geometry are jointly optimized, using end-to-end learning. Optimized constellations are evaluated using two iterative receiver architectures. Bit error rate (BER) performance gain is quantified against standard amplitude phase-shift keying (APSK) and quadrature amplitude modulation (QAM) constellations. A maximum BER gain of 0.3 dB and 0.15 dB are observed under two receivers for the learned constellations compared to standard APSK or QAM. The basic approach is extended to incorporate the full iterative detection and decoding loop, using the deep unfolding technique. A bit error rate gain of 0.1 dB is observed for the iterative scheme with learned constellations under block fading channel conditions, when compared to standard APSK.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22608v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harindu Jayarathne, Dileepa Marasinghe, Nandana Rajatheva, Matti Latva-aho</dc:creator>
    </item>
    <item>
      <title>Graph-Theoretic Characterization of Noise Capacity of Conditional Disclosure of Secrets</title>
      <link>https://arxiv.org/abs/2510.22671</link>
      <description>arXiv:2510.22671v1 Announce Type: new 
Abstract: In the problem of conditional disclosure of secrets (CDS), two parties, Alice and Bob, each has an input and shares a common secret. Their goal is to reveal the secret to a third party, Carol, as efficiently as possible, only if the inputs of Alice and Bob satisfy a certain functional relation $f $. To prevent leakage of the secret to Carol when the input combination is unqualified, both Alice and Bob introduce noise. This work aims to determine the noise capacity, defined as the maximum number of secret bits that can be securely revealed to Carol, normalized by the total number of independent noise bits held jointly by Alice and Bob. Our contributions are twofold. First, we establish the necessary and sufficient conditions under which the CDS noise capacity attains its maximum value of $1$. Second, in addition to the above best-case scenarios, we derive an upper bound on the linear noise capacity for any CDS instance. In particular, this upper bound is equal to $(\rho-1)(d-1)/(\rho d-1)$, where $\rho$ is the covering parameter of the graph representation of $f$, and $d$ is the number of unqualified edges in residing unqualified path.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22671v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhou Li, Siyan Qin, Xiang Zhang, Jihao Fan, Haiqiang Chen, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication</title>
      <link>https://arxiv.org/abs/2510.22718</link>
      <description>arXiv:2510.22718v1 Announce Type: new 
Abstract: Gaussian splatting (GS) struggles with degraded rendering quality on low-cost devices. To address this issue, we present edge collaborative GS (ECO-GS), where each user can switch between a local small GS model to guarantee timeliness and a remote large GS model to guarantee fidelity. However, deciding how to engage the large GS model is nontrivial, due to the interdependency between rendering requirements and resource conditions. To this end, we propose integrated rendering and communication (IRAC), which jointly optimizes collaboration status (i.e., deciding whether to engage large GS) and edge power allocation (i.e., enabling remote rendering) under communication constraints across different users by minimizing a newly-derived GS switching function. Despite the nonconvexity of the problem, we propose an efficient penalty majorization minimization (PMM) algorithm to obtain the critical point solution. Furthermore, we develop an imitation learning optimization (ILO) algorithm, which reduces the computational time by over 100x compared to PMM. Experiments demonstrate the superiority of PMM and the real-time execution capability of ILO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22718v1</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Wan, Chenxuan Liu, Shuai Wang, Tong Zhang, James Jianqiao Yu, Kejiang Ye, Dusit Niyato, Chengzhong Xu</dc:creator>
    </item>
    <item>
      <title>On the Arikan Transformations of Binary-Input Discrete Memoryless Channels</title>
      <link>https://arxiv.org/abs/2510.22896</link>
      <description>arXiv:2510.22896v1 Announce Type: new 
Abstract: The polar codes introduced by Arikan in 2009 achieve the capacity of binary-input discrete memoryless channels (BIDMCs) with low complexity encoding and decoding. Identifying the unreliable synthetic channels, generated by Arikan transformation during the construction of these polar codes, is crucial. Currently, because of the large size of the output alphabets of synthetic channels, there is no efficient and practical approach to evaluate their reliability in general. To tackle this problem, by converting the generation of synthetic channels in polar code construction into algebraic operations, in this paper we develop a method to characterize the synthetic channels as random switching channels of binary symmetric channels when the underlying channels are symmetric. Moreover, a lower bound for the average number of elements that possess the same likelihood ratio within the output alphabet of any synthetic channel generated in polar codes is also derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22896v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yadong Jiao, Xiaoyan Cheng, Yuansheng Tang, Ming Xu</dc:creator>
    </item>
    <item>
      <title>On the use of information fusion techniques to improve information quality: Taxonomy, opportunities and challenges</title>
      <link>https://arxiv.org/abs/2510.23230</link>
      <description>arXiv:2510.23230v1 Announce Type: new 
Abstract: The information fusion field has recently been attracting a lot of interest within the scientific community, as it provides, through the combination of different sources of heterogeneous information, a fuller and/or more precise understanding of the real world than can be gained considering the above sources separately. One of the fundamental aims of computer systems, and especially decision support systems, is to assure that the quality of the information they process is high. There are many different approaches for this purpose, including information fusion. Information fusion is currently one of the most promising methods. It is particularly useful under circumstances where quality might be compromised, for example, either intrinsically due to imperfect information (vagueness, uncertainty) or because of limited resources (energy, time). In response to this goal, a wide range of research has been undertaken over recent years. To date, the literature reviews in this field have focused on problem-specific issues and have been circumscribed to certain system types. Therefore, there is no holistic and systematic knowledge of the state of the art to help establish the steps to be taken in the future. In particular, aspects like what impact different information fusion methods have on information quality, how information quality is characterised, measured and evaluated in different application domains depending on the problem data type or whether fusion is designed as a flexible process capable of adapting to changing system circumstances and their intrinsically limited resources have not been addressed. This paper aims precisely to review the literature on research into the use of information fusion techniques specifically to improve information quality, analysing the above issues in order to identify a series of challenges and research directions, which are presented in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23230v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.inffus.2021.09.017</arxiv:DOI>
      <arxiv:journal_reference>Information Fusion, 78, 102-137; 2022</arxiv:journal_reference>
      <dc:creator>Ra\'ul Guti\'errez, V\'ictor Ramp\'erez, Horacio Paggi, Juan A. Lara, Javier Soriano</dc:creator>
    </item>
    <item>
      <title>Pinching-antenna-enabled Federated Learning: Tail Latency, Participation, and Convergence Analysis</title>
      <link>https://arxiv.org/abs/2510.23315</link>
      <description>arXiv:2510.23315v1 Announce Type: new 
Abstract: Federated learning (FL) in wireless networks is limited by straggler delays from unpredictable channel conditions. In this paper, we investigate the pinching-antenna system (PASS), which dynamically 'pinches' the radiator along a dielectric waveguide to shorten the worst links. In synchronous FL (SFL), we prove that PASS shortens the worst-link distance, and it increases the on-time completion probability in asynchronous FL (AFL). Accordingly, SFL exhibits stochastic dominance on round time, while AFL yields explicit latency and participation gains. We then pair physical-layer (PHY)-aware sampling with error-feedback compression and prove that pinching raises the minimum inclusion probability, thus shrinking both the sampling variability and compression-induced floors in a Lyapunov analysis. Simulations demonstrate consistent wall clock speedups and markedly shorter latency tails. By addressing stragglers at their PHY root, PASS complements higher-layer scheduling and accelerates wireless FL in both SFL and AFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23315v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yushen Lin, Zihan Chen, Zhiguo Ding</dc:creator>
    </item>
    <item>
      <title>Efficient Repair of (k+2, k) Degraded Read Friendly MDS Array Codes With Sub-packetization 2</title>
      <link>https://arxiv.org/abs/2510.23316</link>
      <description>arXiv:2510.23316v1 Announce Type: new 
Abstract: In this paper, we present two constructions of degraded read friendly (DRF) MDS array codes with two parity nodes and a sub-packetization level of 2 over small finite fields, applicable for any arbitrary code length. The first construction achieves the smallest repair bandwidth among all existing constructions with the same parameters, and is asymptotically optimal with respect to the lower bound on the average repair bandwidth characterized by Zhang et al. The second construction supports two repair mechanisms, depending on whether computation within the helper nodes is permitted or not during the node repair process, thereby optimizing either the repair bandwidth or the rebuilding access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23316v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Li, Xiaohu Tang</dc:creator>
    </item>
    <item>
      <title>Quantitative Bounds for Sorting-Based Permutation-Invariant Embeddings</title>
      <link>https://arxiv.org/abs/2510.22186</link>
      <description>arXiv:2510.22186v1 Announce Type: cross 
Abstract: We study the sorting-based embedding $\beta_{\mathbf A} : \mathbb R^{n \times d} \to \mathbb R^{n \times D}$, $\mathbf X \mapsto {\downarrow}(\mathbf X \mathbf A)$, where $\downarrow$ denotes column wise sorting of matrices. Such embeddings arise in graph deep learning where outputs should be invariant to permutations of graph nodes. Previous work showed that for large enough $D$ and appropriate $\mathbf A$, the mapping $\beta_{\mathbf A}$ is injective, and moreover satisfies a bi-Lipschitz condition. However, two gaps remain: firstly, the optimal size $D$ required for injectivity is not yet known, and secondly, no estimates of the bi-Lipschitz constants of the mapping are known.
  In this paper, we make substantial progress in addressing both of these gaps. Regarding the first gap, we improve upon the best known upper bounds for the embedding dimension $D$ necessary for injectivity, and also provide a lower bound on the minimal injectivity dimension. Regarding the second gap, we construct matrices $\mathbf A$, so that the bi-Lipschitz distortion of $\beta_{\mathbf A} $ depends quadratically on $n$, and is completely independent of $d$. We also show that the distortion of $\beta_{\mathbf A}$ is necessarily at least in $\Omega(\sqrt{n})$. Finally, we provide similar results for variants of $\beta_{\mathbf A}$ obtained by applying linear projections to reduce the output dimension of $\beta_{\mathbf A}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22186v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.MG</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadav Dym, Matthias Wellershoff, Efstratios Tsoukanis, Daniel Levy, Radu Balan</dc:creator>
    </item>
    <item>
      <title>The Lossy Horizon: Error-Bounded Predictive Coding for Lossy Text Compression (Episode I)</title>
      <link>https://arxiv.org/abs/2510.22207</link>
      <description>arXiv:2510.22207v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) can achieve near-optimal lossless compression by acting as powerful probability models. We investigate their use in the lossy domain, where reconstruction fidelity is traded for higher compression ratios. This paper introduces Error-Bounded Predictive Coding (EPC), a lossy text codec that leverages a Masked Language Model (MLM) as a decompressor. Instead of storing a subset of original tokens, EPC allows the model to predict masked content and stores minimal, rank-based corrections only when the model's top prediction is incorrect. This creates a residual channel that offers continuous rate-distortion control. We compare EPC to a simpler Predictive Masking (PM) baseline and a transform-based Vector Quantisation with a Residual Patch (VQ+RE) approach. Through an evaluation that includes precise bit accounting and rate-distortion analysis, we demonstrate that EPC consistently dominates PM, offering superior fidelity at a significantly lower bit rate by more efficiently utilising the model's intrinsic knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22207v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nnamdi Aghanya, Jun Li, Kewei Wang</dc:creator>
    </item>
    <item>
      <title>Monitoring State Transitions in Markovian Systems with Sampling Cost</title>
      <link>https://arxiv.org/abs/2510.22327</link>
      <description>arXiv:2510.22327v1 Announce Type: cross 
Abstract: We consider a node-monitor pair, where the node's state varies with time. The monitor needs to track the node's state at all times; however, there is a fixed cost for each state query. So the monitor may instead predict the state using time-series forecasting methods, including time-series foundation models (TSFMs), and query only when prediction uncertainty is high. Since query decisions influence prediction accuracy, determining when to query is nontrivial. A natural approach is a greedy policy that predicts when the expected prediction loss is below the query cost and queries otherwise. We analyze this policy in a Markovian setting, where the optimal (OPT) strategy is a state-dependent threshold policy minimizing the time-averaged sum of query cost and prediction losses. We show that, in general, the greedy policy is suboptimal and can have an unbounded competitive ratio, but under common conditions such as identically distributed transition probabilities, it performs close to OPT. For the case of unknown transition probabilities, we further propose a projected stochastic gradient descent (PSGD)-based learning variant of the greedy policy, which achieves a favorable predict-query tradeoff with improved computational efficiency compared to OPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22327v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kumar Saurav, Ness B. Shroff, Yingbin Liang</dc:creator>
    </item>
    <item>
      <title>A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior</title>
      <link>https://arxiv.org/abs/2510.22501</link>
      <description>arXiv:2510.22501v1 Announce Type: cross 
Abstract: In this paper, we introduce the SDIR (Susceptible-Delayable-Infected-Recovered) model, an extension of the classical SIR epidemic framework, to provide a more explicit characterization of user behavior in online social networks. The newly merged state D (delayable) represents users who have received the information but delayed its spreading and may eventually choose not to share it at all. Based on the mean-field approximation method, we derive the dynamical equations of the model and investigate its convergence and stability conditions. Under these conditions, we further propose an approximation algorithm for the edge-deletion problem, aiming to minimize the influence of information diffusion by identifying approximate solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22501v1</guid>
      <category>cs.SI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tran Van Khanh, Do Xuan Cho, Hoang Phi Dung</dc:creator>
    </item>
    <item>
      <title>Instance optimality in phase retrieval</title>
      <link>https://arxiv.org/abs/2510.22578</link>
      <description>arXiv:2510.22578v1 Announce Type: cross 
Abstract: Compressed sensing has demonstrated that a general signal $\boldsymbol{x} \in \mathbb{F}^n$ ($\mathbb{F}\in \{\mathbb{R},\mathbb{C}\}$) can be estimated from few linear measurements with an error {proportional to} the best $k$-term approximation error, a property known as instance optimality. In this paper, we investigate instance optimality in the context of phaseless measurements using the $\ell_p$-minimization decoder, where $p \in (0, 1]$, for both real and complex cases. More specifically, we prove that $(2,1)$ and $(1,1)$-instance optimality of order $k$ can be achieved with $m =O(k \log(n/k))$ phaseless measurements, paralleling results from linear measurements. These results imply that one can stably recover approximately $k$-sparse signals from $m = O(k \log(n/k))$ phaseless measurements. Our approach leverages the phaseless bi-Lipschitz condition. Additionally, we present a non-uniform version of $(2,2)$-instance optimality result in probability applicable to any fixed vector $\boldsymbol{x} \in \mathbb{F}^n$. These findings reveal striking parallels between compressive phase retrieval and classical compressed sensing, enhancing our understanding of both phase retrieval and instance optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22578v1</guid>
      <category>math.FA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.acha.2025.101818</arxiv:DOI>
      <dc:creator>Yu Xia, Zhiqiang Xu</dc:creator>
    </item>
    <item>
      <title>The Gravitational Aspect of Information: The Physical Reality of Asymmetric "Distance"</title>
      <link>https://arxiv.org/abs/2510.22664</link>
      <description>arXiv:2510.22664v1 Announce Type: cross 
Abstract: We demonstrate that when a Brownian bridge is physically constrained to be canonical, its time evolution becomes identical to an m-geodesic on the statistical manifold of Gaussian distributions. This finding provides strong evidence that, akin to general relativity where free particles follow geodesics, purely random processes also follow ``straight lines" defined by the geometry of information. This geometric principle is a direct consequence of the dually flat structure inherent to information geometry, originating from the asymmetry of informational ``distance" (divergence) leading to the violation of metric compatibility. Our results suggest a geometric foundation for randomness and open the door to an equivalence principle for information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22664v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>gr-qc</category>
      <category>hep-ph</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>quant-ph</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoi Koide, Armin van de Venn</dc:creator>
    </item>
    <item>
      <title>Approximate Signed Multiplier with Sign-Focused Compressor for Edge Detection Applications</title>
      <link>https://arxiv.org/abs/2510.22674</link>
      <description>arXiv:2510.22674v1 Announce Type: cross 
Abstract: This paper presents an approximate signed multiplier architecture that incorporates a sign-focused compressor, specifically designed for edge detection applications in machine learning and signal processing. The multiplier incorporates two types of sign-focused compressors: A + B + C + 1 and A + B + C + D + 1. Both exact and approximate compressor designs are utilized, with a focus on efficiently handling constant value "1" and negative partial products, which frequently appear in the partial product matrices of signed multipliers. To further enhance efficiency, the lower N - 1 columns of the partial product matrix are truncated, followed by an error compensation mechanism. Experimental results show that the proposed 8-bit approximate multiplier achieves a 29.21% reduction in power delay product (PDP) and a 14.39% reduction in power compared to the best of existing multipliers. The proposed multiplier is integrated into a custom convolution layer and performs edge detection, demonstrating its practical utility in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22674v1</guid>
      <category>cs.AR</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Hemanth Krishna, Srinivasu Bodapati, Sreehari Veeramachaneni, BhaskaraRao Jammu, Noor Mahammad Sk</dc:creator>
    </item>
    <item>
      <title>Reducing measurements in quantum erasure correction by quantum local recovery</title>
      <link>https://arxiv.org/abs/2510.22890</link>
      <description>arXiv:2510.22890v1 Announce Type: cross 
Abstract: As measurements are costly and prone to errors on certain quantum computing devices, we should reduce the number of measurements and the number of measured qudits as small as possible in quantum erasure correction. It is intuitively obvious that a decoder can omit measurements of stabilizers that are irrelevant to erased qudits, but this intuition has not been rigorously formalized as far as the author is aware. In this paper, we formalize relevant stabilizers sufficient to correct erased qudits with a quantum stabilizer code, by using a recent idea from quantum local recovery. The minimum required number of measuring stabilizer observables is also clarified, which looks similar to the dimension length profile of classical linear codes. As an application, we also show that correction of $\delta$ erasures on a generalized surface code proposed by Delfosse, Iyer and Poulin requires at most $\delta$ measurements of vertexes and at most $\delta$ measurements of faces, independently of its code parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22890v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryutaroh Matsumoto</dc:creator>
    </item>
    <item>
      <title>Noisy nonlinear information and entropy numbers</title>
      <link>https://arxiv.org/abs/2510.23213</link>
      <description>arXiv:2510.23213v1 Announce Type: cross 
Abstract: It is impossible to recover a vector from $\mathbb{R}^m$ with less than $m$ linear measurements, even if the measurements are chosen adaptively. Recently, it has been shown that one can recover vectors from $\mathbb{R}^m$ with arbitrary precision using only $O(\log m)$ continuous (even Lipschitz) adaptive measurements, resulting in an exponential speed-up of continuous information compared to linear information for various approximation problems. In this note, we characterize the quality of optimal (dis-)continuous information that is disturbed by deterministic noise in terms of entropy numbers. This shows that in the presence of noise the potential gain of continuous over linear measurements is limited, but significant in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23213v1</guid>
      <category>math.NA</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Krieg, Erich Novak, Leszek Plaskota, Mario Ullrich</dc:creator>
    </item>
    <item>
      <title>Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization</title>
      <link>https://arxiv.org/abs/2510.23485</link>
      <description>arXiv:2510.23485v1 Announce Type: cross 
Abstract: In this paper, we leverage stochastic projection and lossy compression to establish new conditional mutual information (CMI) bounds on the generalization error of statistical learning algorithms. It is shown that these bounds are generally tighter than the existing ones. In particular, we prove that for certain problem instances for which existing MI and CMI bounds were recently shown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to describe the right generalization behavior, our bounds yield suitable generalization guarantees of the order of $\mathcal{O}(1/\sqrt{n})$, where $n$ is the size of the training dataset. Furthermore, we use our bounds to investigate the problem of data "memorization" raised in those works, and which asserts that there are learning problem instances for which any learning algorithm that has good prediction there exist distributions under which the algorithm must "memorize" a big fraction of the training dataset. We show that for every learning algorithm, there exists an auxiliary algorithm that does not memorize and which yields comparable generalization error for any data distribution. In part, this shows that memorization is not necessary for good generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23485v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Sefidgaran, Kimia Nadjahi, Abdellatif Zaidi</dc:creator>
    </item>
    <item>
      <title>A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off Perspective</title>
      <link>https://arxiv.org/abs/2510.23507</link>
      <description>arXiv:2510.23507v1 Announce Type: cross 
Abstract: Fair graph clustering seeks partitions that respect network structure while maintaining proportional representation across sensitive groups, with applications spanning community detection, team formation, resource allocation, and social network analysis. Many existing approaches enforce rigid constraints or rely on multi-stage pipelines (e.g., spectral embedding followed by $k$-means), limiting trade-off control, interpretability, and scalability. We introduce \emph{DFNMF}, an end-to-end deep nonnegative tri-factorization tailored to graphs that directly optimizes cluster assignments with a soft statistical-parity regularizer. A single parameter $\lambda$ tunes the fairness--utility balance, while nonnegativity yields parts-based factors and transparent soft memberships. The optimization uses sparse-friendly alternating updates and scales near-linearly with the number of edges. Across synthetic and real networks, DFNMF achieves substantially higher group balance at comparable modularity, often dominating state-of-the-art baselines on the Pareto front. The code is available at https://github.com/SiamakGhodsi/DFNMF.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23507v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siamak Ghodsi, Amjad Seyedi, Tai Le Quy, Fariba Karimi, Eirini Ntoutsi</dc:creator>
    </item>
    <item>
      <title>Pattern Division Random Access (PDRA) for M2M Communications with Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2110.10586</link>
      <description>arXiv:2110.10586v4 Announce Type: replace 
Abstract: In this work, we introduce the pattern-domain pilot design paradigm based on a "superposition of orthogonal-building-blocks" with significantly larger contention space to enhance the massive machine-type communications (mMTC) random access (RA) performance in massive multiple-input multiple-output (MIMO) systems.Specifically, the pattern-domain pilot is constructed based on the superposition of $L$ cyclically-shifted Zadoff-Chu (ZC) sequences. The pattern-domain pilots exhibit zero correlation values between non-colliding patterns from the same root and low correlation values between patterns from different roots. The increased contention space, i.e., from N to $\binom{N}{L}$, where $\binom{N}{L}$ denotes the number of all L-combinations of a set N, and low correlation valueslead to a significantly lower pilot collision probability without compromising excessively on channel estimation performance for mMTC RA in massive MIMO systems.We present the framework and analysis of the RA success probability of the pattern-domain based scheme with massive MIMO systems.Numerical results demonstrate that the proposed pattern division random access (PDRA) scheme achieves an appreciable performance gain over the conventional one,while preserving the existing physical layer virtually unchanged. The extension of the "superposition of orthogonal-building-blocks" scheme to "superposition of quasi-orthogonal-building-blocks" is straightforward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.10586v4</guid>
      <category>cs.IT</category>
      <category>cs.SC</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoming Dai, Tiantian Yan, Qianqian Li, Hua Li, Xiyuan Wang</dc:creator>
    </item>
    <item>
      <title>Exact calculation of quantizer constants for arbitrary lattices</title>
      <link>https://arxiv.org/abs/2211.01987</link>
      <description>arXiv:2211.01987v4 Announce Type: replace 
Abstract: We present an algorithm for the exact computer-aided construction of the Voronoi cells of lattices with known symmetry group. Our algorithm scales better than linearly with the total number of faces and is applicable to dimensions beyond 12, which previous methods could not achieve. The new algorithm is applied to the Coxeter-Todd lattice $K_{12}$ as well as to a family of lattices obtained from laminating $K_{12}$. By optimizing this family, we obtain a new 13-dimensional lattice, whose quantizer constant is smaller than any published at the time of submission. (For subsequent improvements, see Note added in proof after the Conclusions.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01987v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.MG</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4310/BPAM.250918173055</arxiv:DOI>
      <dc:creator>Daniel Pook-Kolb, Bruce Allen, Erik Agrell</dc:creator>
    </item>
    <item>
      <title>Global Optimal Closed-Form Solutions for Intelligent Surfaces With Mutual Coupling: Is Mutual Coupling Detrimental or Beneficial?</title>
      <link>https://arxiv.org/abs/2411.04949</link>
      <description>arXiv:2411.04949v2 Announce Type: replace 
Abstract: Reconfigurable Intelligent Surface (RIS) is a breakthrough technology enabling the dynamic control of the propagation environment in wireless communications through programmable surfaces. To improve the flexibility of conventional diagonal RIS (D-RIS), beyond diagonal RIS (BD-RIS) has emerged as a family of more general RIS architectures. However, D-RIS and BD-RIS have been commonly explored neglecting mutual coupling effects, while the global optimization of RIS with mutual coupling, its performance limits, and scaling laws remain unexplored. This study addresses these gaps by deriving global optimal closed-form solutions for BD-RIS with mutual coupling to maximize the channel gain, specifically fully- and tree-connected RISs. Besides, we provide the expression of the maximum channel gain achievable in the presence of mutual coupling and its scaling law in closed form. By using the derived scaling laws, we analytically prove that mutual coupling increases the channel gain on average under Rayleigh fading channels. Our theoretical analysis, confirmed by numerical simulations, shows that both fully- and tree-connected RISs with mutual coupling achieve the same channel gain upper bound when optimized with the proposed global optimal solutions. Furthermore, we observe that a mutual coupling-unaware optimization of RIS can cause a channel gain degradation of up to 5 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04949v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Hongyu Li, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Physics-Compliant Modeling and Scaling Laws of Multi-RIS Aided MIMO Systems</title>
      <link>https://arxiv.org/abs/2411.06309</link>
      <description>arXiv:2411.06309v2 Announce Type: replace 
Abstract: Reconfigurable intelligent surface (RIS) enables the control of wireless channels to improve coverage. To further extend coverage, multi-RIS aided systems have been explored, where multiple RISs steer the signal via a multi-hop path. However, deriving a physics-compliant channel model for multi-RIS aided systems is still an open problem. In this study, we fill this gap by modeling multi-RIS aided systems through multiport network theory, and deriving a channel model accounting for impedance mismatch, mutual coupling, and structural scattering. The derived physics-compliant model differs from the model widely used in literature, which omits the RIS structural scattering. To quantify this difference, we derive the channel gain scaling laws of the two models under line-of-sight (LoS) and multipath channels. Theoretical insights, validated by numerical results, show an important discrepancy between the physics-compliant and the widely used models, increasing with the number of RISs and multipath richness. In a multi-hop system aided by four 128-element RISs with multipath channels, optimizing the RISs using the widely used model and applying their solutions to the physics-compliant model achieves only 7% of the maximum channel gain. This highlights how severely mismatched channel models can be, calling for more accurate models in communication theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06309v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Gabriele Gradoni, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Irregular RIS-aided UAV-Assisted Optimization: A Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2504.15031</link>
      <description>arXiv:2504.15031v2 Announce Type: replace 
Abstract: Reconfigurable intelligent surfaces (RISs) enhance unmanned aerial vehicles (UAV)-assisted communication by extending coverage, improving efficiency, and enabling adaptive beamforming. This paper investigates a multiple-input single-output system where a base station (BS) communicates with multiple single-antenna users through a UAV-assisted RIS, dynamically adapting to user mobility to maintain seamless connectivity. To extend UAV-RIS operational time, we propose a hybrid energy-harvesting resource allocation (HERA) strategy that leverages the irregular RIS ON/OFF capability while adapting to BS-RIS and RIS-user channels. The HERA strategy dynamically allocates resources by integrating non-linear radio frequency energy harvesting (EH) based on the time-switching (TS) approach and renewable energy as a complementary source. A non-convex mixed-integer nonlinear programming problem is formulated to maximize EH efficiency while satisfying quality-of-service, power, and energy constraints under channel state information and hardware impairments. The optimization jointly considers BS transmit power, RIS phase shifts, TS factor, and RIS element selection as decision variables. To solve this problem, we introduce the energy-efficient deep deterministic policy gradient (EE-DDPG) algorithm. This deep reinforcement learning (DRL)-based approach integrates action clipping and softmax-weighted Q-value estimation to mitigate estimation errors. Simulation results demonstrate that the proposed HERA method significantly improves EH efficiency, reaching up to 81.5\% and 73.2\% in single-user and multi-user scenarios, respectively, contributing to extended UAV operational time. Additionally, the proposed EE-DDPG model outperforms existing DRL algorithms while maintaining practical computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15031v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud M. Salim, Khaled M. Rabie, Ali H. Muqaibel</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient UAV-Mounted RIS for IoT: A Hybrid Energy Harvesting and DRL Approach</title>
      <link>https://arxiv.org/abs/2504.15043</link>
      <description>arXiv:2504.15043v2 Announce Type: replace 
Abstract: Many future Internet of Things (IoT) applications are expected to rely heavily on reconfigurable intelligent surface (RIS)-aided unmanned aerial vehicles (UAVs). However, the endurance of such systems is constrained by the limited onboard energy, where frequent recharging or battery replacements are required. This consequently disrupts continuous operation and may be impractical in disaster scenarios. To address this challenge, we explore a dual energy harvesting (EH) framework that integrates time-switching (TS), power-splitting (PS), and element-splitting (ES) EH protocols for radio frequency energy, along with solar energy as a renewable source. First, we present the proposed system architecture and EH operating protocols, introducing the proposed hybrid ES-TS-PS EH strategy to extend UAV-mounted RIS endurance. Next, we outline key application scenarios and the associated design challenges. After that, a deep reinforcement learning-based framework is introduced to maximize the EH efficiency by jointly optimizing UAV trajectory, RIS phase shifts, and EH strategies. The framework considers dual EH, hardware impairments, and channel state information imperfections to reflect real-world deployment conditions. The optimization problem is formulated as a Markov decision process and solved using an enhanced deep deterministic policy gradient algorithm, incorporating clipped double Q-learning and softmax-based Q-value estimation for improved stability and efficiency. The results demonstrate significant performance gains compared to the considered baseline approaches. Finally, possible challenges and open research directions are presented, highlighting the transformative potential of energy-efficient UAV-mounted RIS networks for IoT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15043v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud M. Salim, Khaled M. Rabie, Ali H. Muqaibel</dc:creator>
    </item>
    <item>
      <title>An Information-Theoretic Framework for Receiver Quantization in Communication</title>
      <link>https://arxiv.org/abs/2505.12258</link>
      <description>arXiv:2505.12258v2 Announce Type: replace 
Abstract: We investigate information-theoretic limits and design of communication under receiver quantization. Unlike most existing studies, this work is more focused on the impact of resolution reduction from high to low. We consider a standard transceiver architecture, which includes i.i.d. complex Gaussian codebook at the transmitter, and a symmetric quantizer cascaded with a nearest neighbor decoder at the receiver. Employing the generalized mutual information (GMI), an achievable rate under general quantization rules is obtained in an analytical form, which shows that the rate loss due to quantization is $\log\left(1+\gamma\mathsf{SNR}\right)$, where $\gamma$ is determined by thresholds and levels of the quantizer. Based on this result, the performance under uniform receiver quantization is analyzed comprehensively. We show that the front-end gain control, which determines the loading factor of quantization, has an increasing impact on performance as the resolution decreases. In particular, we prove that the unique loading factor that minimizes the MSE also maximizes the GMI, and the corresponding irreducible rate loss is given by $\log\left(1+\mathsf {mmse}\cdot\mathsf{SNR}\right)$, where mmse is the minimum MSE normalized by the variance of quantizer input, and is equal to the minimum of $\gamma$. A geometrical interpretation for the optimal uniform quantization at the receiver is further established. Moreover, by asymptotic analysis, we characterize the impact of biased gain control, showing how small rate losses decay to zero and providing rate approximations under large bias. From asymptotic expressions of the optimal loading factor and mmse, approximations and several per-bit rules for performance are also provided. Finally we discuss more types of receiver quantization and show that the consistency between achievable rate maximization and MSE minimization does not hold in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12258v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jing Zhou, Shuqin Pang, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Cooperative NOMA Meets Emerging Technologies: A Survey for Next-Generation Wireless Networks</title>
      <link>https://arxiv.org/abs/2505.16327</link>
      <description>arXiv:2505.16327v2 Announce Type: replace 
Abstract: The emerging demands of sixth-generation wireless networks, such as ultra-connectivity, native intelligence, and cross-domain convergence, are bringing renewed focus to cooperative non-orthogonal multiple access (C-NOMA) as a fundamental enabler of scalable, efficient, and intelligent communication systems. C-NOMA builds on the core benefits of NOMA by leveraging user cooperation and relay strategies to enhance spectral efficiency, coverage, and energy performance. This article presents a unified and forward-looking survey on the integration of C-NOMA with key enabling technologies, including radio frequency energy harvesting, cognitive radio networks, reconfigurable intelligent surfaces, space-air-ground integrated networks, and integrated sensing and communication-assisted semantic communication. Foundational principles and relaying protocols are first introduced to establish the technical relevance of C-NOMA. Then, a focused investigation is conducted into protocol-level synergies, architectural models, and deployment strategies across these technologies. Beyond integration, this article emphasizes the orchestration of C-NOMA across future application domains such as digital twins, extended reality, and e-health. In addition, it provides an extensive and in-depth review of recent literature, categorized by relaying schemes, system models, performance metrics, and optimization paradigms, including model-based, heuristic, and AI-driven approaches. Finally, open challenges and future research directions are outlined, spanning standardization, security, and cross-layer design, positioning C-NOMA as a key pillar of intelligent next-generation network architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16327v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud M. Salim, Suhail I. Al-Dharrab, Daniel Benevides Da Costa, Ali H. Muqaibel</dc:creator>
    </item>
    <item>
      <title>Robust and Resilient Networks with Integrated Sensing, Communication and Computation</title>
      <link>https://arxiv.org/abs/2506.19518</link>
      <description>arXiv:2506.19518v2 Announce Type: replace 
Abstract: Emerging applications such as networked robotics, intelligent transportation, smart factories, and virtual and augmented reality demand integrated perception and connectivity enabled by wireless communication. This has driven growing interests in integrated sensing, communication, and computation (ISCC) systems, with a primary focus on their efficient co-designs. However, as ISCC systems increasingly support critical applications, they must not only deliver high performance but also demonstrate robustness and resilience. In this context, robustness refers to a system's ability to maintain performance under uncertainties, while resilience denotes its capacity to sustain a minimum level of service in the face of major disruptions. To address this gap, this article presents an overview of ISCC systems from the perspectives of robustness and resilience under limited resources. First, key concepts related to these properties are introduced in the ISCC context. Subsequently, design approaches for realizing robust and resilient ISCC networks are discussed. Finally, the article concludes with the discussions of a case study and open research problems in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19518v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming-Chun Lee, Christian Eckrich, Vahid Jamali, Yu-Chih Huang, Arash Asadi, Li-Chun Wang</dc:creator>
    </item>
    <item>
      <title>Non-Reed-Solomon Type MDS Codes from Elliptic Curves</title>
      <link>https://arxiv.org/abs/2509.04247</link>
      <description>arXiv:2509.04247v2 Announce Type: replace 
Abstract: New families of maximum distance separable (MDS) codes are constructed from elliptic curves by exploiting their group structures. In contrast to classical constructions based on divisors supported at a single rational point, the proposed approach employs divisors formed by multiple distinct points constituting a maximal subgroup of the curve. The resulting codes achieve parameters approaching the theoretical upper bound $(q + 1 + \lfloor 2\sqrt{q} \rfloor)/2$ and include non Reed-Solomon (RS) MDS codes. The inequivalence of these codes to RS codes is established through an explicit analysis on the rank of the Schur product of their generator matrices. These results extend the known parameter range of elliptic MDS codes and provide additional evidence supporting the tightness of existing upper bounds for algebraic geometry MDS codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04247v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Puyin Wang, Wei Liu, Jinquan Luo, Dengxin Zhai</dc:creator>
    </item>
    <item>
      <title>Theoretically Grounded Framework for LLM Watermarking: A Distribution-Adaptive Approach</title>
      <link>https://arxiv.org/abs/2410.02890</link>
      <description>arXiv:2410.02890v5 Announce Type: replace-cross 
Abstract: Watermarking has emerged as a crucial method to distinguish AI-generated text from human-created text. Current watermarking approaches often lack formal optimality guarantees or address the scheme and detector design separately. In this paper, we introduce a novel, unified theoretical framework for watermarking Large Language Models (LLMs) that jointly optimizes both the watermarking scheme and detector. Our approach aims to maximize detection performance while maintaining control over the worst-case false positive rate (FPR) and distortion on text quality. We derive closed-form optimal solutions for this joint design and characterize the fundamental trade-off between watermark detectability and distortion. Notably, we reveal that the optimal watermarking schemes should be adaptive to the LLM's generative distribution. Building on our theoretical insights, we propose a distortion-free, distribution-adaptive watermarking algorithm (DAWA) that leverages a surrogate model for model-agnosticism and efficiency. Experiments on Llama2-13B and Mistral-8$\times$7B models confirm the effectiveness of our approach, particularly at ultra-low FPRs. Our code is available at https://github.com/yepengliu/DAWA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02890v5</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyun He, Yepeng Liu, Ziqiao Wang, Yongyi Mao, Yuheng Bu</dc:creator>
    </item>
    <item>
      <title>EVODiff: Entropy-aware Variance Optimized Diffusion Inference</title>
      <link>https://arxiv.org/abs/2509.26096</link>
      <description>arXiv:2509.26096v2 Announce Type: replace-cross 
Abstract: Diffusion models (DMs) excel in image generation, but suffer from slow inference and the training-inference discrepancies. Although gradient-based solvers like DPM-Solver accelerate the denoising inference, they lack theoretical foundations in information transmission efficiency. In this work, we introduce an information-theoretic perspective on the inference processes of DMs, revealing that successful denoising fundamentally reduces conditional entropy in reverse transitions. This principle leads to our key insights into the inference processes: (1) data prediction parameterization outperforms its noise counterpart, and (2) optimizing conditional variance offers a reference-free way to minimize both transition and reconstruction errors. Based on these insights, we propose an entropy-aware variance optimized method for the generative process of DMs, called EVODiff, which systematically reduces uncertainty by optimizing conditional entropy during denoising. Extensive experiments on DMs validate our insights and demonstrate that our method significantly and consistently outperforms state-of-the-art (SOTA) gradient-based solvers. For example, compared to the DPM-Solver++, EVODiff reduces the reconstruction error by up to 45.5\% (FID improves from 5.10 to 2.78) at 10 function evaluations (NFE) on CIFAR-10, cuts the NFE cost by 25\% (from 20 to 15 NFE) for high-quality samples on ImageNet-256, and improves text-to-image generation while reducing artifacts. Code is available at https://github.com/ShiguiLi/EVODiff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26096v2</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shigui Li, Wei Chen, Delu Zeng</dc:creator>
    </item>
    <item>
      <title>A reverse entropy power inequality for i.i.d. log-concave random variables</title>
      <link>https://arxiv.org/abs/2510.09206</link>
      <description>arXiv:2510.09206v2 Announce Type: replace-cross 
Abstract: We show that $h_\infty(X+Y)\leq h_\infty(Z+W)$, where $X, Y$ are independent log-concave random variables, and $Z, W$ are exponential random variables having the same respective $\infty$-R\'enyi entropies. Analogs for integer-valued monotone log-concave random variables are also obtained. Our main tools are decreasing rearrangement, majorization, and the change of measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09206v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhen Fu, Jiange Li</dc:creator>
    </item>
    <item>
      <title>LatticeHashForest: An Efficient Data Structure for Repetitive Data and Operations</title>
      <link>https://arxiv.org/abs/2510.18496</link>
      <description>arXiv:2510.18496v2 Announce Type: replace-cross 
Abstract: Analysis of entire programs as a single unit, or whole-program analysis, involves propagation of large amounts of information through the control flow of the program. This is especially true for pointer analysis, where, unless significant compromises are made in the precision of the analysis, there is a combinatorial blowup of information. One of the key problems we observed in our own efforts to this end is that a lot of duplicate data was being propagated, and many low-level data structure operations were repeated a large number of times.
  We present what we consider to be a novel and generic data structure, LatticeHashForest (LHF), to store and operate on such data in a manner that eliminates a majority of redundant computations and duplicate data in scenarios similar to those encountered in compilers and program optimization. LHF differs from similar work in this vein, such as hash-consing, ZDDs, and BDDs, by not only providing a way to efficiently operate on large, aggregate structures, but also modifying the elements of such structures in a manner that they can be deduplicated immediately. LHF also provides a way to perform a nested construction of elements such that they can be deduplicated at multiple levels, cutting down the need for additional, nested computations.
  We provide a detailed structural description, along with an abstract model of this data structure. An entire C++ implementation of LHF is provided as an artifact along with evaluations of LHF using examples and benchmark programs. We also supply API documentation and a user manual for users to make independent applications of LHF. Our main use case in the realm of pointer analysis shows memory usage reduction to an almost negligible fraction, and speedups beyond 4x for input sizes approaching 10 million when compared to other implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18496v2</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.OS</category>
      <category>cs.PL</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anamitra Ghorui, Uday P. Khedker</dc:creator>
    </item>
    <item>
      <title>Multi-turn Training with Basic Human Feedback Helps Little on LLM Reasoning</title>
      <link>https://arxiv.org/abs/2510.21339</link>
      <description>arXiv:2510.21339v2 Announce Type: replace-cross 
Abstract: The reasoning capabilities of Large Language Models (LLMs) are typically developed through the single-turn reinforcement learning, whereas real-world applications often involve multi-turn interactions with human feedback, leading to a potential mismatch between training and deployment conditions. In this work, we study whether multi-turn training with human feedback is necessary for reasoning tasks. We compare conventional single-turn training with three multi-turn strategies and reach contrary conclusions to previous research. We find that models trained in a single-turn setting generalize effectively to both single- and multi-turn evaluations, while models trained with multi-turn strategies exhibit a significant degradation in single-turn reasoning performance. These results suggest that for tasks with complete information, robust single-turn training remains more effective and reliable, as multi-turn training with basic feedback provides limited benefits and can even degrade reasoning capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21339v2</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Liu, Wuganjing Song, Zhenzhou Lin, Feifan Chen, Qiaolong Cai, Chen Li, Yongduo Sui</dc:creator>
    </item>
  </channel>
</rss>
