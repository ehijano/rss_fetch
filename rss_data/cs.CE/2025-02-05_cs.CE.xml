<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 05:04:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Physics-Informed Surrogates for Temperature Prediction of Multi-Tracks in Laser Powder Bed Fusion</title>
      <link>https://arxiv.org/abs/2502.01820</link>
      <description>arXiv:2502.01820v1 Announce Type: new 
Abstract: Modeling plays a critical role in additive manufacturing (AM), enabling a deeper understanding of underlying processes. Parametric solutions for such models are of great importance, enabling the optimization of production processes and considerable cost reductions. However, the complexity of the problem and diversity of spatio-temporal scales involved in the process pose significant challenges for traditional numerical methods. Surrogate models offer a powerful alternative by accelerating simulations and facilitating real-time monitoring and control. The present study presents an operator learning approach that relies on the deep operator network (DeepONet) and physics-informed neural networks (PINN) to predict the three-dimensional temperature distribution during melting and consolidation in laser powder bed fusion (LPBF). Parametric solutions for both single-track and multi-track scenarios with respect to tool path are obtained. To address the challenges in obtaining parametric solutions for multi-track scenarios using DeepONet architecture, a sequential PINN approach is proposed to efficiently manage the increased training complexity inherent in those scenarios. The accuracy and consistency of the model are verified against finite-difference computations. The developed surrogate allows us to efficiently analyze the effect of scanning paths and laser parameters on the thermal history.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01820v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hesameddin Safari, Henning Wessels</dc:creator>
    </item>
    <item>
      <title>Meta-neural Topology Optimization: Knowledge Infusion with Meta-learning</title>
      <link>https://arxiv.org/abs/2502.01830</link>
      <description>arXiv:2502.01830v1 Announce Type: new 
Abstract: Engineers learn from every design they create, building intuition that helps them quickly identify promising solutions for new problems. Topology optimization (TO) - a well-established computational method for designing structures with optimized performance - lacks this ability to learn from experience. Existing approaches treat design tasks in isolation, starting from a "blank canvas" design for each new problem, often requiring many computationally expensive steps to converge. We propose a meta-learning strategy, termed meta-neural TO, that finds effective initial designs through a systematic transfer of knowledge between related tasks, building on the mesh-agnostic representation provided by neural reparameterization. We compare our approach against established TO methods, demonstrating efficient optimization across diverse test cases without compromising design quality. Further, we demonstrate powerful cross-resolution transfer capabilities, where initializations learned on lower-resolution discretizations lead to superior convergence in 74.1% of tasks on a higher-resolution test set, reducing the average number of iterations by 33.6% compared to standard neural TO. Remarkably, we discover that meta-learning naturally gravitates toward the strain energy patterns found in uniform density designs as effective starting points, aligning with engineering intuition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01830v1</guid>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Kuszczak, Gawel Kus, Federico Bosi, Miguel A. Bessa</dc:creator>
    </item>
    <item>
      <title>Multimaterial topology optimization for finite strain elastoplasticity: theory, methods, and applications</title>
      <link>https://arxiv.org/abs/2502.02052</link>
      <description>arXiv:2502.02052v1 Announce Type: new 
Abstract: Plasticity is inherent to many engineering materials such as metals. While it can degrade the load-carrying capacity of structures via material yielding, it can also protect structures through plastic energy dissipation. To fully harness plasticity, here we present the theory, method, and application of a topology optimization framework that simultaneously optimizes structural geometries and material phases to customize the stiffness, strength, and structural toughness of designs experiencing finite strain elastoplasticity. The framework accurately predicts structural responses by employing a rigorous, mechanics-based elastoplasticity theory that ensures isochoric plastic flow. It also effectively identifies optimal material phase distributions using a gradient-based optimizer, where gradient information is obtained via a reversed adjoint method to address history dependence, along with automatic differentiation to compute the complex partial derivatives. We demonstrate the framework by optimizing a range of 2D and 3D elastoplastic structures, including energy-dissipating dampers, load-carrying beams, impact-resisting bumpers, and cold working profiled sheets. These optimized multimaterial structures reveal important mechanisms for improving design performance under large deformation, such as the transition from kinematic to isotropic hardening with increasing displacement amplitudes and the formation of twisted regions that concentrate stress, enhancing plastic energy dissipation. Through the superior performance of these optimized designs, we demonstrate the framework's effectiveness in tailoring elastoplastic responses across various spatial configurations, material types, hardening behaviors, and combinations of candidate materials. This work offers a systematic approach for optimizing next-generation multimaterial structures with elastoplastic behaviors under large deformations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02052v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingqi Jia, Xiaojia Shelly Zhang</dc:creator>
    </item>
    <item>
      <title>Orientation-aware interaction-based deep material network in polycrystalline materials modeling</title>
      <link>https://arxiv.org/abs/2502.02457</link>
      <description>arXiv:2502.02457v1 Announce Type: new 
Abstract: Multiscale simulations are indispensable for connecting microstructural features to the macroscopic behavior of polycrystalline materials, but their high computational demands limit their practicality. Deep material networks (DMNs) have been proposed as efficient surrogate models, yet they fall short of capturing texture evolution. To address this limitation, we propose the orientation-aware interaction-based deep material network (ODMN), which incorporates an orientation-aware mechanism and an interaction mechanism grounded in the Hill-Mandel principle. The orientation-aware mechanism learns the crystallographic textures, while the interaction mechanism captures stress-equilibrium directions among representative volume element (RVE) subregions, offering insight into internal microstructural mechanics. Notably, ODMN requires only linear elastic data for training yet generalizes effectively to complex nonlinear and anisotropic responses. Our results show that ODMN accurately predicts both mechanical responses and texture evolution under complex plastic deformation, thus expanding the applicability of DMNs to polycrystalline materials. By balancing computational efficiency with predictive fidelity, ODMN provides a robust framework for multiscale simulations of polycrystalline materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02457v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting-Ju Wei, Tung-Huan Su, Chuin-Shan Chen</dc:creator>
    </item>
    <item>
      <title>LEAD: Large Foundation Model for EEG-Based Alzheimer's Disease Detection</title>
      <link>https://arxiv.org/abs/2502.01678</link>
      <description>arXiv:2502.01678v1 Announce Type: cross 
Abstract: Electroencephalogram (EEG) provides a non-invasive, highly accessible, and cost-effective solution for Alzheimer's Disease (AD) detection. However, existing methods, whether based on manual feature extraction or deep learning, face two major challenges: the lack of large-scale datasets for robust feature learning and evaluation, and poor detection performance due to inter-subject variations. To address these challenges, we curate an EEG-AD corpus containing 813 subjects, which forms the world's largest EEG-AD dataset to the best of our knowledge. Using this unique dataset, we propose LEAD, the first large foundation model for EEG-based AD detection. Our method encompasses an entire pipeline, from data selection and preprocessing to self-supervised contrastive pretraining, fine-tuning, and key setups such as subject-independent evaluation and majority voting for subject-level detection. We pre-train the model on 11 EEG datasets and unified fine-tune it on 5 AD datasets. Our self-supervised pre-training design includes sample-level and subject-level contrasting to extract useful general EEG features. Fine-tuning is performed on 5 channel-aligned datasets together. The backbone encoder incorporates temporal and channel embeddings to capture features across both temporal and spatial dimensions. Our method demonstrates outstanding AD detection performance, achieving up to a 9.86% increase in F1 score at the sample-level and up to a 9.31% at the subject-level compared to state-of-the-art methods. The results of our model strongly confirm the effectiveness of contrastive pre-training and channel-aligned unified fine-tuning for addressing inter-subject variation. The source code is at https://github.com/DL4mHealth/LEAD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01678v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihe Wang, Nan Huang, Nadia Mammone, Marco Cecchi, Xiang Zhang</dc:creator>
    </item>
    <item>
      <title>When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy Regression Tasks</title>
      <link>https://arxiv.org/abs/2502.02199</link>
      <description>arXiv:2502.02199v1 Announce Type: cross 
Abstract: Large language models (LLMs) have shown remarkable success in language modelling due to scaling laws found in model size and the hidden dimension of the model's text representation. Yet, we demonstrate that compressed representations of text can yield better performance in LLM-based regression tasks. In this paper, we compare the relative performance of embedding compression in three different signal-to-noise contexts: financial return prediction, writing quality assessment and review scoring. Our results show that compressing embeddings, in a minimally supervised manner using an autoencoder's hidden representation, can mitigate overfitting and improve performance on noisy tasks, such as financial return prediction; but that compression reduces performance on tasks that have high causal dependencies between the input and target data. Our results suggest that the success of interpretable compressed representations such as sentiment may be due to a regularising effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02199v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Felix Drinkall, Janet B. Pierrehumbert, Stefan Zohren</dc:creator>
    </item>
    <item>
      <title>Target-aware Bayesian inference via generalized thermodynamic integration</title>
      <link>https://arxiv.org/abs/2502.02206</link>
      <description>arXiv:2502.02206v1 Announce Type: cross 
Abstract: In Bayesian inference, we are usually interested in the numerical approximation of integrals that are posterior expectations or marginal likelihoods (a.k.a., Bayesian evidence). In this paper, we focus on the computation of the posterior expectation of a function $f(\x)$. We consider a \emph{target-aware} scenario where $f(\x)$ is known in advance and can be exploited in order to improve the estimation of the posterior expectation. In this scenario, this task can be reduced to perform several independent marginal likelihood estimation tasks. The idea of using a path of tempered posterior distributions has been widely applied in the literature for the computation of marginal likelihoods. Thermodynamic integration, path sampling and annealing importance sampling are well-known examples of algorithms belonging to this family of methods. In this work, we introduce a generalized thermodynamic integration (GTI) scheme which is able to perform a target-aware Bayesian inference, i.e., GTI can approximate the posterior expectation of a given function. Several scenarios of application of GTI are discussed and different numerical simulations are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02206v1</guid>
      <category>stat.CO</category>
      <category>cs.CE</category>
      <category>stat.ME</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00180-023-01358-0</arxiv:DOI>
      <arxiv:journal_reference>Computational Statistics, Volume 38, Pages 2097-2119, year 2023</arxiv:journal_reference>
      <dc:creator>F. Llorente, L. Martino, D. Delgado</dc:creator>
    </item>
    <item>
      <title>Towards Full Automation of Geometry Extraction for Biomechanical Analysis of Abdominal Aortic Aneurysm; Neural Network-Based versus Classical Methodologies</title>
      <link>https://arxiv.org/abs/2403.07238</link>
      <description>arXiv:2403.07238v3 Announce Type: replace 
Abstract: Background: For the clinical adoption of stress-based rupture risk estimation in abdominal aortic aneurysms (AAAs), a fully automated pipeline, from clinical imaging to biomechanical stress computation, is essential. To this end, we investigated the impact of AI-based image segmentation methods on stress computation results in the walls of AAAs. We compared wall stress distributions and magnitudes calculated from geometry models obtained from classical semi-automated segmentation versus automated neural network-based segmentation. Method: 16 different AAA contrast-enhanced computed tomography (CT) images were semi-automatically segmented by an analyst, taking between 15 and 40 minutes of human effort per patient, depending on image quality. The same images were automatically segmented using PRAEVAorta2 commercial software by NUREA (https://www.nurea-soft.com/), developed based on artificial intelligence (AI) algorithms, and automatically post-processed with an in-house MATLAB code, requiring only 1-2 minutes of computer time per patient. Aneurysm wall stress calculations were automatically performed using the BioPARR software (https://bioparr.mech.uwa.edu.au/). Results: Compared to the classical semi-automated segmentation, the automatic neural network-based segmentation leads to equivalent stress distributions, and slightly higher peak and 99th percentile maximum principal stress values. However, our statistical analysis indicated that the differences in AAA wall stress obtained using the two segmentation methods are not statistically significant and fall well within the typical range of inter-analyst and intra-analyst variability. Conclusions: Our findings are a steppingstone toward a fully automated pipeline for biomechanical analysis of AAAs, starting with CT scans and concluding with wall stress assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07238v3</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farah Alkhatib, Mostafa Jamshidian, Donatien Le Liepvre, Florian Bernard, Ludovic Minvielle, Antoine Fondan\`eche, Elke R. Gizewski, Eva Gassner, Alexander Loizides, Maximilian Lutz, Florian Enzmann, Hozan Mufty, Inge Fourneau, Adam Wittek, Karol Miller</dc:creator>
    </item>
    <item>
      <title>Foundation Model for Composite Materials and Microstructural Analysis</title>
      <link>https://arxiv.org/abs/2411.06565</link>
      <description>arXiv:2411.06565v2 Announce Type: replace 
Abstract: The rapid advancement of machine learning has unlocked numerous opportunities for materials science, particularly in accelerating the design and analysis of materials. However, a significant challenge lies in the scarcity and high cost of obtaining high-quality materials datasets. While foundation models pre-trained on large datasets have excelled in fields like natural language processing by leveraging latent features through transfer learning, their application in materials science remains limited. Here, we present a foundation model specifically designed for composite materials. Pre-trained on a dataset of short-fiber composites to learn robust latent features, the model accurately predicts homogenized stiffness during transfer learning, even with limited training data. Additionally, our model effectively predicts the material's nonlinear behavior by transferring these learned features to an Interaction-based Material Network, which is a constitutive surrogate model. These results demonstrate the potential of our foundation model to capture complex material behaviors. Our findings validate the feasibility and effectiveness of foundation models in composite materials. We anticipate extending this approach to more complex three-dimensional composite materials, polycrystalline materials, and beyond. Moreover, this framework enables high-accuracy predictions even when experimental data are scarce, paving the way for more efficient and cost-effective materials design and analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06565v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting-Ju Wei, Chuin-Shan Chen</dc:creator>
    </item>
    <item>
      <title>Optimizing MACD Trading Strategies A Dance of Finance, Wavelets, and Genetics</title>
      <link>https://arxiv.org/abs/2501.10808</link>
      <description>arXiv:2501.10808v2 Announce Type: replace 
Abstract: In today's financial markets, quantitative trading has become an essential trading method, with the MACD indicator widely employed in quantitative trading strategies. This paper begins by screening and cleaning the dataset, establishing a model that adheres to the basic buy and sell rules of the MACD, and calculating key metrics such as the win rate, return, Sharpe ratio, and maximum drawdown for each stock. However, the MACD often generates erroneous signals in highly volatile markets. To address this, wavelet transform is applied to reduce noise, smoothing the DIF image, and a model is developed based on this to optimize the identification of buy and sell points. The results show that the annualized return has increased by 5%, verifying the feasibility of the method.
  Subsequently, the divergence principle is used to further optimize the trading strategy, enhancing the model's performance. Additionally, a genetic algorithm is employed to optimize the MACD parameters, tailoring the strategy to the characteristics of different stocks. To improve computational efficiency, the MindSpore framework is used for resource management and parallel computing. The optimized strategy demonstrates improved win rates, returns, Sharpe ratios, and a reduction in maximum drawdown in backtesting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10808v2</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wangyu Chen, Zhenpeng Zhu</dc:creator>
    </item>
    <item>
      <title>Emerging Microelectronic Materials by Design: Navigating Combinatorial Design Space with Scarce and Dispersed Data</title>
      <link>https://arxiv.org/abs/2412.17283</link>
      <description>arXiv:2412.17283v2 Announce Type: replace-cross 
Abstract: The increasing demands of sustainable energy, electronics, and biomedical applications call for next-generation functional materials with unprecedented properties. Of particular interest are emerging materials that display exceptional physical properties, making them promising candidates in energy-efficient microelectronic devices. As the conventional Edisonian approach becomes significantly outpaced by growing societal needs, emerging computational modeling and machine learning (ML) methods are employed for the rational design of materials. However, the complex physical mechanisms, cost of first-principles calculations, and the dispersity and scarcity of data pose challenges to both physics-based and data-driven materials modeling. Moreover, the combinatorial composition-structure design space is high-dimensional and often disjoint, making design optimization nontrivial. In this Account, we review a team effort toward establishing a framework that integrates data-driven and physics-based methods to address these challenges and accelerate materials design. We begin by presenting our integrated materials design framework and its three components in a general context. We then provide an example of applying this materials design framework to metal-insulator transition (MIT) materials, a specific type of emerging materials with practical importance in next-generation memory technologies. We identify multiple new materials which may display this property and propose pathways for their synthesis. Finally, we identify some outstanding challenges in data-driven materials design, such as materials data quality issues and property-performance mismatch. We seek to raise awareness of these overlooked issues hindering materials design, thus stimulating efforts toward developing methods to mitigate the gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17283v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengrui Zhang, Alexandru B. Georgescu, Suraj Yerramilli, Christopher Karpovich, Daniel W. Apley, Elsa A. Olivetti, James M. Rondinelli, Wei Chen</dc:creator>
    </item>
  </channel>
</rss>
