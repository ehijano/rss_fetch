<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Mar 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Luce Model, Regularity, and Choice Overload</title>
      <link>https://arxiv.org/abs/2502.21063</link>
      <description>arXiv:2502.21063v1 Announce Type: new 
Abstract: We characterize regularity (Block &amp; Marschak, 1960) within a novel stochastic model: the General Threshold Luce model [GTLM]. We apply our results to study choice overload, identified by regularity violations that impose a welfare cost on the decision-maker. Generalizing our characterization results, we identify necessary and sufficient conditions for choice overload within GTLMs and, in doing so, disentangle two well-known causes: low discriminatory power (Frick, 2016) and limited attention (Lleras et al., 2017).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21063v1</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Caliari, Henrik Petri</dc:creator>
    </item>
    <item>
      <title>Reputation and Risk in Regimes</title>
      <link>https://arxiv.org/abs/2404.18884</link>
      <description>arXiv:2404.18884v2 Announce Type: replace 
Abstract: How valuable is reputation to a regime seeking to deter uprisings? I show the answer depends almost entirely on players' strategic uncertainty over other players actions. Without higher-order uncertainty, reputational effects are overshadowed by stage-game strategic complementarities: any payoff attainable in the complete-information repeated game remains attainable in the corresponding reputation game. However, when agents face globalized uncertainty over their payoffs, the regime's value for reputation rises sharply. In particular, the regime can leverage globalized strategic uncertainty to successful develop a reputation and secure their Stackelberg payoff in all pure equilibria of the reputation game, even as that same globalized strategic uncertainty forces them to their minimax payoff in the associated complete-information repeated game. Moreover, the globalized reputation game selects a unique pooling Markov equilibria among the continuum of Markov equilibria present in the complete-information game, refining predictions about equilibrium play. To establish these results, I develop new tools for analyzing non-normalized discounted repeated games with endogenous exit, where commitment actions vary with the regime's patience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18884v2</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Luo</dc:creator>
    </item>
    <item>
      <title>Matching Design with Algorithms and Applications to Foster Care</title>
      <link>https://arxiv.org/abs/2411.12860</link>
      <description>arXiv:2411.12860v4 Announce Type: replace 
Abstract: We study the problem of an organization that matches agents to objects where agents have preference rankings over objects and the organization uses algorithms to construct a ranking over objects on behalf of each agent. Our new framework carries the interpretation that the organization and its agents may be misaligned in pursuing some underlying matching goal. We design matching mechanisms that integrate agent decision-making and the algorithm by avoiding matches that are unanimously disagreeable between the two parties. Our mechanisms also satisfy restricted efficiency properties. Subsequently, we prove that no unanimous mechanism is strategy-proof but that ours can be non-obviously manipulable. We generalize our framework to allow for any preference aggregation rules and extend the famed Gibbard-Satterthwaite Theorem to our setting. We apply our framework to place foster children in foster homes to maximize welfare. Using a machine learning model that predicts child welfare in placements and a (planned) novel lab-in-the-field eliciting real caseworkers' preferences, we empirically demonstrate that there are important match-specific welfare gains that our mechanisms extract that are not realized under the status quo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12860v4</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Terence Highsmith Ii</dc:creator>
    </item>
  </channel>
</rss>
