<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 May 2025 01:54:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Efficient Multi-Scale Deformable Attention on NPU</title>
      <link>https://arxiv.org/abs/2505.14022</link>
      <description>arXiv:2505.14022v1 Announce Type: new 
Abstract: Multi-scale deformable attention (MSDA) is a flexible and powerful feature extraction mechanism for visual tasks, but its random-access grid sampling strategy poses significant optimization challenges, especially on domain-specific accelerators such as NPUs. In this work, we present a co-design approach that systematically rethinks memory access and computation strategies for MSDA on the Ascend NPU architecture. With this co-design approach, our implementation supports both efficient forward and backward computation, is fully adapted for training workloads, and incorporates a suite of hardware-aware optimizations. Extensive experiments show that our solution achieves up to $5.9\times$ (forward), $8.9\times$ (backward), and $7.3\times$ (end-to-end training) speedup over the grid sample-based baseline, and $1.9\times$, $2.4\times$, and $2.0\times$ acceleration over the latest vendor library, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14022v1</guid>
      <category>cs.PF</category>
      <category>cs.CV</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenghuan Huang, Zhigeng Xu, Chong Sun, Chen Li, Ziyang Ma</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Memory Pool Tuning</title>
      <link>https://arxiv.org/abs/2505.14294</link>
      <description>arXiv:2505.14294v1 Announce Type: new 
Abstract: We present a lightweight tool for the analysis and tuning of application data placement in systems with heterogeneous memory pools. The tool allows non-intrusively identifying, analyzing, and controlling the placement of individual allocations of the application. We use the tool to analyze a set of benchmarks running on the Intel Sapphire Rapids platform with both HBM and DDR memory. The paper also contains an analysis of the performance of both memory subsystems in terms of read/write bandwidth and latency. The key part of the analysis is to focus on performance if both subsystems are used together. We show that only about 60% to 75% of the data must be placed in HBM memory to achieve 90% of the potential performance of the platform on those benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14294v1</guid>
      <category>cs.PF</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filip Vaverka, Ondrej Vysocky, Lubomir Riha</dc:creator>
    </item>
    <item>
      <title>Task-parallelism in SWIFT for heterogeneous compute architectures</title>
      <link>https://arxiv.org/abs/2505.14538</link>
      <description>arXiv:2505.14538v1 Announce Type: new 
Abstract: This paper highlights the first steps towards enabling graphics processing unit (GPU) acceleration of the smoothed particle hydrodynamics (SPH) solver for cosmology SWIFT and creating a hydrodynamics solver capable of fully leveraging the hardware available on heterogeneous exascale machines composed of central and graphics processing units (CPUs and GPUs). Exploiting the existing task-based parallelism in SWIFT, novel combinations of algorithms are presented which enable SWIFT to function as a truly heterogeneous software leveraging CPUs for memory-bound computations concurrently with GPUs for compute-bound computations in a manner which minimises the effects of CPU-GPU communication latency. These algorithms are validated in extensive testing which shows that the GPU acceleration methodology is capable of delivering up to 3.5x speedups for SWIFTs SPH hydrodynamics computation kernels when including the time required to prepare the computations on the CPU and unpack the results on the CPU. Speedups of 7.5x are demonstrated when not including the CPU data preparation and unpacking times. Whilst these measured speedups are substantial, it is shown that the overall performance of the hydrodynamic solver for a full simulation when accelerated on the GPU of state-of-the-art superchips, is only marginally faster than the code performance when using the Grace Hopper superchips fully parallelised CPU capabilities. This is shown to be mostly due to excessive fine-graining of the tasks prior to offloading on the GPU. Fine-graining introduces significant over-heads associated with task management on the CPU hosting the simulation and also introduces un-necessary duplication of CPU-GPU communications of the same data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14538v1</guid>
      <category>cs.PF</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abouzied M. A. Nasar, Benedict D. Rogers, Georgios Fourtakas, Scott T. Kay, Matthieu Schaller</dc:creator>
    </item>
    <item>
      <title>Bayesian Hierarchical Models for Quantitative Estimates for Performance metrics applied to Saddle Search Algorithms</title>
      <link>https://arxiv.org/abs/2505.13621</link>
      <description>arXiv:2505.13621v1 Announce Type: cross 
Abstract: The increasing use of high-throughput computational chemistry demands rigorous methods for evaluating algorithm performance. We present a Bayesian hierarchical modeling paradigm (brms/Stan) for analyzing key performance metrics: function evaluations, computation time, and success/failure. This framework accounts for variability across different systems and functionals, providing reliable uncertainty estimates beyond subjective visual assessments or frequentist limitations. We applied this to compare conjugate gradient (CG) and L-BFGS algorithms for the Dimer method's rotation phase (EON, with/without removal of external rotations/translations) on a benchmark of 500 initial saddle search approximations, analyzing over 2000 runs. Our results show CG rotations generally outperform L-BFGS, exhibiting a statistically credible, small reduction in PES calls and significantly higher odds of successful convergence. Conversely, enabling rotation removal incurred a substantial PES call penalty without a corresponding credible improvement in success odds in this implementation. These findings, from our novel Bayesian hierarchical modeling application, suggest CG may be preferable for Dimer rotational optimization in similar contexts. This robust statistical framework highlights benefits for revisiting optimization strategies, quantifying uncertainty, and facilitating improved high-throughput computational chemistry methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13621v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.PF</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Goswami (Science Institute and Faculty of Physical Sciences, University of Iceland, Reykjav\'ik, Iceland)</dc:creator>
    </item>
  </channel>
</rss>
