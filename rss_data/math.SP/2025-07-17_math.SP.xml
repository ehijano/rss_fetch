<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.SP</link>
    <description>math.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 01:27:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sturm-Liouville operators with periodically modulated parameters. Part I: Regular case</title>
      <link>https://arxiv.org/abs/2507.12300</link>
      <description>arXiv:2507.12300v1 Announce Type: new 
Abstract: We introduce a new class of Sturm-Liouville operators with periodically modulated parameters. Their spectral properties depend on the monodromy matrix of the underlying periodic problem computed for the spectral parameter equal to $0$. Under certain assumptions, by studying the asymptotic behavior of Christoffel functions and density of states, we prove that the spectral density is a continuous positive everywhere function on the real line.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12300v1</guid>
      <category>math.SP</category>
      <category>math-ph</category>
      <category>math.CA</category>
      <category>math.MP</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Grzegorz \'Swiderski, Bartosz Trojan</dc:creator>
    </item>
    <item>
      <title>Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training</title>
      <link>https://arxiv.org/abs/2410.15460</link>
      <description>arXiv:2410.15460v4 Announce Type: replace-cross 
Abstract: As large language models (LLMs) become increasingly prevalent, concerns about their reliability, particularly due to hallucinations - factually inaccurate or irrelevant outputs - have grown. Our research investigates the relationship between the uncertainty in training dynamics and the emergence of hallucinations. Using models from the Pythia suite and several hallucination detection metrics, we analyze hallucination trends and identify significant variance during training. To address this, we propose \textbf{Sensitivity Dropout (SenD)}, a novel training protocol designed to reduce hallucination variance during training by deterministically dropping embedding indices with significant variability. In addition, we develop an unsupervised hallucination detection metric, Efficient EigenScore (EES), which approximates the traditional EigenScore in 2x speed. This metric is integrated into our training protocol, allowing SenD to be both computationally scalable and effective at reducing hallucination variance. SenD improves test-time reliability of Pythia and Meta's Llama models by up to 17\% and enhances factual accuracy in Wikipedia, Medical, Legal, and Coding domains without affecting downstream task performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15460v4</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.SP</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi</dc:creator>
    </item>
  </channel>
</rss>
