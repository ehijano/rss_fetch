<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 05:01:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The indiscriminate adoption of AI threatens the foundations of academia</title>
      <link>https://arxiv.org/abs/2602.10165</link>
      <description>arXiv:2602.10165v1 Announce Type: new 
Abstract: Artificial intelligence offers much promise, but its use in scientific research should be restrained so that the primary aim of academia -- advancing knowledge for humans -- is safeguarded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10165v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41550-025-02738-w</arxiv:DOI>
      <arxiv:journal_reference>Nat. Astron. 9, 1748-1749 (2025)</arxiv:journal_reference>
      <dc:creator>Roberto Trotta</dc:creator>
    </item>
    <item>
      <title>Observing solar vortices with existing and future instrumentation. Solar Physics International Network for Swirls (SPINS) white paper (Helio)</title>
      <link>https://arxiv.org/abs/2602.10170</link>
      <description>arXiv:2602.10170v1 Announce Type: new 
Abstract: Solar vortices are fundamental components of solar atmospheric dynamics, serving as natural laboratories for magnetic field twisting, energy concentration and transport, wave guidance, and plasma coupling across atmospheric layers. Numerical and observational studies show that solar vortices are intimately connected to key physical processes including magnetic reconnection, atmospheric heating, turbulence, and wave generation. This white paper, prepared for the UK Space Frontiers 2035 call, outline five high-priority scientific questions addressing vortex generation mechanisms, cross-layer coupling, magnetic restructuring, collective wave-guidance structures, and their role in triggering explosive events and modulating the solar wind. Key observations and capabilities required to make significant advancements over the coming decade are identified. The UK solar physics community has established world-leading expertise in vortex dynamics, combining strengths in high-resolution observations, MHD turbulence theory, numerical modelling, and space instrumentation. UK researchers have made foundational contributions to Solar Orbiter, delivered critical systems for DKIST, and maintain active involvement in MUSE and SOLAR-C EUVST missions. Our technical approach centres on developing next-generation instrumentation: a multi-band, space-qualified system employing four tunable Fabry-P\'erot Interferometers providing diffraction-limited, high-cadence spectropolarimetric coverage from the deep photosphere to the low corona. This capability will be validated through a staged mission architecture beginning with balloon-borne demonstrators. Continuing this effort over the coming decade is vital to maintain UK leadership in this field and achieve the goals of roadmap for solar system research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10170v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>physics.space-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suzana S. A. Silva, Viktor Fedun, Gary Verth, Istvan Ballai, Eamon Scullion, Malcolm Druett, Kostas Tziotziou, Alex Pietrow, Nitin Yadav, Ioannis Dakanalis, Elena Khomenko, Hidetaka Kuniyoshi, Shivdev Turkay, Matias Koll Pistarini, Robertus Erdelyi, Luiz Augusto Camargo Aranha Schiavo</dc:creator>
    </item>
    <item>
      <title>Cosmo3DFlow: Wavelet Flow Matching for Spatial-to-Spectral Compression in Reconstructing the Early Universe</title>
      <link>https://arxiv.org/abs/2602.10172</link>
      <description>arXiv:2602.10172v1 Announce Type: new 
Abstract: Reconstructing the early Universe from the evolved present-day Universe is a challenging and computationally demanding problem in modern astrophysics. We devise a novel generative framework, Cosmo3DFlow, designed to address dimensionality and sparsity, the critical bottlenecks inherent in current state-of-the-art methods for cosmological inference. By integrating 3D Discrete Wavelet Transform (DWT) with flow matching, we effectively represent high-dimensional cosmological structures. The Wavelet Transform addresses the ``void problem'' by translating spatial emptiness into spectral sparsity. It decouples high-frequency details from low-frequency structures through spatial compression, and wavelet-space velocity fields facilitate stable ordinary differential equation (ODE) solvers with large step sizes. Using large-scale cosmological $N$-body simulations, at $128^3$ resolution, we achieve up to $50\times$ faster sampling than diffusion models, combining a $10\times$ reduction in integration steps with lower per-step computational cost from wavelet compression. Our results enable initial conditions to be sampled in seconds, compared to minutes for previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10172v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md. Khairul Islam, Zeyu Xia, Ryan Goudjil, Jialu Wang, Arya Farahi, Judy Fox</dc:creator>
    </item>
    <item>
      <title>Why do we do astrophysics?</title>
      <link>https://arxiv.org/abs/2602.10181</link>
      <description>arXiv:2602.10181v1 Announce Type: new 
Abstract: At time of writing, large language models (LLMs) are beginning to obtain the ability to design, execute, write up, and referee scientific projects on the data-science side of astrophysics. What implications does this have for our profession? In this white paper, I list - and argue for - a set of facts or "points of agreement" about what astrophysics is, or should be; these include considerations of novelty, people-centrism, trust, and (the lack of) clinical value. I then list and discuss every possible benefit that astrophysics can be seen as bringing to us, and to science, and to universities, and to the world; these include considerations of love, weaponry, and personal (and personnel) development. I conclude with a discussion of two possible (extreme and bad) policy recommendations related to the use of LLMs in astrophysics, dubbed "let-them-cook" and "ban-and-punish." I argue strongly against both of these; it is not going to be easy to develop or adopt good moderate policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10181v1</guid>
      <category>astro-ph.IM</category>
      <category>physics.hist-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David W. Hogg (NYU, Flatiron, MPIA)</dc:creator>
    </item>
    <item>
      <title>Optimizing Deep Learning Photometric Redshifts for the Roman Space Telescope with HST/CANDELS</title>
      <link>https://arxiv.org/abs/2602.10207</link>
      <description>arXiv:2602.10207v1 Announce Type: new 
Abstract: Photometric redshifts (photo-$z$'s) will be crucial for studies of galaxy evolution, large-scale structure, and transients with the Nancy Grace Roman Space Telescope. Deep learning methods leverage pixel-level information from ground-based images to achieve the best photo-$z$'s for low-redshift galaxies, but their efficacy at higher redshifts with deep, space-based imaging remains largely untested. We used Hubble Space Telescope CANDELS optical and near-infrared imaging to evaluate fully-supervised, self-supervised, and semi-supervised deep learning photo-$z$ algorithms out to $z\sim3$. Compared to template-based and classical machine learning photometry methods, the fully-supervised and semi-supervised models achieved better performance. Our new semi-supervised model, PITA (Photo-$z$ Inference with a Triple-loss Algorithm), outperformed all others by learning from unlabeled and labeled data through a three-part loss function that incorporates images and colors for all objects as well as redshifts when available. PITA produces a latent space that varies smoothly in magnitude, color, and redshift, resulting in the best photo-$z$ performance even when the redshift training set was significantly reduced. In contrast, the self-supervised approach produced a latent space with significant color and redshift fluctuations that hindered photo-$z$ inference. Looking forward to Roman, we recommend using semi supervised deep learning to take full advantage of the information contained in the hundreds of millions of high-resolution images and color measurements, together with the limited redshift measurements available, to achieve the most accurate photo-$z$ estimates for both faint and bright sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10207v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashod Khederlarian, Brett H. Andrews, Jeffrey A. Newman, Tianqing Zhang, Biprateep Dey</dc:creator>
    </item>
    <item>
      <title>Pollux test bench: from NUV to FUV polarimetric measurements</title>
      <link>https://arxiv.org/abs/2602.10901</link>
      <description>arXiv:2602.10901v1 Announce Type: new 
Abstract: Pollux is a high-resolution spectropolarimeter proposed by an European consortium for HWO. The current design of Pollux features four spectropolarimetric channels, three of which are in the UV range. For the near-UV (NUV) [236-472 nm] and mid-UV (MUV) [118-236 nm] channels, the polarimeters consist of waveplates and prisms made of MgF2, a birefringent material. However, no such birefringent material can be used for the far-UV (FUV) channel [100-123 nm]. Therefore, the polarimeter for this FUV channel is composed solely of mirrors in an innovative assembly. In this talk, we aim to detail the architecture of the test bench that will allow us to validate the performance of these different polarimeters, as part of the HWO GOMaP. Given that we are working in the vacuum ultraviolet (VUV) range, the test bench operates in a vacuum chamber in a clean room. We will discuss the adaptable architecture of the bench based on wavelength and the measurement methodology that we will implement to test if the polarimeters achieve the precision of $10^{-3}$ required for the Pollux instrument. With this test bench, we will successfully increase the Technology Readiness Level (TRL) of UV spectropolarimeters and, for the first time, develop a means to test FUV spectropolarimetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10901v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrien Girardot, Coralie Neiner, Jean-Michel Reess, Olivier Dupuis, Margarita Carret</dc:creator>
    </item>
    <item>
      <title>Early Architecture Concepts for the Habitable Worlds Observatory -- System Design, Modeling, and Analysis</title>
      <link>https://arxiv.org/abs/2602.11046</link>
      <description>arXiv:2602.11046v1 Announce Type: new 
Abstract: The Habitable Worlds Observatory (HWO), NASA's next flagship science mission, follows in the tradition of the Nancy Grace Roman Space Telescope and other preceding great observatories. HWO will directly image and characterize Earth-like exoplanet and their atmospheres, with the capability to detect biosignatures and potentially answer the question of whether we are we alone. HWO will also serve as a powerful general astrophysics observatory, enabling breakthroughs in galaxy evolution, stellar astrophysics, and dark matter studies. Currently in pre-formulation, the project has established Exploratory Analytic Cases (EACs), a series of architectural concept designs used to assess the mission's demanding science objectives while exploring challenging engineering parameters. This paper describes the first three EACs, starting with observing strategies and error budget formulation and then progressing to design formulations, trade studies and lessons learned; this paper also discusses the integrated modeling pipeline, a key multidisciplinary system-level analysis capability, and analysis findings as applied to the first EAC. These activities set the stage for the follow on EACs 4 and 5, which will further explore the trade space and prepare for the baseline design that will support the Mission Concept Review (MCR).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11046v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Alice (Kuo-Chia),  Liu, Marie Levine, Charley Noecker, Jon Lawrence, Joshua Abel, Michael Akkerman, Eric Aanstaat, Ruslan Belikov, Pin Chen, Kenneth Dziak, Jordan Effron, Lee Feinberg, Alan Gostin, James Govern, Cameron Haag, Joseph Howard, Brian Kern, Gary Kuan, Milan Mandic, Carson McDonald, Connor Mulrenin, Bijan Nemati, Jon Papa, Fang Shi, Samuel Sirlin, Breann Sitarski, Cory Smiley, J. Scott Smith, Philip Stahl, Christopher Stark, Gregory Walsh, John Ziemer</dc:creator>
    </item>
    <item>
      <title>Machine Learning Methods for Stellar Collisions. I. Predicting Outcomes of SPH Simulations</title>
      <link>https://arxiv.org/abs/2602.10191</link>
      <description>arXiv:2602.10191v1 Announce Type: cross 
Abstract: Stellar collisions can occur frequently in dense cluster environments, and play a crucial role in producing exotic phenomena from blue stragglers in globular clusters to high-energy transients in galactic nuclei. Successive collisions and mergers of massive stars could also lead to the formation of massive black holes, serving as seeds for supermassive black hole in the early universe. While analytic fitting formulae exist for predicting collision outcomes, they do not generalize across different energy scales or stellar evolutionary phases. Smoothed particle hydrodynamics (SPH) simulations are often used to compute the outcomes of stellar collisions, but, even at low resolution, their computational cost makes running on-the-fly calculations during an $N$-body simulation quite challenging. Here we present a new grid of $27,720$ SPH calculations of main-sequence star collisions, spanning a wide range of masses, ages, relative velocities, and impact parameters. Using this grid, we train machine learning models to predict both collision outcomes (merger vs disruption, or flyby) and final remnant masses. We compare the performance of nearest neighbors, support vector machines, and neural networks, achieving classification balanced accuracy of $98.4\%$, and regression relative errors as low as $0.11\%$ and $0.15\%$ for the final stars $1$ and $2$, respectively. We make our trained models publicly available as part of the package collAIder, enabling rapid predictions of stellar collision outcomes in $N$-body models of dense star cluster dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10191v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Gonz\'alez Prieto, James C. Lombardi, Jr., Sanaea C. Rose, Charles F. A. Gibson, Christopher E. O'Connor, Tjitske Starkenburg, Fulya K{\i}ro\u{g}lu, Kyle Kremer, Tristan C. Parmerlee, Frederic A. Rasio</dc:creator>
    </item>
    <item>
      <title>Efficient reduction of stellar contamination and noise in planetary transmission spectra using neural networks</title>
      <link>https://arxiv.org/abs/2602.10330</link>
      <description>arXiv:2602.10330v1 Announce Type: cross 
Abstract: Context: JWST has enabled transmission spectroscopy at unprecedented precision, but stellar heterogeneities (spots and faculae) remain a dominant contamination source that can bias atmospheric retrievals if uncorrected. Aims: We present a fast, unsupervised methodology to reduce stellar contamination and instrument-specific noise in exoplanet transmission spectra using denoising autoencoders, improving the reliability of retrieved atmospheric parameters. Methods: We design and train denoising autoencoder architectures on large synthetic datasets of terrestrial (TRAPPIST-1e analogues) and sub-Neptune (K2-18b analogues) planets. Reconstruction quality is evaluated with the $\chi^2$ statistic over a wide range of signal-to-noise ratios, and atmospheric retrieval experiments on contaminated spectra are used to compare against standard correction approaches in accuracy and computational cost. Results: The autoencoders reconstruct uncontaminated spectra while preserving key molecular features, even at low S/N. In retrieval tests, pre-processing with denoising autoencoders reduces bias in inferred abundances relative to uncorrected baselines and matches the accuracy of simultaneous stellar-contamination fitting while reducing computational time by a factor of three to six. Conclusions: Denoising autoencoders provide an efficient alternative to conventional correction strategies and are promising components of future atmospheric characterization pipelines for both rocky and gaseous exoplanets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10330v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David S. Duque-Casta\~no, Lauren Flor-Torres, Jorge I. Zuluaga</dc:creator>
    </item>
    <item>
      <title>Unidentified falling objects in the LHC as dark matter signals</title>
      <link>https://arxiv.org/abs/2602.10562</link>
      <description>arXiv:2602.10562v1 Announce Type: cross 
Abstract: Unidentified Falling Objects (UFOs) refer to sporadic beam losses observed during LHC operation. The prevailing explanation is that micrometer-sized dust particles released from the beam screen produce beam losses through interactions with the protons. However, the release mechanism of these particles remains unknown. We propose that roughly $(1-10)$% of UFOs may be caused by axion quark nuggets (AQNs), macroscopic dark matter (DM) candidates with masses of order $(5-1000)\,$g. The AQN model naturally relates the dark- and visible-matter abundances ($\Omega_\mathrm{DM}\sim\Omega_\mathrm{visible}$) and provides a mechanism for generating the baryon-antibaryon asymmetry, with DM composed of both matter and antimatter AQNs. When passing underground within approximately 100km of the LHC, an antimatter AQN generates acoustic waves strong enough to trigger multiple UFO events within $2\,$s. If three correlated UFOs (placed at different locations along the LHC ring) are detected, the signal-to-noise ratio can exceed 5 across the entire allowed AQN mass range for a measurement time of about 360 hours. Practically, the LHC can serve as a large broadband acoustic detector for AQNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10562v1</guid>
      <category>hep-ph</category>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <category>physics.acc-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xunyu Liang, Ariel Zhitnitsky</dc:creator>
    </item>
    <item>
      <title>Photons x Force: Differentiable Radiation Pressure Modeling</title>
      <link>https://arxiv.org/abs/2602.10712</link>
      <description>arXiv:2602.10712v1 Announce Type: cross 
Abstract: We propose a system to optimize parametric designs subject to radiation pressure, \ie the effect of light on the motion of objects. This is most relevant in the design of spacecraft, where radiation pressure presents the dominant non-conservative forcing mechanism, which is the case beyond approximately 800 km altitude. Despite its importance, the high computational cost of high-fidelity radiation pressure modeling has limited its use in large-scale spacecraft design, optimization, and space situational awareness applications. We enable this by offering three innovations in the simulation, in representation and in optimization: First, a practical computer graphics-inspired Monte-Carlo (MC) simulation of radiation pressure. The simulation is highly parallel, uses importance sampling and next-event estimation to reduce variance and allows simulating an entire family of designs instead of a single spacecraft as in previous work. Second, we introduce neural networks as a representation of forces from design parameters. This neural proxy model, learned from simulations, is inherently differentiable and can query forces orders of magnitude faster than a full MC simulation. Third, and finally, we demonstrate optimizing inverse radiation pressure designs, such as finding geometry, material or operation parameters that minimizes travel time, maximizes proximity given a desired end-point, minimize thruster fuel, trains mission control policies or allocated compute budget in extraterrestrial compute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10712v1</guid>
      <category>cs.GR</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Constant, Elizabeth Bates, Santosh Bhattarai, Marek Ziebart, Tobias Ritschel</dc:creator>
    </item>
    <item>
      <title>Deep and Sparse Denoising Benchmarks for Spectral Data Cubes of High-z Galaxies: From Simulations to ALMA observations</title>
      <link>https://arxiv.org/abs/2602.10893</link>
      <description>arXiv:2602.10893v1 Announce Type: cross 
Abstract: Beyond cosmic noon, galaxies appear as faint whispers amid noise, yet this epoch is key to understanding massive galaxy assembly. ALMA's sensitivity to cold dust and [C II] emission allows us to probe their interstellar medium, but faint signals make robust denoising essential. We evaluate and benchmark denoising strategies including Principal Component Analysis, Independent Component Analysis, sparse unsupervised representations: iterative soft thresholding with 2D-1D wavelets, and supervised deep learning with a 3D U-Net, to identify techniques that suppress noise while preserving flux and morphology across peak SNRs of 2.5-8, applied to (i) synthetic spectral cubes of rotating toy disk galaxies, (ii) synthetic [C II] IFU cubes from FIRE simulations, and (iii) ALMA [C II] observations of CRISTAL galaxies and W2246-0526. Performance is assessed via RMSE, conservation of flux and spectra, noise reduction, and SNR improvement of the central galaxy. For synthetic cubes: PCA and ICA provide marginal improvement; IST reduces noise effectively at moderate SNRs but can suppress emission at low SNRs; and the U-Net outperforms IST, though it can produce quantifiable hallucinations at lower-SNRs. For moderate-SNR observations (ALMA-CRISTAL), U-Net and IST achieve comparable performance, conserving &gt;91% flux and increasing SNR by &gt;6. However, for observations with complex morphologies absent in the training set (W2246), the U-Net underperforms relative to IST, recovering ~80% flux, while IST robustly conserves flux and improves SNR by ~3, highlighting generalisation challenges and the need for physically-motivated training priors. We conclude that IST is a robust unsupervised denoiser for moderate-SNR data, and a synthetically trained U-Net generalises effectively to real data, dependent on training priors. This framework offers a pathway for transferable denoising for ALMA, VLT/MUSE, and JWST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10893v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnab Lahiry, Tanio D\'iaz-Santos, Jean-Luc Starck, Niranjan Chandra Roy, Daniel Angl\'es-Alc\'azar, Grigorios Tsagkatakis, Panagiotis Tsakalides</dc:creator>
    </item>
    <item>
      <title>Future Perspectives on Black Hole Jet Mechanisms: Insights from Next-Generation Observatories and Theoretical Developments</title>
      <link>https://arxiv.org/abs/2602.11094</link>
      <description>arXiv:2602.11094v1 Announce Type: cross 
Abstract: Black hole jets represent one of the most extreme manifestations of astrophysical processes, linking accretion physics, relativistic magnetohydrodynamics, and large-scale feedback in galaxies and clusters. Despite decades of observational and theoretical work, the mechanisms governing jet launching, collimation, and energy dissipation remain open questions. In this article, we discuss how upcoming facilities such as the Event Horizon Telescope (EHT), the Cherenkov Telescope Array (CTA), the Vera C. Rubin Observatory (LSST), and the Whole Earth Blazar Telescope (WEBT) will provide unprecedented constraints on jet dynamics, variability, and multi-wavelength signatures. Furthermore, we highlight theoretical challenges, including the role of magnetically arrested disks (MADs), plasma microphysics, and general relativistic magnetohydrodynamic (GRMHD) simulations in shaping our understanding of jet formation. By combining high-resolution imaging, time-domain surveys, and advanced simulations, the next decade promises transformative progress in unveiling the physics of black hole jets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11094v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/universe12010024</arxiv:DOI>
      <arxiv:journal_reference>Universe 2026, Volume 12, 24</arxiv:journal_reference>
      <dc:creator>Andre L. B. Ribeiro, Nathalia M. N. da Rocha</dc:creator>
    </item>
    <item>
      <title>HyperAIRI: a plug-and-play algorithm for precise hyperspectral image reconstruction in radio interferometry</title>
      <link>https://arxiv.org/abs/2510.15198</link>
      <description>arXiv:2510.15198v2 Announce Type: replace 
Abstract: The next-generation radio-interferometric (RI) telescopes require imaging algorithms capable of forming high-resolution high-dynamic-range images from large data volumes spanning wide frequency bands. Recently, AIRI, a plug-and-play (PnP) approach taking the forward-backward algorithmic structure (FB), has demonstrated state-of-the-art performance in monochromatic RI imaging by alternating a data-fidelity step with a regularization step via learned denoisers. In this work, we introduce HyperAIRI, its hyperspectral extension, underpinned by learned hyperspectral denoisers enforcing a power-law spectral model. For each spectral channel, the HyperAIRI denoiser takes as input its current image estimate, alongside estimates of its two immediate neighboring channels and the spectral index map, and provides as output its associated denoised image. To ensure convergence of HyperAIRI, the denoisers are trained with a Jacobian regularization enforcing non-expansiveness. To accommodate varying dynamic ranges, we assemble a shelf of pre-trained denoisers, each tailored to a specific dynamic range. At each HyperAIRI iteration, the spectral channels of the target image cube are updated in parallel using dynamic-range-matched denoisers from the pre-trained shelf. The denoisers are also endowed with a spatial image faceting functionality, enabling scalability to varied image sizes. Additionally, we formally introduce Hyper-uSARA, a variant of the optimization-based algorithm HyperSARA, promoting joint sparsity across spectral channels via the $\ell_{2,1}$-norm, also adopting FB. We evaluate HyperAIRI's performance on simulated and real observations. We showcase its superior performance compared to its optimization-based counterpart Hyper-uSARA, CLEAN's hyperspectral variant in WSClean, and the monochromatic imaging algorithms AIRI and uSARA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15198v2</guid>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chao Tang, Arwa Dabbech, Adrian Jackson, Yves Wiaux</dc:creator>
    </item>
    <item>
      <title>Simulation-based inference with neural posterior estimation applied to X-ray spectral fitting -- III Deriving exact posteriors with dimension reduction and importance sampling</title>
      <link>https://arxiv.org/abs/2512.16709</link>
      <description>arXiv:2512.16709v2 Announce Type: replace 
Abstract: Simulation-based inference (SBI) with neural posterior estimation (NPE) provides rapid X-ray spectral fitting in both Gaussian and Poisson regimes by learning approximate parameter posteriors from simulations. We investigate auto-encoders for compressing high-resolution X-ray spectra, motivated by newAthena X-ray Integral Field Unit (X-IFU), and use likelihood-based importance sampling to refine NPE outputs. Our auto-encoder maps spectra to a low-dimensional latent space and is trained with a custom loss equal to the Cash statistic (C-stat) between simulated and reconstructed spectra. A neural density estimator is then trained on the latent representations. Both models are trained in multiple rounds: at each round, new simulations are drawn from a truncated proposal concentrated around the observation, improving efficiency as the proposal contracts. After NPE convergence, we apply likelihood-based importance sampling to correct the learned posterior. To assess information retention, we train a diagnostic network that predicts the original spectral parameters from the latent space, and we also train a network to learn the likelihood directly to accelerate importance sampling. On X-IFU-like simulations, the auto-encoder and multi-round NPE outperforms PCA and hand-crafted spectral summaries in accuracy and robustness. After importance sampling, the resulting posteriors are statistically indistinguishable from those obtained with nested sampling. On a standard laptop, the full pipeline (simulation, compression, inference, correction) delivers 10x speedups. We further demonstrate the approach on XRISM/Resolve and on lower-resolution NICER and XMM-Newton EPIC-pn data, confirming applicability across instruments and resolutions. Overall, NPE on compressed spectra paired with likelihood-based importance sampling offers an exact yet efficient alternative for Bayesian X-ray spectral fitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16709v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Didier Barret, Simon Dupourqu\'e</dc:creator>
    </item>
    <item>
      <title>Ten-dimensional neural network emulator for the nonlinear matter power spectrum</title>
      <link>https://arxiv.org/abs/2507.07177</link>
      <description>arXiv:2507.07177v2 Announce Type: replace-cross 
Abstract: We present GokuNEmu, a ten-dimensional neural network emulator for the nonlinear matter power spectrum, designed to support next-generation cosmological analyses. Built on the Goku $N$-body simulation suite and the T2N-MusE emulation framework, GokuNEmu predicts the matter power spectrum with $\sim 0.5 \%$ average accuracy for redshifts $0 \leq z \leq 3$ and scales $0.006 \leq k/(h\,\mathrm{Mpc}^{-1}) \leq 10$. The emulator models a 10D parameter space that extends beyond $\Lambda$CDM to include dynamical dark energy (characterized by $w_0$ and $w_a$), massive neutrinos ($\sum m_\nu$), the effective number of neutrinos ($N_\text{eff}$), and running of the spectral index ($\alpha_\text{s}$). Its broad parameter coverage, particularly for the extensions, makes it the only matter power spectrum emulator capable of testing recent dynamical dark energy constraints from DESI. In addition, it requires only $\sim $2 milliseconds to predict a single cosmology on a laptop, orders of magnitude faster than existing emulators. These features make GokuNEmu a uniquely powerful tool for interpreting observational data from upcoming surveys such as LSST, Euclid, the Roman Space Telescope, and CSST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07177v2</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/8yzy-t59w</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 136, 061001 (2026)</arxiv:journal_reference>
      <dc:creator>Yanhui Yang, Simeon Bird, Ming-Feng Ho, Mahdi Qezlou</dc:creator>
    </item>
    <item>
      <title>Design and optimization of neural networks for multifidelity cosmological emulation</title>
      <link>https://arxiv.org/abs/2507.07184</link>
      <description>arXiv:2507.07184v2 Announce Type: replace-cross 
Abstract: Accurate and efficient simulation-based emulators are essential for interpreting cosmological survey data down to nonlinear scales. Multifidelity emulation techniques reduce simulation costs by combining high- and low-fidelity data, but traditional regression methods such as Gaussian processes struggle with scalability in sample size and dimensionality. In this work, we present T2N-MusE, a neural network framework characterized by (i) a novel 2-step multifidelity architecture, (ii) a 2-stage Bayesian hyperparameter optimization, (iii) a 2-phase $k$-fold training strategy, and (iv) a per-$z$ principal component analysis strategy. We apply T2N-MusE to selected data from the Goku simulation suite, covering a 10-dimensional cosmological parameter space, and build emulators for the matter power spectrum over a range of redshifts with different configurations. We find the emulators outperform our earlier Gaussian process models significantly and demonstrate that each of these techniques is efficient in training neural networks or/and effective in improving generalization accuracy. We observe a reduction in the mean error by more than a factor of five and in the worst-case error by approximately a factor of eight in leave-one-out cross-validation, relative to previous work. This framework has been used to build the most powerful emulator for the matter power spectrum, GokuNEmu, and will also be used to construct emulators for other statistics in future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07184v2</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/cqrc-k8wq</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 113, 043508 (2026)</arxiv:journal_reference>
      <dc:creator>Yanhui Yang, Simeon Bird, Ming-Feng Ho, Mahdi Qezlou</dc:creator>
    </item>
    <item>
      <title>A semi-coherent search for optical pulsations from Scorpius X-1</title>
      <link>https://arxiv.org/abs/2508.04873</link>
      <description>arXiv:2508.04873v2 Announce Type: replace-cross 
Abstract: The emission of continuous gravitational waves (CWs) possibly explains why pulsars spinning with a period shorter than a millisecond have not been observed so far. Neutron stars accreting mass at the highest rates are the most promising targets for a search for CWs, because a strong emission of gravitational waves is required to balance the torque exerted by mass accretion onto the neutron star. Detecting coherent pulsations in the electromagnetic emission maximizes the search sensitivity, but has so far not been successful for most of the brightest accreting neutron stars. Here, we present the first search for pulsations in the optical band from the brightest accreting neutron star known, Sco X-1. To this end, we tailored semi-coherent search strategies to data obtained over four years, for a total of $\sim$$56$ ks, by the SiFAP2 fast photometer mounted at the Telescopio Nazionale Galileo (TNG). These searches are especially suited to analysing long observations of systems for which only limited knowledge on the orbital parameters is available, and involve joining coherent analyses on shorter segments without connecting the spin phase between them. The large count rates afforded by an optical telescope and the efficiency of the search strategy employed allowed us to set an upper limit of $9 \times 10^{-5}$ to the pulsed amplitude, which is lower by a factor of four with respect to previous searches in the X-ray band. We also show that the application of semi-coherent searches to SiFAP2 observations of the first detected optical millisecond pulsar, PSR J1023+0038, could have preceded its detection in the radio band. These results highlight the role played by high-time-resolution optical observations in performing deep searches of quickly rotating pulsars.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04873v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1051/0004-6361/202556662</arxiv:DOI>
      <dc:creator>Riccardo La Placa (INAF - Osservatorio Astronomico di Roma, Monte Porzio Catone, Italy), Alessandro Papitto (INAF - Osservatorio Astronomico di Roma, Monte Porzio Catone, Italy), Giulia Illiano (INAF - Osservatorio Astronomico di Brera, Merate, Italy, INAF - Osservatorio Astronomico di Roma, Monte Porzio Catone, Italy), Filippo Ambrosino (INAF - Osservatorio Astronomico di Roma, Monte Porzio Catone, Italy), Christian Malacaria (INAF - Osservatorio Astronomico di Roma, Monte Porzio Catone, Italy), Luigi Stella (INAF - Osservatorio Astronomico di Roma, Monte Porzio Catone, Italy), Paola Leaci (INFN, Sezione di Roma, Roma, Italy, Universit\`a di Roma 'La Sapienza', Roma, Italy), Pia Astone (INFN, Sezione di Roma, Roma, Italy), Cristiano Palomba (INFN, Sezione di Roma, Roma, Italy), Sara Motta (INAF - Osservatorio Astronomico di Brera, Merate, Italy, University of Oxford, Department of Physics, Astrophysics, Oxford, United Kingdom), Adriano Ghedina (Fundaci\'on Galileo Galilei - INAF, B.Baja), Massimo Cecconi (Fundaci\'on Galileo Galilei - INAF, B.Baja), Francesco Leone (Dipartimento di Fisica e Astronomia, Sezione Astrofisica, Universit\`a di Catania, Catania, Italy, INAF - Osservatorio Astrofisico di Catania, Catania, Italy), Manuel Gonz\'alez (Fundaci\'on Galileo Galilei - INAF, B.Baja), H\'ector P\'erez Ventura (Fundaci\'on Galileo Galilei - INAF, B.Baja), Marcos Hernandez Diaz (Fundaci\'on Galileo Galilei - INAF, B.Baja), Jos\'e San Juan (Fundaci\'on Galileo Galilei - INAF, B.Baja)</dc:creator>
    </item>
    <item>
      <title>An Implementation to Identify the Properties of Multiple Population of Gravitational Wave Sources</title>
      <link>https://arxiv.org/abs/2509.13638</link>
      <description>arXiv:2509.13638v3 Announce Type: replace-cross 
Abstract: The rapidly increasing sensitivity of gravitational wave detectors is enabling the detection of a growing number of compact binary mergers. These events are crucial for understanding the population properties of compact binaries. However, many previous studies rely on computationally expensive inference frameworks, limiting their scalability.
  In this work, we present GWKokab, a JAX-based framework that enables modular model building with independent rate for each subpopulation such as BBH, BNS, and NSBH binaries. It provides accelerated inference using the normalizing flow based sampler called flowMC and is also compatible with NumPyro samplers.
  To validate our framework, we generated two synthetic populations, one comprising spinning eccentric binaries and the other circular binaries using a multi-source model. We then recovered their injected parameters at significantly reduced computational cost and demonstrated that eccentricity distribution can be recovered even in spinning eccentric populations. We also reproduced results from two prior studies: one on non-spinning eccentric populations, and another on the BBH mass distribution using the third Gravitational Wave Transient Catalog (GWTC-4).
  We anticipate that GWKokab will not only reduce computational costs but also enable more detailed subpopulation analyses such as their mass, spin, eccentricity, and redshift distributions in gravitational wave events, offering deeper insights into compact binary formation and evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13638v3</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meesum Qazalbash, Muhammad Zeeshan, Richard O'Shaughnessy</dc:creator>
    </item>
    <item>
      <title>First Multi-Constellation Observations of Navigation Satellite Signals in the Lunar Domain by Post-Processing L1/L5 IQ Snapshots</title>
      <link>https://arxiv.org/abs/2601.06081</link>
      <description>arXiv:2601.06081v2 Announce Type: replace-cross 
Abstract: The use of Global Navigation Satellite Systems (GNSS) to increase spacecraft autonomy for orbit determination has gained renewed momentum following the Lunar GNSS Receiver Experiment (LuGRE), which demonstrated feasible onboard GPS and Galileo signal reception and tracking at lunar distances. This work processes in-phase and quadrature (IQ) snapshots collected by the LuGRE receiver in cis-lunar space and on the lunar surface to assess multi-frequency, multi-constellation signal availability. Signals from additional systems beyond GPS and Galileo, including RNSS and SBAS constellations, are observable and successfully acquired exclusively in the recorded IQ snapshots. These observations provide the first experimental evidence that signals from multiple constellations, including systems not supported by LuGRE realtime operations, are detectable at unprecedented distances from Earth. Useful observables can be extracted from the IQ snapshots, despite minimal sampling rates, 4-bit quantization, and short durations (200 ms-2 s), through a hybrid coherent/non-coherent acquisition stage compensating for code Doppler. These observations are exploited to tune simulation tools and to perform extended simulation campaigns, showing that the inclusion of additional constellations significantly improves availability; for a 26 dB-Hz acquisition threshold, the fraction of epochs with at least four visible satellites increases from 11% to 46% of the total epoch count. These findings indicate that BeiDou, RNSS, and SBAS signals can substantially enhance GNSS-based autonomy for lunar and cislunar missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06081v2</guid>
      <category>physics.space-ph</category>
      <category>astro-ph.IM</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lorenzo Sciacca, Alex Minetto, Andrea Nardin, Fabio Dovis, Luca Canzian, Mario Musmeci, Claudia Facchinetti, Giancarlo Varacalli</dc:creator>
    </item>
  </channel>
</rss>
