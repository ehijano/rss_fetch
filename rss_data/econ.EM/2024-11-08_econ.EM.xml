<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:01:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An Adversarial Approach to Identification and Inference</title>
      <link>https://arxiv.org/abs/2411.04239</link>
      <description>arXiv:2411.04239v1 Announce Type: new 
Abstract: We introduce a novel framework to characterize identified sets of structural and counterfactual parameters in econometric models. Our framework centers on a discrepancy function, which we construct using insights from convex analysis. The zeros of the discrepancy function determine the identified set, which may be a singleton. The discrepancy function has an adversarial game interpretation: a critic maximizes the discrepancy between data and model features, while a defender minimizes it by adjusting the probability measure of the unobserved heterogeneity. Our approach enables fast computation via linear programming. We use the sample analog of the discrepancy function as a test statistic, and show that it provides asymptotically valid inference for the identified set. Applied to nonlinear panel models with fixed effects, it offers a unified approach for identifying both structural and counterfactual parameters across exogeneity conditions, including strict and sequential, without imposing parametric restrictions on the distribution of error terms or functional form assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04239v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irene Botosaru, Isaac Loh, Chris Muris</dc:creator>
    </item>
    <item>
      <title>Bounded Rationality in Central Bank Communication</title>
      <link>https://arxiv.org/abs/2411.04286</link>
      <description>arXiv:2411.04286v1 Announce Type: new 
Abstract: This study explores the influence of FOMC sentiment on market expectations, focusing on cognitive differences between experts and non-experts. Using sentiment analysis of FOMC minutes, we integrate these insights into a bounded rationality model to examine the impact on inflation expectations. Results show that experts form more conservative expectations, anticipating FOMC stabilization actions, while non-experts react more directly to inflation concerns. A lead-lag analysis indicates that institutions adjust faster, though the gap with individual investors narrows in the short term. These findings highlight the need for tailored communication strategies to better align public expectations with policy goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04286v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wonseong Kim, Choong Lyol Lee</dc:creator>
    </item>
    <item>
      <title>Lee Bounds with a Continuous Treatment in Sample Selection</title>
      <link>https://arxiv.org/abs/2411.04312</link>
      <description>arXiv:2411.04312v1 Announce Type: new 
Abstract: Sample selection problems arise when treatment affects both the outcome and the researcher's ability to observe it. This paper generalizes Lee (2009) bounds for the average treatment effect of a binary treatment to a continuous/multivalued treatment. We evaluate the Job Crops program to study the causal effect of training hours on wages. To identify the average treatment effect of always-takers who are selected regardless of the treatment values, we assume that if a subject is selected at some sufficient treatment values, then it remains selected at all treatment values. For example, if program participants are employed with one month of training, then they remain employed with any training hours. This sufficient treatment values assumption includes the monotone assumption on the treatment effect on selection as a special case. We further allow the conditional independence assumption and subjects with different pretreatment covariates to have different sufficient treatment values. The estimation and inference theory utilize the orthogonal moment function and cross-fitting for double debiased machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04312v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying-Ying Lee, Chu-An Liu</dc:creator>
    </item>
    <item>
      <title>Identification of Long-Term Treatment Effects via Temporal Links, Observational, and Experimental Data</title>
      <link>https://arxiv.org/abs/2411.04380</link>
      <description>arXiv:2411.04380v1 Announce Type: new 
Abstract: Recent literature proposes combining short-term experimental and long-term observational data to provide credible alternatives to conventional observational studies for identification of long-term average treatment effects (LTEs). I show that experimental data have an auxiliary role in this context. They bring no identifying power without additional modeling assumptions. When modeling assumptions are imposed, experimental data serve to amplify their identifying power. If the assumptions fail, adding experimental data may only yield results that are farther from the truth. Motivated by this, I introduce two assumptions on treatment response that may be defensible based on economic theory or intuition. To utilize them, I develop a novel two-step identification approach that centers on bounding temporal link functions -- the relationship between short-term and mean long-term potential outcomes. The approach provides sharp bounds on LTEs for a general class of assumptions, and allows for imperfect experimental compliance -- extending existing results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04380v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filip Obradovi\'c</dc:creator>
    </item>
    <item>
      <title>Partial Identification of Distributional Treatment Effects in Panel Data using Copula Equality Assumptions</title>
      <link>https://arxiv.org/abs/2411.04450</link>
      <description>arXiv:2411.04450v1 Announce Type: new 
Abstract: This paper aims to partially identify the distributional treatment effects (DTEs) that depend on the unknown joint distribution of treated and untreated potential outcomes. We construct the DTE bounds using panel data and allow individuals to switch between the treated and untreated states more than once over time. Individuals are grouped based on their past treatment history, and DTEs are allowed to be heterogeneous across different groups. We provide two alternative group-wise copula equality assumptions to bound the unknown joint and the DTEs, both of which leverage information from the past observations. Testability of these two assumptions are also discussed, and test results are presented. We apply this method to study the treatment effect heterogeneity of exercising on the adults' body weight. These results demonstrate that our method improves the identification power of the DTE bounds compared to the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04450v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heshani Madigasekara, D. S. Poskitt, Lina Zhang, Xueyan Zhao</dc:creator>
    </item>
    <item>
      <title>The role of expansion strategies and operational attributes on hotel performance: a compositional approach</title>
      <link>https://arxiv.org/abs/2411.04640</link>
      <description>arXiv:2411.04640v1 Announce Type: new 
Abstract: This study aims to explore the impact of expansion strategies and specific attributes of hotel establishments on the performance of international hotel chains, focusing on four key performance indicators: RevPAR, efficiency, occupancy, and asset turnover. Data were collected from 255 hotels across various international hotel chains, providing a comprehensive assessment of how different expansion strategies and hotel attributes influence performance. The research employs compositional data analysis (CoDA) to address the methodological limitations of traditional financial ratios in statistical analysis. The findings indicate that ownership-based expansion strategies result in higher operational performance, as measured by revenue per available room, but yield lower economic performance due to the high capital investment required. Non-ownership strategies, such as management contracts and franchising, show superior economic efficiency, offering more flexibility and reduced financial risk. This study contributes to the hospitality management literature by applying CoDA, a novel methodological approach in this field, to examine the performance of different hotel expansion strategies with a sound and more appropriate method. The insights provided can guide hotel managers and investors in making informed decisions to optimize both operational and economic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04640v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Mulet-Forteza, Berta Ferrer-Rosell, Onofre Martorell Cunill, Salvador Linares-Mustar\'os</dc:creator>
    </item>
    <item>
      <title>Does Principal Component Analysis Preserve the Sparsity in Sparse Weak Factor Models?</title>
      <link>https://arxiv.org/abs/2305.05934</link>
      <description>arXiv:2305.05934v2 Announce Type: replace 
Abstract: This paper studies the principal component (PC) method-based estimation of weak factor models with sparse loadings. We uncover an intrinsic near-sparsity preservation property for the PC estimators of loadings, which comes from the approximately upper triangular (block) structure of the rotation matrix. It implies an asymmetric relationship among factors: the rotated loadings for a stronger factor can be contaminated by those from a weaker one, but the loadings for a weaker factor is almost free of the impact of those from a stronger one. More importantly, the finding implies that there is no need to use complicated penalties to sparsify the loading estimators. Instead, we adopt a simple screening method to recover the sparsity and construct estimators for various factor strengths. In addition, for sparse weak factor models, we provide a singular value thresholding-based approach to determine the number of factors and establish uniform convergence rates for PC estimators, which complement Bai and Ng (2023). The accuracy and efficiency of the proposed estimators are investigated via Monte Carlo simulations. The application to the FRED-QD dataset reveals the underlying factor strengths and loading sparsity as well as their dynamic features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05934v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.23601.04965</arxiv:DOI>
      <dc:creator>Jie Wei, Yonghui Zhang</dc:creator>
    </item>
    <item>
      <title>Inference for Two-Stage Extremum Estimators</title>
      <link>https://arxiv.org/abs/2402.05030</link>
      <description>arXiv:2402.05030v2 Announce Type: replace 
Abstract: We present a simulation-based inference approach for two-stage estimators, focusing on extremum estimators in the second stage. We accommodate a broad range of first-stage estimators, including extremum estimators, high-dimensional estimators, and other types of estimators such as Bayesian estimators. The key contribution of our approach lies in its ability to estimate the asymptotic distribution of two-stage estimators, even when the distributions of both the first- and second-stage estimators are non-normal and when the second-stage estimator's bias, scaled by the square root of the sample size, does not vanish asymptotically. This enables reliable inference in situations where standard methods fail. Additionally, we propose a debiased estimator, based on the mean of the estimated distribution function, which exhibits improved finite sample properties. Unlike resampling methods, our approach avoids the need for multiple calculations of the two-stage estimator. We illustrate the effectiveness of our method in an empirical application on peer effects in adolescent fast-food consumption, where we address the issue of biased instrumental variable estimates resulting from many weak instruments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05030v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aristide Houndetoungan, Abdoul Haki Maoude</dc:creator>
    </item>
    <item>
      <title>Comment on 'Sparse Bayesian Factor Analysis when the Number of Factors is Unknown' by S. Fr\"uhwirth-Schnatter, D. Hosszejni, and H. Freitas Lopes</title>
      <link>https://arxiv.org/abs/2411.02531</link>
      <description>arXiv:2411.02531v2 Announce Type: replace-cross 
Abstract: The techniques suggested in Fr\"uhwirth-Schnatter et al. (2024) concern sparsity and factor selection and have enormous potential beyond standard factor analysis applications. We show how these techniques can be applied to Latent Space (LS) models for network data. These models suffer from well-known identification issues of the latent factors due to likelihood invariance to factor translation, reflection, and rotation (see Hoff et al., 2002). A set of observables can be instrumental in identifying the latent factors via auxiliary equations (see Liu et al., 2021). These, in turn, share many analogies with the equations used in factor modeling, and we argue that the factor loading restrictions may be beneficial for achieving identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02531v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Casarin (Ca' Foscari University of Venice), Antonio Peruzzi (Ca' Foscari University of Venice)</dc:creator>
    </item>
  </channel>
</rss>
