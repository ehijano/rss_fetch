<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2025 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploiting Partial Assignments in Optimization Modulo Theories</title>
      <link>https://arxiv.org/abs/2502.19963</link>
      <description>arXiv:2502.19963v1 Announce Type: new 
Abstract: Optimization Modulo Theories (OMT) extends Satisfiability Modulo Theories (SMT) with the task of optimizing some objective function(s). In OMT solvers, a CDCL-based SMT solver enumerates theory-satisfiable total truth assignments, and a theory-specific procedure finds an optimum model for each of them; the current optimum is then used to tighten the search space for the next assignments, until no better solution is found.
  In this paper, we analyze the role of truth-assignment enumeration in OMT. First, we spotlight that the enumeration of total truth assignments is suboptimal, since they may over-restrict the search space for the optimization procedure, whereas using partial truth assignments instead can improve the effectiveness of the optimization. Second, we propose some reduction techniques for better exploiting partial assignments in the OMT context. We implemented these techniques in the OPTIMATHSAT solver, and conducted an experimental evaluation on OMT(LRA) benchmarks. The results support the efficiency and effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19963v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gabriele Masina, Roberto Sebastiani</dc:creator>
    </item>
    <item>
      <title>Model Checking Linear Temporal Logic with Standpoint Modalities</title>
      <link>https://arxiv.org/abs/2502.20193</link>
      <description>arXiv:2502.20193v1 Announce Type: new 
Abstract: Standpoint linear temporal logic ($SLTL$) is a recently introduced extension of classical linear temporal logic ($LTL$) with standpoint modalities. Intuitively, these modalities allow to express that, from agent $a$'s standpoint, it is conceivable that a given formula holds.
  Besides the standard interpretation of the standpoint modalities we introduce four new semantics, which differ in the information an agent can extract from the history. We provide a general model checking algorithm applicable to $SLTL$ under any of the five semantics. Furthermore we analyze the computational complexity of the corresponding model checking problems, obtaining PSPACE-completeness in three cases, which stands in contrast to the known EXPSPACE-completeness of the $SLTL$ satisfiability problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20193v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajab Aghamov, Christel Baier, Toghrul Karimov, Rupak Majumdar, Jo\"el Ouaknine, Jakob Piribauer, Timm Spork</dc:creator>
    </item>
    <item>
      <title>On Piecewise Affine Reachability with Bellman Operators</title>
      <link>https://arxiv.org/abs/2502.19923</link>
      <description>arXiv:2502.19923v1 Announce Type: cross 
Abstract: A piecewise affine map is one of the simplest mathematical objects exhibiting complex dynamics. The reachability problem of piecewise affine maps is given as follows: Given two vectors $\mathbf{s}, \mathbf{t} \in \mathbb{Q}^d$ and a piecewise affine map $f$, is there $n\in \mathbb{N}$ such that $f^{n}(\mathbf{s}) = \mathbf{t}$? Koiran, Cosnard, and Garzon show that the reachability problem of piecewise affine maps is undecidable even in dimension 2.
  Most of the recent progress has been focused on decision procedures for one-dimensional piecewise affine maps, where the reachability problem has been shown to be decidable for some subclasses. However, the general undecidability discouraged research into positive results in arbitrary dimension.
  In this work, we consider a rich subclass of piecewise affine maps defined by Bellman operators of Markov decision processes (MDPs). We then investigate the restriction of the piecewise affine reachability problem to that with Bellman operators and, in particular, its decidability in any dimension. As one of our primary contributions, we establish the decidability of reachability for two-dimensional Bellman operators, in contrast to the negative result known for general piecewise affine maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19923v1</guid>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <category>math.DS</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Varonka, Kazuki Watanabe</dc:creator>
    </item>
    <item>
      <title>L-types for resource aware languages: an implicit name approach</title>
      <link>https://arxiv.org/abs/2112.11062</link>
      <description>arXiv:2112.11062v2 Announce Type: replace 
Abstract: A novel formalisation of variable control in languages with implicit names based on de Bruijn indices is presented. We design and implement three languages: first, a restricted language with implicit names; then, a restricted calculus with implicit names and explicit substitution, and finally, an extended calculus with implicit names and resource control. We propose a novel concept of list types, which are used to give a simple and manageable definition of linearity. We develop an implementation in Haskell.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.11062v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Silvia Ghilezan (MISANU), Jelena Iveti\'c (LIP, PLUME), Simona Ka\v{s}terovi\'c (LIP, PLUME), Pierre Lescanne (LIP, PLUME)</dc:creator>
    </item>
    <item>
      <title>Congruence Closure Modulo Groups</title>
      <link>https://arxiv.org/abs/2310.05014</link>
      <description>arXiv:2310.05014v4 Announce Type: replace 
Abstract: This paper presents a new framework for constructing congruence closure of a finite set of ground equations over uninterpreted symbols and interpreted symbols for the group axioms. In this framework, ground equations are flattened into certain forms by introducing new constants, and a completion procedure is performed on ground flat equations. The proposed completion procedure uses equational inference rules and constructs a ground convergent rewrite system for congruence closure with such interpreted symbols. If the completion procedure terminates, then it yields a decision procedure for the word problem for a finite set of ground equations with respect to the group axioms. This paper also provides a sufficient terminating condition of the completion procedure for constructing a ground convergent rewrite system from ground flat equations containing interpreted symbols for the group axioms. In addition, this paper presents a new method for constructing congruence closure of a finite set of ground equations containing interpreted symbols for the semigroup, monoid, and the multiple disjoint sets of group axioms, respectively, using the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05014v4</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dohan Kim</dc:creator>
    </item>
    <item>
      <title>Probabilistic Variational Causal Approach in Observational Studies</title>
      <link>https://arxiv.org/abs/2208.06269</link>
      <description>arXiv:2208.06269v5 Announce Type: replace-cross 
Abstract: In this paper, we introduce a new causal methodology that accounts for the rarity and frequency of events in observational studies based on their relevance to the underlying problem. Specifically, we propose a direct causal effect metric called the Probabilistic vAriational Causal Effect (PACE) and its variations adhering to certain postulates applicable to both non-binary and binary treatments. The PACE metric is derived by integrating the concept of total variation, representing the purely causal component, with interventions on the treatment value, combined with the probabilities of hypothetical transitioning between treatment levels. PACE features a parameter $d$, where lower values of $d$ correspond to scenarios emphasizing rare treatment values, while higher values of $d$ focus on situations where the causal impact of more frequent treatment levels is more relevant. Thus, instead of a single causal effect value, we provide a causal effect function of the degree $d$. Additionally, we introduce positive and negative PACE to measure the respective positive and negative causal changes in the outcome as exposure values shift. We also consider normalized versions of PACE, referred to MEAN PACE. Furthermore, we provide an identifiability criterion for PACE to handle counterfactual challenges in observational studies, and we define several generalizations of our methodology. Lastly, we compare our framework with other well-known causal frameworks through the analysis of various examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06269v5</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Usef Faghihi, Amir Saki</dc:creator>
    </item>
    <item>
      <title>Denotational Foundations for Expected Cost Analysis</title>
      <link>https://arxiv.org/abs/2402.01009</link>
      <description>arXiv:2402.01009v2 Announce Type: replace-cross 
Abstract: Reasoning about the cost of executing programs is one of the fundamental questions in computer science. In the context of programming with probabilities, however, the notion of cost stops being deterministic, since it depends on the probabilistic samples made throughout the execution of the program. This interaction is further complicated by the non-trivial interaction between cost, recursion and evaluation strategy.
  In this work we introduce $\mathbf{cert}$: a Call-By-Push-Value (CBPV) metalanguage for reasoning about probabilistic cost. We equip $\mathbf{cert}$ with an operational cost semantics and define two denotational semantics -- a cost semantics and an expected-cost semantics. We prove operational soundness and adequacy for the denotational cost semantics and a cost adequacy theorem for the expected-cost semantics.
  We formally relate both denotational semantics by stating and proving a novel \emph{effect simulation} property for CBPV. We also prove a canonicity property of the expected-cost semantics as the minimal semantics for expected cost and probability by building on recent advances on monadic probabilistic semantics.
  Finally, we illustrate the expressivity of $\mathbf{cert}$ and the expected-cost semantics by presenting case-studies ranging from randomized algorithms to stochastic processes and show how our semantics capture their intended expected cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01009v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro H. Azevedo de Amorim</dc:creator>
    </item>
    <item>
      <title>Herald: A Natural Language Annotated Lean 4 Dataset</title>
      <link>https://arxiv.org/abs/2410.10878</link>
      <description>arXiv:2410.10878v2 Announce Type: replace-cross 
Abstract: Verifiable formal languages like Lean have profoundly impacted mathematical reasoning, particularly through the use of large language models (LLMs) for automated reasoning. A significant challenge in training LLMs for these formal languages is the lack of parallel datasets that align natural language with formal language proofs. To address this challenge, this paper introduces a novel framework for translating the Mathlib4 corpus (a unified library of mathematics in formal language Lean 4) into natural language. Building upon this, we employ a dual augmentation strategy that combines tactic-based and informal-based approaches, leveraging the Lean-jixia system, a Lean 4 analyzer. We present the results of this pipeline on Mathlib4 as Herald (Hierarchy and Retrieval-based Translated Lean Dataset). We also propose the Herald Translator, which is fine-tuned on Herald. Herald translator achieves a 93.2% accuracy (Pass@128) on formalizing statements in the miniF2F-test and a 22.5% accuracy on our internal graduate-level textbook dataset, outperforming InternLM2-Math-Plus-7B (74.0% and 7.5%) and TheoremLlama (50.1% and 4.0%). Furthermore, we propose a section-level translation framework for real-world applications. As a direct application of Herald translator, we have successfully translated a template section in the Stack project, marking a notable progress in the automatic formalization of graduate-level mathematical literature. Our model, along with the datasets, are open-sourced to the public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10878v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guoxiong Gao, Yutong Wang, Jiedong Jiang, Qi Gao, Zihan Qin, Tianyi Xu, Bin Dong</dc:creator>
    </item>
    <item>
      <title>Programming Really Is Simple Mathematics</title>
      <link>https://arxiv.org/abs/2502.17149</link>
      <description>arXiv:2502.17149v3 Announce Type: replace-cross 
Abstract: A re-construction of the fundamentals of programming as a small mathematical theory (PRISM) based on elementary set theory. Highlights:
  $\bullet$ Zero axioms. No properties are assumed, all are proved (from standard set theory).
  $\bullet$ A single concept covers specifications and programs.
  $\bullet$ Its definition only involves one relation and one set.
  $\bullet$ Everything proceeds from three operations: choice, composition and restriction.
  $\bullet$ These techniques suffice to derive the axioms of classic papers on the "laws of programming" as consequences and prove them mechanically.
  $\bullet$ The ordinary subset operator suffices to define both the notion of program correctness and the concepts of specialization and refinement.
  $\bullet$ From this basis, the theory deduces dozens of theorems characterizing important properties of programs and programming.
  $\bullet$ All these theorems have been mechanically verified (using Isabelle/HOL); the proofs are available in a public repository. This paper is a considerable extension and rewrite of an earlier contribution [arXiv:1507.00723]</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17149v3</guid>
      <category>cs.SE</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bertrand Meyer, Reto Weber</dc:creator>
    </item>
  </channel>
</rss>
