<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ML updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ML" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference</title>
      <link>https://arxiv.org/abs/2408.01582</link>
      <description>arXiv:2408.01582v1 Announce Type: new 
Abstract: Estimating treatment effects from observational data is of central interest across numerous application domains. Individual treatment effect offers the most granular measure of treatment effect on an individual level, and is the most useful to facilitate personalized care. However, its estimation and inference remain underdeveloped due to several challenges. In this article, we propose a novel conformal diffusion model-based approach that addresses those intricate challenges. We integrate the highly flexible diffusion modeling, the model-free statistical inference paradigm of conformal inference, along with propensity score and covariate local approximation that tackle distributional shifts. We unbiasedly estimate the distributions of potential outcomes for individual treatment effect, construct an informative confidence interval, and establish rigorous theoretical guarantees. We demonstrate the competitive performance of the proposed method over existing solutions through extensive numerical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01582v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengrui Cai, Huaqing Jin, Lexin Li</dc:creator>
    </item>
    <item>
      <title>Cost-constrained multi-label group feature selection using shadow features</title>
      <link>https://arxiv.org/abs/2408.01851</link>
      <description>arXiv:2408.01851v1 Announce Type: new 
Abstract: We consider the problem of feature selection in multi-label classification, considering the costs assigned to groups of features. In this task, the goal is to select a subset of features that will be useful for predicting the label vector, but at the same time, the cost associated with the selected features will not exceed the assumed budget. Solving the problem is of great importance in medicine, where we may be interested in predicting various diseases based on groups of features. The groups may be associated with parameters obtained from a certain diagnostic test, such as a blood test. Because diagnostic test costs can be very high, considering cost information when selecting relevant features becomes crucial to reducing the cost of making predictions. We focus on the feature selection method based on information theory. The proposed method consists of two steps. First, we select features sequentially while maximizing conditional mutual information until the budget is exhausted. In the second step, we select additional cost-free features, i.e., those coming from groups that have already been used in previous steps. Limiting the number of added features is possible using the stop rule based on the concept of so-called shadow features, which are randomized counterparts of the original ones. In contrast to existing approaches based on penalized criteria, in our method, we avoid the need for computationally demanding optimization of the penalty parameter. Experiments conducted on the MIMIC medical database show the effectiveness of the method, especially when the assumed budget is limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01851v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tomasz Klonecki, Pawe{\l} Teisseyre, Jaesung Lee</dc:creator>
    </item>
    <item>
      <title>Meta-Posterior Consistency for the Bayesian Inference of Metastable System</title>
      <link>https://arxiv.org/abs/2408.01868</link>
      <description>arXiv:2408.01868v1 Announce Type: new 
Abstract: The vast majority of the literature on learning dynamical systems or stochastic processes from time series has focused on stable or ergodic systems, for both Bayesian and frequentist inference procedures. However, most real-world systems are only metastable, that is, the dynamics appear to be stable on some time scale, but are in fact unstable over longer time scales. Consistency of inference for metastable systems may not be possible, but one can ask about metaconsistency: Do inference procedures converge when observations are taken over a large but finite time interval, but diverge on longer time scales? In this paper we introduce, discuss, and quantify metaconsistency in a Bayesian framework. We discuss how metaconsistency can be exploited to efficiently infer a model for a sub-system of a larger system, where inference on the global behavior may require much more data. We also discuss the relation between meta-consistency and the spectral properties of the model dynamical system in the case of uniformly ergodic diffusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01868v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary P Adams, Sayan Mukherjee</dc:creator>
    </item>
    <item>
      <title>DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation</title>
      <link>https://arxiv.org/abs/2408.02045</link>
      <description>arXiv:2408.02045v1 Announce Type: new 
Abstract: Semiparametric statistics play a pivotal role in a wide range of domains, including but not limited to missing data, causal inference, and transfer learning, to name a few. In many settings, semiparametric theory leads to (nearly) statistically optimal procedures that yet involve numerically solving Fredholm integral equations of the second kind. Traditional numerical methods, such as polynomial or spline approximations, are difficult to scale to multi-dimensional problems. Alternatively, statisticians may choose to approximate the original integral equations by ones with closed-form solutions, resulting in computationally more efficient, but statistically suboptimal or even incorrect procedures. To bridge this gap, we propose a novel framework by formulating the semiparametric estimation problem as a bi-level optimization problem; and then we develop a scalable algorithm called Deep Neural-Nets Assisted Semiparametric Estimation (DNA-SE) by leveraging the universal approximation property of Deep Neural-Nets (DNN) to streamline semiparametric procedures. Through extensive numerical experiments and a real data analysis, we demonstrate the numerical and statistical advantages of $\dnase$ over traditional methods. To the best of our knowledge, we are the first to bring DNN into semiparametric statistics as a numerical solver of integral equations in our proposed general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02045v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinshuo Liu, Zixin Wang, Xi-An Li, Xinyao Ji, Lei Zhang, Lin Liu, Zhonghua Liu</dc:creator>
    </item>
    <item>
      <title>Quantile Regression using Random Forest Proximities</title>
      <link>https://arxiv.org/abs/2408.02355</link>
      <description>arXiv:2408.02355v1 Announce Type: new 
Abstract: Due to the dynamic nature of financial markets, maintaining models that produce precise predictions over time is difficult. Often the goal isn't just point prediction but determining uncertainty. Quantifying uncertainty, especially the aleatoric uncertainty due to the unpredictable nature of market drivers, helps investors understand varying risk levels. Recently, quantile regression forests (QRF) have emerged as a promising solution: Unlike most basic quantile regression methods that need separate models for each quantile, quantile regression forests estimate the entire conditional distribution of the target variable with a single model, while retaining all the salient features of a typical random forest. We introduce a novel approach to compute quantile regressions from random forests that leverages the proximity (i.e., distance metric) learned by the model and infers the conditional distribution of the target variable. We evaluate the proposed methodology using publicly available datasets and then apply it towards the problem of forecasting the average daily volume of corporate bonds. We show that using quantile regression using Random Forest proximities demonstrates superior performance in approximating conditional target distributions and prediction intervals to the original version of QRF. We also demonstrate that the proposed framework is significantly more computationally efficient than traditional approaches to quantile regressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02355v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingshu Li, Bhaskarjit Sarmah, Dhruv Desai, Joshua Rosaler, Snigdha Bhagat, Philip Sommer, Dhagash Mehta</dc:creator>
    </item>
    <item>
      <title>On Probabilistic Embeddings in Optimal Dimension Reduction</title>
      <link>https://arxiv.org/abs/2408.02433</link>
      <description>arXiv:2408.02433v1 Announce Type: new 
Abstract: Dimension reduction algorithms are a crucial part of many data science pipelines, including data exploration, feature creation and selection, and denoising. Despite their wide utilization, many non-linear dimension reduction algorithms are poorly understood from a theoretical perspective. In this work we consider a generalized version of multidimensional scaling, which is posed as an optimization problem in which a mapping from a high-dimensional feature space to a lower-dimensional embedding space seeks to preserve either inner products or norms of the distribution in feature space, and which encompasses many commonly used dimension reduction algorithms. We analytically investigate the variational properties of this problem, leading to the following insights: 1) Solutions found using standard particle descent methods may lead to non-deterministic embeddings, 2) A relaxed or probabilistic formulation of the problem admits solutions with easily interpretable necessary conditions, 3) The globally optimal solutions to the relaxed problem actually must give a deterministic embedding. This progression of results mirrors the classical development of optimal transportation, and in a case relating to the Gromov-Wasserstein distance actually gives explicit insight into the structure of the optimal embeddings, which are parametrically determined and discontinuous. Finally, we illustrate that a standard computational implementation of this task does not learn deterministic embeddings, which means that it learns sub-optimal mappings, and that the embeddings learned in that context have highly misleading clustering structure, underscoring the delicate nature of solving this problem computationally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02433v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Murray, Adam Pickarski</dc:creator>
    </item>
    <item>
      <title>Gradient flow in parameter space is equivalent to linear interpolation in output space</title>
      <link>https://arxiv.org/abs/2408.01517</link>
      <description>arXiv:2408.01517v1 Announce Type: cross 
Abstract: We prove that the usual gradient flow in parameter space that underlies many training algorithms for neural networks in deep learning can be continuously deformed into an adapted gradient flow which yields (constrained) Euclidean gradient flow in output space. Moreover, if the Jacobian of the outputs with respect to the parameters is full rank (for fixed training data), then the time variable can be reparametrized so that the resulting flow is simply linear interpolation, and a global minimum can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01517v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patr\'icia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Deep Learning Framework for History Matching CO2 Storage with 4D Seismic and Monitoring Well Data</title>
      <link>https://arxiv.org/abs/2408.01575</link>
      <description>arXiv:2408.01575v1 Announce Type: cross 
Abstract: Geological carbon storage entails the injection of megatonnes of supercritical CO2 into subsurface formations. The properties of these formations are usually highly uncertain, which makes design and optimization of large-scale storage operations challenging. In this paper we introduce a history matching strategy that enables the calibration of formation properties based on early-time observations. Early-time assessments are essential to assure the operation is performing as planned. Our framework involves two fit-for-purpose deep learning surrogate models that provide predictions for in-situ monitoring well data and interpreted time-lapse (4D) seismic saturation data. These two types of data are at very different scales of resolution, so it is appropriate to construct separate, specialized deep learning networks for their prediction. This approach results in a workflow that is more straightforward to design and more efficient to train than a single surrogate that provides global high-fidelity predictions. The deep learning models are integrated into a hierarchical Markov chain Monte Carlo (MCMC) history matching procedure. History matching is performed on a synthetic case with and without 4D seismic data, which allows us to quantify the impact of 4D seismic on uncertainty reduction. The use of both data types is shown to provide substantial uncertainty reduction in key geomodel parameters and to enable accurate predictions of CO2 plume dynamics. The overall history matching framework developed in this study represents an efficient way to integrate multiple data types and to assess the impact of each on uncertainty reduction and performance predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01575v1</guid>
      <category>cs.LG</category>
      <category>physics.geo-ph</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nanzhe Wang, Louis J. Durlofsky</dc:creator>
    </item>
    <item>
      <title>Fair Risk Minimization under Causal Path-Specific Effect Constraints</title>
      <link>https://arxiv.org/abs/2408.01630</link>
      <description>arXiv:2408.01630v1 Announce Type: cross 
Abstract: This paper introduces a framework for estimating fair optimal predictions using machine learning where the notion of fairness can be quantified using path-specific causal effects. We use a recently developed approach based on Lagrange multipliers for infinite-dimensional functional estimation to derive closed-form solutions for constrained optimization based on mean squared error and cross-entropy risk criteria. The theoretical forms of the solutions are analyzed in detail and described as nuanced adjustments to the unconstrained minimizer. This analysis highlights important trade-offs between risk minimization and achieving fairnes. The theoretical solutions are also used as the basis for construction of flexible semiparametric estimation strategies for these nuisance components. We describe the robustness properties of our estimators in terms of achieving the optimal constrained risk, as well as in terms of controlling the value of the constraint. We study via simulation the impact of using robust estimators of pathway-specific effects to validate our theory. This work advances the discourse on algorithmic fairness by integrating complex causal considerations into model training, thus providing strategies for implementing fair models in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01630v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Razieh Nabi, David Benkeser</dc:creator>
    </item>
    <item>
      <title>Neural Term Structure of Additive Process for Option Pricing</title>
      <link>https://arxiv.org/abs/2408.01642</link>
      <description>arXiv:2408.01642v1 Announce Type: cross 
Abstract: The additive process generalizes the L\'evy process by relaxing its assumption of time-homogeneous increments and hence covers a larger family of stochastic processes. Recent research in option pricing shows that modeling the underlying log price with an additive process has advantages in easier construction of the risk-neural measure, an explicit option pricing formula and characteristic function, and more flexibility to fit the implied volatility surface. Still, the challenge of calibrating an additive model arises from its time-dependent parameterization, for which one has to prescribe parametric functions for the term structure. For this, we propose the neural term structure model to utilize feedforward neural networks to represent the term structure, which alleviates the difficulty of designing parametric functions and thus attenuates the misspecification risk. Numerical studies with S\&amp;P 500 option data are conducted to evaluate the performance of the neural term structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01642v1</guid>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jimin Lin, Guixin Liu</dc:creator>
    </item>
    <item>
      <title>Principal component analysis balancing prediction and approximation accuracy for spatial data</title>
      <link>https://arxiv.org/abs/2408.01662</link>
      <description>arXiv:2408.01662v1 Announce Type: cross 
Abstract: Dimension reduction is often the first step in statistical modeling or prediction of multivariate spatial data. However, most existing dimension reduction techniques do not account for the spatial correlation between observations and do not take the downstream modeling task into consideration when finding the lower-dimensional representation. We formalize the closeness of approximation to the original data and the utility of lower-dimensional scores for downstream modeling as two complementary, sometimes conflicting, metrics for dimension reduction. We illustrate how existing methodologies fall into this framework and propose a flexible dimension reduction algorithm that achieves the optimal trade-off. We derive a computationally simple form for our algorithm and illustrate its performance through simulation studies, as well as two applications in air pollution modeling and spatial transcriptomics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01662v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Si Cheng, Magali N. Blanco, Timothy V. Larson, Lianne Sheppard, Adam Szpiro, Ali Shojaie</dc:creator>
    </item>
    <item>
      <title>Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization</title>
      <link>https://arxiv.org/abs/2408.01697</link>
      <description>arXiv:2408.01697v1 Announce Type: cross 
Abstract: Graph out-of-distribution (OOD) generalization remains a major challenge in graph learning since graph neural networks (GNNs) often suffer from severe performance degradation under distribution shifts. Invariant learning, aiming to extract invariant features across varied distributions, has recently emerged as a promising approach for OOD generation. Despite the great success of invariant learning in OOD problems for Euclidean data (i.e., images), the exploration within graph data remains constrained by the complex nature of graphs. Existing studies, such as data augmentation or causal intervention, either suffer from disruptions to invariance during the graph manipulation process or face reliability issues due to a lack of supervised signals for causal parts. In this work, we propose a novel framework, called Invariant Graph Learning based on Information bottleneck theory (InfoIGL), to extract the invariant features of graphs and enhance models' generalization ability to unseen distributions. Specifically, InfoIGL introduces a redundancy filter to compress task-irrelevant information related to environmental factors. Cooperating with our designed multi-level contrastive learning, we maximize the mutual information among graphs of the same class in the downstream classification tasks, preserving invariant features for prediction to a great extent. An appealing feature of InfoIGL is its strong generalization ability without depending on supervised signal of invariance. Experiments on both synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance under OOD generalization for graph classification tasks. The source code is available at https://github.com/maowenyu-11/InfoIGL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01697v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyu Mao, Jiancan Wu, Haoyang Liu, Yongduo Sui, Xiang Wang</dc:creator>
    </item>
    <item>
      <title>Can LLMs predict the convergence of Stochastic Gradient Descent?</title>
      <link>https://arxiv.org/abs/2408.01736</link>
      <description>arXiv:2408.01736v1 Announce Type: cross 
Abstract: Large-language models are notoriously famous for their impressive performance across a wide range of tasks. One surprising example of such impressive performance is a recently identified capacity of LLMs to understand the governing principles of dynamical systems satisfying the Markovian property. In this paper, we seek to explore this direction further by studying the dynamics of stochastic gradient descent in convex and non-convex optimization. By leveraging the theoretical link between the SGD and Markov chains, we show a remarkable zero-shot performance of LLMs in predicting the local minima to which SGD converges for previously unseen starting points. On a more general level, we inquire about the possibility of using LLMs to perform zero-shot randomized trials for larger deep learning models used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01736v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oussama Zekri, Abdelhakim Benechehab, Ievgen Redko</dc:creator>
    </item>
    <item>
      <title>Batch Active Learning in Gaussian Process Regression using Derivatives</title>
      <link>https://arxiv.org/abs/2408.01861</link>
      <description>arXiv:2408.01861v1 Announce Type: cross 
Abstract: We investigate the use of derivative information for Batch Active Learning in Gaussian Process regression models. The proposed approach employs the predictive covariance matrix for selection of data batches to exploit full correlation of samples. We theoretically analyse our proposed algorithm taking different optimality criteria into consideration and provide empirical comparisons highlighting the advantage of incorporating derivatives information. Our results show the effectiveness of our approach across diverse applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01861v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hon Sum Alec Yu, Christoph Zimmer, Duy Nguyen-Tuong</dc:creator>
    </item>
    <item>
      <title>Efficient Decision Trees for Tensor Regressions</title>
      <link>https://arxiv.org/abs/2408.01926</link>
      <description>arXiv:2408.01926v1 Announce Type: cross 
Abstract: We proposed the tensor-input tree (TT) method for scalar-on-tensor and tensor-on-tensor regression problems. We first address scalar-on-tensor problem by proposing scalar-output regression tree models whose input variable are tensors (i.e., multi-way arrays). We devised and implemented fast randomized and deterministic algorithms for efficient fitting of scalar-on-tensor trees, making TT competitive against tensor-input GP models. Based on scalar-on-tensor tree models, we extend our method to tensor-on-tensor problems using additive tree ensemble approaches. Theoretical justification and extensive experiments on real and synthetic datasets are provided to illustrate the performance of TT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01926v1</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengrui Luo, Akira Horiguchi, Li Ma</dc:creator>
    </item>
    <item>
      <title>Multiview learning with twin parametric margin SVM</title>
      <link>https://arxiv.org/abs/2408.01981</link>
      <description>arXiv:2408.01981v1 Announce Type: cross 
Abstract: Multiview learning (MVL) seeks to leverage the benefits of diverse perspectives to complement each other, effectively extracting and utilizing the latent information within the dataset. Several twin support vector machine-based MVL (MvTSVM) models have been introduced and demonstrated outstanding performance in various learning tasks. However, MvTSVM-based models face significant challenges in the form of computational complexity due to four matrix inversions, the need to reformulate optimization problems in order to employ kernel-generated surfaces for handling non-linear cases, and the constraint of uniform noise assumption in the training data. Particularly in cases where the data possesses a heteroscedastic error structure, these challenges become even more pronounced. In view of the aforementioned challenges, we propose multiview twin parametric margin support vector machine (MvTPMSVM). MvTPMSVM constructs parametric hyperplanes with the goal of maximizing the parametric margin between two classes, aiming to regulate and manage the impact of the heteroscedastic noise structure existing within the data. The proposed MvTPMSVM model avoids the explicit computation of matrix inversions in the dual formulation, leading to enhanced computational efficiency. We perform an extensive assessment of the MvTPMSVM model using benchmark datasets such as UCI, KEEL, synthetic, and Animals with Attributes (AwA). Our experimental results, coupled with rigorous statistical analyses, confirm the superior generalization capabilities of the proposed MvTPMSVM model compared to the baseline models. The source code of the proposed MvTPMSVM model is available at \url{https://github.com/mtanveer1/MvTPMSVM}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01981v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. Quadir, M. Tanveer</dc:creator>
    </item>
    <item>
      <title>Winners with Confidence: Discrete Argmin Inference with an Application to Model Selection</title>
      <link>https://arxiv.org/abs/2408.02060</link>
      <description>arXiv:2408.02060v1 Announce Type: cross 
Abstract: We study the problem of finding the index of the minimum value of a vector from noisy observations. This problem is relevant in population/policy comparison, discrete maximum likelihood, and model selection. We develop a test statistic that is asymptotically normal, even in high-dimensional settings and with potentially many ties in the population mean vector, by integrating concepts and tools from cross-validation and differential privacy. The key technical ingredient is a central limit theorem for globally dependent data. We also propose practical ways to select the tuning parameter that adapts to the signal landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02060v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianyu Zhang, Hao Lee, Jing Lei</dc:creator>
    </item>
    <item>
      <title>A Multi-class Ride-hailing Service Subsidy System Utilizing Deep Causal Networks</title>
      <link>https://arxiv.org/abs/2408.02065</link>
      <description>arXiv:2408.02065v1 Announce Type: cross 
Abstract: In the ride-hailing industry, subsidies are predominantly employed to incentivize consumers to place more orders, thereby fostering market growth. Causal inference techniques are employed to estimate the consumer elasticity with different subsidy levels. However, the presence of confounding effects poses challenges in achieving an unbiased estimate of the uplift effect. We introduce a consumer subsidizing system to capture relationships between subsidy propensity and the treatment effect, which proves effective while maintaining a lightweight online environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02065v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhe Yu, Chi Xia, Shaosheng Cao, Lin Zhou</dc:creator>
    </item>
    <item>
      <title>Understanding Deep Learning via Notions of Rank</title>
      <link>https://arxiv.org/abs/2408.02111</link>
      <description>arXiv:2408.02111v1 Announce Type: cross 
Abstract: Despite the extreme popularity of deep learning in science and industry, its formal understanding is limited. This thesis puts forth notions of rank as key for developing a theory of deep learning, focusing on the fundamental aspects of generalization and expressiveness. In particular, we establish that gradient-based training can induce an implicit regularization towards low rank for several neural network architectures, and demonstrate empirically that this phenomenon may facilitate an explanation of generalization over natural data (e.g., audio, images, and text). Then, we characterize the ability of graph neural networks to model interactions via a notion of rank, which is commonly used for quantifying entanglement in quantum physics. A central tool underlying these results is a connection between neural networks and tensor factorizations. Practical implications of our theory for designing explicit regularization schemes and data preprocessing algorithms are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02111v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noam Razin</dc:creator>
    </item>
    <item>
      <title>SPINEX-TimeSeries: Similarity-based Predictions with Explainable Neighbors Exploration for Time Series and Forecasting Problems</title>
      <link>https://arxiv.org/abs/2408.02159</link>
      <description>arXiv:2408.02159v1 Announce Type: cross 
Abstract: This paper introduces a new addition to the SPINEX (Similarity-based Predictions with Explainable Neighbors Exploration) family, tailored specifically for time series and forecasting analysis. This new algorithm leverages the concept of similarity and higher-order temporal interactions across multiple time scales to enhance predictive accuracy and interpretability in forecasting. To evaluate the effectiveness of SPINEX, we present comprehensive benchmarking experiments comparing it against 18 algorithms and across 49 synthetic and real datasets characterized by varying trends, seasonality, and noise levels. Our performance assessment focused on forecasting accuracy and computational efficiency. Our findings reveal that SPINEX consistently ranks among the top 5 performers in forecasting precision and has a superior ability to handle complex temporal dynamics compared to commonly adopted algorithms. Moreover, the algorithm's explainability features, Pareto efficiency, and medium complexity (on the order of O(log n)) are demonstrated through detailed visualizations to enhance the prediction and decision-making process. We note that integrating similarity-based concepts opens new avenues for research in predictive analytics, promising more accurate and transparent decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02159v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Z Naser, MZ Naser</dc:creator>
    </item>
    <item>
      <title>Embedding generalization within the learning dynamics: An approach based-on sample path large deviation theory</title>
      <link>https://arxiv.org/abs/2408.02167</link>
      <description>arXiv:2408.02167v1 Announce Type: cross 
Abstract: We consider a typical learning problem of point estimations for modeling of nonlinear functions or dynamical systems in which generalization, i.e., verifying a given learned model, can be embedded as an integral part of the learning process or dynamics. In particular, we consider an empirical risk minimization based learning problem that exploits gradient methods from continuous-time perspective with small random perturbations, which is guided by the training dataset loss. Here, we provide an asymptotic probability estimate in the small noise limit based-on the Freidlin-Wentzell theory of large deviations, when the sample path of the random process corresponding to the randomly perturbed gradient dynamical system hits a certain target set, i.e., a rare event, when the latter is specified by the testing dataset loss landscape. Interestingly, the proposed framework can be viewed as one way of improving generalization and robustness in learning problems that provides new insights leading to optimal point estimates which is guided by training data loss, while, at the same time, the learning dynamics has an access to the testing dataset loss landscape in some form of future achievable or anticipated target goal. Moreover, as a by-product, we establish a connection with optimal control problem, where the target set, i.e., the rare event, is considered as the desired outcome or achievable target goal for a certain optimal control problem, for which we also provide a verification result reinforcing the rationale behind the proposed framework. Finally, we present a computational algorithm that solves the corresponding variational problem leading to an optimal point estimates and, as part of this work, we also present some numerical results for a typical case of nonlinear regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02167v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting</title>
      <link>https://arxiv.org/abs/2408.02279</link>
      <description>arXiv:2408.02279v1 Announce Type: cross 
Abstract: Long-term time series forecasting (LTSF) has been widely applied in finance, traffic prediction, and other domains. Recently, patch-based transformers have emerged as a promising approach, segmenting data into sub-level patches that serve as input tokens. However, existing methods mostly rely on predetermined patch lengths, necessitating expert knowledge and posing challenges in capturing diverse characteristics across various scales. Moreover, time series data exhibit diverse variations and fluctuations across different temporal scales, which traditional approaches struggle to model effectively. In this paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm to capture diverse receptive fields and sparse patterns of time series data. In order to build hierarchical receptive fields, we develop a multi-scale Transformer model, coupled with multi-scale sequence extraction, capable of capturing multi-resolution features. Additionally, we introduce a group-aware rotary position encoding technique to enhance intra- and inter-group position awareness among representations across different temporal scales. Our proposed model, named DRFormer, is evaluated on various real-world datasets, and experimental results demonstrate its superiority compared to existing methods. Our code is available at: https://github.com/ruixindingECNU/DRFormer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02279v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3627673.3679724</arxiv:DOI>
      <dc:creator>Ruixin Ding, Yuqi Chen, Yu-Ting Lan, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.02295</link>
      <description>arXiv:2408.02295v1 Announce Type: cross 
Abstract: Conventional uncertainty-aware temporal difference (TD) learning methods often rely on simplistic assumptions, typically including a zero-mean Gaussian distribution for TD errors. Such oversimplification can lead to inaccurate error representations and compromised uncertainty estimation. In this paper, we introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning, applicable to both discrete and continuous control settings. Our framework enhances the flexibility of error distribution modeling by incorporating higher-order moments, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent noise, i.e., aleatoric uncertainty. We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter. Additionally, we propose a theoretically grounded weighting scheme to fully leverage the GGD. To address epistemic uncertainty, we enhance the batch inverse variance weighting by incorporating bias reduction and kurtosis considerations, resulting in improved robustness. Extensive experimental evaluations using policy gradient algorithms demonstrate the consistent efficacy of our method, showcasing significant performance improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02295v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Seungeon Baek</dc:creator>
    </item>
    <item>
      <title>A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion Models</title>
      <link>https://arxiv.org/abs/2408.02320</link>
      <description>arXiv:2408.02320v1 Announce Type: cross 
Abstract: Diffusion models, which convert noise into new data instances by learning to reverse a diffusion process, have become a cornerstone in contemporary generative modeling. In this work, we develop non-asymptotic convergence theory for a popular diffusion-based sampler (i.e., the probability flow ODE sampler) in discrete time, assuming access to $\ell_2$-accurate estimates of the (Stein) score functions. For distributions in $\mathbb{R}^d$, we prove that $d/\varepsilon$ iterations -- modulo some logarithmic and lower-order terms -- are sufficient to approximate the target distribution to within $\varepsilon$ total-variation distance. This is the first result establishing nearly linear dimension-dependency (in $d$) for the probability flow ODE sampler. Imposing only minimal assumptions on the target data distribution (e.g., no smoothness assumption is imposed), our results also characterize how $\ell_2$ score estimation errors affect the quality of the data generation processes. In contrast to prior works, our theory is developed based on an elementary yet versatile non-asymptotic approach without the need of resorting to SDE and ODE toolboxes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02320v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gen Li, Yuting Wei, Yuejie Chi, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Explosive neural networks via higher-order interactions in curved statistical manifolds</title>
      <link>https://arxiv.org/abs/2408.02326</link>
      <description>arXiv:2408.02326v1 Announce Type: cross 
Abstract: Higher-order interactions underlie complex phenomena in systems such as biological and artificial neural networks, but their study is challenging due to the lack of tractable standard models. By leveraging the maximum entropy principle in curved statistical manifolds, here we introduce curved neural networks as a class of prototypical models for studying higher-order phenomena. Through exact mean-field descriptions, we show that these curved neural networks implement a self-regulating annealing process that can accelerate memory retrieval, leading to explosive order-disorder phase transitions with multi-stability and hysteresis effects. Moreover, by analytically exploring their memory capacity using the replica trick near ferromagnetic and spin-glass phase boundaries, we demonstrate that these networks enhance memory capacity over the classical associative-memory networks. Overall, the proposed framework provides parsimonious models amenable to analytical study, revealing novel higher-order phenomena in complex network systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02326v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>nlin.AO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel Aguilera, Pablo A. Morales, Fernando E. Rosas, Hideaki Shimazaki</dc:creator>
    </item>
    <item>
      <title>Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel Precision Matrices</title>
      <link>https://arxiv.org/abs/2408.02346</link>
      <description>arXiv:2408.02346v1 Announce Type: cross 
Abstract: The Hilbert-space Gaussian Process (HGP) approach offers a hyperparameter-independent basis function approximation for speeding up Gaussian Process (GP) inference by projecting the GP onto M basis functions. These properties result in a favorable data-independent $\mathcal{O}(M^3)$ computational complexity during hyperparameter optimization but require a dominating one-time precomputation of the precision matrix costing $\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating computational complexity to $\mathcal{O}(NM)$ with no additional approximations. We can do this because we realize that the precision matrix can be split into a sum of Hankel-Toeplitz matrices, each having $\mathcal{O}(M)$ unique entries. Based on this realization we propose computing only these unique entries at $\mathcal{O}(NM)$ costs. Further, we develop two theorems that prescribe sufficient conditions for the complexity reduction to hold generally for a wide range of other approximate GP models, such as the Variational Fourier Feature (VFF) approach. The two theorems do this with no assumptions on the data and no additional approximations of the GP models themselves. Thus, our contribution provides a pure speed-up of several existing, widely used, GP approximations, without further approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02346v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frida Viset, Anton Kullberg, Frederiek Wesel, Arno Solin</dc:creator>
    </item>
    <item>
      <title>Graphical Modelling without Independence Assumptions for Uncentered Data</title>
      <link>https://arxiv.org/abs/2408.02393</link>
      <description>arXiv:2408.02393v1 Announce Type: cross 
Abstract: The independence assumption is a useful tool to increase the tractability of one's modelling framework. However, this assumption does not match reality; failing to take dependencies into account can cause models to fail dramatically. The field of multi-axis graphical modelling (also called multi-way modelling, Kronecker-separable modelling) has seen growth over the past decade, but these models require that the data have zero mean. In the multi-axis case, inference is typically done in the single sample scenario, making mean inference impossible.
  In this paper, we demonstrate how the zero-mean assumption can cause egregious modelling errors, as well as propose a relaxation to the zero-mean assumption that allows the avoidance of such errors. Specifically, we propose the "Kronecker-sum-structured mean" assumption, which leads to models with nonconvex-but-unimodal log-likelihoods that can be solved efficiently with coordinate descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02393v1</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bailey Andrew, David R. Westhead, Luisa Cutillo</dc:creator>
    </item>
    <item>
      <title>On the influence of dependent features in classification problems: a game-theoretic perspective</title>
      <link>https://arxiv.org/abs/2408.02481</link>
      <description>arXiv:2408.02481v1 Announce Type: cross 
Abstract: This paper deals with a new measure of the influence of each feature on the response variable in classification problems, accounting for potential dependencies among certain feature subsets. Within this framework, we consider a sample of individuals characterized by specific features, each feature encompassing a finite range of values, and classified based on a binary response variable. This measure turns out to be an influence measure explored in existing literature and related to cooperative game theory. We provide an axiomatic characterization of our proposed influence measure by tailoring properties from the cooperative game theory to our specific context. Furthermore, we demonstrate that our influence measure becomes a general characterization of the well-known Banzhaf-Owen value for games with a priori unions, from the perspective of classification problems. The definitions and results presented herein are illustrated through numerical examples and various applications, offering practical insights into our methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02481v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Davila-Pena, Alejandro Saavedra-Nieves, Balbina Casas-M\'endez</dc:creator>
    </item>
    <item>
      <title>Full error analysis of policy gradient learning algorithms for exploratory linear quadratic mean-field control problem in continuous time with common noise</title>
      <link>https://arxiv.org/abs/2408.02489</link>
      <description>arXiv:2408.02489v1 Announce Type: cross 
Abstract: We consider reinforcement learning (RL) methods for finding optimal policies in linear quadratic (LQ) mean field control (MFC) problems over an infinite horizon in continuous time, with common noise and entropy regularization. We study policy gradient (PG) learning and first demonstrate convergence in a model-based setting by establishing a suitable gradient domination condition.Next, our main contribution is a comprehensive error analysis, where we prove the global linear convergence and sample complexity of the PG algorithm with two-point gradient estimates in a model-free setting with unknown parameters. In this setting, the parameterized optimal policies are learned from samples of the states and population distribution.Finally, we provide numerical evidence supporting the convergence of our implemented algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02489v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noufel Frikha (CES), Huy\^en Pham (LPSM), Xuanye Song (LPSM)</dc:creator>
    </item>
    <item>
      <title>Peer-induced Fairness: A Causal Approach to Reveal Algorithmic Unfairness in Credit Approval</title>
      <link>https://arxiv.org/abs/2408.02558</link>
      <description>arXiv:2408.02558v1 Announce Type: cross 
Abstract: This paper introduces a novel framework, "peer-induced fairness", to scientifically audit algorithmic fairness. It addresses a critical but often overlooked issue: distinguishing between adverse outcomes due to algorithmic discrimination and those resulting from individuals' insufficient capabilities. By utilizing counterfactual fairness and advanced causal inference techniques, such as the Single World Intervention Graph, this model-agnostic approach evaluates fairness at the individual level through peer comparisons and hypothesis testing. It also tackles challenges like data scarcity and imbalance, offering a flexible, plug-and-play self-audit tool for stakeholders and an external audit tool for regulators, while providing explainable feedback for those affected by unfavorable decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02558v1</guid>
      <category>stat.AP</category>
      <category>cs.CY</category>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiqi Fang, Zexun Chen, Jake Ansell</dc:creator>
    </item>
    <item>
      <title>Robust Unsupervised Multi-task and Transfer Learning on Gaussian Mixture Models</title>
      <link>https://arxiv.org/abs/2209.15224</link>
      <description>arXiv:2209.15224v4 Announce Type: replace 
Abstract: Unsupervised learning has been widely used in many real-world applications. One of the simplest and most important unsupervised learning models is the Gaussian mixture model (GMM). In this work, we study the multi-task learning problem on GMMs, which aims to leverage potentially similar GMM parameter structures among tasks to obtain improved learning performance compared to single-task learning. We propose a multi-task GMM learning procedure based on the EM algorithm that effectively utilizes unknown similarities between related tasks and is robust against a fraction of outlier tasks from arbitrary distributions. The proposed procedure is shown to achieve the minimax optimal rate of convergence for both parameter estimation error and the excess mis-clustering error, in a wide range of regimes. Moreover, we generalize our approach to tackle the problem of transfer learning for GMMs, where similar theoretical results are derived. Additionally, iterative unsupervised multi-task and transfer learning methods may suffer from an initialization alignment problem, and two alignment algorithms are proposed to resolve the issue. Finally, we demonstrate the effectiveness of our methods through simulations and real data examples. To the best of our knowledge, this is the first work studying multi-task and transfer learning on GMMs with theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.15224v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Tian, Haolei Weng, Lucy Xia, Yang Feng</dc:creator>
    </item>
    <item>
      <title>A Primal-Dual Approach to Solving Variational Inequalities with General Constraints</title>
      <link>https://arxiv.org/abs/2210.15659</link>
      <description>arXiv:2210.15659v4 Announce Type: replace 
Abstract: Yang et al. (2023) recently showed how to use first-order gradient methods to solve general variational inequalities (VIs) under a limiting assumption that analytic solutions of specific subproblems are available. In this paper, we circumvent this assumption via a warm-starting technique where we solve subproblems approximately and initialize variables with the approximate solution found at the previous iteration. We prove the convergence of this method and show that the gap function of the last iterate of the method decreases at a rate of $O(\frac{1}{\sqrt{K}})$ when the operator is $L$-Lipschitz and monotone. In numerical experiments, we show that this technique can converge much faster than its exact counterpart. Furthermore, for the cases when the inequality constraints are simple, we introduce an alternative variant of ACVI and establish its convergence under the same conditions. Finally, we relax the smoothness assumptions in Yang et al., yielding, to our knowledge, the first convergence result for VIs with general constraints that does not rely on the assumption that the operator is $L$-Lipschitz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.15659v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>ICLR 2024</arxiv:journal_reference>
      <dc:creator>Tatjana Chavdarova, Tong Yang, Matteo Pagliardini, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Robust Survival Analysis with Adversarial Regularization</title>
      <link>https://arxiv.org/abs/2312.16019</link>
      <description>arXiv:2312.16019v3 Announce Type: replace 
Abstract: Survival Analysis (SA) models the time until an event occurs, with applications in fields like medicine, defense, finance, and aerospace. Recent work shows that Neural Networks (NNs) can capture complex relationships in SA. However, dataset uncertainties (e.g., noisy measurements, human error) can degrade model performance. To address this, we leverage NN verification advances to create algorithms for robust, fully-parametric survival models. We introduce a robust loss function and use CROWN-IBP regularization to handle computational challenges in the Min-Max problem. Evaluating our approach on SurvSet datasets, we find that our Survival Analysis with Adversarial Regularization (SAWAR) method consistently outperforms baselines under various perturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier Score (IBS), and Concordance Index (CI). This demonstrates that adversarial regularization enhances SA performance and calibration, mitigating data uncertainty and improving generalization across diverse datasets up to 150% across all perturbation magnitudes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16019v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Potter, Stefano Maxenti, Michael Everett</dc:creator>
    </item>
    <item>
      <title>Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests</title>
      <link>https://arxiv.org/abs/2402.12668</link>
      <description>arXiv:2402.12668v2 Announce Type: replace 
Abstract: We study the often overlooked phenomenon, first noted in \cite{breiman2001random}, that random forests appear to reduce bias compared to bagging. Motivated by an interesting paper by \cite{mentch2020randomization}, where the authors argue that random forests reduce effective degrees of freedom and only outperform bagging ensembles in low signal-to-noise ratio (SNR) settings, we explore how random forests can uncover patterns in the data missed by bagging. We empirically demonstrate that in the presence of such patterns, random forests reduce bias along with variance and increasingly outperform bagging ensembles when SNR is high. Our observations offer insights into the real-world success of random forests across a range of SNRs and enhance our understanding of the difference between random forests and bagging ensembles with respect to the randomization injected into each split. Our investigations also yield practical insights into the importance of tuning $mtry$ in random forests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12668v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Liu, Rahul Mazumder</dc:creator>
    </item>
    <item>
      <title>Rapid Discovery of Graphene Nanocrystals Using DFT and Bayesian Optimization with Neural Network Kernel</title>
      <link>https://arxiv.org/abs/2208.07612</link>
      <description>arXiv:2208.07612v2 Announce Type: replace-cross 
Abstract: Density functional theory (DFT) is a powerful computational method used to obtain physical and chemical properties of materials. In the materials discovery framework, it is often necessary to virtually screen a large and high-dimensional chemical space to find materials with desired properties. However, grid searching a large chemical space with DFT is inefficient due to its high computational cost. We propose an approach utilizing Bayesian optimization (BO) with an artificial neural network kernel to enable smart search. This method leverages the BO algorithm, where the neural network, trained on a limited number of DFT results, determines the most promising regions of the chemical space to explore in subsequent iterations. This approach aims to discover materials with target properties while minimizing the number of DFT calculations required. To demonstrate the effectiveness of this method, we investigated 63 doped graphene quantum dots (GQDs) with sizes ranging from 1 to 2 nm to find the structure with the highest light absorbance. Using time-dependent DFT (TDDFT) only 12 times, we achieved a significant reduction in computational cost, approximately 20% of what would be required for a full grid search, by employing the BO algorithm with a neural network kernel. Considering that TDDFT calculations for a single GQD require about half a day of wall time on high-performance computing nodes, this reduction is substantial. Our approach can be generalized to the discovery of new drugs, chemicals, crystals, and alloys with high-dimensional and large chemical spaces, offering a scalable solution for various applications in materials science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07612v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\c{S}ener \"Oz\"onder, H. K\"ubra K\"u\c{c}\"ukkartal</dc:creator>
    </item>
    <item>
      <title>Learning The Likelihood Test With One-Class Classifiers for Physical Layer Authentication</title>
      <link>https://arxiv.org/abs/2210.12494</link>
      <description>arXiv:2210.12494v4 Announce Type: replace-cross 
Abstract: In physical layer authentication (PLA) mechanisms, a verifier decides whether a received message has been transmitted by a legitimate user or an intruder, according to some features of the physical channel over which the message traveled. To design the authentication check implemented at the verifier, typically either the statistics or a dataset of features are available for the channel from the legitimate user, while no information is available when under attack. When the statistics are known, a well-known good solution is the likelihood test (LT). When a dataset is available, the decision problem is one-class classification (OCC) and a good understanding of the machine learning (ML) techniques used for its solution is important to ensure security. Thus, in this paper, we aim at obtaining ML PLA verifiers that operate as the LT. We show how to do it with the neural network (NN) and the one-class least-squares support vector machine (OCLSSVM) models, trained as two-class classifiers on the single-class dataset and an artificial dataset. The artificial dataset for the negative class is obtained by generating channel feature (CF) vectors uniformly distributed over the domain of the legitimate class dataset. We also derive a modified stochastic gradient descent (SGD) algorithm that trains a PLA verifier operating as LT without the need for the artificial dataset. Furthermore, we show that the one-class least-squares support vector machine with suitable kernels operates as the LT at convergence. Lastly, we show that the widely used autoencoder classifier generally does not provide the LT. Numerical results are provided considering PLA on both wireless and underwater acoustic channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12494v4</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Ardizzon, Stefano Tomasin</dc:creator>
    </item>
    <item>
      <title>Algorithm Design for Online Meta-Learning with Task Boundary Detection</title>
      <link>https://arxiv.org/abs/2302.00857</link>
      <description>arXiv:2302.00857v2 Announce Type: replace-cross 
Abstract: Online meta-learning has recently emerged as a marriage between batch meta-learning and online learning, for achieving the capability of quick adaptation on new tasks in a lifelong manner. However, most existing approaches focus on the restrictive setting where the distribution of the online tasks remains fixed with known task boundaries. In this work, we relax these assumptions and propose a novel algorithm for task-agnostic online meta-learning in non-stationary environments. More specifically, we first propose two simple but effective detection mechanisms of task switches and distribution shift based on empirical observations, which serve as a key building block for more elegant online model updates in our algorithm: the task switch detection mechanism allows reusing of the best model available for the current task at hand, and the distribution shift detection mechanism differentiates the meta model update in order to preserve the knowledge for in-distribution tasks and quickly learn the new knowledge for out-of-distribution tasks. In particular, our online meta model updates are based only on the current data, which eliminates the need of storing previous data as required in most existing methods. We further show that a sublinear task-averaged regret can be achieved for our algorithm under mild conditions. Empirical studies on three different benchmarks clearly demonstrate the significant advantage of our algorithm over related baseline approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00857v2</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daouda Sow, Sen Lin, Yingbin Liang, Junshan Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Principal Component Regression with Applications to Panel Data</title>
      <link>https://arxiv.org/abs/2307.01357</link>
      <description>arXiv:2307.01357v3 Announce Type: replace-cross 
Abstract: Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for (regularized) PCR whenever data is collected adaptively. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. We demonstrate the usefulness of our bounds by applying them to the domain of panel data, a ubiquitous setting in econometrics and statistics. As our first application, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy. Our second application is a procedure for learning such an intervention assignment policy in a setting where units arrive sequentially to be treated. In addition to providing theoretical performance guarantees (as measured by regret), we show that our method empirically outperforms a baseline which does not leverage error-in-variables regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01357v3</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anish Agarwal, Keegan Harris, Justin Whitehouse, Zhiwei Steven Wu</dc:creator>
    </item>
    <item>
      <title>Solving PDEs on Spheres with Physics-Informed Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2308.09605</link>
      <description>arXiv:2308.09605v2 Announce Type: replace-cross 
Abstract: Physics-informed neural networks (PINNs) have been demonstrated to be efficient in solving partial differential equations (PDEs) from a variety of experimental perspectives. Some recent studies have also proposed PINN algorithms for PDEs on surfaces, including spheres. However, theoretical understanding of the numerical performance of PINNs, especially PINNs on surfaces or manifolds, is still lacking. In this paper, we establish rigorous analysis of the physics-informed convolutional neural network (PICNN) for solving PDEs on the sphere. By using and improving the latest approximation results of deep convolutional neural networks and spherical harmonic analysis, we prove an upper bound for the approximation error with respect to the Sobolev norm. Subsequently, we integrate this with innovative localization complexity analysis to establish fast convergence rates for PICNN. Our theoretical results are also confirmed and supplemented by our experiments. In light of these findings, we explore potential strategies for circumventing the curse of dimensionality that arises when solving high-dimensional PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09605v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanhang Lei, Zhen Lei, Lei Shi, Chenyu Zeng, Ding-Xuan Zhou</dc:creator>
    </item>
    <item>
      <title>Fun with Flags: Robust Principal Directions via Flag Manifolds</title>
      <link>https://arxiv.org/abs/2401.04071</link>
      <description>arXiv:2401.04071v4 Announce Type: replace-cross 
Abstract: Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations. The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types. Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold. Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04071v4</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Mankovich, Gustau Camps-Valls, Tolga Birdal</dc:creator>
    </item>
    <item>
      <title>On the resilience of the quadratic Littlewood-Offord problem</title>
      <link>https://arxiv.org/abs/2402.10504</link>
      <description>arXiv:2402.10504v2 Announce Type: replace-cross 
Abstract: We study the statistical resilience of the anti-concentration properties of Rademacher polynomials in face of adversarial deterministic noise taking the form of sign-flips. Given a multilinear polynomial $f:\mathbb{R}^n \to \mathbb{R}$ and a Rademacher vector $\boldsymbol{\xi} \in \{\pm 1\}^n$ (with independent entries), our results provide probabilistic lower bound estimations on the number of sign-flips that $\boldsymbol{\xi}$ can sustain without ``inflating" the atom probability $\sup_{x \in \mathbb{R} } \mathbb{P}\{f(\boldsymbol{\xi}) = x\}$ otherwise resulting in an adversarially biased distribution. Special emphasis is put on bilinear and quadratic forms, for which strengthened estimates are attained. From a computational perspective, our results in this venue are instance-bound in such a way that allows for an efficient computation of the statistical resilience guarantees from the quadratic polynomial itself directly. All of our probabilistic lower bound resilience guarantees are asymptotically tight.
  On route, we provide a short proof for a new small-ball probability estimate fitting Rademacher multilinear polynomials $f: \mathbb{R}^n \to \mathbb{R}$ removeing a polylog-factor from the classical Meka-Nguyen-Vu bound provided the coefficients are independent of $n$ (dimension-free, hereafter). This removal was conjectured to be possible by Meka-Nguyen-Vu regardless of our assumption. Bilinear Rademacher forms with dimension-free coefficients arise naturally in Combinatorics and specifically in the dense case of the edge-statistics conjecture posed by Alon, Hefetz, Krivelevich, and Tyomkyn. This case of the conjecture was resolved by Kwan and Sauermann. Replacing the appeal to the Meka-Nguyen-Vu classical bound in the work of Kwan, Sudakov, and Tran with our shortly proved result attains an additional proof of the dense case of the edge-statistics conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10504v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elad Aigner-Horev, Daniel Rosenberg, Roi Weiss</dc:creator>
    </item>
    <item>
      <title>Molecular relaxation by reverse diffusion with time step prediction</title>
      <link>https://arxiv.org/abs/2404.10935</link>
      <description>arXiv:2404.10935v2 Announce Type: replace-cross 
Abstract: Molecular relaxation, finding the equilibrium state of a non-equilibrium structure, is an essential component of computational chemistry to understand reactivity. Classical force field (FF) methods often rely on insufficient local energy minimization, while neural network FF models require large labeled datasets encompassing both equilibrium and non-equilibrium structures. As a remedy, we propose MoreRed, molecular relaxation by reverse diffusion, a conceptually novel and purely statistical approach where non-equilibrium structures are treated as noisy instances of their corresponding equilibrium states. To enable the denoising of arbitrarily noisy inputs via a generative diffusion model, we further introduce a novel diffusion time step predictor. Notably, MoreRed learns a simpler pseudo potential energy surface (PES) instead of the complex physical PES. It is trained on a significantly smaller, and thus computationally cheaper, dataset consisting of solely unlabeled equilibrium structures, avoiding the computation of non-equilibrium structures altogether. We compare MoreRed to classical FFs, equivariant neural network FFs trained on a large dataset of equilibrium and non-equilibrium data, as well as a semi-empirical tight-binding model. To assess this quantitatively, we evaluate the root-mean-square deviation between the found equilibrium structures and the reference equilibrium structures as well as their energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10935v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/2632-2153/ad652c</arxiv:DOI>
      <dc:creator>Khaled Kahouli, Stefaan Simon Pierre Hessmann, Klaus-Robert M\"uller, Shinichi Nakajima, Stefan Gugler, Niklas Wolf Andreas Gebauer</dc:creator>
    </item>
    <item>
      <title>Integer Programming for Learning Directed Acyclic Graphs from Non-identifiable Gaussian Models</title>
      <link>https://arxiv.org/abs/2404.12592</link>
      <description>arXiv:2404.12592v2 Announce Type: replace-cross 
Abstract: We study the problem of learning directed acyclic graphs from continuous observational data, generated according to a linear Gaussian structural equation model. State-of-the-art structure learning methods for this setting have at least one of the following shortcomings: i) they cannot provide optimality guarantees and can suffer from learning sub-optimal models; ii) they rely on the stringent assumption that the noise is homoscedastic, and hence the underlying model is fully identifiable. We overcome these shortcomings and develop a computationally efficient mixed-integer programming framework for learning medium-sized problems that accounts for arbitrary heteroscedastic noise. We present an early stopping criterion under which we can terminate the branch-and-bound procedure to achieve an asymptotically optimal solution and establish the consistency of this approximate solution. In addition, we show via numerical experiments that our method outperforms state-of-the-art algorithms and is robust to noise heteroscedasticity, whereas the performance of some competing methods deteriorates under strong violations of the identifiability assumption. The software implementation of our method is available as the Python package \emph{micodag}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12592v2</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Xu, Armeen Taeb, Simge K\"u\c{c}\"ukyavuz, Ali Shojaie</dc:creator>
    </item>
    <item>
      <title>Learnability of Parameter-Bounded Bayes Nets</title>
      <link>https://arxiv.org/abs/2407.00927</link>
      <description>arXiv:2407.00927v2 Announce Type: replace-cross 
Abstract: Bayes nets are extensively used in practice to efficiently represent joint probability distributions over a set of random variables and capture dependency relations. In a seminal paper, Chickering et al. (JMLR 2004) showed that given a distribution $\mathbb{P}$, that is defined as the marginal distribution of a Bayes net, it is $\mathsf{NP}$-hard to decide whether there is a parameter-bounded Bayes net that represents $\mathbb{P}$. They called this problem LEARN. In this work, we extend the $\mathsf{NP}$-hardness result of LEARN and prove the $\mathsf{NP}$-hardness of a promise search variant of LEARN, whereby the Bayes net in question is guaranteed to exist and one is asked to find such a Bayes net. We complement our hardness result with a positive result about the sample complexity that is sufficient to recover a parameter-bounded Bayes net that is close (in TV distance) to a given distribution $\mathbb{P}$, that is represented by some parameter-bounded Bayes net, generalizing a degree-bounded sample complexity result of Brustle et al. (EC 2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00927v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Bhattacharyya, Davin Choo, Sutanu Gayen, Dimitrios Myrisiotis</dc:creator>
    </item>
    <item>
      <title>Maximum mean discrepancies of Farey sequences</title>
      <link>https://arxiv.org/abs/2407.10214</link>
      <description>arXiv:2407.10214v2 Announce Type: replace-cross 
Abstract: We identify a large class of positive-semidefinite kernels for which a certain polynomial rate of convergence of maximum mean discrepancies of Farey sequences is equivalent to the Riemann hypothesis. This class includes all Mat\'ern kernels of order at least one-half.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10214v2</guid>
      <category>math.ST</category>
      <category>math.NT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toni Karvonen, Anatoly Zhigljavsky</dc:creator>
    </item>
    <item>
      <title>Sparks of Quantum Advantage and Rapid Retraining in Machine Learning</title>
      <link>https://arxiv.org/abs/2407.16020</link>
      <description>arXiv:2407.16020v4 Announce Type: replace-cross 
Abstract: The advent of quantum computing holds the potential to revolutionize various fields by solving complex problems more efficiently than classical computers. Despite this promise, practical quantum advantage is hindered by current hardware limitations, notably the small number of qubits and high noise levels. In this study, we leverage adiabatic quantum computers to optimize Kolmogorov-Arnold Networks, a powerful neural network architecture for representing complex functions with minimal parameters. By modifying the network to use Bezier curves as the basis functions and formulating the optimization problem into a Quadratic Unconstrained Binary Optimization problem, we create a fixed-sized solution space, independent of the number of training samples. This strategy allows for the optimization of an entire neural network in a single training iteration in which, due to order of operations, a majority of the processing is done using a collapsed version of the training dataset. This inherently creates extremely fast training speeds, which are validated experimentally, compared to classical optimizers including Adam, Stochastic Gradient Descent, Adaptive Gradient, and simulated annealing. Additionally, we introduce a novel rapid retraining capability, enabling the network to be retrained with new data without reprocessing old samples, thus enhancing learning efficiency in dynamic environments. Experiments on retraining demonstrate a hundred times speed up using adiabatic quantum computing based optimization compared to that of the gradient descent based optimizers, with theoretical models allowing this speed up to be much larger! Our findings suggest that with further advancements in quantum hardware and algorithm optimization, quantum-optimized machine learning models could have broad applications across various domains, with initial focus on rapid retraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16020v4</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Troy</dc:creator>
    </item>
  </channel>
</rss>
