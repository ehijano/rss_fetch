<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Jul 2024 02:26:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reconstruction of geometric random graphs with the Simple algorithm</title>
      <link>https://arxiv.org/abs/2407.18591</link>
      <description>arXiv:2407.18591v1 Announce Type: new 
Abstract: Graph reconstruction can efficiently detect the underlying topology of massive networks such as the Internet. Given a query oracle and a set of nodes, the goal is to obtain the edge set by performing as few queries as possible. An algorithm for graph reconstruction is the Simple algorithm (Mathieu &amp; Zhou, 2023), which reconstructs bounded-degree graphs in $\tilde{O}(n^{3/2})$ queries. We extend the use of this algorithm to the class of geometric random graphs with connection radius $r \sim n^k$, with diverging average degree. We show that for this class of graphs, the query complexity is $\tilde{O}(n^{2k+1})$ when k &gt; 3/20. This query complexity is up to a polylog(n) term equal to the number of edges in the graph, which means that the reconstruction algorithm is almost edge-optimal. We also show that with only $n^{1+o(1)}$ queries it is already possible to reconstruct at least 75% of the non-edges of a geometric random graph, in both the sparse and dense setting. Finally, we show that the number of queries is indeed of the same order as the number of edges on the basis of simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18591v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clara Stegehuis, Lotte Weedage</dc:creator>
    </item>
    <item>
      <title>Rollercoasters with Plateaus</title>
      <link>https://arxiv.org/abs/2407.18620</link>
      <description>arXiv:2407.18620v1 Announce Type: new 
Abstract: In this paper we investigate the problem of detecting, counting, and enumerating (generating) all maximum length plateau-$k$-rollercoasters appearing as a subsequence of some given word (sequence, string), while allowing for plateaus. We define a plateau-$k$-rollercoaster as a word consisting of an alternating sequence of (weakly) increasing and decreasing \emph{runs}, with each run containing at least $k$ \emph{distinct} elements, allowing the run to contain multiple copies of the same symbol consecutively. This differs from previous work, where runs within rollercoasters have been defined only as sequences of distinct values. Here, we are concerned with rollercoasters of \emph{maximum} length embedded in a given word $w$, that is, the longest rollercoasters that are a subsequence of $w$.
  We present algorithms allowing us to determine the longest plateau-$k$-roller\-coasters appearing as a subsequence in any given word $w$ of length $n$ over an alphabet of size $\sigma$ in $O(n \sigma k)$ time, to count the number of plateau-$k$-rollercoasters in $w$ of maximum length in $O(n \sigma k)$ time, and to output all of them with $O(n)$ delay after $O(n \sigma k)$ preprocessing. Furthermore, we present an algorithm to determine the longest common plateau-$k$-rollercoaster within a set of words in $O(N k \sigma)$ where $N$ is the product of all word lengths within the set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18620v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Duncan Adamson, Pamela Fleischmann, Annika Huch</dc:creator>
    </item>
    <item>
      <title>On Computing the Smallest Suffixient Set</title>
      <link>https://arxiv.org/abs/2407.18753</link>
      <description>arXiv:2407.18753v1 Announce Type: new 
Abstract: Let T in \Sigma^n be a text over alphabet \Sigma. A suffixient set S \subseteq [n] for T is a set of positions such that, for every one-character right-extension T[i,j] of every right-maximal substring T[i,j-1] of T, there exists x in S such that T[i,j] is a suffix of T[1,x]. It was recently shown that, given a suffixient set of cardinality q and an oracle offering fast random access on T (for example, a straight-line program), there is a data structure of O(q) words (on top of the oracle) that can quickly find all Maximal Exact Matches (MEMs) of any query pattern P in T with high probability. The paper introducing suffixient sets left open the problem of computing the smallest such set; in this paper, we solve this problem by describing a simple quadratic-time algorithm, a O(n + \bar r|\Sigma|)-time algorithm running in compressed working space (\bar r is the number of runs in the Burrows-Wheeler transform of T reversed), and an optimal O(n)-time algorithm computing the smallest suffixient set. We present an implementation of our compressed-space algorithm and show experimentally that it uses a small memory footprint on repetitive text collections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18753v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Cenzato, Francisco Olivares, Nicola Prezza</dc:creator>
    </item>
    <item>
      <title>A Model for Combinatorial Dictionary Learning and Inference</title>
      <link>https://arxiv.org/abs/2407.18436</link>
      <description>arXiv:2407.18436v1 Announce Type: cross 
Abstract: We are often interested in decomposing complex, structured data into simple components that explain the data. The linear version of this problem is well-studied as dictionary learning and factor analysis. In this work, we propose a combinatorial model in which to study this question, motivated by the way objects occlude each other in a scene to form an image. First, we identify a property we call "well-structuredness" of a set of low-dimensional components which ensures that no two components in the set are too similar. We show how well-structuredness is sufficient for learning the set of latent components comprising a set of sample instances. We then consider the problem: given a set of components and an instance generated from some unknown subset of them, identify which parts of the instance arise from which components. We consider two variants: (1) determine the minimal number of components required to explain the instance; (2) determine the correct explanation for as many locations as possible. For the latter goal, we also devise a version that is robust to adversarial corruptions, with just a slightly stronger assumption on the components. Finally, we show that the learning problem is computationally infeasible in the absence of any assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18436v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avrim Blum, Kavya Ravichandran</dc:creator>
    </item>
    <item>
      <title>On Approximating the Weighted Region Problem in Square Tessellations</title>
      <link>https://arxiv.org/abs/2407.18758</link>
      <description>arXiv:2407.18758v1 Announce Type: cross 
Abstract: The weighted region problem is the problem of finding the weighted shortest path on a plane consisting of polygonal regions with different weights. For the case when the plane is tessellated by squares, we can solve the problem approximately by finding the shortest path on a grid graph defined by placing a vertex at the center of each grid. In this note, we show that the obtained path admits $(\sqrt{2}+1)$-approximation. This improves the previous result of $2\sqrt{2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18758v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naonori Kakimura, Rio Katsu</dc:creator>
    </item>
    <item>
      <title>The Leafed Induced Subtree in chordal and bounded treewidth graphs</title>
      <link>https://arxiv.org/abs/2301.12783</link>
      <description>arXiv:2301.12783v2 Announce Type: replace 
Abstract: In the Fully Leafed Induced Subtrees, one is given a graph $G$ and two integers $a$ and $b$ and the question is to find an induced subtree of $G$ with $a$ vertices and at least $b$ leaves. This problem is known to be NP-complete even when the input graph is $4$-regular. Polynomial algorithms are known when the input graph is restricted to be a tree or series-parallel. In this paper we generalize these results by providing an FPT algorithm parameterized by treewidth. We also provide a polynomial algorithm when the input graph is restricted to be a chordal graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12783v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Baste</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Injectivity and Bounded Surjectivity of One-dimensional Nonlinear Cellular Automata</title>
      <link>https://arxiv.org/abs/2309.03073</link>
      <description>arXiv:2309.03073v2 Announce Type: replace 
Abstract: Nonlinear cellular automata are extensively used in simulations, image processing, cryptography, and so on. The determination of their fundamental properties, injectivity and surjectivity, related to information loss during the evolution, is necessary in various applications. Currently, people still use Amoroso's algorithms for injectivity and surjectivity determinations, but this incurs significant computational costs when applied to complex nonlinear cellular automata. We have optimized Amoroso's surjectivity algorithm, improving its operational efficiency greatly and extended its applicability to various boundaries. Furthermore, we have introduced new theorems and algorithms for determining injectivity, which offer substantial improvements over Amoroso's algorithm in both time and space. With these new algorithms, we are equipped to determine the properties of larger and more complex cellular automata, thereby employing more advanced cellular automata to achieve increasingly complex functionalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.03073v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Wang, Junchi Ma, Defu Lin, Weilin Chen, Chao Wang</dc:creator>
    </item>
    <item>
      <title>Space-efficient SLP Encoding for $O(\log N)$-time Random Access</title>
      <link>https://arxiv.org/abs/2406.15011</link>
      <description>arXiv:2406.15011v2 Announce Type: replace 
Abstract: A Straight-Line Program (SLP) $G$ for a string $T$ is a context-free grammar (CFG) that derives $T$ only, which can be considered as a compressed representation of $T$. In this paper, we show how to encode $G$ in $n \lceil \lg N \rceil + (n + n') \lceil \lg (n+\sigma) \rceil + 4n - 2n' + o(n)$ bits to support random access queries of extracting $T[p..q]$ in worst-case $O(\log N + p - q)$ time, where $N$ is the length of $T$, $\sigma$ is the alphabet size, $n$ is the number of variables in $G$ and $n' \le n$ is the number of symmetric centroid paths in the DAG representation for $G$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15011v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akito Takasaka, Tomohiro I</dc:creator>
    </item>
    <item>
      <title>Online Differentially Private Synthetic Data Generation</title>
      <link>https://arxiv.org/abs/2402.08012</link>
      <description>arXiv:2402.08012v2 Announce Type: replace-cross 
Abstract: We present a polynomial-time algorithm for online differentially private synthetic data generation. For a data stream within the hypercube $[0,1]^d$ and an infinite time horizon, we develop an online algorithm that generates a differentially private synthetic dataset at each time $t$. This algorithm achieves a near-optimal accuracy bound of $O(\log(t)t^{-1/d})$ for $d\geq 2$ and $O(\log^{4.5}(t)t^{-1})$ for $d=1$ in the 1-Wasserstein distance. This result extends the previous work on the continual release model for counting queries to Lipschitz queries. Compared to the offline case, where the entire dataset is available at once, our approach requires only an extra polylog factor in the accuracy bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08012v2</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyun He, Roman Vershynin, Yizhe Zhu</dc:creator>
    </item>
  </channel>
</rss>
