<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Aug 2024 01:41:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Symbolic dynamics of joint brain states during dyadic coordination</title>
      <link>https://arxiv.org/abs/2408.13360</link>
      <description>arXiv:2408.13360v1 Announce Type: new 
Abstract: We propose a novel approach to investigate the brain mechanisms that support coordination of behavior between individuals. Brain states in single individuals defined by the patterns of functional connectivity between brain regions are used to create joint symbolic representations of the evolution of brain states in two or more individuals performing a task together. These symbolic dynamics can be analyzed to reveal aspects of the dynamics of joint brain states that are related to coordination or other interactive behaviors. We apply this approach to simultaneous electroencephalographic (EEG) data from pairs of subjects engaged in two different modes of finger-tapping coordination tasks (synchronization and syncopation) under different interaction conditions (Uncoupled, Leader-Follower, and Mutual) to explore the neural mechanisms of multi-person motor coordination. Our results reveal that the dyads exhibit mostly the same joint symbols in different interaction conditions - the most important differences are reflected in the symbolic dynamics. Recurrence analysis shows that interaction influences the dwell time in specific joint symbols and the structure of joint symbol sequences (motif length). In synchronization, increasing feedback promotes stability with longer dwell times and motif length. In syncopation, Leader-Follower interactions enhance stability (increase dwell time and motif length), but Mutual feedback dramatically reduces stability. Network analysis reveals distinct topological changes with task and feedback. In synchronization, stronger coupling stabilizes a few states restricting the pattern of flow between states, preserving a core-periphery structure of the joint brain states. In syncopation, a more distributed flow amongst a larger set of joint brain states reduces the dominance of core joint brain states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13360v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Italo Ivo Lima Dias Pinto, Zhibin Zhou, Javier O. Garcia, Ramesh Srinivasan</dc:creator>
    </item>
    <item>
      <title>Automatic recognition and detection of aphasic natural speech</title>
      <link>https://arxiv.org/abs/2408.14082</link>
      <description>arXiv:2408.14082v1 Announce Type: new 
Abstract: Aphasia is a language disorder affecting one third of stroke patients. Current aphasia assessment does not consider natural speech due to the time consuming nature of manual transcriptions and a lack of knowledge on how to analyze such data. Here, we evaluate the potential of automatic speech recognition (ASR) to transcribe Dutch aphasic speech and the ability of natural speech features to detect aphasia. A picture-description task was administered and automatically transcribed in 62 persons with aphasia and 57 controls. Acoustic and linguistic features were semi-automatically extracted and provided as input to a support vector machine (SVM) classifier. Our ASR model obtained a WER of 24.5%, outperforming earlier ASR models for aphasia. The SVM shows high accuracy (86.6%) at the individual level, with fluency features as most dominant to detect aphasia. ASR and semi-automatic feature extraction can thus facilitate natural speech analysis in a time efficient manner in clinical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14082v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mara Barberis, Pieter De Clercq, Bastiaan Tamm, Hugo Van hamme, Maaike Vandermosten</dc:creator>
    </item>
    <item>
      <title>Emergence of brain function from structure: an algebraic quantum model</title>
      <link>https://arxiv.org/abs/2408.14221</link>
      <description>arXiv:2408.14221v1 Announce Type: new 
Abstract: A fundamental paradigm in neuroscience is that cognitive functions -- such as perception, learning, memory, and locomotion -- are governed by the brain's structural organization. Yet, the theoretical principles explaining how the physical architecture of the nervous system shapes its function remain elusive. Here, we combine concepts from quantum statistical mechanics and graph C*-algebras to introduce a theoretical framework where functional states of a structural connectome emerge as thermal equilibrium states of the underlying directed network. These equilibrium states, defined from the Kubo-Martin-Schwinger states formalism (KMS states), quantify the relative contribution of each neuron to the information flow within the connectome. Using the prototypical connectome of the nematode {\em Caenorhabditis elegans}, we provide a comprehensive description of these KMS states, explore their functional implications, and establish the predicted functional network based on the nervous system's anatomical connectivity. Ultimately, we present a model for identifying the potential functional states of a detailed structural connectome and for conceptualizing the structure-function relationship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14221v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math.OA</category>
      <category>quant-ph</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elka\"ioum M. Moutuou, Habib Benali</dc:creator>
    </item>
    <item>
      <title>Integrated Brain Connectivity Analysis with fMRI, DTI, and sMRI Powered by Interpretable Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2408.14254</link>
      <description>arXiv:2408.14254v1 Announce Type: new 
Abstract: Multimodal neuroimaging modeling has becomes a widely used approach but confronts considerable challenges due to heterogeneity, which encompasses variability in data types, scales, and formats across modalities. This variability necessitates the deployment of advanced computational methods to integrate and interpret these diverse datasets within a cohesive analytical framework. In our research, we amalgamate functional magnetic resonance imaging, diffusion tensor imaging, and structural MRI into a cohesive framework. This integration capitalizes on the unique strengths of each modality and their inherent interconnections, aiming for a comprehensive understanding of the brain's connectivity and anatomical characteristics. Utilizing the Glasser atlas for parcellation, we integrate imaging derived features from various modalities: functional connectivity from fMRI, structural connectivity from DTI, and anatomical features from sMRI within consistent regions. Our approach incorporates a masking strategy to differentially weight neural connections, thereby facilitating a holistic amalgamation of multimodal imaging data. This technique enhances interpretability at connectivity level, transcending traditional analyses centered on singular regional attributes. The model is applied to the Human Connectome Project's Development study to elucidate the associations between multimodal imaging and cognitive functions throughout youth. The analysis demonstrates improved predictive accuracy and uncovers crucial anatomical features and essential neural connections, deepening our understanding of brain structure and function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14254v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gang Qu, Ziyu Zhou, Vince D. Calhoun, Aiying Zhang, Yu-Ping Wang</dc:creator>
    </item>
    <item>
      <title>Quantum Multimodal Contrastive Learning Framework</title>
      <link>https://arxiv.org/abs/2408.13919</link>
      <description>arXiv:2408.13919v2 Announce Type: cross 
Abstract: In this paper, we propose a novel framework for multimodal contrastive learning utilizing a quantum encoder to integrate EEG (electroencephalogram) and image data. This groundbreaking attempt explores the integration of quantum encoders within the traditional multimodal learning framework. By leveraging the unique properties of quantum computing, our method enhances the representation learning capabilities, providing a robust framework for analyzing time series and visual information concurrently. We demonstrate that the quantum encoder effectively captures intricate patterns within EEG signals and image features, facilitating improved contrastive learning across modalities. This work opens new avenues for integrating quantum computing with multimodal data analysis, particularly in applications requiring simultaneous interpretation of temporal and visual data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13919v2</guid>
      <category>quant-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Aidan Hung-Wen Tsai, Sheng-Chieh Huang</dc:creator>
    </item>
    <item>
      <title>Formulation of downward causation in the brain: whole beats its parts</title>
      <link>https://arxiv.org/abs/2310.10005</link>
      <description>arXiv:2310.10005v5 Announce Type: replace 
Abstract: Downward causation is self-causation: the causal effect from the whole at the macro level to its parts at the micro level, and is regarded as a solution to the mind-body problem. However, no actual example of downward causation has been propsed. Here, we argue that a feedback control of micro-level neural mechanisms using macro-level algebraic structure information between neural network modules that is physically composed of neurons is a model of downward causation in the brain. We speculate that downward causation causes mathematical structure in our perceptual experience by controlling algebraic structure in the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10005v5</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshiyuki Ohmura, Yasuo Kuniyoshi</dc:creator>
    </item>
    <item>
      <title>Advantageous and disadvantageous inequality aversion can be taught through vicarious learning of others' preferences</title>
      <link>https://arxiv.org/abs/2405.06500</link>
      <description>arXiv:2405.06500v2 Announce Type: replace 
Abstract: While enforcing egalitarian social norms is critical for human society, punishing social norm violators often incurs a cost to the self. This cost looms even larger when one can benefit from an unequal distribution of resources (i.e. advantageous inequity), as in receiving a higher salary than a colleague with the identical role. In the Ultimatum Game, a classic test bed for fairness norm enforcement, individuals rarely reject (punish) such unequal proposed divisions of resources because doing so entails a sacrifice of one's own benefit. Recent work has demonstrated that observing another's punitive responses to unfairness can efficiently alter the punitive preferences of an observer. It remains an open question, however, whether such contagion is powerful enough to impart advantageous inequity aversion to individuals. Using a variant of the Ultimatum Game in which participants are tasked with responding to fairness violations on behalf of another 'Teacher' - whose aversion to advantageous (versus disadvantageous) inequity was systematically manipulated-we probe whether individuals subsequently increase their punishment unfair after experiencing fairness violations on their own behalf. In two experiments, we found individuals can acquire aversion to advantageous inequity 'vicariously' through observing (and implementing) the Teacher's preferences. Computationally, these learning effects were best characterized by a model which learns the latent structure of the Teacher's preferences, rather than a simple Reinforcement Learning account. In summary, our study is the first to demonstrate that people can swiftly and readily acquire another's preferences for advantageous inequity, suggesting in turn that behavioral contagion may be one promising mechanism through which social norm enforcement - which people rarely implement in the case of advantageous inequality - can be enhanced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06500v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shen Zhang, Oriel FeldmanHall, S\'ebastien H\'etu, A. Ross Otto</dc:creator>
    </item>
    <item>
      <title>A Concept-Value Network as a Brain Model</title>
      <link>https://arxiv.org/abs/1904.04579</link>
      <description>arXiv:1904.04579v5 Announce Type: replace-cross 
Abstract: This paper suggests a statistical framework for describing the relations between the physical and conceptual entities of a brain-like model. Features and concept instances are put into context, where the paper suggests that features may be the electrical wiring, although chemical connections are also possible. With this idea, the actual length of the connection is important, because it is related to firing rates and neuron synchronization, but the signal type is less important. The paper then suggests that concepts are neuron groups that link feature sets and concept instances are determined by chemical signals from those groups. Therefore, features become the static horizontal framework of the neural system and concepts are vertically interconnected combinations of these. With regards to functionality, the neuron is then considered to be functional and the more horizontal memory structures can even be glial. This would also suggest that features can be distributed entities and not concentrated to a single area.</description>
      <guid isPermaLink="false">oai:arXiv.org:1904.04579v5</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kieran Greer</dc:creator>
    </item>
    <item>
      <title>Multilevel Interpretability Of Artificial Neural Networks: Leveraging Framework And Methods From Neuroscience</title>
      <link>https://arxiv.org/abs/2408.12664</link>
      <description>arXiv:2408.12664v2 Announce Type: replace-cross 
Abstract: As deep learning systems are scaled up to many billions of parameters, relating their internal structure to external behaviors becomes very challenging. Although daunting, this problem is not new: Neuroscientists and cognitive scientists have accumulated decades of experience analyzing a particularly complex system - the brain. In this work, we argue that interpreting both biological and artificial neural systems requires analyzing those systems at multiple levels of analysis, with different analytic tools for each level. We first lay out a joint grand challenge among scientists who study the brain and who study artificial neural networks: understanding how distributed neural mechanisms give rise to complex cognition and behavior. We then present a series of analytical tools that can be used to analyze biological and artificial neural systems, organizing those tools according to Marr's three levels of analysis: computation/behavior, algorithm/representation, and implementation. Overall, the multilevel interpretability framework provides a principled way to tackle neural system complexity; links structure, computation, and behavior; clarifies assumptions and research priorities at each level; and paves the way toward a unified effort for understanding intelligent systems, may they be biological or artificial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12664v2</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 27 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhonghao He, Jascha Achterberg, Katie Collins, Kevin Nejad, Danyal Akarca, Yinzhu Yang, Wes Gurnee, Ilia Sucholutsky, Yuhan Tang, Rebeca Ianov, George Ogden, Chole Li, Kai Sandbrink, Stephen Casper, Anna Ivanova, Grace W. Lindsay</dc:creator>
    </item>
  </channel>
</rss>
