<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Dec 2025 02:27:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Research on Novelty Measurement Indicator of Academic Papers Based on the Atypical Recombination of Knowledge</title>
      <link>https://arxiv.org/abs/2512.18979</link>
      <description>arXiv:2512.18979v1 Announce Type: new 
Abstract: The advancement of science is inherently dependent on the recombination of existing knowledge, and innovative research typically relies on the atypical recombination of established knoweldge bases. This study introduces a Knowledge Eccentricity to enable timely assessment of the novelty of research outputs by quantifying their degree of deviation from the existing knowledge system. For empirical analysis, we selected sample data including research articles published in Science and Nature, top 1% highly cited papers, and zero-cited papers for the year 2005, 2010, 2015, 2020, and 2025. We calculated the knowledge eccentricity scores for these papers and examined their potential influencing factors. The results indicate that team size exerts a significant negative effect on paper novelty, meaning larger team size is less conductive to enhancing the novelty of research outputs. Conversely, the number of references shows a signifcant positive correlation with paper novelty, which means that a greater number of references is associated with a moderate imporovement in a paper's novelty. The proposed indicator offers strong timeliness and operability, allowing for the evaluation of a paper's novelty immediately upon its publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18979v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Guoqiang, Sun Jian, Lin Gege, Zhang Shuo</dc:creator>
    </item>
    <item>
      <title>Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown</title>
      <link>https://arxiv.org/abs/2512.18115</link>
      <description>arXiv:2512.18115v1 Announce Type: cross 
Abstract: Academic documents stored in PDF format can be transformed into plain text structured markup languages to enhance accessibility and enable scalable digital library workflows. Markup languages allow for easier updates and customization, making academic content more adaptable and accessible to diverse usage, such as linguistic corpus compilation. Such documents, typically delivered in PDF format, contain complex elements including mathematical formulas, figures, headers, and tables, as well as densely layouted text. Existing end-to-end decoder transformer models can transform screenshots of documents into markup language. However, these models exhibit significant inefficiencies; their token-by-token decoding from scratch wastes a lot of inference steps in regenerating dense text that could be directly copied from PDF files. To solve this problem, we introduce EditTrans, a hybrid editing-generation model whose features allow identifying a queue of to-be-edited text from a PDF before starting to generate markup language. EditTrans contains a lightweight classifier fine-tuned from a Document Layout Analysis model on 162,127 pages of documents from arXiv. In our evaluations, EditTrans reduced the transformation latency up to 44.5% compared to end-to-end decoder transformer models, while maintaining transformation quality. Our code and reproducible dataset production scripts are open-sourced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18115v1</guid>
      <category>cs.MM</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.DL</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-04614-7_13</arxiv:DOI>
      <dc:creator>Changxu Duan</dc:creator>
    </item>
    <item>
      <title>Accelerating End-to-End PDF to Markdown Conversion Through Assisted Generation</title>
      <link>https://arxiv.org/abs/2512.18122</link>
      <description>arXiv:2512.18122v1 Announce Type: cross 
Abstract: Converting data from machine-unreadable formats like PDFs into Markdown has the potential to enhance the accessibility of scientific research. Existing end-to-end decoder transformer models can transform screenshots of PDFs into Markdown, offering more flexibility than pipeline-based methods. Yet, decoding text token by token from scratch is inefficient, especially when dense text can be directly copied from the PDF. To address this challenge, this paper modifies Prompt Lookup Decoding (PLD) to extract candidate sequences directly from PDF files, leveraging the high n-gram overlap between PDFs and their Markdown equivalents. A new method, Copy Lookup Decoding (CLD), is introduced here to enhance PLD's candidate generation mechanism. Experiments demonstrate that CLD can accelerate the conversion process by up to 1.70$\times$ at original quality. The codebase for this paper is open-source on GitHub (https://github.com/Fireblossom/CopyLookup).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18122v1</guid>
      <category>cs.MM</category>
      <category>cs.DL</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-97141-9_3</arxiv:DOI>
      <dc:creator>Changxu Duan</dc:creator>
    </item>
    <item>
      <title>Improving Data Reusability in Interactive Information Retrieval: Insights from the Community</title>
      <link>https://arxiv.org/abs/2512.18283</link>
      <description>arXiv:2512.18283v1 Announce Type: cross 
Abstract: In this study, we conducted semi-structured interviews with 21 IIR researchers to investigate their data reuse practices. This study aims to expand upon current findings by exploring IIR researchers' information-obtaining behaviors regarding data reuse. We identified the information about shared data characteristics that IIR researchers need when evaluating data reusability, as well as the sources they typically consult to obtain this information. We consider this work to be an initial step toward revealing IIR researchers' data reuse practices and identifying what the community needs to do to promote data reuse. We hope that this study, as well as future research, will inspire more individuals to contribute to ongoing efforts aimed at designing standards, infrastructures, and policies, as well as fostering a sustainable culture of data sharing and reuse in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18283v1</guid>
      <category>cs.IR</category>
      <category>cs.DL</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianji Jiang, Wenqi Li, Jiqun Liu</dc:creator>
    </item>
    <item>
      <title>Multimodal LLMs for Historical Dataset Construction from Archival Image Scans: German Patents (1877-1918)</title>
      <link>https://arxiv.org/abs/2512.19675</link>
      <description>arXiv:2512.19675v1 Announce Type: cross 
Abstract: We leverage multimodal large language models (LLMs) to construct a dataset of 306,070 German patents (1877-1918) from 9,562 archival image scans using our LLM-based pipeline powered by Gemini-2.5-Pro and Gemini-2.5-Flash-Lite. Our benchmarking exercise provides tentative evidence that multimodal LLMs can create higher quality datasets than our research assistants, while also being more than 795 times faster and 205 times cheaper in constructing the patent dataset from our image corpus. About 20 to 50 patent entries are embedded on each page, arranged in a double-column format and printed in Gothic and Roman fonts. The font and layout complexity of our primary source material suggests to us that multimodal LLMs are a paradigm shift in how datasets are constructed in economic history. We open-source our benchmarking and patent datasets as well as our LLM-based data pipeline, which can be easily adapted to other image corpora using LLM-assisted coding tools, lowering the barriers for less technical researchers. Finally, we explain the economics of deploying LLMs for historical dataset construction and conclude by speculating on the potential implications for the field of economic history.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19675v1</guid>
      <category>econ.GN</category>
      <category>cs.CV</category>
      <category>cs.DL</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niclas Griesshaber, Jochen Streb</dc:creator>
    </item>
    <item>
      <title>Mapping Research Data at the University of Bologna</title>
      <link>https://arxiv.org/abs/2503.13464</link>
      <description>arXiv:2503.13464v2 Announce Type: replace 
Abstract: Research data management (RDM) strategies and practices play a pivotal role in adhering to the paradigms of reproducibility and transparency by enabling research sharing in accordance with the principles of Open Science. Discipline-specificity is an essential factor when understanding RDM declinations, to tailor a comprehensive support service and to enhance interdisciplinarity. In this paper we present the results of a mapping carried out to gather information on research data generated and managed within the University of Bologna (UniBO). The aim is to identify differences and commonalities between disciplines and potential challenges for institutional support. We analyzed the data management plans (DMPs) of European competitive projects drafted by researchers affiliated with UniBO. We applied descriptive statistics to the collected variables to answer three main questions: How diverse is the range of data managed within the University of Bologna? Which trends of problems and patterns in terms of data management can influence/improve data stewardship service? Is there an interdisciplinary approach to data production within the University? The research work evidenced many points of contact between different disciplines in terms of data produced, formats used and modest predilection for data reuse. Hot topics such as data confidentiality, needed either on privacy or intellectual property rights (IPR) premises, and long-term preservation pose challenges to all researchers. These results show an increasing attention to RDM while highlighting the relevance of training and support to face the relatively new challenges posed by this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13464v2</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5334/dsj-2025-038</arxiv:DOI>
      <arxiv:journal_reference>Data Science Journal, 24(), p. 38 (2025)</arxiv:journal_reference>
      <dc:creator>C. Basalti, G. Caldoni, S. Coppini, B. Gualandi, M. Marino, F. Masini, S. Peroni</dc:creator>
    </item>
    <item>
      <title>The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems</title>
      <link>https://arxiv.org/abs/2509.08713</link>
      <description>arXiv:2509.08713v2 Announce Type: replace-cross 
Abstract: AI scientist systems, capable of autonomously executing the full research workflow from hypothesis generation and experimentation to paper writing, hold significant potential for accelerating scientific discovery. However, the internal workflow of these systems have not been closely examined. This lack of scrutiny poses a risk of introducing flaws that could undermine the integrity, reliability, and trustworthiness of their research outputs. In this paper, we identify four potential failure modes in contemporary AI scientist systems: inappropriate benchmark selection, data leakage, metric misuse, and post-hoc selection bias. To examine these risks, we design controlled experiments that isolate each failure mode while addressing challenges unique to evaluating AI scientist systems. Our assessment of two prominent open-source AI scientist systems reveals the presence of several failures, across a spectrum of severity, which can be easily overlooked in practice. Finally, we demonstrate that access to trace logs and code from the full automated workflow enables far more effective detection of such failures than examining the final paper alone. We thus recommend journals and conferences evaluating AI-generated research to mandate submission of these artifacts alongside the paper to ensure transparency, accountability, and reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08713v2</guid>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziming Luo, Atoosa Kasirzadeh, Nihar B. Shah</dc:creator>
    </item>
  </channel>
</rss>
