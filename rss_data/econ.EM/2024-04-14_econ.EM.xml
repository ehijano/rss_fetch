<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Apr 2024 04:01:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Uniform Inference in High-Dimensional Threshold Regression Models</title>
      <link>https://arxiv.org/abs/2404.08105</link>
      <description>arXiv:2404.08105v1 Announce Type: new 
Abstract: We develop uniform inference for high-dimensional threshold regression parameters and valid inference for the threshold parameter in this paper. We first establish oracle inequalities for prediction errors and $\ell_1$ estimation errors for the Lasso estimator of the slope parameters and the threshold parameter, allowing for heteroskedastic non-subgaussian error terms and non-subgaussian covariates. Next, we derive the asymptotic distribution of tests involving an increasing number of slope parameters by debiasing (or desparsifying) the scaled Lasso estimator. The asymptotic distribution of tests without the threshold effect is identical to that with a fixed effect. Moreover, we perform valid inference for the threshold parameter using subsampling method. Finally, we conduct simulation studies to demonstrate the performance of our method in finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08105v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiatong Li, Hongqiang Yan</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference for Three-Dimensional Panel Data Models</title>
      <link>https://arxiv.org/abs/2404.08365</link>
      <description>arXiv:2404.08365v1 Announce Type: new 
Abstract: Hierarchical panel data models have recently garnered significant attention. This study contributes to the relevant literature by introducing a novel three-dimensional (3D) hierarchical panel data model, which integrates panel regression with three sets of latent factor structures: one set of global factors and two sets of local factors. Instead of aggregating latent factors from various nodes, as seen in the literature of distributed principal component analysis (PCA), we propose an estimation approach capable of recovering the parameters of interest and disentangling latent factors at different levels and across different dimensions. We establish an asymptotic theory and provide a bootstrap procedure to obtain inference for the parameters of interest while accommodating various types of cross-sectional dependence and time series autocorrelation. Finally, we demonstrate the applicability of our framework by examining productivity convergence in manufacturing industries worldwide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08365v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Guohua Feng, Jiti Gao, Fei Liu, Bin Peng</dc:creator>
    </item>
    <item>
      <title>One Factor to Bind the Cross-Section of Returns</title>
      <link>https://arxiv.org/abs/2404.08129</link>
      <description>arXiv:2404.08129v1 Announce Type: cross 
Abstract: We propose a new non-linear single-factor asset pricing model $r_{it}=h(f_{t}\lambda_{i})+\epsilon_{it}$. Despite its parsimony, this model represents exactly any non-linear model with an arbitrary number of factors and loadings -- a consequence of the Kolmogorov-Arnold representation theorem. It features only one pricing component $h(f_{t}\lambda_{I})$, comprising a nonparametric link function of the time-dependent factor and factor loading that we jointly estimate with sieve-based estimators. Using 171 assets across major classes, our model delivers superior cross-sectional performance with a low-dimensional approximation of the link function. Most known finance and macro factors become insignificant controlling for our single-factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08129v1</guid>
      <category>q-fin.GN</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Borri, Denis Chetverikov, Yukun Liu, Aleh Tsyvinski</dc:creator>
    </item>
    <item>
      <title>Non-robustness of diffusion estimates on networks with measurement error</title>
      <link>https://arxiv.org/abs/2403.05704</link>
      <description>arXiv:2403.05704v3 Announce Type: replace 
Abstract: Network diffusion models are used to study things like disease transmission, information spread, and technology adoption. However, small amounts of mismeasurement are extremely likely in the networks constructed to operationalize these models. We show that estimates of diffusions are highly non-robust to this measurement error. First, we show that even when measurement error is vanishingly small, such that the share of missed links is close to zero, forecasts about the extent of diffusion will greatly underestimate the truth. Second, a small mismeasurement in the identity of the initial seed generates a large shift in the locations of expected diffusion path. We show that both of these results still hold when the vanishing measurement error is only local in nature. Such non-robustness in forecasting exists even under conditions where the basic reproductive number is consistently estimable. Possible solutions, such as estimating the measurement error or implementing widespread detection efforts, still face difficulties because the number of missed links are so small. Finally, we conduct Monte Carlo simulations on simulated networks, and real networks from three settings: travel data from the COVID-19 pandemic in the western US, a mobile phone marketing campaign in rural India, and in an insurance experiment in China.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05704v3</guid>
      <category>econ.EM</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arun G. Chandrasekhar, Paul Goldsmith-Pinkham, Tyler H. McCormick, Samuel Thau, Jerry Wei</dc:creator>
    </item>
    <item>
      <title>Inference for Synthetic Controls via Refined Placebo Tests</title>
      <link>https://arxiv.org/abs/2401.07152</link>
      <description>arXiv:2401.07152v2 Announce Type: replace-cross 
Abstract: The synthetic control method is often applied to problems with one treated unit and a small number of control units. A common inferential task in this setting is to test null hypotheses regarding the average treatment effect on the treated. Inference procedures that are justified asymptotically are often unsatisfactory due to (1) small sample sizes that render large-sample approximation fragile and (2) simplification of the estimation procedure that is implemented in practice. An alternative is permutation inference, which is related to a common diagnostic called the placebo test. It has provable Type-I error guarantees in finite samples without simplification of the method, when the treatment is uniformly assigned. Despite this robustness, the placebo test suffers from low resolution since the null distribution is constructed from only $N$ reference estimates, where $N$ is the sample size. This creates a barrier for statistical inference at a common level like $\alpha = 0.05$, especially when $N$ is small. We propose a novel leave-two-out procedure that bypasses this issue, while still maintaining the same finite-sample Type-I error guarantee under uniform assignment for a wide range of $N$. Unlike the placebo test whose Type-I error always equals the theoretical upper bound, our procedure often achieves a lower unconditional Type-I error than theory suggests; this enables useful inference in the challenging regime when $\alpha &lt; 1/N$. Empirically, our procedure achieves a higher power when the effect size is reasonably large and a comparable power otherwise. We generalize our procedure to non-uniform assignments and show how to conduct sensitivity analysis. From a methodological perspective, our procedure can be viewed as a new type of randomization inference different from permutation or rank-based inference, which is particularly effective in small samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07152v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lihua Lei, Timothy Sudijono</dc:creator>
    </item>
    <item>
      <title>Liquidity Jump, Liquidity Diffusion, and Treatment on Wash Trading of Crypto Assets</title>
      <link>https://arxiv.org/abs/2404.07222</link>
      <description>arXiv:2404.07222v2 Announce Type: replace-cross 
Abstract: We propose that the liquidity of an asset includes two components: liquidity jump and liquidity diffusion. We show that liquidity diffusion has a higher correlation with crypto wash trading than liquidity jump and demonstrate that treatment on wash trading significantly reduces the level of liquidity diffusion, but only marginally reduces that of liquidity jump. We confirm that the autoregressive models are highly effective in modeling the liquidity-adjusted return with and without treatment on wash trading. We argue that treatment on wash trading is unnecessary in modeling established crypto assets that trade in unregulated but mainstream exchanges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07222v2</guid>
      <category>q-fin.ST</category>
      <category>econ.EM</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Deng, Zhong-guo Zhou</dc:creator>
    </item>
  </channel>
</rss>
