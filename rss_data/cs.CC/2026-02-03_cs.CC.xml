<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Saxe's theorems about the complexity of the Distance Geometry Problem</title>
      <link>https://arxiv.org/abs/2602.00001</link>
      <description>arXiv:2602.00001v1 Announce Type: new 
Abstract: In 1979, James B.~Saxe published an extended summary on the complexity of the Distance Geometry Problem in the proceedings of the 17th Allerton Conference. Many of the proofs in his paper are sketches, and even the whole proofs do not have all the details. In this paper we provide a commentary to Saxe's results and hopefully more understandable versions thereof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00001v1</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>math.MG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ma\"el Kupperschmitt, Leo Liberti</dc:creator>
    </item>
    <item>
      <title>Non-Clashing Teaching in Graphs: Algorithms, Complexity, and Bounds</title>
      <link>https://arxiv.org/abs/2602.00657</link>
      <description>arXiv:2602.00657v1 Announce Type: new 
Abstract: Kirkpatrick et al. [ALT 2019] and Fallat et al. [JMLR 2023] introduced non-clashing teaching and proved that it is the most efficient batch machine teaching model satisfying the collusion-avoidance benchmark established in the seminal work of Goldman and Mathias [COLT 1993]. Recently, (positive) non-clashing teaching was thoroughly studied for balls in graphs, yielding numerous algorithmic and combinatorial results. In particular, Chalopin et al. [COLT 2024] and Ganian et al. [ICLR 2025] gave an almost complete picture of the complexity landscape of the positive variant, showing that it is tractable only for restricted graph classes due to the non-trivial nature of the problem and concept class.
  In this work, we consider (positive) non-clashing teaching for closed neighborhoods in graphs. This concept class is not only extensively studied in various related contexts, but it also exhibits broad generality, as any finite binary concept class can be equivalently represented by a set of closed neighborhoods in a graph. In comparison to the works on balls in graphs, we provide improved algorithmic results, notably including FPT algorithms for more general classes of parameters, and we complement these results by deriving stronger lower bounds. Lastly, we obtain combinatorial upper bounds for wider classes of graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00657v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Liana Khazaliya, Fionn Mc Inerney</dc:creator>
    </item>
    <item>
      <title>Hardness Condensation for Decision Tree Measures by Restrictions</title>
      <link>https://arxiv.org/abs/2602.00754</link>
      <description>arXiv:2602.00754v1 Announce Type: new 
Abstract: For any Boolean function $f:\{0,1\}^n \to \{0,1\}$ with a complexity measure having value $k \ll n$, is it possible to restrict the function $f$ to $\Theta(k)$ variables while keeping the complexity preserved at $\Theta(k)$? This question, in the context of query complexity, was recently studied by G{\"{o}}{\"{o}}s, Newman, Riazanov and Sokolov (STOC 2024). They showed, among other results, that query complexity can not be condensed losslessly. They asked if complexity measures like block sensitivity or unambiguous certificate complexity can be condensed losslessly?
  In this work, we show that decision tree measures like block sensitivity and certificate complexity, cannot be condensed losslessly. That is, there exists a Boolean function $f$ such that any restriction of $f$ to $O(\mathcal{M}(f))$ variables has $\mathcal{M}(\cdot)$-complexity at most $\tilde{O}(\mathcal{M}(f)^{2/3})$, where $\mathcal{M} \in \{\mathsf{bs},\mathsf{fbs},\mathsf{C},\mathsf{D}\}$. This also improves upon a result of G{\"{o}}{\"{o}}s, Newman, Riazanov and Sokolov (STOC 2024).
  We also complement the negative results on lossless condensation with positive results about lossy condensation. In particular, we show that for every Boolean function $f$ there exists a restriction of $f$ to $O(\mathcal{M}(f))$ variables such that its $\mathcal{M}(\cdot)$-complexity is at least $\Omega(\mathcal{M}(f)^{1/2})$, where $\mathcal{M} \in \{\mathsf{bs},\mathsf{fbs},\mathsf{C},\mathsf{UC}_{min},\mathsf{UC}_1,\mathsf{UC},\mathsf{D},\widetilde{\mathsf{deg}},\lambda\}$. We also show a slightly weaker positive result for randomized and quantum query complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00754v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandrima Kayal, Rajat Mittal, Manaswi Paraashar, Nitin Saurabh</dc:creator>
    </item>
    <item>
      <title>The complexity of finding coset-generating polymorphisms and the promise metaproblem</title>
      <link>https://arxiv.org/abs/2602.00778</link>
      <description>arXiv:2602.00778v1 Announce Type: new 
Abstract: We show that the metaproblem for coset-generating polymorphisms is NP-complete, answering a question of Chen and Larose: given a finite structure, the computational question is whether this structure has a polymorphism of the form $(x,y,z) \mapsto x y^{-1} z$ with respect to some group; such operations are also called coset-generating, or heaps.
  Furthermore, we introduce a promise version of the metaproblem, parametrised by two polymorphism conditions $\Sigma_1$ and $\Sigma_2$ and defined analogously to the promise constraint satisfaction problem. We give sufficient conditions under which the promise metaproblem for $(\Sigma_1,\Sigma_2)$ is in P and under which it is NP-hard. In particular, the promise metaproblem is in P if $\Sigma_1$ states the existence of a Maltsev polymorphism and $\Sigma_2$ states the existence of an abelian heap polymorphism -- despite the fact that neither the metaproblem for $\Sigma_1$ nor the metaproblem for $\Sigma_2$ is known to be in P. We also show that the creation-metaproblem for Maltsev polymorphisms, under the promise that a heap polymorphism exists, is in P if and only if there is a uniform polynomial-time algorithm for CSPs with a heap polymorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00778v1</guid>
      <category>cs.CC</category>
      <category>math.RA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Bodirsky, Armin Wei{\ss}</dc:creator>
    </item>
    <item>
      <title>On Condensation of Block Sensitivity, Certificate Complexity and the $\mathsf{AND}$ (and $\mathsf{OR}$) Decision Tree Complexity</title>
      <link>https://arxiv.org/abs/2602.01042</link>
      <description>arXiv:2602.01042v1 Announce Type: new 
Abstract: Given an $n$-bit Boolean function with a complexity measure (such as block sensitivity, query complexity, etc.) $M(f) = k$, the hardness condensation question asks whether $f$ can be restricted to $O(k)$ variables such that the complexity measure is $\Omega(k)$?
  In this work, we study the condensability of block sensitivity, certificate complexity, AND (and OR) query complexity and Fourier sparsity. We show that block sensitivity does not condense under restrictions, unlike sensitivity: there exists a Boolean function $f$ with query complexity $k$ such that any restriction of $f$ to $O(k)$ variables has block sensitivity $O(k^{\frac{2}{3}})$. This answers an open question in G\"o\"os, Newman, Riazanov, and Sokolov (2024) in the negative. The same function yields an analogous incondensable result for certificate complexity. We further show that $\mathsf{AND}$(and $\mathsf{OR}$) decision trees are also incondensable. In contrast, we prove that Fourier sparsity admits a weak form of condensation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01042v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Soumya Nalli, Karthikeya Polisetty, Jayalal Sarma</dc:creator>
    </item>
    <item>
      <title>Breaking the Temporal Complexity Barrier: Bucket Calculus for Parallel Machine Scheduling</title>
      <link>https://arxiv.org/abs/2602.01356</link>
      <description>arXiv:2602.01356v1 Announce Type: new 
Abstract: This paper introduces bucket calculus, a novel mathematical framework that fundamentally transforms the computational complexity landscape of parallel machine scheduling optimization. We address the strongly NP-hard problem $P2|r_j|C_{\max}$ through an innovative adaptive temporal discretization methodology that achieves exponential complexity reduction from $O(T^n)$ to $O(B^n)$ where $B \ll T$, while maintaining near-optimal solution quality. Our bucket-indexed mixed-integer linear programming (MILP) formulation exploits dimensional complexity heterogeneity through precision-aware discretization, reducing decision variables by 94.4\% and achieving a theoretical speedup factor $2.75 \times 10^{37}$ for 20-job instances. Theoretical contributions include partial discretization theory, fractional bucket calculus operators, and quantum-inspired mechanisms for temporal constraint modeling. Empirical validation on instances with 20--400 jobs demonstrates 97.6\% resource utilization, near-perfect load balancing ($\sigma/\mu = 0.006$), and sustained performance across problem scales with optimality gaps below 5.1\%. This work represents a paradigm shift from fine-grained temporal discretization to multi-resolution precision allocation, bridging the fundamental gap between exact optimization and computational tractability for industrial-scale NP-hard scheduling problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01356v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noor Islam S. Mohammad</dc:creator>
    </item>
    <item>
      <title>$m$-Eternal Dominating Set Problem on Subclasses of Chordal Graphs</title>
      <link>https://arxiv.org/abs/2602.02135</link>
      <description>arXiv:2602.02135v1 Announce Type: new 
Abstract: A dominating set of a graph G(V, E) is a set of vertices D\subseteq V such that every vertex in V\D has a neighbor in D. An eternal dominating set extends this concept by placing mobile guards on the vertices of D. In response to an infinite sequence of attacks on unoccupied vertices, a guard can move to the attacked vertex from an adjacent position, ensuring that the new guards configuration remains a dominating set. In the one (all) guard(s) move model, only one (multiple) guard(s) moves(may move) per attack. The set of vertices representing the initial configuration of guards in one(all) guard move model is the eternal dominating set (m-eternal dominating set) of G. The minimum size of such a set in one(all) guard move model is called the eternal domination number (m-eternal domination number) of G, respectively. Given a graph G and an integer k, the m-Eternal Dominating Set asks whether G has an m-eternal dominating set of size at most k. In this work, we focus mainly on the computational complexity of m-Eternal Dominating Set in subclasses of chordal graphs. For split graphs, we show a dichotomy result by first designing a polynomial-time algorithm for K1,t-free split graphs with t\le 4, and then proving that the problem becomes NP-complete for t\ge 5. We showed that the problem is NP-hard on undirected path graphs. Moreover, we exhibit the computational complexity difference between the variants by showing the existence of two graph classes such that, in one, both Dominating Set and m-Eternal Dominating Set are solvable in polynomial time while Eternal Dominating Set is NP-hard, whereas in the other, Eternal Dominating Set is solvable in polynomial time and both Dominating Set and m-Eternal Dominating Set are NP-hard. Finally, we present a graph class where Dominating Set is NP-hard, but m-Eternal Dominating Set is efficiently solvable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02135v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashutosh Rai, Soumyashree Rana</dc:creator>
    </item>
    <item>
      <title>The SPARSE-Relativization Framework and Applications to Optimal Proof Systems</title>
      <link>https://arxiv.org/abs/2602.02294</link>
      <description>arXiv:2602.02294v1 Announce Type: new 
Abstract: We investigate the following longstanding open questions raised by Kraj\'i\v{c}ek and Pudl\'ak (J. Symb. L. 1989), Sadowski (FCT 1997), K\"obler and Messner (CCC 1998) and Messner (PhD 2000).
  Q1: Does TAUT have (p-)optimal proof systems?
  Q2: Does QBF have (p-)optimal proof systems?
  Q3: Are there arbitrarily complex sets with (p-)optimal proof systems?
  Recently, Egidy and Gla{\ss}er (STOC 2025) contributed to these questions by constructing oracles that show that there are no relativizable proofs for positive answers of these questions, even when assuming well-established conjectures about the separation of complexity classes. We continue this line of research by providing the same proof barrier for negative answers of these questions. For this, we introduce the SPARSE-relativization framework, which is an application of the notion of bounded relativization by Hirahara, Lu, and Ren (CCC 2023). This framework allows the construction of sparse oracles for statements such that additional useful properties (like an infinite polynomial-time hierarchy) hold. By applying the SPARSE-relativization framework, we show that the oracle construction of Egidy and Gla{\ss}er also yields the following new oracle.
  O1: No set in PSPACE\NP has optimal proof systems, $\mathrm{NP} \subsetneq \mathrm{PH} \subsetneq \mathrm{PSPACE}$, and PH collapses
  We use techniques of Cook and Kraj\'i\v{c}ek (J. Symb. L. 2007) and Beyersdorff, K\"obler, and M\"uller (Inf. Comp. 2011) and apply our SPARSE-relativization framework to obtain the following new oracle.
  O2: All sets in PSPACE have p-optimal proof systems, there are arbitrarily complex sets with p-optimal proof systems, and PH is infinite
  Together with previous results, our oracles show that questions Q1 and Q2 are independent of an infinite or collapsing polynomial-time hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02294v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Egidy</dc:creator>
    </item>
    <item>
      <title>End Cover for Initial Value Problem: Complete Validated Algorithms with Complexity Analysis</title>
      <link>https://arxiv.org/abs/2602.00162</link>
      <description>arXiv:2602.00162v1 Announce Type: cross 
Abstract: We consider the first-order autonomous ordinary differential equation \[ \mathbf{x}' = \mathbf{f}(\mathbf{x}), \] where $\mathbf{f} : \mathbb{R}^n \to \mathbb{R}^n$ is locally Lipschitz. For a box $B_0 \subseteq \mathbb{R}^n$ and $h &gt; 0$, we denote by $\mathrm{IVP}_{\mathbf{f}}(B_0,h)$ the set of solutions $\mathbf{x} : [0,h] \to \mathbb{R}^n$ satisfying \[ \mathbf{x}'(t) = \mathbf{f}(\mathbf{x}(t)), \qquad \mathbf{x}(0) \in B_0 . \]
  We present a complete validated algorithm for the following \emph{End Cover Problem}: given $(\mathbf{f}, B_0, \varepsilon, h)$, compute a finite set $\mathcal{C}$ of boxes such that \[ \mathrm{End}_{\mathbf{f}}(B_0,h) \;\subseteq\; \bigcup_{B \in \mathcal{C}} B \;\subseteq\; \mathrm{End}_{\mathbf{f}}(B_0,h) \oplus [-\varepsilon,\varepsilon]^n , \] where \[ \mathrm{End}_{\mathbf{f}}(B_0,h) = \left\{ \mathbf{x}(h) : \mathbf{x} \in \mathrm{IVP}_{\mathbf{f}}(B_0,h) \right\}. \]
  Moreover, we provide a complexity analysis of our algorithm and introduce a novel technique for computing the end cover $\mathcal{C}$ based on covering the boundary of $\mathrm{End}_{\mathbf{f}}(B_0,h)$. Finally, we present experimental results demonstrating the practicality of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00162v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingwei Zhang, Chee Yap</dc:creator>
    </item>
    <item>
      <title>Entanglement-Dependent Error Bounds for Hamiltonian Simulation</title>
      <link>https://arxiv.org/abs/2602.00555</link>
      <description>arXiv:2602.00555v1 Announce Type: cross 
Abstract: We establish tight connections between entanglement entropy and the approximation error in Trotter-Suzuki product formulas for Hamiltonian simulation. Product formulas remain the workhorse of quantum simulation on near-term devices, yet standard error analyses yield worst-case bounds that can vastly overestimate the resources required for structured problems. For systems governed by geometrically local Hamiltonians with maximum entanglement entropy $S_\text{max}$ across all bipartitions, we prove that the first-order Trotter error scales as $\mathcal{O}(t^2 S_\text{max} \operatorname{polylog}(n)/r)$ rather than the worst-case $\mathcal{O}(t^2 n/r)$, where $n$ is the system size and $r$ is the number of Trotter steps. This yields improvements of $\tilde{\Omega}(n^2)$ for one-dimensional area-law systems and $\tilde{\Omega}(n^{3/2})$ for two-dimensional systems. We extend these bounds to higher-order Suzuki formulas, where the improvement factor involves $2^{pS^*/2}$ for the $p$-th order formula. We further establish a separation result demonstrating that volume-law entangled systems fundamentally require $\tilde{\Omega}(n)$ more Trotter steps than area-law systems to achieve the same precision. This separation is tight up to logarithmic factors. Our analysis combines Lieb-Robinson bounds for locality, tensor network representations for entanglement structure, and novel commutator-entropy inequalities that bound the expectation value of nested commutators by the Schmidt rank of the state. These results have immediate applications to quantum chemistry, condensed matter simulation, and resource estimation for fault-tolerant quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00555v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prateek P. Kulkarni</dc:creator>
    </item>
    <item>
      <title>Hardness and Tractability of T_{h+1}-Free Edge Deletion</title>
      <link>https://arxiv.org/abs/2602.00644</link>
      <description>arXiv:2602.00644v1 Announce Type: cross 
Abstract: We study the parameterized complexity of the T(h+1)-Free Edge Deletion problem. Given a graph G and integers k and h, the task is to delete at most k edges so that every connected component of the resulting graph has size at most h. The problem is NP-complete for every fixed h at least 3, while it is solvable in polynomial time for h at most 2.
  Recent work showed strong hardness barriers: the problem is W[1]-hard when parameterized by the solution size together with the size of a feedback edge set, ruling out fixed-parameter tractability for many classical structural parameters. We significantly strengthen these negative results by proving W[1]-hardness when parameterized by the vertex deletion distance to a disjoint union of paths, the vertex deletion distance to a disjoint union of stars, or the twin cover number. These results unify and extend known hardness results for treewidth, pathwidth, and feedback vertex set, and show that several restrictive parameters, including treedepth, cluster vertex deletion number, and modular width, do not yield fixed-parameter tractability when h is unbounded.
  On the positive side, we identify parameterizations that restore tractability. We show that the problem is fixed-parameter tractable when parameterized by cluster vertex deletion together with h, and also when parameterized by neighborhood diversity together with h via an integer linear programming formulation. We further present a fixed-parameter tractable bicriteria approximation algorithm parameterized by k. Finally, we show that the problem admits fixed-parameter tractable algorithms on split graphs and interval graphs, and we establish hardness for a directed generalization even on directed acyclic graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00644v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad, Soumen Maity, Leeja R</dc:creator>
    </item>
    <item>
      <title>A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention</title>
      <link>https://arxiv.org/abs/2602.01763</link>
      <description>arXiv:2602.01763v1 Announce Type: cross 
Abstract: Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01763v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaowei Ye, Xiaoyu He, Chao Liao, Chen Wu, Pinyan Lu</dc:creator>
    </item>
    <item>
      <title>Structure of sparse Boolean functions over Abelian groups, and its application to testing</title>
      <link>https://arxiv.org/abs/2406.18700</link>
      <description>arXiv:2406.18700v4 Announce Type: replace 
Abstract: We study Fourier-sparse Boolean functions over general finite Abelian groups. A Boolean function $f : G \to \{-1,+1\}$ is $s$-sparse if it has at most $s$ non-zero Fourier coefficients. We introduce a general notion of granularity of Fourier coefficients and prove that every non-zero coefficient of an $s$-sparse Boolean function has magnitude at least \begin{equation*} \frac{1}{2^{\varphi(\Delta)/2} \, s^{\varphi(\Delta)/2}}, \end{equation*} where $\Delta$ denotes the exponent of the group $G$ (that is, the maximum order of an element in $G$) and $\varphi$ is the Euler's totient function. This generalizes the celebrated result of Gopalan et al. (SICOMP 2011) for $\mathbb{Z}_2^n$, extending it to all finite Abelian groups via new techniques from group theory and algebraic number theory.
  Using our new structural results on the Fourier coefficients of sparse functions, we design an efficient sparsity testing algorithm for Boolean functions. The tester distinguishes whether a given function is $s$-sparse or $\epsilon$-far from every $s$-sparse Boolean function, with query complexity $poly\left((2s)^{\varphi(\Delta)},1/\epsilon \right)$. In addition, we generalize the classical notion of Boolean degree to arbitrary Abelian groups and establish an $\Omega(\sqrt{s})$ lower bound for adaptive sparsity testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18700v4</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourav Chakraborty, Swarnalipa Datta, Pranjal Dutta, Arijit Ghosh, Swagato Sanyal</dc:creator>
    </item>
    <item>
      <title>Spectral Certificates and Sum-of-Squares Lower Bounds for Semirandom Hamiltonians</title>
      <link>https://arxiv.org/abs/2511.02264</link>
      <description>arXiv:2511.02264v3 Announce Type: replace 
Abstract: The $k$-$\mathsf{XOR}$ problem is one of the most well-studied problems in classical complexity. We study a natural quantum analogue of $k$-$\mathsf{XOR}$, the problem of computing the ground energy of a certain subclass of structured local Hamiltonians, signed sums of $k$-local Pauli operators, which we refer to as $k$-$\mathsf{XOR}$ Hamiltonians. As an exhibition of the connection between this model and classical $k$-$\mathsf{XOR}$, we extend results on refuting $k$-$\mathsf{XOR}$ instances to the Hamiltonian setting by crafting a quantum variant of the Kikuchi matrix for CSP refutation, instead capturing ground energy optimization. As our main result, we show an $n^{O(\ell)}$-time classical spectral algorithm certifying ground energy at most $\frac{1}{2} + \varepsilon$ in (1) semirandom Hamiltonian $k$-$\mathsf{XOR}$ instances or (2) sums of Gaussian-signed $k$-local Paulis both with $O(n) \cdot \left(\frac{n}{\ell}\right)^{k/2-1} \log n /\varepsilon^4$ local terms, a tradeoff known as the refutation threshold. Additionally, we give evidence this tradeoff is tight in the semirandom regime via non-commutative Sum-of-Squares lower bounds embedding classical $k$-$\mathsf{XOR}$ instances as entirely classical Hamiltonians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02264v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Kocurek</dc:creator>
    </item>
    <item>
      <title>The Query Complexity of Local Search in Rounds on General Graphs</title>
      <link>https://arxiv.org/abs/2601.13266</link>
      <description>arXiv:2601.13266v2 Announce Type: replace 
Abstract: We analyze the query complexity of finding a local minimum in $t$ rounds on general graphs. More precisely, given a graph $G = (V,E)$ and oracle access to an unknown function $f : V \to \mathbb{R}$, the goal is to find a local minimum--a vertex $v$ such that $f(v) \leq f(u)$ for all $(u,v) \in E$--using at most $t$ rounds of interaction with the oracle. The query complexity is well understood on grids, but much less is known beyond. This abstract problem captures many optimization tasks, such as finding a local minimum of a loss function during neural network training.
  For each graph with $n$ vertices, we prove a deterministic upper bound of $O(t n^{1/t} (s\Delta)^{1-1/t})$, where $s$ is the separation number and $\Delta$ is the maximum degree of the graph. We complement this result with a randomized lower bound of $\Omega(t n^{1/t}-t)$ that holds for any connected graph. We also find that parallel steepest descent with a warm start provides improved bounds for graphs with high separation number and bounded degree.
  To obtain our results, we utilized an advanced version of Gemini at various stages of our research. We discuss our experience in a methodology section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13266v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simina Br\^anzei, Ioannis Panageas, Dimitris Paparas</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Sufficiency in Decision Problems</title>
      <link>https://arxiv.org/abs/2601.15571</link>
      <description>arXiv:2601.15571v2 Announce Type: replace 
Abstract: We characterize the computational complexity of coordinate sufficiency in decision problems within the formal model. Given action set $A$, state space $S = X_1 \times \cdots \times X_n$, and utility $u: A \times S \to \mathbb{R}$, a coordinate set $I$ is sufficient if $s_I = s'_I$ implies $\mathrm{Opt}(s) = \mathrm{Opt}(s')$. The landscape in the formal model: - General case: SUFFICIENCY-CHECK is coNP-complete; ANCHOR-SUFFICIENCY is $\Sigma_2^P$-complete. - Tractable cases: Polynomial-time for bounded action sets under the explicit-state encoding; separable utilities ($u = f + g$) under any encoding; and tree-structured utility with explicit local factors. - Encoding-regime separation: Polynomial-time under the explicit-state encoding (polynomial in $|S|$). Under ETH, there exist succinctly encoded worst-case instances witnessed by a strengthened gadget construction (mechanized in Lean) with $k^* = n$ for which SUFFICIENCY-CHECK requires $2^{\Omega(n)}$ time. The tractable cases are stated with explicit encoding assumptions. Together, these results answer the question "when is decision-relevant information identifiable efficiently?" within the stated regimes. The primary contribution is theoretical: a complete characterization of the core decision-relevant problems in the formal model (coNP/$\Sigma_2^P$ completeness and tractable cases under explicit encoding assumptions). The practical corollaries follow from these theorems. The reduction constructions and key equivalence theorems are machine-checked in Lean 4 ($\sim$5,000 lines, 200+ theorems); complexity classifications follow by composition with standard results</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15571v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tristan Simas</dc:creator>
    </item>
    <item>
      <title>Quantum algorithms through graph composition</title>
      <link>https://arxiv.org/abs/2504.02115</link>
      <description>arXiv:2504.02115v2 Announce Type: replace-cross 
Abstract: We introduce the graph composition framework, a generalization of the $st$-connectivity framework for constructing quantum algorithms. Our framework constructs algorithms that solve a connectivity problem on an undirected graph, where the availability of each edge is computed by a span program. The key novelty of our framework is that the construction allows for amortization of the span programs' costs, while at the same time avoiding build-up of errors due to composition. We give generic time-efficient implementations of algorithms generated through the graph composition framework in the quantum read-only memory model, which is a weaker assumption than the more common quantum random-access model. Along the way, we also simplify the span program algorithm by converting it to a transducer, and remove the dependence of its analysis on the effective spectral gap lemma.
  We use graph composition to unify existing quantum algorithmic frameworks. Surprisingly, we show that any randomized algorithm can be converted into an instance of the $st$-connectivity framework. Furthermore, we show that the $st$-connectivity framework subsumes the learning graph framework, and the weighted-decision-tree framework. We show that the graph composition framework subsumes part of the quantum divide-and-conquer framework, and that it is itself subsumed by the multidimensional quantum walk framework. Moreover, we show polynomial relations and separations between the optimal query complexities that can be achieved with several of these frameworks. Finally, we apply our techniques to give improved algorithms for various string-search problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02115v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjan Cornelissen</dc:creator>
    </item>
    <item>
      <title>Optimal Hardness of Online Algorithms for Large Independent Sets</title>
      <link>https://arxiv.org/abs/2504.11450</link>
      <description>arXiv:2504.11450v2 Announce Type: replace-cross 
Abstract: We study the algorithmic problem of finding a large independent set in the Erd{\"o}s-R\'{e}nyi random graph $G(n,p)$. For constant $p$ and $b=1/(1-p)$, the largest independent set has size $2\log_b n$, while a simple greedy algorithm - revealing vertices sequentially and making decisions based only on previously seen vertices - finds an independent set of size $\log_b n$. In his seminal 1976 paper, Karp challenged to either improve this guarantee or establish its hardness. Decades later, this problem remains open - one of the most prominent algorithmic problems in the theory of random graphs.
  In this paper, we establish that a broad class of online algorithms fails to find an independent set of size $(1+\epsilon)\log_b n$ whp. This class includes Karp's algorithm as a special case, and extends it by allowing the algorithm to query exceptional edges, not yet "seen" by the algorithm. Our lower bound holds for $p\in [d/n,1-n^{-1/d}]$. In the dense regime (constant $p$), we also prove that our result is asymptotically tight with respect to the number of exceptional edges queried, by designing an online algorithm which beats the half-optimality threshold when the number of exceptional edges slightly exceeds our bound.
  Our result provides evidence for the algorithmic hardness of Karp's problem, by supporting the conjectured optimality of the greedy algorithm and establishing it within the class of online algorithms. Our proof relies on a refined analysis of the geometric structure of large independent sets, establishing a variant of the Overlap Gap Property (OGP). While OGP has predominantly served as a barrier to stable algorithms, online algorithms are inherently unstable, necessitating new ideas. Our proof refines the OGP framework by incorporating several new ideas (including temporal interpolation paths and stopping-times) that we expect to be useful for other online models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11450v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Gamarnik, Eren C. K{\i}z{\i}lda\u{g}, Lutz Warnke</dc:creator>
    </item>
  </channel>
</rss>
