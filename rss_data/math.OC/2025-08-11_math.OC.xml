<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 04:01:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Optimal Smoothings of Sublinear Functions and Convex Cones</title>
      <link>https://arxiv.org/abs/2508.06681</link>
      <description>arXiv:2508.06681v1 Announce Type: new 
Abstract: This paper considers the problem of smoothing convex functions and sets, seeking the nearest smooth convex function or set to a given one. For convex cones and sublinear functions, a full characterization of the set of all optimal smoothings is given. These provide if and only if characterizations of the set of optimal smoothings for any target level of smoothness. Optimal smoothings restricting to either inner or outer approximations also follow from our theory. Finally, we apply our theory to provide insights into smoothing amenable functions given by compositions with sublinear functions and generic convex sets by expressing them as conic sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06681v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thabo Samakhoana, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Learning to control inexact Benders decomposition via reinforcement learning</title>
      <link>https://arxiv.org/abs/2508.06700</link>
      <description>arXiv:2508.06700v1 Announce Type: new 
Abstract: Benders decomposition (BD), along with its generalized version (GBD), is a widely used algorithm for solving large-scale mixed-integer optimization problems that arise in the operation of process systems. However, the off-the-shelf application to online settings can be computationally inefficient due to the repeated solution of the master problem. An approach to reduce the solution time is to solve the master problem to local optimality. However, identifying the level of suboptimality at each iteration that minimizes the total solution time is nontrivial. In this paper, we propose the application of reinforcement learning to determine the best optimality gap at each GBD iteration. First, we show that the inexact GBD can converge to the optimal solution given a properly designed optimality gap schedule. Next, leveraging reinforcement learning, we learn a policy that minimizes the total solution time, balancing the solution time per iteration with optimality gap improvement. In the resulting RL-iGBD algorithm, the policy adapts the optimality gap at each iteration based on the features of the problem and the solution progress. In numerical experiments on a mixed-integer economic model predictive control problem, we show that the proposed RL-enhanced iGBD method achieves substantial reductions in solution time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06700v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhe Li, Bernard T. Agyeman, Ilias Mitrai, Prodromos Daoutidis</dc:creator>
    </item>
    <item>
      <title>Electric Vehicle Scheduling and Vehicle-to-Grid Integration in Microgrids</title>
      <link>https://arxiv.org/abs/2508.06752</link>
      <description>arXiv:2508.06752v1 Announce Type: new 
Abstract: The logistical challenges and high costs associated with procuring and transporting fuel to remote military bases underscore the need for sustainable and resilient energy solutions. Integrating renewable energy sources and electric vehicles into military microgrids offers a promising approach to enhance energy security and operational readiness. This paper explores the optimization of travel, charging, and discharging schedules for a fleet of military electric trucks, aiming to minimize reliance on fuel-generated electricity while ensuring that mission-critical transportation needs are met. We extend the classical Vehicle Scheduling Problem by incorporating Electric Vehicle Scheduling Problem dynamics and Vehicle-to-Grid capabilities, developing a comprehensive optimization model that addresses both logistical and energy demands within a military microgrid context. Utilizing a column generation approach, we efficiently solve large-scale instances and demonstrate significant improvements in fuel efficiency, renewable energy utilization, and overall operational cost. Computational experiments using realistic demand and solar generation data illustrate that integration of vehicle-to-grid enabled electric vehicles substantially reduces fuel consumption and can generate surplus energy returned to the grid. The results indicate that while battery constraints may require an increased fleet size, strategic scheduling of charging and discharging yields considerable economic and operational benefits. Our findings provide valuable insights for planners aiming to optimize energy use, reduce dependence on traditional fuel sources, and enhance operational resilience in remote environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06752v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nathan Cho, Andrea Lodi, Anna Scaglione</dc:creator>
    </item>
    <item>
      <title>Risk Aware Reservoir Control For Safer Urban Traffic Networks</title>
      <link>https://arxiv.org/abs/2508.06790</link>
      <description>arXiv:2508.06790v1 Announce Type: new 
Abstract: We present a risk-aware perimeter-style controller that couples safety and efficiency targets in large, heterogeneous urban traffic networks. The network is compressed into two interacting "reservoirs" whose dynamics follow the Generalized Bathtub Model, while accidents are described by a self-exciting (Hawkes) counting process whose intensity depends on vehicle exposure, speed dispersion between reservoirs and accident clustering. Accident occurrences feed back into operations through an analytically simple degradation factor that lowers speed and discharge capacity in proportion to the live accident load. A receding-horizon policy minimizes a mixed delay-safety objective that includes a variance penalty capturing risk aversion; the resulting open-loop problem is shown to possess a bang-bang optimum whose gates switch only at accident times. This structure enables an event-triggered MPC that only re-optimizes when new accidents occur, reducing on-line computation significantly. Parameters are calibrated using OpenStreetMap data for metropolitan Copenhagen to analyze traffic dynamics during morning peak commuter demand. Monte-Carlo simulations demonstrate delay savings of up to 30% and accident reductions of up to 35% relative to an uncontrolled baseline, with a transparent trade-off governed by a single risk parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06790v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Hammerl, Wenlong Jin, Ravi Seshadri, Thomas Kj{\ae}r Rasmussen, Otto Anker Nielsen</dc:creator>
    </item>
    <item>
      <title>Optimal Evacuation Control in Large Urban Networks With Stochastic Demand</title>
      <link>https://arxiv.org/abs/2508.06797</link>
      <description>arXiv:2508.06797v1 Announce Type: new 
Abstract: We develop a risk-aware Model Predictive Control (MPC) framework for large-scale vehicular evacuations. Traffic dynamics are captured by the Generalized Bathtub Model, which describes the network-wide trip completion rate by tracking the time evolution of the distribution of remaining trip distances. We model evacuation inflow as a stochastic inflow process, and employ origin gating as the control policy, implemented through staged departure orders or adaptive ramp metering. A convex objective integrates total evacuation delay with a generic hazard-exposure term which can embed any spatial risk field (e.g., flood depth, fire intensity). We prove that if the residual-distance distribution exhibits non-decreasing hazard rate, then the optimal origin-gating profile is necessarily monotone decreasing and, under an inflow cap, bang-bang (single switch). This result supplies a closed-form seed for numerical optimizations and clarifies why early heavy release followed by throttling is optimal. Furthermore, we demonstrate that the assumption of a non-decreasing hazard rate is always satisfied when the origins of evacuation movements are uniformly distributed over a convexly bounded evacuation zone-a property that is fulfilled in the vast majority of real evacuation scenarios, at least approximately. The framework is demonstrated through a flood evacuation scenario on Amager Island, a densely populated area of Copenhagen that faces significant flood risk due to its low elevation and coastal exposure. The Generalized Bathtub evacuation model is coupled with a lightweight shallow-water model parameterized using real bathymetric and topographic data from Amager Island. Across 10,000 stochastic demand scenarios, the MPC policy reduces the expected area-under-queue by an average of 27% compared to a no-control scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06797v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Hammerl, Wenlong Jin, Ravi Seshadri, Thomas Kj{\ae}r Rasmusssen, Otoo Anker Nielsen</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Convergence of Accelerated Gradient Methods under Generalized and $(L_0, L_1)$-Smoothness</title>
      <link>https://arxiv.org/abs/2508.06884</link>
      <description>arXiv:2508.06884v1 Announce Type: new 
Abstract: We study first-order methods for convex optimization problems with functions $f$ satisfying the recently proposed $\ell$-smoothness condition $||\nabla^{2}f(x)|| \le \ell\left(||\nabla f(x)||\right),$ which generalizes the $L$-smoothness and $(L_{0},L_{1})$-smoothness. While accelerated gradient descent AGD is known to reach the optimal complexity $O(\sqrt{L} R / \sqrt{\varepsilon})$ under $L$-smoothness, where $\varepsilon$ is an error tolerance and $R$ is the distance between a starting and an optimal point, existing extensions to $\ell$-smoothness either incur extra dependence on the initial gradient, suffer exponential factors in $L_{1} R$, or require costly auxiliary sub-routines, leaving open whether an AGD-type $O(\sqrt{\ell(0)} R / \sqrt{\varepsilon})$ rate is possible for small-$\varepsilon$, even in the $(L_{0},L_{1})$-smoothness case.
  We resolve this open question. Leveraging a new Lyapunov function and designing new algorithms, we achieve $O(\sqrt{\ell(0)} R / \sqrt{\varepsilon})$ oracle complexity for small-$\varepsilon$ and virtually any $\ell$. For instance, for $(L_{0},L_{1})$-smoothness, our bound $O(\sqrt{L_0} R / \sqrt{\varepsilon})$ is provably optimal in the small-$\varepsilon$ regime and removes all non-constant multiplicative factors present in prior accelerated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06884v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin</dc:creator>
    </item>
    <item>
      <title>Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization</title>
      <link>https://arxiv.org/abs/2508.06906</link>
      <description>arXiv:2508.06906v1 Announce Type: new 
Abstract: Integer and mixed-integer nonlinear programming (INLP, MINLP) are central to logistics, energy, and scheduling, but remain computationally challenging. This survey examines how machine learning and reinforcement learning can enhance exact optimization methods - particularly branch-and-bound (BB), without compromising global optimality. We cover discrete, continuous, and mixed-integer formulations, and highlight applications such as crew scheduling, vehicle routing, and hydropower planning. We introduce a unified BB framework that embeds learning-based strategies into branching, cut selection, node ordering, and parameter control. Classical algorithms are augmented using supervised, imitation, and reinforcement learning models to accelerate convergence while maintaining correctness. We conclude with a taxonomy of learning methods by solver class and learning paradigm, and outline open challenges in generalization, hybridization, and scaling intelligent solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06906v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morteza Kimiaei, Vyacheslav Kungurtsev, Brian Olimba</dc:creator>
    </item>
    <item>
      <title>On the Convergence of a Noisy Gradient Method for Non-convex Distributed Resource Allocation: Saddle Point Escape</title>
      <link>https://arxiv.org/abs/2508.06922</link>
      <description>arXiv:2508.06922v1 Announce Type: new 
Abstract: This paper considers a class of distributed resource allocation problems where each agent privately holds a smooth, potentially non-convex local objective, subject to a globally coupled equality constraint. Built upon the existing method, Laplacian-weighted Gradient Descent, we propose to add random perturbations to the gradient iteration to enable efficient escape from saddle points and achieve second-order convergence guarantees. We show that, with a sufficiently small fixed step size, the iterates of all agents converge to an approximate second-order optimal solution with high probability. Numerical experiments confirm the effectiveness of the proposed approach, demonstrating improved performance over standard weighted gradient descent in non-convex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06922v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Qin, Ye Pu</dc:creator>
    </item>
    <item>
      <title>Tilt Stability for Nonlinear Programs under Relaxed Constant Rank Constraint Qualification</title>
      <link>https://arxiv.org/abs/2508.06927</link>
      <description>arXiv:2508.06927v1 Announce Type: new 
Abstract: This paper investigates the tilt stability of local minimizers for nonlinear programs under the relaxed constant rank constraint qualification in finite dimensions. By employing a neighborhood primal-dual approach and extending calculus rules for subgradient graphical derivative, we obtain some pointbased characterizations of tilt-stable local minimizers along with an explicit formula for calculating the exact bound of tilt stability. These results extend the corresponding ones of H. Gfrerer and B.S.Mordukhovich [SIAM J. Optim. 25 (2015), 2081-2119] by relaxing the constraint qualification and removing the linear independence condition of gradients of equality constraint functions. Examples are provided illustrating our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06927v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Huy Chieu, Nguyen Thi Quynh Trang, Nguyen Thi Hai Yen</dc:creator>
    </item>
    <item>
      <title>Decision-Dependent Distributionally Robust Optimization with Application to Dynamic Pricing</title>
      <link>https://arxiv.org/abs/2508.06965</link>
      <description>arXiv:2508.06965v1 Announce Type: new 
Abstract: We consider decision-making problems under decision-dependent uncertainty (DDU), where the distribution of uncertain parameters depends on the decision variables and is only observable through a finite offline dataset. To address this challenge, we formulate a decision-dependent distributionally robust optimization (DD-DRO) problem, and leverage multivariate interpolation techniques along with the Wasserstein metric to construct decision-dependent nominal distributions (thereby decision-dependent ambiguity sets) based on the offline data. We show that the resulting ambiguity sets provide a finite-sample, high-probability guarantee that the true decision-dependent distribution is contained within them. Furthermore, we establish key properties of the DD-DRO framework, including a non-asymptotic out-of-sample performance guarantee, an optimality gap bound, and a tractable reformulation. The practical effectiveness of our approach is demonstrated through numerical experiments on a dynamic pricing problem with nonstationary demand, where the DD-DRO solution produces pricing strategies with guaranteed expected revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06965v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengrui Qu, Huiwen Jia, Pengcheng You</dc:creator>
    </item>
    <item>
      <title>Global Nonconvex Optimization with Integer Variables</title>
      <link>https://arxiv.org/abs/2508.07018</link>
      <description>arXiv:2508.07018v1 Announce Type: new 
Abstract: Nonconvex optimization refers to the process of solving problems whose objective or constraints are nonconvex. Historically, this type of problems have been very difficult to solve to global optimality, with traditional solvers often relying on approximate solutions. Bertsimas et al. introduce a novel approach for solving continuous nonconvex optimization problems to provable optimality, called the Relaxation Perspectification Technique - Branch and Bound (RPT-BB). In this paper, we extend the RPT-BB approach to the binary, mixed-binary, integer, and mixed-integer variable domains. We outline a novel branch-and-bound algorithm that makes use of the Relaxation Perspectification Technique (RPT), as well as binary, integer, and eigenvector cuts. We demonstrate the performance of this approach on four representative nonconvex problems, as well as one real-world nonconvex optimization problem, and we benchmark its performance on BARON and SCIP, two state-of-the-art optimization solvers for nonconvex mixed-integer problems. Our results show that our method stands well against BARON, and often outperforms BARON, in terms of computational time and optimal objective value. Moreover, our results show that, while SCIP continues to lead as the state-of-the-art solver, the proposed algorithm demonstrates strong performance on challenging instances, successfully solving problems to global optimality that SCIP and BARON are unable to solve within the time limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07018v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Danique de Moor, Thodoris Koukouvinos, Demetrios Kriezis</dc:creator>
    </item>
    <item>
      <title>An Optimization Perspective on the Monotonicity of the Multiplicative Algorithm for Optimal Experimental Design</title>
      <link>https://arxiv.org/abs/2508.07074</link>
      <description>arXiv:2508.07074v1 Announce Type: new 
Abstract: We provide an optimization-based argument for the monotonicity of the multiplicative algorithm (MA) for a class of optimal experimental design problems considered in Yu (2010). Our proof avoids introducing auxiliary variables (or problems) and leveraging statistical arguments, and is much more straightforward and simpler compared to the proof in Yu (2010). The simplicity of our monotonicity proof also allows us to easily identify several sufficient conditions that ensure the strict monotonicity of MA. In addition, we provide two simple and similar-looking examples on which MA behaves very differently. These examples offer insight in the behaviors of MA, and also reveal some limitations of MA when applied to certain optimality criteria. We discuss these limitations, and pose open problems that may lead to deeper understanding of the behaviors of MA on these optimality criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07074v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renbo Zhao</dc:creator>
    </item>
    <item>
      <title>Queue Replacement Approach to Dynamic User Equilibrium Assignment with Route and Departure Time Choice</title>
      <link>https://arxiv.org/abs/2508.07159</link>
      <description>arXiv:2508.07159v1 Announce Type: new 
Abstract: This study develops a hybrid analytical and numerical approach for the dynamic user equilibrium (DUE) assignment with route and departure time choice (RDTC) for homogeneous users. The core concept of the proposed approach is the generalized queue replacement principle (GQRP). The GQRP is an equivalence between the equilibrium queueing delay pattern and the solution to a linear programming (LP) problem obtained by relaxing certain conditions in the original DUE-RDTC problem. We present a systematic method to determine whether the GQRP holds. Based on the GQRP, we develop a systematic procedure to obtain an exact DUE solution by sequentially solving two LPs: one for the equilibrium cost pattern (including the queueing delay pattern) and the other for the equilibrium flow pattern. Furthermore, we demonstrate the effectiveness of the proposed method through detailed illustrative examples and numerical examples for networks of various scales, including Sioux Falls and Eastern Massachusetts networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07159v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takara Sakai, Takashi Akamatsu, Koki Satsukawa</dc:creator>
    </item>
    <item>
      <title>First-order equivalent static loads for dynamic response structural optimization</title>
      <link>https://arxiv.org/abs/2508.07222</link>
      <description>arXiv:2508.07222v1 Announce Type: new 
Abstract: A novel first-order equivalent static loads approach for optimization of structural dynamic response, F-ESL, is presented and compared to the basic equivalent static load formulation, ESL. F-ESL simplifies dynamic optimization problems by converting them into a series of static optimization sub-problems. The ESL algorithm in its original formulation does not have a guaranteed capability of reaching, or recognizing, final designs that satisfy necessary first-order optimality conditions. F-ESL addresses this limitation by including first-order terms directly into the equivalent static load definition. This new mathematical information guides the optimization algorithm more effectively toward solutions that satisfy both feasibility and optimality conditions. Using reproducible numerical examples, we show that F-ESL overcomes the known limitations of the original ESL, often with few outer function evaluations and fast convergence. At the same time, F-ESL maintains ESL simplicity, robustness, and ease of implementation, providing practitioners with an effective tool for structural dynamic optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07222v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mordechay Buzaglo, Nicol\`o Pollini</dc:creator>
    </item>
    <item>
      <title>Time Scaling Makes Accelerated Gradient Flow and Proximal Method Faster in Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2508.07254</link>
      <description>arXiv:2508.07254v1 Announce Type: new 
Abstract: This paper extends a class of single-objective gradient flows and accelerated proximal methods to the multiobjective optimization domain within Euclidean spaces. The proposed gradient flow is a second-order differential equation composed of a second-order term, a first-order term with asymptotic vanishing behavior, and a gradient term with time scaling. We prove the existence of trajectory solutions to the equation and, through Lyapunov analysis, demonstrate that with appropriate parameter choices, the trajectory solutions can achieve a sublinear convergence rate faster than $O(1/t^2)$. For the proposed proximal algorithm, we similarly obtain a sublinear convergence rate faster than $O(1/k^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07254v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingdong Yin</dc:creator>
    </item>
    <item>
      <title>Threshold dynamics in time-delay systems: polynomial $\beta$-control in a pressing process and connections to blow-up</title>
      <link>https://arxiv.org/abs/2508.07268</link>
      <description>arXiv:2508.07268v1 Announce Type: new 
Abstract: This paper addresses a press control problem in straightening machines with small time delays due to system communication. To handle this, we propose a generalized $\beta$-control method, which replaces conventional linear velocity control with a polynomial of degree $\beta \ge 1$. The resulting model is a delay differential equation (DDE), for which we derive basic properties through nondimensionalization and analysis. Numerical experiments suggest the existence of a threshold initial velocity separating overshoot and non-overshoot dynamics, which we formulate as a conjecture. Based on this, we design a control algorithm under velocity constraints and confirm its effectiveness. We also highlight a connection between threshold behavior and finite-time blow-up in DDEs. This study provides a practical control strategy and contributes new insights into threshold dynamics and blow-up phenomena in delay systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07268v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masato Kimura, Hirotaka Kuma, Yikan Liu, Kazunori Matsui, Masahiro Yamamoto, Zhenxing Yang</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean Field Games with Common Noise: A Direct Approach</title>
      <link>https://arxiv.org/abs/2508.07271</link>
      <description>arXiv:2508.07271v1 Announce Type: new 
Abstract: This paper investigates a linear-quadratic mean field games problem with common noise, where the drift term and diffusion term of individual state equations are coupled with both the state, control, and mean field terms of the state, and we adopt the direct approach to tackle this problem. Compared with addressing the corresponding mean field teams problem, the mean field games problem with state coupling presents greater challenges. This is not only reflected in the explosive increase in the number of adjoint equations when applying variational analysis but also in the need for more Riccati equations during decoupling the high-dimensional forward-backward stochastic differential equations system. We take a different set of steps and ingeniously utilize the inherent properties of the equations to address this challenge. First, we solve an $N$-player games problem within a vast and finite population setting, and obtain a set of forward-backward stochastic differential equations by variational analysis. Then, we derive the limiting forward-backward stochastic differential equations by taking the limit as $N$ approaches infinity and applying the law of large numbers. Based on the existence and uniqueness of solutions to backward stochastic differential equations, some variables in the equations are identically zero, which significantly reduces the complexity of the analysis. This allows us to introduce just two Riccati equations to explicitly construct decentralized strategies for all participants. Moreover, we demonstrate that the constructed decentralized strategies constitute an $\epsilon$-Nash equilibrium strategy for the original problem. We also extend the results to the infinite-horizon case and analyze the solvability of algebraic Riccati equations. Finally, numerical simulations are provided to illustrate the preceding conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07271v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wenyu Cong, Jingtao Shi, Bingchang Wang</dc:creator>
    </item>
    <item>
      <title>A K-adaptability Approach to Proton Radiation Therapy Robust Treatment Planning</title>
      <link>https://arxiv.org/abs/2508.07368</link>
      <description>arXiv:2508.07368v1 Announce Type: new 
Abstract: Uncertainties such as setup and range errors can significantly compromise proton therapy. A discrete uncertainty set is often constructed to represent different uncertainty scenarios. A min-max robust optimization approach is then utilized to optimize the worst-case performance of a radiation therapy plan against the uncertainty set. However, the min-max approach can be too conservative as a single plan has to account for the entire uncertainty set. K-adaptability is a novel approach to robust optimization which covers the uncertainty set with multiple (K) solutions, reducing the conservativeness. Solving K-adaptability to optimality is known to be computationally intractable. To that end, we developed a novel and efficient K-adaptability heuristic that iteratively clusters the scenarios based on plan-scenario performance for the proton radiation therapy planning problem. Compared to the conventional robust solution, the developed K-adaptability heuristic increased the worst-case CTV Dmin dose up to 4.52 Gy on average across five head and neck patients. The developed heuristic also demonstrated its superiority in objective value and time-efficiency compared to the competing methods we tested.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07368v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zihang Qiu, Ali Ajdari, Mislav Bobi\'c, Thomas Bortfeld, Dick den Hertog, Jannis Kurtz, Hoyeon Lee</dc:creator>
    </item>
    <item>
      <title>A Complete Derivation of Complex Circle Manifold (CCM) Riemannian manifold Optimization Equations</title>
      <link>https://arxiv.org/abs/2508.07396</link>
      <description>arXiv:2508.07396v1 Announce Type: new 
Abstract: After reviewing manifold optimization techniques in applications like MIMO communication systems, phased array beamforming, radar, and control theory, we observed that the Complex Circle Manifold (CCM) is widely employed, yet its foundational relations and equations lack a rigorous, self-contained derivation in the literature. This paper provides a systematic and rigorous proof of CCM's key properties, including its tangent space and Riemannian gradient operations, with explicit connections to real-world optimization problems. Our work aims to serve as a unified reference for researchers and practitioners applying CCM Manifold Optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07396v1</guid>
      <category>math.OC</category>
      <category>math.CV</category>
      <category>math.DG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Tabrizi, Mohammad Hadi Mirmohammadi</dc:creator>
    </item>
    <item>
      <title>From Product Hilbert Spaces to the Generalized Koopman Operator and the Nonlinear Fundamental Lemma</title>
      <link>https://arxiv.org/abs/2508.07494</link>
      <description>arXiv:2508.07494v1 Announce Type: new 
Abstract: The generalization of the Koopman operator to systems with control input and the derivation of a nonlinear fundamental lemma are two open problems that play a key role in the development of data-driven control methods for nonlinear systems. Both problems hinge on the construction of observable or basis functions and their corresponding Hilbert space that enable an infinite-dimensional, linear system representation. In this paper we derive a novel solution to these problems based on orthonormal expansion in a product Hilbert space constructed as the tensor product between the Hilbert spaces of the state and input observable functions, respectively. We prove that there exists an infinite-dimensional linear operator, i.e. the generalized Koopman operator, from the constructed product Hilbert space to the Hilbert space corresponding to the lifted state propagated forward in time. A scalable data-driven method for computing finite-dimensional approximations of generalized Koopman operators and several choices of observable functions are also presented. Moreover, we derive a nonlinear fundamental lemma by exploiting the bilinear structure of the infinite-dimensional generalized Koopman model. The effectiveness of the developed generalized Koopman embedding is illustrated on the Van der Pol oscillator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07494v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mircea Lazar</dc:creator>
    </item>
    <item>
      <title>Randomized coordinate gradient descent almost surely escapes strict saddle points</title>
      <link>https://arxiv.org/abs/2508.07535</link>
      <description>arXiv:2508.07535v1 Announce Type: new 
Abstract: We analyze the behavior of randomized coordinate gradient descent for nonconvex optimization, proving that under standard assumptions, the iterates almost surely escape strict saddle points. By formulating the method as a nonlinear random dynamical system and characterizing neighborhoods of critical points, we establish this result through the center-stable manifold theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07535v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Chen, Yingzhou Li, Zihao Li</dc:creator>
    </item>
    <item>
      <title>Nash Equilibria of Noncooperative/Miexd Differential Games with Density Constraints in Infinite Dimensions</title>
      <link>https://arxiv.org/abs/2508.07623</link>
      <description>arXiv:2508.07623v1 Announce Type: new 
Abstract: Motivated by Cournot models, this paper proposes novel models of the noncooperative and cooperative differential games with density constraints in infinite dimensions, where markets consist of infinite firms and demand dynamics are governed by controlled differential equations. Markets engage in noncooperative competition with each other, while firms within each market engage in noncooperative or cooperative games. The main problems are to find the noncooperative Nash equilibrium (NNE) of the noncooperative differential game and the mixed Nash equilibrium (MNE) of the mixed noncooperative and cooperative differential game. Moreover, fundamental relationship is established between noncooperative/mixed differential game with density constraints and infinite-dimensional differential variational inequalities with density constraints. By variational analysis, it is proved under two conditions with certain symmetry that both of the two equilibrium problems can be reduced to solving systems of finite-dimensional projection equations with integral constraints by iterative computational methods. Crucially, the two conditions with certain symmetry, ensuring the uniqueness of the NNE and the MNE, provide theoretical foundations for strategic decision making regarding competitive versus cooperative market behaviors. Finally, the theoretical framework is validated through numerical simulations demonstrating the efficacy of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07623v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhun Gou, Nan-Jing Huang, Jian-Hao Kang, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Optimization of a Nonlinear Acoustics -- Structure Interaction Model</title>
      <link>https://arxiv.org/abs/2508.07728</link>
      <description>arXiv:2508.07728v1 Announce Type: new 
Abstract: In this paper, we consider a control/shape optimization problem of a nonlinear acoustics-structure interaction model of PDEs, whereby acoustic wave propagation in a chamber is governed by the Westervelt equation, and the motion of the elastic part of the boundary is governed by a 4th order Kirchoff equation. We consider a quadratic objective functional capturing the tracking of prescribed desired states, with three types of controls: 1) An excitation control represented by prescribed Neumann data for the pressure on the excitation part of the boundary 2) A mechanical control represented by a forcing function in the Kirchoff equations and 3) Shape of the excitation part of the boundary represented by a graph function. Our main result is the existence of solutions to the minimization problem, and the characterization of the optimal states through an adjoint system of PDEs derived from the first-order optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07728v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Barbara Kaltenbacher, Amjad Tuffaha</dc:creator>
    </item>
    <item>
      <title>Anderson Accelerated Primal-Dual Hybrid Gradient for solving LP</title>
      <link>https://arxiv.org/abs/2508.08062</link>
      <description>arXiv:2508.08062v1 Announce Type: new 
Abstract: We present the Anderson Accelerated Primal-Dual Hybrid Gradient (AA-PDHG), a fixed-point-based framework designed to overcome the slow convergence of the standard PDHG method for the solution of linear programming (LP) problems. We establish the global convergence of AA-PDHG under a safeguard condition. In addition, we propose a filtered variant (FAA-PDHG) that applies angle and length filtering to preserve the uniform boundedness of the coefficient matrix, a property crucial for guaranteeing convergence. Numerical results show that both AA-PDHG and FAA-PDHG deliver significant speedups over vanilla PDHG for large-scale LP instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08062v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingxin Zhou, Stefano Cipolla, Phan Tu Vuong</dc:creator>
    </item>
    <item>
      <title>Optimal Dividend, Reinsurance, and Capital Injection Strategies for an Insurer with Two Collaborating Business Lines</title>
      <link>https://arxiv.org/abs/2508.08130</link>
      <description>arXiv:2508.08130v1 Announce Type: new 
Abstract: This paper considers an insurer with two collaborating business lines, and the risk exposure of each line follows a diffusion risk model. The manager of the insurer makes three decisions for each line: (i) dividend payout, (ii) (proportional) reinsurance coverage, and (iii) capital injection (from one line into the other). The manager seeks an optimal dividend, reinsurance, and capital injection strategy to maximize the expected weighted sum of the total dividend payments until the first ruin. We completely solve this problem and obtain the value function and optimal strategies in closed form. We show that the optimal dividend strategy is a threshold strategy, and the more important line always has a lower threshold to pay dividends. The optimal proportion of risk ceded to the reinsurer is decreasing with respect to the aggregate reserve level for each line, and capital injection is only used to prevent the ruin of a business line. Finally, numerical examples are presented to illustrate the impact of model parameters on the optimal strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08130v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim J. Boonen, Engel John C. Dela Vega, Bin Zou</dc:creator>
    </item>
    <item>
      <title>An efficient branch-and-cut approach for the sequential competitive facility location problem under partially binary rule</title>
      <link>https://arxiv.org/abs/2508.08135</link>
      <description>arXiv:2508.08135v1 Announce Type: new 
Abstract: We investigate the sequential competitive facility location problem (SCFLP) under partially binary rule where two companies sequentially open a limited number of facilities to maximize their market shares, requiring customers to patronize, for each company, the facility with the highest utility. The SCFLP is a bilevel mixed integer nonlinear programming (MINLP) problem and can be rewritten as a single-level MINLP problem, where each nonlinear constraint corresponds to a hypograph of a multiple ratio function characterizing the leader's market share for a fixed follower's location choice. To address the challenge arising in the poor linear programming (LP) relaxation of the underlying formulation, we develop two new mixed integer linear programming (MILP) formulations for the SCFLP as well as efficient B&amp;C algorithms based on them. The first MILP formulation is based on a class of improved submodular inequalities, which include the classic submodular inequalities as special cases, and are able to characterize the convex hull of the mixed 0-1 set. The second one is an extended formulation of the first one that provides the same LP relaxation bound. We also develop efficient algorithms for the separations of the exponential families of the inequalities arising in the MILP formulations. By extensive computational experiments, we demonstrate that the proposed B&amp;C algorithms significantly outperform an adapted state-of-the-art B&amp;C algorithm and a sophisticated heuristic algorithm in the literature. Moreover, the proposed B&amp;C algorithms are capable of finding optimal solutions for SCFLP instances with up to 1000 customers and facilities within a time limit of two hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08135v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Qi Guo, Yan-Ru Wang, Wei-Kun Chen, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>A Distributed Asynchronous Generalized Momentum Algorithm Without Delay Bounds</title>
      <link>https://arxiv.org/abs/2508.08218</link>
      <description>arXiv:2508.08218v1 Announce Type: new 
Abstract: Asynchronous optimization algorithms often require delay bounds to prove their convergence, though these bounds can be difficult to obtain in practice. Existing algorithms that do not require delay bounds often converge slowly. Therefore, we introduce a novel distributed generalized momentum algorithm that provides fast convergence and allows arbitrary delays. It subsumes Nesterov's accelerated gradient algorithm and the heavy ball algorithm, among others. We first develop conditions on the parameters of this algorithm that ensure asymptotic convergence. Then we show its convergence rate is linear in a function of the number of computations and communications that processors perform (in a way that we make precise). Simulations compare this algorithm to gradient descent, heavy ball, and Nesterov's accelerated gradient algorithm with a classification problem on the Fashion-MNIST dataset. Across a range of scenarios with unbounded delays, convergence of the generalized momentum algorithm requires at least 71% fewer iterations than gradient descent, 41% fewer iterations than the heavy ball algorithm, and 19% fewer iterations that Nesterov's accelerated gradient algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08218v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ellie Pond, Yichen Zhao, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems</title>
      <link>https://arxiv.org/abs/2508.06539</link>
      <description>arXiv:2508.06539v1 Announce Type: cross 
Abstract: Survival is traditionally modeled as a supervised learning task, reliant on curated outcome labels and fixed covariates. This work rejects that premise. It proposes that survival is not an externally annotated target but a geometric consequence: an emergent property of the curvature and flow inherent in biological state space. We develop a theory of Self-Organizing Survival Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature geodesic flows on latent manifolds shaped by internal biological constraints. A survival energy functional based on geodesic curvature minimization is introduced and shown to induce structures where prognosis aligns with geometric flow stability. We derive discrete and continuous formulations of the objective and prove theoretical results demonstrating the emergence and convergence of survival-aligned trajectories under biologically plausible conditions. The framework draws connections to thermodynamic efficiency, entropy flow, Ricci curvature, and optimal transport, grounding survival modeling in physical law. Health, disease, aging, and death are reframed as geometric phase transitions in the manifold's structure. This theory offers a universal, label-free foundation for modeling survival as a property of form, not annotation-bridging machine learning, biophysics, and the geometry of life itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06539v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Atahan Karagoz</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications</title>
      <link>https://arxiv.org/abs/2508.07473</link>
      <description>arXiv:2508.07473v1 Announce Type: cross 
Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a finite variance, many algorithms provably work and guarantee a sublinear regret. However, limited results are known if the gradient estimate has a heavy tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this work examines different old algorithms for OCO (e.g., Online Gradient Descent) in the more challenging heavy-tailed setting. Under the standard bounded domain assumption, we establish new regrets for these classical methods without any algorithmic modification. Remarkably, these regret bounds are fully optimal in all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting that OCO with heavy tails can be solved effectively without any extra operation (e.g., gradient clipping). Our new results have several applications. A particularly interesting one is the first provable convergence result for nonsmooth nonconvex optimization under heavy-tailed noise without gradient clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and extend our ideas to optimistic algorithms to handle different cases simultaneously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07473v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu</dc:creator>
    </item>
    <item>
      <title>Embedding Sustainability in Undergraduate Mathematics with Actionable Case Studies</title>
      <link>https://arxiv.org/abs/2508.07594</link>
      <description>arXiv:2508.07594v1 Announce Type: cross 
Abstract: There is a growing need to integrate sustainability into tertiary mathematics education given the urgency of addressing global environmental challenges. This paper presents four case studies from Australian university courses that incorporate ecological and environmentally-conscious concepts into the mathematics curriculum. These case studies cover topics such as population dynamics, sustainable fisheries management, statistical inference for endangered species assessment, and mathematical modelling of climate effects on marine ecosystems. Each case demonstrates how fundamental mathematical methods, including calculus, statistics and operations research, can be applied to real-world ecological issues. These examples are ready-to-implement problems for integrating ecological thinking into mathematics classes, providing educators with practical tools to help students develop interdisciplinary problem-solving skills and prepare for the challenges of sustainability in their future careers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07594v1</guid>
      <category>q-bio.PE</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Kleshnina, Matthew Holden, Ryan Heneghan, Kate Helmstedt</dc:creator>
    </item>
    <item>
      <title>Age of Information Minimization in Goal-Oriented Communication with Processing and Cost of Actuation Error Constraints</title>
      <link>https://arxiv.org/abs/2508.07865</link>
      <description>arXiv:2508.07865v1 Announce Type: cross 
Abstract: We study a goal-oriented communication system in which a source monitors an environment that evolves as a discrete-time, two-state Markov chain. At each time slot, a controller decides whether to sample the environment and if so whether to transmit a raw or processed sample, to the controller. Processing improves transmission reliability over an unreliable wireless channel, but incurs an additional cost. The objective is to minimize the long-term average age of information (AoI), subject to constraints on the costs incurred at the source and the cost of actuation error (CAE), a semantic metric that assigns different penalties to different actuation errors. Although reducing AoI can potentially help reduce CAE, optimizing AoI alone is insufficient, as it overlooks the evolution of the underlying process. For instance, faster source dynamics lead to higher CAE for the same average AoI, and different AoI trajectories can result in markedly different CAE under identical average AoI. To address this, we propose a stationary randomized policy that achieves an average AoI within a bounded multiplicative factor of the optimal among all feasible policies. Extensive numerical experiments are conducted to characterize system behavior under a range of parameters. These results offer insights into the feasibility of the optimization problem, the structure of near-optimal actions, and the fundamental trade-offs between AoI, CAE, and the costs involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07865v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rishabh S. Pomaje, Jayanth S., Rajshekhar V. Bhat, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation for Two-Timescale Linear Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2508.07928</link>
      <description>arXiv:2508.07928v1 Announce Type: cross 
Abstract: In this paper, we establish non-asymptotic bounds for accuracy of normal approximation for linear two-timescale stochastic approximation (TTSA) algorithms driven by martingale difference or Markov noise. Focusing on both the last iterate and Polyak-Ruppert averaging regimes, we derive bounds for normal approximation in terms of the convex distance between probability distributions. Our analysis reveals a non-trivial interaction between the fast and slow timescales: the normal approximation rate for the last iterate improves as the timescale separation increases, while it decreases in the Polyak-Ruppert averaged setting. We also provide the high-order moment bounds for the error of linear TTSA algorithm, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07928v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bogdan Butyrin, Artemy Rubtsov, Alexey Naumov, Vladimir Ulyanov, Sergey Samsonov</dc:creator>
    </item>
    <item>
      <title>Optimal Fees for Liquidity Provision in Automated Market Makers</title>
      <link>https://arxiv.org/abs/2508.08152</link>
      <description>arXiv:2508.08152v1 Announce Type: cross 
Abstract: Passive liquidity providers (LPs) in automated market makers (AMMs) face losses due to adverse selection (LVR), which static trading fees often fail to offset in practice. We study the key determinants of LP profitability in a dynamic reduced-form model where an AMM operates in parallel with a centralized exchange (CEX), traders route their orders optimally to the venue offering the better price, and arbitrageurs exploit price discrepancies. Using large-scale simulations and real market data, we analyze how LP profits vary with market conditions such as volatility and trading volume, and characterize the optimal AMM fee as a function of these conditions. We highlight the mechanisms driving these relationships through extensive comparative statics, and confirm the model's relevance through market data calibration. A key trade-off emerges: fees must be low enough to attract volume, yet high enough to earn sufficient revenues and mitigate arbitrage losses. We find that under normal market conditions, the optimal AMM fee is competitive with the trading cost on the CEX and remarkably stable, whereas in periods of very high volatility, a high fee protects passive LPs from severe losses. These findings suggest that a threshold-type dynamic fee schedule is both robust enough to market conditions and improves LP outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08152v1</guid>
      <category>q-fin.TR</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.EC</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven Campbell, Philippe Bergault, Jason Milionis, Marcel Nutz</dc:creator>
    </item>
    <item>
      <title>Robust Adaptive Discrete-Time Control Barrier Certificate</title>
      <link>https://arxiv.org/abs/2508.08153</link>
      <description>arXiv:2508.08153v1 Announce Type: cross 
Abstract: This work develops a robust adaptive control strategy for discrete-time systems using Control Barrier Functions (CBFs) to ensure safety under parametric model uncertainty and disturbances. A key contribution of this work is establishing a barrier function certificate in discrete time for general online parameter estimation algorithms. This barrier function certificate guarantees positive invariance of the safe set despite disturbances and parametric uncertainty without access to the true system parameters. In addition, real-time implementation and inherent robustness guarantees are provided. Our approach demonstrates that, using the proposed robust adaptive CBF framework, the parameter estimation module can be designed separately from the CBF-based safety filter, simplifying the development of safe adaptive controllers for discrete-time systems. The resulting safety filter guarantees that the system remains within the safe set while adapting to model uncertainties, making it a promising strategy for real-world applications involving discrete-time safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08153v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Changrui Liu, Anil Alan, Shengling Shi, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>Time-delayed opinion dynamics with leader-follower interactions: consensus, stability, and mean-field limits</title>
      <link>https://arxiv.org/abs/2508.08157</link>
      <description>arXiv:2508.08157v1 Announce Type: cross 
Abstract: We study a time-delayed variant of the Hegselmann-Krause opinion formation model featuring a small group of leaders and a large group of non-leaders. In this model, leaders influence all agents but only interact among themselves. At the same time, non-leaders update their opinions via interactions with their peers and the leaders, with time delays accounting for communication and decision-making lags. We prove the exponential convergence to consensus of the particle system, without imposing smallness assumptions on the delay parameters. Furthermore, we analyze the mean-field limit in two regimes: (i) with a fixed number of leaders and an infinite number of non-leaders, and (ii) with both populations tending to infinity, obtaining existence, uniqueness, and exponential decay estimates for the corresponding macroscopic models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08157v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young-Pil Choi, Chiara Cicolani, Cristina Pignotti</dc:creator>
    </item>
    <item>
      <title>Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers</title>
      <link>https://arxiv.org/abs/2508.08206</link>
      <description>arXiv:2508.08206v1 Announce Type: cross 
Abstract: We propose a joint learning framework for Byzantine-resilient spectrum sensing and secure intelligent reflecting surface (IRS)--assisted opportunistic access under channel state information (CSI) uncertainty. The sensing stage performs logit-domain Bayesian updates with trimmed aggregation and attention-weighted consensus, and the base station (BS) fuses network beliefs with a conservative minimum rule, preserving detection accuracy under a bounded number of Byzantine users. Conditioned on the sensing outcome, we pose downlink design as sum mean-squared error (MSE) minimization under transmit-power and signal-leakage constraints and jointly optimize the BS precoder, IRS phase shifts, and user equalizers. With partial (or known) CSI, we develop an augmented-Lagrangian alternating algorithm with projected updates and provide provable sublinear convergence, with accelerated rates under mild local curvature. With unknown CSI, we perform constrained Bayesian optimization (BO) in a geometry-aware low-dimensional latent space using Gaussian process (GP) surrogates; we prove regret bounds for a constrained upper confidence bound (UCB) variant of the BO module, and demonstrate strong empirical performance of the implemented procedure. Simulations across diverse network conditions show higher detection probability at fixed false-alarm rate under adversarial attacks, large reductions in sum MSE for honest users, strong suppression of eavesdropper signal power, and fast convergence. The framework offers a practical path to secure opportunistic communication that adapts to CSI availability while coherently coordinating sensing and transmission through joint learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08206v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirhossein Taherpour, Abbas Taherpour, Tamer Khattab</dc:creator>
    </item>
    <item>
      <title>On the attainability of singular Wiener bound</title>
      <link>https://arxiv.org/abs/2508.08208</link>
      <description>arXiv:2508.08208v1 Announce Type: cross 
Abstract: We characterize the lower and upper attainability of the Wiener bound (also known as Voigt-Reuss bound) for singularly distributed conductive material mixtures. For the lower attainability we consider mixtures in which high-conductance materials support on sets having finite one-dimensional Hausdorff measures. We show that, under a mild coercivity condition, the kernel of the effective tensor of the mixture is equal to the orthogonal complement of the homotopy classes of closed paths in the supporting set. This shows that a periodic planar network has positive definite effective tensor, i.e., it is resilient to fluctuations, if and only if the network is reticulate. We provide a geometric characterization of the upper attainability by applying a transformation from varifolds to matrix-valued measures. We show that this transformation leads to an equivalence between two distinct notions from material science and geometric measure theory respectively: conductance maximality and area criticality. Based on this relation we show a pointwise dimension bound for mixtures that attain the upper Wiener bound by applying a fractional version of the monotonicity formula for stationary varifolds. This dimension bound illustrates how the maximality condition constrains the local anisotropy and the local distribution of conductance magnitudes. Both the lower and upper attainability results have potential novel applications in modeling leaf venation patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08208v1</guid>
      <category>math.AP</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhonggan Huang</dc:creator>
    </item>
    <item>
      <title>Autonomous Air-Ground Vehicle Operations Optimization in Hazardous Environments: A Multi-Armed Bandit Approach</title>
      <link>https://arxiv.org/abs/2508.08217</link>
      <description>arXiv:2508.08217v1 Announce Type: cross 
Abstract: Hazardous environments such as chemical spills, radiological zones, and bio-contaminated sites pose significant threats to human safety and public infrastructure. Rapid and reliable hazard mitigation in these settings often unsafe for humans, calling for autonomous systems that can adaptively sense and respond to evolving risks. This paper presents a decision-making framework for autonomous vehicle dispatch in hazardous environments with uncertain and evolving risk levels. The system integrates a Bayesian Upper Confidence Bound (BUCB) sensing strategy with task-specific vehicle routing problems with profits (VRPP), enabling adaptive coordination of unmanned aerial vehicles (UAVs) for hazard sensing and unmanned ground vehicles (UGVs) for cleaning. Using VRPP allows selective site visits under resource constraints by assigning each site a visit value that reflects sensing or cleaning priorities. Site-level hazard beliefs are maintained through a time-weighted Bayesian update. BUCB scores guide UAV routing to balance exploration and exploitation under uncertainty, while UGV routes are optimized to maximize expected hazard reduction under resource constraints. Simulation results demonstrate that our framework reduces the number of dispatch cycles to resolve hazards by around 30% on average compared to baseline dispatch strategies, underscoring the value of uncertainty-aware vehicle dispatch for reliable hazard mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08217v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimin Choi, Max Z. Li</dc:creator>
    </item>
    <item>
      <title>Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent</title>
      <link>https://arxiv.org/abs/2508.08222</link>
      <description>arXiv:2508.08222v1 Announce Type: cross 
Abstract: Transformers have demonstrated remarkable capabilities in multi-step reasoning tasks. However, understandings of the underlying mechanisms by which they acquire these abilities through training remain limited, particularly from a theoretical standpoint. This work investigates how transformers learn to solve symbolic multi-step reasoning problems through chain-of-thought processes, focusing on path-finding in trees. We analyze two intertwined tasks: a backward reasoning task, where the model outputs a path from a goal node to the root, and a more complex forward reasoning task, where the model implements two-stage reasoning by first identifying the goal-to-root path and then reversing it to produce the root-to-goal path. Our theoretical analysis, grounded in the dynamics of gradient descent, shows that trained one-layer transformers can provably solve both tasks with generalization guarantees to unseen trees. In particular, our multi-phase training dynamics for forward reasoning elucidate how different attention heads learn to specialize and coordinate autonomously to solve the two subtasks in a single autoregressive path. These results provide a mechanistic explanation of how trained transformers can implement sequential algorithmic procedures. Moreover, they offer insights into the emergence of reasoning abilities, suggesting that when tasks are structured to take intermediate chain-of-thought steps, even shallow multi-head transformers can effectively solve problems that would otherwise require deeper architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08222v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Yang, Yu Huang, Yingbin Liang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Methods for Geodesically Convex Optimization: Tractable Algorithms and Convergence Analysis</title>
      <link>https://arxiv.org/abs/2202.02036</link>
      <description>arXiv:2202.02036v2 Announce Type: replace 
Abstract: We propose computationally tractable accelerated first-order methods for Riemannian optimization, extending the Nesterov accelerated gradient (NAG) method. For both geodesically convex and geodesically strongly convex objective functions, our algorithms are shown to have the same iteration complexities as those for the NAG method on Euclidean spaces, under only standard assumptions. To the best of our knowledge, the proposed scheme is the first fully accelerated method for geodesically convex optimization problems. Our convergence analysis makes use of novel metric distortion lemmas as well as carefully designed potential functions. A connection with the continuous-time dynamics for modeling Riemannian acceleration in (Alimisis et al., 2020) is also identified by letting the stepsize tend to zero. We validate our theoretical results through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.02036v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jungbin Kim, Insoon Yang</dc:creator>
    </item>
    <item>
      <title>Online Learning and Optimization for Queues with Unknown Demand Curve and Service Distribution</title>
      <link>https://arxiv.org/abs/2303.03399</link>
      <description>arXiv:2303.03399v2 Announce Type: replace 
Abstract: We investigate an optimization problem in a queueing system where the service provider selects the optimal service fee p and service capacity \mu to maximize the cumulative expected profit (the service revenue minus the capacity cost and delay penalty). The conventional predict-then-optimize (PTO) approach takes two steps: first, it estimates the model parameters (e.g., arrival rate and service-time distribution) from data; second, it optimizes a model based on the estimated parameters. A major drawback of PTO is that its solution accuracy can often be highly sensitive to the parameter estimation errors because PTO is unable to properly link these errors (step 1) to the quality of the optimized solutions (step 2). To remedy this issue, we develop an online learning framework that automatically incorporates the aforementioned parameter estimation errors in the solution prescription process; it is an integrated method that can "learn" the optimal solution without needing to set up the parameter estimation as a separate step as in PTO. Effectiveness of our online learning approach is substantiated by (i) theoretical results including the algorithm convergence and analysis of the regret ("cost" to pay over time for the algorithm to learn the optimal policy), and (ii) engineering confirmation via simulation experiments of a variety of representative examples. We also provide careful comparisons for PTO and the online learning method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03399v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyun Chen, Guiyu Hong, Yunan Liu</dc:creator>
    </item>
    <item>
      <title>Stabilized SQP Methods in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2312.14801</link>
      <description>arXiv:2312.14801v2 Announce Type: replace 
Abstract: Based on techniques by (S.J. Wright 1998) for finite-dimensional optimization, we investigate a stabilized sequential quadratic programming method for nonlinear optimization problems in infinite-dimensional Hilbert spaces. The method is shown to achieve fast local convergence even in the absence of a constraint qualification, generalizing the results obtained by (S.J. Wright 1998 and W.W. Hager 1999) in finite dimensions to this broader setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14801v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrian Uihlein, Winnifried Wollner</dc:creator>
    </item>
    <item>
      <title>Hilbert Space-Valued LQ Mean Field Games: An Infinite-Dimensional Analysis</title>
      <link>https://arxiv.org/abs/2403.01012</link>
      <description>arXiv:2403.01012v5 Announce Type: replace 
Abstract: This paper presents a comprehensive study of linear-quadratic (LQ) mean field games (MFGs) in Hilbert spaces, generalizing the classic LQ MFG theory to scenarios involving $N$ agents with dynamics governed by infinite-dimensional stochastic equations. In this framework, both state and control processes of each agent take values in separable Hilbert spaces. All agents are coupled through the average state of the population which appears in their linear dynamics and quadratic cost functional. Specifically, the dynamics of each agent incorporates an infinite-dimensional noise, namely a $Q$-Wiener process, and an unbounded operator. The diffusion coefficient of each agent is stochastic involving the state, control, and average state processes. We first study the well-posedness of a system of $N$ coupled semilinear infinite-dimensional stochastic evolution equations establishing the foundation of MFGs in Hilbert spaces. We then specialize to $N$-player LQ games described above and study the asymptotic behaviour as the number of agents, $N$, approaches infinity. We develop an infinite-dimensional variant of the Nash Certainty Equivalence principle and characterize a unique Nash equilibrium for the limiting MFG. Finally, we study the connections between the $N$-player game and the limiting MFG, demonstrating that the empirical average state converges to the mean field and that the resulting limiting best-response strategies form an $\epsilon$-Nash equilibrium for the $N$-player game in Hilbert spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01012v5</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanchao Liu, Dena Firoozi</dc:creator>
    </item>
    <item>
      <title>Learning to Optimally Stop Diffusion Processes, with Financial Applications</title>
      <link>https://arxiv.org/abs/2408.09242</link>
      <description>arXiv:2408.09242v3 Announce Type: replace 
Abstract: We study optimal stopping for diffusion processes with unknown model primitives within the continuous-time reinforcement learning (RL) framework developed by Wang et al. (2020), and present applications to option pricing and portfolio choice. By penalizing the corresponding variational inequality formulation, we transform the stopping problem into a stochastic optimal control problem with two actions. We then randomize controls into Bernoulli distributions and add an entropy regularizer to encourage exploration. We derive a semi-analytical optimal Bernoulli distribution, based on which we devise RL algorithms using the martingale approach established in Jia and Zhou (2022a). We establish a policy improvement theorem and prove the fast convergence of the resulting policy iterations. We demonstrate the effectiveness of the algorithms in pricing finite-horizon American put options, solving Merton's problem with transaction costs, and scaling to high-dimensional optimal stopping problems. In particular, we show that both the offline and online algorithms achieve high accuracy in learning the value functions and characterizing the associated free boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09242v3</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min Dai, Yu Sun, Zuo Quan Xu, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>On the inadequacy of nudging data assimilation algorithms for non-dissipative systems</title>
      <link>https://arxiv.org/abs/2411.08273</link>
      <description>arXiv:2411.08273v2 Announce Type: replace 
Abstract: In this work, we study the applicability of the Azouani-Olson-Titi (AOT) nudging algorithm for continuous data assimilation to evolutionary dynamical systems that are not dissipative. Specifically, we apply the AOT algorithm a partially dissipative variant of the Lorenz 1963 system, the Korteweg-de Vries (KdV) in 1D, and the 2D incompressible Euler equations. Our analysis reveals that both the Euler and KdV equations lack the finitely many determining modes property, leading to the construction of infinitely many solutions with exactly the same sparse observational data, which data assimilation methods cannot distinguish between. Simultaneously, we numerically verify that the AOT algorithm successfully recovers these counterexamples for the damped and driven KdV equation, which is dissipative. Additionally, to further support our argument, we present numerical evidence showing that the AOT algorithm is ineffective at accurately recovering solutions for a partially dissipative variant of the Lorenz 1963 system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08273v2</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edriss S. Titi, Collin Victor</dc:creator>
    </item>
    <item>
      <title>Multi-View Clustering Meets Heterogenous Data: A Fusion Regularized Method</title>
      <link>https://arxiv.org/abs/2501.10972</link>
      <description>arXiv:2501.10972v2 Announce Type: replace 
Abstract: Multi-view clustering leverages consistent and complementary information across multiple views to provide more comprehensive insights than single-view analysis. However, the heterogeneity and redundancy of multi-view data pose significant challenges to the existing clustering techniques. To tackle these challenges effectively, this paper proposes a novel multi-view fusion regularized clustering method with adaptive group sparsity, enabling discriminative clustering while capturing informative features. Technically, for heterogeneous multi-view data with mixed-type feature sets, different losses or divergence metrics are considered with a joint fusion penalty to obtain consistent cluster structures. Moreover, the non-convex group sparsity consisting of inter-group sparsity and intra-group sparsity is utilized to eliminate redundant features, thereby enhancing the robustness. Furthermore, we develop an effective alternating direction method of multipliers (ADMM), where all subproblems can be solved in closed form. Extensive numerical experiments on real data validate the superior performance of our presented method in clustering accuracy and feature selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10972v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangru Xing, Yan Li, Xin Wang, Huangyue Chen, Xianchao Xiu</dc:creator>
    </item>
    <item>
      <title>Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square</title>
      <link>https://arxiv.org/abs/2501.16690</link>
      <description>arXiv:2501.16690v2 Announce Type: replace 
Abstract: Consider a decentralized partially-observed Markov decision problem (POMDP) with multiple cooperative agents aiming to maximize a long-term-average reward criterion. We observe that the availability, at a fixed rate, of entangled states of a product quantum system between the agents, where each agent has access to one of the component systems, can result in strictly improved performance even compared to the scenario where common randomness is provided to the agents, i.e. there is a quantum advantage in decentralized control. This observation comes from a simple reinterpretation of the conclusions of the well-known Mermin-Peres square, which underpins the Mermin-Peres game. While quantum advantage has been demonstrated earlier in one-shot team problems of this kind, it is notable that there are examples where there is a quantum advantage for the one-shot criterion but it disappears in the dynamical scenario. The presence of a quantum advantage in dynamical scenarios is thus seen to be a novel finding relative to the current state of knowledge about the achievable performance in decentralized control problems.
  This paper is dedicated to the memory of Pravin P. Varaiya.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16690v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Venkat Anantharam</dc:creator>
    </item>
    <item>
      <title>Sequential Quadratic Optimization for Solving Expectation Equality Constrained Stochastic Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.09490</link>
      <description>arXiv:2503.09490v3 Announce Type: replace 
Abstract: A sequential quadratic programming method is designed for solving general smooth nonlinear stochastic optimization problems subject to expectation equality constraints. We consider the setting where the objective and constraint function values, as well as their derivatives, are not directly available. The algorithm applies an adaptive step size policy and only relies on objective gradient estimates, constraint function estimates, and constraint derivative estimates to update iterates. Both asymptotic and non-asymptotic convergence properties of the algorithm are analyzed. Under reasonable assumptions, the algorithm generates a sequence of iterates whose first-order stationary measure diminishes in expectation. In addition, we identify the iteration and sample complexity for obtaining a first-order $\varepsilon$-stationary iterate in expectation. The results of numerical experiments demonstrate the efficiency and efficacy of our proposed algorithm compared to a penalty method and an augmented Lagrangian method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09490v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoming Shen, Yang Zeng, Baoyu Zhou</dc:creator>
    </item>
    <item>
      <title>Structure of average distance minimizers in general dimensions</title>
      <link>https://arxiv.org/abs/2503.23256</link>
      <description>arXiv:2503.23256v3 Announce Type: replace 
Abstract: For a fixed, compactly supported probability measure $\mu$ on the $d$-dimensional space $\mathbb{R}^d$, we consider the problem of minimizing the $p^{\mathrm{th}}$-power average distance functional over all compact, connected $\Sigma \subseteq \mathbb{R}^d$ with Hausdorff 1-measure $\mathcal{H}^1(\Sigma) \leq l$. This problem, known as the average distance problem, was first studied by Buttazzo, Oudet, and Stepanov in 2002, and has undergone a considerable amount of research since. We will provide a novel approach to studying this problem by analyzing it using the so-called \textit{barycentre field} considered previously by Hayase and two of the authors. This allows us to provide a complete topological description of minimizers in arbitrary dimensions when $p = 2$ and $p &gt; \frac{1}{2}(3 + \sqrt{5}) \approx 2.618$, the first such result that includes the case when $d &gt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23256v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas O'Brien, Forest Kobayashi, Young-Heon Kim</dc:creator>
    </item>
    <item>
      <title>Mathematical programs with complementarity constraints and application to hyperparameter tuning for nonlinear support vector machines</title>
      <link>https://arxiv.org/abs/2504.13006</link>
      <description>arXiv:2504.13006v2 Announce Type: replace 
Abstract: We consider the Mathematical Program with Complementarity Constraints (MPCC). One of the main challenges in solving this problem is the systematic failure of standard Constraint Qualifications (CQs). Carefully accounting for the combinatorial nature of the complementarity constraints, tractable versions of the Mangasarian Fromovitz Constraint Qualification (MFCQ) have been designed and widely studied in the literature. This paper looks closely at two such MPCC-MFCQs and their influence on MPCC algorithms. As a key contribution, we prove the convergence of the sequential penalisation and Scholtes relaxation algorithms under a relaxed MPCC-MFCQ that is much weaker than the CQs currently used in the literature. We then form the problem of tuning hyperparameters of a nonlinear Support Vector Machine (SVM), a fundamental machine learning problem for classification, as a MPCC. For this application, we establish that the aforementioned relaxed MPCC-MFCQ holds under a very mild assumption. Moreover, we program robust implementations and comprehensive numerical experimentation on real-world data sets, where we show that the sequential penalisation method applied to the MPCC formulation for tuning SVM hyperparameters can outperform both the Scholtes relaxation technique and the state-of-the-art derivative-free methods from the machine learning literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13006v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel Ward, Alain Zemkoho, Selin Ahipasaoglu</dc:creator>
    </item>
    <item>
      <title>Markov control of continuous time Markov processes with long run functionals by time discretization</title>
      <link>https://arxiv.org/abs/2505.06916</link>
      <description>arXiv:2505.06916v2 Announce Type: replace 
Abstract: In the paper we study continuous time controlled Markov processes using discrete time controlled Markov processes. We consider long run functionals: average reward per unit time or long run risk sensitive functional. We also investigate stability of continuous time functionals with respect to pointwise convergence of Markov controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06916v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukasz Stettner</dc:creator>
    </item>
    <item>
      <title>RIDGECUT: Learning Graph Partitioning with Rings and Wedges</title>
      <link>https://arxiv.org/abs/2505.13986</link>
      <description>arXiv:2505.13986v3 Announce Type: replace 
Abstract: Reinforcement Learning (RL) has proven to be a powerful tool for combinatorial optimization (CO) problems due to its ability to learn heuristics that can generalize across problem instances. However, integrating knowledge that will steer the RL framework for CO solutions towards domain appropriate outcomes remains a challenging task. In this paper, we propose RIDGECUT, the first RL framework that constrains the action space to enforce structure-aware partitioning in the Normalized Cut problem. Using transportation networks as a motivating example, we introduce a novel concept that leverages domain knowledge about urban road topology -- where natural partitions often take the form of concentric rings and radial wedges. Our method reshapes the graph into a linear or circular structure to simplify the partitioning task so that we can apply sequential transformers and enables efficient learning via Proximal Policy Optimization. The resulting partitions are not only aligned with expected spatial layouts but also achieve lower normalized cuts compared to existing methods. While we focus on traffic data, our approach is broadly applicable and offers a mechanism for embedding structural priors into RL for graph partitioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13986v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qize Jiang, Linsey Pang, Alice Gatti, Mahima Aggarwal, Giovanna Vantini, Xiaosong Ma, Weiwei Sun, Sourav Medya, Sanjay Chawla</dc:creator>
    </item>
    <item>
      <title>Singular Perturbation in Multiscale Stochastic Control Problems with Domain Restriction in the Slow Variable</title>
      <link>https://arxiv.org/abs/2505.14987</link>
      <description>arXiv:2505.14987v2 Announce Type: replace 
Abstract: We study a multiscale stochastic optimal control problem subject to state constraints on the slow variable. To address this class of problems, we develop a rigorous theoretical framework based on singular perturbation analysis, tailored to settings with constrained dynamics. Our approach relies on the theory of viscosity solutions for degenerate Hamilton-Jacobi-Bellman equations with Neumann-type boundary conditions. We also establish the convergence of the multiscale value functions in the infinite-horizon regime. Finally, we present two illustrative examples that highlight the applicability and effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14987v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anderson O. Calixto, Bernardo Freitas Paulo da Costa, Glauco Valle</dc:creator>
    </item>
    <item>
      <title>Solving a linear program via a single unconstrained minimization</title>
      <link>https://arxiv.org/abs/2505.21232</link>
      <description>arXiv:2505.21232v2 Announce Type: replace 
Abstract: This paper proposes a novel approach for solving linear programs. We reformulate a primal-dual linear program as an unconstrained minimization of a convex and twice continuously differentiable merit function. When the optimal set of the primal-dual pair is nonempty, its optimal set is equal to the optimal set of the proposed merit function. Minimizing this merit function poses some challenges due to its Hessian being singular at some points in the domain, including the optimal solutions. We handle singular Hessians using the Newton method with Levenberg-Marquardt regularization. We show that the Newton method with Levenberg-Marquardt regularization yields global convergence to a solution of the primal-dual linear program in at most $O(\epsilon^{-3/2})$ iterations requiring only the assumption that the optimal set of the primal-dual linear program is bounded. Testing on random synthetic problems demonstrates convergence to optimal solutions to very high accuracy significantly faster than the derived worst-case bound. We further introduce a modified merit function that depends on a scalar parameter $\nu &gt; 0$, whose Hessian is nonsingular for all $\nu &gt; 0$ and which reduces exactly to the original merit function when $\nu = 0$. Based on this formulation, we propose a heuristic scheme that performs Newton steps while gradually decreasing $\nu$ toward zero. Numerical experiments indicate that this approach achieves faster convergence, particularly on higher-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21232v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adilet Otemissov, Alina Abdikarimova</dc:creator>
    </item>
    <item>
      <title>Convergence rates of regularized quasi-Newton methods without strong convexity</title>
      <link>https://arxiv.org/abs/2506.00521</link>
      <description>arXiv:2506.00521v5 Announce Type: replace 
Abstract: In this paper, we study convergence rates of the cubic regularized proximal quasi-Newton method (\csr) for solving non-smooth additive composite problems that satisfy the so-called Kurdyka-\L ojasiewicz (K\L ) property with respect to some desingularization function $\phi$ rather than strong convexity. After a number of iterations $k_0$, Cubic SR1 PQN exhibits non-asymptotic explicit super-linear convergence rates for any $k\geq k_0$. In particular, when $\phi(t)=ct^{1/2}$, Cubic SR1 PQN has a convergence rate of order $\left(\frac{C}{(k-k_0)^{1/2}}\right)^{(k-k_0)/2}$, where $k$ is the number of iterations and $C&gt;0$ is a constant. For the special case, i.e. functions which satisfy \L ojasiewicz inequality, the rate becomes global and non-asymptotic. This work presents, for the first time, non-asymptotic explicit convergence rates of regularized (proximal) SR1 quasi-Newton methods applied to non-convex non-smooth problems with K\L\ property. Actually, the rates are novel even in the smooth non-convex case. Notably, we achieve this without employing line search or trust region strategies, without assuming the Dennis-Mor\'e condition, without any assumptions on quasi-Newton metrics and without assuming strong convexity. Furthermore, for convex problems, we focus on a more tractable gradient regularized quasi-Newton method (Grad SR1 PQN) which can achieve results similar to those obtained with cubic regularization. We also demonstrate, for the first time, the non-asymptotic super-linear convergence rate of Grad SR1 PQN for solving convex problems with the help of the \L ojasiewicz inequality instead of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00521v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Distributed Retraction-Free and Communication-Efficient Optimization on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2506.02879</link>
      <description>arXiv:2506.02879v2 Announce Type: replace 
Abstract: Optimization problems on the Stiefel manifold, ranging from principal component analysis to enhancing neural network robustness, are ubiquitous in machine learning. The Landing algorithm avoids computationally expensive retraction operations on manifolds, making it highly competitive for large-scale problems. This paper extends this method to distributed settings, introducing *EF-Landing*, the first retraction-free and communication-efficient algorithm for distributed stochastic optimization on the Stiefel manifold. By incorporating communication compression and error feedback, EF-Landing ensures convergence and constraint feasibility while significantly reducing communication overhead. We provide sharp convergence guarantees, demonstrating that EF-Landing achieves the same asymptotic linear speedup convergence rate as existing methods without communication compression. Furthermore, our analysis is highly versatile, applying to both deterministic and stochastic settings and encompassing algorithms based on gradient descent or momentum-based gradient descent. We also generalize EF-Landing to operate on block-wise Stiefel manifolds, enabling greater flexibility for structured constraints. Extensive numerical experiments validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02879v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilong Song, Peijin Li, Bin Gao, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions</title>
      <link>https://arxiv.org/abs/2506.22568</link>
      <description>arXiv:2506.22568v3 Announce Type: replace 
Abstract: Multi-objective optimization problems (MOPs) often require a trade-off between conflicting objectives, maximizing diversity and convergence in the objective space. This study presents an approach to improve the quality of MOP solutions by optimizing the dispersion in the decision space and the convergence in a specific region of the objective space. Our approach defines a Region of Interest (ROI) based on a cone representing the decision maker's preferences in the objective space, while enhancing the dispersion of solutions in the decision space using a uniformity measure. Combining solution concentration in the objective space with dispersion in the decision space intensifies the search for Pareto-optimal solutions while increasing solution diversity. When combined, these characteristics improve the quality of solutions and avoid the bias caused by clustering solutions in a specific region of the decision space. Preliminary experiments suggest that this method enhances multi-objective optimization by generating solutions that effectively balance dispersion and concentration, thereby mitigating bias in the decision space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22568v3</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gladston Moreira, Ivan Meneghini, Elizabeth Wanner</dc:creator>
    </item>
    <item>
      <title>A Bi-Objective Mathematical Model for the Multi-Skilled Resource-Constrained Project Scheduling Problem Considering Reliability: An AUGMECON2VIKOR Hybrid Method</title>
      <link>https://arxiv.org/abs/2507.21436</link>
      <description>arXiv:2507.21436v2 Announce Type: replace 
Abstract: In recent years, resources with multiple skills have received attention as an extension of the resource-constrained project scheduling problem known as MSRCPSP. Although the disruption rate is well-estimated in today's manufacturing projects, its impact on project makespan and cost need further investigation. Hence, this study presents a novel mathematical model for the MSRCPSP considering reliability, namely MSRCPSPR. The model proposes both objectives of minimizing project makespan and project cost. The MSRCPSP is an NP-hard problem, and including reliability constraints, as proposed in this paper, makes solving the problem more intractable. To cope with the computational challenges of solving the problem, a combination of an enhanced version of the epsilon-constraint method as well as an augmented version of the VIKOR algorithm, namely AUGMECON2VIKOR, is employed to solve benchmark instances j10 and j20 from the PSPLIB. A comparative analysis demonstrates the performance of the proposed method, and the sensitivity analysis represents the effects of positive reliable constraints on the objective functions. Employing the proposed method, the project makespan and cost are reduced by nearly 2.55% and 2.80% in j10 on average. CPU time is also decreased by about 543 seconds in comparison to the epsilon-constraint method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21436v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Ghasemi, Asef Nazari, Dhananjay Thiruvady, Reza Tavakkoli-Moghaddam, Reza Shahabi-Shahmiri, Seyed-Ali Mirnezami</dc:creator>
    </item>
    <item>
      <title>Many-Server Asymptotics for Join-the-Shortest-Queue: Large Deviations and Rare Events</title>
      <link>https://arxiv.org/abs/1904.04938</link>
      <description>arXiv:1904.04938v3 Announce Type: replace-cross 
Abstract: The Join-the-Shortest-Queue routing policy is studied in an asymptotic regime where the number of processors $n$ scales with the arrival rate. A large deviation principle (LDP) for the occupancy process is established, as $n\to \infty$, in a suitable infinite-dimensional path space. Model features that present technical challenges include, Markovian dynamics with discontinuous statistics, a diminishing rate property of the transition probability rates, and an infinite-dimensional state space. The difficulty is in the proof of the Laplace lower bound which requires establishing the uniqueness of solutions of certain infinite-dimensional systems of controlled ordinary differential equations. The LDP gives information on the rate of decay of probabilities of various types of rare events associated with the system. We illustrate this by establishing explicit exponential decay rates for probabilities of long queues. In particular, denoting by $E_j^n(T)$ the event that there is at least one queue with $j$ or more jobs at some time instant over $[0,T]$, we show that, in the critical case, for large $n$ and $T$, $\mathbb{P}(E^n_j(T)) \approx \exp\left [-\frac{n (j-2)^2}{4T}\right].$</description>
      <guid isPermaLink="false">oai:arXiv.org:1904.04938v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1214/20-AAP1650</arxiv:DOI>
      <dc:creator>Amarjit Budhiraja, Eric Friedlander, Ruoyu Wu</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Based Resource Allocator for Communication Networks with Dynamic User Utility Demands</title>
      <link>https://arxiv.org/abs/2311.04600</link>
      <description>arXiv:2311.04600v3 Announce Type: replace-cross 
Abstract: Deep learning (DL) based resource allocation (RA) has recently gained significant attention due to its performance efficiency. However, most related studies assume an ideal case where the number of users and their utility demands, e.g., data rate constraints, are fixed, and the designed DL-based RA scheme exploits a policy trained only for these fixed parameters. Consequently, computationally complex policy retraining is required whenever these parameters change. In this paper, we introduce a DL-based resource allocator (ALCOR) that allows users to adjust their utility demands freely, such as based on their application layer requirements. ALCOR employs deep neural networks (DNNs) as the policy in a time-sharing problem. The underlying optimization algorithm iteratively optimizes the on-off status of users to satisfy their utility demands in expectation. The policy performs unconstrained RA (URA) -- RA without considering user utility demands -- among active users to maximize the sum utility (SU) at each time instant. Depending on the chosen URA scheme, ALCOR can perform RA in either a centralized or distributed scenario. The derived convergence analyses provide theoretical guarantees for ALCOR's convergence, and numerical experiments corroborate its effectiveness compared to meta-learning and reinforcement learning approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04600v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2025.3592774</arxiv:DOI>
      <dc:creator>Pourya Behmandpoor, Mark Eisen, Panagiotis Patrinos, Marc Moonen</dc:creator>
    </item>
    <item>
      <title>Reward-Directed Score-Based Diffusion Models via q-Learning</title>
      <link>https://arxiv.org/abs/2409.04832</link>
      <description>arXiv:2409.04832v2 Announce Type: replace-cross 
Abstract: We propose a new reinforcement learning (RL) formulation for training continuous-time score-based diffusion models for generative AI to generate samples that maximize reward functions while keeping the generated distributions close to the unknown target data distributions. Different from most existing studies, ours does not involve any pretrained model for the unknown score functions of the noise-perturbed data distributions, nor does it attempt to learn the score functions. Instead, we formulate the problem as entropy-regularized continuous-time RL and show that the optimal stochastic policy has a Gaussian distribution with a known covariance matrix. Based on this result, we parameterize the mean of Gaussian policies and develop an actor--critic type (little) q-learning algorithm to solve the RL problem. A key ingredient in our algorithm design is to obtain noisy observations from the unknown score function via a ratio estimator. Our formulation can also be adapted to solve pure score-matching and fine-tuning pretrained models. Numerically, we show the effectiveness of our approach by comparing its performance with two state-of-the-art RL methods that fine-tune pretrained models on several generative tasks including high-dimensional image generations. Finally, we discuss extensions of our RL formulation to probability flow ODE implementation of diffusion models and to conditional diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04832v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Gao, Jiale Zha, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Mean--Variance Portfolio Selection by Continuous-Time Reinforcement Learning: Algorithms, Regret Analysis, and Empirical Study</title>
      <link>https://arxiv.org/abs/2412.16175</link>
      <description>arXiv:2412.16175v2 Announce Type: replace-cross 
Abstract: We study continuous-time mean--variance portfolio selection in markets where stock prices are diffusion processes driven by observable factors that are also diffusion processes, yet the coefficients of these processes are unknown. Based on the recently developed reinforcement learning (RL) theory for diffusion processes, we present a general data-driven RL algorithm that learns the pre-committed investment strategy directly without attempting to learn or estimate the market coefficients. For multi-stock Black--Scholes markets without factors, we further devise a baseline algorithm and prove its performance guarantee by deriving a sublinear regret bound in terms of the Sharpe ratio. For performance enhancement and practical implementation, we modify the baseline algorithm and carry out an extensive empirical study to compare its performance, in terms of a host of common metrics, with a large number of widely employed portfolio allocation strategies on S\&amp;P 500 constituents. The results demonstrate that the proposed continuous-time RL strategy is consistently among the best, especially in a volatile bear market, and decisively outperforms the model-based continuous-time counterparts by significant margins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16175v2</guid>
      <category>q-fin.PM</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang, Yanwei Jia, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Navigating Demand Uncertainty in Container Shipping: Deep Reinforcement Learning for Enabling Adaptive and Feasible Master Stowage Planning</title>
      <link>https://arxiv.org/abs/2502.12756</link>
      <description>arXiv:2502.12756v5 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) has shown promise in solving various combinatorial optimization problems. However, conventional RL faces challenges when dealing with complex, real-world constraints, especially when action space feasibility is explicit and dependent on the corresponding state or trajectory. In this work, we address stochastic sequential dynamic decision-making problems with state-dependent constraints. As a relevant and real-world case study, we focus on the master stowage planning problem in container shipping, which aims to optimize revenue and operational costs under demand uncertainty and operational constraints. We propose a deep RL framework with an encoder-decoder model and feasibility layers that satisfy convex constraints and maintain unbiased gradient flow, which embed problem instances, current solutions, and demand uncertainty to guide learning. Experiments show that our model efficiently finds adaptive, feasible solutions that generalize across varying distributions and scale to larger instances, outperforming state-of-the-art baselines in constrained RL and stochastic programming. By uniting artificial intelligence and operations research, our policy empowers humans to make adaptive, uncertainty-aware decisions for resilient and sustainable planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12756v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaike van Twiller, Yossiri Adulyasak, Erick Delage, Djordje Grbic, Rune M{\o}ller Jensen</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking Control for Antenna Pointing via Symmetric Product Approximation</title>
      <link>https://arxiv.org/abs/2502.17252</link>
      <description>arXiv:2502.17252v2 Announce Type: replace-cross 
Abstract: This paper investigates extremum seeking control for a torque-controlled antenna pointing system without direct angular measurements. We consider a two-degree-of-freedom (2-DOF) antenna system that receives an unknown signal from its environment, where the signal strength varies with the antenna orientation. It is assumed that only real-time measurements of the signal are available. We develop an extremum seeking control strategy that enables the antenna to autonomously adjust its direction to maximize the received signal strength based on the symmetric product approximation. Under suitable assumptions on the signal function, we prove local practical uniform asymptotic stability for the closed-loop system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17252v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Wang, Hashem Ashrafiuon, Sergey G. Nersesov</dc:creator>
    </item>
    <item>
      <title>Pontryagin Maximum Principle for McKean-Vlasov Stochastic Reaction-Diffusion Equations</title>
      <link>https://arxiv.org/abs/2507.16288</link>
      <description>arXiv:2507.16288v2 Announce Type: replace-cross 
Abstract: We consider the stochastic control of a semi-linear stochastic partial differential equations (SPDE) of McKean-Vlasov type. Based on a recent novel approach to the Lions derivative for Banach space valued functions, we prove the Gateaux differentiability of the control to state map and, using adjoint calculus, we derive explicit representations of the gradient of the cost functional and a Pontryagin maximum principle. On the way, we also prove a novel existence and uniqueness result for linear McKean-Vlasov backward SPDE. Furthermore, for deterministic controls, we prove the existence of optimal controls using a martingale approach and a novel compactness method. This result is complemented in the appendix with a rigorous proof of folklore results on the compactness method in the variational approach to SPDE. Our setting uses the variational approach to SPDE with monotone coefficients, allowing for a polynomial perturbation and allowing the drift and diffusion coefficients to depend on the state, the distribution of the state and the control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16288v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johan Benedikt Spille, Wilhelm Stannat</dc:creator>
    </item>
    <item>
      <title>A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model</title>
      <link>https://arxiv.org/abs/2507.22854</link>
      <description>arXiv:2507.22854v2 Announce Type: replace-cross 
Abstract: We propose novel classical and quantum online algorithms for learning finite-horizon and infinite-horizon average-reward Markov Decision Processes (MDPs). Our algorithms are based on a hybrid exploration-generative reinforcement learning (RL) model wherein the agent can, from time to time, freely interact with the environment in a generative sampling fashion, i.e., by having access to a "simulator". By employing known classical and new quantum algorithms for approximating optimal policies under a generative model within our learning algorithms, we show that it is possible to avoid several paradigms from RL like "optimism in the face of uncertainty" and "posterior sampling" and instead compute and use optimal policies directly, which yields better regret bounds compared to previous works. For finite-horizon MDPs, our quantum algorithms obtain regret bounds which only depend logarithmically on the number of time steps $T$, thus breaking the $O(\sqrt{T})$ classical barrier. This matches the time dependence of the prior quantum works of Ganguly et al. (arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other parameters like state space size $S$ and action space size $A$. For infinite-horizon MDPs, our classical and quantum bounds still maintain the $O(\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we propose a novel measure of regret for infinite-horizon MDPs with respect to which our quantum algorithms have $\operatorname{poly}\log{T}$ regret, exponentially better compared to classical algorithms. Finally, we generalise all of our results to compact state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22854v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andris Ambainis, Joao F. Doriguello, Debbie Lim</dc:creator>
    </item>
    <item>
      <title>Decision Theory For Large Scale Outlier Detection Using Aleatoric Uncertainty: With a Note on Bayesian FDR</title>
      <link>https://arxiv.org/abs/2508.01988</link>
      <description>arXiv:2508.01988v2 Announce Type: replace-cross 
Abstract: Aleatoric and Epistemic uncertainty have achieved recent attention in the literature as different sources from which uncertainty can emerge in stochastic modeling. Epistemic being intrinsic or model based notions of uncertainty, and aleatoric being the uncertainty inherent in the data. We propose a novel decision theoretic framework for outlier detection in the context of aleatoric uncertainty; in the context of Bayesian modeling. The model incorporates bayesian false discovery rate control for multiplicty adjustment, and a new generalization of Bayesian FDR is introduced. The model is applied to simulations based on temporally fluctuating outlier detection where fixing thresholds often results in poor performance due to nonstationarity, and a case study is outlined on on a novel cybersecurity detection. Cyberthreat signals are highly nonstationary; giving a credible stress test of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01988v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan Warnick</dc:creator>
    </item>
    <item>
      <title>Optimal Transfer Mechanism for Municipal Soft-Budget Constraints in Newfoundland</title>
      <link>https://arxiv.org/abs/2508.02171</link>
      <description>arXiv:2508.02171v3 Announce Type: replace-cross 
Abstract: Newfoundland and Labrador's municipalities face severe soft budget pressures due to narrow tax bases, high fixed service costs, and volatile resource revenues. We develop a Stackelberg style mechanism design model in which the province commits at t = 0 to an ex ante grant schedule and an ex post bailout rule. Municipalities privately observe their fiscal need type, choose effort, investment, and debt, and may receive bailouts when deficits exceed a statutory threshold. Under convexity and single crossing, the problem reduces to one dimensional screening and admits a tractable transfer mechanism with quadratic bailout costs and a statutory cap. The optimal ex ante rule is threshold-cap; under discretionary rescue at t = 2, it becomes threshold-linear-cap. A knife-edge inequality yields a self-consistent no bailout regime, and an explicit discount factor threshold renders hard budgets dynamically credible. We emphasize a class of monotone threshold signal rules; under this class, grant crowd out is null almost everywhere, which justifies the constant grant weight used in closed form expressions. The closed form characterization provides a policy template that maps to Newfoundland's institutions and clarifies the micro-data required for future calibration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02171v3</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinli Guo</dc:creator>
    </item>
  </channel>
</rss>
