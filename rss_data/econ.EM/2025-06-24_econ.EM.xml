<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Jun 2025 04:04:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Difference-in-Differences and Event Study Estimators</title>
      <link>https://arxiv.org/abs/2506.17729</link>
      <description>arXiv:2506.17729v1 Announce Type: new 
Abstract: This paper investigates efficient Difference-in-Differences (DiD) and Event Study (ES) estimation using short panel data sets within the heterogeneous treatment effect framework, free from parametric functional form assumptions and allowing for variation in treatment timing. We provide an equivalent characterization of the DiD potential outcome model using sequential conditional moment restrictions on observables, which shows that the DiD identification assumptions typically imply nonparametric overidentification restrictions. We derive the semiparametric efficient influence function (EIF) in closed form for DiD and ES causal parameters under commonly imposed parallel trends assumptions. The EIF is automatically Neyman orthogonal and yields the smallest variance among all asymptotically normal, regular estimators of the DiD and ES parameters. Leveraging the EIF, we propose simple-to-compute efficient estimators. Our results highlight how to optimally explore different pre-treatment periods and comparison groups to obtain the tightest (asymptotic) confidence intervals, offering practical tools for improving inference in modern DiD and ES applications even in small samples. Calibrated simulations and an empirical application demonstrate substantial precision gains of our efficient estimators in finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17729v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Pedro H. C. Sant'Anna, Haitian Xie</dc:creator>
    </item>
    <item>
      <title>An Empirical Comparison of Weak-IV-Robust Procedures in Just-Identified Models</title>
      <link>https://arxiv.org/abs/2506.18001</link>
      <description>arXiv:2506.18001v1 Announce Type: new 
Abstract: Instrumental variable (IV) regression is recognized as one of the five core methods for causal inference, as identified by Angrist and Pischke (2008). This paper compares two leading approaches to inference under weak identification for just-identified IV models: the classical Anderson-Rubin (AR) procedure and the recently popular tF method proposed by Lee et al. (2022). Using replication data from the American Economic Review (AER) and Monte Carlo simulation experiments, we evaluate the two procedures in terms of statistical significance testing and confidence interval (CI) length. Empirically, we find that the AR procedure typically offers higher power and yields shorter CIs than the tF method. Nonetheless, as noted by Lee et al. (2022), tF has a theoretical advantage in terms of expected CI length. Our findings suggest that the two procedures may be viewed as complementary tools in empirical applications involving potentially weak instruments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18001v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenze Li</dc:creator>
    </item>
    <item>
      <title>Beyond utility: incorporating eye-tracking, skin conductance and heart rate data into cognitive and econometric travel behaviour models</title>
      <link>https://arxiv.org/abs/2506.18068</link>
      <description>arXiv:2506.18068v1 Announce Type: new 
Abstract: Choice models for large-scale applications have historically relied on economic theories (e.g. utility maximisation) that establish relationships between the choices of individuals, their characteristics, and the attributes of the alternatives. In a parallel stream, choice models in cognitive psychology have focused on modelling the decision-making process, but typically in controlled scenarios. Recent research developments have attempted to bridge the modelling paradigms, with choice models that are based on psychological foundations, such as decision field theory (DFT), outperforming traditional econometric choice models for travel mode and route choice behaviour. The use of physiological data, which can provide indications about the choice-making process and mental states, opens up the opportunity to further advance the models. In particular, the use of such data to enrich 'process' parameters within a cognitive theory-driven choice model has not yet been explored. This research gap is addressed by incorporating physiological data into both econometric and DFT models for understanding decision-making in two different contexts: stated-preference responses (static) of accomodation choice and gap-acceptance decisions within a driving simulator experiment (dynamic). Results from models for the static scenarios demonstrate that both models can improve substantially through the incorporation of eye-tracking information. Results from models for the dynamic scenarios suggest that stress measurement and eye-tracking data can be linked with process parameters in DFT, resulting in larger improvements in comparison to simpler methods for incorporating this data in either DFT or econometric models. The findings provide insights into the value added by physiological data as well as the performance of different candidate modelling frameworks for integrating such data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18068v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas O. Hancock, Stephane Hess, Charisma F. Choudhury</dc:creator>
    </item>
    <item>
      <title>Poverty Targeting with Imperfect Information</title>
      <link>https://arxiv.org/abs/2506.18188</link>
      <description>arXiv:2506.18188v1 Announce Type: new 
Abstract: A key challenge for targeted antipoverty programs in developing countries is that policymakers must rely on estimated rather than observed income, which leads to substantial targeting errors. I propose a statistical decision framework in which a benevolent planner, subject to a budget constraint and equipped only with noisy income estimates, allocates cash transfers to the poorest individuals. In this setting, the commonly used plug-in rule, which allocates transfers based on point estimates, is inadmissible and uniformly dominated by a shrinkage-based alternative. Building on this result, I propose an empirical Bayes (EB) targeting rule. I show that the regret of the empirical Bayes rule converges at the same rate as that of the posterior mean estimator, despite applying a nonsmooth transformation to it. Simulations show that the EB rule delivers large improvements over the plug-in approach in an idealized setting and modest but consistent gains in a more realistic application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18188v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan C. Yamin</dc:creator>
    </item>
    <item>
      <title>100-Day Analysis of USD/IDR Exchange Rate Dynamics Around the 2025 U.S. Presidential Inauguration</title>
      <link>https://arxiv.org/abs/2506.18738</link>
      <description>arXiv:2506.18738v1 Announce Type: new 
Abstract: Using a 100-day symmetric window around the January 2025 U.S. presidential inauguration, non-parametric statistical methods with bootstrap resampling (10,000 iterations) analyze distributional properties and anomalies. Results indicate a statistically significant 3.61\% Indonesian rupiah depreciation post-inauguration, with a large effect size (Cliff's Delta $= -0.9224$, CI: $[-0.9727, -0.8571]$). Central tendency shifted markedly, yet volatility remained stable (variance ratio $= 0.9061$, $p = 0.504$). Four significant anomalies exhibiting temporal clustering are detected. These findings provide quantitative evidence of political transition effects on emerging market currencies, highlighting implications for monetary policy and currency risk management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18738v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandy H. S. Herho, Siti N. Kaban, Cahya Nugraha</dc:creator>
    </item>
    <item>
      <title>Randomization Inference of Heterogeneous Treatment Effects under Network Interference</title>
      <link>https://arxiv.org/abs/2308.00202</link>
      <description>arXiv:2308.00202v4 Announce Type: replace 
Abstract: We develop randomization-based tests for heterogeneous treatment effects in the presence of network interference. Leveraging the exposure mapping framework, we study a broad class of null hypotheses that represent various forms of constant treatment effects in networked populations. These null hypotheses, unlike the classical Fisher sharp null, are not sharp due to unknown parameters and multiple potential outcomes. Existing conditional randomization procedures either fail to control size or suffer from low statistical power in this setting. We propose a testing procedure that constructs a data-dependent focal assignment set and permits variation in focal units across focal assignments. These features complicate both estimation and inference, necessitating new technical developments. We establish the asymptotic validity of the proposed procedure under general conditions on the test statistic and characterize the asymptotic size distortion in terms of observable quantities. The procedure is applied to experimental network data and evaluated via Monte Carlo simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00202v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Julius Owusu</dc:creator>
    </item>
    <item>
      <title>Decision Theory for Treatment Choice Problems with Partial Identification</title>
      <link>https://arxiv.org/abs/2312.17623</link>
      <description>arXiv:2312.17623v3 Announce Type: replace 
Abstract: We apply classical statistical decision theory to a large class of treatment choice problems with partial identification. We show that, in a general class of problems with Gaussian likelihood, all decision rules are admissible; it is maximin-welfare optimal to ignore all data; and, for severe enough partial identification, there are infinitely many minimax-regret optimal decision rules, all of which sometimes randomize the policy recommendation. We uniquely characterize the minimax-regret optimal rule that least frequently randomizes, and show that, in some cases, it can outperform other minimax-regret optimal rules in terms of what we term profiled regret. We analyze the implications of our results in the aggregation of experimental estimates for policy adoption, extrapolation of Local Average Treatment Effects, and policy making in the presence of omitted variable bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17623v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e Luis Montiel Olea, Chen Qiu, J\"org Stoye</dc:creator>
    </item>
    <item>
      <title>Self-Normalized Inference in (Quantile, Expected Shortfall) Regressions for Time Series</title>
      <link>https://arxiv.org/abs/2502.10065</link>
      <description>arXiv:2502.10065v2 Announce Type: replace 
Abstract: This paper proposes valid inference tools, based on self-normalization, in time series expected shortfall regressions and, as a corollary, also in quantile regressions. Extant methods for such time series regressions, based on a bootstrap or direct estimation of the long-run variance, are computationally more involved, require the choice of tuning parameters and have serious size distortions when the regression errors are strongly serially dependent. In contrast, our inference tools only require estimates of the (quantile, expected shortfall) regression parameters that are computed on an expanding window, and are correctly sized as we show in simulations. Two empirical applications to stock return predictability and to Growth-at-Risk demonstrate the practical usefulness of the developed inference tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10065v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yannick Hoga, Christian Schulz</dc:creator>
    </item>
    <item>
      <title>The Risk-Neutral Equivalent Pricing of Model-Uncertainty</title>
      <link>https://arxiv.org/abs/2502.13744</link>
      <description>arXiv:2502.13744v5 Announce Type: replace-cross 
Abstract: Existing approaches to asset-pricing under model-uncertainty adapt classical utility-maximization frameworks and seek theoretical comprehensiveness. We move toward practice by considering binary model-risks and by emphasizing 'constraints' over 'preference'. This decomposes viable economic asset-pricing into that of model and non-model risks separately, leading to a unique and convenient model-risk pricing formula. Its parameter, a dynamically conserved constant of model-risk inference, allows an integrated representation of ex-ante risk-pricing and bias such that their ex-post impacts are disentangled via well-known anomalies, Momentum and Low-Risk, whose risk-reward patterns acquire a fresh significance: peak-reward reveals ex-ante risk-premia, and peak-location, bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13744v5</guid>
      <category>q-fin.MF</category>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ken Kangda Wren</dc:creator>
    </item>
  </channel>
</rss>
