<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.MF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.MF</link>
    <description>q-fin.MF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.MF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust forward investment and consumption under drift and volatility uncertainties: A randomization approach</title>
      <link>https://arxiv.org/abs/2410.01378</link>
      <description>arXiv:2410.01378v1 Announce Type: cross 
Abstract: This paper studies robust forward investment and consumption preferences and optimal strategies for a risk-averse and ambiguity-averse agent in an incomplete financial market with drift and volatility uncertainties. We focus on non-zero volatility and constant relative risk aversion (CRRA) forward preferences. Given the non-convexity of the Hamiltonian with respect to uncertain volatilities, we first construct robust randomized forward preferences through endogenous randomization in an auxiliary market. We derive the corresponding optimal and robust investment and consumption strategies. Furthermore, we show that such forward preferences and strategies, developed in the auxiliary market, remain optimal and robust in the physical market, offering a comprehensive framework for forward investment and consumption under model uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01378v1</guid>
      <category>q-fin.PM</category>
      <category>q-fin.MF</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wing Fung Chong, Gechun Liang</dc:creator>
    </item>
    <item>
      <title>Neural Term Structure of Additive Process for Option Pricing</title>
      <link>https://arxiv.org/abs/2408.01642</link>
      <description>arXiv:2408.01642v2 Announce Type: replace-cross 
Abstract: The additive process generalizes the L\'evy process by relaxing its assumption of time-homogeneous increments and hence covers a larger family of stochastic processes. Recent research in option pricing shows that modeling the underlying log price with an additive process has advantages in easier construction of the risk-neural measure, an explicit option pricing formula and characteristic function, and more flexibility to fit the implied volatility surface. Still, the challenge of calibrating an additive model arises from its time-dependent parameterization, for which one has to prescribe parametric functions for the term structure. For this, we propose the neural term structure model to utilize feedforward neural networks to represent the term structure, which alleviates the difficulty of designing parametric functions and thus attenuates the misspecification risk. Numerical studies with S\&amp;P 500 option data are conducted to evaluate the performance of the neural term structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01642v2</guid>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jimin Lin, Guixin Liu</dc:creator>
    </item>
    <item>
      <title>Exploratory Optimal Stopping: A Singular Control Formulation</title>
      <link>https://arxiv.org/abs/2408.09335</link>
      <description>arXiv:2408.09335v2 Announce Type: replace-cross 
Abstract: This paper explores continuous-time and state-space optimal stopping problems from a reinforcement learning perspective. We begin by formulating the stopping problem using randomized stopping times, where the decision maker's control is represented by the probability of stopping within a given time--specifically, a bounded, non-decreasing, c\`adl\`ag control process. To encourage exploration and facilitate learning, we introduce a regularized version of the problem by penalizing it with the cumulative residual entropy of the randomized stopping time. The regularized problem takes the form of an (n+1)-dimensional degenerate singular stochastic control with finite-fuel. We address this through the dynamic programming principle, which enables us to identify the unique optimal exploratory strategy. For the specific case of a real option problem, we derive a semi-explicit solution to the regularized problem, allowing us to assess the impact of entropy regularization and analyze the vanishing entropy limit. Finally, we propose a reinforcement learning algorithm based on policy iteration. We show both policy improvement and policy convergence results for our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09335v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.MF</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jodi Dianetti, Giorgio Ferrari, Renyuan Xu</dc:creator>
    </item>
  </channel>
</rss>
