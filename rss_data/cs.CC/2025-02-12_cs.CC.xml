<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 13:54:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Explicit Codes approaching Generalized Singleton Bound using Expanders</title>
      <link>https://arxiv.org/abs/2502.07308</link>
      <description>arXiv:2502.07308v1 Announce Type: cross 
Abstract: We construct a new family of explicit codes that are list decodable to capacity and achieve an optimal list size of $O(\frac{1}{\epsilon})$. In contrast to existing explicit constructions of codes achieving list decoding capacity, our arguments do not rely on algebraic structure but utilize simple combinatorial properties of expander graphs.
  Our construction is based on a celebrated distance amplification procedure due to Alon, Edmonds, and Luby [FOCS'95], which transforms any high-rate code into one with near-optimal rate-distance tradeoff. We generalize it to show that the same procedure can be used to transform any high-rate code into one that achieves list decoding capacity. Our proof can be interpreted as a "local-to-global" phenomenon for (a slight strengthening of) the generalized Singleton bound. Using this construction, for every $R, \epsilon \in (0,1)$ and $k \in \mathbb{N}^+$, we obtain an \emph{explicit} family of codes $\mathcal{C} \subseteq \Sigma^n$, with rate $R$ such that,
  - They achieve the $\epsilon$-relaxed generalized Singleton bound: for any $g \in \Sigma^n$ and any list $\mathcal{H}$ of at most $k$ codewords, we have, \[ \underset{h \in \mathcal{H}}{\mathbb{E}} [\Delta(g,h)] ~\geq~ \frac{|\mathcal{H}|-1}{|\mathcal{H}|} \cdot (1 - R - \epsilon). \]
  - The alphabet size is a constant depending only on $\epsilon$ and $k$.
  - They can be list decoded up to radius $\frac{k-1}{k}(1-R-\epsilon)$, in time $n^{O_{k,\epsilon}(1)}$.
  As a corollary of our result, we also obtain the first explicit construction of LDPC codes achieving list decoding capacity, and in fact arbitrarily close to the generalized Singleton bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07308v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Granha Jeronimo, Tushant Mittal, Shashank Srivastava, Madhur Tulsiani</dc:creator>
    </item>
    <item>
      <title>A forbidden subgraph study for cut problems on graphs permitting loops and multiedges</title>
      <link>https://arxiv.org/abs/2502.07769</link>
      <description>arXiv:2502.07769v1 Announce Type: cross 
Abstract: We take the recently-introduced C123-framework, for the study of (simple) graph problems restricted to inputs specified by the omission of some finite set of subgraphs, to more general graph problems possibly involving self-loops and multiedges. We study specifically the problems Partially Reflexive Stable Cut and Multigraph Matching Cut in this connection. When one forbids a single (simple) subgraph, these problems exhibit the same complexity behaviour as C123-problems, but on finite sets of forbidden subgraphs, the classification appears more complex. While Multigraph Matching Cut and Multigraph d-Cut are C123-problems, already Partially Reflexive Stable Cut fails to be. This is witnessed by forbidding as subgraphs both $C_3$ and $H_1$. Indeed, the difference of behaviour occurs only around pendant subdivisions of nets and pendant subdivisions of $H_1$. We examine this area in close detail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07769v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tala Eagling-Vose, Barnaby Martin, Daniel Paulusma, Siani Smith</dc:creator>
    </item>
    <item>
      <title>A point to set principle for finite-state dimension</title>
      <link>https://arxiv.org/abs/2208.00157</link>
      <description>arXiv:2208.00157v2 Announce Type: replace 
Abstract: Effective dimension has proven very useful in geometric measure theory through the point-to-set principle \cite{LuLu18}\ that characterizes Hausdorff dimension by relativized effective dimension. Finite-state dimension is the least demanding effectivization in this context \cite{FSD}\ that among other results can be used to characterize Borel normality \cite{BoHiVi05}.
  In this paper we prove a characterization of finite-state dimension in terms of information content of a real number at a certain precision. We then use this characterization to give a robust concept of relativized normality and prove a finite-state dimension point-to-set principle. We finish with an open question on the equidistribution properties of relativized normality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.00157v2</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elvira Mayordomo</dc:creator>
    </item>
    <item>
      <title>A Quadratic Lower Bound for Stable Roommates Solvability</title>
      <link>https://arxiv.org/abs/2502.06464</link>
      <description>arXiv:2502.06464v2 Announce Type: replace 
Abstract: In their seminal work on the Stable Marriage Problem (SM), Gale and Shapley introduced a generalization of SM referred to as the Stable Roommates Problem (SR). An instance of SR consists of a set of $2n$ agents, and each agent has preferences in the form of a ranked list of all other agents. The goal is to find a one-to-one matching between the agents that is stable in the sense that no pair of agents have a mutual incentive to deviate from the matching. Unlike the (bipartite) stable marriage problem, in SR, stable matchings need not exist. Irving devised an algorithm that finds a stable matching or reports that none exists in $O(n^2)$ time. In their influential 1989 text, Gusfield and Irving posed the question of whether $\Omega(n^2)$ time is required for SR solvability -- the task of deciding if an SR instance admits a stable matching.
  In this paper we provide an affirmative answer to Gusfield and Irving's question. We show that any (randomized) algorithm that decides SR solvability requires $\Omega(n^2)$ adaptive Boolean queries to the agents' preferences (in expectation). Our argument follows from a reduction from the communication complexity of the set disjointness function. The query lower bound implies quadratic time lower bounds for Turing machines, and memory access lower bounds for random access machines. Thus, we establish that Irving's algorithm is optimal (up to a logarithmic factor) in a very strong sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06464v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Will Rosenbaum</dc:creator>
    </item>
    <item>
      <title>Equations over Finite Monoids with Infinite Promises</title>
      <link>https://arxiv.org/abs/2502.06762</link>
      <description>arXiv:2502.06762v2 Announce Type: replace 
Abstract: Larrauri and \v{Z}ivn\'y recently established a complete complexity classification of the problem of solving a system of equations over a monoid $N$ assuming that a solution exists over a monoid $M$, where both monoids are finite and $M$ admits a homomorphism to $N$. Using the algebraic approach to promise constraint satisfaction problems, we extend their complexity classification in two directions: we obtain a complexity dichotomy in the case where arbitrary relations are added to the monoids, and we moreover allow the monoid $M$ to be finitely generated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06762v2</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alberto Larrauri, Antoine Mottet, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Vector TSP: A Traveling Salesperson Problem with Racetrack-like Acceleration Constraints</title>
      <link>https://arxiv.org/abs/2006.03666</link>
      <description>arXiv:2006.03666v5 Announce Type: replace-cross 
Abstract: We study a new version of the Traveling Salesperson Problem, called \VectorTSP, where the traveler is subject to discrete acceleration constraints, as defined in the paper-and-pencil game Racetrack (also known as Vector Racer). In this model, the degrees of freedom at a certain point in time depends on the current velocity, and the speed is not limited.
  The paper introduces this problem and initiates its study, discussing also the main differences with existing versions of TSP. Not surprisingly, the problem turns out to be NP-hard. A key feature of \VectorTSP is that it deals with acceleration in a discrete, combinatorial way, making the problem more amenable to algorithmic investigation. The problem involves two layers of trajectory planning: (1) the order in which cities are visited, and (2) the physical trajectory realizing such a visit, both interacting with each other. This interaction is formalized as an interactive protocol between a high-level tour algorithm and a trajectory oracle, the former calling the latter repeatedly. We present an exact implementation of the trajectory oracle, adapting the A* algorithm for paths over multiple checkpoints whose ordering is \emph{given} (this algorithm being possibly of independent interest). To motivate the problem further, we perform experiments showing that the naive approach consisting of solving the instance as an \EuclideanTSP first, then optimizing the trajectory of the resulting tour, is typically suboptimal and outperformed by simple (but dedicated) heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.03666v5</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnaud Casteigts, Mathieu Raffinot, Mikhail Raskin, Jason Schoeters</dc:creator>
    </item>
    <item>
      <title>An efficient uniqueness theorem for overcomplete tensor decomposition</title>
      <link>https://arxiv.org/abs/2404.07801</link>
      <description>arXiv:2404.07801v2 Announce Type: replace-cross 
Abstract: We give a new, constructive uniqueness theorem for tensor decomposition. It applies to order 3 tensors of format $n \times n \times p$ and can prove uniqueness of decomposition for generic tensors up to rank $r=4n/3$ as soon as $p \geq 4$. One major advantage over Kruskal's uniqueness theorem is that our theorem has an algorithmic proof, and the resulting algorithm is efficient. Like the uniqueness theorem, it applies in the range $n \leq r \leq 4n/3$. As a result, we obtain the first efficient algorithm for overcomplete decomposition of generic tensors of order 3.
  For instance, prior to this work it was not known how to efficiently decompose generic tensors of format $n \times n \times n$ and rank $r=1.01n$ (or rank $r \leq (1+\epsilon) n$, for some constant $\epsilon &gt;0$). Efficient overcomplete decomposition of generic tensors of format $n \times n \times 3$ remains an open problem.
  Our results are based on the method of commuting extensions pioneered by Strassen for the proof of his $3n/2$ lower bound on tensor rank and border rank. In particular, we rely on an algorithm for the computation of commuting extensions recently proposed in a companion paper, and on the classical diagonalization-based "Jennrich algorithm" for undercomplete tensor decomposition.
  This is an updated version of a paper presented at SODA 2025. As a new result, we answer a question from that paper by giving a NP-hardness result for the computation of commuting extensions. The proof relies on a recent construction by Shitov. After the paper appearing in the SODA proceedings was written, another algorithm for the overcomplete decomposition of generic tensors of order~3 was proposed by Kothari, Moitra and Wein.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07801v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Koiran</dc:creator>
    </item>
    <item>
      <title>Space-bounded quantum interactive proof systems</title>
      <link>https://arxiv.org/abs/2410.23958</link>
      <description>arXiv:2410.23958v2 Announce Type: replace-cross 
Abstract: We introduce two models of space-bounded quantum interactive proof systems, ${\sf QIPL}$ and ${\sf QIP_{\rm U}L}$. The ${\sf QIP_{\rm U}L}$ model, a space-bounded variant of quantum interactive proofs (${\sf QIP}$) introduced by Watrous (CC 2003) and Kitaev and Watrous (STOC 2000), restricts verifier actions to unitary circuits. In contrast, ${\sf QIPL}$ allows logarithmically many pinching intermediate measurements per verifier action, making it the weakest model that encompasses the classical model of Condon and Ladner (JCSS 1995).
  We characterize the computational power of ${\sf QIPL}$ and ${\sf QIP_{\rm U}L}$. When the message number $m$ is polynomially bounded, ${\sf QIP_{\rm U}L} \subsetneq {\sf QIPL}$ unless ${\sf P} = {\sf NP}$:
  - ${\sf QIPL}$ contains ${\sf NP}$ and is contained in ${\sf SBP}$, which is a subclass of ${\sf AM}$.
  - ${\sf QIP_{\rm U}L}$ is contained in ${\sf P}$ and contains ${\sf SAC}^1 \cup {\sf BQL}$, where ${\sf SAC}^1$ denotes problems solvable by classical logarithmic-depth, semi-unbounded fan-in circuits.
  However, this distinction vanishes when $m$ is constant. Our results further indicate that (pinching) intermediate measurements uniquely impact space-bounded quantum interactive proofs, unlike in space-bounded quantum computation, where ${\sf BQL}={\sf BQ_{\rm U}L}$.
  We also introduce space-bounded unitary quantum statistical zero-knowledge (${\sf QSZK_{\rm U}L}$), a specific form of ${\sf QIP_{\rm U}L}$ proof systems with statistical zero-knowledge against any verifier. This class is a space-bounded variant of quantum statistical zero-knowledge (${\sf QSZK}$) defined by Watrous (SICOMP 2009). We prove that ${\sf QSZK_{\rm U}L} = {\sf BQL}$, implying that the statistical zero-knowledge property negates the computational advantage typically gained from the interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23958v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Le Gall, Yupan Liu, Harumichi Nishimura, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>Neural Networks and (Virtual) Extended Formulations</title>
      <link>https://arxiv.org/abs/2411.03006</link>
      <description>arXiv:2411.03006v2 Announce Type: replace-cross 
Abstract: Neural networks with piecewise linear activation functions, such as rectified linear units (ReLU) or maxout, are among the most fundamental models in modern machine learning. We make a step towards proving lower bounds on the size of such neural networks by linking their representative capabilities to the notion of the extension complexity $\mathrm{xc}(P)$ of a polytope $P$. This is a well-studied quantity in combinatorial optimization and polyhedral geometry describing the number of inequalities needed to model $P$ as a linear program. We show that $\mathrm{xc}(P)$ is a lower bound on the size of any monotone or input-convex neural network that solves the linear optimization problem over $P$. This implies exponential lower bounds on such neural networks for a variety of problems, including the polynomially solvable maximum weight matching problem.
  In an attempt to prove similar bounds also for general neural networks, we introduce the notion of virtual extension complexity $\mathrm{vxc}(P)$, which generalizes $\mathrm{xc}(P)$ and describes the number of inequalities needed to represent the linear optimization problem over $P$ as a difference of two linear programs. We prove that $\mathrm{vxc}(P)$ is a lower bound on the size of any neural network that optimizes over $P$. While it remains an open question to derive useful lower bounds on $\mathrm{vxc}(P)$, we argue that this quantity deserves to be studied independently from neural networks by proving that one can efficiently optimize over a polytope $P$ using a small virtual extended formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03006v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hertrich, Georg Loho</dc:creator>
    </item>
  </channel>
</rss>
