<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 03:06:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Separable choices</title>
      <link>https://arxiv.org/abs/2504.03056</link>
      <description>arXiv:2504.03056v2 Announce Type: new 
Abstract: We introduce the novel setting of joint choices, in which options are vectors with components associated to different dimensions. In this framework, menus are multidimensional, being vectors whose components are one-dimensional menus, that is, nonempty subsets of elements associated to each dimension. We provide a natural notion of separability, requiring that selections from some dimensions are never affected by those performed on the remaining dimensions. Stability of separability across dimensions is throughly investigated. Moreover, we analyze rationalizable joint choices, which are those explained by the maximization of a revealed preference. The interplay between rationalizability e separability of joint choices allows to show that latter extends the classical definition of separability of discrete preference relations, and to assess the consistency of the former across dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03056v2</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Davide Carpentiere, Alfio Giarlotta, Angelo Petralia, Ester Sudano</dc:creator>
    </item>
    <item>
      <title>Persuasive Calibration</title>
      <link>https://arxiv.org/abs/2504.03211</link>
      <description>arXiv:2504.03211v1 Announce Type: cross 
Abstract: We introduce and study the persuasive calibration problem, where a principal aims to provide trustworthy predictions about underlying events to a downstream agent to make desired decisions. We adopt the standard calibration framework that regulates predictions to be unbiased conditional on their own value, and thus, they can reliably be interpreted at the face value by the agent. Allowing a small calibration error budget, we aim to answer the following question: what is and how to compute the optimal predictor under this calibration error budget, especially when there exists incentive misalignment between the principal and the agent? We focus on standard Lt-norm Expected Calibration Error (ECE) metric.
  We develop a general framework by viewing predictors as post-processed versions of perfectly calibrated predictors. Using this framework, we first characterize the structure of the optimal predictor. Specifically, when the principal's utility is event-independent and for L1-norm ECE, we show: (1) the optimal predictor is over-(resp. under-) confident for high (resp. low) true expected outcomes, while remaining perfectly calibrated in the middle; (2) the miscalibrated predictions exhibit a collinearity structure with the principal's utility function. On the algorithmic side, we provide a FPTAS for computing approximately optimal predictor for general principal utility and general Lt-norm ECE. Moreover, for the L1- and L-Infinity-norm ECE, we provide polynomial-time algorithms that compute the exact optimal predictor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03211v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiding Feng, Wei Tang</dc:creator>
    </item>
    <item>
      <title>Imprecision Attenuates Updating</title>
      <link>https://arxiv.org/abs/2504.02238</link>
      <description>arXiv:2504.02238v2 Announce Type: replace 
Abstract: This paper studies how imprecision in noisy signals attenuates Bayesian updating toward the prior. This phenomenon is well-known under a normal prior and normal noise, where less precise signals yield posterior means closer to the prior mean. We show this effect extends to any symmetric, log-concave prior and any symmetric, quasi-concave location experiment, using a newly introduced precision order. Our main result is that for any such prior and any signal realization, the posterior mean under location experiment S is closer to the prior mean than is the posterior mean under S', if and only if S is less precise than S'. We discuss applications to cognitive imprecision, prior precision, and overconfidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02238v2</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Vaeth</dc:creator>
    </item>
  </channel>
</rss>
