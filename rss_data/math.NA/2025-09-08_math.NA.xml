<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Sep 2025 02:22:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A matrix-free convex limiting framework for continuous Galerkin methods with nonlinear stabilization</title>
      <link>https://arxiv.org/abs/2509.04673</link>
      <description>arXiv:2509.04673v1 Announce Type: new 
Abstract: We equip a high-order continuous Galerkin discretization of a general hyperbolic problem with a nonlinear stabilization term and introduce a new methodology for enforcing preservation of invariant domains. The amount of shock-capturing artificial viscosity is determined by a smoothness sensor that measures deviations from a weighted essentially nonoscillatory (WENO) reconstruction. Since this kind of dissipative stabilization does not guarantee that the nodal states of the finite element approximation stay in a convex admissible set, we adaptively constrain deviations of these states from intermediate cell averages. The representation of our scheme in terms of such cell averages makes it possible to apply convex limiting techniques originally designed for positivity-preserving discontinuous Galerkin (DG) methods. Adapting these techniques to the continuous Galerkin setting and using Bernstein polynomials as local basis functions, we prove the invariant domain preservation property under a time step restriction that can be significantly weakened by using a flux limiter for the auxiliary cell averages. The close relationship to DG-WENO schemes is exploited and discussed. All algorithmic steps can be implemented in a matrix-free and hardware-aware manner. The effectiveness of the new element-based limiting strategy is illustrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04673v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitri Kuzmin, Hennes Hajduk, Joshua Vedral</dc:creator>
    </item>
    <item>
      <title>On convergence of upwinding Petrov-Galerkin methods for convection-diffusion</title>
      <link>https://arxiv.org/abs/2509.04703</link>
      <description>arXiv:2509.04703v1 Announce Type: new 
Abstract: We consider special upwinding Petrov-Galerkin discretizations for convection-diffusion problems. For the one dimensional case with a standard continuous linear element as the trial space and a special exponential bubble test space, we prove that the Green function associated to the continuous solution can generate the test space. In this case, we find a formula for the exact inverse of the discretization matrix, that is used for establishing new error estimates for other bubble upwinding Petrov-Galerkin discretizations. We introduce a quadratic bubble upwinding method with a special scaling parameter that provides optimal approximation order for the solution in the discrete infinity norm. % while avoiding exponential test functions. Provided the linear interpolant has standard approximation properties, we prove optimal approximation estimates in $L^2$ and $H^1$ norms. The quadratic bubble method is extended to a two dimensional convection diffusion problem. The proposed discretization produces optimal $L^2$ and $H^1$ convergence orders on subdomains that avoid the boundary layers. The tensor idea of using an efficient upwinding Petrov-Galerkin discretization along each stream line direction in combination with a standard discretizations for the orthogonal direction(s) can lead to new and efficient discretization methods for multidimensional convection dominated models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04703v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Bacuta</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Acoustic Obstacle Scattering Problem with Phaseless Far-Field Measurement Using Deep Neural Network Surrogates</title>
      <link>https://arxiv.org/abs/2509.04747</link>
      <description>arXiv:2509.04747v1 Announce Type: new 
Abstract: In this work, we investigate the use of deep neural networks (DNNs) as surrogates for solving the inverse acoustic scattering problem of recovering a sound-soft obstacle from phaseless far-field measurements. We approximate the forward maps from the obstacle to the far-field data using DNNs, and for star-shaped domains in two and three dimensions, we establish the expression rates for fully connected feedforward neural networks with the ReLU activation for approximating the forward maps. The analysis is based on the weak formulation of the direct problem, and can handle variable coefficients. Numerically we validate the accuracy of the DNN surrogates of the forward maps, and demonstrate the use of DNN surrogates in the Bayesian treatment of the inverse obstacle scattering problem. Numerical experiments indicate that the surrogates are effective in both two- and three-dimensional cases, and can significantly speed up the exploration of the posterior distribution of the shape parameters using Markov chain Monte Carlo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04747v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuxin Fan, Jiho Hong, Bangti Jin</dc:creator>
    </item>
    <item>
      <title>Filtering with Randomised Observations: Sequential Learning of Relevant Subspace Properties and Accuracy Analysis</title>
      <link>https://arxiv.org/abs/2509.04867</link>
      <description>arXiv:2509.04867v1 Announce Type: new 
Abstract: State estimation that combines observational data with mathematical models is central to many applications and is commonly addressed through filtering methods, such as ensemble Kalman filters. In this article, we examine the signal-tracking performance of a continuous ensemble Kalman filtering under fixed, randomised, and adaptively varying partial observations. Rigorous bounds are established for the expected signal-tracking error relative to the randomness of the observation operator. In addition, we propose a sequential learning scheme that adaptively determines the dimension of a state subspace sufficient to ensure bounded filtering error, by balancing observation complexity with estimation accuracy. Beyond error control, the adaptive scheme provides a systematic approach to identifying the appropriate size of the filter-relevant subspace of the underlying dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04867v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nazanin Abedini, Jana de Wiljes, Svetlana Dubinkina</dc:creator>
    </item>
    <item>
      <title>Synthetic Acceleration Preconditioners for Parametric Radiative Transfer Equations based on Trajectory-Aware Reduced Order Models</title>
      <link>https://arxiv.org/abs/2509.05001</link>
      <description>arXiv:2509.05001v1 Announce Type: new 
Abstract: The parametric radiative transfer equation (RTE) arises in multi-query applications, such as design optimization, inverse problems, and uncertainty quantification, which require solving the RTE multiple times for various parameters. Classical synthetic acceleration (SA) preconditioners are designed based on low-order approximations of a kinetic correction equation, e.g., its diffusion limit in diffusion synthetic acceleration (DSA). Despite their widespread success, these methods rely on empirical physical assumptions and do not leverage low-rank structures across parameters of the parametric problem.
  To address these limitations, our previous work introduced a reduced-order model (ROM) enhanced preconditioner called ROMSAD, which exploits low-rank structures across parameters and the original kinetic description of the correction equation. While ROMSAD improves overall efficiency compared with DSA, its efficiency reduces after the first iteration, because the construction of the underlying ROM ignores the preconditioner-dependence of the residual trajectory, leading to a mismatch between the offline and online residual trajectories.
  To overcome this issue, we introduce a trajectory-aware framework that iteratively constructs ROMs to eliminate the mismatch between offline and online residual trajectories. Numerical tests demonstrate superior efficiency over DSA, and substantial gains in both efficiency and robustness over ROMSAD. For a parametric lattice problem, trajectory-aware ROM preconditioners achieve rapid convergence within only $2$-$3$ iterations online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05001v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Tang, Zhichao Peng</dc:creator>
    </item>
    <item>
      <title>Numerical approximations to statistical conservation laws for scalar hyperbolic equations</title>
      <link>https://arxiv.org/abs/2509.05039</link>
      <description>arXiv:2509.05039v1 Announce Type: new 
Abstract: Motivated by the statistical description of turbulence, we study statistical conservation laws in the form of kinetic-type PDEs for joint probability density functions (PDFs) and cumulative distribution functions (CDFs) associated with solutions of scalar balance laws. Starting from viscous balance laws, the resulting PDF/CDF equations involve unclosed conditional averages arising in the viscous terms. We show that these terms exhibit a dissipative anomaly: they remain non-negligible in the vanishing viscosity limit and are essential to preserve the nonnegativity of evolving PDFs. To approximate these PDF/CDF equations in a unified framework, we propose a novel sampling-based estimator for the unclosed terms, constructed from numerical or exact realizations of the underlying balance-law solutions. In certain cases, a priori error bounds can be derived, demonstrating that the deviation between the true and approximate CDFs is controlled by the estimation error of the unclosed terms. Numerical experiments with analytically solvable test problems confirm that the sampling-based approximation converges satisfactorily with the number of samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05039v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Huang, Christian Rohde</dc:creator>
    </item>
    <item>
      <title>Two Precision-controlled Numerical Algorithms for the CDF of Doubly Non-central Beta Distribution Based on the Segmentation of the Infinite Double Series Matrix</title>
      <link>https://arxiv.org/abs/2509.05045</link>
      <description>arXiv:2509.05045v1 Announce Type: new 
Abstract: The cumulative distribution function (CDF) of the doubly non-central beta distribution can be expressed as an infinite double series. By truncating the sum of this series, one can obtain an approximate value of the CDF. Although numerous methods exist for calculating the non-central beta distribution, which allow for the control of the truncation range and estimation of the computational error, no such methods have been developed for the doubly non-central beta distribution. In this paper, we propose two new numerical computation methods based on the segmentation of the infinite double series, termed DIV1 and DIV2. Both methods enable automated calculations once the error control parameters are set; there is no need to predetermine the truncation range, and their computational times are comparable. Following detailed derivations, we have established the upper bounds of the errors for both methods, thus ensuring the determinability of the precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05045v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Li, Fangfang Ma, Junjie Wang, Yinhua Tian, Baoli Dai, Tianyan Dong</dc:creator>
    </item>
    <item>
      <title>New Constructions of Cubature Formulas on Wiener Space</title>
      <link>https://arxiv.org/abs/2509.05236</link>
      <description>arXiv:2509.05236v1 Announce Type: new 
Abstract: Building on techniques developed by Lyons and Victoir, we present the first explicit construction of a degree-7 cubature formula for Wiener space over $\mathbb{R}^3$. We then examine and compare two approaches for computing cubature approximations: one based on the stochastic Taylor expansion and the other on the Log-ODE method. Our numerical experiments illustrate how the cubature degree influences the order of convergence and demonstrate the utility of cubature methods for weak approximations of stochastic differential equations (SDEs). These results were originally part of a Master's thesis and are provided here as context and a reference point for subsequent work. A more general construction in arbitrary dimensions has since been obtained by Ferrucci, Herschell, Litterer and Lyons arXiv:2411.13707 using different techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05236v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy Herschell</dc:creator>
    </item>
    <item>
      <title>Uncertain but Useful: Leveraging CNN Variability into Data Augmentation</title>
      <link>https://arxiv.org/abs/2509.05238</link>
      <description>arXiv:2509.05238v1 Announce Type: new 
Abstract: Deep learning (DL) is rapidly advancing neuroimaging by achieving state-of-the-art performance with reduced computation times. Yet the numerical stability of DL models -- particularly during training -- remains underexplored. While inference with DL is relatively stable, training introduces additional variability primarily through iterative stochastic optimization. We investigate this training-time variability using FastSurfer, a CNN-based whole-brain segmentation pipeline. Controlled perturbations are introduced via floating point perturbations and random seeds. We find that: (i) FastSurfer exhibits higher variability compared to that of a traditional neuroimaging pipeline, suggesting that DL inherits and is particularly susceptible to sources of instability present in its predecessors; (ii) ensembles generated with perturbations achieve performance similar to an unperturbed baseline; and (iii) variability effectively produces ensembles of numerical model families that can be repurposed for downstream applications. As a proof of concept, we demonstrate that numerical ensembles can be used as a data augmentation strategy for brain age regression. These findings position training-time variability not only as a reproducibility concern but also as a resource that can be harnessed to improve robustness and enable new applications in neuroimaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05238v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>In\'es Gonzalez-Pepe, Vinuyan Sivakolunthu, Yohan Chatelain, Tristan Glatard</dc:creator>
    </item>
    <item>
      <title>Inverse problem for the Navier-Stokes equations and identification of immersed obstacles in the Mediterranean Sea</title>
      <link>https://arxiv.org/abs/2509.05287</link>
      <description>arXiv:2509.05287v1 Announce Type: new 
Abstract: This paper presents a theoretical and numerical investigation of object detection in a fluid governed by the three-dimensional evolutionary Navier--Stokes equations. To solve this inverse problem, we assume that interior velocity measurements are available only within a localized subregion of the fluid domain. First, we present an identifiability result. We then formulate the problem as a shape optimization task: to identify the obstacle, we minimize a nonlinear least-squares criterion with a regularization term that penalizes the perimeter of the obstacle to be identified. We prove the existence and stability of a minimizer of the least-squares functional. To recover the unknown obstacle, we present a non-iterative identification method based on the topological derivative. The corresponding asymptotic expansion of the least-squares functional is computed in a straightforward manner using a penalty method. Finally, as a realistic application, we demonstrate the robustness and effectiveness of the proposed non-iterative procedure through numerical experiments using the INSTMCOTRHD ocean model, which incorporates realistic Mediterranean bathymetry, stratification, and forcing conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05287v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mourad Hrizi, Marwa Ouni, Maatoug Hassine</dc:creator>
    </item>
    <item>
      <title>Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction Around a Complex-Shaped Pin-Fin</title>
      <link>https://arxiv.org/abs/2509.04463</link>
      <description>arXiv:2509.04463v1 Announce Type: cross 
Abstract: This study presents the development of a domain-responsive edge-aware multiscale Graph Neural Network for predicting steady, turbulent flow and thermal behavior in a two-dimensional channel containing arbitrarily shaped complex pin-fin geometries. The training dataset was constructed through an automated framework that integrated geometry generation, meshing, and flow-field solutions in ANSYS Fluent. The pin-fin geometry was parameterized using piecewise cubic splines, producing 1,000 diverse configurations through Latin Hypercube Sampling. Each simulation was converted into a graph structure, where nodes carried a feature vector containing spatial coordinates, a normalized streamwise position, one-hot boundary indicators, and a signed distance to the nearest boundary such as wall. This graph structure served as input to the newly developed Graph Neural Network, which was trained to predict temperature, velocity magnitude, and pressure at each node using data from ANSYS. The network predicted fields with outstanding accuracy, capturing boundary layers, recirculation, and the stagnation region upstream of the pin-fins while reducing wall time by 2-3 orders of magnitude. In conclusion, the novel graph neural network offered a fast and reliable surrogate for simulations in complex flow configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04463v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Riddhiman Raut, Evan M. Mihalko, Amrita Basak</dc:creator>
    </item>
    <item>
      <title>Fidelity-preserving enhancement of ptychography with foundational text-to-image models</title>
      <link>https://arxiv.org/abs/2509.04513</link>
      <description>arXiv:2509.04513v1 Announce Type: cross 
Abstract: Ptychographic phase retrieval enables high-resolution imaging of complex samples but often suffers from artifacts such as grid pathology and multislice crosstalk, which degrade reconstructed images. We propose a plug-and-play (PnP) framework that integrates physics model-based phase retrieval with text-guided image editing using foundational diffusion models. By employing the alternating direction method of multipliers (ADMM), our approach ensures consensus between data fidelity and artifact removal subproblems, maintaining physics consistency while enhancing image quality. Artifact removal is achieved using a text-guided diffusion image editing method (LEDITS++) with a pre-trained foundational diffusion model, allowing users to specify artifacts for removal in natural language. Demonstrations on simulated and experimental datasets show significant improvements in artifact suppression and structural fidelity, validated by metrics such as peak signal-to-noise ratio (PSNR) and diffraction pattern consistency. This work highlights the combination of text-guided generative models and model-based phase retrieval algorithms as a transferable and fidelity-preserving method for high-quality diffraction imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04513v1</guid>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ming Du, Volker Rose, Junjing Deng, Dileep Singh, Si Chen, Mathew J. Cherukara</dc:creator>
    </item>
    <item>
      <title>Instance-Wise Adaptive Sampling for Dataset Construction in Approximating Inverse Problem Solutions</title>
      <link>https://arxiv.org/abs/2509.04583</link>
      <description>arXiv:2509.04583v1 Announce Type: cross 
Abstract: We propose an instance-wise adaptive sampling framework for constructing compact and informative training datasets for supervised learning of inverse problem solutions. Typical learning-based approaches aim to learn a general-purpose inverse map from datasets drawn from a prior distribution, with the training process independent of the specific test instance. When the prior has a high intrinsic dimension or when high accuracy of the learned solution is required, a large number of training samples may be needed, resulting in substantial data collection costs. In contrast, our method dynamically allocates sampling effort based on the specific test instance, enabling significant gains in sample efficiency. By iteratively refining the training dataset conditioned on the latest prediction, the proposed strategy tailors the dataset to the geometry of the inverse map around each test instance. We demonstrate the effectiveness of our approach in the inverse scattering problem under two types of structured priors. Our results show that the advantage of the adaptive method becomes more pronounced in settings with more complex priors or higher accuracy requirements. While our experiments focus on a particular inverse problem, the adaptive sampling strategy is broadly applicable and readily extends to other inverse problems, offering a scalable and practical alternative to conventional fixed-dataset training regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04583v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiequn Han, Kui Ren, Nathan Soedjak</dc:creator>
    </item>
    <item>
      <title>Interpreting Transformer Architectures as Implicit Multinomial Regression</title>
      <link>https://arxiv.org/abs/2509.04653</link>
      <description>arXiv:2509.04653v1 Announce Type: cross 
Abstract: Mechanistic interpretability aims to understand how internal components of modern machine learning models, such as weights, activations, and layers, give rise to the model's overall behavior. One particularly opaque mechanism is attention: despite its central role in transformer models, its mathematical underpinnings and relationship to concepts like feature polysemanticity, superposition, and model performance remain poorly understood. This paper establishes a novel connection between attention mechanisms and multinomial regression. Specifically, we show that in a fixed multinomial regression setting, optimizing over latent features yields optimal solutions that align with the dynamics induced by attention blocks. In other words, the evolution of representations through a transformer can be interpreted as a trajectory that recovers the optimal features for classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04653v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonas A. Actor, Anthony Gruber, Eric C. Cyr</dc:creator>
    </item>
    <item>
      <title>Spectral scheme for an energetic Fokker-Planck equation with $\kappa$-distribution steady states</title>
      <link>https://arxiv.org/abs/2509.04911</link>
      <description>arXiv:2509.04911v1 Announce Type: cross 
Abstract: The concern of the present paper is the design of efficient numerical schemes for a specific Fokker-Planck equation describing the dynamics of energetic particles occurring in thermonuclear fusion plasmas (runaway electrons for example). In the long-time limit, the velocity distribution function of these particles tends towards a thermal non-equilibrium $\kappa$-distribution function which is a steady-state of the considered Fokker-Planck equation. These $\kappa$-distribution functions have the particularity of being only algebraically decaying for large velocities, thus describing very well suprathermal particle populations. Our aim is to present two efficient spectral methods for the simulation of such energetic particle dynamics. The first method will be based on rational Chebyshev basis functions, rather than on Hermite basis sets, which are the basis of choice for Maxwellian steady states. The second method is based on a different polynomial basis set, constructed via the Gram-Schmidt orthogonalisation process. These two new spectral schemes, specifically adapted to the here considered physical context, shall permit to cope with the long-time asymptotics without significant numerical costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04911v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Parada (IMT), Claudia Negulescu</dc:creator>
    </item>
    <item>
      <title>Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations</title>
      <link>https://arxiv.org/abs/2509.05186</link>
      <description>arXiv:2509.05186v2 Announce Type: cross 
Abstract: In-context operator networks (ICON) are a class of operator learning methods based on the novel architectures of foundation models. Trained on a diverse set of datasets of initial and boundary conditions paired with corresponding solutions to ordinary and partial differential equations (ODEs and PDEs), ICON learns to map example condition-solution pairs of a given differential equation to an approximation of its solution operator. Here, we present a probabilistic framework that reveals ICON as implicitly performing Bayesian inference, where it computes the mean of the posterior predictive distribution over solution operators conditioned on the provided context, i.e., example condition-solution pairs. The formalism of random differential equations provides the probabilistic framework for describing the tasks ICON accomplishes while also providing a basis for understanding other multi-operator learning methods. This probabilistic perspective provides a basis for extending ICON to \emph{generative} settings, where one can sample from the posterior predictive distribution of solution operators. The generative formulation of ICON (GenICON) captures the underlying uncertainty in the solution operator, which enables principled uncertainty quantification in the solution predictions in operator learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05186v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin J. Zhang, Siting Liu, Stanley J. Osher, Markos A. Katsoulakis</dc:creator>
    </item>
    <item>
      <title>A note concerning polyhyperbolic and related splines</title>
      <link>https://arxiv.org/abs/2307.00343</link>
      <description>arXiv:2307.00343v3 Announce Type: replace 
Abstract: This note concerns the interpolation problem with two parametrized families of splines related to polynomial spline interpolation. We address the questions of uniqueness and establish basic convergence rates for splines of the form $ s_\alpha = p\cosh(\alpha\cdot)+q\sinh(\alpha \cdot)$ and $t_\alpha = p+q\tanh(\alpha \cdot) $ between the nodes where $p,q\in\Pi_{k-1}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00343v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeff Ledford, Luke Paris, Ryan Urban, Alec Vidanes</dc:creator>
    </item>
    <item>
      <title>Stability Analysis for Electromagnetic Waveguides. Part 1: Acoustic and Homogeneous Electromagnetic Waveguides</title>
      <link>https://arxiv.org/abs/2307.04521</link>
      <description>arXiv:2307.04521v2 Announce Type: replace 
Abstract: In a time-harmonic setting, we show for heterogeneous acoustic and homogeneous electromagnetic wavesguides stability estimates with the stability constant depending linearly on the length $L$ of the waveguide. These stability estimates are used for the analysis of the (ideal) ultraweak (UW) variant of the Discontinuous Petrov Galerkin (DPG) method. For this UW DPG, we show that the stability deterioration with $L$ can be countered by suitably scaling the test norm of the method. We present the ``full envelope approximation'', a UW DPG method based on non-polynomial ansatz functions that allows for treating long waveguides.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04521v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1599239</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Math. Anal. 57 (2025) pp. 2559-2595</arxiv:journal_reference>
      <dc:creator>Jens Markus Melenk, Leszek Demkowicz, Stefan Henneking</dc:creator>
    </item>
    <item>
      <title>Underdetermined Fourier Extensions for Surface Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2401.04328</link>
      <description>arXiv:2401.04328v3 Announce Type: replace 
Abstract: We analyze and test using Fourier extensions that minimize a Hilbert space norm for the purpose of solving partial differential equations (PDEs) on surfaces. In particular, we prove that the approach is arbitrarily high-order and also show a general result relating boundedness, solvability, and convergence that can be used to find eigenvalues. The method works by extending a solution to a surface PDE into a box-shaped domain so that the differential operators of the extended function agree with the surface differential operators, as in the Closest Point Method. This differs from approaches that require a basis for the surface of interest, which may not be available. Numerical experiments are also provided, demonstrating super-algebraic convergence. Current high-order methods for surface PDEs are often limited to a small class of surfaces or use radial basis functions (RBFs). Our approach offers certain advantages related to conditioning, generality, and ease of implementation. The method is meshfree and works on arbitrary surfaces (closed or non-closed) defined by point clouds with minimal conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04328v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel R. Venn, Steven J. Ruuth</dc:creator>
    </item>
    <item>
      <title>GePUP-ES: High-order Energy-stable Projection Methods for the Incompressible Navier-Stokes Equations with No-slip Conditions</title>
      <link>https://arxiv.org/abs/2409.11255</link>
      <description>arXiv:2409.11255v2 Announce Type: replace 
Abstract: Inspired by the unconstrained PPE (UPPE) formulation [Liu, Liu, &amp; Pego 2007 Comm. Pure Appl. Math., 60 pp. 1443], we previously proposed the GePUP formulation [Zhang 2016 J. Sci. Comput., 67 pp. 1134] for numerically solving the incompressible Navier-Stokes equations (INSE) on no-slip domains. In this paper, we propose GePUP-E and GePUP-ES, variants of GePUP that feature (a) electric boundary conditions with no explicit enforcement of the no-penetration condition, (b) equivalence to the no-slip INSE, (c) exponential decay of the divergence of an initially non-solenoidal velocity, and (d) monotonic decrease of the kinetic energy. Different from UPPE, the GePUP-E and GePUP-ES formulations are of strong forms and are designed for finite volume/difference methods under the framework of method of lines. Furthermore, we develop semi-discrete algorithms that preserve (c) and (d) and fully discrete algorithms that are fourth-order accurate for velocity both in time and in space. These algorithms employ algebraically stable time integrators in a black-box manner and only consist of solving a sequence of linear equations in each time step. Results of numerical tests confirm our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11255v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Li, Xu Wu, Jiatu Yan, Jiang Yang, Qinghai Zhang, Shubo Zhao</dc:creator>
    </item>
    <item>
      <title>Theory and numerics of subspace approximation of eigenvalue problems</title>
      <link>https://arxiv.org/abs/2412.08891</link>
      <description>arXiv:2412.08891v2 Announce Type: replace 
Abstract: Large-scale eigenvalue problems arise in various fields of science and engineering and demand computationally efficient solutions. In this study, we investigate the subspace approximation for parametric linear eigenvalue problems, aiming to mitigate the computational burden associated with high-fidelity systems. We provide general error estimates under non-simple eigenvalue conditions, establishing some theoretical foundations for understanding the convergence behavior of subspace approximations. Numerical examples, including problems with one-dimensional to three-dimensional spatial domain and one-dimensional to two-dimensional parameter domain, are presented to demonstrate the efficacy of reduced basis method in handling parametric variations in boundary conditions and coefficient fields to achieve significant computational savings while maintaining high accuracy, making them promising tools for practical applications in large-scale eigenvalue computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08891v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siu Wun Cheung, Youngsoo Choi, Seung Whan Chung, Jean-Luc Fattebert, Coleman Kendrick, Daniel Osei-Kuffuor</dc:creator>
    </item>
    <item>
      <title>Deep asymptotic expansion method for solving singularly perturbed time-dependent reaction-advection-diffusion equations</title>
      <link>https://arxiv.org/abs/2505.23002</link>
      <description>arXiv:2505.23002v2 Announce Type: replace 
Abstract: Physics-informed neural network (PINN) has shown great potential in solving partial differential equations. However, it faces challenges when dealing with problems involving steep gradients. The solutions to singularly perturbed time-dependent reaction-advection-diffusion equations exhibit internal moving transition layers with sharp gradients, and thus the standard PINN becomes ineffective. In this work, we propose a deep asymptotic expansion (DAE) method, which is inspired by asymptotic analysis and leverages deep learning to approximate the smooth part of the expansion. We first derive the governing equations for transition layers, which are then solved using PINN. Numerical experiments show that the DAE outperforms the standard PINN, gPINN, and PINN with adaptive sampling. We also show its robustness with respect to training point distributions, network architectures, and random seeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23002v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiao Zhu, Dmitrii Chaikovskii, Bangti Jin, Ye Zhang</dc:creator>
    </item>
    <item>
      <title>Fourth-order Adaptive Mesh Refinement both in space and in time for incompressible Navier-Stokes equations with Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2506.02663</link>
      <description>arXiv:2506.02663v2 Announce Type: replace 
Abstract: We present a fourth-order projection method with adaptive mesh refinement (AMR) for numerically solving the incompressible Navier-Stokes equations (INSE) with subcycling in time. Our method features (i) a reformulation of INSE so that the velocity divergence decays exponentially on the coarsest level, (ii) a derivation of coarse-fine interface conditions that preserves the decay of velocity divergence on any refinement level of the AMR hierarchy, (iii) an approximation of the coarse-fine interface conditions via spatiotemporal interpolations to facilitate subcycling in time, (iv) enforcing to machine precision solvability conditions of elliptic equations over each connected component of the subdomain covered by any refinement level, (v) a composite projection for synchronizing multiple levels, and (vi) geometric multigrid for solving linear systems with optimal complexity. Different from current block-structured AMR algorithms, our method never adopts refluxing at the coarse-fine interface, nor is fine-to-coarse averaging applied to projected velocities. Results of numerical tests demonstrate the high accuracy and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02663v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubo Zhao, Qinghai Zhang</dc:creator>
    </item>
    <item>
      <title>Entropy stable finite difference methods via entropy correction artificial viscosity and knapsack limiting</title>
      <link>https://arxiv.org/abs/2508.21226</link>
      <description>arXiv:2508.21226v2 Announce Type: replace 
Abstract: Entropy stable methods have become increasingly popular in the field of computational fluid dynamics. They often work by satisfying some form of a discrete entropy inequality: a discrete form of the 2nd law of thermodynamics. Schemes which satisfy a (semi-)discrete entropy inequality typically behave much more robustly, and do so in a way that is hyperparameter free. Recently, a new strategy was introduced to construct entropy stable discontinuous Galerkin methods: knapsack limiting, which blends together a low order, positivity preserving, and entropy stable scheme with a high order accurate scheme, in order to produce a high order accurate, entropy stable, and positivity preserving scheme. Another recent strategy introduces an entropy correction artificial viscosity into a high order scheme, aiming to satisfy a cell entropy inequality.
  In this work, we introduce the techniques of knapsack limiting and artificial viscosity for finite difference discretizations. The proposed schemes preserve high order accuracy in sufficiently smooth conditions, are entropy stable, and are hyperparameter free. Moreover, the proposed knapsack limiting scheme provably preserves positivity for the compressible Euler and Navier-Stokes equations. Both schemes achieve this goal without significant performance tradeoffs compared to state of the art stabilized schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21226v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Christner, Jesse Chan</dc:creator>
    </item>
    <item>
      <title>FEniCSx-pctools: Tools for PETSc block linear algebra preconditioning in FEniCSx</title>
      <link>https://arxiv.org/abs/2402.02523</link>
      <description>arXiv:2402.02523v3 Announce Type: replace-cross 
Abstract: Solving partial differential equations with the finite element method leads to large linear systems of equations that must be solved. When these systems have a natural block structure due to multiple field variables, using iterative solvers with carefully designed preconditioning strategies that exploit the underlying physical structure becomes necessary for an efficient and scalable solution process. FEniCSx Preconditioning Tools (FEniCSx-pctools) is a software package that eases the specification of PETSc (Portable, Extensible Toolkit for Scientific Computation) block preconditioning strategies on linear systems assembled using the DOLFINx finite element solver of the FEniCS Project. The package automatically attaches all necessary metadata so that preconditioning strategies can be applied via PETSc's standard options database to monolithic and block assembled systems. The documented examples include a simple mixed Poisson system and more complex pressure convection-diffusion approach to preconditioning the Navier-Stokes equations. We show weak parallel scaling on a fully coupled temperature-Navier-Stokes system up to 8192 MPI (Message Passing Interface) processes, demonstrating the applicability of the approach to large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02523v3</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin \v{R}eho\v{r}, Jack S. Hale</dc:creator>
    </item>
    <item>
      <title>Continuum Attention for Neural Operators</title>
      <link>https://arxiv.org/abs/2406.06486</link>
      <description>arXiv:2406.06486v2 Announce Type: replace-cross 
Abstract: Transformers, and the attention mechanism in particular, have become ubiquitous in machine learning. Their success in modeling nonlocal, long-range correlations has led to their widespread adoption in natural language processing, computer vision, and time series problems. Neural operators, which map spaces of functions into spaces of functions, are necessarily both nonlinear and nonlocal if they are universal; it is thus natural to ask whether the attention mechanism can be used in the design of neural operators. Motivated by this, we study transformers in the function space setting. We formulate attention as a map between infinite dimensional function spaces and prove that the attention mechanism as implemented in practice is a Monte Carlo or finite difference approximation of this operator. The function space formulation allows for the design of transformer neural operators, a class of architectures designed to learn mappings between function spaces. In this paper, we state and prove the first universal approximation result for transformer neural operators, using only a slight modification of the architecture implemented in practice. The prohibitive cost of applying the attention operator to functions defined on multi-dimensional domains leads to the need for more efficient attention-based architectures. For this reason we also introduce a function space generalization of the patching strategy from computer vision, and introduce a class of associated neural operators. Numerical results, on an array of operator learning problems, demonstrate the promise of our approaches to function space formulations of attention and their use in neural operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06486v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Calvello, Nikola B. Kovachki, Matthew E. Levine, Andrew M. Stuart</dc:creator>
    </item>
    <item>
      <title>A CFL condition for the finite cell method</title>
      <link>https://arxiv.org/abs/2502.13675</link>
      <description>arXiv:2502.13675v3 Announce Type: replace-cross 
Abstract: Immersed boundary finite element methods allow the user to bypass the potentially troublesome task of boundary-conforming mesh generation. When combined with explicit time integration, poorly cut elements with little support in the physical domain lead to a severely reduced critical time step size, posing a major challenge for immersed wave propagation simulations. The finite cell method stabilizes cut elements by defining the weak form of the problem also in the fictitious domain, but scaled by a small value $\alpha$. This paper investigates the effect of the finite cell method on the critical time step size for explicit time integration. Starting with an analytical one-degree-of-freedom model, we systematically study the influence of $\alpha$-stabilization on the maximum eigenvalue, and thus on the critical time step size, for corner and sliver cuts. The analysis is complemented by a numerical study of an example with one element and increasing polynomial degree, confirming that the critical time step size does not decrease below a certain limit, even as the cut fraction tends to zero. This lower bound is controlled by the choice of $\alpha$. In higher dimensions, sliver cuts are found to be more detrimental than corner cuts, thus determining the minimum critical time step size. Increasing the polynomial degree has only little effect on this degradation. Based on these observations, we derive an estimate of the minimum critical time step size as a function of $\alpha$, which we use to propose a modified CFL condition for the finite cell method. The validity of this condition is demonstrated on a two-dimensional perforated plate example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13675v3</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim B\"urchner, Lars Radtke, Philipp Kopp</dc:creator>
    </item>
  </channel>
</rss>
