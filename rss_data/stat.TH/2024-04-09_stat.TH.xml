<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Apr 2024 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bivariate measure-inducing quasi-copulas</title>
      <link>https://arxiv.org/abs/2404.04560</link>
      <description>arXiv:2404.04560v1 Announce Type: new 
Abstract: It is well known that every bivariate copula induces a positive measure on the Borel $\sigma$-algebra on $[0,1]^2$, but there exist bivariate quasi-copulas that do not induce a signed measure on the same $\sigma$-algebra. In this paper we show that a signed measure induced by a bivariate quasi-copula can always be expressed as an infinite combination of measures induced by copulas. With this we are able to give the first characterization of measure-inducing quasi-copulas in the bivariate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04560v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nik Stopar</dc:creator>
    </item>
    <item>
      <title>High-dimensional bootstrap and asymptotic expansion</title>
      <link>https://arxiv.org/abs/2404.05006</link>
      <description>arXiv:2404.05006v1 Announce Type: new 
Abstract: The recent seminal work of Chernozhukov, Chetverikov and Kato has shown that bootstrap approximation for the maximum of a sum of independent random vectors is justified even when the dimension is much larger than the sample size. In this context, numerical experiments suggest that third-moment match bootstrap approximations would outperform normal approximation even without studentization, but the existing theoretical results cannot explain this phenomenon. In this paper, we first show that Edgeworth expansion, if justified, can give an explanation for this phenomenon. Second, we obtain valid Edgeworth expansions in the high-dimensional setting when the random vectors have Stein kernels. Finally, we prove the second-order accuracy of a double wild bootstrap method in this setting. As a byproduct, we find an interesting blessing of dimensionality phenomenon: The single third-moment match wild bootstrap is already second-order accurate in high-dimensions if the covariance matrix is spherical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05006v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuta Koike</dc:creator>
    </item>
    <item>
      <title>Faithlessness in Gaussian graphical models</title>
      <link>https://arxiv.org/abs/2404.05306</link>
      <description>arXiv:2404.05306v1 Announce Type: new 
Abstract: The implication problem for conditional independence (CI) asks whether the fact that a probability distribution obeys a given finite set of CI relations implies that a further CI statement also holds in this distribution. This problem has a long and fascinating history, cumulating in positive results about implications now known as the semigraphoid axioms as well as impossibility results about a general finite characterization of CI implications. Motivated by violation of faithfulness assumptions in causal discovery, we study the implication problem in the special setting where the CI relations are obtained from a directed acyclic graphical (DAG) model along with one additional CI statement. Focusing on the Gaussian case, we give a complete characterization of when such an implication is graphical by using algebraic techniques. Moreover, prompted by the relevance of strong faithfulness in statistical guarantees for causal discovery algorithms, we give a graphical solution for an approximate CI implication problem, in which we ask whether small values of one additional partial correlation entail small values for yet a further partial correlation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05306v1</guid>
      <category>math.ST</category>
      <category>math.AC</category>
      <category>math.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathias Drton, Leonard Henckel, Benjamin Hollering, Pratik Misra</dc:creator>
    </item>
    <item>
      <title>Quickest Change Detection for Multiple Data Streams Using the James-Stein Estimator</title>
      <link>https://arxiv.org/abs/2404.05486</link>
      <description>arXiv:2404.05486v1 Announce Type: new 
Abstract: The problem of quickest change detection is studied in the context of detecting an arbitrary unknown mean-shift in multiple independent Gaussian data streams. The James-Stein estimator is used in constructing detection schemes that exhibit strong detection performance both asymptotically and non-asymptotically. First, a James-Stein-based extension of the recently developed windowed CuSum test is introduced. Our results indicate that the proposed scheme constitutes a uniform improvement over its typical maximum likelihood variant. That is, the proposed James-Stein version achieves a smaller detection delay simultaneously for all possible post-change parameter values and every false alarm rate constraint, as long as the number of parallel data streams is greater than three. Additionally, an alternative detection procedure that utilizes the James-Stein estimator is shown to have asymptotic detection delay properties that compare favorably to existing tests. The second-order term of the asymptotic average detection delay is reduced in a predefined low-dimensional subspace of the parameter space, while second-order asymptotic minimaxity is preserved. The results are verified in simulations, where the proposed schemes are shown to achieve smaller detection delays compared to existing alternatives, especially when the number of data streams is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05486v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Topi Halme, Venugopal V. Veeravalli, Visa Koivunen</dc:creator>
    </item>
    <item>
      <title>Maximum likelihood estimation in continuous affine Volterra processes in the ergodic regime</title>
      <link>https://arxiv.org/abs/2404.05554</link>
      <description>arXiv:2404.05554v1 Announce Type: new 
Abstract: We study statistical inference of the drift parameters for the Volterra Ornstein-Uhlenbeck process on R and the Volterra Cox-Ingersoll-Ross process on R+ in the ergodic regime. For continuous-time observations, we derive the corresponding maximum likelihood estimators and show that they are strongly consistent and asymptotically normal locally uniformly in the parameters. For the case of discrete high-frequency observations, we prove similar results by discretization of the continuous-time maximum likelihood estimator. Finally, for discrete low-frequency observations, we show that the method of moments is consistent. Our proofs are crucially based on the law of large numbers. To prove the latter, we introduce the notion of asymptotic independence which has the advantage that it can be effectively verified by the affine transformation formula and convergence of the characteristic function. As a side product of our results, we show that the stationary processes are ergodic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05554v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Ben Alaya, Martin Friesen, Jonas Kremer</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference in Ultrahigh Dimensional Partially Linear Single-Index Models</title>
      <link>https://arxiv.org/abs/2404.04471</link>
      <description>arXiv:2404.04471v1 Announce Type: cross 
Abstract: This paper is concerned with estimation and inference for ultrahigh dimensional partially linear single-index models. The presence of high dimensional nuisance parameter and nuisance unknown function makes the estimation and inference problem very challenging. In this paper, we first propose a profile partial penalized least squares estimator and establish the sparsity, consistency and asymptotic representation of the proposed estimator in ultrahigh dimensional setting. We then propose an $F$-type test statistic for parameters of primary interest and show that the limiting null distribution of the test statistic is $\chi^2$ distribution, and the test statistic can detect local alternatives, which converge to the null hypothesis at the root-$n$ rate. We further propose a new test for the specification testing problem of the nonparametric function. The test statistic is shown to be asymptotically normal. Simulation studies are conducted to examine the finite sample performance of the proposed estimators and tests. A real data example is used to illustrate the proposed procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04471v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijie Cui, Xu Guo, Zhe Zhang</dc:creator>
    </item>
    <item>
      <title>Common Trends and Long-Run Multipliers in Nonlinear Structural VARs</title>
      <link>https://arxiv.org/abs/2404.05349</link>
      <description>arXiv:2404.05349v1 Announce Type: cross 
Abstract: While it is widely recognised that linear (structural) VARs may omit important features of economic time series, the use of nonlinear SVARs has to date been almost entirely confined to the modelling of stationary time series, because of a lack of understanding as to how common stochastic trends may be accommodated within nonlinear VAR models. This has unfortunately circumscribed the range of series to which such models can be applied -- and/or required that these series be first transformed to stationarity, a potential source of misspecification -- and prevented the use of long-run identifying restrictions in these models. To address these problems, we develop a flexible class of additively time-separable nonlinear SVARs, which subsume models with threshold-type endogenous regime switching, both of the piecewise linear and smooth transition varieties. We extend the Granger-Johansen representation theorem to this class of models, obtaining conditions that specialise exactly to the usual ones when the model is linear. We further show that, as a corollary, these models are capable of supporting the same kinds of long-run identifying restrictions as are available in linear cointegrated SVARs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05349v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James A. Duffy, Sophocles Mavroeidis</dc:creator>
    </item>
    <item>
      <title>Empirical Risk Minimization with Relative Entropy Regularization</title>
      <link>https://arxiv.org/abs/2211.06617</link>
      <description>arXiv:2211.06617v5 Announce Type: replace 
Abstract: The empirical risk minimization (ERM) problem with relative entropy regularization (ERM-RER) is investigated under the assumption that the reference measure is a $\sigma$-finite measure, and not necessarily a probability measure. Under this assumption, which leads to a generalization of the ERM-RER problem allowing a larger degree of flexibility for incorporating prior knowledge, numerous relevant properties are stated. Among these properties, the solution to this problem, if it exists, is shown to be a unique probability measure, mutually absolutely continuous with the reference measure. Such a solution exhibits a probably-approximately-correct guarantee for the ERM problem independently of whether the latter possesses a solution. For a fixed dataset and under a specific condition, the empirical risk is shown to be a sub-Gaussian random variable when the models are sampled from the solution to the ERM-RER problem. The generalization capabilities of the solution to the ERM-RER problem (the Gibbs algorithm) are studied via the sensitivity of the expected empirical risk to deviations from such a solution towards alternative probability measures. Finally, an interesting connection between sensitivity, generalization error, and lautum information is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06617v5</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2024.3365728</arxiv:DOI>
      <dc:creator>Samir M. Perlaza, Gaetan Bisson, I\~naki Esnaola, Alain Jean-Marie, Stefano Rini</dc:creator>
    </item>
    <item>
      <title>Skewed Bernstein-von Mises theorem and skew-modal approximations</title>
      <link>https://arxiv.org/abs/2301.03038</link>
      <description>arXiv:2301.03038v3 Announce Type: replace 
Abstract: Gaussian approximations are routinely employed in Bayesian statistics to ease inference when the target posterior is intractable. Although these approximations are asymptotically justified by Bernstein-von Mises type results, in practice the expected Gaussian behavior may poorly represent the shape of the posterior, thus affecting approximation accuracy. Motivated by these considerations, we derive an improved class of closed-form approximations of posterior distributions which arise from a new treatment of a third-order version of the Laplace method yielding approximations in a tractable family of skew-symmetric distributions. Under general assumptions which account for misspecified models and non-i.i.d. settings, this family of approximations is shown to have a total variation distance from the target posterior whose rate of convergence improves by at least one order of magnitude the one established by the classical Bernstein-von Mises theorem. Specializing this result to the case of regular parametric models shows that the same improvement in approximation accuracy can be also derived for polynomially bounded posterior functionals. Unlike other higher-order approximations, our results prove that it is possible to derive closed-form and valid densities which are expected to provide, in practice, a more accurate, yet similarly-tractable, alternative to Gaussian approximations of the target posterior, while inheriting its limiting frequentist properties. We strengthen such arguments by developing a practical skew-modal approximation for both joint and marginal posteriors that achieves the same theoretical guarantees of its theoretical counterpart by replacing the unknown model parameters with the corresponding MAP estimate. Empirical studies confirm that our theoretical results closely match the remarkable performance observed in practice, even in finite, possibly small, sample regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.03038v3</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Durante, Francesco Pozza, Botond Szabo</dc:creator>
    </item>
    <item>
      <title>Graph Convex Hull Bounds as generalized Jensen Inequalities</title>
      <link>https://arxiv.org/abs/2304.04856</link>
      <description>arXiv:2304.04856v2 Announce Type: replace 
Abstract: Jensen's inequality is ubiquitous in measure and probability theory, statistics, machine learning, information theory and many other areas of mathematics and data science. It states that, for any convex function $f\colon K \to \mathbb{R}$ defined on a convex domain $K \subseteq \mathbb{R}^{d}$ and any random variable $X$ taking values in $K$, $\mathbb{E}[f(X)] \geq f(\mathbb{E}[X])$. In this paper, sharp upper and lower bounds on $\mathbb{E}[f(X)]$, termed ``graph convex hull bounds'', are derived for arbitrary functions $f$ on arbitrary domains $K$, thereby extensively generalizing Jensen's inequality. The derivation of these bounds necessitates the investigation of the convex hull of the graph of $f$, which can be challenging for complex functions. On the other hand, once these inequalities are established, they hold, just like Jensen's inequality, for \emph{any} $K$-valued random variable $X$. Therefore, these bounds are of particular interest in cases where $f$ is relatively simple and $X$ is complicated or unknown. Both finite- and infinite-dimensional domains and codomains of $f$ are covered as well as analogous bounds for conditional expectations and Markov operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04856v2</guid>
      <category>math.ST</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilja Klebanov</dc:creator>
    </item>
    <item>
      <title>On optimality of Mallows model averaging</title>
      <link>https://arxiv.org/abs/2309.13239</link>
      <description>arXiv:2309.13239v3 Announce Type: replace 
Abstract: In the past decades, model averaging (MA) has attracted much attention as it has emerged as an alternative tool to the model selection (MS) statistical approach. Hansen [Econometrica 75 (2007) 1175--1189] introduced a Mallows model averaging (MMA) method with model weights selected by minimizing a Mallows' $C_p$ criterion. The main theoretical justification for MMA is an asymptotic optimality (AOP), which states that the risk/loss of the resulting MA estimator is asymptotically equivalent to that of the best but infeasible averaged model. MMA's AOP is proved in the literature by either constraining weights in a special discrete weight set or limiting the number of candidate models. In this work, it is first shown that under these restrictions, however, the optimal risk of MA becomes an unreachable target, and MMA may converge more slowly than MS. In this background, a foundational issue that has not been addressed is: When a suitably large set of candidate models is considered, and the model weights are not harmfully constrained, can the MMA estimator perform asymptotically as well as the optimal convex combination of the candidate models? We answer this question in both nested and non-nested settings. In the nested setting, we provide finite sample inequalities for the risk of MMA and show that without unnatural restrictions on the candidate models, MMA's AOP holds in a general continuous weight set under certain mild conditions. In the non-nested setting, a sufficient condition and a negative result are established for the achievability of the optimal MA risk. Implications on minimax adaptivity are given as well. The results from simulations back up our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13239v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingfu Peng, Yang Li, Yuhong Yang</dc:creator>
    </item>
    <item>
      <title>Dependence properties of bivariate copula families</title>
      <link>https://arxiv.org/abs/2310.17307</link>
      <description>arXiv:2310.17307v3 Announce Type: replace 
Abstract: Motivated by recently investigated results on dependence measures and robust risk models, this paper provides an overview of dependence properties of many well-known bivariate copula families, where the focus is on the Schur order for conditional distributions, which has the fundamental property that minimal elements characterize independence and maximal elements characterize perfect directed dependence. We give conditions on copulas that imply the Schur ordering of the associated conditional distribution functions. For extreme-value copulas, we prove the equivalence of the lower orthant order, the Schur order for conditional distributions, and the pointwise order of the associated Pickands dependence functions. Further, we provide several tables and figures that list and illustrate various positive dependence and monotonicity properties of copula families, in particular, from classes of Archimedean, extreme-value, and elliptical copulas. Finally, for Chatterjee's rank correlation, which is consistent with the Schur order for conditional distributions, we give some new closed-form formulas in terms of the parameter of the underlying copula family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17307v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Ansari, Marcus Rockel</dc:creator>
    </item>
    <item>
      <title>Optimal linear prediction with functional observations: Why you can use a simple post-dimension reduction estimator</title>
      <link>https://arxiv.org/abs/2401.06326</link>
      <description>arXiv:2401.06326v2 Announce Type: replace 
Abstract: This paper investigates optimal linear prediction for a random function in an infinite-dimensional Hilbert space. We analyze the mean square prediction error (MSPE) associated with a linear predictor, revealing that non-unique solutions that minimize the MSPE generally exist and consistent estimation is often impossible even if a unique solution exists. However, we show that defining asymptotically optimal linear operators, whose empirical MSPEs approach the minimal achievable level, is feasible. Remarkably, standard post-dimension reduction estimators, widely employed in the literature, achieve this asymptotic optimality under minimal conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06326v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Won-Ki Seo</dc:creator>
    </item>
    <item>
      <title>Maximum a posteriori testing in statistical inverse problems</title>
      <link>https://arxiv.org/abs/2402.00686</link>
      <description>arXiv:2402.00686v2 Announce Type: replace 
Abstract: This paper is concerned with a Bayesian approach to testing hypotheses in statistical inverse problems. Based on the posterior distribution $\Pi \left(\cdot |Y = y\right)$, we want to infer whether a feature $\langle\varphi, u^\dagger\rangle$ of the unknown quantity of interest $u^\dagger$ is positive. This can be done by the so-called maximum a posteriori test. We provide a frequentistic analysis of this test's properties such as level and power, and prove that it is a regularized test in the sense of Kretschmann et al. (2024). Furthermore we provide lower bounds for its power under classical spectral source conditions in case of Gaussian priors. Numerical simulations illustrate its superior performance both in moderately and severely ill-posed situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00686v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Remo Kretschmann, Frank Werner</dc:creator>
    </item>
    <item>
      <title>Estimators for multivariate allometric regression model</title>
      <link>https://arxiv.org/abs/2402.11219</link>
      <description>arXiv:2402.11219v3 Announce Type: replace 
Abstract: In a regression model with multiple response variables and multiple explanatory variables, if the difference of the mean vectors of the response variables for different values of explanatory variables is always in the direction of the first principal eigenvector of the covariance matrix of the response variables, then it is called a multivariate allometric regression model. This paper studies the estimation of the first principal eigenvector in the multivariate allometric regression model. A class of estimators that includes conventional estimators is proposed based on weighted sum-of-squares matrices of regression sum-of-squares matrix and residual sum-of-squares matrix. We establish an upper bound of the mean squared error of the estimators contained in this class, and the weight value minimizing the upper bound is derived. Sufficient conditions for the consistency of the estimators are discussed in weak identifiability regimes under which the difference of the largest and second largest eigenvalues of the covariance matrix decays asymptotically and in "large $p$, large $n$" regimes, where $p$ is the number of response variables and $n$ is the sample size. Several numerical results are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11219v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koji Tsukuda, Shun Matsuura</dc:creator>
    </item>
    <item>
      <title>Sparse maximum likelihood estimation for regression models</title>
      <link>https://arxiv.org/abs/2403.09081</link>
      <description>arXiv:2403.09081v2 Announce Type: replace 
Abstract: For regression model selection via maximum likelihood estimation, we adopt a vector representation of candidate models and study the likelihood ratio confidence region for the regression parameter vector of a full model. We show that when its confidence level increases with the sample size at a certain speed, with probability tending to one, the confidence region consists of vectors representing models containing all active variables, including the true parameter vector of the full model. Using this result, we examine the asymptotic composition of models of maximum likelihood and find the subset of such models that contain all active variables. We then devise a consistent model selection criterion which has a sparse maximum likelihood estimation interpretation and certain advantages over popular information criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09081v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Tsao</dc:creator>
    </item>
    <item>
      <title>Extreme change-point detection</title>
      <link>https://arxiv.org/abs/2403.19237</link>
      <description>arXiv:2403.19237v2 Announce Type: replace 
Abstract: We examine rules for predicting whether a point in $\mathbb{R}$ generated from a 50-50 mixture of two different probability distributions came from one distribution or the other, given limited (or no) information on the two distributions, and, as clues, one point generated randomly from each of the two distributions. We prove that nearest-neighbor prediction does better than chance when we know the two distributions are Gaussian densities without knowing their parameter values. We conjecture that this result holds for general probability distributions and, furthermore, that the nearest-neighbor rule is optimal in this setting, i.e., no other rule can do better than it if we do not know the distributions or do not know their parameters, or both.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19237v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Bleakley (CELESTE, LMO)</dc:creator>
    </item>
    <item>
      <title>Multivariate Trend Filtering for Lattice Data</title>
      <link>https://arxiv.org/abs/2112.14758</link>
      <description>arXiv:2112.14758v2 Announce Type: replace-cross 
Abstract: We study a multivariate version of trend filtering, called Kronecker trend filtering or KTF, for the case in which the design points form a lattice in $d$ dimensions. KTF is a natural extension of univariate trend filtering (Steidl et al., 2006; Kim et al., 2009; Tibshirani, 2014), and is defined by minimizing a penalized least squares problem whose penalty term sums the absolute (higher-order) differences of the parameter to be estimated along each of the coordinate directions. The corresponding penalty operator can be written in terms of Kronecker products of univariate trend filtering penalty operators, hence the name Kronecker trend filtering. Equivalently, one can view KTF in terms of an $\ell_1$-penalized basis regression problem where the basis functions are tensor products of falling factorial functions, a piecewise polynomial (discrete spline) basis that underlies univariate trend filtering.
  This paper is a unification and extension of the results in Sadhanala et al. (2016, 2017). We develop a complete set of theoretical results that describe the behavior of $k^{\mathrm{th}}$ order Kronecker trend filtering in $d$ dimensions, for every $k \geq 0$ and $d \geq 1$. This reveals a number of interesting phenomena, including the dominance of KTF over linear smoothers in estimating heterogeneously smooth functions, and a phase transition at $d=2(k+1)$, a boundary past which (on the high dimension-to-smoothness side) linear smoothers fail to be consistent entirely. We also leverage recent results on discrete splines from Tibshirani (2020), in particular, discrete spline interpolation results that enable us to extend the KTF estimate to any off-lattice location in constant-time (independent of the size of the lattice $n$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.14758v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Veeranjaneyulu Sadhanala, Yu-Xiang Wang, Addison J. Hu, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Subspace Phase Retrieval</title>
      <link>https://arxiv.org/abs/2206.02480</link>
      <description>arXiv:2206.02480v5 Announce Type: replace-cross 
Abstract: In recent years, phase retrieval has received much attention in statistics, applied mathematics and optical engineering. In this paper, we propose an efficient algorithm, termed Subspace Phase Retrieval (SPR), which can accurately recover an $n$-dimensional $k$-sparse complex-valued signal $\x$ given its $\Omega(k^2\log n)$ magnitude-only Gaussian samples if the minimum nonzero entry of $\x$ satisfies $|x_{\min}| = \Omega(\|\x\|/\sqrt{k})$. Furthermore, if the energy sum of the most significant $\sqrt{k}$ elements in $\x$ is comparable to $\|\x\|^2$, the SPR algorithm can exactly recover $\x$ with $\Omega(k \log n)$ magnitude-only samples, which attains the information-theoretic sampling complexity for sparse phase retrieval. Numerical Experiments demonstrate that the proposed algorithm achieves the state-of-the-art reconstruction performance compared to existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.02480v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2024.3386821</arxiv:DOI>
      <dc:creator>Mengchu Xu, Dekuan Dong, Jian Wang</dc:creator>
    </item>
  </channel>
</rss>
