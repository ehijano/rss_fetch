<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Mar 2024 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 21 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient k-step Weighted Reachability Query Processing Algorithms</title>
      <link>https://arxiv.org/abs/2403.13181</link>
      <description>arXiv:2403.13181v1 Announce Type: new 
Abstract: Given a data graph G, a source vertex u and a target vertex v of a reachability query, the reachability query is used to answer whether there exists a path from u to v in G. Reachability query processing is one of the fundamental operations in graph data management, which is widely used in biological networks, communication networks, and social networks to assist data analysis. The data graphs in practical applications usually contain information such as quantization weights associated with the structural relationships, in addition to the structural relationships between vertices. Thus, in addition to the traditional reachability relationships, users may want to further understand whether such reachability relationships satisfy specific constraints. In this paper, we study the problem of efficiently processing k -step reachability queries with weighted constraints in weighted graphs. The k -step weighted reachability query questions are used to answer the question of whether there exists a path from a source vertex u to a goal vertex v in a given weighted graph. If it exists, the path needs to satisfy 1) all edges in the path satisfy the given weight constraints, and 2) the length of the path does not exceed the given distance threshold k. To address the problem, firstly, WKRI index supporting k -step weighted reachability query processing and index construction methods based on efficient pruning strategies are proposed. Secondly, the idea of constructing index based on part of the vertexs is proposed to reduce the size of the index. We design and implement two optimized indexes GWKRI and LWKRI based on the vertex coverage set. Finally, experiments are conducted on several real datasets. The experimental results verify the efficiency of the method proposed in this paper in answering k -step weighted reachability queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13181v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lian Chen, Junfeng Zhou, Ming Du, Sheng Yu, Xian Tang, Ziyang Chen</dc:creator>
    </item>
    <item>
      <title>Distance Comparison Operators for Approximate Nearest Neighbor Search: Exploration and Benchmark</title>
      <link>https://arxiv.org/abs/2403.13491</link>
      <description>arXiv:2403.13491v1 Announce Type: new 
Abstract: Approximate nearest neighbor search (ANNS) on high-dimensional vectors has become a fundamental and essential component in various machine learning tasks. Prior research has shown that the distance comparison operation is the bottleneck of ANNS, which determines the query and indexing performance. To overcome this challenge, some novel methods have been proposed recently. The basic idea is to estimate the actual distance with fewer calculations, at the cost of accuracy loss. Inspired by this, we also propose that some classical techniques and deep learning models can also be adapted to this purpose. In this paper, we systematically categorize the techniques that have been or can be used to accelerate distance approximation. And to help the users understand the pros and cons of different techniques, we design a fair and comprehensive benchmark, Fudist implements these techniques with the same base index and evaluates them on 16 real datasets with several evaluation metrics. Designed as an independent and portable library, Fudist is orthogonal to the specific index structure and thus can be easily utilized in the current ANNS library to achieve significant improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13491v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Wang, Haoran Xiong, Zhenying He, Peng Wang, Wei wang</dc:creator>
    </item>
    <item>
      <title>No more optimization rules: LLM-enabled policy-based multi-modal query optimizer (version 1)</title>
      <link>https://arxiv.org/abs/2403.13597</link>
      <description>arXiv:2403.13597v1 Announce Type: new 
Abstract: Large language model (LLM) has marked a pivotal moment in the field of machine learning and deep learning. Recently its capability for query planning has been investigated, including both single-modal and multi-modal queries. However, there is no work on the query optimization capability of LLM. As a critical (or could even be the most important) step that significantly impacts the execution performance of the query plan, such analysis and attempts should not be missed. From another aspect, existing query optimizers are usually rule-based or rule-based + cost-based, i.e., they are dependent on manually created rules to complete the query plan rewrite/transformation. Given the fact that modern optimizers include hundreds to thousands of rules, designing a multi-modal query optimizer following a similar way is significantly time-consuming since we will have to enumerate as many multi-modal optimization rules as possible, which has not been well addressed today. In this paper, we investigate the query optimization ability of LLM and use LLM to design LaPuda, a novel LLM and Policy based multi-modal query optimizer. Instead of enumerating specific and detailed rules, LaPuda only needs a few abstract policies to guide LLM in the optimization, by which much time and human effort are saved. Furthermore, to prevent LLM from making mistakes or negative optimization, we borrow the idea of gradient descent and propose a guided cost descent (GCD) algorithm to perform the optimization, such that the optimization can be kept in the correct direction. In our evaluation, our methods consistently outperform the baselines in most cases. For example, the optimized plans generated by our methods result in 1~3x higher execution speed than those by the baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13597v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wang, Haodi Ma, Daisy Zhe Wang</dc:creator>
    </item>
    <item>
      <title>Overview of Publicly Available Degradation Data Sets for Tasks within Prognostics and Health Management</title>
      <link>https://arxiv.org/abs/2403.13694</link>
      <description>arXiv:2403.13694v1 Announce Type: new 
Abstract: Central to the efficacy of prognostics and health management methods is the acquisition and analysis of degradation data, which encapsulates the evolving health condition of engineering systems over time. Degradation data serves as a rich source of information, offering invaluable insights into the underlying degradation processes, failure modes, and performance trends of engineering systems. This paper provides an overview of publicly available degradation data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13694v1</guid>
      <category>cs.DB</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Mauthe, Christopher Braun, Julian Raible, Peter Zeiler, Marco F. Huber</dc:creator>
    </item>
    <item>
      <title>Unifews: Unified Entry-Wise Sparsification for Efficient Graph Neural Network</title>
      <link>https://arxiv.org/abs/2403.13268</link>
      <description>arXiv:2403.13268v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) have shown promising performance in various graph learning tasks, but at the cost of resource-intensive computations. The primary overhead of GNN update stems from graph propagation and weight transformation, both involving operations on graph-scale matrices. Previous studies attempt to reduce the computational budget by leveraging graph-level or network-level sparsification techniques, resulting in downsized graph or weights. In this work, we propose Unifews, which unifies the two operations in an entry-wise manner considering individual matrix elements, and conducts joint edge-weight sparsification to enhance learning efficiency. The entry-wise design of Unifews enables adaptive compression across GNN layers with progressively increased sparsity, and is applicable to a variety of architectural designs with on-the-fly operation simplification. Theoretically, we establish a novel framework to characterize sparsified GNN learning in view of a graph optimization process, and prove that Unifews effectively approximates the learning objective with bounded error and reduced computational load. We conduct extensive experiments to evaluate the performance of our method in diverse settings. Unifews is advantageous in jointly removing more than 90% of edges and weight entries with comparable or better accuracy than baseline models. The sparsification offers remarkable efficiency improvements including 10-20x matrix operation reduction and up to 100x acceleration in graph propagation time for the largest graph at the billion-edge scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13268v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ningyi Liao, Zihao Yu, Siqiang Luo</dc:creator>
    </item>
    <item>
      <title>A Sampling-based Framework for Hypothesis Testing on Large Attributed Graphs</title>
      <link>https://arxiv.org/abs/2403.13286</link>
      <description>arXiv:2403.13286v1 Announce Type: cross 
Abstract: Hypothesis testing is a statistical method used to draw conclusions about populations from sample data, typically represented in tables. With the prevalence of graph representations in real-life applications, hypothesis testing in graphs is gaining importance. In this work, we formalize node, edge, and path hypotheses in attributed graphs. We develop a sampling-based hypothesis testing framework, which can accommodate existing hypothesis-agnostic graph sampling methods. To achieve accurate and efficient sampling, we then propose a Path-Hypothesis-Aware SamplEr, PHASE, an m- dimensional random walk that accounts for the paths specified in a hypothesis. We further optimize its time efficiency and propose PHASEopt. Experiments on real datasets demonstrate the ability of our framework to leverage common graph sampling methods for hypothesis testing, and the superiority of hypothesis-aware sampling in terms of accuracy and time efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13286v1</guid>
      <category>stat.ML</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yun Wang, Chrysanthi Kosyfaki, Sihem Amer-Yahia, Reynold Cheng</dc:creator>
    </item>
    <item>
      <title>Secure Query Processing with Linear Complexity</title>
      <link>https://arxiv.org/abs/2403.13492</link>
      <description>arXiv:2403.13492v1 Announce Type: cross 
Abstract: We present LINQ, the first join protocol with linear complexity (in both running time and communication) under the secure multi-party computation model (MPC). It can also be extended to support all free-connex queries, a large class of select-join-aggregate queries, still with linear complexity. This matches the plaintext result for the query processing problem, as free-connex queries are the largest class of queries known to be solvable in linear time in plaintext. We have then built a query processing system based on LINQ, and the experimental results show that LINQ significantly outperforms the state of the art. For example, it can finish a query on three relations with an output size of 1 million tuples in around 100s in the LAN setting, while existing protocols that support the query cannot finish in an hour. Thus LINQ brings MPC query processing closer to practicality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13492v1</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyao Luo, Yilei Wang, Wei Dong, Ke Yi</dc:creator>
    </item>
    <item>
      <title>CheckMate: Evaluating Checkpointing Protocols for Streaming Dataflows</title>
      <link>https://arxiv.org/abs/2403.13629</link>
      <description>arXiv:2403.13629v1 Announce Type: cross 
Abstract: Stream processing in the last decade has seen broad adoption in both commercial and research settings. One key element for this success is the ability of modern stream processors to handle failures while ensuring exactly-once processing guarantees. At the moment of writing, virtually all stream processors that guarantee exactly-once processing implement a variant of Apache Flink's coordinated checkpoints - an extension of the original Chandy-Lamport checkpoints from 1985. However, the reasons behind this prevalence of the coordinated approach remain anecdotal, as reported by practitioners of the stream processing community. At the same time, common checkpointing approaches, such as the uncoordinated and the communication-induced ones, remain largely unexplored.
  This paper is the first to address this gap by i) shedding light on why practitioners have favored the coordinated approach and ii) by investigating whether there are viable alternatives. To this end, we implement three checkpointing approaches that we surveyed and adapted for the distinct needs of streaming dataflows. Our analysis shows that the coordinated approach outperforms the uncoordinated and communication-induced protocols under uniformly distributed workloads. To our surprise, however, the uncoordinated approach is not only competitive to the coordinated one in uniformly distributed workloads, but it also outperforms the coordinated approach in skewed workloads. We conclude that rather than blindly employing coordinated checkpointing, research should focus on optimizing the very promising uncoordinated approach, as it can address issues with skew and support prevalent cyclic queries. We believe that our findings can trigger further research into checkpointing mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13629v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>George Siachamis, Kyriakos Psarakis, Marios Fragkoulis, Arie van Deursen, Paris Carbone, Asterios Katsifodimos</dc:creator>
    </item>
    <item>
      <title>WaZI: A Learned and Workload-aware Z-Index</title>
      <link>https://arxiv.org/abs/2310.04268</link>
      <description>arXiv:2310.04268v3 Announce Type: replace 
Abstract: Learned indexes fit machine learning (ML) models to the data and use them to make query operations more time and space-efficient. Recent works propose using learned spatial indexes to improve spatial query performance by optimizing the storage layout or internal search structures according to the data distribution. However, only a few learned indexes exploit the query workload distribution to enhance their performance. In addition, building and updating learned spatial indexes are often costly on large datasets due to the inefficiency of (re)training ML models. In this paper, we present WaZI, a learned and workload-aware variant of the Z-index, which jointly optimizes the storage layout and search structures, as a viable solution for the above challenges of spatial indexing. Specifically, we first formulate a cost function to measure the performance of a Z-index on a dataset for a range-query workload. Then, we optimize the Z-index structure by minimizing the cost function through adaptive partitioning and ordering for index construction. Moreover, we design a novel page-skipping mechanism to improve the query performance of WaZI by reducing access to irrelevant data pages. Our extensive experiments show that the WaZI index improves range query time by 40% on average over the baselines while always performing better or comparably to state-of-the-art spatial indexes. Additionally, it also maintains good point query performance. Generally, WaZI provides favorable tradeoffs among query latency, construction time, and index size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04268v3</guid>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sachith Pai, Michael Mathioudakis, Yanhao Wang</dc:creator>
    </item>
    <item>
      <title>On enforcing dyadic-type homogeneous binary function product constraints in MatBase</title>
      <link>https://arxiv.org/abs/2312.06502</link>
      <description>arXiv:2312.06502v5 Announce Type: replace 
Abstract: Homogeneous binary function products are often encountered in the sub-universes modeled by databases, from genealogical trees to sports, from education to healthcare, etc. Their properties must be discovered and enforced by the software applications managing such data to guarantee plausibility. The (Elementary) Mathematical Data Model provides 18 dyadic-type homogeneous binary function product constraint types. MatBase, an intelligent data and knowledge base management system prototype, allows database designers to simply declare them by only clicking corresponding checkboxes and automatically generates code for enforcing them. This paper describes the algorithms that MatBase uses for enforcing all these 18 homogeneous binary function product constraint types, which may also be used by developers not having access to MatBase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06502v5</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.30564/jcsr.v6i1.6227</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computer Science Research | Volume 06 | Issue 01 | January 2024</arxiv:journal_reference>
      <dc:creator>Christian Mancas</dc:creator>
    </item>
  </channel>
</rss>
