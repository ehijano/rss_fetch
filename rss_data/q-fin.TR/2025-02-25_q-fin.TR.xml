<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.TR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.TR</link>
    <description>q-fin.TR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.TR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2025 05:05:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>LLM Trading: Analysis of LLM Agent Behavior in Experimental Asset Markets</title>
      <link>https://arxiv.org/abs/2502.15800</link>
      <description>arXiv:2502.15800v1 Announce Type: new 
Abstract: This paper explores how Large Language Models (LLMs) behave in a classic experimental finance paradigm widely known for eliciting bubbles and crashes in human participants. We adapt an established trading design, where traders buy and sell a risky asset with a known fundamental value, and introduce several LLM-based agents, both in single-model markets (all traders are instances of the same LLM) and in mixed-model "battle royale" settings (multiple LLMs competing in the same market). Our findings reveal that LLMs generally exhibit a "textbook-rational" approach, pricing the asset near its fundamental value, and show only a muted tendency toward bubble formation. Further analyses indicate that LLM-based agents display less trading strategy variance in contrast to humans. Taken together, these results highlight the risk of relying on LLM-only data to replicate human-driven market phenomena, as key behavioral features, such as large emergent bubbles, were not robustly reproduced. While LLMs clearly possess the capacity for strategic decision-making, their relative consistency and rationality suggest that they do not accurately mimic human market dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15800v1</guid>
      <category>q-fin.TR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Henning, Siddhartha M. Ojha, Ross Spoon, Jiatong Han, Colin F. Camerer</dc:creator>
    </item>
    <item>
      <title>The "double" square-root law: Evidence for the mechanical origin of market impact using Tokyo Stock Exchange data</title>
      <link>https://arxiv.org/abs/2502.16246</link>
      <description>arXiv:2502.16246v1 Announce Type: new 
Abstract: Understanding the impact of trades on prices is a crucial question for both academic research and industry practice. It is well established that impact follows a square-root impact as a function of traded volume. However, the microscopic origin of such a law remains elusive: empirical studies are particularly challenging due to the anonymity of orders in public data. Indeed, there is ongoing debate about whether price impact has a mechanical origin or whether it is primarily driven by information, as suggested by many economic theories. In this paper, we revisit this question using a very detailed dataset provided by the Japanese stock exchange, containing the trader IDs for all orders sent to the exchange between 2012 and 2018. Our central result is that such a law has in fact microscopic roots and applies already at the level of single child orders, provided one waits long enough for the market to "digest" them. The mesoscopic impact of metaorders arises from a "double" square-root effect: square-root in volume of individual impact, followed by an inverse square-root decay as a function of time. Since market orders are anonymous, we expect and indeed find that these results apply to any market orders, and the impact of synthetic metaorders, reconstructed by scrambling the identity of the issuers, is described by the very same square-root impact law. We conclude that price impact is essentially mechanical, at odds with theories that emphasize the information content of such trades to explain the square-root impact law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16246v1</guid>
      <category>q-fin.TR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Maitrier, Gr\'egoire Loeper, Kiyoshi Kanazawa, Jean-Philippe Bouchaud</dc:creator>
    </item>
    <item>
      <title>Currency Arbitrage Optimization using Quantum Annealing, QAOA and Constraint Mapping</title>
      <link>https://arxiv.org/abs/2502.15742</link>
      <description>arXiv:2502.15742v1 Announce Type: cross 
Abstract: Currency arbitrage capitalizes on price discrepancies in currency exchange rates between markets to produce profits with minimal risk. By employing a combinatorial optimization problem, one can ascertain optimal paths within directed graphs, thereby facilitating the efficient identification of profitable trading routes. This research investigates the methodologies of quantum annealing and gate-based quantum computing in relation to the currency arbitrage problem. In this study, we implement the Quantum Approximate Optimization Algorithm (QAOA) utilizing Qiskit version 1.2. In order to optimize the parameters of QAOA, we perform simulations utilizing the AerSimulator and carry out experiments in simulation. Furthermore, we present an NchooseK-based methodology utilizing D-Wave's Ocean suite. This methodology enables a comparison of the effectiveness of quantum techniques in identifying optimal arbitrage paths. The results of our study enhance the existing literature on the application of quantum computing in financial optimization challenges, emphasizing both the prospective benefits and the present limitations of these developing technologies in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15742v1</guid>
      <category>q-fin.CP</category>
      <category>math.OC</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sangram Deshpande, Elin Ranjan Das, Frank Mueller</dc:creator>
    </item>
    <item>
      <title>TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data</title>
      <link>https://arxiv.org/abs/2502.15757</link>
      <description>arXiv:2502.15757v1 Announce Type: cross 
Abstract: Stock Price Trend Prediction (SPTP) based on Limit Order Book (LOB) data is a fundamental challenge in financial markets. Despite advances in deep learning, existing models fail to generalize across different market conditions and struggle to reliably predict short-term trends. Surprisingly, by adapting a simple MLP-based architecture to LOB, we show that we surpass SoTA performance; thus, challenging the necessity of complex architectures. Unlike past work that shows robustness issues, we propose TLOB, a transformer-based model that uses a dual attention mechanism to capture spatial and temporal dependencies in LOB data. This allows it to adaptively focus on the market microstructure, making it particularly effective for longer-horizon predictions and volatile market conditions. We also introduce a new labeling method that improves on previous ones, removing the horizon bias. To assess TLOB's effectiveness, we evaluate it on the well-known FI-2010 benchmark (F1 of 92.8\%) and on Tesla (+2.67\% on F1) and Intel (+14.16\% on F1). Additionally, we empirically show how stock price predictability has declined over time (-6.68 absolute points in F1), highlighting the growing market efficiencies. Predictability must be considered in relation to transaction costs, so we experimented with defining trends using an average spread, reflecting the primary transaction cost. The resulting performance deterioration underscores the complexity of translating trend classification into profitable trading strategies. We argue that our work provides new insights into the evolving landscape of stock price trend prediction and sets a strong foundation for future advancements in financial AI. We release the code at github.com/LeonardoBerti00/TLOB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15757v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Leonardo Berti, Gjergji Kasneci</dc:creator>
    </item>
    <item>
      <title>Quantitative Trading using Deep Q Learning</title>
      <link>https://arxiv.org/abs/2304.06037</link>
      <description>arXiv:2304.06037v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) is a subfield of machine learning that has been used in many fields, such as robotics, gaming, and autonomous systems. There has been growing interest in using RL for quantitative trading, where the goal is to make trades that generate profits in financial markets. This paper presents the use of RL for quantitative trading and reports a case study based on an RL-based trading algorithm. The results show that RL can be a useful tool for quantitative trading and can perform better than traditional trading algorithms. The use of reinforcement learning for quantitative trading is a promising area of research that can help develop more sophisticated and efficient trading systems. Future research can explore the use of other reinforcement learning techniques, the use of other data sources, and the testing of the system on a range of asset classes. Together, our work shows the potential in the use of reinforcement learning for quantitative trading and the need for further research and development in this area. By developing the sophistication and efficiency of trading systems, it may be possible to make financial markets more efficient and generate higher returns for investors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06037v2</guid>
      <category>q-fin.TR</category>
      <category>cs.LG</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.22214/ijraset.2023.50170</arxiv:DOI>
      <dc:creator>Soumyadip Sarkar</dc:creator>
    </item>
    <item>
      <title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
      <link>https://arxiv.org/abs/2412.20138</link>
      <description>arXiv:2412.20138v4 Announce Type: replace 
Abstract: Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/TradingAgents-AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20138v4</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijia Xiao, Edward Sun, Di Luo, Wei Wang</dc:creator>
    </item>
  </channel>
</rss>
