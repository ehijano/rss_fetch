<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Nov 2025 02:47:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reconstructing Sets of Strings from Their k-way Projections: Algorithms &amp; Complexity</title>
      <link>https://arxiv.org/abs/2511.17707</link>
      <description>arXiv:2511.17707v1 Announce Type: new 
Abstract: Graphs are a powerful tool for analyzing large data sets, but many real-world phenomena involve interactions that go beyond the simple pairwise relationships captured by a graph. In this paper we introduce and study a simple combinatorial model to capture higher order dependencies from an algorithms and computational complexity perspective. Specifically, we introduce the String Set Reconstruction problem, which asks when a set of strings can be reconstructed from seeing only the k-way projections of strings in the set. This problem is distinguished from genetic reconstruction problems in that we allow projections from any k indices and we maintain knowledge of those indices, but not which k-mer came from which string. We give several results on the complexity of this problem, including hardness results, inapproximability, and parametrized complexity.
  Our main result is the introduction of a new algorithm for this problem using a modified version of overlap graphs from genetic reconstruction algorithms. A key difference we must overcome is that in our setting the k-mers need not be contiguous, unlike the setting of genetic reconstruction. We exhibit our algorithm's efficiency in a variety of experiments, and give high-level explanations for how its complexity is observed to scale with various parameters. We back up these explanation with analytic approximations. We also consider the related problems of: whether a single string can be reconstructed from the k-way projections of a given set of strings, and finding the largest k at which we get no information about the original data set from its k-way projections (i.e., the largest $k$ for which it is "k-wise independent").</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17707v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elise Tate, Joshua A. Grochow</dc:creator>
    </item>
    <item>
      <title>From Hop Reduction to Sparsification for Negative Length Shortest Paths</title>
      <link>https://arxiv.org/abs/2511.18253</link>
      <description>arXiv:2511.18253v1 Announce Type: new 
Abstract: The textbook algorithm for real-weighted single-source shortest paths takes $O(m n)$ time on a graph with $m$ edges and $n$ vertices. A recent breakthrough algorithm by [Fin24] takes $\tilde{O}(m n^{8/9})$ randomized time. The running time was subsequently improved to $\tilde{O}(mn^{4/5})$ [HJQ25] and then $\tilde{O}(m n^{3/4} + m^{4/5} n)$ [HJQ26].
  We build on the algorithms of [Fin24, HJQ25, HJQ26] to obtain faster strongly-polynomial randomized-time algorithms for negative-length shortest paths. An important new technique in this algorithm repurposes previous "hop-reducers" from [Fin24, HJQ26] into "negative edge sparsifiers", reducing the number of negative edges by essentially the same factor by which the "hops" were previously reduced. A simple recursive algorithm based on sparsifying the layered hop reducers of [Fin24] already gives an $\tilde{O}(m n^{\smash{\sqrt{3}}-1}) &lt; O(mn^{.7321})$ randomized running time, improving [HJQ26] uniformly.
  We also improve the construction of the bootstrapped hop reducers in [HJQ26] by proposing new sparse shortcut graphs replacing the dense shortcut graphs in [HJQ26]. Integrating all three of layered sparsification, recursion, and sparse bootstrapping into the algorithm of [HJQ26] gives new upper bounds of $O(mn^{.7193})$ randomized time for $m \geq n^{1.03456}$ and $O((mn)^{.8620})$ randomized time for $m \leq n^{1.03456}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18253v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kent Quanrud, Navid Tajkhorshid</dc:creator>
    </item>
    <item>
      <title>Approximating maximum properly colored forests via degree bounded independent sets</title>
      <link>https://arxiv.org/abs/2511.18263</link>
      <description>arXiv:2511.18263v1 Announce Type: new 
Abstract: In the Maximum-size Properly Colored Forest problem, we are given an edge-colored undirected graph and the goal is to find a properly colored forest with as many edges as possible. We study this problem within a broader framework by introducing the Maximum-size Degree Bounded Matroid Independent Set problem: given a matroid, a hypergraph on its ground set with maximum degree $\Delta$, and an upper bound $g(e)$ for each hyperedge $e$, the task is to find a maximum-size independent set that contains at most $g(e)$ elements from each hyperedge $e$. We present approximation algorithms for this problem whose guarantees depend only on $\Delta$. When applied to the Maximum-size Properly Colored Forest problem, this yields a $2/3$-approximation on multigraphs, improving the $5/9$ factor of Bai, B\'erczi, Cs\'aji, and Schwarcz [Eur. J. Comb. 132 (2026) 104269].</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18263v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhang Bai, Krist\'of B\'erczi, Johanna K. Siemelink</dc:creator>
    </item>
    <item>
      <title>Steiner Forest: A Simplified Better-Than-2 Approximation</title>
      <link>https://arxiv.org/abs/2511.18460</link>
      <description>arXiv:2511.18460v1 Announce Type: new 
Abstract: In the Steiner Forest problem, we are given a graph with edge lengths, and a collection of demand pairs; the goal is to find a subgraph of least total length such that each demand pair is connected in this subgraph. For over twenty years, the best approximation ratio known for the problem was a $2$-approximation due to Agrawal, Klein, and Ravi (STOC 1991), despite many attempts to surpass this bound. Finally, in a recent breakthrough, Ahmadi, Gholami, Hajiaghayi, Jabbarzade, and Mahdavi (FOCS 2025) gave a $2-\varepsilon$-approximation, where $\varepsilon \approx 10^{-11}$.
  In this work, we show how to simplify and extend the work of Ahmadi et al. to obtain an improved $1.994$-approximation. We combine some ideas from their work (e.g., an extended run of the moat-growing primal-dual algorithm, and identifying autarkic pairs) with other ideas -- submodular maximization to find components to contract, as in the relative greedy algorithms for Steiner tree, and the use of autarkic triples. We hope that our cleaner abstraction will open the way for further improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18460v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Gupta, Vera Traub</dc:creator>
    </item>
    <item>
      <title>Weighted Chairman Assignment and Flow-Time Scheduling</title>
      <link>https://arxiv.org/abs/2511.18546</link>
      <description>arXiv:2511.18546v1 Announce Type: new 
Abstract: Given positive integers $m, n$, a fractional assignment $x \in [0,1]^{m \times n}$ and weights $d \in \mathbb{R}^n_{&gt;0}$, we show that there exists an assignment $y \in \{0,1\}^{m \times n}$ so that for every $i\in[m]$ and $t\in [n]$, \[ \Big|\sum_{j \in [t]} d_j (x_{ij} - y_{ij}) \Big| &lt; \max_{j \in [n]} d_j. \] This generalizes a result of Tijdeman (1973) on the unweighted version, known as the chairman assignment problem. This also confirms a special case of the single-source unsplittable flow conjecture with arc-wise lower and upper bounds due to Morell and Skutella (IPCO 2020). As an application, we consider a scheduling problem where jobs have release times and machines have closing times, and a job can only be scheduled on a machine if it is released before the machine closes. We give a $3$-approximation algorithm for maximum flow-time minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18546v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyue Liu, Victor Reis</dc:creator>
    </item>
    <item>
      <title>Online Smoothed Demand Management</title>
      <link>https://arxiv.org/abs/2511.18554</link>
      <description>arXiv:2511.18554v1 Announce Type: new 
Abstract: We introduce and study a class of online problems called online smoothed demand management $(\texttt{OSDM})$, motivated by paradigm shifts in grid integration and energy storage for large energy consumers such as data centers. In $\texttt{OSDM}$, an operator makes two decisions at each time step: an amount of energy to be purchased, and an amount of energy to be delivered (i.e., used for computation). The difference between these decisions charges (or discharges) the operator's energy storage (e.g., a battery). Two types of demand arrive online: base demand, which must be covered at the current time, and flexible demand, which can be satisfied at any time steps before a demand-specific deadline $\Delta_t$. The operator's goal is to minimize a cost (subject to the constraints above) that combines a cost of purchasing energy, a cost for delivering energy (if applicable), and smoothness penalties on the purchasing and delivery rates to discourage fluctuations and encourage ``grid healthy'' decisions. $\texttt{OSDM}$ generalizes several problems in the online algorithms literature while being the first to fully model applications of interest. We propose a competitive algorithm called $\texttt{PAAD}$ (partitioned accounting \&amp; aggregated decisions) and show it achieves the optimal competitive ratio. To overcome the pessimism typical of worst-case analysis, we also propose a novel learning framework that provides guarantees on the worst-case competitive ratio (i.e., to provide robustness against nonstationarity) while allowing end-to-end differentiable learning of the best algorithm on historical instances of the problem. We evaluate our algorithms in a case study of a grid-integrated data center with battery storage, showing that $\texttt{PAAD}$ effectively solves the problem and end-to-end learning achieves substantial performance improvements compared to $\texttt{PAAD}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18554v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Lechowicz, Nicolas Christianson, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy</dc:creator>
    </item>
    <item>
      <title>Overlap Analysis of the Shortest Path Problem: Local Search, Landscapes, and Franz--Parisi Potential</title>
      <link>https://arxiv.org/abs/2511.18666</link>
      <description>arXiv:2511.18666v1 Announce Type: new 
Abstract: Two directions in algorithms and complexity involve: (1) classifying which optimization problems can be solved in polynomial time, and (2) understanding which computational problems are hard to solve \emph{on average} in addition to the worst case. For many average-case problems, there does not currently exist strong evidence via reductions that they are hard. However, we can still attempt to predict their polynomial time tractability by proving lower bounds against restricted classes of algorithms.
  Geometric approaches to predicting tractability typically study the \emph{optimization landscape}. For optimization problems with random objectives or constraints, ideas originating in statistical physics suggest we should study the \emph{overlap} between approximately-optimal solutions. Formally, properties of \emph{Gibbs measures} and the \emph{Franz--Parisi potential} imply lower bounds against natural local search algorithms, such as Langevin dynamics. A related theory, the \emph{Overlap Gap Property (OGP)}, proves rigorous lower bounds against classes of algorithms which are stable functions of their input.
  A remarkable recent work of Li and Schramm showed that the shortest path problem in random graphs admits lower bounds against a class of stable algorithms, via the OGP. Yet this problem is polynomial time tractable. We further investigate this. We find that both the OGP and the Franz--Parisi potential predict that: (1) local search will fail in the optimization landscape of shortest paths, but (2) local search should succeed in the optimization landscape for shortest path \emph{trees}, which is true. Using the Franz--Parisi potential, we explain an analogy with results from combinatorial optimization -- submodular minimization is tractable via local search on the Lov\'asz extension, even though ``naive'' local search over sets or the multilinear extension provably fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18666v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederic Koehler, Joonhyung Shin</dc:creator>
    </item>
    <item>
      <title>A sufficient condition for characterizing the one-sided testable properties of families of graphs in the Random Neighbour Oracle Model</title>
      <link>https://arxiv.org/abs/2511.19027</link>
      <description>arXiv:2511.19027v1 Announce Type: new 
Abstract: We study property testing in the \emph{random neighbor oracle} model for graphs, originally introduced by Czumaj and Sohler [STOC 2019]. Specifically, we initiate the study of characterizing the graph families that are $H$-\emph{testable} in this model. A graph family $\mathcal{F}$ is $H$-testable if, for every graph $H$, $H$-\emph{freeness} (that is, not having a subgraph isomorphic to $H$) is testable with one-sided error on all inputs from $\mathcal{F}$.
  Czumaj and Sohler showed that for any $H$-testable family of graphs $\mathcal{F}$, the family of testable properties of $\mathcal{F}$ has a known characterization, a major goal in the study of property testing. Consequently, characterizing the collection of $H$-testable graph families will not only result in new characterizations, but will also exhaust this method of characterizing testable properties. We believe that our result is a substantial step towards this goal.
  Czumaj and Sohler further showed that the family of planar graphs is $H$-testable, as is any family of minor-free graphs. In this paper, we provide a sufficient and much broader criterion under which a family of graphs is $H$-testable. As a corollary, we obtain new characterizations for many families of graphs including: families that are closed under taking topological minors or immersions, geometric intersection graphs of low-density objects, euclidean nearest-neighbour graphs with bounded clique number, graphs with bounded crossing number (per edge), graphs with bounded queue- and stack number, and more.
  The criterion we provide is based on the \emph{$r$-admissibility} graph measure from the theory of sparse graph families initiated by Nesetril and Ossona de Mendez. Proving that specific families of graphs satisfy this criterion is an active area of research, consequently, the implications of this paper may be strengthened in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19027v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christine Awofeso, Patrick Greaves, Oded Lachish, Amit Levi, Felix Reidl</dc:creator>
    </item>
    <item>
      <title>New Algorithms and Hardness Results for Connected Clustering</title>
      <link>https://arxiv.org/abs/2511.19085</link>
      <description>arXiv:2511.19085v1 Announce Type: new 
Abstract: Connected clustering denotes a family of constrained clustering problems in which we are given a distance metric and an undirected connectivity graph $G$ that can be completely unrelated to the metric. The aim is to partition the $n$ vertices into a given number $k$ of clusters such that every cluster forms a connected subgraph of $G$ and a given clustering objective gets minimized. The constraint that the clusters are connected has applications in many different fields, like for example community detection and geodesy.
  So far, $k$-center and $k$-median have been studied in this setting. It has been shown that connected $k$-median is $\Omega(n^{1- \epsilon})$-hard to approximate which also carries over to the connected $k$-means problem, while for connected $k$-center it remained an open question whether one can find a constant approximation in polynomial time. We answer this question by providing an $\Omega(\log^*(k))$-hardness result for the problem. Given these hardness results, we study the problems on graphs with bounded treewidth. We provide exact algorithms that run in polynomial time if the treewidth $w$ is a constant. Furthermore, we obtain constant approximation algorithms that run in FPT time with respect to the parameter $\max(w,k)$.
  Additionally, we consider the min-sum-radii (MSR) and min-sum-diameter (MSD) objective. We prove that on general graphs connected MSR can be approximated with an approximation factor of $(3 + \epsilon)$ and connected MSD with an approximation factor of $(4 + \epsilon)$. The latter also directly improves the best known approximation guarantee for unconstrained MSD from $(6 + \epsilon)$ to $(4 + \epsilon)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19085v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Eube, Heiko R\"oglin</dc:creator>
    </item>
    <item>
      <title>Fast and Flexible Flow Decompositions in General Graphs via Dominators</title>
      <link>https://arxiv.org/abs/2511.19153</link>
      <description>arXiv:2511.19153v1 Announce Type: new 
Abstract: Multi-assembly methods rely at their core on a flow decomposition problem, namely, decomposing a weighted graph into weighted paths or walks. However, most results over the past decade have focused on decompositions over directed acyclic graphs (DAGs). This limitation has lead to either purely heuristic methods, or in applications transforming a graph with cycles into a DAG via preprocessing heuristics. In this paper we show that flow decomposition problems can be solved in practice also on general graphs with cycles, via a framework that yields fast and flexible Mixed Integer Linear Programming (MILP) formulations.
  Our key technique relies on the graph-theoretic notion of dominator tree, which we use to find all safe sequences of edges, that are guaranteed to appear in some walk of any flow decomposition solution. We generalize previous results from DAGs to cyclic graphs, by showing that maximal safe sequences correspond to extensions of common leaves of two dominator trees, and that we can find all of them in time linear in their size. Using these, we can accelerate MILPs for any flow decomposition into walks in general graphs, by setting to (at least) 1 suitable variables encoding solution walks, and by setting to 0 other walks variables non-reachable to and from safe sequences. This reduces model size and eliminates costly linearizations of MILP variable products.
  We experiment with three decomposition models (Minimum Flow Decomposition, Least Absolute Errors and Minimum Path Error), on four bacterial datasets. Our pre-processing enables up to thousand-fold speedups and solves even under 30 seconds many instances otherwise timing out. We thus hope that our dominator-based MILP simplification framework, and the accompanying software library can become building blocks in multi-assembly applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19153v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Sena, Alexandru I. Tomescu</dc:creator>
    </item>
    <item>
      <title>PTF Testing Lower Bounds for Non-Gaussian Component Analysis</title>
      <link>https://arxiv.org/abs/2511.19398</link>
      <description>arXiv:2511.19398v1 Announce Type: new 
Abstract: This work studies information-computation gaps for statistical problems. A common approach for providing evidence of such gaps is to show sample complexity lower bounds (that are stronger than the information-theoretic optimum) against natural models of computation. A popular such model in the literature is the family of low-degree polynomial tests. While these tests are defined in such a way that make them easy to analyze, the class of algorithms that they rule out is somewhat restricted. An important goal in this context has been to obtain lower bounds against the stronger and more natural class of low-degree Polynomial Threshold Function (PTF) tests, i.e., any test that can be expressed as comparing some low-degree polynomial of the data to a threshold. Proving lower bounds against PTF tests has turned out to be challenging. Indeed, we are not aware of any non-trivial PTF testing lower bounds in the literature.
  In this paper, we establish the first non-trivial PTF testing lower bounds for a range of statistical tasks. Specifically, we prove a near-optimal PTF testing lower bound for Non-Gaussian Component Analysis (NGCA). Our NGCA lower bound implies similar lower bounds for a number of other statistical problems. Our proof leverages a connection to recent work on pseudorandom generators for PTFs and recent techniques developed in that context. At the technical level, we develop several tools of independent interest, including novel structural results for analyzing the behavior of low-degree polynomials restricted to random directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19398v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Thanasis Pittas</dc:creator>
    </item>
    <item>
      <title>High-Accuracy List-Decodable Mean Estimation</title>
      <link>https://arxiv.org/abs/2511.17822</link>
      <description>arXiv:2511.17822v1 Announce Type: cross 
Abstract: In list-decodable learning, we are given a set of data points such that an $\alpha$-fraction of these points come from a nice distribution $D$, for some small $\alpha \ll 1$, and the goal is to output a short list of candidate solutions, such that at least one element of this list recovers some non-trivial information about $D$. By now, there is a large body of work on this topic; however, while many algorithms can achieve optimal list size in terms of $\alpha$, all known algorithms must incur error which decays, in some cases quite poorly, with $1 / \alpha$. In this paper, we ask if this is inherent: is it possible to trade off list size with accuracy in list-decodable learning? More formally, given $\epsilon &gt; 0$, can we can output a slightly larger list in terms of $\alpha$ and $\epsilon$, but so that one element of this list has error at most $\epsilon$ with the ground truth? We call this problem high-accuracy list-decodable learning. Our main result is that non-trivial high-accuracy guarantees, both information-theoretically and algorithmically, are possible for the canonical setting of list-decodable mean estimation of identity-covariance Gaussians. Specifically, we demonstrate that there exists a list of candidate means of size at most $L = \exp \left( O\left( \tfrac{\log^2 1 / \alpha}{\epsilon^2} \right)\right)$ so that one of the elements of this list has $\ell_2$ distance at most $\epsilon$ to the true mean. We also design an algorithm that outputs such a list with runtime and sample complexity $n = d^{O(\log L)} + \exp \exp (\widetilde{O}(\log L))$. We do so by demonstrating a completely novel proof of identifiability, as well as a new algorithmic way of leveraging this proof without the sum-of-squares hierarchy, which may be of independent technical interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17822v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyun Chen, Spencer Compton, Daniel Kane, Jerry Li</dc:creator>
    </item>
    <item>
      <title>The Mixed Birth-death/death-Birth Moran Process</title>
      <link>https://arxiv.org/abs/2511.18252</link>
      <description>arXiv:2511.18252v1 Announce Type: cross 
Abstract: We study evolutionary dynamics on graphs in which each step consists of one birth and one death, also known as the Moran processes. There are two types of individuals: residents with fitness $1$ and mutants with fitness $r$. Two standard update rules are used in the literature. In Birth-death (Bd), a vertex is chosen to reproduce proportional to fitness, and one of its neighbors is selected uniformly at random to be replaced by the offspring. In death-Birth (dB), a vertex is chosen uniformly to die, and then one of its neighbors is chosen, proportional to fitness, to place an offspring into the vacancy. We formalize and study a unified model, the $\lambda$-mixed Moran process, in which each step is independently a Bd step with probability $\lambda \in [0,1]$ and a dB step otherwise. We analyze this mixed process for undirected, connected graphs. As an interesting special case, we show at $\lambda=1/2$, for any graph that the fixation probability when $r=1$ with a single mutant initially on the graph is exactly $1/n$, and also at $\lambda=1/2$ that the absorption time for any $r$ is $O_r(n^4)$. We also show results for graphs that are "almost regular," in a manner defined in the paper. We use this to show that for suitable random graphs from $G \sim G(n,p)$ and fixed $r&gt;1$, with high probability over the choice of graph, the absorption time is $O_r(n^4)$, the fixation probability is $\Omega_r(n^{-2})$, and we can approximate the fixation probability in polynomial time. Another special case is when the graph has only two distinct degree values $\{d_1, d_2\}$ with $d_1 \leq d_2$. For those graphs, we give exact formulas for fixation probabilities when $r = 1$ and any $\lambda$, and establish an absorption time of $O_r(n^4 \alpha^4)$ for all $\lambda$, where $\alpha = d_2 / d_1$. We also provide explicit formulas for the star and cycle under any $r$ or $\lambda$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18252v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David A. Brewster, Yichen Huang, Michael Mitzenmacher, Martin A. Nowak</dc:creator>
    </item>
    <item>
      <title>Using random spanning trees in survivable networks design</title>
      <link>https://arxiv.org/abs/2511.19018</link>
      <description>arXiv:2511.19018v1 Announce Type: cross 
Abstract: We investigate a process of joining $k$ random spanning trees on a fixed clique $K_n$. The joined trees may not be disjoint and multiple edges are replaced by one simple edge. This process produces a simple graph $G$ on $n$~vertices with an edge set, which is a union of edge sets of the joined trees. We study a random variable $S_{k}$ of the number of edges in the generated graph $G$. The exact formula is derived for the expected value of the random variable $S_{k}$. In addition, an upper bound on the concentration coefficient of the random variable $S_{k}$ is provided. We use results of our analysis to design an algorithm to generate $k$-edge connected graphs for arbitrarily large values of $k \geq 2$. The designed algorithm solves a particular case of the Survivable Network Design Problem, where the cost of each edge is $c_{e} = 1$ and the connectivity requirement for each pair of vertices $u, v \in V(G)$ is $k$.The proposed algorithm is within a factor strictly less than $2$ of the optimal value (i.e., the number of edges in the generated graph) and its running time is $O(kn\log{n})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19018v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Blazej Wrobel, Dominik Bojko</dc:creator>
    </item>
    <item>
      <title>The TAG array of a multiple sequence alignment</title>
      <link>https://arxiv.org/abs/2511.19068</link>
      <description>arXiv:2511.19068v1 Announce Type: cross 
Abstract: Modern genomic analyses increasingly rely on pangenomes, that is, representations of the genome of entire populations. The simplest representation of a pangenome is a set of individual genome sequences. Compared to e.g. sequence graphs, this has the advantage that efficient exact search via indexes based on the Burrows-Wheeler Transform (BWT) is possible, that no chimeric sequences are created, and that the results are not influenced by heuristics. However, such an index may report a match in thousands of positions even if these all correspond to the same locus, making downstream analysis unnecessarily expensive. For sufficiently similar sequences (e.g. human chromosomes), a multiple sequence alignment (MSA) can be computed. Since an MSA tends to group similar strings in the same columns, it is likely that a string occurring thousands of times in the pangenome can be described by very few columns in the MSA. We describe a method to tag entries in the BWT with the corresponding column in the MSA and develop an index that can map matches in the BWT to columns in the MSA in time proportional to the output. As a by-product, we can efficiently project a match to a designated reference genome, a capability that current pangenome aligners based on the BWT lack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19068v1</guid>
      <category>q-bio.GN</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jannik Olbrich, Enno Ohlebusch</dc:creator>
    </item>
    <item>
      <title>Bipartiteness in Progressive Second-Price Multi-Auction Networks with Perfect Substitute</title>
      <link>https://arxiv.org/abs/2511.19225</link>
      <description>arXiv:2511.19225v1 Announce Type: cross 
Abstract: We consider a bipartite network of buyers and sellers, where the sellers run locally independent Progressive Second-Price (PSP) auctions, and buyers may participate in multiple auctions, forming a multi-auction market with perfect substitute. The paper develops a projection-based influence framework for decentralized PSP auctions. We formalize primary and expanded influence sets using projections on the active bid index set and show how partial orders on bid prices govern allocation, market shifts, and the emergence of saturated one-hop shells. Our results highlight the robustness of PSP auctions in decentralized environments by introducing saturated components and a structured framework for phase transitions in multi-auction dynamics. This structure ensures deterministic coverage of the strategy space, enabling stable and truthful embedding in the larger game. We further model intra-round dynamics using an index to capture coordinated asynchronous seller updates coupled through buyers' joint constraints. Together, these constructions explain how local interactions propagate across auctions and gives premise for coherent equilibria--without requiring global information or centralized control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19225v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordana Blazek, Frederick C. Harris Jr</dc:creator>
    </item>
    <item>
      <title>Double-Ended Palindromic Trees in Linear Time</title>
      <link>https://arxiv.org/abs/2210.02292</link>
      <description>arXiv:2210.02292v3 Announce Type: replace 
Abstract: The palindromic tree (a.k.a. eertree) is a data structure that provides access to all palindromic substrings of a string. In this paper, we propose a dynamic version of eertree, called double-ended eertree, which supports online operations on the stored string, including double-ended queue operations, counting distinct palindromic substrings, and finding the longest palindromic prefix/suffix. At the heart of our construction, we identify a new class of substring occurrences, called surfaces, that are palindromic substring occurrences that are neither prefixes nor suffixes of any other palindromic substring occurrences, which is of independent interest. Surfaces characterize the link structure of all palindromic substrings in the eertree, thereby allowing a linear-time implementation of double-ended eertrees through a linear-time maintenance of surfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.02292v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ic.2025.105379</arxiv:DOI>
      <arxiv:journal_reference>Information and Computation, 307: 105379, 2025</arxiv:journal_reference>
      <dc:creator>Qisheng Wang, Ming Yang, Xinrui Zhu</dc:creator>
    </item>
    <item>
      <title>Optimization with pattern-avoiding input</title>
      <link>https://arxiv.org/abs/2310.04236</link>
      <description>arXiv:2310.04236v4 Announce Type: replace 
Abstract: Permutation pattern-avoidance is a central concept of both enumerative and extremal combinatorics. In this paper we study the effect of permutation pattern-avoidance on the complexity of optimization problems.
  In the context of the dynamic optimality conjecture (Sleator, Tarjan, STOC 1983), Chalermsook, Goswami, Kozma, Mehlhorn, and Saranurak (FOCS 2015) conjectured that the amortized search cost of an optimal binary search tree (BST) is constant whenever the search sequence is pattern-avoiding. The best known bound to date is $2^{\alpha{(n)}(1+o(1))}$ recently obtained by Chalermsook, Pettie, and Yingchareonthawornchai (SODA 2024); here $n$ is the BST size and $\alpha(\cdot)$ the inverse-Ackermann function. In this paper we resolve the conjecture, showing a tight $O(1)$ bound. This indicates a barrier to dynamic optimality: any candidate online BST (e.g., splay trees or greedy trees) must match this optimum, but current analysis techniques only give superconstant bounds.
  More broadly, we argue that the easiness of pattern-avoiding input is a general phenomenon, not limited to BSTs or even to data structures. To illustrate this, we show that when the input avoids an arbitrary, fixed, a priori unknown pattern, one can efficiently compute a $k$-server solution of $n$ requests from a unit interval, with total cost $n^{O(1/\log k)}$, in contrast to the worst-case $\Theta(n/k)$ bound; and a traveling salesman tour of $n$ points from a unit box, of length $O(\log{n})$, in contrast to the worst-case $\Theta(\sqrt{n})$ bound; similar results hold for the euclidean minimum spanning tree, Steiner tree, and nearest-neighbor graphs.
  We show both results to be tight. Our techniques build on the Marcus-Tardos proof of the Stanley-Wilf conjecture, and on the recently emerging concept of twin-width.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04236v4</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Aram Berendsohn, L\'aszl\'o Kozma, Michal Opler</dc:creator>
    </item>
    <item>
      <title>Fast and Slow Mixing of the Kawasaki Dynamics on Bounded-Degree Graphs</title>
      <link>https://arxiv.org/abs/2405.06209</link>
      <description>arXiv:2405.06209v2 Announce Type: replace 
Abstract: We study the worst-case mixing time of the global Kawasaki dynamics for the fixed-magnetization Ising model on the class of graphs of maximum degree $\Delta$. Proving a conjecture of Carlson, Davies, Kolla, and Perkins, we show that below the tree uniqueness threshold, the Kawasaki dynamics mix rapidly for all magnetizations. Disproving a conjecture of Carlson, Davies, Kolla, and Perkins, we show that the regime of fast mixing does not extend throughout the regime of tractability for this model: there is a range of parameters for which there exist efficient sampling algorithms for the fixed-magnetization Ising model on max-degree $\Delta$ graphs, but the Kawasaki dynamics can take exponential time to mix. Our techniques involve showing spectral independence in the fixed-magnetization Ising model and proving a sharp threshold for the existence of multiple metastable states in the Ising model with external field on random regular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06209v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/rsa.70038</arxiv:DOI>
      <arxiv:journal_reference>Random Structures &amp; Algorithms. 67 (2025), no.4, e70038</arxiv:journal_reference>
      <dc:creator>Aiya Kuchukova, Marcus Pappik, Will Perkins, Corrine Yap</dc:creator>
    </item>
    <item>
      <title>Correcting the Foundational Analysis of Karp--Vazirani--Vazirani (STOC 1990): A Rigorous Revision of the $1-1/e$ Upper Bound</title>
      <link>https://arxiv.org/abs/2503.09530</link>
      <description>arXiv:2503.09530v2 Announce Type: replace 
Abstract: We revisit the classical analysis of Karp, Vazirani, and Vazirani (KVV, STOC~1990), which established the well-known upper bound of $1 - 1/e$ as the limiting proportion of vertices that can be matched by any online procedure in a canonical bipartite structure. Although foundational, the original analysis contains several inaccuracies, including a fundamental technical gap in the treatment of the underlying discrete process. We give a transparent and fully rigorous reconstruction of the KVV argument by reformulating the evolution of available neighbors as a discrete-time death process and deriving a sharp upper bound via a simple factor-revealing linear program that captures the correct recurrence structure. This yields a precise bound $\lceil n(1 - 1/e) + 2 - 1/e \rceil$ on the expected number of matched vertices, refining the classical claim $n(1 - 1/e) + o(n)$. Our goal is not to optimize this upper bound, but to provide a mathematically sound and conceptually clean correction of the classical KVV analysis, while remaining faithful to its original combinatorial framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09530v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pan Xu</dc:creator>
    </item>
    <item>
      <title>Optimal Approximations for the Requirement Cut Problem on Sparse Graph Classes</title>
      <link>https://arxiv.org/abs/2505.21433</link>
      <description>arXiv:2505.21433v4 Announce Type: replace 
Abstract: We study the Requirement Cut problem, a generalization of numerous classical graph partitioning problems including Multicut, Multiway Cut, $k$-Cut, and Steiner Multicut among others. Given a graph with edge costs, terminal groups $(S_1, ..., S_g)$ and integer requirements $(r_1,... , r_g)$; the goal is to compute a minimum-cost edge cut that separates each group $S_i$ into at least $r_i$ connected components. Despite many efforts, the best known approximation for Requirement Cut yields a double-logarithmic $O(\log(g).\log(n))$ approximation ratio as it relies on embedding general graphs into trees and solving the tree instance.
  In this paper, we explore two largely unstudied structural parameters in order to obtain single-logarithmic approximation ratios: (1) the number of minimal Steiner trees in the instance, which in particular is upper-bounded by the number of spanning trees of the graphs multiplied by $g$, and (2) the depth of series-parallel graphs. Specifically, we show that if the number of minimal Steiner trees is polynomial in $n$, then a simple LP-rounding algorithm yields an $O(\log n)$-approximation, and if the graph is series-parallel with a constant depth then a refined analysis of a known probabilistic embedding yields a $O(depth.\log(g))$-approximation on series-parallel graphs of bounded depth. Both results extend the known class of graphs that have a single-logarithmic approximation ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21433v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadym Mallek, Kirill Simonov</dc:creator>
    </item>
    <item>
      <title>Non-Adaptive Evaluation of $k$-of-$n$ Functions: Tight Gap and a Unit-Cost PTAS</title>
      <link>https://arxiv.org/abs/2507.05877</link>
      <description>arXiv:2507.05877v2 Announce Type: replace 
Abstract: We consider the Stochastic Boolean Function Evaluation (SBFE) problem in the well-studied case of $k$-of-$n$ functions: There are independent Boolean random variables $x_1,\dots,x_n$ where each variable $i$ has a known probability $p_i$ of taking value $1$, and a known cost $c_i$ that can be paid to find out its value. The value of the function is $1$ iff there are at least $k$ $1$s among the variables. The goal is to efficiently compute a strategy that, at minimum expected cost, tests the variables until the function value is determined. While an elegant polynomial-time exact algorithm is known when tests can be made adaptively, we focus on the non-adaptive variant, for which much less is known.
  First, we show a clean and tight lower bound of $2$ on the adaptivity gap, i.e., the worst-case multiplicative loss in the objective function caused by disallowing adaptivity, of the problem. This improves the tight lower bound of $3/2$ for the unit-cost variant.
  Second, we give a PTAS for computing the best non-adaptive strategy in the unit-cost case, the first PTAS for an SBFE problem. At the core, our scheme establishes a novel notion of two-sided dominance (w.r.t. the optimal solution) by guessing so-called milestone tests for a set of carefully chosen buckets of tests. To turn this technique into a polynomial-time algorithm, we use a decomposition approach paired with a random-shift argument.
  In fact, our PTAS extends to the class of arbitrary symmetric Boolean functions, which are Boolean functions whose value only depends on the number of $1$s among the input variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05877v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mads Anker Nielsen, Lars Rohwedder, Kevin Schewior</dc:creator>
    </item>
    <item>
      <title>Disjoint Tours and the Price of Diversity</title>
      <link>https://arxiv.org/abs/2507.13026</link>
      <description>arXiv:2507.13026v2 Announce Type: replace 
Abstract: We study a variant of the Traveling Salesman Problem, where instead of finding a single tour, we want to find a pair of two edge-disjoint tours whose longer tour is as short as possible. We investigate the Price of Diversity (PoD) for this problem, which is the ratio of the cost of the longer of the two tours and the cost of a single optimal tour, in the worst case over all possible instances. We prove (almost) tight bounds on this quantity for a special 1-dimensional scenario and for general metric spaces. We believe that the Price-of-Diversity framework that we introduce is interesting in its own right, and may lead to follow-up work on other problems as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13026v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark de Berg, Andr\'es L\'opez Mart\'inez, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>A Gentle Wakeup Call: Symmetry Breaking with Less Collision Cost</title>
      <link>https://arxiv.org/abs/2508.11006</link>
      <description>arXiv:2508.11006v3 Announce Type: replace 
Abstract: The wakeup problem addresses the fundamental challenge of symmetry breaking. Initially, n devices share a time-slotted multiple access channel, which models wireless communication. A transmission succeeds if exactly one device sends in a slot; if two or more transmit, a collision occurs and none succeed. The goal is to achieve a single successful transmission efficiently.
  Prior work on wakeup primarily analyzes latency -- the number of slots until the first success. However, in many modern systems, each collision incurs a nontrivial delay, C, which prior analyses neglect. Consequently, although existing algorithms achieve polylogarithmic-in-n latency, they still suffer a delay of \Omega(C) due to collisions.
  Here, we design and analyze a randomized wakeup algorithm, Aim-High. When C is sufficiently large with respect to n, Aim-High has expected latency and expected total cost of collisions that are nearly O(\sqrt{C}); otherwise, both quantities are O(poly{\log n}). Finally, for a well-studied class of algorithms, we establish a trade-off between latency and expected total cost of collisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11006v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umesh Biswas, Maxwell Young</dc:creator>
    </item>
    <item>
      <title>Engineering Algorithms for $\ell$-Isolated Maximal Clique Enumeration</title>
      <link>https://arxiv.org/abs/2511.03525</link>
      <description>arXiv:2511.03525v2 Announce Type: replace 
Abstract: Maximal cliques play a fundamental role in numerous application domains, where their enumeration can prove extremely useful. Yet their sheer number, even in sparse real-world graphs, can make them impractical to be exploited effectively. To address this issue, one approach is to enumerate $\ell$-isolated maximal cliques, whose vertices have (on average) less than $\ell$ edges toward the rest of the graph. By tuning parameter $\ell$, the degree of isolation can be controlled, and cliques that are overly connected to the outside are filtered out. Building on Tomita et al.'s very practical recursive algorithm for maximal clique enumeration, we propose four pruning heuristics, applicable individually or in combination, that discard recursive search branches that are guaranteed not to yield $\ell$-isolated maximal cliques. Besides proving correctness, we characterize both the pruning power and the computational cost of these heuristics, and we conduct an extensive experimental study comparing our methods with Tomita's baseline and with a state-of-the-art approach. Results show that two of our heuristics offer substantial efficiency improvements, especially on real-world graphs with social network properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03525v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco D'Elia, Irene Finocchi, Maurizio Patrignani</dc:creator>
    </item>
    <item>
      <title>Depth-13 Sorting Networks for 28 Channels</title>
      <link>https://arxiv.org/abs/2511.04107</link>
      <description>arXiv:2511.04107v2 Announce Type: replace 
Abstract: We establish new depth upper bounds for sorting networks on 27 and 28 channels, improving the previous best bound of 14 to 13. Our 28-channel network is constructed with reflectional symmetry by combining high-quality prefixes of 16- and 12-channel networks, extending them greedily one comparator at a time, and using a SAT solver to complete the remaining layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04107v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengu Wang</dc:creator>
    </item>
    <item>
      <title>Real Time Proportional Throughput Maximization: How much advance notice should you give your scheduler?</title>
      <link>https://arxiv.org/abs/2511.16023</link>
      <description>arXiv:2511.16023v2 Announce Type: replace 
Abstract: We will be exploring a generalization of real time scheduling problem sometimes called the real time throughput maximization problem. Our input is a sequence of jobs specified by their release time, deadline and processing time. We assume that jobs are announced before or at their release time. At each time step, the algorithm must decide whether to schedule a job based on the information so far. The goal is to maximize the value of the sum of the processing times of jobs that finish before their deadline, this is often called real time throughput with proportional weights.
  We extend this problem by defining a notion of $t$-advance-notice, a measure of how far in advance each job is announced relative to their processing time. We show that there exists a $\frac{t}{2t+1}$-competitive algorithm when all jobs have $t$-advance-notice for $t\in [0,1]$, this gives us a competitive ratio of $\frac{1}{3}$ when $t$ is greater than or equal to $1$. We also show that this ratio is optimal for all algorithms with $t$-advance-notice and that the upper bound of $\frac{t}{2t+1}$-competitiveness holds for all $t$, in particular that regardless of how much advance-notice is given, no algorithm can reach $\frac{1}{2}$-competitiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16023v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadim A. Mottu</dc:creator>
    </item>
    <item>
      <title>Fairness in Streaming Submodular Maximization over a Matroid Constraint</title>
      <link>https://arxiv.org/abs/2305.15118</link>
      <description>arXiv:2305.15118v3 Announce Type: replace-cross 
Abstract: Streaming submodular maximization is a natural model for the task of selecting a representative subset from a large-scale dataset. If datapoints have sensitive attributes such as gender or race, it becomes important to enforce fairness to avoid bias and discrimination. This has spurred significant interest in developing fair machine learning algorithms. Recently, such algorithms have been developed for monotone submodular maximization under a cardinality constraint.
  In this paper, we study the natural generalization of this problem to a matroid constraint. We give streaming algorithms as well as impossibility results that provide trade-offs between efficiency, quality and fairness. We validate our findings empirically on a range of well-known real-world applications: exemplar-based clustering, movie recommendation, and maximum coverage in social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15118v3</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marwa El Halabi, Federico Fusco, Ashkan Norouzi-Fard, Jakab Tardos, Jakub Tarnawski</dc:creator>
    </item>
    <item>
      <title>Minimax optimal testing by classification</title>
      <link>https://arxiv.org/abs/2306.11085</link>
      <description>arXiv:2306.11085v2 Announce Type: replace-cross 
Abstract: This paper considers an ML inspired approach to hypothesis testing known as classifier/classification-accuracy testing ($\mathsf{CAT}$). In $\mathsf{CAT}$, one first trains a classifier by feeding it labeled synthetic samples generated by the null and alternative distributions, which is then used to predict labels of the actual data samples. This method is widely used in practice when the null and alternative are only specified via simulators (as in many scientific experiments).
  We study goodness-of-fit, two-sample ($\mathsf{TS}$) and likelihood-free hypothesis testing ($\mathsf{LFHT}$), and show that $\mathsf{CAT}$ achieves (near-)minimax optimal sample complexity in both the dependence on the total-variation ($\mathsf{TV}$) separation $\epsilon$ and the probability of error $\delta$ in a variety of non-parametric settings, including discrete distributions, $d$-dimensional distributions with a smooth density, and the Gaussian sequence model. In particular, we close the high probability sample complexity of $\mathsf{LFHT}$ for each class. As another highlight, we recover the minimax optimal complexity of $\mathsf{TS}$ over discrete distributions, which was recently established by Diakonikolas et al. (2021). The corresponding $\mathsf{CAT}$ simply compares empirical frequencies in the first half of the data, and rejects the null when the classification accuracy on the second half is better than random.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.11085v2</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrik R\'obert Gerber, Yanjun Han, Yury Polyanskiy</dc:creator>
    </item>
    <item>
      <title>Reserve Matching with Thresholds</title>
      <link>https://arxiv.org/abs/2309.13766</link>
      <description>arXiv:2309.13766v3 Announce Type: replace-cross 
Abstract: We develop a general framework for reserve systems that allocate scarce resources such as vaccines to unit-demand agents under prioritization and eligibility constraints, along with a computationally efficient mechanism. Reserve systems allocate scarce resources --such as vaccines, medical units, school seats, or government positions-- to essential groups by creating categories with prioritized beneficiaries. Prior work typically assumed a common baseline priority ordering and featured either hard or soft reserves. The threshold reserve model we introduce supports independent priority orderings, mixtures of hard and soft reserves, and overlapping categories, thereby capturing both beneficiary designations and eligibility constraints while offering policymakers greater flexibility. Our Iterative Max-in-Max Assignment Mechanism (IMMAM) satisfies all desirable properties in this domain: it respects priorities within categories, maximizes resource utilization, and then lexicographically maximizes beneficiary assignments. IMMAM is path independent and therefore well-behaved in settings with multiple institutions making simultaneous allocation decisions. We leverage path independence to obtain comparative statics and to significantly improve the mechanism's computational efficiency. We outline applications of our framework in the context of vaccine allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13766v3</guid>
      <category>econ.TH</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Suat Evren</dc:creator>
    </item>
    <item>
      <title>The Squishy Grid Problem</title>
      <link>https://arxiv.org/abs/2507.23105</link>
      <description>arXiv:2507.23105v2 Announce Type: replace-cross 
Abstract: In this paper we consider the problem of approximating Euclidean distances by the infinite integer grid graph. Although the topology of the graph is fixed, we have control over the edge-weight assignment $w:E\to \mathbb{R}_{\ge 0}$, and hope to have grid distances be asymptotically isometric to Euclidean distances, that is, for all grid points $u,v$, $\mathrm{dist}_w(u,v) = (1\pm o(1))\|u-v\|_2$. We give three methods for solving this problem, each attractive in its own way.
  * Our first construction is based on an embedding of the recursive, non-periodic pinwheel tiling of Radin and Conway into the integer grid. Distances in the pinwheel graph are asymptotically isometric to Euclidean distances, but no explicit bound on the rate of convergence was known. We prove that the multiplicative distortion of the pinwheel graph is $(1+1/\Theta(\log^\xi \log D))$, where $D$ is the Euclidean distance and $\xi=\Theta(1)$. The pinwheel tiling approach is conceptually simple, but can be improved quantitatively.
  * Our second construction is based on a hierarchical arrangement of "highways." It is simple, achieving stretch $(1 + 1/\Theta(D^{1/9}))$, which converges doubly exponentially faster than the pinwheel tiling approach.
  * The first two methods are deterministic. An even simpler approach is to sample the edge weights independently from a common distribution $\mathscr{D}$. Whether there exists a distribution $\mathscr{D}^*$ that makes grid distances Euclidean, asymptotically and in expectation, is major open problem in the theory of first passage percolation. Previous experiments show that when $\mathscr{D}$ is a Fisher distribution, grid distances are within 1\% of Euclidean. We demonstrate experimentally that this level of accuracy can be achieved by a simple 2-point distribution that assigns weights 0.41 or 4.75 with probability 44\% and 56\%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23105v2</guid>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixi Cai, Kuowen Chen, Shengquan Du, Arnold Filtser, Seth Pettie, Daniel Skora</dc:creator>
    </item>
  </channel>
</rss>
