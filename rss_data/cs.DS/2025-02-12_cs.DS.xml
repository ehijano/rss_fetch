<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 05:01:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Breaking Barriers: Combinatorial Algorithms for Non-monotone Submodular Maximization with Sublinear Adaptivity and $1/e$ Approximation</title>
      <link>https://arxiv.org/abs/2502.07062</link>
      <description>arXiv:2502.07062v1 Announce Type: new 
Abstract: With the rapid growth of data in modern applications, parallel combinatorial algorithms for maximizing non-monotone submodular functions have gained significant attention. The state-of-the-art approximation ratio of $1/e$ is currently achieved only by a continuous algorithm (Ene &amp; Nguyen, 2020) with adaptivity $\mathcal O(\log(n))$. In this work, we focus on size constraints and propose a $(1/4-\varepsilon)$-approximation algorithm with high probability for this problem, as well as the first randomized parallel combinatorial algorithm achieving a $1/e-\varepsilon$ approximation ratio, which bridges the gap between continuous and combinatorial approaches. Both algorithms achieve $\mathcal O(\log(n)\log(k))$ adaptivity and $\mathcal O(n\log(n)\log(k))$ query complexity. Empirical results show our algorithms achieve competitive objective values, with the first algorithm particularly efficient in queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07062v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Chen, Wenjing Chen, Alan Kuhnle</dc:creator>
    </item>
    <item>
      <title>One-Shot Learning for k-SAT</title>
      <link>https://arxiv.org/abs/2502.07135</link>
      <description>arXiv:2502.07135v1 Announce Type: new 
Abstract: Consider a $k$-SAT formula $\Phi$ where every variable appears at most $d$ times, and let $\sigma$ be a satisfying assignment of $\Phi$ sampled proportionally to $e^{\beta m(\sigma)}$ where $m(\sigma)$ is the number of variables set to true and $\beta$ is a real parameter. Given $\Phi$ and $\sigma$, can we learn the value of $\beta$ efficiently?
  This problem falls into a recent line of works about single-sample ("one-shot") learning of Markov random fields. The $k$-SAT setting we consider here was recently studied by Galanis, Kandiros, and Kalavasis (SODA'24) where they showed that single-sample learning is possible when roughly $d\leq 2^{k/6.45}$ and impossible when $d\geq (k+1) 2^{k-1}$. Crucially, for their impossibility results they used the existence of unsatisfiable instances which, aside from the gap in $d$, left open the question of whether the feasibility threshold for one-shot learning is dictated by the satisfiability threshold of $k$-SAT formulas of bounded degree.
  Our main contribution is to answer this question negatively. We show that one-shot learning for $k$-SAT is infeasible well below the satisfiability threshold; in fact, we obtain impossibility results for degrees $d$ as low as $k^2$ when $\beta$ is sufficiently large, and bootstrap this to small values of $\beta$ when $d$ scales exponentially with $k$, via a probabilistic construction. On the positive side, we simplify the analysis of the learning algorithm and obtain significantly stronger bounds on $d$ in terms of $\beta$. In particular, for the uniform case $\beta\rightarrow 0$ that has been studied extensively in the sampling literature, our analysis shows that learning is possible under the condition $d\lesssim 2^{k/2}$. This is nearly optimal (up to constant factors) in the sense that it is known that sampling a uniformly-distributed satisfying assignment is NP-hard for $d\gtrsim 2^{k/2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07135v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Galanis, Leslie Ann Goldberg, Xusheng Zhang</dc:creator>
    </item>
    <item>
      <title>Exploring Word-Representable Temporal Graphs</title>
      <link>https://arxiv.org/abs/2502.07496</link>
      <description>arXiv:2502.07496v1 Announce Type: new 
Abstract: Word-representable graphs are a subset of graphs that may be represented by a word $w$ over an alphabet composed of the vertices in the graph. In such graphs, an edge exists if and only if the occurrences of the corresponding vertices alternate in the word $w$. We generalise this notion to temporal graphs, constructing timesteps by partitioning the word into factors (contiguous subwords) such that no factor contains more than one copy of any given symbol. With this definition, we study the problem of \emph{exploration}, asking for the fastest schedule such that a given agent may explore all $n$ vertices of the graph. We show that if the corresponding temporal graph is connected in every timestep, we may explore the graph in $2\delta n$ timesteps, where $\delta$ is the lowest degree of any vertex in the graph. In general, we show that, for any temporal graph represented by a word of length at least $n(2dn + d)$, with a connected underlying graph, the full graph can be explored in $2 d n$ timesteps, where $d$ is the diameter of the graph. We show this is asymptotically optimal by providing a class of graphs of diameter $d$ requiring $\Omega(d n)$ timesteps to explore, for any $d \in [1, n]$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07496v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duncan Adamson</dc:creator>
    </item>
    <item>
      <title>Faster diameter computation in graphs of bounded Euler genus</title>
      <link>https://arxiv.org/abs/2502.07501</link>
      <description>arXiv:2502.07501v1 Announce Type: new 
Abstract: We show that for any fixed integer $k \geq 0$, there exists an algorithm that computes the diameter and the eccentricies of all vertices of an input unweighted, undirected $n$-vertex graph of Euler genus at most $k$ in time \[ \mathcal{O}_k(n^{2-\frac{1}{25}}). \] Furthermore, for the more general class of graphs that can be constructed by clique-sums from graphs that are of Euler genus at most $k$ after deletion of at most $k$ vertices, we show an algorithm for the same task that achieves the running time bound \[ \mathcal{O}_k(n^{2-\frac{1}{356}} \log^{6k} n). \] Up to today, the only known subquadratic algorithms for computing the diameter in those graph classes are that of [Ducoffe, Habib, Viennot; SICOMP 2022], [Le, Wulff-Nilsen; SODA 2024], and [Duraj, Konieczny, Pot\k{e}pa; ESA 2024]. These algorithms work in the more general setting of $K_h$-minor-free graphs, but the running time bound is $\mathcal{O}_h(n^{2-c_h})$ for some constant $c_h &gt; 0$ depending on $h$. That is, our savings in the exponent, as compared to the naive quadratic algorithm, are independent of the parameter $k$. The main technical ingredient of our work is an improved bound on the number of distance profiles, as defined in [Le, Wulff-Nilsen; SODA 2024], in graphs of bounded Euler genus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07501v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kacper Kluk, Marcin Pilipczuk, Micha{\l} Pilipczuk, Giannos Stamoulis</dc:creator>
    </item>
    <item>
      <title>Robust-Sorting and Applications to Ulam-Median</title>
      <link>https://arxiv.org/abs/2502.07653</link>
      <description>arXiv:2502.07653v1 Announce Type: new 
Abstract: Sorting is one of the most basic primitives in many algorithms and data analysis tasks. Comparison-based sorting algorithms, like quick-sort and merge-sort, are known to be optimal when the outcome of each comparison is error-free. However, many real-world sorting applications operate in scenarios where the outcome of each comparison can be noisy. In this work, we explore settings where a bounded number of comparisons are potentially corrupted by erroneous agents, resulting in arbitrary, adversarial outcomes.
  We model the sorting problem as a query-limited tournament graph where edges involving erroneous nodes may yield arbitrary results. Our primary contribution is a randomized algorithm inspired by quick-sort that, in expectation, produces an ordering close to the true total order while only querying $\tilde{O}(n)$ edges. We achieve a distance from the target order $\pi$ within $(3 + \epsilon)|B|$, where $B$ is the set of erroneous nodes, balancing the competing objectives of minimizing both query complexity and misalignment with $\pi$. Our algorithm needs to carefully balance two aspects: identify a pivot that partitions the vertex set evenly and ensure that this partition is "truthful" and yet query as few "triangles" in the graph $G$ as possible. Since the nodes in $B$ can potentially hide in an intricate manner, our algorithm requires several technical steps.
  Additionally, we demonstrate significant implications for the Ulam-$k$-Median problem, a classical clustering problem where the metric is defined on the set of permutations on a set of $d$ elements. Chakraborty, Das, and Krauthgamer gave a $(2-\varepsilon)$ FPT approximation algorithm for this problem, where the running time is super-linear in both $n$ and $d$. We use our robust sorting framework to give the first $(2-\varepsilon)$ FPT linear time approximation algorithm for this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07653v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ragesh Jaiswal, Amit Kumar, Jatin Yadav</dc:creator>
    </item>
    <item>
      <title>Private Low-Rank Approximation for Covariance Matrices, Dyson Brownian Motion, and Eigenvalue-Gap Bounds for Gaussian Perturbations</title>
      <link>https://arxiv.org/abs/2502.07657</link>
      <description>arXiv:2502.07657v1 Announce Type: new 
Abstract: We consider the problem of approximating a $d \times d$ covariance matrix $M$ with a rank-$k$ matrix under $(\varepsilon,\delta)$-differential privacy. We present and analyze a complex variant of the Gaussian mechanism and obtain upper bounds on the Frobenius norm of the difference between the matrix output by this mechanism and the best rank-$k$ approximation to $M$. Our analysis provides improvements over previous bounds, particularly when the spectrum of $M$ satisfies natural structural assumptions. The novel insight is to view the addition of Gaussian noise to a matrix as a continuous-time matrix Brownian motion. This viewpoint allows us to track the evolution of eigenvalues and eigenvectors of the matrix, which are governed by stochastic differential equations discovered by Dyson. These equations enable us to upper bound the Frobenius distance between the best rank-$k$ approximation of $M$ and that of a Gaussian perturbation of $M$ as an integral that involves inverse eigenvalue gaps of the stochastically evolving matrix, as opposed to a sum of perturbation bounds obtained via Davis-Kahan-type theorems. Subsequently, again using the Dyson Brownian motion viewpoint, we show that the eigenvalues of the matrix $M$ perturbed by Gaussian noise have large gaps with high probability. These results also contribute to the analysis of low-rank approximations under average-case perturbations, and to an understanding of eigenvalue gaps for random matrices, both of which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07657v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oren Mangoubi, Nisheeth K. Vishnoi</dc:creator>
    </item>
    <item>
      <title>Coresets for Robust Clustering via Black-box Reductions to Vanilla Case</title>
      <link>https://arxiv.org/abs/2502.07669</link>
      <description>arXiv:2502.07669v1 Announce Type: new 
Abstract: We devise $\epsilon$-coresets for robust $(k,z)$-Clustering with $m$ outliers through black-box reductions to vanilla case. Given an $\epsilon$-coreset construction for vanilla clustering with size $N$, we construct coresets of size $N\cdot \mathrm{poly}\log(km\epsilon^{-1}) + O_z\left(\min\{km\epsilon^{-1}, m\epsilon^{-2z}\log^z(km\epsilon^{-1}) \}\right)$ for various metric spaces, where $O_z$ hides $2^{O(z\log z)}$ factors. This increases the size of the vanilla coreset by a small multiplicative factor of $\mathrm{poly}\log(km\epsilon^{-1})$, and the additive term is up to a $(\epsilon^{-1}\log (km))^{O(z)}$ factor to the size of the optimal robust coreset. Plugging in vanilla coreset results of [Cohen-Addad et al., STOC'21], we obtain the first coresets for $(k,z)$-Clustering with $m$ outliers with size near-linear in $k$ while previous results have size at least $\Omega(k^2)$ [Huang et al., ICLR'23; Huang et al., SODA'25].
  Technically, we establish two conditions under which a vanilla coreset is as well a robust coreset. The first condition requires the dataset to satisfy special structures - it can be broken into "dense" parts with bounded diameter. We combine this with a new bounded-diameter decomposition that has only $O_z(km \epsilon^{-1})$ non-dense points to obtain the $O_z(km \epsilon^{-1})$ additive bound. Another condition requires the vanilla coreset to possess an extra size-preserving property. We further give a black-box reduction that turns a vanilla coreset to the one satisfying the said size-preserving property, leading to the alternative $O_z(m\epsilon^{-2z}\log^{z}(km\epsilon^{-1}))$ additive bound.
  We also implement our reductions in the dynamic streaming setting and obtain the first streaming algorithms for $k$-Median and $k$-Means with $m$ outliers, using space $\tilde{O}(k+m)\cdot\mathrm{poly}(d\epsilon^{-1}\log\Delta)$ for inputs on the grid $[\Delta]^d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07669v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaofeng H. -C. Jiang, Jianing Lou</dc:creator>
    </item>
    <item>
      <title>Online matching and market imbalance</title>
      <link>https://arxiv.org/abs/2502.07731</link>
      <description>arXiv:2502.07731v1 Announce Type: new 
Abstract: Our work introduces the effect of supply/demand imbalances into the literature on online matching with stochastic rewards in bipartite graphs. We provide a parameterized definition that characterizes instances as over- or undersupplied (or balanced), and show that higher competitive ratios against an offline clairvoyant algorithm are achievable, for both adversarial and stochastic arrivals, when instances are more imbalanced. The competitive ratio guarantees we obtain are the best-possible for the class of delayed algorithms we focus on (such algorithms may adapt to the history of arrivals and the algorithm's own decisions, but not to the stochastic realization of each potential match).
  We then explore the real-world implications of our improved competitive ratios. First, we demonstrate analytically that the improved competitive ratios under imbalanced instances is not a one-way street by showing that a platform that conducts effective supply- and demand management should incorporate the effect of imbalance on its matching performance on its supply planning in order to create imbalanced instances. Second, we empirically study the relationship between achieved competitive ratios and imbalance using the data of a volunteer matching platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07731v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Barrientos, Daniel Freund, Daniela Saban</dc:creator>
    </item>
    <item>
      <title>Polynomial-Time Approximability of Constrained Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.07764</link>
      <description>arXiv:2502.07764v1 Announce Type: new 
Abstract: We study the computational complexity of approximating general constrained Markov decision processes. Our primary contribution is the design of a polynomial time $(0,\epsilon)$-additive bicriteria approximation algorithm for finding optimal constrained policies across a broad class of recursively computable constraints, including almost-sure, chance, expectation, and their anytime variants. Matching lower bounds imply our approximation guarantees are optimal so long as $P \neq NP$. The generality of our approach results in answers to several long-standing open complexity questions in the constrained reinforcement learning literature. Specifically, we are the first to prove polynomial-time approximability for the following settings: policies under chance constraints, deterministic policies under multiple expectation constraints, policies under non-homogeneous constraints (i.e., constraints of different types), and policies under constraints for continuous-state processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07764v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan</dc:creator>
    </item>
    <item>
      <title>Pareto Optimal Algorithmic Recourse in Multi-cost Function</title>
      <link>https://arxiv.org/abs/2502.07214</link>
      <description>arXiv:2502.07214v1 Announce Type: cross 
Abstract: In decision-making systems, algorithmic recourse aims to identify minimal-cost actions to alter an individual features, thereby obtaining a desired outcome. This empowers individuals to understand, question, or alter decisions that negatively affect them. However, due to the variety and sensitivity of system environments and individual personalities, quantifying the cost of a single function is nearly impossible while considering multiple criteria situations. Most current recourse mechanisms use gradient-based methods that assume cost functions are differentiable, often not applicable in real-world scenarios, resulting in sub-optimal solutions that compromise various criteria. These solutions are typically intractable and lack rigorous theoretical foundations, raising concerns regarding interpretability, reliability, and transparency from the explainable AI (XAI) perspective.
  To address these issues, this work proposes an algorithmic recourse framework that handles non-differentiable and discrete multi-cost functions. By formulating recourse as a multi-objective optimization problem and assigning weights to different criteria based on their importance, our method identifies Pareto optimal recourse recommendations. To demonstrate scalability, we incorporate the concept of epsilon-net, proving the ability to find approximated Pareto optimal actions. Experiments show the trade-off between different criteria and the methods scalability in large graphs. Compared to current heuristic practices, our approach provides a stronger theoretical foundation and better aligns recourse suggestions with real-world requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07214v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wen-Ling Chen, Hong-Chang Huang, Kai-Hung Lin, Shang-Wei Hwang, Hao-Tsung Yang</dc:creator>
    </item>
    <item>
      <title>Quantum Communication Advantage for Leader Election and Agreement</title>
      <link>https://arxiv.org/abs/2502.07416</link>
      <description>arXiv:2502.07416v1 Announce Type: cross 
Abstract: This work focuses on understanding the quantum message complexity of two central problems in distributed computing, namely, leader election and agreement in synchronous message-passing communication networks. We show that quantum communication gives an advantage for both problems by presenting quantum distributed algorithms that significantly outperform their respective classical counterparts under various network topologies.
  While prior works have studied and analyzed quantum distributed algorithms in the context of (improving) round complexity, a key conceptual contribution of our work is positing a framework to design and analyze the message complexity of quantum distributed algorithms. We present and show how quantum algorithmic techniques such as Grover search, quantum counting, and quantum walks can make distributed algorithms significantly message-efficient.
  In particular, our leader election protocol for diameter-2 networks uses quantum walks to achieve the improved message complexity. To the best of our knowledge, this is the first such application of quantum walks in distributed computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07416v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabien Dufoulon, Fr\'ed\'eric Magniez, Gopal Pandurangan</dc:creator>
    </item>
    <item>
      <title>Vector TSP: A Traveling Salesperson Problem with Racetrack-like Acceleration Constraints</title>
      <link>https://arxiv.org/abs/2006.03666</link>
      <description>arXiv:2006.03666v5 Announce Type: replace 
Abstract: We study a new version of the Traveling Salesperson Problem, called \VectorTSP, where the traveler is subject to discrete acceleration constraints, as defined in the paper-and-pencil game Racetrack (also known as Vector Racer). In this model, the degrees of freedom at a certain point in time depends on the current velocity, and the speed is not limited.
  The paper introduces this problem and initiates its study, discussing also the main differences with existing versions of TSP. Not surprisingly, the problem turns out to be NP-hard. A key feature of \VectorTSP is that it deals with acceleration in a discrete, combinatorial way, making the problem more amenable to algorithmic investigation. The problem involves two layers of trajectory planning: (1) the order in which cities are visited, and (2) the physical trajectory realizing such a visit, both interacting with each other. This interaction is formalized as an interactive protocol between a high-level tour algorithm and a trajectory oracle, the former calling the latter repeatedly. We present an exact implementation of the trajectory oracle, adapting the A* algorithm for paths over multiple checkpoints whose ordering is \emph{given} (this algorithm being possibly of independent interest). To motivate the problem further, we perform experiments showing that the naive approach consisting of solving the instance as an \EuclideanTSP first, then optimizing the trajectory of the resulting tour, is typically suboptimal and outperformed by simple (but dedicated) heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.03666v5</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnaud Casteigts, Mathieu Raffinot, Mikhail Raskin, Jason Schoeters</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Algorithm for Directed Expander Decompositions</title>
      <link>https://arxiv.org/abs/2403.04542</link>
      <description>arXiv:2403.04542v2 Announce Type: replace 
Abstract: In this work, we present the first algorithm to compute expander decompositions in an m-edge directed graph with near-optimal time \~O(m). Further, our algorithm can maintain such a decomposition in a dynamic graph and again obtains near-optimal update times. Our result improves over previous algorithms of Bernstein-Probst Gutenberg-Saranurak (FOCS 2020), Hua-Kyng-Probst Gutenberg-Wu (SODA 2023) that only obtained algorithms optimal up to subpolynomial factors.
  In order to obtain our new algorithm, we present a new push-pull-relabel flow framework that generalizes the classic push-relabel flow algorithm Goldberg-Tarjan (JACM 1988) which was later dynamized for computing expander decompositions in undirected graphs Henzinger-Rao-Wang (SIAM J. Comput. 2020), Saranurak-Wang (SODA 2019). We then show that the flow problems formulated in recent work Hua-Kyng-Probst Gutenberg-Wu (SODA 2023) to decompose directed graphs can be solved much more efficiently in the push-pull-relabel flow framework.
  Recently, our algorithm has already been employed to obtain the currently fastest algorithm to compute min-cost flows Van den Brand-Chen-Kyng-Liu-Probst Gutenberg-Sachdeva (FOCS 2024). We further believe that our algorithm can be used to speed-up and simplify recent breakthroughs in combinatorial graph algorithms towards fast maximum flow algorithms Chuzhoy-Khanna (SODA 2024), Chuzhoy-Khanna (STOC 2024), Bernstein-Blikstad-Saranurak-Tu (FOCS 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04542v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aurelio L. Sulser, Maximilian Probst Gutenberg</dc:creator>
    </item>
    <item>
      <title>An efficient uniqueness theorem for overcomplete tensor decomposition</title>
      <link>https://arxiv.org/abs/2404.07801</link>
      <description>arXiv:2404.07801v2 Announce Type: replace 
Abstract: We give a new, constructive uniqueness theorem for tensor decomposition. It applies to order 3 tensors of format $n \times n \times p$ and can prove uniqueness of decomposition for generic tensors up to rank $r=4n/3$ as soon as $p \geq 4$. One major advantage over Kruskal's uniqueness theorem is that our theorem has an algorithmic proof, and the resulting algorithm is efficient. Like the uniqueness theorem, it applies in the range $n \leq r \leq 4n/3$. As a result, we obtain the first efficient algorithm for overcomplete decomposition of generic tensors of order 3.
  For instance, prior to this work it was not known how to efficiently decompose generic tensors of format $n \times n \times n$ and rank $r=1.01n$ (or rank $r \leq (1+\epsilon) n$, for some constant $\epsilon &gt;0$). Efficient overcomplete decomposition of generic tensors of format $n \times n \times 3$ remains an open problem.
  Our results are based on the method of commuting extensions pioneered by Strassen for the proof of his $3n/2$ lower bound on tensor rank and border rank. In particular, we rely on an algorithm for the computation of commuting extensions recently proposed in a companion paper, and on the classical diagonalization-based "Jennrich algorithm" for undercomplete tensor decomposition.
  This is an updated version of a paper presented at SODA 2025. As a new result, we answer a question from that paper by giving a NP-hardness result for the computation of commuting extensions. The proof relies on a recent construction by Shitov. After the paper appearing in the SODA proceedings was written, another algorithm for the overcomplete decomposition of generic tensors of order~3 was proposed by Kothari, Moitra and Wein.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07801v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Koiran</dc:creator>
    </item>
    <item>
      <title>GIST: Greedy Independent Set Thresholding for Diverse Data Summarization</title>
      <link>https://arxiv.org/abs/2405.18754</link>
      <description>arXiv:2405.18754v2 Announce Type: replace 
Abstract: We introduce a novel subset selection problem called min-distance diversification with monotone submodular utility ($\textsf{MDMS}$), which has a wide variety of applications in machine learning, e.g., data sampling and feature selection. Given a set of points in a metric space, the goal of $\textsf{MDMS}$ is to maximize an objective function combining a monotone submodular utility term and a min-distance diversity term between any pair of selected points, subject to a cardinality constraint. We propose the $\texttt{GIST}$ algorithm, which achieves a $\frac{1}{2}$-approximation guarantee for $\textsf{MDMS}$ by approximating a series of maximum independent set problems with a bicriteria greedy algorithm. We also prove that it is NP-hard to approximate to within a factor of $0.5584$. Finally, we demonstrate that $\texttt{GIST}$ outperforms existing benchmarks for on a real-world image classification task that studies single-shot subset selection for ImageNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18754v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Fahrbach, Srikumar Ramalingam, Morteza Zadimoghaddam, Sara Ahmadian, Gui Citovsky, Giulia DeSalvo</dc:creator>
    </item>
    <item>
      <title>Sparse induced subgraphs in $P_7$-free graphs of bounded clique number</title>
      <link>https://arxiv.org/abs/2412.14836</link>
      <description>arXiv:2412.14836v2 Announce Type: replace 
Abstract: Many natural computational problems, including e.g. Max Weight Independent Set, Feedback Vertex Set, or Vertex Planarization, can be unified under an umbrella of finding the largest sparse induced subgraph, that satisfies some property definable in CMSO$_2$ logic.
  It is believed that each problem expressible with this formalism can be solved in polynomial time in graphs that exclude a fixed path as an induced subgraph.
  This belief is supported by the existence of a quasipolynomial-time algorithm by Gartland, Lokshtanov, Pilipczuk, Pilipczuk, and Rz\k{a}\.zewski [STOC 2021], and a recent polynomial-time algorithm for $P_6$-free graphs by Chudnovsky, McCarty, Pilipczuk, Pilipczuk, and Rz\k{a}\.zewski [SODA 2024].
  In this work we extend polynomial-time tractability of all such problems to $P_7$-free graphs of bounded clique number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14836v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Chudnovsky, Jadwiga Czy\.zewska, Kacper Kluk, Marcin Pilipczuk, Pawe{\l} Rz\k{a}\.zewski</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Telephone Broadcasting: From Cacti to Bounded Pathwidth Graphs</title>
      <link>https://arxiv.org/abs/2501.12316</link>
      <description>arXiv:2501.12316v2 Announce Type: replace 
Abstract: In the Telephone Broadcasting problem, the goal is to disseminate a message from a given source vertex of an input graph to all other vertices in the minimum number of rounds, where at each round, an informed vertex can send the message to at most one of its uninformed neighbors. For general graphs of n vertices, the problem is NP-complete, and the best existing algorithm has an approximation factor of O(log n/ log log n). The existence of a constant factor approximation for the general graphs is still unknown.
  In this paper, we study the problem in two simple families of sparse graphs, namely, cacti and graphs of bounded pathwidth. There have been several efforts to understand the complexity of the problem in cactus graphs, mostly establishing the presence of polynomial-time solutions for restricted families of cactus graphs. Despite these efforts, the complexity of the problem in arbitrary cactus graphs remained open. We settle this question by establishing the NP-completeness of telephone broadcasting in cactus graphs. For that, we show the problem is NP-complete in a simple subfamily of cactus graphs, which we call snowflake graphs. These graphs not only are cacti but also have pathwidth 2. These results establish that, despite being polynomial-time solvable in trees, the problem becomes NP-complete in very simple extensions of trees.
  On the positive side, we present constant-factor approximation algorithms for the studied families of graphs, namely, an algorithm with an approximation factor of 2 for cactus graphs and an approximation factor of O(1) for graphs of bounded pathwidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12316v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aida Aminian, Shahin Kamali, Seyed-Mohammad Seyed-Javadi,  Sumedha</dc:creator>
    </item>
    <item>
      <title>Southwest Tree: A Low-Memory Data Structure for Partial Accumulations by Non-Commutative Invertible Operations</title>
      <link>https://arxiv.org/abs/2502.01603</link>
      <description>arXiv:2502.01603v2 Announce Type: replace 
Abstract: The task of accumulating a portion of a list of values, whose values may be updated at any time, is widely used throughout various applications in computer science. While it is trivial to accomplish this task without any constraints, trivial solutions often sacrifice time complexity in either accumulating or updating the values, one being constant time and the other being linear. To even out the complexity, two well-known data structures have been used to accomplish this task, namely the Segment Tree and the Binary Indexed Tree, which are able to carry out both tasks in O(log_2 N) time for a list of N elements. However, the Segment Tree suffers from requiring auxiliary memory to contain additional values, while the Binary Indexed Tree is unable to handle non-commutative accumulation operations. Here, we present a data structure, called the Southwest Tree, that accomplishes these tasks for non-commutative, invertible accumulation operations in O(log_2 N) time and uses no additional memory to store the structure apart from the initial input array.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01603v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas J. C. Papadopoulos</dc:creator>
    </item>
    <item>
      <title>Vertical Federated Learning with Missing Features During Training and Inference</title>
      <link>https://arxiv.org/abs/2410.22564</link>
      <description>arXiv:2410.22564v2 Announce Type: replace-cross 
Abstract: Vertical federated learning trains models from feature-partitioned datasets across multiple clients, who collaborate without sharing their local data. Standard approaches assume that all feature partitions are available during both training and inference. Yet, in practice, this assumption rarely holds, as for many samples only a subset of the clients observe their partition. However, not utilizing incomplete samples during training harms generalization, and not supporting them during inference limits the utility of the model. Moreover, if any client leaves the federation after training, its partition becomes unavailable, rendering the learned model unusable. Missing feature blocks are therefore a key challenge limiting the applicability of vertical federated learning in real-world scenarios. To address this, we propose LASER-VFL, a vertical federated learning method for efficient training and inference of split neural network-based models that is capable of handling arbitrary sets of partitions. Our approach is simple yet effective, relying on the sharing of model parameters and on task-sampling to train a family of predictors. We show that LASER-VFL achieves a $\mathcal{O}({1}/{\sqrt{T}})$ convergence rate for nonconvex objectives and, under the Polyak-{\L}ojasiewicz inequality, it achieves linear convergence to a neighborhood of the optimum. Numerical experiments show improved performance of LASER-VFL over the baselines. Remarkably, this is the case even in the absence of missing features. For example, for CIFAR-100, we see an improvement in accuracy of $18.2\%$ when each of four feature blocks is observed with a probability of 0.5 and of $7.4\%$ when all features are observed. The code for this work is available at https://github.com/Valdeira/LASER-VFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22564v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Valdeira, Shiqiang Wang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Erd\H{o}s-Gy\'arf\'as conjecture on graphs without long induced paths</title>
      <link>https://arxiv.org/abs/2410.22842</link>
      <description>arXiv:2410.22842v2 Announce Type: replace-cross 
Abstract: Erd\H{o}s and Gy\'arf\'as conjectured in 1994 that every graph with minimum degree at least 3 has a cycle of length a power of 2. In 2022, Gao and Shan (Graphs and Combinatorics) proved that the conjecture is true for $P_8$-free graphs, i.e., graphs without any induced copies of a path on 8 vertices. In 2024, Hu and Shen (Discrete Mathematics) improved this result by proving that the conjecture is true for $P_{10}$ -free graphs. With the aid of a computer search, we improve this further by proving that the conjecture is true for $P_{13}$ -free graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22842v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anand Shripad Hegde, R. B. Sandeep, P. Shashank</dc:creator>
    </item>
    <item>
      <title>A Quadratic Lower Bound for Stable Roommates Solvability</title>
      <link>https://arxiv.org/abs/2502.06464</link>
      <description>arXiv:2502.06464v2 Announce Type: replace-cross 
Abstract: In their seminal work on the Stable Marriage Problem (SM), Gale and Shapley introduced a generalization of SM referred to as the Stable Roommates Problem (SR). An instance of SR consists of a set of $2n$ agents, and each agent has preferences in the form of a ranked list of all other agents. The goal is to find a one-to-one matching between the agents that is stable in the sense that no pair of agents have a mutual incentive to deviate from the matching. Unlike the (bipartite) stable marriage problem, in SR, stable matchings need not exist. Irving devised an algorithm that finds a stable matching or reports that none exists in $O(n^2)$ time. In their influential 1989 text, Gusfield and Irving posed the question of whether $\Omega(n^2)$ time is required for SR solvability -- the task of deciding if an SR instance admits a stable matching.
  In this paper we provide an affirmative answer to Gusfield and Irving's question. We show that any (randomized) algorithm that decides SR solvability requires $\Omega(n^2)$ adaptive Boolean queries to the agents' preferences (in expectation). Our argument follows from a reduction from the communication complexity of the set disjointness function. The query lower bound implies quadratic time lower bounds for Turing machines, and memory access lower bounds for random access machines. Thus, we establish that Irving's algorithm is optimal (up to a logarithmic factor) in a very strong sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06464v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Will Rosenbaum</dc:creator>
    </item>
  </channel>
</rss>
