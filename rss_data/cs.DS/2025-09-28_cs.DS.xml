<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Sep 2025 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>New Algorithmic Directions in Optimal Transport and Applications for Product Spaces</title>
      <link>https://arxiv.org/abs/2509.21502</link>
      <description>arXiv:2509.21502v1 Announce Type: new 
Abstract: We study optimal transport between two high-dimensional distributions $\mu,\nu$ in $R^n$ from an algorithmic perspective: given $x \sim \mu$, find a close $y \sim \nu$ in $poly(n)$ time, where $n$ is the dimension of $x,y$. Thus, running time depends on the dimension rather than the full representation size of $\mu,\nu$. Our main result is a general algorithm for transporting any product distribution $\mu$ to any $\nu$ with cost $\Delta + \delta$ under $\ell_p^p$, where $\Delta$ is the Knothe-Rosenblatt transport cost and $\delta$ is a computational error decreasing with runtime. This requires $\nu$ to be "sequentially samplable" with bounded average sampling cost, a new but natural notion.
  We further prove:
  An algorithmic version of Talagrand's inequality for transporting the standard Gaussian $\Phi^n$ to arbitrary $\nu$ under squared Euclidean cost. For $\nu = \Phi^n$ conditioned on a set $\mathcal{S}$ of measure $\varepsilon$, we construct the sequential sampler in expected time $poly(n/\varepsilon)$ using membership oracle access to $\mathcal{S}$. This yields an algorithmic transport from $\Phi^n$ to $\Phi^n|\mathcal{S}$ in $poly(n/\varepsilon)$ time and expected squared distance $O(\log 1/\varepsilon)$, optimal for general $\mathcal{S}$ of measure $\varepsilon$.
  As corollary, we obtain the first computational concentration result (Etesami et al. SODA 2020) for Gaussian measure under Euclidean distance with dimension-independent transportation cost, resolving an open question of Etesami et al. Specifically, for any $\mathcal{S}$ of Gaussian measure $\varepsilon$, most $\Phi^n$ samples can be mapped to $\mathcal{S}$ within distance $O(\sqrt{\log 1/\varepsilon})$ in $poly(n/\varepsilon)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21502v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salman Beigi, Omid Etesami, Mohammad Mahmoody, Amir Najafi</dc:creator>
    </item>
    <item>
      <title>New Parallel and Streaming Algorithms for Directed Densest Subgraph</title>
      <link>https://arxiv.org/abs/2509.21729</link>
      <description>arXiv:2509.21729v1 Announce Type: new 
Abstract: Finding dense subgraphs is a fundamental problem with applications to community detection, clustering, and data mining. Our work focuses on finding approximate densest subgraphs in directed graphs in computational models for processing massive data. We consider two such models: Massively Parallel Computation (MPC) and semi-streaming. We show how to find a $(2+\varepsilon)$-approximation in $\tilde{O}(\sqrt{\log n})$ MPC rounds with sublinear memory per machine. This improves the state-of-the-art results by Bahmani et al. (WAW 2014) and Mitrovi\'c &amp; Pan (ICML 2024). Moreover, we show how to find an $O(\log n)$-approximation in a single pass in semi-streaming. This is in stark contrast to prior work, which implies $\tilde{\Omega}(n^{1/6})$-approximation for a single pass; a better approximation is known only for randomized streams (Mitrovi\'c &amp; Pan). This is the first deterministic single-pass semi-streaming algorithm for the densest subgraph problem, both for undirected and directed graphs. Our semi-streaming approach is also an insertion-only dynamic algorithm, attaining the first directed densest subgraph algorithm with $O(\log^2 n)$ worst-case update time while using sub-linear memory. We empirically evaluate our approaches in two ways. First, we illustrate that our single-pass semi-streaming algorithm performs much better than the theoretical guarantee. Specifically, its approximation on temporal datasets matches the $(2+\varepsilon)$-approximation of an $O(\log n)$-pass algorithm by Bahmani et al. (VLDB 2012). Second, we demonstrate that our MPC algorithm requires fewer rounds than prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21729v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Slobodan Mitrovi\'c, Theodore Pan, Mahdi Qaempanah, Mohammad Amin Raeisi</dc:creator>
    </item>
    <item>
      <title>Stable coresets: Unleashing the power of uniform sampling</title>
      <link>https://arxiv.org/abs/2509.22189</link>
      <description>arXiv:2509.22189v1 Announce Type: new 
Abstract: Uniform sampling is a highly efficient method for data summarization. However, its effectiveness in producing coresets for clustering problems is not yet well understood, primarily because it generally does not yield a strong coreset, which is the prevailing notion in the literature. We formulate \emph{stable coresets}, a notion that is intermediate between the standard notions of weak and strong coresets, and effectively combines the broad applicability of strong coresets with highly efficient constructions, through uniform sampling, of weak coresets. Our main result is that a uniform sample of size $O(\epsilon^{-2}\log d)$ yields, with high constant probability, a stable coreset for $1$-median in $\mathbb{R}^d$ under the $\ell_1$ metric. We then leverage the powerful properties of stable coresets to easily derive new coreset constructions, all through uniform sampling, for $\ell_1$ and related metrics, such as Kendall-tau and Jaccard. We also show applications to fair clustering and to approximation algorithms for $k$-median problems in these metric spaces. Our experiments validate the benefits of stable coresets in practice, in terms of both construction time and approximation quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22189v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Carmel, Robert Krauthgamer</dc:creator>
    </item>
    <item>
      <title>Less is More: Faster Maximum Clique Search by Work-Avoidance</title>
      <link>https://arxiv.org/abs/2509.22245</link>
      <description>arXiv:2509.22245v1 Announce Type: new 
Abstract: The maximum clique (MC) problem is a challenging graph mining problem which, due to its NP-hard nature, can take a substantial amount of execution time. The MC problem is dominated by set intersection operations similar to Maximal Clique Enumeration, however it differs in requiring to find only a clique of maximum size. As such, key to the problem is to demonstrate efficiently that a particular part of the search space does not contain a maximum clique, allowing to skip over major parts of the search space. We present a number of techniques to optimize MC search in light of leaving major parts of the search space unvisited, including (i) an efficient, lazily constructed graph representation; (ii) filtering prior to initiating a detailed search; (iii) efficient early-exit intersection algorithms; (iv) exploiting algorithmic choice. These techniques result in a speedup of up to 38.9x compared to PMC, which is the most comparable algorithm, and a speedup up to 11x over MC-BRB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22245v1</guid>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/IPDPS64566.2025.00025</arxiv:DOI>
      <arxiv:journal_reference>2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS), Milano, Italy, 2025, pp. 187-198</arxiv:journal_reference>
      <dc:creator>Hans Vandierendonck</dc:creator>
    </item>
    <item>
      <title>Online Firefighting on Cactus Graphs</title>
      <link>https://arxiv.org/abs/2509.22277</link>
      <description>arXiv:2509.22277v1 Announce Type: new 
Abstract: It is known that the online firefighting is 2-competitive on trees (Coupechoux et al. 2016), which suggests that the problem is relatively easy on trees. We extend the study to graphs containing cycles. We first show that the presence of cycles gives a strong advantage to the adversary: cycles create situations where the algorithm and the optimal solution operate on different game states, and the adversary can exploit the uncertainty in the firefighter sequence to trap the algorithm. Specifically, we prove that even on a tadpole graph (a cycle with a tail path), no deterministic online algorithm achieves a competitive ratio better than $\Omega(\sqrt{n})$, where n is the number of vertices. We then propose an $O(\sqrt{n})$-competitive algorithm for 1-almost trees, which contain at most one cycle and generalize tadpole graphs. We further generalize this algorithm to cactus graphs, in which multiple cycles may appear, but no two share more than one vertex, and show that the online firefighting problem on cactus graphs remains $O(\sqrt{n})$-competitive. Finally, since cactus graphs have treewidth at most 2, we study a variant where firefighters are released in pairs, that is, each round an even number of firefighters is available. Surprisingly, in this setting the competitive complexity is significantly reduced, and we prove that the problem is at most 3-competitive.
  The main technical challenges lie in both algorithm design and analysis, since the algorithm and the optimal solution may break different cycles and thus operate on different residual graphs. To overcome this difficulty, we design a charging framework that carefully partitions the vertices saved by the optimal solution and charges them to the vertices saved by the algorithm. Namely, the charging scheme is carefully constructed to ensure that each vertex saved by the algorithm is charged at most a constant number of times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22277v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Hugen, Bob Krekelberg, Alison Hsiang-Hsuan Liu</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Classification Of Detecting Dominating Patterns</title>
      <link>https://arxiv.org/abs/2509.22332</link>
      <description>arXiv:2509.22332v1 Announce Type: new 
Abstract: We consider the following generalization of dominating sets: Let $G$ be a host graph and $P$ be a pattern graph $P$. A dominating $P$-pattern in $G$ is a subset $S$ of vertices in $G$ that (1) forms a dominating set in $G$ \emph{and} (2) induces a subgraph isomorphic to $P$. The graph theory literature studies the properties of dominating $P$-patterns for various patterns $P$, including cliques, matchings, independent sets, cycles and paths. Previous work (Kunnemann, Redzic 2024) obtains algorithms and conditional lower bounds for detecting dominating $P$-patterns particularly for $P$ being a $k$-clique, a $k$-independent set and a $k$-matching. Their results give conditionally tight lower bounds if $k$ is sufficiently large (where the bound depends the matrix multiplication exponent $\omega$). We ask: Can we obtain a classification of the fine-grained complexity for \emph{all} patterns $P$?
  Indeed, we define a graph parameter $\rho(P)$ such that if $\omega=2$, then \[ \left(n^{\rho(P)} m^{\frac{|V(P)|-\rho(P)}{2}}\right)^{1\pm o(1)} \] is the optimal running time assuming the Orthogonal Vectors Hypothesis, for all patterns $P$ except the triangle $K_3$. Here, the host graph $G$ has $n$ vertices and $m=\Theta(n^\alpha)$ edges, where $1\le \alpha \le 2$.
  The parameter $\rho(P)$ is closely related (but sometimes different) to a parameter $\delta(P) = \max_{S\subseteq V(P)} |S|-|N(S)|$ studied in (Alon 1981) to tightly quantify the maximum number of occurrences of induced subgraphs isomorphic to $P$. Our results stand in contrast to the lack of a full fine-grained classification of detecting an arbitrary (not necessarily \emph{dominating}) induced $P$-pattern.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22332v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ESA.2025.97</arxiv:DOI>
      <dc:creator>Jonathan Dransfeld, Marvin K\"unnemann, Mirza Redzic</dc:creator>
    </item>
    <item>
      <title>Orientation does not help with 3-coloring a grid in online-LOCAL</title>
      <link>https://arxiv.org/abs/2509.22233</link>
      <description>arXiv:2509.22233v1 Announce Type: cross 
Abstract: The online-LOCAL and SLOCAL models are extensions of the LOCAL model where nodes are processed in a sequential but potentially adversarial order. So far, the only problem we know of where the global memory of the online-LOCAL model has an advantage over SLOCAL is 3-coloring bipartite graphs. Recently, Chang et al. [PODC 2024] showed that even in grids, 3-coloring requires $\Omega(\log n)$ locality in deterministic online-LOCAL. This result was subsequently extended by Akbari et al. [STOC 2025] to also hold in randomized online-LOCAL. However, both proofs heavily rely on the assumption that the algorithm does not have access to the orientation of the underlying grid. In this paper, we show how to lift this requirement and obtain the same lower bound (against either model) even when the algorithm is explicitly given a globally consistent orientation of the grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22233v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Boudier, Filippo Casagrande, Avinandan Das, Massimo Equi, Henrik Lievonen, Augusto Modanese, Ronja Stimpert</dc:creator>
    </item>
    <item>
      <title>High-dimensional quantum Schur transforms</title>
      <link>https://arxiv.org/abs/2509.22640</link>
      <description>arXiv:2509.22640v1 Announce Type: cross 
Abstract: The quantum Schur transform has become a foundational quantum algorithm, yet even after two decades since the seminal 2005 paper by Bacon, Chuang, and Harrow (BCH), some aspects of the transform remain insufficiently understood. Moreover, an alternative approach proposed by Krovi in 2018 was recently found to contain a crucial error. In this paper, we present a corrected version of Krovi's algorithm along with a detailed treatment of the high-dimensional version of the BCH Schur transform. This high-dimensional focus makes the two versions of the transform practical for regimes where the number of qudits $n$ is smaller than the local dimension $d$, with Krovi's algorithm scaling as $\widetilde{O}(n^4)$ and BCH as $\widetilde{O}(\min(n^5,nd^4))$. Our work addresses a key gap in the literature, strengthening the algorithmic foundations of a wide range of results that rely on Schur--Weyl duality in quantum information theory and quantum computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22640v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.RT</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adam Burchardt, Jiani Fei, Dmitry Grinko, Martin Larocca, Maris Ozols, Sydney Timmerman, Vladyslav Visnevskyi</dc:creator>
    </item>
    <item>
      <title>New Tools for Smoothed Analysis: Least Singular Value Bounds for Random Matrices with Dependent Entries</title>
      <link>https://arxiv.org/abs/2405.01517</link>
      <description>arXiv:2405.01517v2 Announce Type: replace 
Abstract: We develop new techniques for proving lower bounds on the least singular value of random matrices with limited randomness. The matrices we consider have entries that are given by polynomials of a few underlying base random variables. This setting captures a core technical challenge for obtaining smoothed analysis guarantees in many algorithmic settings. Least singular value bounds often involve showing strong anti-concentration inequalities that are intricate and much less understood compared to concentration (or large deviation) bounds.
  First, we introduce a general technique involving a hierarchical $\epsilon$-nets to prove least singular value bounds. Our second tool is a new statement about least singular values to reason about higher-order lifts of smoothed matrices, and the action of linear operators on them.
  Apart from getting simpler proofs of existing smoothed analysis results, we use these tools to now handle more general families of random matrices. This allows us to produce smoothed analysis guarantees in several previously open settings. These include new smoothed analysis guarantees for power sum decompositions, subspace clustering and certifying robust entanglement of subspaces, where prior work could only establish least singular value bounds for fully random instances or only show non-robust genericity guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01517v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Bhaskara, Eric Evert, Vaidehi Srinivas, Aravindan Vijayaraghavan</dc:creator>
    </item>
    <item>
      <title>Stealing From the Dragon's Hoard: Online Unbounded Knapsack With Removal</title>
      <link>https://arxiv.org/abs/2509.19914</link>
      <description>arXiv:2509.19914v2 Announce Type: replace 
Abstract: We introduce the Online Unbounded Knapsack Problem with Removal, a variation of the well-known Online Knapsack Problem. Items, each with a weight and value, arrive online and an algorithm must decide on whether or not to pack them into a knapsack with a fixed weight limit. An item may be packed an arbitrary number of times and items may be removed from the knapsack at any time without cost. The goal is to maximize the total value of items packed, while respecting a weight limit. We show that this is one of the very few natural online knapsack variants that allow for competitive deterministic algorithms in the general setting, by providing an algorithm with competitivity 1.6911. We complement this with a lower bound of 1.5877.
  We also analyze the proportional setting, where the weight and value of any single item agree, and show that deterministic algorithms can be exactly 3/2-competitive. Lastly, we give lower and upper bounds of 6/5 and 4/3 on the competitivity of randomized algorithms in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19914v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Gehnen, Moritz Stocker</dc:creator>
    </item>
    <item>
      <title>Fast Partition-Based Cross-Validation With Centering and Scaling for $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$</title>
      <link>https://arxiv.org/abs/2401.13185</link>
      <description>arXiv:2401.13185v4 Announce Type: replace-cross 
Abstract: We present algorithms that substantially accelerate partition-based cross-validation for machine learning models that require matrix products $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$. Our algorithms have applications in model selection for, for example, principal component analysis (PCA), principal component regression (PCR), ridge regression (RR), ordinary least squares (OLS), and partial least squares (PLS). Our algorithms support all combinations of column-wise centering and scaling of $\mathbf{X}$ and $\mathbf{Y}$, and we demonstrate in our accompanying implementation that this adds only a manageable, practical constant over efficient variants without preprocessing. We prove the correctness of our algorithms under a fold-based partitioning scheme and show that the running time is independent of the number of folds; that is, they have the same time complexity as that of computing $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ and space complexity equivalent to storing $\mathbf{X}$, $\mathbf{Y}$, $\mathbf{X}^\mathbf{T}\mathbf{X}$, and $\mathbf{X}^\mathbf{T}\mathbf{Y}$. Importantly, unlike alternatives found in the literature, we avoid data leakage due to preprocessing. We achieve these results by eliminating redundant computations in the overlap between training partitions. Concretely, we show how to manipulate $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ using only samples from the validation partition to obtain the preprocessed training partition-wise $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$. To our knowledge, we are the first to derive correct and efficient cross-validation algorithms for any of the $16$ combinations of column-wise centering and scaling, for which we also prove only $12$ give distinct matrix products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13185v4</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/cem.70008</arxiv:DOI>
      <arxiv:journal_reference>Journal of Chemometrics. Volume 39, Issue 3, 2025, e70008</arxiv:journal_reference>
      <dc:creator>Ole-Christian Galbo Engstr{\o}m, Martin Holm Jensen</dc:creator>
    </item>
    <item>
      <title>Reducing Leximin Fairness to Utilitarian Optimization</title>
      <link>https://arxiv.org/abs/2409.10395</link>
      <description>arXiv:2409.10395v4 Announce Type: replace-cross 
Abstract: Two prominent objectives in social choice are utilitarian - maximizing the sum of agents' utilities, and leximin - maximizing the smallest agent's utility, then the second-smallest, etc. Utilitarianism is typically computationally easier to attain but is generally viewed as less fair. This paper presents a general reduction scheme that, given a utilitarian solver, produces a distribution over states (deterministic outcomes) that is leximin in expectation. Importantly, the scheme is robust in the sense that, given an approximate utilitarian solver, it produces a lottery that is approximately-leximin (in expectation) - with the same approximation factor. We apply our scheme to several social choice problems: stochastic allocations of indivisible goods, giveaway lotteries, and fair lotteries for participatory budgeting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10395v4</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1609/aaai.v39i13.33521</arxiv:DOI>
      <dc:creator>Eden Hartman, Yonatan Aumann, Avinatan Hassidim, Erel Segal-Halevi</dc:creator>
    </item>
  </channel>
</rss>
