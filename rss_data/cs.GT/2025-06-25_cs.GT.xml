<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 01:31:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Online Learning for Dynamic Vickrey-Clarke-Groves Mechanism in Sequential Auctions under Unknown Environments</title>
      <link>https://arxiv.org/abs/2506.19038</link>
      <description>arXiv:2506.19038v1 Announce Type: new 
Abstract: We consider the problem of online dynamic mechanism design for sequential auctions in unknown environments, where the underlying market and, thus, the bidders' values vary over time as interactions between the seller and the bidders progress. We model the sequential auctions as an infinite-horizon average-reward Markov decision process (MDP), where the transition kernel and reward functions are unknown to the seller. In each round, the seller determines an allocation and a payment for each bidder. Each bidder receives a private reward and submits a sealed bid to the seller. The state, which represents the underlying market, evolves according to an unknown transition kernel and the seller's allocation policy. Unlike existing works that formulate the problem as a multi-armed bandit model or as an episodic MDP, where the environment resets to an initial state after each round or episode, our paper considers a more realistic and sophisticated setting in which the market continues to evolve without restarting. We first extend the Vickrey-Clarke-Groves (VCG) mechanism, which is known to be efficient, truthful, and individually rational for one-shot static auctions, to sequential auctions, thereby obtaining a dynamic VCG mechanism counterpart that preserves these desired properties. We then focus on the online setting and develop an online reinforcement learning algorithm for the seller to learn the underlying MDP model and implement a mechanism that closely resembles the dynamic VCG mechanism. We show that the learned online mechanism asymptotically converges to a dynamic mechanism that approximately satisfies efficiency, truthfulness, and individual rationality with arbitrarily high probability and achieves guaranteed performance in terms of various notions of regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19038v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Leon, S. Rasoul Etesami</dc:creator>
    </item>
    <item>
      <title>A Principled Approach to Randomized Selection under Uncertainty</title>
      <link>https://arxiv.org/abs/2506.19083</link>
      <description>arXiv:2506.19083v1 Announce Type: new 
Abstract: Many decision-making processes involve evaluating and then selecting items; examples include scientific peer review, job hiring, school admissions, and investment decisions. The eventual selection is performed by applying rules or deliberations to the raw evaluations, and then deterministically selecting the items deemed to be the best. These domains feature error-prone evaluations and uncertainty about future outcomes, which undermine the reliability of such deterministic selection rules. As a result, selection mechanisms involving explicit randomization that incorporate the uncertainty are gaining traction in practice. However, current randomization approaches are ad hoc, and as we prove, inappropriate for their purported objectives. In this paper, we propose a principled framework for randomized decision-making based on interval estimates of the quality of each item. We introduce MERIT (Maximin Efficient Randomized Interval Top-k), an optimization-based method that maximizes the worst-case expected number of top candidates selected, under uncertainty represented by overlapping intervals (e.g., confidence intervals or min-max intervals). MERIT provides an optimal resource allocation scheme under an interpretable notion of robustness. We develop a polynomial-time algorithm to solve the optimization problem and demonstrate empirically that the method scales to over 10,000 items. We prove that MERIT satisfies desirable axiomatic properties not guaranteed by existing approaches. Finally, we empirically compare algorithms on synthetic peer review data. Our experiments demonstrate that MERIT matches the performance of existing algorithms in expected utility under fully probabilistic review data models used in previous work, while outperforming previous methods with respect to our novel worst-case formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19083v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Goldberg, Giulia Fanti, Nihar B. Shah</dc:creator>
    </item>
    <item>
      <title>Distributed Interview Selection for Stable Matching in Large Random Markets</title>
      <link>https://arxiv.org/abs/2506.19345</link>
      <description>arXiv:2506.19345v1 Announce Type: new 
Abstract: In real-world settings of the Deferred Acceptance stable matching algorithm, such as the American medical residency match (NRMP), school choice programs, and various national university entrance systems, candidates need to decide which programs to list. In many of these settings there is an initial phase of interviews or information gathering which affect the preferences on one or both sides. We ask: which interviews should candidates seek? We study this question in a model, introduced by Lee (2016) and modified by Allman and Ashlagi (2023), with preferences based on correlated cardinal utilities.
  We describe a distributed, low-communication strategy for the doctors and students, which lead to non-match rates of $e^{(-\widetilde{O}(\sqrt{k}))}$ in the residency setting and $e^{(-\widetilde{O}(k))}$ in the school-choice setting, where $k$ is the number of interviews per doctor in the first setting, and the number of proposals per student in the second setting; these bounds do not apply to the agents with the lowest public ratings, the bottommost agents, who may not fare as well. We also obtain bounds on the expected utilities each non-bottommost agent obtains.
  These results are parameterized by the capacity of the hospital programs and schools. Larger capacities improve the outcome for the hospitals and schools, but don't significantly affect the outcomes of the doctors or students. Finally, in the school choice setting we obtain an $\epsilon$-Nash type equilibrium for the students apart from the bottommost ones; importantly, the equilibrium holds regardless of the actions of the bottommost students. We also discuss to what extent this result extends to the residency setting. We complement our theoretical results with an experimental study that shows the asymptotic results hold for real-world values of $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19345v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Cole, Pranav Jangir</dc:creator>
    </item>
    <item>
      <title>Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition</title>
      <link>https://arxiv.org/abs/2506.19191</link>
      <description>arXiv:2506.19191v1 Announce Type: cross 
Abstract: We introduce a mathematically rigorous framework for an artificial intelligence system composed of probabilistic agents evolving through structured competition and belief revision. The architecture, grounded in Bayesian inference, measure theory, and population dynamics, defines agent fitness as a function of alignment with a fixed external oracle representing ground truth. Agents compete in a discrete-time environment, adjusting posterior beliefs through observed outcomes, with higher-rated agents reproducing and lower-rated agents undergoing extinction. Ratings are updated via pairwise truth-aligned utility comparisons, and belief updates preserve measurable consistency and stochastic convergence. We introduce hash-based cryptographic identity commitments to ensure traceability, alongside causal inference operators using do-calculus. Formal theorems on convergence, robustness, and evolutionary stability are provided. The system establishes truth as an evolutionary attractor, demonstrating that verifiable knowledge arises from adversarial epistemic pressure within a computable, self-regulating swarm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19191v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>math.LO</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Craig Steven Wright</dc:creator>
    </item>
    <item>
      <title>The Autonomy of the Lightning Network: A Mathematical and Economic Proof of Structural Decoupling from BTC</title>
      <link>https://arxiv.org/abs/2506.19333</link>
      <description>arXiv:2506.19333v1 Announce Type: cross 
Abstract: This paper presents a formal analysis of the Lightning Network as a monetary system structurally diverging from Bitcoin's base-layer settlement model. We demonstrate that under increasing transaction demand, BTC transaction fees rise superlinearly due to throughput constraints, while Lightning Network routing costs approach a bounded asymptote. Using mathematical modeling, game-theoretic proofs, and complexity analysis, we show that Lightning enables indefinite off-chain operation via the emergence of liquidity hub oligopolies. These hubs exhibit properties of unregulated financial intermediaries, including rent extraction, opacity, and systemic fragility. Strategic agent models show that channel closure becomes economically infeasible, and routing problems approach hardness limits in P-Space complexity. We conclude that Lightning does not merely extend Bitcoin, but constitutes a synthetic financial system with shadowbank characteristics, lacking reserve discipline, transparency, or enforceable settlement guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19333v1</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Craig Steven Wright</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Neural Networks for Industrial Gas Turbines: Recent Trends, Advancements and Challenges</title>
      <link>https://arxiv.org/abs/2506.19503</link>
      <description>arXiv:2506.19503v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a promising computational framework for solving differential equations by integrating deep learning with physical constraints. However, their application in gas turbines is still in its early stages, requiring further refinement and standardization for wider adoption. This survey provides a comprehensive review of PINNs in Industrial Gas Turbines (IGTs) research, highlighting their contributions to the analysis of aerodynamic and aeromechanical phenomena, as well as their applications in flow field reconstruction, fatigue evaluation, and flutter prediction, and reviews recent advancements in accuracy, computational efficiency, and hybrid modelling strategies. In addition, it explores key research efforts, implementation challenges, and future directions aimed at improving the robustness and scalability of PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19503v1</guid>
      <category>cs.CE</category>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Afila Ajithkumar Sophiya, Sepehr Maleki, Giuseppe Bruni, Senthil K. Krishnababu</dc:creator>
    </item>
    <item>
      <title>Game Connectivity and Adaptive Dynamics</title>
      <link>https://arxiv.org/abs/2309.10609</link>
      <description>arXiv:2309.10609v5 Announce Type: replace-cross 
Abstract: We analyse the typical structure of games in terms of the connectivity properties of their best-response graphs. Our central result shows that, among games that are `generic' (without indifferences) and that have a pure Nash equilibrium, all but a small fraction are \emph{connected}, meaning that every action profile that is not a pure Nash equilibrium can reach every pure Nash equilibrium via best-response paths. This has important implications for dynamics in games. In particular, we show that there are simple, uncoupled, adaptive dynamics for which period-by-period play converges almost surely to a pure Nash equilibrium in all but a small fraction of generic games that have one (which contrasts with the known fact that there is no such dynamic that leads almost surely to a pure Nash equilibrium in \emph{every} generic game that has one). We build on recent results in probabilistic combinatorics for our characterisation of game connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10609v5</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.CO</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Johnston, Michael Savery, Alex Scott, Bassel Tarbush</dc:creator>
    </item>
  </channel>
</rss>
