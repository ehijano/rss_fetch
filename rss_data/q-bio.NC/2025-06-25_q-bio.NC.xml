<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 01:30:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Automatic Depression Assessment using Machine Learning: A Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2506.18915</link>
      <description>arXiv:2506.18915v1 Announce Type: new 
Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18915v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyang Song, Yupeng Huo, Shiqing Tang, Jiaee Cheong, Rui Gao, Michel Valstar, Hatice Gunes</dc:creator>
    </item>
    <item>
      <title>Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness</title>
      <link>https://arxiv.org/abs/2506.18935</link>
      <description>arXiv:2506.18935v1 Announce Type: new 
Abstract: This paper presents a novel paradigm of the local percept-perceiver phenomenon to formalize certain observations in neuroscientific theories of consciousness. Using this model, a set-theoretic formalism is developed for artificial systems, and the existence of machine consciousness is proved by invoking Zermelo-Fraenkel set theory. The article argues for the possibility of a reductionist form of epistemic consciousness within machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18935v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shri Lal Raghudev Ram Singh</dc:creator>
    </item>
    <item>
      <title>How brains build higher order representations of uncertainty</title>
      <link>https://arxiv.org/abs/2506.19057</link>
      <description>arXiv:2506.19057v1 Announce Type: new 
Abstract: Higher-order representations (HORs) are neural or computational states that are "about" first-order representations (FORs), encoding information not about the external world per se but about the agent's own representational processes -- such as the reliability, source, or structure of a FOR. These HORs appear critical to metacognition, learning, and even consciousness by some accounts, yet their dimensionality, construction, and neural substrates remain poorly understood. Here, we propose that metacognitive estimates of uncertainty or noise reflect a read-out of "posterior-like" HORs from a Bayesian perspective. We then discuss how these posterior-like HORs reflect a combination of "likelihood-like" estimates of current FOR uncertainty and "prior-like" learned distributions over expected FOR uncertainty, and how various emerging engineering and theory-based analytical approaches may be employed to examine the estimation processes and neural correlates associated with these highly under-explored components of our experienced uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19057v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Megan A. K. Peters, Hojjat Azimi Asrari</dc:creator>
    </item>
    <item>
      <title>Accurate identification of communication between multiple interacting neural populations</title>
      <link>https://arxiv.org/abs/2506.19094</link>
      <description>arXiv:2506.19094v1 Announce Type: new 
Abstract: Neural recording technologies now enable simultaneous recording of population activity across many brain regions, motivating the development of data-driven models of communication between brain regions. However, existing models can struggle to disentangle the sources that influence recorded neural populations, leading to inaccurate portraits of inter-regional communication. Here, we introduce Multi-Region Latent Factor Analysis via Dynamical Systems (MR-LFADS), a sequential variational autoencoder designed to disentangle inter-regional communication, inputs from unobserved regions, and local neural population dynamics. We show that MR-LFADS outperforms existing approaches at identifying communication across dozens of simulations of task-trained multi-region networks. When applied to large-scale electrophysiology, MR-LFADS predicts brain-wide effects of circuit perturbations that were held out during model fitting. These validations on synthetic and real neural data position MR-LFADS as a promising tool for discovering principles of brain-wide information processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19094v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CE</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Forty-second International Conference on Machine Learning (2025)</arxiv:journal_reference>
      <dc:creator>Belle Liu, Jacob Sacks, Matthew D. Golub</dc:creator>
    </item>
    <item>
      <title>Longitudinal analysis of heart rate variability as it pertains to anxiety and readiness</title>
      <link>https://arxiv.org/abs/2506.19128</link>
      <description>arXiv:2506.19128v1 Announce Type: new 
Abstract: The aim of this study is to explore the relationship between lifestyle choices, subjective experiences and objective biometric data in a single individual. The participant, at the time a male in his twenties, used the EliteHRV app to perform Heart Rate Variability Readings across twenty-six months accompanied by logs about the previous days activity as well as current emotional and physical state. The study will use a mixed-methods approach to analyze the data, including quantitative analysis of the biometric data and correlation analysis between the biometric data and subjective experience tags. Qualitative analysis of the daily logs will also be conducted to gain a deeper understanding of the participant's experiences and to identify keywords, people, or ideas that affect biometric output. The results of this study will provide insights into the relationship between subjective and objective measures, and the potential benefits or drawbacks of certain lifestyle choices and ways of thinking. The findings could have implications for the development of wearable-based personalized interventions for improving mental health and well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19128v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tucker Paron</dc:creator>
    </item>
    <item>
      <title>Convergent and divergent connectivity patterns of the arcuate fasciculus in macaques and humans</title>
      <link>https://arxiv.org/abs/2506.19266</link>
      <description>arXiv:2506.19266v1 Announce Type: new 
Abstract: The organization and connectivity of the arcuate fasciculus (AF) in nonhuman primates remain contentious, especially concerning how its anatomy diverges from that of humans. Here, we combined cross-scale single-neuron tracing - using viral-based genetic labeling and fluorescence micro-optical sectioning tomography in macaques (n = 4; age 3 - 11 years) - with whole-brain tractography from 11.7T diffusion MRI. Complemented by spectral embedding analysis of 7.0T MRI in humans, we performed a comparative connectomic analysis of the AF across species. We demonstrate that the macaque AF originates in the temporal-parietal cortex, traverses the auditory cortex and parietal operculum, and projects into prefrontal regions. In contrast, the human AF exhibits greater expansion into the middle temporal gyrus and stronger prefrontal and parietal operculum connectivity - divergences quantified by Kullback-Leibler analysis that likely underpin the evolutionary specialization of human language networks. These interspecies differences - particularly the human AF's broader temporal integration and strengthened frontoparietal linkages - suggest a connectivity-based substrate for the emergence of advanced language processing unique to humans. Furthermore, our findings offer a neuroanatomical framework for understanding AF-related disorders such as aphasia and dyslexia, where aberrant connectivity disrupts language function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19266v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahao Huang, Ruifeng Li, Wenwen Yu, Anan Li, Xiangning Li, Mingchao Yan, Lei Xie, Qingrun Zeng, Xueyan Jia, Shuxin Wang, Ronghui Ju, Feng Chen, Qingming Luo, Hui Gong, Xiaoquan Yang, Yuanjing Feng, Zheng Wang</dc:creator>
    </item>
    <item>
      <title>Increasing Efficiency of the Chain of Contagion Task</title>
      <link>https://arxiv.org/abs/2506.19314</link>
      <description>arXiv:2506.19314v1 Announce Type: new 
Abstract: The chain of contagion task (CCT) is a pychological test to measure the amount of contagious beliefs in individuals. Contagious beliefs thereby refer to the perception that certain objects, people, or substances can transmit contamination through mere contact or proximity (Rozin et al., 1986). In the CCT, a neutral object (usually a pen) is rubbed against an inherently disgusting object (e.g. a toilet paper with feces) and participants are asked how contaminated this pen is on a scale from 0 (not at all) to 100 (very contaminated). Afterwards, this pen is rubbed against another pen, and again, the experienced degree of contamination is assessed. This is repeated 12 times. The CCT has first been experimentally investigated by Tolin et al. (2004) in an in vivo procedure with real disgusting objects. The authors could show that contagious beliefs measured with the CCT show a strong bias for people with contamination-based obsessive-compulsive disorder (C-OCD) compared to anxious individuals and non-anxious controls. Fink-Lamotte et al. (2024) replicated these findings with an online version of the CCT using audio-imagery-based and video-based stimuli and instructions. Both studies used 12 pens to assess the degree of contagious beliefs. Within this brief report, we show that after 8 pens, hardly any additional variance is explained between participants and after the tenth pen, no new information is gained. Thus, we recommend only using 8 pens instead of 12 when using the CCT to assess contagious beliefs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19314v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars OM Rothkegel, Jakob Fink-Lamotte</dc:creator>
    </item>
    <item>
      <title>The time course of visuo-semantic representations in the human brain is captured by combining vision and language models</title>
      <link>https://arxiv.org/abs/2506.19497</link>
      <description>arXiv:2506.19497v1 Announce Type: new 
Abstract: The human visual system provides us with a rich and meaningful percept of the world, transforming retinal signals into visuo-semantic representations. For a model of these representations, here we leveraged a combination of two currently dominating approaches: vision deep neural networks (DNNs) and large language models (LLMs). Using large-scale human electroencephalography (EEG) data recorded during object image viewing, we built encoding models to predict EEG responses using representations from a vision DNN, an LLM, and their fusion. We show that the fusion encoding model outperforms encoding models based on either the vision DNN or the LLM alone, as well as previous modelling approaches, in predicting neural responses to visual stimulation. The vision DNN and the LLM complemented each other in explaining stimulus-related signal in the EEG responses. The vision DNN uniquely captured earlier and broadband EEG signals, whereas the LLM uniquely captured later and low frequency signals, as well as detailed visuo-semantic stimulus information. Together, this provides a more accurate model of the time course of visuo-semantic processing in the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19497v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boyan Rong, Alessandro Thomas Gifford, Emrah D\"uzel, Radoslaw Martin Cichy</dc:creator>
    </item>
    <item>
      <title>Modeling the influences of non-local connectomic projections on geometrically constrained cortical dynamics</title>
      <link>https://arxiv.org/abs/2506.19800</link>
      <description>arXiv:2506.19800v1 Announce Type: new 
Abstract: The function and dynamics of the cortex are fundamentally shaped by the specific wiring configurations of its constituent axonal fibers, also known as the connectome. However, many dynamical properties of macroscale cortical activity are well captured by instead describing the activity as propagating waves across the cortical surface, constrained only by the surface's two-dimensional geometry. It thus remains an open question why the local geometry of the cortex can successfully capture macroscale cortical dynamics, despite neglecting the specificity of Fast-conducting, Non-local Projections (FNPs) which are known to mediate the rapid and non-local propagation of activity between remote neural populations. Here we address this question by developing a novel mathematical model of macroscale cortical activity in which cortical populations interact both by a continuous sheet and by an additional set of FNPs wired independently of the sheet's geometry. By simulating the model across a range of connectome topologies, external inputs, and timescales, we demonstrate that the addition of FNPs strongly shape the model dynamics of rapid, stimulus-evoked responses on fine millisecond timescales ($\lessapprox 30~\text{ms}$), but contribute relatively little to slower, spontaneous fluctuations over longer timescales ($&gt; 30~\text{ms}$), which increasingly resemble geometrically constrained dynamics without FNPs. Our results suggest that the discrepant views regarding the relative contributions of local (geometric) and non-local (connectomic) cortico-cortical interactions are context-dependent: While FNPs specified by the connectome are needed to capture rapid communication between specific distant populations (as per the rapid processing of sensory inputs), they play a relatively minor role in shaping slower spontaneous fluctuations (as per resting-state functional magnetic resonance imaging).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19800v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rishikesan Maran, Eli J. M\"uller, Ben D. Fulcher</dc:creator>
    </item>
    <item>
      <title>Markov Blanket Density and Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2506.05794</link>
      <description>arXiv:2506.05794v3 Announce Type: replace 
Abstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics (including the minimization of variational and expected free energy) naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the definability and coherence of the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05794v3</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca M. Possati</dc:creator>
    </item>
    <item>
      <title>Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers</title>
      <link>https://arxiv.org/abs/2410.05266</link>
      <description>arXiv:2410.05266v2 Announce Type: replace-cross 
Abstract: We introduce BrainSAIL, a method for linking neural selectivity with spatially distributed semantic visual concepts in natural scenes. BrainSAIL leverages recent advances in large-scale artificial neural networks, using them to provide insights into the functional topology of the brain. To overcome the challenge presented by the co-occurrence of multiple categories in natural images, BrainSAIL exploits semantically consistent, dense spatial features from pre-trained vision models, building upon their demonstrated ability to robustly predict neural activity. This method derives clean, spatially dense embeddings without requiring any additional training, and employs a novel denoising process that leverages the semantic consistency of images under random augmentations. By unifying the space of whole-image embeddings and dense visual features and then applying voxel-wise encoding models to these features, we enable the identification of specific subregions of each image which drive selectivity patterns in different areas of the higher visual cortex. This provides a powerful tool for dissecting the neural mechanisms that underlie semantic visual processing for natural images. We validate BrainSAIL on cortical regions with known category selectivity, demonstrating its ability to accurately localize and disentangle selectivity to diverse visual concepts. Next, we demonstrate BrainSAIL's ability to characterize high-level visual selectivity to scene properties and low-level visual features such as depth, luminance, and saturation, providing insights into the encoding of complex visual information. Finally, we use BrainSAIL to directly compare the feature selectivity of different brain encoding models across different regions of interest in visual cortex. Our innovative method paves the way for significant advances in mapping and decomposing high-level visual representations in the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05266v2</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrew F. Luo, Jacob Yeung, Rushikesh Zawar, Shaurya Dewan, Margaret M. Henderson, Leila Wehbe, Michael J. Tarr</dc:creator>
    </item>
  </channel>
</rss>
