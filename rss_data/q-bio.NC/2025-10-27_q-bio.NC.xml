<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Oct 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Statistics of correlations in nonlinear recurrent neural networks</title>
      <link>https://arxiv.org/abs/2510.21742</link>
      <description>arXiv:2510.21742v1 Announce Type: new 
Abstract: The statistics of correlations are central quantities characterizing the collective dynamics of recurrent neural networks. We derive exact expressions for the statistics of correlations of nonlinear recurrent networks in the limit of a large number N of neurons, including systematic 1/N corrections. Our approach uses a path-integral representation of the network's stochastic dynamics, which reduces the description to a few collective variables and enables efficient computation. This generalizes previous results on linear networks to include a wide family of nonlinear activation functions, which enter as interaction terms in the path integral. These interactions can resolve the instability of the linear theory and yield a strictly positive participation dimension. We present explicit results for power-law activations, revealing scaling behavior controlled by the network coupling. In addition, we introduce a class of activation functions based on Pade approximants and provide analytic predictions for their correlation statistics. Numerical simulations confirm our theoretical results with excellent agreement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21742v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>German Mato, Facundo Rigatuso, Gonzalo Torroba</dc:creator>
    </item>
    <item>
      <title>Limitations of Proprioceptive Working Memory</title>
      <link>https://arxiv.org/abs/2510.21996</link>
      <description>arXiv:2510.21996v1 Announce Type: new 
Abstract: Recalling previously experienced movements is essential for a range of activities, including sports, music, and rehabilitation, yet little is known about the accuracy and decay of proprioceptive working memory. We examined how introducing a short-term memory component affected movement reproduction accuracy by comparing movement reproduction under two conditions: simultaneous reproduction (SimRep) and memorized reproduction (MemRep). In Experiment 1 (N = 191), participants felt a 5-s haptic trajectory with one hand and reproduced it with the other hand simultaneously or immediately after the template ended. Errors were greater in MemRep than SimRep (31.1 deg vs. 21.5 deg, p &lt; 0.001). MemRep trajectories showed systematic temporal distortions: participants lagged fast movements and led slow ones (R = -0.32, p = 0.01), unlike the ~279 ms lag in SimRep. In Experiment 2 (N = 33), we varied template durations (2-8 s). Longer durations increased error for MemRep but not SimRep (p &lt; 0.001). During MemRep, accuracy declined steadily, with replay-template correlations dropping from ~0.4 to ~0.1 over ~3 s, while SimRep correlations rose from ~0.25 to ~0.6. In ~10% of MemRep templates, participants moved in the wrong direction initially, especially for low-amplitude movements (p &lt; 0.001). Templates with more than four movements showed element omission; after four movements had been reproduced participants ceased movement prematurely, affecting up to 40% of 8-s templates. These findings show that transferring proprioceptive experiences into working memory introduces systematic temporal and structural distortions. Accuracy decays within seconds, and memory span for movement trajectories was limited to four movements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21996v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caitlin Callaghan, David J Reinkensmeyer</dc:creator>
    </item>
    <item>
      <title>Lateral Ventricular Brain-Computer Interface System with Lantern-Inspired Electrode for Stable Performance and Memory Decoding</title>
      <link>https://arxiv.org/abs/2510.22262</link>
      <description>arXiv:2510.22262v1 Announce Type: new 
Abstract: We present a lateral ventricular brain-computer interface (LV-BCI) that deploys an expandable, flexible electrode into the lateral ventricle through a minimally invasive external ventricular drainage pathway. Inspired by the framework of traditional Chinese lanterns, the electrode expands uniformly within the ventricle and conforms to the ependymal wall. Compared with conventional subdural ECoG electrodes, the LV-BCI shows superior signal stability and immunocompatibility. Resting-state spectral analyses revealed a maximum effective bandwidth comparable to subdural ECoG. In evoked potential tests, the LV-BCI maintained a consistently higher signal-to-noise ratio over 112 days without the decline typically associated with scarring or other immune responses. Immunohistochemistry showed only a transient, early microglial activation after implantation, returning to control levels and remaining stable through 168 days. We further designed an "action-memory T-maze" task and developed a microstate sequence classifier (MSSC) to predict rats' turn decisions. The LV-BCI achieved prediction accuracy up to 98%, significantly outperforming subdural ECoG, indicating enhanced access to decision-related information from deep structures such as the hippocampus. These results establish the lateral ventricle as a viable route for neural signal acquisition. Using a lantern-inspired flexible electrode, we achieve long-term stable recordings and robust memory decision decoding from within the ventricular system, opening new directions for BCI technology and systems neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22262v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yike Sun, Yaxuan Gao, Kewei Wang, Jingnan Sun, Yuzhen Chen, Yanan Yang, Tianhua Zhao, Haochen Zhu, Ran Liu, Xiaogang Chen, Bai Lu, Xiaorong Gao</dc:creator>
    </item>
    <item>
      <title>Tuned for Creativity? Graph-Theoretical Mapping of Resting-State EEG Reveals Neural Signatures of Creativity</title>
      <link>https://arxiv.org/abs/2510.22364</link>
      <description>arXiv:2510.22364v1 Announce Type: new 
Abstract: Understanding how creativity is represented in the brain's intrinsic functional architecture remains a central challenge in cognitive neuroscience. While resting-state fMRI studies have revealed large-scale network correlates of creative potential, electroencephalography (EEG) offers a temporally precise and scalable approach to capture the fast oscillatory dynamics that underlie spontaneous neural organization. In this study, we used a data-driven network approach to examine whether resting-state EEG connectivity patterns differentiate individuals according to their creative abilities. Creativity was evaluated by: The Inventory of Creative Activities and Achievements (ICAA), The Divergent Association Task (DAT), The Matchstick Arithmetic Puzzles Task (MAPT) and Self-rating (SR) of creative ability in 30 healthy young adults. Graph-theoretical analyses were applied to functional connectivity matrices and clustered based on graph similarity. Two distinct participant clusters emerged, differing systematically across multiple dimensions of creativity. Cluster 1, characterized by consistently higher performance across multiple creativity variables (ICAA, DAT, MAPT and SR), showed broad alpha-band hypoconnectivity, relatively preserved left frontal connectivity and greater network modularity. Cluster 0, associated with lower creativity scores, exhibited stronger overall connectivity strength, reduced modularity and higher local clustering. These findings suggest that resting-state EEG connectivity patterns can index stable cognitive traits such as creativity. More broadly, they point to an intrinsic neural signature of adaptive brain function marked by efficient yet flexible network organization that may support creative and adaptive cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22364v1</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samir Damji, Simrut Kurry, Shazia'Ayn Babul, Joydeep Bhattacharya, Naznin Virji-Babul</dc:creator>
    </item>
    <item>
      <title>Neural Recording Power Optimization Through Machine Learning Guided Resolution Reconfiguration</title>
      <link>https://arxiv.org/abs/2510.22924</link>
      <description>arXiv:2510.22924v1 Announce Type: new 
Abstract: Neural recording implants are a crucial tool for both neuroscience research and enabling new clinical applications. The power consumption of high channel count implants is dominated by the circuits used to amplify and digitize neural signals. Since circuit designers have pushed the efficiency of these circuits close to the theoretical physical limits, reducing power further requires system level optimization. Recent advances use a strategy called channel selection, in which less important channels are turned off to save power. We demonstrate resolution reconfiguration, in which the resolution of less important channels is scaled down to save power. Our approach leverages variable importance of each channel inside machine-learning-based decoders and we trial this methodology across three applications: seizure detection, gesture recognition, and force regression. With linear decoders, resolution reconfiguration saves 8.7x, 12.8x, and 23.0x power compared to a traditional recording array for each task respectively. It further saves 1.6x, 3.4x, and 5.2x power compared to channel selection. The results demonstrate the power benefits of resolution reconfigurable front-ends and their wide applicability to neural decoding problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22924v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviral Pandey, Dhruv Vaish, I-Ting Lin, Rikky Muller</dc:creator>
    </item>
    <item>
      <title>Model-Behavior Alignment under Flexible Evaluation: When the Best-Fitting Model Isn't the Right One</title>
      <link>https://arxiv.org/abs/2510.23321</link>
      <description>arXiv:2510.23321v1 Announce Type: new 
Abstract: Linearly transforming stimulus representations of deep neural networks yields high-performing models of behavioral and neural responses to complex stimuli. But does the test accuracy of such predictions identify genuine representational alignment? We addressed this question through a large-scale model-recovery study. Twenty diverse vision models were linearly aligned to 4.5 million behavioral judgments from the THINGS odd-one-out dataset and calibrated to reproduce human response variability. For each model in turn, we sampled synthetic responses from its probabilistic predictions, fitted all candidate models to the synthetic data, and tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set size but plateaued below 80%, even at millions of simulated trials. Regression analyses linked misidentification primarily to shifts in representational geometry induced by the linear transformation, as well as to the effective dimensionality of the transformed features. These findings demonstrate that, even with massive behavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison experiments must be designed to balance the trade-off between predictive accuracy and identifiability-ensuring that the best-fitting model is also the right one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23321v1</guid>
      <category>q-bio.NC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itamar Avitan, Tal Golan</dc:creator>
    </item>
    <item>
      <title>Conduction velocity of intracortical axons in monkey primary visual cortex grows with distance: implications for computation</title>
      <link>https://arxiv.org/abs/2510.23391</link>
      <description>arXiv:2510.23391v1 Announce Type: new 
Abstract: A critical visual computation is to construct global scene properties from activities of early visual cortical neurons which have small receptive fields. Such a computation is enabled by contextual influences, through which a neuron's response to visual inputs is influenced by contextual inputs outside its classical receptive fields. Accordingly, neurons can signal global properties including visual saliencies and figure-ground relationships. Many believe that intracortical axons conduct signals too slowly to bring the contextual information from receptive fields of other neurons. A popular opinion is that much of the contextual influences arise from feedback from higher visual areas whose neurons have larger receptive fields. This paper re-examines pre-existing data to reveal these unexpected findings: the conduction speed of V1 intracortical axons increases approximately linearly with the conduction distance, and is sufficiently high for conveying the contextual influences. Recognizing the importance of intracortical contribution to critical visual computations should enable fresh progress in answering long-standing questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23391v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Zhaoping</dc:creator>
    </item>
    <item>
      <title>Automated Tinnitus Detection Through Dual-Modality Neuroimaging: EEG Microstate Analysis and Resting-State fMRI Classification Using Deep Learning</title>
      <link>https://arxiv.org/abs/2510.21748</link>
      <description>arXiv:2510.21748v1 Announce Type: cross 
Abstract: Objective: Tinnitus affects 10-15% of the population yet lacks objective diagnostic biomarkers. This study applied machine learning to EEG and fMRI data to identify neural signatures distinguishing tinnitus patients from healthy controls. Methods: Two datasets were analyzed: 64-channel EEG recordings from 80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38 participants (19 tinnitus, 19 controls). EEG analysis extracted microstate features across four to seven clustering states and five frequency bands, producing 440 features per subject. Global Field Power signals were also transformed into wavelet images for deep learning. fMRI data were analyzed using slice-wise convolutional neural networks and hybrid models combining pre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest, and SVM classifiers. Model performance was evaluated using 5-fold cross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC. Results: EEG microstate analysis revealed altered network dynamics in tinnitus, particularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs tinnitus: 43.81, p &lt; 0.001) and diminished alpha coverage. Tree-based classifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed EEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively. fMRI analysis identified 12 high-performing axial slices (&gt;=90% accuracy), with slice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95% +/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural biomarkers for tinnitus classification. Tree-based and hybrid models demonstrated superior performance, highlighting tinnitus as a multi-network disorder requiring multimodal analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21748v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiana Kiashemshaki, Sina Samieirad, Sarvenaz Erfani, Aryan Jalaeianbanayan, Nasibeh Asadi Isakan, Hossein Najafzadeh</dc:creator>
    </item>
    <item>
      <title>Control of neural field equations with step-function inputs</title>
      <link>https://arxiv.org/abs/2510.22022</link>
      <description>arXiv:2510.22022v1 Announce Type: cross 
Abstract: Wilson-Cowan and Amari-type models capture nonlinear neural population dynamics, providing a fundamental framework for modeling how sensory and other exogenous inputs shape activity in neural tissue. We study the controllability properties of Amari-type neural fields subject to piecewise/constant-in-time inputs. The model describes the time evolution of the polarization of neural tissue within a spatial continuum, with synaptic interactions represented by a convolution kernel. We study the synthesis of piecewise/constant-in-time inputs to achieve two-point boundary-type control objectives, namely, steering neural activity from an initial state to a prescribed target state. This approach is particularly relevant for predicting the emergence of paradoxical neural representations, such as discordant visual illusions that occur in response to overt sensory stimuli. We first present a control synthesis based on the Banach fixed-point theorem, which yields an iterative construction of a constant-in-time input under minimal regularity assumptions on the kernel and transfer function; however, it exhibits practical limitations, even in the linear case. To overcome these challenges, we then develop a generic synthesis framework based on the flow of neural dynamics drift, enabling explicit piecewise constant and constant-in-time inputs. Extensive numerical results in one and two spatial dimensions confirm the effectiveness of the proposed syntheses and demonstrate their superior performance compared to inputs derived from naive linearization at the initial or target states when these states are not equilibria of the drift dynamics. By providing a mathematically rigorous framework for controlling Amari-type neural fields, this work advances our understanding of nonlinear neural population control with potential applications in computational neuroscience, psychophysics, and neurostimulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22022v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, ShiNung Ching</dc:creator>
    </item>
    <item>
      <title>Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability</title>
      <link>https://arxiv.org/abs/2510.22039</link>
      <description>arXiv:2510.22039v1 Announce Type: cross 
Abstract: Learning a compact representation of history is critical for planning and generalization in partially observable environments. While meta-reinforcement learning (RL) agents can attain near Bayes-optimal policies, they often fail to learn the compact, interpretable Bayes-optimal belief states. This representational inefficiency potentially limits the agent's adaptability and generalization capacity. Inspired by predictive coding in neuroscience--which suggests that the brain predicts sensory inputs as a neural implementation of Bayesian inference--and by auxiliary predictive objectives in deep RL, we investigate whether integrating self-supervised predictive coding modules into meta-RL can facilitate learning of Bayes-optimal representations. Through state machine simulation, we show that meta-RL with predictive modules consistently generates more interpretable representations that better approximate Bayes-optimal belief states compared to conventional meta-RL across a wide variety of tasks, even when both achieve optimal policies. In challenging tasks requiring active information seeking, only meta-RL with predictive modules successfully learns optimal representations and policies, whereas conventional meta-RL struggles with inadequate representation learning. Finally, we demonstrate that better representation learning leads to improved generalization. Our results strongly suggest the role of predictive learning as a guiding principle for effective representation learning in agents navigating partial observability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22039v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Po-Chen Kuo, Han Hou, Will Dabney, Edgar Y. Walker</dc:creator>
    </item>
    <item>
      <title>Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable Affective Computing</title>
      <link>https://arxiv.org/abs/2510.22197</link>
      <description>arXiv:2510.22197v1 Announce Type: cross 
Abstract: Task-specific pre-training is essential when task representations diverge from generic pre-training features. Existing task-general pre-training EEG models struggle with complex tasks like emotion recognition due to mismatches between task-specific features and broad pre-training approaches. This work aims to develop a task-specific multi-dataset joint pre-training framework for cross-dataset emotion recognition, tackling problems of large inter-dataset distribution shifts, inconsistent emotion category definitions, and substantial inter-subject variability. We introduce a cross-dataset covariance alignment loss to align second-order statistical properties across datasets, enabling robust generalization without the need for extensive labels or per-subject calibration. To capture the long-term dependency and complex dynamics of EEG, we propose a hybrid encoder combining a Mamba-like linear attention channel encoder and a spatiotemporal dynamics model. Our method outperforms state-of-the-art large-scale EEG models by an average of 4.57% in AUROC for few-shot emotion recognition and 11.92% in accuracy for zero-shot generalization to a new dataset. Performance scales with the increase of datasets used in pre-training. Multi-dataset joint pre-training achieves a performance gain of 8.55% over single-dataset training. This work provides a scalable framework for task-specific pre-training and highlights its benefit in generalizable affective computing. Our code is available at https://github.com/ncclab-sustech/mdJPT_nips2025.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22197v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Qingzhu Zhang, Jiani Zhong, Zongsheng Li, Xinke Shen, Quanying Liu</dc:creator>
    </item>
    <item>
      <title>Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement</title>
      <link>https://arxiv.org/abs/2510.22860</link>
      <description>arXiv:2510.22860v1 Announce Type: cross 
Abstract: Understanding how the human brain progresses from processing simple linguistic inputs to performing high-level reasoning is a fundamental challenge in neuroscience. While modern large language models (LLMs) are increasingly used to model neural responses to language, their internal representations are highly "entangled," mixing information about lexicon, syntax, meaning, and reasoning. This entanglement biases conventional brain encoding analyses toward linguistically shallow features (e.g., lexicon and syntax), making it difficult to isolate the neural substrates of cognitively deeper processes. Here, we introduce a residual disentanglement method that computationally isolates these components. By first probing an LM to identify feature-specific layers, our method iteratively regresses out lower-level representations to produce four nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically, reasoning. We used these disentangled embeddings to model intracranial (ECoG) brain recordings from neurosurgical patients listening to natural speech. We show that: 1) This isolated reasoning embedding exhibits unique predictive power, accounting for variance in neural activity not explained by other linguistic features and even extending to the recruitment of visual regions beyond classical language areas. 2) The neural signature for reasoning is temporally distinct, peaking later (~350-400ms) than signals related to lexicon, syntax, and meaning, consistent with its position atop a processing hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as their predictive success is primarily attributable to linguistically shallow features, masking the more subtle contributions of deeper cognitive processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22860v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Linyang He, Tianjun Zhong, Richard Antonello, Gavin Mischler, Micah Goldblum, Nima Mesgarani</dc:creator>
    </item>
    <item>
      <title>Clinic-Oriented Feasibility of a Sensor-Fused Wearable for Upper-Limb Function</title>
      <link>https://arxiv.org/abs/2510.22913</link>
      <description>arXiv:2510.22913v1 Announce Type: cross 
Abstract: Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of daily living (ADL) and reduce adherence to home rehabilitation. Objective: To assess technical feasibility and clinician-relevant signals of a sensor-fused wearable targeting the triceps brachii and extensor pollicis brevis. Methods: A lightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and flex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and a safety-bounded assist policy (angle/torque/jerk limits; stall/time-out). Healthy adults (n = 12) performed three ADL-like tasks. Primary outcomes: Tremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$). Secondary: EMG median-frequency slope (fatigue trend), closed-loop latency, session completion, and device-related adverse events. Analyses used subject-level paired medians with BCa 95\% CIs; exact Wilcoxon $p$-values are reported in the Results. Results: Assistance was associated with lower tremor prominence and improved task throughput: TI decreased by $-0.092$ (95\% CI [$-0.102$, $-0.079$]), ROM increased by $+12.65\%$ (95\% CI [$+8.43$, $+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\% CI [$+2.61$, $+3.35$]). Median on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were completed with no device-related adverse events. Conclusions: Multimodal sensing with low-latency, safety-bounded assistance produced improved movement quality (TI $\downarrow$) and throughput (ROM, Reps $\uparrow$) in a pilot technical-feasibility setting, supporting progression to IRB-approved patient studies. Trial registration: Not applicable (pilot non-clinical).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22913v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanyanee Srichaisak, Arissa Ieochai, Aueaphum Aueawattthanaphisut</dc:creator>
    </item>
    <item>
      <title>Connectivity structure and dynamics of nonlinear recurrent neural networks</title>
      <link>https://arxiv.org/abs/2409.01969</link>
      <description>arXiv:2409.01969v3 Announce Type: replace 
Abstract: Studies of the dynamics of nonlinear recurrent neural networks often assume independent and identically distributed couplings, but large-scale connectomics data indicate that biological neural circuits exhibit markedly different connectivity properties. These include rapidly decaying singular-value spectra and structured singular-vector overlaps. Here, we develop a theory to analyze how these forms of structure shape high-dimensional collective activity in nonlinear recurrent neural networks. We first introduce the random-mode model, a random-matrix ensemble related to the singular-value decomposition that enables control over the spectrum and right-left mode overlaps. Then, using a novel path-integral calculation, we derive analytical expressions that reveal how connectivity structure affects features of collective dynamics: the dimension of activity, which quantifies the number of high-variance collective-activity fluctuations, and the temporal correlations that characterize the timescales of these fluctuations. We show that connectivity structure can be invisible in single-neuron activities while dramatically shaping collective activity. Furthermore, despite the nonlinear, high-dimensional nature of these networks, the dimension of activity depends on just two connectivity parameters -- the variance of the couplings and the effective rank of the coupling matrix, which quantifies the number of dominant rank-one connectivity components. We contrast the effects of single-neuron heterogeneity and low dimensional connectivity, making predictions about how z-scoring data affects the dimension of activity. Finally, we demonstrate the presence of structured overlaps between left and right modes in the Drosophila connectome, incorporate them into the theory, and show how they further shape collective dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01969v3</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David G. Clark, Owen Marschall, Alexander van Meegen, Ashok Litwin-Kumar</dc:creator>
    </item>
    <item>
      <title>Probabilistic adaptation of language comprehension for individual speakers: evidence from neural oscillations</title>
      <link>https://arxiv.org/abs/2502.01299</link>
      <description>arXiv:2502.01299v2 Announce Type: replace 
Abstract: Listeners adapt language comprehension based on their mental representations of speakers, but how these representations are updated remains unclear. We investigated whether listeners probabilistically adapt comprehension based on the frequency of speakers making stereotype-incongruent statements. In two EEG experiments, participants heard speakers make stereotype-congruent or incongruent statements, with incongruency base rate manipulated. In Experiment 1, stereotype-incongruent statements decreased high-beta (21-30 Hz) and theta (4-6 Hz) oscillatory power in the low base rate condition but increased it in the high base rate condition. The theta effect varied with listeners' openness trait: less open-minded participants tended to show theta increases to stereotype incongruencies, while more open-minded participants tended to show theta decreases. In Experiment 2, we dissociated incongruency base rate from the target speaker by manipulating it using a non-target speaker and found that only the high-beta effect persisted. Our findings reveal two potential mechanisms: a speaker-general mechanism (indicated by high-beta oscillations) that adjusts overall expectations about hearing statements that violate social stereotypes, and a speaker-specific mechanism (indicated by theta oscillations) that updates a more detailed mental model specifically about an individual speaker. These findings provide evidence for how language processing interacts with social cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01299v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/scan/nsaf085</arxiv:DOI>
      <arxiv:journal_reference>Hanlin Wu, Xiaohui Rao, Zhenguang G Cai, Probabilistic adaptation of language comprehension for individual speakers: evidence from neural oscillations, Social Cognitive and Affective Neuroscience, Volume 20, Issue 1, 2025, nsaf085</arxiv:journal_reference>
      <dc:creator>Hanlin Wu, Xiaohui Rao, Zhenguang G Cai</dc:creator>
    </item>
    <item>
      <title>Place Cells as Multi-Scale Position Embeddings: Random Walk Transition Kernels for Path Planning</title>
      <link>https://arxiv.org/abs/2505.14806</link>
      <description>arXiv:2505.14806v4 Announce Type: replace 
Abstract: The hippocampus supports spatial navigation by encoding cognitive maps through collective place cell activity. We model the place cell population as non-negative spatial embeddings derived from the spectral decomposition of multi-step random walk transition kernels. In this framework, inner product or equivalently Euclidean distance between embeddings encode similarity between locations in terms of their transition probability across multiple scales, forming a cognitive map of adjacency. The combination of non-negativity and inner-product structure naturally induces sparsity, providing a principled explanation for the localized firing fields of place cells without imposing explicit constraints. The temporal parameter that defines the diffusion scale also determines field size, aligning with the hippocampal dorsoventral hierarchy. Our approach constructs global representations efficiently through recursive composition of local transitions, enabling smooth, trap-free navigation and preplay-like trajectory generation. Moreover, theta phase arises intrinsically as the angular relation between embeddings, linking spatial and temporal coding within a single representational geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14806v4</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minglu Zhao, Dehong Xu, Deqian Kong, Wen-Hao Zhang, Ying Nian Wu</dc:creator>
    </item>
    <item>
      <title>Transformer brain encoders explain human high-level visual responses</title>
      <link>https://arxiv.org/abs/2505.17329</link>
      <description>arXiv:2505.17329v2 Announce Type: replace 
Abstract: A major goal of neuroscience is to understand brain computations during visual processing in naturalistic settings. A dominant approach is to use image-computable deep neural networks trained with different task objectives as a basis for linear encoding models. However, in addition to requiring estimation of a large number of linear encoding parameters, this approach ignores the structure of the feature maps both in the brain and the models. Recently proposed alternatives factor the linear mapping into separate sets of spatial and feature weights, thus finding static receptive fields for units, which is appropriate only for early visual areas. In this work, we employ the attention mechanism used in the transformer architecture to study how retinotopic visual features can be dynamically routed to category-selective areas in high-level visual processing. We show that this computational motif is significantly more powerful than alternative methods in predicting brain activity during natural scene viewing, across different feature basis models and modalities. We also show that this approach is inherently more interpretable as the attention-routing signals for different high-level categorical areas can be easily visualized for any input image. Given its high performance at predicting brain responses to novel images, the model deserves consideration as a candidate mechanistic model of how visual information from retinotopic maps is routed in the human brain based on the relevance of the input content to different category-selective regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17329v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hossein Adeli, Sun Minni, Nikolaus Kriegeskorte</dc:creator>
    </item>
    <item>
      <title>REMI: Reconstructing Episodic Memory During Internally Driven Path Planning</title>
      <link>https://arxiv.org/abs/2507.02064</link>
      <description>arXiv:2507.02064v2 Announce Type: replace 
Abstract: Grid cells in the medial entorhinal cortex (MEC) and place cells in the hippocampus (HC) both form spatial representations. Grid cells fire in triangular grid patterns, while place cells fire at specific locations and respond to contextual cues. How do these interacting systems support not only spatial encoding but also internally driven path planning, such as navigating to locations recalled from cues? Here, we propose a system-level theory of MEC-HC wiring that explains how grid and place cell patterns could be connected to enable cue-triggered goal retrieval, path planning, and reconstruction of sensory experience along planned routes. We suggest that place cells autoassociate sensory inputs with grid cell patterns, allowing sensory cues to trigger recall of goal-location grid patterns. We show analytically that grid-based planning permits shortcuts through unvisited locations and generalizes local transitions to long-range paths. During planning, intermediate grid states trigger place cell pattern completion, reconstructing sensory experiences along the route. Using a single-layer RNN modeling the HC-MEC loop with a planning subnetwork, we demonstrate these effects in both biologically grounded navigation simulations using RatatouGym and visually realistic navigation tasks using Habitat Sim.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02064v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoze Wang, Genela Morris, Dori Derdikman, Pratik Chaudhari, Vijay Balasubramanian</dc:creator>
    </item>
    <item>
      <title>Time-Resolved EEG Decoding of Semantic Processing Reveals Altered Neural Dynamics in Depression and Suicidality</title>
      <link>https://arxiv.org/abs/2507.22313</link>
      <description>arXiv:2507.22313v2 Announce Type: replace 
Abstract: Depression and suicidality affect cognitive and emotional processes, yet objective, task-evoked neural readouts of mental health remain limited. We investigated the spatiotemporal dynamics of affective semantic processing using multivariate decoding of time-resolved, 64-channel electroencephalography (EEG). Participants (N=137) performed a sentence-evaluation task with emotionally salient, self-referential statements. We identified robust neural signatures of semantic processing, with peak decoding accuracy between 300-600 ms -- a window associated with rapid, stimulus-driven semantic evaluation and conflict monitoring. Relative to healthy controls, individuals with depression and suicidal ideation showed earlier onset, longer duration, and greater amplitude decoding responses, along with broader cross-temporal generalization and enhanced contributions from frontocentral and parietotemporal components. These findings suggest altered sensitivity and impaired disengagement from emotionally salient content in the clinical groups, advancing our understanding of the neurocognitive basis of mental health and establishing a compact and interpretable EEG-based index of semantic-evaluation dynamics with potential diagnostic relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22313v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Woojae Jeong, Aditya Kommineni, Kleanthis Avramidis, Colin McDaniel, Donald Berry, Myzelle Hughes, Thomas McGee, Elsi Kaiser, Dani Byrd, Assal Habibi, B. Rael Cahn, Idan A. Blank, Kristina Lerman, Dimitrios Pantazis, Sudarsana R. Kadiri, Takfarinas Medani, Shrikanth Narayanan, Richard M. Leahy</dc:creator>
    </item>
    <item>
      <title>The ISLab Solution to the Algonauts Challenge 2025: A Multimodal Deep Learning Approach to Brain Response Prediction</title>
      <link>https://arxiv.org/abs/2508.06499</link>
      <description>arXiv:2508.06499v2 Announce Type: replace 
Abstract: In this work, we present a network-specific approach for predicting brain responses to complex multimodal movies, leveraging the Yeo 7-network parcellation of the Schaefer atlas. Rather than treating the brain as a homogeneous system, we grouped the seven functional networks into four clusters and trained separate multi-subject, multi-layer perceptron (MLP) models for each. This architecture supports cluster-specific optimization and adaptive memory modeling, allowing each model to adjust temporal dynamics and modality weighting based on the functional role of its target network. Our results demonstrate that this clustered strategy significantly enhances prediction accuracy across the 1,000 cortical regions of the Schaefer atlas. The final model achieved an eighth-place ranking in the Algonauts Project 2025 Challenge, with out-of-distribution (OOD) correlation scores nearly double those of the baseline model used in the selection phase. Code is available at https://github.com/Corsi01/algo2025.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06499v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Corsico, Giorgia Rigamonti, Simone Zini, Luigi Celona, Paolo Napoletano</dc:creator>
    </item>
    <item>
      <title>Quantifying Mental States in Work Environment: Mathematical Perspectives</title>
      <link>https://arxiv.org/abs/2509.12162</link>
      <description>arXiv:2509.12162v3 Announce Type: replace 
Abstract: We introduce a novel framework for quantifying mental and emotional states over time by combining virtual reality (VR) exposure with EEG recordings. Participants experienced a stress-inducing work scenario in VR, originally designed as a training tool for bank employees, providing a controlled proxy for high-stakes situations. This setup enables integration of subjective emotional self-assessments with objective neural data, from which an algorithm was efficiently used to infer emotional states. Building on these measurements, we propose possible mathematical models to capture the temporal dynamics of mental states, offering a quantitative approach to studying emotional processing and informing adaptive training in complex environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12162v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aymen Balti, Assane Wade, Abdelatif Oujbara, M. A.,  Aziz-Alaoui, Hicham Bellarabi, Frederic Dutertre, Benjamin Ambrosio</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2509.17174</link>
      <description>arXiv:2509.17174v2 Announce Type: replace 
Abstract: Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data generated from ring attractor network models and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model reliably resolves spurious correlations and recovers accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17174v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kijung Yoon</dc:creator>
    </item>
    <item>
      <title>State of Brain Emulation Report 2025</title>
      <link>https://arxiv.org/abs/2510.15745</link>
      <description>arXiv:2510.15745v2 Announce Type: replace 
Abstract: The State of Brain Emulation Report 2025 provides a comprehensive reassessment of the field's progress since Sandberg and Bostrom's 2008 Whole Brain Emulation roadmap. The report is organized around three core capabilities required for brain emulation: recording brain function (Neural Dynamics), mapping brain structure (Connectomics), and emulation and embodiment (Computational Neuroscience). It also identifies ongoing challenges and outlines strategic priorities to help the field move forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15745v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niccol\`o Zanichelli, Maximilian Schons, Isaak Freeman, Philip Shiu, Anton Arkhipov</dc:creator>
    </item>
    <item>
      <title>A Minimal Quantitative Model of Perceptual Suppression and Breakthrough in Visual Rivalry</title>
      <link>https://arxiv.org/abs/2510.17154</link>
      <description>arXiv:2510.17154v2 Announce Type: replace 
Abstract: When conflicting images are presented to either eye, binocular fusion is disrupted. Rather than experiencing a blend of both percepts, often only one eye's image is experienced, whilst the other is suppressed from awareness. Importantly, suppression is transient - the two rival images compete for dominance, with stochastic switches between mutually exclusive percepts occurring every few seconds with law-like regularity. From the perspective of dynamical systems theory, visual rivalry offers an experimentally tractable window into the dynamical mechanisms governing perceptual awareness. In a recently developed visual rivalry paradigm - tracking continuous flash suppression (tCFS) - it was shown that the transition between awareness and suppression is hysteretic, with a higher contrast threshold required for a stimulus to breakthrough suppression into awareness than to be suppressed from awareness. Here, we present an analytically-tractable model of visual rivalry that quantitatively explains the hysteretic transition between periods of awareness and suppression in tCFS. Grounded in the theory of neural dynamics, we derive closed-form expressions for the duration of perceptual dominance and suppression, and for the degree of hysteresis (i.e. the depth of perceptual suppression), as a function of model parameters. Finally, our model yields a series of novel behavioural predictions, the first of which - distributions of dominance and suppression durations during tCFS should be approximately equal - we empirically validate in human psychophysical data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17154v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christopher J. Whyte, Hugh R. Wilson, Shay Tobin, Brandon R. Munn, Shervin Safavi, Eli J. Muller, Jayson Jeganathan, Matt Davidson, James M. Shine, David Alais</dc:creator>
    </item>
    <item>
      <title>Zero Echo Time Functional MRI in Humans</title>
      <link>https://arxiv.org/abs/2502.19146</link>
      <description>arXiv:2502.19146v2 Announce Type: replace-cross 
Abstract: Motivation: Conventional echo planar imaging(EPI) based functional MRI(fMRI) uses the BOLD contrast to map activity changes in human brains. Introducing an efficient ZTE sequence for functional brain mapping can help address limitations of EPI and demonstrate the feasibility of using T1 related changes as a surrogate marker of brain activity. Goals: To test and optimize ZTE sequence for fMRI. Methods: A ZTE sequence with radial inside out spokes was used to prepare a dynamic imaging protocol that matches conventional EPI time course. Temporal SNR and sensitivity to susceptibility differences of ZTE were evaluated and the sequence was benchmarked against BOLD EPI in a task based visual fMRI study with healthy volunteers at 3T. Results: Phantom measurements confirmed sensitivity of the ZTE protocol to the oxygen concentration. Functional activation in primary visual cortex could be detected using ZTE. Resting state networks could also be identified using independent component analysis. Discussion: ZTE-based fMRI is proposed for mapping functional activation in human brain. ZTE is robust against susceptibility artefacts and significantly reduces acoustic noise. Radial sampling pattern allows for high undersampling rates to increase temporal resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19146v2</guid>
      <category>physics.med-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali Caglar Ozen, Shuai Liu, Serhat Ilbey, Michael Bock, Uzay Emir, Yen-Yu Ian Shih</dc:creator>
    </item>
    <item>
      <title>Distinct social-linguistic processing between humans and large audio-language models: Evidence from model-brain alignment</title>
      <link>https://arxiv.org/abs/2503.19586</link>
      <description>arXiv:2503.19586v2 Announce Type: replace-cross 
Abstract: Voice-based AI development faces unique challenges in processing both linguistic and paralinguistic information. This study compares how large audio-language models (LALMs) and humans integrate speaker characteristics during speech comprehension, asking whether LALMs process speaker-contextualized language in ways that parallel human cognitive mechanisms. We compared two LALMs' (Qwen2-Audio and Ultravox 0.5) processing patterns with human EEG responses. Using surprisal and entropy metrics from the models, we analyzed their sensitivity to speaker-content incongruency across social stereotype violations (e.g., a man claiming to regularly get manicures) and biological knowledge violations (e.g., a man claiming to be pregnant). Results revealed that Qwen2-Audio exhibited increased surprisal for speaker-incongruent content and its surprisal values significantly predicted human N400 responses, while Ultravox 0.5 showed limited sensitivity to speaker characteristics. Importantly, neither model replicated the human-like processing distinction between social violations (eliciting N400 effects) and biological violations (eliciting P600 effects). These findings reveal both the potential and limitations of current LALMs in processing speaker-contextualized language, and suggest differences in social-linguistic processing mechanisms between humans and LALMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19586v2</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.18653/v1/2025.cmcl-1.18</arxiv:DOI>
      <arxiv:journal_reference>Hanlin Wu, Xufeng Duan, and Zhenguang Cai. 2025. Distinct social-linguistic processing between humans and large audio-language models: Evidence from model-brain alignment. In Proceedings of CMCL, pages 135-143, ACL</arxiv:journal_reference>
      <dc:creator>Hanlin Wu, Xufeng Duan, Zhenguang Cai</dc:creator>
    </item>
    <item>
      <title>Representational Difference Explanations</title>
      <link>https://arxiv.org/abs/2505.23917</link>
      <description>arXiv:2505.23917v2 Announce Type: replace-cross 
Abstract: We propose a method for discovering and visualizing the differences between two learned representations, enabling more direct and interpretable model comparisons. We validate our method, which we call Representational Differences Explanations (RDX), by using it to compare models with known conceptual differences and demonstrate that it recovers meaningful distinctions where existing explainable AI (XAI) techniques fail. Applied to state-of-the-art models on challenging subsets of the ImageNet and iNaturalist datasets, RDX reveals both insightful representational differences and subtle patterns in the data. Although comparison is a cornerstone of scientific analysis, current tools in machine learning, namely post hoc XAI methods, struggle to support model comparison effectively. Our work addresses this gap by introducing an effective and explainable tool for contrasting model representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23917v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona</dc:creator>
    </item>
    <item>
      <title>Engram Memory Encoding and Retrieval: A Neurocomputational Perspective</title>
      <link>https://arxiv.org/abs/2506.01659</link>
      <description>arXiv:2506.01659v2 Announce Type: replace-cross 
Abstract: Despite substantial research into the biological basis of memory, the precise mechanisms by which experiences are encoded, stored, and retrieved in the brain remain incompletely understood. A growing body of evidence supports the engram theory, which posits that sparse populations of neurons undergo lasting physical and biochemical changes to support long-term memory. Yet, a comprehensive computational framework that integrates biological findings with mechanistic models remains elusive. This work synthesizes insights from cellular neuroscience and computational modeling to address key challenges in engram research: how engram neurons are identified and manipulated; how synaptic plasticity mechanisms contribute to stable memory traces; and how sparsity promotes efficient, interference-resistant representations. Relevant computational approaches -- such as sparse regularization, engram gating, and biologically inspired architectures like Sparse Distributed Memory and spiking neural networks -- are also examined. Together, these findings suggest that memory efficiency, capacity, and stability emerge from the interaction of plasticity and sparsity constraints. By integrating neurobiological and computational perspectives, this paper provides a comprehensive theoretical foundation for engram research and proposes a roadmap for future inquiry into the mechanisms underlying memory, with implications for the diagnosis and treatment of memory-related disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01659v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Szelogowski</dc:creator>
    </item>
    <item>
      <title>Kuramoto Orientation Diffusion Models</title>
      <link>https://arxiv.org/abs/2509.15328</link>
      <description>arXiv:2509.15328v2 Announce Type: replace-cross 
Abstract: Orientation-rich images, such as fingerprints and textures, often exhibit coherent angular directional patterns that are challenging to model using standard generative approaches based on isotropic Euclidean diffusion. Motivated by the role of phase synchronization in biological systems, we propose a score-based generative model built on periodic domains by leveraging stochastic Kuramoto dynamics in the diffusion process. In neural and physical systems, Kuramoto models capture synchronization phenomena across coupled oscillators -- a behavior that we re-purpose here as an inductive bias for structured image generation. In our framework, the forward process performs \textit{synchronization} among phase variables through globally or locally coupled oscillator interactions and attraction to a global reference phase, gradually collapsing the data into a low-entropy von Mises distribution. The reverse process then performs \textit{desynchronization}, generating diverse patterns by reversing the dynamics with a learned score function. This approach enables structured destruction during forward diffusion and a hierarchical generation process that progressively refines global coherence into fine-scale details. We implement wrapped Gaussian transition kernels and periodicity-aware networks to account for the circular geometry. Our method achieves competitive results on general image benchmarks and significantly improves generation quality on orientation-dense datasets like fingerprints and textures. Ultimately, this work demonstrates the promise of biologically inspired synchronization dynamics as structured priors in generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15328v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yue Song, T. Anderson Keller, Sevan Brodjian, Takeru Miyato, Yisong Yue, Pietro Perona, Max Welling</dc:creator>
    </item>
  </channel>
</rss>
