<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Mar 2024 14:40:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>It Takes a Village: A Distributed Training Model for AI-based Chatbots</title>
      <link>https://arxiv.org/abs/2403.01545</link>
      <description>arXiv:2403.01545v1 Announce Type: new 
Abstract: In Summer 2023, staff from the information technology and reference departments at the University of Delaware Library, Museums and Press came together in a unique partnership to pilot a low-cost AI-powered chatbot. The goal of the pilot is to learn more about student and faculty interest in engaging with this tool, and to better understand the labor required on the staff side. Reference librarians and other public facing staff, including student workers, were instrumental in helping to train the chatbot. This article discusses the development of prompts, leveraging of existing data sources for training materials, and workflows involved in the pilot. It argues that, when implementing AI-based tools in the academic library, involving staff from across the organization is essential to ensure buy-in and success. Although chatbots are designed to hide the effort of the people behind them, such labor can be substantial and needs to be recognized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01545v1</guid>
      <category>cs.DL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Colleen Estes, Beth Twomey, Annie Johnson</dc:creator>
    </item>
    <item>
      <title>Astronomy in Colombia: a bibliometric perspective</title>
      <link>https://arxiv.org/abs/2403.02255</link>
      <description>arXiv:2403.02255v1 Announce Type: new 
Abstract: In Colombia, astronomical research is experiencing accelerated growth. In order to better understand its evolution and current state, we conducted a bibliometric study using data from the Astrophysics Data System (ADS) and Web of Science (WoS). In ADS, we identified 422 peer-reviewed publications from 1980, the year of the first publication, until 2023, which was the cutoff date for our study. Among the 25 Colombian institutions identified as participants in at least one publication, the contributions of four universities stand out: Universidad de los Andes, Universidad Nacional de Colombia, Universidad Industrial de Santander, and Universidad de Antioquia, with 104, 78, 68, and 67 publications, respectively. By cross-referencing information from ADS and WoS, we found that the areas with the greatest impact in publications are threefold: high-energy and fundamental physics, stars and stellar physics, and galaxies and cosmology. Globally, according to WoS, Colombia ranks 52nd in the number of peer-reviewed publications between 2019 and 2023, and fifth in Latin America. Additionally, we identified three highly cited publications (top 1% worldwide) belonging to the field of observational cosmology. When analyzing countries with equal or greater bibliographic production, we estimate that Colombian production is approximately four times lower than expected considering its population and GDP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02255v1</guid>
      <category>cs.DL</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sof\'ia Guevara-Montoya, Felipe Ortiz-Ferreira, Mar\'ia Paula Silva-Ar\'evalo, Paola A. Ni\~no-Mu\~noz, Jaime E. Forero-Romero</dc:creator>
    </item>
    <item>
      <title>Enhancing Cloud-Based Large Language Model Processing with Elasticsearch and Transformer Models</title>
      <link>https://arxiv.org/abs/2403.00807</link>
      <description>arXiv:2403.00807v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are a class of generative AI models built using the Transformer network, capable of leveraging vast datasets to identify, summarize, translate, predict, and generate language. LLMs promise to revolutionize society, yet training these foundational models poses immense challenges. Semantic vector search within large language models is a potent technique that can significantly enhance search result accuracy and relevance. Unlike traditional keyword-based search methods, semantic search utilizes the meaning and context of words to grasp the intent behind queries and deliver more precise outcomes. Elasticsearch emerges as one of the most popular tools for implementing semantic search an exceptionally scalable and robust search engine designed for indexing and searching extensive datasets. In this article, we delve into the fundamentals of semantic search and explore how to harness Elasticsearch and Transformer models to bolster large language model processing paradigms. We gain a comprehensive understanding of semantic search principles and acquire practical skills for implementing semantic search in real-world model application scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00807v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <category>cs.DL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunhe Ni, Jiang Wu, Hongbo Wang, Wenran Lu, Chenwei Zhang</dc:creator>
    </item>
    <item>
      <title>A Randomized Controlled Trial on Anonymizing Reviewers to Each Other in Peer Review Discussions</title>
      <link>https://arxiv.org/abs/2403.01015</link>
      <description>arXiv:2403.01015v1 Announce Type: cross 
Abstract: Peer review often involves reviewers submitting their independent reviews, followed by a discussion among reviewers of each paper. A question among policymakers is whether the reviewers of a paper should be anonymous to each other during the discussion. We shed light on this by conducting a randomized controlled trial at the UAI 2022 conference. We randomly split the reviewers and papers into two conditions--one with anonymous discussions and the other with non-anonymous discussions, and conduct an anonymous survey of all reviewers, to address the following questions: 1. Do reviewers discuss more in one of the conditions? Marginally more in anonymous (n = 2281, p = 0.051). 2. Does seniority have more influence on final decisions when non-anonymous? Yes, the decisions are closer to senior reviewers' scores in the non-anonymous condition than in anonymous (n = 484, p = 0.04). 3. Are reviewers more polite in one of the conditions? No significant difference in politeness of reviewers' text-based responses (n = 1125, p = 0.72). 4. Do reviewers' self-reported experiences differ across the two conditions? No significant difference for each of the five questions asked (n = 132 and p &gt; 0.3). 5. Do reviewers prefer one condition over the other? Yes, there is a weak preference for anonymous discussions (n = 159 and Cohen's d= 0.25). 6. What do reviewers consider important to make policy on anonymity among reviewers? Reviewers' feeling of safety in expressing their opinions was rated most important, while polite communication among reviewers was rated least important (n = 159). 7. Have reviewers experienced dishonest behavior due to non-anonymity in discussions? Yes, roughly 7% of respondents answered affirmatively (n = 167). Overall, this experiment reveals evidence supporting an anonymous discussion setup in the peer-review process, in terms of the evaluation criteria considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01015v1</guid>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charvi Rastogi, Xiangchen Song, Zhijing Jin, Ivan Stelmakh, Hal Daum\'e III, Kun Zhang, Nihar B. Shah</dc:creator>
    </item>
    <item>
      <title>Characterizing Semantic Ambiguity of the Materials Science Ontologies</title>
      <link>https://arxiv.org/abs/2310.00078</link>
      <description>arXiv:2310.00078v2 Announce Type: replace 
Abstract: Growth in computational materials science and initiatives such as the Materials Genome Initiative (MGI) and the European Materials Modelling Council (EMMC) has motivated the development and application of ontologies. A key factor has been increased adoption of the FAIR principles, making research data findable, accessible, interoperable, and reusable (Wilkinson et al. 2016). This paper characterizes semantic interoperability among a subset of materials science ontologies in the MatPortal repository. Background context covers semantic interoperability, ontological commitment, and the materials science ontology landscape. The research focused on MatPortal's two interoperability protocols: LOOM term matching and URI matching. Results report the degree of overlap and demonstrate the different types of ambiguity among ontologies. The discussion considers implications for FAIR and AI, and the conclusion highlight key findings and next steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00078v2</guid>
      <category>cs.DL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Scott McClellan, Yuan An, Xintong Zhao, Xia Lin, Jane Greenberg</dc:creator>
    </item>
    <item>
      <title>Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility</title>
      <link>https://arxiv.org/abs/2401.13782</link>
      <description>arXiv:2401.13782v2 Announce Type: replace 
Abstract: As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside controls precisely matched by 9 key covariates. Our statistical and causal inference analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. Given these findings, we advocate for a responsible approach to curation, encouraging influencers to uphold the journalistic standard that includes showcasing diverse research topics, authors, and institutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13782v2</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iain Xie Weissburg, Mehir Arora, Xinyi Wang, Liangming Pan, William Yang Wang</dc:creator>
    </item>
    <item>
      <title>Forecasting high-impact research topics via machine learning on evolving knowledge graphs</title>
      <link>https://arxiv.org/abs/2402.08640</link>
      <description>arXiv:2402.08640v2 Announce Type: replace 
Abstract: The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08640v2</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuemei Gu, Mario Krenn</dc:creator>
    </item>
  </channel>
</rss>
