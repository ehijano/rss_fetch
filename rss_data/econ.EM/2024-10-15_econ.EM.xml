<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 04:02:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Nickell Meets Stambaugh: A Tale of Two Biases in Panel Predictive Regressions</title>
      <link>https://arxiv.org/abs/2410.09825</link>
      <description>arXiv:2410.09825v1 Announce Type: new 
Abstract: In panel predictive regressions with persistent covariates, coexistence of the Nickell bias and the Stambaugh bias imposes challenges for hypothesis testing. This paper introduces a new estimator, the IVX-X-Jackknife (IVXJ), which effectively removes this composite bias and reinstates standard inferential procedures. The IVXJ estimator is inspired by the IVX technique in time series. In panel data where the cross section is of the same order as the time dimension, the bias of the baseline panel IVX estimator can be corrected via an analytical formula by leveraging an innovative X-Jackknife scheme that divides the time dimension into the odd and even indices. IVXJ is the first procedure that achieves unified inference across a wide range of modes of persistence in panel predictive regressions, whereas such unified inference is unattainable for the popular within-group estimator. Extended to accommodate long-horizon predictions with multiple regressions, IVXJ is used to examine the impact of debt levels on financial crises by panel local projection. Our empirics provide comparable results across different categories of debt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09825v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengwang Liao, Ziwei Mei, Zhentao Shi</dc:creator>
    </item>
    <item>
      <title>Large Scale Longitudinal Experiments: Estimation and Inference</title>
      <link>https://arxiv.org/abs/2410.09952</link>
      <description>arXiv:2410.09952v1 Announce Type: new 
Abstract: Large-scale randomized experiments are seldom analyzed using panel regression methods because of computational challenges arising from the presence of millions of nuisance parameters. We leverage Mundlak's insight that unit intercepts can be eliminated by using carefully chosen averages of the regressors to rewrite several common estimators in a form that is amenable to weighted-least squares estimation with frequency weights. This renders regressions involving arbitrary strata intercepts tractable with very large datasets, optionally with the key compression step computed out-of-memory in SQL. We demonstrate that these methods yield more precise estimates than other commonly used estimators, and also find that the compression strategy greatly increases computational efficiency. We provide in-memory (pyfixest) and out-of-memory (duckreg) python libraries to implement these estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09952v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Apoorva Lal, Alexander Fischer, Matthew Wardrop</dc:creator>
    </item>
    <item>
      <title>Testing the order of fractional integration in the presence of smooth trends, with an application to UK Great Ratios</title>
      <link>https://arxiv.org/abs/2410.10749</link>
      <description>arXiv:2410.10749v1 Announce Type: new 
Abstract: This note proposes semi-parametric tests for investigating whether a stochastic process is fractionally integrated of order $\delta$, where $|\delta| &lt; 1/2$, when smooth trends are present in the model. We combine the semi-parametric approach by Iacone, Nielsen &amp; Taylor (2022) to model the short range dependence with the use of Chebyshev polynomials by Cuestas &amp; Gil-Alana to describe smooth trends. Our proposed statistics have standard limiting null distributions and match the asymptotic local power of infeasible tests based on unobserved errors. We also establish the conditions under which an information criterion can consistently estimate the order of the Chebyshev polynomial. The finite sample performance is evaluated using simulations, and an empirical application is given for the UK Great Ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10749v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mustafa R. K{\i}l{\i}n\c{c}, Michael Massmann, Maximilian Ambros</dc:creator>
    </item>
    <item>
      <title>Identification and Estimation of Dynamic Games with Unknown Information Structure</title>
      <link>https://arxiv.org/abs/2205.03706</link>
      <description>arXiv:2205.03706v4 Announce Type: replace 
Abstract: This paper studies the identification and estimation of dynamic games when the underlying information structure is unknown to the researcher. To tractably characterize the set of Markov perfect equilibrium predictions while maintaining weak assumptions on players' information, we introduce \textit{Markov correlated equilibrium}, a dynamic analog of Bayes correlated equilibrium. The set of Markov correlated equilibrium predictions coincides with the set of Markov perfect equilibrium predictions that can arise when the players can observe more signals than assumed by the analyst. Using Markov correlated equilibrium as the solution concept, we propose tractable computational strategies for informationally robust estimation, inference, and counterfactual analysis that deal with the non-convexities arising in dynamic environments. We use our method to analyze the dynamic competition between Starbucks and Dunkin' in the US and the role of informational assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03706v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konan Hara, Yuki Ito, Paul Koh</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification in Synthetic Controls with Staggered Treatment Adoption</title>
      <link>https://arxiv.org/abs/2210.05026</link>
      <description>arXiv:2210.05026v4 Announce Type: replace 
Abstract: We propose principled prediction intervals to quantify the uncertainty of a large class of synthetic control predictions (or estimators) in settings with staggered treatment adoption, offering precise non-asymptotic coverage probability guarantees. From a methodological perspective, we provide a detailed discussion of different causal quantities to be predicted, which we call causal predictands, allowing for multiple treated units with treatment adoption at possibly different points in time. From a theoretical perspective, our uncertainty quantification methods improve on prior literature by (i) covering a large class of causal predictands in staggered adoption settings, (ii) allowing for synthetic control methods with possibly nonlinear constraints, (iii) proposing scalable robust conic optimization methods and principled data-driven tuning parameter selection, and (iv) offering valid uniform inference across post-treatment periods. We illustrate our methodology with an empirical application studying the effects of economic liberalization on real GDP per capita for Sub-Saharan African countries. Companion general-purpose software packages are provided in Python, R, and Stata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05026v4</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Yingjie Feng, Filippo Palomba, Rocio Titiunik</dc:creator>
    </item>
    <item>
      <title>Estimating Time-Varying Parameters of Various Smoothness in Linear Models via Kernel Regression</title>
      <link>https://arxiv.org/abs/2406.14046</link>
      <description>arXiv:2406.14046v2 Announce Type: replace 
Abstract: We consider estimating nonparametric time-varying parameters in linear models using kernel regression. Our contributions are twofold. First, We consider a broad class of time-varying parameters including deterministic smooth functions, the rescaled random walk, structural breaks, the threshold model and their mixtures. We show that those time-varying parameters can be consistently estimated by kernel regression. Our analysis exploits the smoothness of the time-varying parameter, which is quantified by a single parameter. The second contribution is to reveal that the bandwidth used in kernel regression determines the trade-off between the rate of convergence and the size of the class of time-varying parameters that can be estimated. We demonstrate that an improper choice of the bandwidth yields biased estimation and provide a guide on the bandwidth selection. An empirical application shows that the kernel-based estimator with a particular bandwidth choice can capture the random-walk dynamics in time-varying parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14046v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikihito Nishi</dc:creator>
    </item>
    <item>
      <title>A new GARCH model with a deterministic time-varying intercept</title>
      <link>https://arxiv.org/abs/2410.03239</link>
      <description>arXiv:2410.03239v2 Announce Type: replace 
Abstract: It is common for long financial time series to exhibit gradual change in the unconditional volatility. We propose a new model that captures this type of nonstationarity in a parsimonious way. The model augments the volatility equation of a standard GARCH model by a deterministic time-varying intercept. It captures structural change that slowly affects the amplitude of a time series while keeping the short-run dynamics constant. We parameterize the intercept as a linear combination of logistic transition functions. We show that the model can be derived from a multiplicative decomposition of volatility and preserves the financial motivation of variance decomposition. We use the theory of locally stationary processes to show that the quasi maximum likelihood estimator (QMLE) of the parameters of the model is consistent and asymptotically normally distributed. We examine the quality of the asymptotic approximation in a small simulation study. An empirical application to Oracle Corporation stock returns demonstrates the usefulness of the model. We find that the persistence implied by the GARCH parameter estimates is reduced by including a time-varying intercept in the volatility equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03239v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas Ahlgren, Alexander Back, Timo Ter\"asvirta</dc:creator>
    </item>
    <item>
      <title>Welfare Analysis in Dynamic Models</title>
      <link>https://arxiv.org/abs/1908.09173</link>
      <description>arXiv:1908.09173v2 Announce Type: replace-cross 
Abstract: This paper provides welfare metrics for dynamic choice. We give estimation and inference methods for functions of the expected value of dynamic choice. These parameters include average value by group, average derivatives with respect to endowments, and structural decompositions. The example of dynamic discrete choice is considered. We give dual and doubly robust representations of these parameters. A least squares estimator of the dynamic Riesz representer for the parameter of interest is given. Debiased machine learners are provided and asymptotic theory given.</description>
      <guid isPermaLink="false">oai:arXiv.org:1908.09173v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Chernozhukov, Whitney Newey, Vira Semenova</dc:creator>
    </item>
    <item>
      <title>Multivariate Tie-breaker Designs</title>
      <link>https://arxiv.org/abs/2202.10030</link>
      <description>arXiv:2202.10030v5 Announce Type: replace-cross 
Abstract: In a tie-breaker design (TBD), subjects with high values of a running variable are given some (usually desirable) treatment, subjects with low values are not, and subjects in the middle are randomized. TBDs are intermediate between regression discontinuity designs (RDDs) and randomized controlled trials (RCTs). TBDs allow a tradeoff between the resource allocation efficiency of an RDD and the statistical efficiency of an RCT. We study a model where the expected response is one multivariate regression for treated subjects and another for control subjects. We propose a prospective D-optimality, analogous to Bayesian optimal design, to understand design tradeoffs without reference to a specific data set. For given covariates, we show how to use convex optimization to choose treatment probabilities that optimize this criterion. We can incorporate a variety of constraints motivated by economic and ethical considerations. In our model, D-optimality for the treatment effect coincides with D-optimality for the whole regression, and, without constraints, an RCT is globally optimal. We show that a monotonicity constraint favoring more deserving subjects induces sparsity in the number of distinct treatment probabilities. We apply the convex optimization solution to a semi-synthetic example involving triage data from the MIMIC-IV-ED database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.10030v5</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim P. Morrison, Art B. Owen</dc:creator>
    </item>
    <item>
      <title>Synthetic Potential Outcomes and Causal Mixture Identifiability</title>
      <link>https://arxiv.org/abs/2405.19225</link>
      <description>arXiv:2405.19225v2 Announce Type: replace-cross 
Abstract: A mixture model consists of a latent class that exerts a discrete signal on the observed data. Uncovering these latent classes is fundamental to unsupervised learning. In this paper, we consider the problem of recovering latent classes defined with respect to causal responses. We allow overlapping support in the distributions of these classes, meaning individuals cannot be clustered into groups with a similar response. Instead, we build on a setting from proximal causal inference to develop a method of moments approach to synthetically sample potential outcome distributions. This approach is the first known identifiability result for what we call Mixtures of Treatment Effects (MTEs). More broadly, we show how MTEs fit into a hierarchy of causal identifiability that unifies a number of perspectives on latent class confounding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19225v2</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bijan Mazaheri, Chandler Squires, Caroline Uhler</dc:creator>
    </item>
  </channel>
</rss>
