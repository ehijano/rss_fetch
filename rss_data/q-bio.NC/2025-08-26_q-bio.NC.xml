<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bridging Foundation Models and Efficient Architectures: A Modular Brain Imaging Framework with Local Masking and Pretrained Representation Learning</title>
      <link>https://arxiv.org/abs/2508.16597</link>
      <description>arXiv:2508.16597v1 Announce Type: new 
Abstract: Functional connectivity (FC) derived from resting-state fMRI plays a critical role in personalized predictions such as age and cognitive performance. However, applying foundation models(FM) to fMRI data remains challenging due to its high dimensionality, computational complexity, and the difficulty in capturing complex spatiotemporal dynamics and indirect region-of-interest (ROI) interactions. To address these limitations, we propose a modular neuroimaging framework that integrates principles from FM with efficient, domain-specific architectures. Our approach begins with a Local Masked Autoencoder (LMAE) for pretraining, which reduces the influence of hemodynamic response function (HRF) dynamics and suppresses noise. This is followed by a Random Walk Mixture of Experts (RWMOE) module that clusters features across spatial and temporal dimensions, effectively capturing intricate brain interactions. Finally, a state-space model (SSM)-based predictor performs downstream task inference. Evaluated on the Cambridge Centre for Ageing and Neuroscience (Cam-CAN) dataset, our framework achieved mean absolute errors (MAEs) of 5.343 for age prediction and 2.940 for fluid intelligence, with Pearson correlation coefficients (PCCs) of 0.928 and 0.887, respectively-outperforming existing state-of-the-art methods. Visualization of expert distribution weights further enhances interpretability by identifying key brain regions. This work provides a robust, interpretable alternative to LLM-based approaches for fMRI analysis, offering novel insights into brain aging and cognitive function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16597v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanwen Wang, Xinglin Zhao, Yijin Song, Xiaobo Liu, Yanrong Hao, Rui Cao, Xin Wen</dc:creator>
    </item>
    <item>
      <title>BrainPath: Generating Subject-Specific Brain Aging Trajectories</title>
      <link>https://arxiv.org/abs/2508.16667</link>
      <description>arXiv:2508.16667v1 Announce Type: new 
Abstract: Quantifying and forecasting individual brain aging trajectories is critical for understanding neurodegenerative disease and the heterogeneity of aging, yet current approaches remain limited. Most models predict chronological age, an imperfect surrogate for biological aging, or generate synthetic MRIs that enhance data diversity but fail to capture subject-specific trajectories. Here, we present BrainPath, a 3D generative framework that learns longitudinal brain aging dynamics during training and, at inference, predicts anatomically faithful MRIs at arbitrary timepoints from a single baseline scan. BrainPath integrates an age calibration loss, a swap learning strategy, and an age perceptual loss to preserve subtle, biologically meaningful variations. Across held-out ADNI and an independent NACC dataset, BrainPath outperforms state-of-the-art reference models in structural similarity (SSIM), mean squared error (MSE), peak signal-to-noise ratio (PSNR), and MRI age-difference accuracy, while capturing realistic and temporally consistent aging patterns. Beyond methodological innovation, BrainPath enables personalized mapping of brain aging, synthetic follow-up scan prediction, and trajectory-based analyses, providing a foundation for precision modeling of brain aging and supporting research into neurodegeneration and aging interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16667v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Li, Javad Sohankar, Ji Luo, Jing Li, Yi Su</dc:creator>
    </item>
    <item>
      <title>Rethinking scale in network neuroscience: Contributions and opportunities at the nanoscale</title>
      <link>https://arxiv.org/abs/2508.16760</link>
      <description>arXiv:2508.16760v1 Announce Type: new 
Abstract: Network science has been applied widely to study brain network organization, especially at the meso-scale, where nodes represent brain areas and edges reflect interareal connectivity inferred from imaging or tract-tracing data. While this approach has yielded important insights into large-scale brain network architecture, its foundational assumptions often misalign with the biological realities of neural systems. In this review, we argue that network science finds its most direct and mechanistically grounded application in nanoscale connectomics-wiring diagrams reconstructed at the level of individual neurons and synapses, often from high-resolution electron microscopy volumes. At this finer scale, core network concepts such as paths, motifs, communities, and centrality acquire concrete biological interpretations. Unlike meso-scale models, nanoscale connectomes are typically derived from individual animals, preserve synaptic resolution, and are richly annotated with cell types, neurotransmitter identities, and morphological detail. These properties enable biologically grounded, mechanistically interpretable analyses of circuit structure and function. We review how nanoscale data support new forms of network modeling, from realistic dynamical simulations to topology-informed circuit inference, and outline emerging directions in multimodal integration, cross-species comparisons, and generative modeling. We also emphasize the continued importance of meso- and macro-scale connectomics, especially in human neuroscience, and discuss how nanoscale insights can inform interpretation at coarser scales. Together, these efforts point toward a multi-scale future for network neuroscience, grounded in the strengths of each resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16760v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Betzel, Caio Seguin, Maria Grazia Puxeddu</dc:creator>
    </item>
    <item>
      <title>A coalgebraic perspective on predictive processing</title>
      <link>https://arxiv.org/abs/2508.16877</link>
      <description>arXiv:2508.16877v1 Announce Type: new 
Abstract: Predictive processing and active inference posit that the brain is a system performing Bayesian inference on the environment. By virtue of this, a prominent interpretation of predictive processing states that the generative model (a POMDP) encoded by the brain synchronises with the generative process (another POMDP) representing the environment while trying to explain what hidden properties of the world generated its sensory input. In this view, the brain is thought to become a copy of the environment. This claim has however been disputed, stressing the fact that a structural copy, or isomorphism as it is at times invoked to be, is not an accurate description of this process since the environment is necessarily more complex than the brain, and what matters is not the capacity to exactly recapitulate the veridical causal structure of the world. In this work, we make parts of this counterargument formal by using ideas from the theory of coalgebras, an abstract mathematical framework for dynamical systems that brings together work from automata theory, concurrency theory, probabilistic processes and other fields. To do so, we cast generative model and process, in the form of POMDPs, as coalgebras, and use maps between them to describe a form of consistency that goes beyond mere structural similarity, giving the necessary mathematical background to describe how different processes can be seen as behaviourally, rather than structurally, equivalent, i.e. how they can be seen as emitting the same observations, and thus minimise prediction error, over time without strict assumptions about structural similarity. In particular, we will introduce three standard notions of equivalence from the literature on coalgebras, evaluating them in the context of predictive processing and identifying the one closest to claims made by proponents of this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16877v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Baltieri, Filippo Torresan, Tomoya Nakai</dc:creator>
    </item>
    <item>
      <title>Quantum State Fidelity for Functional Neural Network Construction</title>
      <link>https://arxiv.org/abs/2508.16895</link>
      <description>arXiv:2508.16895v1 Announce Type: cross 
Abstract: Neuroscientists face challenges in analyzing high-dimensional neural recording data of dense functional networks. Without ground-truth reference data, finding the best algorithm for recovering neurologically relevant networks remains an open question. We implemented hybrid quantum algorithms to construct functional networks and compared them with the results of documented classical techniques. We demonstrated that our quantum state fidelity can provide a competitive alternative to classical metrics by revealing distinct functional networks. Our results suggest that quantum computing offers a viable and potentially advantageous alternative for data-driven modeling in neuroscience, underscoring its broader applicability in high-dimensional graph inference and complex system analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16895v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>math.MG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Skylar Chan, Wilson Smith, Kyla Gabriel</dc:creator>
    </item>
    <item>
      <title>Disentangling the Factors of Convergence between Brains and Computer Vision Models</title>
      <link>https://arxiv.org/abs/2508.18226</link>
      <description>arXiv:2508.18226v1 Announce Type: cross 
Abstract: Many AI models trained on natural images develop representations that resemble those of the human brain. However, the factors that drive this brain-model similarity remain poorly understood. To disentangle how the model, training and data independently lead a neural network to develop brain-like representations, we trained a family of self-supervised vision transformers (DINOv3) that systematically varied these different factors. We compare their representations of images to those of the human brain recorded with both fMRI and MEG, providing high resolution in spatial and temporal analyses. We assess the brain-model similarity with three complementary metrics focusing on overall representational similarity, topographical organization, and temporal dynamics. We show that all three factors - model size, training amount, and image type - independently and interactively impact each of these brain similarity metrics. In particular, the largest DINOv3 models trained with the most human-centric images reach the highest brain-similarity. This emergence of brain-like representations in AI models follows a specific chronology during training: models first align with the early representations of the sensory cortices, and only align with the late and prefrontal representations of the brain with considerably more training. Finally, this developmental trajectory is indexed by both structural and functional properties of the human cortex: the representations that are acquired last by the models specifically align with the cortical areas with the largest developmental expansion, thickness, least myelination, and slowest timescales. Overall, these findings disentangle the interplay between architecture and experience in shaping how artificial neural networks come to see the world as humans do, thus offering a promising framework to understand how the human brain comes to represent its visual world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18226v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'ephine Raugel, Marc Szafraniec, Huy V. Vo, Camille Couprie, Patrick Labatut, Piotr Bojanowski, Valentin Wyart, Jean-R\'emi King</dc:creator>
    </item>
    <item>
      <title>CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience</title>
      <link>https://arxiv.org/abs/2507.09024</link>
      <description>arXiv:2507.09024v3 Announce Type: replace 
Abstract: Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets. CNeuroMod-THINGS meets this need by capturing neural representations for a wide set of semantic concepts using well-characterized images in a new densely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS exploits synergies between two existing projects: the THINGS initiative (THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has developed a common set of thoroughly annotated images broadly sampling natural and man-made objects which is used to acquire a growing collection of large-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring hundreds of hours of fMRI data from a core set of participants during controlled and naturalistic tasks, including visual tasks like movie watching and videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each completed 33-36 sessions of a continuous recognition paradigm using approximately 4000 images from the THINGS stimulus set spanning 720 categories. We report behavioural and neuroimaging metrics that showcase the quality of the data. By bridging together large existing resources, CNeuroMod-THINGS expands our capacity to model broad slices of the human visual experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09024v3</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Marie St-Laurent, Basile Pinsard, Oliver Contier, Elizabeth DuPre, Katja Seeliger, Valentina Borghesani, Julie A. Boyle, Lune Bellec, Martin N. Hebart</dc:creator>
    </item>
    <item>
      <title>Neural Fields and Noise-Induced Patterns in Neurons on Large Disordered Networks</title>
      <link>https://arxiv.org/abs/2408.12540</link>
      <description>arXiv:2408.12540v2 Announce Type: replace-cross 
Abstract: We study pattern formation in class of a large-dimensional neural networks posed on random graphs and subject to spatio-temporal stochastic forcing. Under generic conditions on coupling and nodal dynamics, we prove that the network admits a rigorous mean-field limit, resembling a Wilson-Cowan neural field equation. The state variables of the limiting systems are the mean and variance of neuronal activity. We select networks whose mean-field equations are tractable and we perform a bifurcation analysis using as control parameter the diffusivity strength of the afferent white noise on each neuron. We find conditions for Turing-like bifurcations in a system where the cortex is modelled as a ring, and we produce numerical evidence of noise-induced spiral waves in models with a two-dimensional cortex. We provide numerical evidence that solutions of the finite-size network converge weakly to solutions of the mean-field model. Finally, we prove a Large Deviation Principle, which provides a means of assessing the likelihood of deviations from the mean-field equations induced by finite-size effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12540v2</guid>
      <category>math.PR</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Avitabile, James MacLaurin</dc:creator>
    </item>
  </channel>
</rss>
