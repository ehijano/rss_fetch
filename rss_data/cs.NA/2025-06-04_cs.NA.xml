<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 01:42:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Introduction to the theory of generalized locally Toeplitz sequences and its applications</title>
      <link>https://arxiv.org/abs/2506.02151</link>
      <description>arXiv:2506.02151v1 Announce Type: new 
Abstract: The theory of generalized locally Toeplitz (GLT) sequences was conceived as an apparatus for computing the spectral distribution of matrices arising from the numerical discretization of differential equations (DEs). The purpose of this review is to introduce the reader to the theory of GLT sequences and to present some of its applications to the computation of the spectral distribution of DE discretization matrices. We mainly focus on the applications, whereas the theory is presented in a self-contained tool-kit fashion, without entering into technical details. The exposition is supposed to be understandable to master's degree students in mathematics. It also discloses new more efficient approaches to the spectral analysis of DE discretization matrices as well as a novel spectral analysis tool that has not been considered in the GLT literature heretofore, i.e., the modulus of integral continuity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02151v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Garoni</dc:creator>
    </item>
    <item>
      <title>Second-order AAA algorithms for structured data-driven modeling</title>
      <link>https://arxiv.org/abs/2506.02241</link>
      <description>arXiv:2506.02241v1 Announce Type: new 
Abstract: The data-driven modeling of dynamical systems has become an essential tool for the construction of accurate computational models from real-world data. In this process, the inherent differential structures underlying the considered physical phenomena are often neglected making the reinterpretation of the learned models in a physically meaningful sense very challenging. In this work, we present three data-driven modeling approaches for the construction of dynamical systems with second-order differential structure directly from frequency domain data. Based on the second-order structured barycentric form, we extend the well-known Adaptive Antoulas-Anderson algorithm to the case of second-order systems. Depending on the available computational resources, we propose variations of the proposed method that prioritize either higher computation speed or greater modeling accuracy, and we present a theoretical analysis for the expected accuracy and performance of the proposed methods. Three numerical examples demonstrate the effectiveness of our new structured approaches in comparison to classical unstructured data-driven modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02241v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael S. Ackermann, Ion Victor Gosea, Serkan Gugercin, Steffen W. R. Werner</dc:creator>
    </item>
    <item>
      <title>Greedy recursion parameter selection for the One-Way Navier-Stokes (OWNS) equations</title>
      <link>https://arxiv.org/abs/2506.02320</link>
      <description>arXiv:2506.02320v1 Announce Type: new 
Abstract: The One-Way Navier-Stokes (OWNS) equations use recursive filtering to construct efficient, well-posed one-way approximations to linear hyperbolic systems. The recursion parameters are critical to the accuracy and stability of the method, and have previously been chosen based on heuristic estimates of key eigenvalues (or their branches), which converges slowly and requires trial-and-error tuning for new systems. We review the projection and recursive OWNS formulations (OWNS-P and OWNS-R) for inhomogeneous equations and propose a greedy algorithm for parameter selection. We show that it converges faster and leads to a net decrease in computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02320v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael K. Sleeman, Tim Colonius</dc:creator>
    </item>
    <item>
      <title>An adaptive delaminating Levin method in two dimensions</title>
      <link>https://arxiv.org/abs/2506.02424</link>
      <description>arXiv:2506.02424v1 Announce Type: new 
Abstract: We present an adaptive delaminating Levin method for evaluating bivariate oscillatory integrals over rectangular domains. Whereas previous analyses of Levin methods impose non-resonance conditions that exclude stationary and resonance points, we rigorously establish the existence of a slowly-varying, approximate solution to the Levin PDE across all frequency regimes, even when the non-resonance condition is violated. This allows us to derive error estimates for the numerical solution of the Levin PDE via the Chebyshev spectral collocation method, and for the evaluation of the corresponding oscillatory integrals, showing that high accuracy can be achieved regardless of whether or not stationary and resonance points are present. We then present a Levin method incorporating adaptive subdivision in both two and one dimensions, as well as delaminating Chebyshev spectral collocation, which is effective in both the presence and absence of stationary and resonance points. We demonstrate the effectiveness of our algorithm with a number of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02424v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shukui Chen, Kirill Serkh, James Bremer, Murdock Aubry</dc:creator>
    </item>
    <item>
      <title>Rust Implementation of Finite Element Exterior Calculus on Coordinate-Free Simplicial Complexes</title>
      <link>https://arxiv.org/abs/2506.02429</link>
      <description>arXiv:2506.02429v1 Announce Type: new 
Abstract: This thesis presents the development of a novel finite element library in Rust based on the principles of Finite Element Exterior Calculus (FEEC). The library solves partial differential equations formulated using differential forms on abstract, coordinate-free simplicial complexes in arbitrary dimensions, employing an intrinsic Riemannian metric derived from edge lengths via Regge Calculus. We focus on solving elliptic Hodge-Laplace eigenvalue and source problems on the nD de Rham complex. We restrict ourselves to first-order Whitney basis functions. The implementation is partially verified through convergence studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02429v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.AT</category>
      <category>math.DG</category>
      <category>math.FA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Wirth</dc:creator>
    </item>
    <item>
      <title>Numerical methods for fully nonlinear degenerate diffusions</title>
      <link>https://arxiv.org/abs/2506.02595</link>
      <description>arXiv:2506.02595v1 Announce Type: new 
Abstract: We propose finite difference methods for degenerate fully nonlinear elliptic equations and prove the convergence of the schemes. Our focus is on the pure equation and a related free boundary problem of transmission type. The cornerstone of our argument is a regularisation procedure. It decouples the degeneracy term from the elliptic operator driving the diffusion process. In the free boundary setting, the absence of degenerate ellipticity entails new, genuine difficulties. To bypass them, we resort to the intrinsic properties of the regularised problem. We present numerical experiments supporting our theoretical results. Our methods are flexible, and our approach can be extended to a broader class of non-variational problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02595v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edgard A. Pimentel, Erc\'ilia Sousa</dc:creator>
    </item>
    <item>
      <title>Fourth-order Adaptive Mesh Refinement both in space and in time for incompressible Navier-Stokes equations with Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2506.02663</link>
      <description>arXiv:2506.02663v1 Announce Type: new 
Abstract: We present a fourth-order projection method with adaptive mesh refinement (AMR) for numerically solving the incompressible Navier-Stokes equations (INSE) with subcycling in time. Our method features (i) a reformulation of INSE so that the velocity divergence decays exponentially on the coarsest level, (ii) a derivation of coarse-fine interface conditions that preserves the decay of velocity divergence on any refinement level of the AMR hierarchy, (iii) an approximation of the coarse-fine interface conditions via spatiotemporal interpolations to facilitate subcycling in time, (iv) enforcing to machine precision solvability conditions of elliptic equations over each connected component of the subdomain covered by any refinement level, (v) a composite projection for synchronizing multiple levels, and (vi) geometric multigrid for solving linear systems with optimal complexity. Different from current block-structured AMR algorithms, our method never adopts refluxing at the coarse-fine interface, nor is fine-to-coarse averaging applied to projected velocities. Results of numerical tests demonstrate the high accuracy and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02663v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubo Zhao, Qinghai Zhang</dc:creator>
    </item>
    <item>
      <title>Nonsmooth data error estimates for exponential Runge--Kutta methods and applications to split exponential integrators</title>
      <link>https://arxiv.org/abs/2506.02778</link>
      <description>arXiv:2506.02778v1 Announce Type: new 
Abstract: We derive error bounds for exponential Runge-Kutta discretizations of parabolic equations with nonsmooth initial data. Our analysis is carried out in a framework of abstract semilinear evolution equations with operators having non-dense domain. In particular, we investigate nonsmooth data error estimates for the Allen-Cahn and the Burgers' equation. As an application, we apply these nonsmooth data error estimates to split exponential integrators and derive a convergence result in terms of the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02778v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiumei Huang, Alexander Ostermann, Gangfan Zhong</dc:creator>
    </item>
    <item>
      <title>The Bayesian Finite Element Method in Inverse Problems: a Critical Comparison between Probabilistic Models for Discretization Error</title>
      <link>https://arxiv.org/abs/2506.02815</link>
      <description>arXiv:2506.02815v1 Announce Type: new 
Abstract: When using the finite element method (FEM) in inverse problems, its discretization error can produce parameter estimates that are inaccurate and overconfident. The Bayesian finite element method (BFEM) provides a probabilistic model for the epistemic uncertainty due to discretization error. In this work, we apply BFEM to various inverse problems, and compare its performance to the random mesh finite element method (RM-FEM) and the statistical finite element method (statFEM), which serve as a frequentist and inference-based counterpart to BFEM. We find that by propagating this uncertainty to the posterior, BFEM can produce more accurate parameter estimates and prevent overconfidence, compared to FEM. Because the BFEM covariance operator is designed to leave uncertainty only in the appropriate space, orthogonal to the FEM basis, BFEM is able to outperform RM-FEM, which does not have such a structure to its covariance. Although inferring the discretization error via a model misspecification component is possible as well, as is done in statFEM, the feasibility of such an approach is contingent on the availability of sufficient data. We find that the BFEM is the most robust way to consistently propagate uncertainty due to discretization error to the posterior of a Bayesian inverse problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02815v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Poot, Iuri Rocha, Pierre Kerfriden, Frans van der Meeer</dc:creator>
    </item>
    <item>
      <title>Eigenvalue bounds for preconditioned symmetric multiple saddle-point matrices</title>
      <link>https://arxiv.org/abs/2506.02816</link>
      <description>arXiv:2506.02816v1 Announce Type: new 
Abstract: We develop eigenvalue bounds for symmetric, block tridiagonal multiple saddle-point linear systems, preconditioned with block diagonal matrices. We extend known results for $3 \times 3$ block systems [Bradley and Greif, IMA J.\ Numer. Anal. 43 (2023)] and for $4 \times 4$ systems [Pearson and Potschka, IMA J. Numer. Anal. 44 (2024)] to an arbitrary number of blocks. Moreover, our results generalize the bounds in [Sogn and Zulehner, IMA J. Numer. Anal. 39 (2018)], developed for an arbitrary number of blocks with null diagonal blocks. Extension to the bounds when the Schur complements are approximated is also provided, using perturbation arguments. Practical bounds are also obtained for the double saddle-point linear system. Numerical experiments validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02816v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L. Bergamaschi, A. Martinez, J. W. Pearson, A. Potschka</dc:creator>
    </item>
    <item>
      <title>Real and finite field versions of Chebotarev's theorem</title>
      <link>https://arxiv.org/abs/2506.02947</link>
      <description>arXiv:2506.02947v1 Announce Type: new 
Abstract: Chebotarev's theorem on roots of unity states that all minors of the Fourier matrix of prime size are non-vanishing. This result has been rediscovered several times and proved via different techniques. We follow the proof of Evans and Isaacs and generalize the original result to a real version and a version over finite fields. For the latter, we are able to remove an order condition between the characteristic of the field and the size of the matrix as well as decrease a sufficient lower bound on the characteristic by Zhang considerably. Direct applications include a specific real phase retrieval problem as well as a recent result for Riesz bases of exponentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02947v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarek Emmrich, Stefan Kunis</dc:creator>
    </item>
    <item>
      <title>Newtonian potentials of Legendre polynomials on rectangles have displacement structure</title>
      <link>https://arxiv.org/abs/2506.03003</link>
      <description>arXiv:2506.03003v1 Announce Type: new 
Abstract: Particular solutions of the Poisson equation can be constructed via Newtonian potentials, integrals involving the corresponding Green's function which in two-dimensions has a logarithmic singularity. The singularity represents a significant challenge for computing the integrals, which is typically overcome via specially designed quadrature methods involving a large number of evaluations of the function and kernel. We present an attractive alternative: we show that Newtonian potentials (and their gradient) applied to (tensor products of) Legendre polynomials can be expressed in terms of complex integrals which satisfy simple and explicit recurrences that can be utilised to exactly compute singular integrals, i.e., singular integral quadrature is completely avoided. The inhomogeneous part of the recurrence has low rank structure (its rank is at most three for the Newtonian potential) and hence these recurrences have displacement structure. Using the recurrence directly is a fast approach for evaluation on or near the integration domain that remains accurate for low degree polynomial approximations, while high-precision arithmetic allows accurate use of the approach for moderate degree polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03003v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheehan Olver</dc:creator>
    </item>
    <item>
      <title>Bivariate polynomial histopolation techniques on Padua, Fekete and Leja triangles</title>
      <link>https://arxiv.org/abs/2506.03025</link>
      <description>arXiv:2506.03025v1 Announce Type: new 
Abstract: This paper explores the reconstruction of a real-valued function $f$ defined over a domain $\Omega \subset \mathbb{R}^2$ using bivariate polynomials that satisfy triangular histopolation conditions. More precisely, we assume that only the averages of $f$ over a given triangulation $\mathcal{T}_N$ of $\Omega$ are available and seek a bivariate polynomial that approximates $f$ using a histopolation approach, potentially flanked by an additional regression technique. This methodology relies on the selection of a subset of triangles $\mathcal{T}_M \subset \mathcal{T}_N$ for histopolation, ensuring both the solvability and the well-conditioning of the problem. The remaining triangles can potentially be used to enhance the accuracy of the polynomial approximation through a simultaneous regression. We will introduce histopolation and combined histopolation-regression methods using the Padua points, discrete Leja sequences, and approximate Fekete nodes. The proposed algorithms are implemented and evaluated through numerical experiments that demonstrate their effectiveness in function approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03025v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ludovico Bruni Bruno, Francesco Dell'Accio, Wolfgang Erb, Federico Nudo</dc:creator>
    </item>
    <item>
      <title>Rates of convergence of finite element approximations of second-order mean field games with nondifferentiable Hamiltonians</title>
      <link>https://arxiv.org/abs/2506.03039</link>
      <description>arXiv:2506.03039v1 Announce Type: new 
Abstract: We prove a rate of convergence for finite element approximations of stationary, second-order mean field games with nondifferentiable Hamiltonians posed in general bounded polytopal Lipschitz domains with strongly monotone running costs. In particular, we obtain a rate of convergence in the $H^1$-norm for the value function approximations and in the $L^2$-norm for the approximations of the density. We also establish a rate of convergence for the error between the exact solution of the MFG system with a nondifferentiable Hamiltonian and the finite element discretizations of the corresponding MFG system with a regularized Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03039v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohance A. P. Osborne, Iain Smears</dc:creator>
    </item>
    <item>
      <title>A structure-preserving and thermodynamically compatible cell-centered Lagrangian finite volume scheme for continuum mechanics</title>
      <link>https://arxiv.org/abs/2506.03081</link>
      <description>arXiv:2506.03081v1 Announce Type: new 
Abstract: In this work we present a novel structure-preserving scheme for the discretization of the Godunov-Peshkov-Romenski (GPR) model of continuum mechanics written in Lagrangian form. This model admits an extra conservation law for the total energy (first principle of thermodynamics) and satisfies the entropy inequality (second principle of thermodynamics). Furthermore, in the absence of algebraic source terms, the distortion field of the continuum and the specific thermal impulse satisfy a curl-free condition, provided the initial data are curl-free. Last but not least, the determinant of the distortion field is related to the density of the medium, i.e. the system is also endowed with a nonlinear algebraic constraint.
  The objective of this work is to construct and analyze a new semi-discrete thermodynamically compatible cell-centered Lagrangian finite volume scheme on moving unstructured meshes that satisfies the following structural properties of the governing PDE exactly at the discrete level: i) compatibility with the first law of thermodynamics, i.e. discrete total energy conservation; ii) compatibility with the second law of thermodynamics, i.e. discrete entropy inequality; iii) exact discrete compatibility between the density and the determinant of the distortion field; iv) exact preservation of the curl-free property of the distortion field and of the specific thermal impulse in the absence of algebraic source terms. We show that it is possible to achieve all above properties simultaneously. Unlike in existing schemes, we choose to directly discretize the entropy inequality, hence obtaining total energy conservation as a consequence of an appropriate and thermodynamically compatible discretization of all the other equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03081v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Walter Boscheri, Michael Dumbser, Raphael Loub\`ere, Pierre-Henri Maire</dc:creator>
    </item>
    <item>
      <title>On a spherically lifted spin model at finite temperature</title>
      <link>https://arxiv.org/abs/2506.02220</link>
      <description>arXiv:2506.02220v1 Announce Type: cross 
Abstract: We investigate an \(n\)-vector model over \(k\) sites with generic pairwise interactions and spherical constraints. The model is a lifting of the Ising model whereby the support of the spin is lifted to a hypersphere. We show that the \(n\)-vector model converges to a limiting distribution at a rate of \(n^{-1/2 + o(1)}\). We show that the limiting distribution for \(n \to \infty\) is determined by the solution of an equality-constrained maximization task over positive definite matrices. We prove that the obtained maximal value and maximizer, respectively, give rise to the free energy and correlation function of the limiting distribution. In the finite temperature regime, the maximization task is a log-determinant regularization of the semidefinite program (SDP) in the Goemans-Williamson algorithm. Moreover, the inverse temperature determines the regularization strength, with the zero temperature limit converging to the SDP in Goemans-Williamson. Our derivation draws a curious connection between the semidefinite relaxation of integer programming and the spherical lifting of sampling on a hypercube. To the authors' best knowledge, this work is the first to solve the setting of fixed \(k\) and infinite \(n\) under unstructured pairwise interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02220v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun Tang, Yuehaw Khoo, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Discovery of Probabilistic Dirichlet-to-Neumann Maps on Graphs</title>
      <link>https://arxiv.org/abs/2506.02337</link>
      <description>arXiv:2506.02337v1 Announce Type: cross 
Abstract: Dirichlet-to-Neumann maps enable the coupling of multiphysics simulations across computational subdomains by ensuring continuity of state variables and fluxes at artificial interfaces. We present a novel method for learning Dirichlet-to-Neumann maps on graphs using Gaussian processes, specifically for problems where the data obey a conservation constraint from an underlying partial differential equation. Our approach combines discrete exterior calculus and nonlinear optimal recovery to infer relationships between vertex and edge values. This framework yields data-driven predictions with uncertainty quantification across the entire graph, even when observations are limited to a subset of vertices and edges. By optimizing over the reproducing kernel Hilbert space norm while applying a maximum likelihood estimation penalty on kernel complexity, our method ensures that the resulting surrogate strictly enforces conservation laws without overfitting. We demonstrate our method on two representative applications: subsurface fracture networks and arterial blood flow. Our results show that the method maintains high accuracy and well-calibrated uncertainty estimates even under severe data scarcity, highlighting its potential for scientific applications where limited data and reliable uncertainty quantification are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02337v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrienne M. Propp, Jonas A. Actor, Elise Walker, Houman Owhadi, Nathaniel Trask, Daniel M. Tartakovsky</dc:creator>
    </item>
    <item>
      <title>Non-exchangeable evolutionary and mean field games and their applications</title>
      <link>https://arxiv.org/abs/2506.02644</link>
      <description>arXiv:2506.02644v2 Announce Type: cross 
Abstract: A replicator dynamic for non-exchangeable agents in a continuous action space is formulated and its well-posedness is proven in a space of probability measures. The non-exchangeability allows for the analysis of evolutionary games involving agents with distinct (and possibly infinitely many) types. We also explicitly connect this replicator dynamic to a stationary mean field game, which determines the pairwise actions of the heterogeneous agents. Moreover, as a byproduct of our theoretical results, we show that a class of nonlinear voter models, recently the subject of increasing interest, called q-voter models, can be viewed as a replicator dynamic driven by a utility that is a power of the probability density. This implies that non-exchangeable and/or mean-field game formulations of these models can also be constructed. We also present computational examples of evolutionary and mean field game models using a finite difference method, focusing on tragedy of the commons and the q-voter model with non-exchangeable agents, of which are interesting cases from theoretical and computational perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02644v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Yoshioka, M. Tsujimura, T. Tanaka</dc:creator>
    </item>
    <item>
      <title>Multilevel Stochastic Gradient Descent for Optimal Control Under Uncertainty</title>
      <link>https://arxiv.org/abs/2506.02647</link>
      <description>arXiv:2506.02647v1 Announce Type: cross 
Abstract: We present a multilevel stochastic gradient descent method for the optimal control of systems governed by partial differential equations under uncertain input data. The gradient descent method used to find the optimal control leverages a parallel multilevel Monte Carlo method as stochastic gradient estimator. As a result, we achieve precise control over the stochastic gradient's bias, introduced by numerical approximation, and its sampling error, arising from the use of incomplete gradients, while optimally managing computational resources. We show that the method exhibits linear convergence in the number of optimization steps while avoiding the cost of computing the full gradient at the highest fidelity. Numerical experiments demonstrate that the method significantly outperforms the standard (mini-) batched stochastic gradient descent method in terms of convergence speed and accuracy. The method is particularly well-suited for high-dimensional control problems, taking advantage of parallel computing resources and a distributed multilevel data structure. Additionally, we evaluate and implement different step size strategies, optimizer schemes, and budgeting techniques. The method's performance is studied using a two-dimensional elliptic subsurface diffusion problem with log-normal coefficients and Mat\'ern covariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02647v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Niklas Baumgarten, David Schneiderhan</dc:creator>
    </item>
    <item>
      <title>TL;DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression</title>
      <link>https://arxiv.org/abs/2506.02678</link>
      <description>arXiv:2506.02678v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have recently achieved remarkable progress by leveraging Reinforcement Learning and extended Chain-of-Thought (CoT) techniques. However, the challenge of performing efficient language reasoning--especially during inference with extremely long outputs--has drawn increasing attention from the research community. In this work, we propose a dynamic ratio-based training pipeline that does not rely on sophisticated data annotations or interpolation between multiple models. We continuously balance the weights between the model's System-1 and System-2 data to eliminate redundant reasoning processes while preserving the model's reasoning capability. We validate our approach across models on DeepSeek-R1-Distill-7B and DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying difficulty levels. Our method significantly reduces the number of output tokens by nearly 40% while maintaining the accuracy of the reasoning. Our code and data will be available soon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02678v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhong-Zhi Li, Xiao Liang, Zihao Tang, Lei Ji, Peijie Wang, Haotian Xu, Xing W, Haizhen Huang, Weiwei Deng, Ying Nian Wu, Yeyun Gong, Zhijiang Guo, Xiao Liu, Fei Yin, Cheng-Lin Liu</dc:creator>
    </item>
    <item>
      <title>A priori error estimates for the $\theta$-method for the flow of nonsmooth velocity fields</title>
      <link>https://arxiv.org/abs/2506.02747</link>
      <description>arXiv:2506.02747v1 Announce Type: cross 
Abstract: Velocity fields with low regularity (below the Lipschitz threshold) naturally arise in many models from mathematical physics, such as the inhomogeneous incompressible Navier-Stokes equations, and play a fundamental role in the analysis of nonlinear PDEs. The DiPerna-Lions theory ensures existence and uniqueness of the flow associated with a divergence-free velocity field with Sobolev regularity. In this paper, we establish a priori error estimates showing a logarithmic rate of convergence of numerical solutions, constructed via the $\theta$-method, towards the exact (analytic) flow for a velocity field with Sobolev regularity. In addition, we derive analogous a priori error estimates for Lagrangian solutions of the associated transport equation, exhibiting the same logarithmic rate of convergence. Our theoretical results are supported by numerical experiments, which confirm the predicted logarithmic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02747v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gennaro Ciampa, Tommaso Cortopassi, Gianluca Crippa, Raffaele D'Ambrosio, Stefano Spirito</dc:creator>
    </item>
    <item>
      <title>GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches</title>
      <link>https://arxiv.org/abs/2506.03070</link>
      <description>arXiv:2506.03070v1 Announce Type: cross 
Abstract: A litany of theoretical and numerical results have established the sketch-and-precondition paradigm as a powerful approach to solving large linear regression problems in standard computing environments. Perhaps surprisingly, much less work has been done on understanding how sketch-and-precondition performs on graphics processing unit (GPU) systems. We address this gap by benchmarking an implementation of sketch-and-precondition based on sparse sign-sketches on single and multi-GPU systems. In doing so, we describe a novel, easily parallelized, rejection-sampling based method for generating sparse sign sketches. Our approach, which is particularly well-suited for GPUs, is easily adapted to a variety of computing environments. Taken as a whole, our numerical experiments indicate that sketch-and-precondition with sparse sign sketches is particularly well-suited for GPUs, and may be suitable for use in black-box least-squares solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03070v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen, Pradeep Niroula, Archan Ray, Pragna Subrahmanya, Marco Pistoia, Niraj Kumar</dc:creator>
    </item>
    <item>
      <title>A new characterization of the convergence factor of two-level methods</title>
      <link>https://arxiv.org/abs/2102.08600</link>
      <description>arXiv:2102.08600v2 Announce Type: replace 
Abstract: Multilevel methods are among the most efficient numerical methods for solving large-scale systems of equations that arise from discretized partial differential equations. Two-level convergence theory plays a fundamental role in the analysis and design of multilevel methods. In this paper, we present a concise and easy-to-use identity for characterizing the convergence factor of two-level methods, whose hierarchical spaces can be either overlapping or non-overlapping. In order to illustrate its usability and convenience, we give several applications, which offer new insights into the design of multilevel methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.08600v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Xu</dc:creator>
    </item>
    <item>
      <title>Shallow ReLU neural networks and finite elements</title>
      <link>https://arxiv.org/abs/2403.05809</link>
      <description>arXiv:2403.05809v2 Announce Type: replace 
Abstract: We point out that (continuous or discontinuous) piecewise linear functions on a convex polytope mesh can be represented by two-hidden-layer ReLU neural networks in a weak sense. In addition, the numbers of neurons of the two hidden layers required to weakly represent are accurately given based on the numbers of polytopes and hyperplanes involved in this mesh. The results naturally hold for constant and linear finite element functions. Such weak representation establishes a bridge between shallow ReLU neural networks and finite element functions, and leads to a perspective for analyzing approximation capability of ReLU neural networks in $L^p$ norm via finite element functions. Moreover, we discuss the strict representation for tensor finite element functions via the recent tensor neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05809v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengzhan Jin</dc:creator>
    </item>
    <item>
      <title>Learning WENO for entropy stable schemes to solve conservation laws</title>
      <link>https://arxiv.org/abs/2403.14848</link>
      <description>arXiv:2403.14848v2 Announce Type: replace 
Abstract: Entropy conditions play a crucial role in the extraction of a physically relevant solution for systems of conservation laws, thus motivating the construction of entropy stable schemes that satisfy a discrete analogue of such conditions. TeCNO schemes (Fjordholm et al. 2012) form a class of arbitrary high-order entropy stable finite difference solvers, which require specialized reconstruction algorithms satisfying the sign property at each cell interface. Third-order weighted essentially non-oscillatory (WENO) schemes called SP-WENO (Fjordholm and Ray, 2016) and SP-WENOc (Ray, 2018) have been designed to satisfy the sign property. However, these WENO algorithms can perform poorly near shocks, with the numerical solutions exhibiting large spurious oscillations. In the present work, we propose a variant of the SP-WENO, termed as Deep Sign-Preserving WENO (DSP-WENO), where a neural network is trained to learn the WENO weighting strategy. The sign property and third-order accuracy are strongly imposed in the algorithm, which constrains the WENO weight selection region to a convex polygon. Thereafter, a neural network is trained to select the WENO weights from this convex region with the goal of improving the shock-capturing capabilities without sacrificing the rate of convergence in smooth regions. The proposed synergistic approach retains the mathematical framework of the TeCNO scheme while integrating deep learning to remedy the computational issues of the WENO-based reconstruction. We present several numerical experiments to demonstrate the significant improvement with DSP-WENO over the existing variants of WENO satisfying the sign property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14848v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Charles, Deep Ray</dc:creator>
    </item>
    <item>
      <title>Computing the Proximal Operator of the $q$-th Power of the $\ell_{1,q}$-norm for Group Sparsity</title>
      <link>https://arxiv.org/abs/2409.14156</link>
      <description>arXiv:2409.14156v2 Announce Type: replace 
Abstract: In this note, we comprehensively characterize the proximal operator of the $q$-th power of the $\ell_{1,q}$-norm (denoted by $\ell_{1,q}^{q}$) with $0\!&lt;\!q\!&lt;\!1$ by exploiting the well-known proximal operator of $|\cdot|^q$ on the real line. In particular, much more explicit characterizations can be obtained whenever $q\!=\!1/2$ and $q\!=\!2/3$ due to the existence of closed-form expressions for the proximal operators of $|\cdot|^{1/2}$ and $|\cdot|^{2/3}$. Numerical experiments demonstrate potential advantages of the $\ell_{1,q}^{q}$ regularization in the }inter-group and intra-group sparse vector recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14156v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rongrong Lin, Shihai Chen, Han Feng, Yulan Liu</dc:creator>
    </item>
    <item>
      <title>An Immersed Interface Method for Incompressible Flows and Geometries with Sharp Features</title>
      <link>https://arxiv.org/abs/2410.16466</link>
      <description>arXiv:2410.16466v5 Announce Type: replace 
Abstract: The immersed interface method (IIM) for models of fluid flow and fluid-structure interaction imposes jump conditions that capture stress discontinuities generated by forces that are concentrated along immersed boundaries. Most prior work using the IIM for fluid dynamic applications has focused on smooth interfaces, but boundaries with sharp features such as corners and edges can appear in practical analyses, particularly on engineered structures. The present study builds on our work to integrate finite element-type representations of interface geometries with the IIM. Initial realizations of this approach used a continuous Galerkin (CG) finite element discretization for the boundary, but as we show herein, these approaches generate large errors near sharp geometrical features. To overcome this difficulty, this study introduces an IIM approach using discontinuous Galerkin (DG) representation of the jump conditions. Numerical examples explore the impacts of different interface representations on accuracy for both smooth and sharp boundaries, particularly flows interacting with fixed interface configurations. We demonstrate that using a DG approach provides accuracy that is comparable to the CG method for smooth cases. Further, we identify a time step size restriction for the CG representation that is directly related to the sharpness of the geometry. In contrast, time step size restrictions imposed by DG representations are demonstrated to be insensitive to the presence of sharp features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16466v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael J. Facci, Ebrahim M. Kolahdouz, Boyce E. Griffith</dc:creator>
    </item>
    <item>
      <title>Neural numerical homogenization based on Deep Ritz corrections</title>
      <link>https://arxiv.org/abs/2411.14084</link>
      <description>arXiv:2411.14084v2 Announce Type: replace 
Abstract: Numerical homogenization methods aim at providing appropriate coarse-scale approximations of solutions to (elliptic) partial differential equations that involve highly oscillatory coefficients. The localized orthogonal decomposition (LOD) method is an effective way of dealing with such coefficients, especially if they are non-periodic and non-smooth. It modifies classical finite element basis functions by suitable fine-scale corrections. In this paper, we make use of the structure of the LOD method, but we propose to calculate the corrections based on a Deep Ritz approach involving a parametrization of the coefficients to tackle temporal variations or uncertainties. Numerical examples for a parabolic model problem are presented to assess the performance of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14084v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Elasmi, Felix Krumbiegel, Roland Maier</dc:creator>
    </item>
    <item>
      <title>Numerical schemes for a fully nonlinear coagulation-fragmentation model coming from wave kinetic theory</title>
      <link>https://arxiv.org/abs/2412.05402</link>
      <description>arXiv:2412.05402v3 Announce Type: replace 
Abstract: This article introduces a novel numerical approach, based on Finite Volume Techniques, for studying fully nonlinear coagulation-fragmentation models, where both the coagulation and fragmentation components of the collision operator are nonlinear. The models come from $3-$wave kinetic equations, a pivotal framework in wave turbulence theory. Despite the importance of wave turbulence theory in physics and mechanics, there have been very few numerical schemes for $3-$wave kinetic equations, in which no ad-hoc additional assumptions are imposed on the evolution of the solutions, and the current manuscript provides one of the first of such schemes. To the best of our knowledge, this also is the first numerical scheme capable of accurately capturing the long-term asymptotic behavior of solutions to a fully nonlinear coagulation-fragmentation model that includes both forward and backward energy cascades. The scheme is implemented on some test problems, demonstrating strong alignment with theoretical predictions of energy cascade rates. We further introduce a weighted Finite Volume variant to ensure energy conservation across varying degrees of kernel homogeneity. Convergence and first-order consistency are established through theoretical analysis and verified by experimental convergence orders in test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05402v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arijit Das, Minh-Binh Tran</dc:creator>
    </item>
    <item>
      <title>Changing the ranking in eigenvector centrality of a weighted graph by small perturbations</title>
      <link>https://arxiv.org/abs/2501.10745</link>
      <description>arXiv:2501.10745v2 Announce Type: replace 
Abstract: In this article, we consider eigenvector centrality for the nodes of a graph and study the robustness (and stability) of this popular centrality measure. For a given weighted graph ${\mathcal G}$ (both directed and undirected), we consider the associated weighted adjacency matrix $A$, which by definition is a non-negative matrix. The eigenvector centralities of the nodes of ${\mathcal G}$ are the entries of the Perron eigenvector of $A$, which is the (positive) eigenvector associated with the eigenvalue with largest modulus. They provide a ranking of the nodes according to the corresponding centralities. An indicator of the robustness of eigenvector centrality consists in looking for a nearby perturbed graph $\widetilde{\mathcal G}$, with the same structure as ${\mathcal G}$ (i.e., with the same vertices and edges), but with a weighted adjacency matrix $\widetilde A$ such that the highest $m$ entries ($m \ge 2$) of the Perron eigenvector of $\widetilde A$ coalesce, making the ranking at the highest level ambiguous. To compute a solution to this matrix nearness problem, a nested iterative algorithm is proposed that makes use of a constrained gradient system of matrix differential equations in the inner iteration and a one-dimensional optimization of the perturbation size in the outer iteration.
  The proposed algorithm produces the {\em optimal} perturbation (i.e., the one with smallest Frobenius norm) of the $A$ which causes the looked-for coalescence, which is a measure of the sensitivity of the graph. Our numerical experiments indicate that the proposed strategy outperforms more standard approaches based on algorithms for constrained optimization. The methodology is formulated in terms of graphs but applies to any nonnegative matrix, with potential applications in fields like population models, consensus dynamics, economics, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10745v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michele Benzi, Nicola Guglielmi</dc:creator>
    </item>
    <item>
      <title>Airy Phase Functions</title>
      <link>https://arxiv.org/abs/2503.02306</link>
      <description>arXiv:2503.02306v2 Announce Type: replace 
Abstract: It is well known that phase function methods allow for the numerical solution of a large class of oscillatory second order linear ordinary differential equations in time independent of frequency. Unfortunately, these methods break down in the commonly-occurring case in which the equation has turning points. Here, we resolve this difficulty by introducing a generalized phase function method designed for the case of second order linear ordinary differential equations with turning points. More explicitly, we prove the existence of a slowly-varying ``Airy phase function'' that efficiently represents a basis in the space of solutions of such an equation, and describe a numerical algorithm for calculating this Airy phase function. The running time of our algorithm is independent of the magnitude of the logarithmic derivatives of the equation's solutions, which is a measure of their rate of variation that generalizes the notion of frequency to functions which are rapidly varying but not necessarily oscillatory. Once the Airy phase function has been constructed, any reasonable initial or boundary value problem for the equation can be readily solved and, unlike step methods which output the values of a rapidly-varying solution on a sparse discretization grid that is insufficient for interpolation, the output of our scheme allows for the rapid evaluation of the obtained solution at any point in its domain. We rigorously justify our approach by proving not only the existence of slowly-varying Airy phase functions, but also the convergence of our numerical method. Moreover, we present the results of extensive numerical experiments demonstrating the efficacy of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02306v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Chow, James Bremer</dc:creator>
    </item>
    <item>
      <title>A linearly-implicit energy-momentum preserving scheme for geometrically nonlinear mechanics based on non-canonical Hamiltonian formulations</title>
      <link>https://arxiv.org/abs/2503.04695</link>
      <description>arXiv:2503.04695v2 Announce Type: replace 
Abstract: This work presents a novel formulation and numerical strategy for the simulation of geometrically nonlinear structures. First, a non-canonical Hamiltonian (Poisson) formulation is introduced by including the dynamics of the stress tensor. This framework is developed for von-K\'arm\'an nonlinearities in beams and plates, as well as geometrically nonlinear elasticity with Saint-Venant material behavior. In the case of plates, both negligible and non-negligible membrane inertia are considered. For the former case the two-dimensional elasticity complex is leveraged to express the dynamics in terms of the Airy stress function. The finite element discretization employs a mixed approach, combining a conforming approximation for displacement and velocity fields with a discontinuous stress tensor representation. A staggered, linear implicit time integration scheme is proposed, establishing connections with existing explicit-implicit energy-preserving methods. The stress degrees of freedom are statically condensed, reducing the computational complexity to solving a system with a positive definite matrix. The integration strategy preserves energy and angular momentum exactly. The methodology is validated through numerical experiments on the Duffing oscillator, a von-K\'arm\'an beam, and a column undergoing finite deformations. Comparisons with fully implicit energy-preserving method and the leapfrog scheme demonstrate that the proposed approach achieves superior accuracy while maintaining energy stability. Additionally, it enables larger time steps compared to explicit schemes and exhibits computational efficiency comparable to the leapfrog method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04695v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Brugnoli, Denis Matignon, Joseph Morlier</dc:creator>
    </item>
    <item>
      <title>Effects of Interpolation Error and Bias on the Random Mesh Finite Element Method for Inverse Problems</title>
      <link>https://arxiv.org/abs/2504.03393</link>
      <description>arXiv:2504.03393v2 Announce Type: replace 
Abstract: Bayesian inverse problems are an important application for probabilistic solvers of partial differential equations: when fully resolving numerical error is computationally infeasible, probabilistic solvers can be used to consistently model the error and propagate it to the posterior. In this work, the performance of the random mesh finite element method (RM-FEM) is investigated in a Bayesian inverse setting. We show how interpolation error negatively affects the RM-FEM posterior, and how these negative effects can be diminished. In scenarios where FEM is biased for a quantity of interest, we find that RM-FEM struggles to accurately model this bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03393v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Poot, Iuri Rocha, Pierre Kerfriden, Frans van der Meer</dc:creator>
    </item>
    <item>
      <title>Exact root-exponential convergence rates of lightning plus polynomial approximations for corner singularities</title>
      <link>https://arxiv.org/abs/2504.16756</link>
      <description>arXiv:2504.16756v2 Announce Type: replace 
Abstract: This paper builds rigorous analysis on the root-exponential convergence for the lightning schemes via rational functions in approximating corner singularity problems with uniform exponentially clustered poles proposed by Gopal and Trefethen. The start point is to set up the representations of $z^\alpha$ and $z^\alpha\log z$ in the slit disk and develop results akin to Paley-Wiener theorem, from which, together with the Poisson summation formula, the root-exponential convergence of the lightning plus polynomial scheme with an exact order for each clustered parameter is established in approximation of prototype functions $g(z)z^\alpha$ or $g(z)z^\alpha\log z$ on a sector-shaped domain, which includes $[0,1]$ as a special case. In addition, the fastest convergence rate is confirmed based upon the best choice of the clustered parameter. Furthermore, the optimal choice of the clustered parameter and the convergence rate for corner singularity problems in solving Laplace equations are attested based on Lehman and Wasow's study of corner singularities and along with the decomposition of Gopal and Trefethen. The thorough analysis provides a solid foundation for lightning schemes and rational approximation. Ample numerical evidences demonstrate the optimality and sharpness of the estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16756v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuhuang Xiang, Shunfeng Yang, Yanghao Wu</dc:creator>
    </item>
    <item>
      <title>Neural semi-Lagrangian method for high-dimensional advection-diffusion problems</title>
      <link>https://arxiv.org/abs/2504.20715</link>
      <description>arXiv:2504.20715v2 Announce Type: replace 
Abstract: This work is devoted to the numerical approximation of high-dimensional advection-diffusion equations. It is well-known that classical methods, such as the finite volume method, suffer from the curse of dimensionality, and that their time step is constrained by a stability condition. The semi-Lagrangian method is known to overcome the stability issue, while recent time-discrete neural network-based approaches overcome the curse of dimensionality. In this work, we propose a novel neural semi-Lagrangian method that combines these last two approaches. It relies on projecting the initial condition onto a finite-dimensional neural space, and then solving an optimization problem, involving the backwards characteristic equation, at each time step. It is particularly well-suited for implementation on GPUs, as it is fully parallelizable and does not require a mesh. We provide rough error estimates, and present several high-dimensional numerical experiments to assess the performance of our approach, and compare it to other neural methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20715v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emmanuel Franck, Victor Michel-Dansac, Laurent Navoret, Vincent Vigon</dc:creator>
    </item>
    <item>
      <title>Modeling of thin plate flexural vibrations by Partition of Unity Finite Element Method</title>
      <link>https://arxiv.org/abs/2505.04227</link>
      <description>arXiv:2505.04227v2 Announce Type: replace 
Abstract: This paper presents a conforming thin plate bending element based on the Partition of Unity Finite Element Method (PUFEM), for the simulation of steady-state forced vibration. The issue of ensuring the continuity of displacement and slope between elements is addressed by the use of cubic Hermite-type Partition of Unity (PU) functions. With appropriate PU functions, the PUFEM allows the incorporation of the special enrichment functions into the finite elements to better cope with plate oscillations in a broad frequency band. The enrichment strategies consist of the sum of a power series up to a given order and a combination of progressive flexural wave solutions with polynomials. The applicability and the effectiveness of the PUFEM plate elements is first verified via the structural frequency response. Investigation is then carried out to analyze the role of polynomial enrichment orders and enriched plane wave distributions for achieving good computational performance in terms of accuracy and data reduction. Numerical results show that the PUFEM with high-order polynomials and hybrid wave-polynomial combinations can provide highly accurate prediction results by using reduced degrees of freedom and improved rate of convergence, as compared with the classical FEM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04227v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S1758825121500307</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Applied Mechanics Vol. 13, No. 03, 2150030 (2021)</arxiv:journal_reference>
      <dc:creator>Tong Zhou, Jean-Daniel Chazot, Emmanuel Perrey-Debain, Li Cheng</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Neural Networks for the Relativistic Burgers Equation in the Exterior of a Schwarzschild Black Hole</title>
      <link>https://arxiv.org/abs/2506.00951</link>
      <description>arXiv:2506.00951v2 Announce Type: replace 
Abstract: We introduce a Physics-Informed Neural Networks(PINN) to solve a relativistic Burgers equation in the exterior domain of a Schwarzschild black hole. Our main contribution is a PINN architecture that is able to simulate shock wave formations in such curved spacetime, by training a shock-aware network block and introducing a Godunov-inspired residuals in the loss function. We validate our method with numerical experiments with different kinds of initial conditions. We show its ability to reproduce both smooth and discontinuous solutions in the context of general relativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00951v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>gr-qc</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyang Xiang</dc:creator>
    </item>
    <item>
      <title>Quantum Circuit Encodings of Polynomial Chaos Expansions</title>
      <link>https://arxiv.org/abs/2506.01811</link>
      <description>arXiv:2506.01811v2 Announce Type: replace 
Abstract: This work investigates the expressive power of quantum circuits in approximating high-dimensional, real-valued functions. We focus on countably-parametric holomorphic maps $u:U\to \mathbb{R}$, where the parameter domain is $U=[-1,1]^{\mathbb{N}}$. We establish dimension-independent quantum circuit approximation rates via the best $n$-term truncations of generalized polynomial chaos (gPC) expansions of these parametric maps, demonstrating that these rates depend solely on the summability exponent of the gPC expansion coefficients. The key to our findings is based on the fact that so-called ``$(\boldsymbol{b},\epsilon)$-holomorphic'' functions, where $\boldsymbol{b}\in (0,1]^\mathbb N \cap \ell^p(\mathbb N)$ for some $p\in(0,1)$, permit structured and sparse gPC expansions. Then, $n$-term truncated gPC expansions are known to admit approximation rates of order $n^{-1/p + 1/2}$ in the $L^2$ norm and of order $n^{-1/p + 1}$ in the $L^\infty$ norm. We show the existence of parameterized quantum circuit (PQC) encodings of these $n$-term truncated gPC expansions, and bound PQC depth and width via (i) tensorization of univariate PQCs that encode Cheby\v{s}ev-polynomials in $[-1,1]$ and (ii) linear combination of unitaries (LCU) to build PQC emulations of $n$-term truncated gPC expansions. The results provide a rigorous mathematical foundation for the use of quantum algorithms in high-dimensional function approximation. As countably-parametric holomorphic maps naturally arise in parametric PDE models and uncertainty quantification (UQ), our results have implications for quantum-enhanced algorithms for a wide range of maps in applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01811v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junaid Aftab, Christoph Schwab, Haizhao Yang, Jakob Zech</dc:creator>
    </item>
    <item>
      <title>Why Shallow Networks Struggle to Approximate and Learn High Frequencies</title>
      <link>https://arxiv.org/abs/2306.17301</link>
      <description>arXiv:2306.17301v3 Announce Type: replace-cross 
Abstract: In this work, we present a comprehensive study combining mathematical and computational analysis to explain why a two-layer neural network struggles to handle high frequencies in both approximation and learning, especially when machine precision, numerical noise, and computational cost are significant factors in practice. Specifically, we investigate the following fundamental computational issues: (1) the minimal numerical error achievable under finite precision, (2) the computational cost required to attain a given accuracy, and (3) the stability of the method with respect to perturbations. The core of our analysis lies in the conditioning of the representation and its learning dynamics. Explicit answers to these questions are provided, along with supporting numerical evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17301v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijun Zhang, Hongkai Zhao, Yimin Zhong, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Structured and Balanced Multi-Component and Multi-Layer Neural Networks</title>
      <link>https://arxiv.org/abs/2407.00765</link>
      <description>arXiv:2407.00765v2 Announce Type: replace-cross 
Abstract: In this work, we propose a balanced multi-component and multi-layer neural network (MMNN) structure to accurately and efficiently approximate functions with complex features, in terms of both degrees of freedom and computational cost. The main idea is inspired by a multi-component approach, in which each component can be effectively approximated by a single-layer network, combined with a multi-layer decomposition strategy to capture the complexity of the target function. Although MMNNs can be viewed as a simple modification of fully connected neural networks (FCNNs) or multi-layer perceptrons (MLPs) by introducing balanced multi-component structures, they achieve a significant reduction in training parameters, a much more efficient training process, and improved accuracy compared to FCNNs or MLPs. Extensive numerical experiments demonstrate the effectiveness of MMNNs in approximating highly oscillatory functions and their ability to automatically adapt to localized features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00765v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijun Zhang, Hongkai Zhao, Yimin Zhong, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm</title>
      <link>https://arxiv.org/abs/2505.16932</link>
      <description>arXiv:2505.16932v2 Announce Type: replace-cross 
Abstract: Computing the polar decomposition and the related matrix sign function, has been a well-studied problem in numerical analysis for decades. More recently, it has emerged as an important subroutine in deep learning, particularly within the Muon optimization framework. However, the requirements in this setting differ significantly from those of traditional numerical analysis. In deep learning, methods must be highly efficient and GPU-compatible, but high accuracy is often unnecessary. As a result, classical algorithms like Newton-Schulz (which suffers from slow initial convergence) and methods based on rational functions (which rely on QR decompositions or matrix inverses) are poorly suited to this context. In this work, we introduce Polar Express, a GPU-friendly algorithm for computing the polar decomposition. Like classical polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix multiplications, making it GPU-compatible. Motivated by earlier work of Chen &amp; Chow and Nakatsukasa &amp; Freund, Polar Express adapts the polynomial update rule at each iteration by solving a minimax optimization problem, and we prove that it enjoys a strong worst-case optimality guarantee. This property ensures both rapid early convergence and fast asymptotic convergence. We also address finite-precision issues, making it stable in bfloat16 in practice. We apply Polar Express within the Muon optimization framework and show consistent improvements in validation loss on large-scale models such as GPT-2, outperforming recent alternatives across a range of learning rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16932v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Amsel, David Persson, Christopher Musco, Robert M. Gower</dc:creator>
    </item>
  </channel>
</rss>
