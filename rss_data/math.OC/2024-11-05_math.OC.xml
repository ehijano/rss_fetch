<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Nov 2024 02:53:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Problem of Calculus of Variations and Game Theory</title>
      <link>https://arxiv.org/abs/2411.00791</link>
      <description>arXiv:2411.00791v1 Announce Type: new 
Abstract: In this paper, we study a theoretical math problem of game theory and calculus of variations in which we minimize a functional involving two players. A general relationship between the optimal strategies for both players is presented, followed by computer analysis as well as polynomial approximation. Nash equilibrium strategies are determined through algebraic manipulation and linear programming. Lastly, a variation of the game is also investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00791v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grace Luo, Christopher Boyer, Siddharth Penmetsa</dc:creator>
    </item>
    <item>
      <title>A Flight-Mechanics Solver for Aircraft Inverse Simulations and Application to 3D Mirage-III Maneuver</title>
      <link>https://arxiv.org/abs/2411.00834</link>
      <description>arXiv:2411.00834v1 Announce Type: new 
Abstract: The main objective of this paper is to present a general mathematical model and an associated numerical algorithm applicable to an arbitrary fixed-wing fixed-mass aircraft undergoing an arbitrary maneuver, based on the 3D nonlinear coupled differential-algebraic equations of motion, including force, moment, kinematic and constraint equations. The model is formulated to address the inverse simulation problem where a target maneuver is prescribed and the corresponding time dependent patterns of the control variables are solved for to meet this maneuver. The model utilizes two different moving frames of references, namely the body axes and the wind axes. The numerical algorithm features sequential solution of equations in a fully explicit manner. It is straightforward to use the model in a reverse mode, namely the direct simulation problem. The inverse problem may be summarized as follows: Inputs: Time history of desired-trajectory rectangular coordinates relative to the ground-fixed axes. A constraint should be specified, which we arbitrarily chose it to be the bank angle. Also, certain geometric and aerodynamic aircraft data are needed. Outputs: Time history of the control variables (thrust magnitude, elevator angle, rudder angle, ailerons angle), which will satisfy the aimed trajectory. The paper finally applies the presented numerical algorithm to a roll maneuver for the Mirage-III fighter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00834v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.1346086</arxiv:DOI>
      <arxiv:journal_reference>Global Journal of Control Engineering and Technology, vol. 1, pp. 14-26, 2015</arxiv:journal_reference>
      <dc:creator>Osama A. Marzouk</dc:creator>
    </item>
    <item>
      <title>A Bregman firmly nonexpansive proximal operator for baryconvex optimization</title>
      <link>https://arxiv.org/abs/2411.00928</link>
      <description>arXiv:2411.00928v1 Announce Type: new 
Abstract: We present a generalization of the proximal operator defined through a convex combination of convex objectives, where the coefficients are updated in a minimax fashion. We prove that this new operator is Bregman firmly nonexpansive with respect to a Bregman divergence that combines Euclidean and information geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00928v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mastane Achab</dc:creator>
    </item>
    <item>
      <title>A Block Coordinate and Variance-Reduced Method for Generalized Variational Inequalities of Minty Type</title>
      <link>https://arxiv.org/abs/2411.00979</link>
      <description>arXiv:2411.00979v1 Announce Type: new 
Abstract: Block coordinate methods have been extensively studied for minimization problems, where they come with significant complexity improvements whenever the considered problems are compatible with block decomposition and, moreover, block Lipschitz parameters are highly nonuniform. For the more general class of variational inequalities with monotone operators, essentially none of the existing methods transparently shows potential complexity benefits of using block coordinate updates in such settings. Motivated by this gap, we develop a new randomized block coordinate method and study its oracle complexity and runtime. We prove that in the setting where block Lipschitz parameters are highly nonuniform -- the main setting in which block coordinate methods lead to high complexity improvements in any of the previously studied settings -- our method can lead to complexity improvements by a factor order-$m$, where $m$ is the number of coordinate blocks. The same method further applies to the more general problem with a finite-sum operator with $m$ components, where it can be interpreted as performing variance reduction. Compared to the state of the art, the method leads to complexity improvements up to a factor $\sqrt{m},$ obtained when the component Lipschitz parameters are highly nonuniform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00979v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Trajectory Design and Guidance for Far-range Proximity Operations of Active Debris Removal Missions with Angles-only Navigation and Safety Considerations</title>
      <link>https://arxiv.org/abs/2411.01021</link>
      <description>arXiv:2411.01021v1 Announce Type: new 
Abstract: Observability of the target, safety, and robustness are often recognized as critical factors in ensuring successful far-range proximity operations. The application of angles-only (AO) navigation for proximity operations is often met with hesitancy due to its inherent limitations in determining range, leading to issues in target observability and consequently, mission safety. However, this form of navigation remains highly appealing due to its low cost. This work employs Particle Swarm Optimization (PSO) and Reinforcement Learning (RL) for the design and guidance of such far-range trajectories, assuring observability, safety and robustness under angles-only navigation. Firstly, PSO is used to design a nominal trajectory that is observable, robust and safe. Subsequently, Proximal Policy Optimization (PPO), a cutting-edge RL algorithm, is utilized to develop a guidance controller capable of maintaining observability while steering the spacecraft from an initial perturbed state to a target state. The fidelity of the guidance controller is then tested in a Monte-Carlo (MC) manner by varying the initial relative spacecraft state. The observability of the nominal trajectory and the perturbed trajectories with guidance are validated using an Extended Kalman Filter (EKF). The perturbed trajectories are also shown to adhere to the safety requirements satisfied by the nominal trajectory. Results demonstrate that the trained controller successfully determines maneuvers that maintain observability and safety and reaches the target end state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01021v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minduli C. Wijayatunga, Roberto Armellin, Harry Holt</dc:creator>
    </item>
    <item>
      <title>On the Strong Convexity of PnP Regularization Using Linear Denoisers</title>
      <link>https://arxiv.org/abs/2411.01027</link>
      <description>arXiv:2411.01027v1 Announce Type: new 
Abstract: In the Plug-and-Play (PnP) method, a denoiser is used as a regularizer within classical proximal algorithms for image reconstruction. It is known that a broad class of linear denoisers can be expressed as the proximal operator of a convex regularizer. Consequently, the associated PnP algorithm can be linked to a convex optimization problem $\mathcal{P}$. For such a linear denoiser, we prove that $\mathcal{P}$ exhibits strong convexity for linear inverse problems. Specifically, we show that the strong convexity of $\mathcal{P}$ can be used to certify objective and iterative convergence of any PnP algorithm derived from classical proximal methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01027v1</guid>
      <category>math.OC</category>
      <category>eess.IV</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LSP.2024.3475913</arxiv:DOI>
      <arxiv:journal_reference>IEEE Signal Processing Letters, vol. 31, 2024, pg. 2790-2794</arxiv:journal_reference>
      <dc:creator>Arghya Sinha, Kunal N Chaudhury</dc:creator>
    </item>
    <item>
      <title>Distributed Nash Equilibrium Seeking for a Class of Uncertain Nonlinear Systems subject to Bounded Disturbances</title>
      <link>https://arxiv.org/abs/2411.01187</link>
      <description>arXiv:2411.01187v1 Announce Type: new 
Abstract: In this paper, we study the problem of the distributed Nash equilibrium seeking of N-player games over jointly strongly connected switching networks. The action of each player is governed by a class of uncertain nonlinear systems. Our approach integrates the consensus algorithm, the distributed estimator over jointly strongly connected switching networks, and some adaptive control technique. Furthermore, we also consider the disturbance rejection problem for bounded disturbances with unknown bounds. A special case of our results gives the solution of the distributed Nash equilibrium seeking for high-order integrator systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01187v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jie Huang</dc:creator>
    </item>
    <item>
      <title>Spatial Transformers for Radio Map Estimation</title>
      <link>https://arxiv.org/abs/2411.01211</link>
      <description>arXiv:2411.01211v1 Announce Type: new 
Abstract: Radio map estimation (RME) involves spatial interpolation of radio measurements to predict metrics such as the received signal strength at locations where no measurements were collected. The most popular estimators nowadays project the measurement locations to a regular grid and complete the resulting measurement tensor with a convolutional deep neural network. Unfortunately, these approaches suffer from poor spatial resolution and require a great number of parameters. The first contribution of this paper addresses these limitations by means of an attention-based estimator named Spatial TransfOrmer for Radio Map estimation (STORM). This scheme not only outperforms the existing estimators, but also exhibits lower computational complexity, translation equivariance, rotation equivariance, and full spatial resolution. The second contribution is an extended transformer architecture that allows STORM to perform active sensing, where the next measurement location is selected based on the previous measurements. This is particularly useful for minimization of drive tests (MDT) in cellular networks, where operators request user equipment to collect measurements. Finally, STORM is extensively validated by experiments with one ray-tracing and two real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01211v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Q. Viet, Daniel Romero</dc:creator>
    </item>
    <item>
      <title>On the ReLU Lagrangian Cuts for Stochastic Mixed Integer Programming</title>
      <link>https://arxiv.org/abs/2411.01229</link>
      <description>arXiv:2411.01229v1 Announce Type: new 
Abstract: We study stochastic mixed integer programs where both first-stage and recourse decisions can be mixed integers. A new family of Lagrangian cuts, termed ``ReLU Lagrangian cuts," is introduced by reformulating the nonanticipativity constraints using ReLU functions. These cuts can be integrated into scenario decomposition algorithms. Unlike the ordinary Lagrangian cuts, we prove that the inclusion of ReLU Lagrangian cuts is sufficient to solve the original stochastic mixed integer programs to optimality. Without solving the Lagrangian dual problems, we derive closed-form expressions for these cuts. Furthermore, to speed up the cut-generating procedures, we introduce linear programming-based techniques to enhance the cut coefficients. Numerical studies demonstrate the effectiveness of the proposed cuts compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01229v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyun Deng, Weijun Xie</dc:creator>
    </item>
    <item>
      <title>On strict proto-differentiability of set-valued mappings</title>
      <link>https://arxiv.org/abs/2411.01346</link>
      <description>arXiv:2411.01346v1 Announce Type: new 
Abstract: We will show that a multifunction is strictly proto-differentiable at a point of its graph if and only if it is graphically strictly differentiable, i.e., the graph of the multifunction locally coincides, up to a change of coordinates, with the graph of a single-valued mapping, which is strictly differentiable at the transformed reference point. This result allows point-based characterizations of strict proto-differentiability in terms of various generalized derivatives. Further we will prove that under strict proto-differentiability the properties of strong metric regularity, metric regularity and strong metric subregularity are equivalent. Finally, under strict proto-differentiability of the subgradient mapping, we provide a novel second-order relation between function values and subgradients for prox-regular functions which constitutes a nonsmooth extension of the trapezoidal rule of numerical integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01346v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helmut Gfrerer</dc:creator>
    </item>
    <item>
      <title>On the Value of Risk-Averse Multistage Stochastic Programming in Capacity Planning</title>
      <link>https://arxiv.org/abs/2411.01370</link>
      <description>arXiv:2411.01370v1 Announce Type: new 
Abstract: We consider a risk-averse stochastic capacity planning problem under uncertain demand in each period. Using a scenario tree representation of the uncertainty, we formulate a multistage stochastic integer program to adjust the capacity expansion plan dynamically as more information on the uncertainty is revealed. Specifically, in each stage, a decision maker optimizes capacity acquisition and resource allocation to minimize certain risk measures of maintenance and operational cost. We compare it with a two-stage approach that determines the capacity acquisition for all the periods up front. Using expected conditional risk measures (ECRMs), we derive a tight lower bound and an upper bound for the gaps between the optimal objective values of risk-averse multistage models and their two-stage counterparts. Based on these derived bounds, we present general guidelines on when to solve risk-averse two-stage or multistage models. Furthermore, we propose approximation algorithms to solve the two models more efficiently, which are asymptotically optimal under an expanding market assumption. We conduct numerical studies using randomly generated and real-world instances with diverse sizes, to demonstrate the tightness of the analytical bounds and efficacy of the approximation algorithms. We find that the gaps between risk-averse multistage and two-stage models increase as the variability of the uncertain parameters increases and decrease as the decision maker becomes more risk-averse. Moreover, stagewise-dependent scenario tree attains much higher gaps than stagewise-independent counterpart, while the latter produces tighter analytical bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01370v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1287/ijoc.2023.0396</arxiv:DOI>
      <dc:creator>Xian Yu, Siqian Shen</dc:creator>
    </item>
    <item>
      <title>Sequential Charging Station Location Optimization under Uncertain Charging Behavior and User Growth</title>
      <link>https://arxiv.org/abs/2411.01416</link>
      <description>arXiv:2411.01416v1 Announce Type: new 
Abstract: Charging station availability is crucial for a thriving electric vehicle market. Due to budget constraints, locating these stations usually proceeds in phases, which calls for careful consideration of the (random) charging demand growth throughout the planning horizon. This paper integrates user choice behavior into two-stage and multi-stage stochastic programming models for intracity charging station planning under demand uncertainty. We derive a second-order conic representation for the nonlinear, nonconvex formulation by taking advantage of the binary nature of location variables and propose subgradient inequalities to accelerate computation. Numerical results demonstrate the value of employing multi-stage models, particularly in scenarios of high demand fluctuations, increased demand dispersion, and high user sensitivity to the distance-to-recharge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01416v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjia Shen, Bo Zhou, Ruiwei Jiang, Siqian Shen</dc:creator>
    </item>
    <item>
      <title>SPICE: Scaling-Aware Prediction Correction Methods with a Free Convergence Rate for Nonlinear Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.01421</link>
      <description>arXiv:2411.01421v1 Announce Type: new 
Abstract: Recently, the prediction-correction method has been developed to solve nonlinear convex optimization problems. However, its convergence rate is often poor since large regularization parameters are set to ensure convergence conditions. In this paper, the scaling-aware prediction correction (\textsf{Spice}) method is proposed to achieve a free convergence rate. This method adopts a novel scaling technique that adjusts the weight of the objective and constraint functions. The theoretical analysis demonstrates that increasing the scaling factor for the objective function or decreasing the scaling factor for constraint functions significantly enhances the convergence rate of the prediction correction method. In addition, the \textsf{Spice} method is further extended to solve separable variable nonlinear convex optimization. By employing different scaling factors as functions of the iterations, the \textsf{Spice} method achieves convergence rates of $\mathcal{O}(1/(t+1))$, $\mathcal{O}(1/[e^{t}(t+1)])$, and $\mathcal{O}(1/(t+1)^{t+1})$. Numerical experiments further validate the theoretical findings, demonstrating the effectiveness of the \textsf{Spice} method in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01421v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sai Wang</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Resource Allocation with Trust-aided Parametric Information Fusion</title>
      <link>https://arxiv.org/abs/2411.01428</link>
      <description>arXiv:2411.01428v1 Announce Type: new 
Abstract: Reference information plays an essential role for making decisions under uncertainty, yet may vary across multiple data sources. In this paper, we study resource allocation in stochastic dynamic environments, where we perform information fusion based on trust of different data sources, to design an ambiguity set for attaining distributionally robust resource allocation solutions. We dynamically update the trust parameter to simulate the decision maker's trust change based on losses caused by mis-specified reference information. We show an equivalent tractable linear programming reformulation of the distributionally robust optimization model and demonstrate the performance in a wildfire suppression application, where we use drone and satellite data to estimate the needs of resources in different regions. We demonstrate how our methods can improve trust and decision accuracy. The computational time grows linearly in the number of data sources and problem sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01428v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanru Guo (Jessie), Bo Zhou (Jessie), Ruiwei Jiang (Jessie),  Xi (Jessie),  Yang, Siqian Shen</dc:creator>
    </item>
    <item>
      <title>Sparsity-promoting Design under Uncertainty for a Char Combustion Process</title>
      <link>https://arxiv.org/abs/2411.01429</link>
      <description>arXiv:2411.01429v1 Announce Type: new 
Abstract: This work presents a design under uncertainty approach for a char combustion process in a limited-data setting, where simulations of the fluid-solid coupled system are computationally expensive. We integrate a polynomial dimensional decomposition (PDD) surrogate model into the design optimization and induce computational efficiency in three key areas. First, we transform the input random variables to have fixed probability measures, which eliminates the need to recalculate the PDD's basis functions associated with these probability quantities. Second, using the limited available data from a physics-based high-fidelity solver, we estimate the PDD coefficients via sparsity-promoting diffeomorphic modulation under observable response preserving homotopy regression. Third, we propose a single-pass surrogate model training process that avoids the need to generate new training data and update the PDD coefficients during the derivative-free optimization process. The results provide insights for optimizing process parameters to ensure consistently high energy production from char combustion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01429v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yulin Guo, Dongjin Lee, Boris Kramer</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Discrete-Time Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2411.01484</link>
      <description>arXiv:2411.01484v1 Announce Type: new 
Abstract: This paper focuses on optimal control problem for a class of discrete-time nonlinear systems. In practical applications, computation time is a crucial consideration in solving optimal control problem, especially when meeting the real-time requirements of control systems. To address this challenge, this study proposes a novel framework based on the optimal control method. Firstly, the original optimal control problem is transformed into an equivalent optimization problem, which is resolved using the Pontryagin's maximum principle from the perspective of optimal control. Furthermore, explicit formulas for computing both the gradient and hessian matrix of the cost function are proposed. A numerical algorithm with rapid convergence and high efficiency is also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01484v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuanzhi Lv, Xunmin Yin, Hongdan Li, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>On the existence of extremal solutions for the conjugate discrete-time Riccati equation</title>
      <link>https://arxiv.org/abs/2411.01546</link>
      <description>arXiv:2411.01546v1 Announce Type: new 
Abstract: In this paper we consider a class of conjugate discrete-time Riccati equations (CDARE), arising originally from the linear quadratic regulation problem for discrete-time antilinear systems. Recently, we have proved the existence of the maximal solution to the CDARE with a nonsingular control weighting matrix under the framework of the constructive method. Our contribution in the work is to finding another meaningful Hermitian solutions, which has received little attention in this topic. Moreover, we show that some extremal solutions cannot be attained at the same time, and almost (anti-)stabilizing solutions coincide with some extremal solutions. It is to be expected that our theoretical results presented in this paper will play an important role in the optimal control problems for discrete-time antilinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01546v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chun-Yueh Chiang</dc:creator>
    </item>
    <item>
      <title>Linear Quadratic Mean Field Games with Quantile-Dependent Cost Coefficients</title>
      <link>https://arxiv.org/abs/2411.01668</link>
      <description>arXiv:2411.01668v1 Announce Type: new 
Abstract: This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population's state distribution through its quantile function. Such a formulation allows for modelling agents that are sensitive to not only the population average but also the population variance. The corresponding mean field game equilibrium is identified, which involves solving two coupled differential equations: one is a Riccati equation and the other the variance evolution equation. Furthermore, the conditions for the existence and uniqueness of the mean field equilibrium are established. Finally, numerical results are presented to illustrate the behavior of two coupled differential equations and the performance of the mean field game solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01668v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Gao, Roland P. Malham\'e</dc:creator>
    </item>
    <item>
      <title>Geometric stabilization of virtual linear nonholonomic constraints</title>
      <link>https://arxiv.org/abs/2411.01692</link>
      <description>arXiv:2411.01692v1 Announce Type: new 
Abstract: In this paper, we give sufficient conditions for and deduce a control law under which a mechanical control system converges exponentially fast to a virtual linear nonholonomic constraint that is control invariant via the same feedback control. Virtual constraints are relations imposed on a control system that become invariant via feedback control, as opposed to physical constraints acting on the system. Virtual nonholonomic constraints, similarly to mechanical nonholonomic constraints, are a class of virtual constraints that depend on velocities rather than only on the configurations of the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01692v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Anahory Simoes, Anthony Bloch, Leonardo Colombo, Efstratios Stratoglou</dc:creator>
    </item>
    <item>
      <title>Joint optimization for production operations considering reworking</title>
      <link>https://arxiv.org/abs/2411.01772</link>
      <description>arXiv:2411.01772v1 Announce Type: new 
Abstract: In pursuit of enhancing the comprehensive efficiency of production systems, our study focused on the joint optimization problem of scheduling and machine maintenance in scenarios where product rework occurs. The primary challenge lies in the interdependence between product \underline{q}uality, machine \underline{r}eliability, and \underline{p}roduction scheduling, compounded by the uncertainties from machine degradation and product quality, which is prevalent in sophisticated manufacturing systems. To address this issue, we investigated the dynamic relationship among these three aspects, named as QRP-co-effect. On this basis, we constructed an optimization model that integrates production scheduling, machine maintenance, and product rework decisions, encompassing the context of stochastic degradation and product quality uncertainties within a mixed-integer programming problem. To effectively solve this problem, we proposed a dual-module solving framework that integrates planning and evaluation for solution improvement via dynamic communication. By analyzing the structural properties of this joint optimization problem, we devised an efficient solving algorithm with an interactive mechanism that leverages \emph{in-situ} condition information regarding the production system's state and computational resources. The proposed methodology has been validated through comparative and ablation experiments. The experimental results demonstrated the significant enhancement of production system efficiency, along with a reduction in machine maintenance costs in scenarios involving rework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01772v1</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilan Shen, Boyang Li, Xi Zhang</dc:creator>
    </item>
    <item>
      <title>A new approach to data assimilation initialization problems with sparse data using multiple cost functions</title>
      <link>https://arxiv.org/abs/2411.01786</link>
      <description>arXiv:2411.01786v1 Announce Type: new 
Abstract: This article develops a novel data assimilation methodology, addressing challenges that are common in real-world settings, such as severe sparsity of observations, lack of reliable models, and non-stationarity of the system dynamics. These challenges often cause identifiability issues and can confound model parameter initialization, both of which can lead to estimated models with unrealistic qualitative dynamics and induce deeper parameter estimation errors. The proposed methodology's objective function is constructed as a sum of components, each serving a different purpose: enforcing point-wise and distribution-wise agreement between data and model output, enforcing agreement of variables and parameters with a model provided, and penalizing unrealistic rapid parameter changes, unless they are due to external drivers or interventions. This methodology was motivated by, developed and evaluated in the context of estimating blood glucose levels in different medical settings. Both simulated and real data are used to evaluate the methodology from different perspectives, such as its ability to estimate unmeasured variables, its ability to reproduce the correct qualitative blood glucose dynamics, how it manages known non-stationarity, and how it performs when given a range of dense and severely sparse data. The results show that a multicomponent cost function can balance the minimization of point-wise errors with global properties, robustly preserving correct qualitative dynamics and managing data sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01786v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David J. Abers, George Hripcsak, Lena Mamykina, Melike Sirlanci, Esteban G. Tabak</dc:creator>
    </item>
    <item>
      <title>$H_2$-Optimal Estimation of a Class of Linear PDE Systems using Partial Integral Equations</title>
      <link>https://arxiv.org/abs/2411.01793</link>
      <description>arXiv:2411.01793v1 Announce Type: new 
Abstract: The $H_2$ norm is a commonly used performance metric in the design of estimators. However, $H_2$-optimal estimation of most PDEs is complicated by the lack of state-space and transfer function representations. To address this problem, we re-characterize the $H_2$-norm in terms of a map from initial condition to output. We then leverage the Partial Integral Equation (PIE) state-space representation of systems of linear PDEs coupled with ODEs to recast this characterization of $H_2$ norm as a convex optimization problem defined in terms of Linear Partial Integral (LPI) inequalities. We then parameterize a class of PIE-based observers and formulate the associated $H_2$-optimal estimation problem. The optimal observer synthesis problem is then recast as an LPI, and the resulting observers are validated using numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01793v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danio Braghini, Sachin Shivakumar, Matthew M. Peet</dc:creator>
    </item>
    <item>
      <title>Gradient Methods with Online Scaling</title>
      <link>https://arxiv.org/abs/2411.01803</link>
      <description>arXiv:2411.01803v1 Announce Type: new 
Abstract: We introduce a framework to accelerate the convergence of gradient-based methods with online learning. The framework learns to scale the gradient at each iteration through an online learning algorithm and provably accelerates gradient-based methods asymptotically. In contrast with previous literature, where convergence is established based on worst-case analysis, our framework provides a strong convergence guarantee with respect to the optimal scaling matrix for the iteration trajectory. For smooth strongly convex optimization, our results provide an $O(\kappa^\star \log(1/\varepsilon)$) complexity result, where $\kappa^\star$ is the condition number achievable by the optimal preconditioner, improving on the previous $O(\sqrt{n}\kappa^\star \log(1/\varepsilon))$ result. In particular, a variant of our method achieves superlinear convergence on convex quadratics. For smooth convex optimization, we show for the first time that the widely-used hypergradient descent heuristic improves on the convergence of gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01803v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Ya-Chi Chu, Yinyu Ye, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>An online optimization algorithm for tracking a linearly varying optimal point with zero steady-state error</title>
      <link>https://arxiv.org/abs/2411.01826</link>
      <description>arXiv:2411.01826v1 Announce Type: new 
Abstract: In this paper, we develop an online optimization algorithm for solving a class of nonconvex optimization problems with a linearly varying optimal point. The global convergence of the algorithm is guaranteed using the circle criterion for the class of functions whose gradient is bounded within a sector. Also, we show that the corresponding Lur\'e-type nonlinear system involves a double integrator, which demonstrates its ability to track a linearly varying optimal point with zero steady-state error. The algorithm is applied to solving a time-of-arrival based localization problem with constant velocity and the results show that the algorithm is able to estimate the source location with zero steady-state error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01826v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator> Alex (Xinting),  Wu, Ian R. Petersen, Valery Ugrinovskii, Iman Shames</dc:creator>
    </item>
    <item>
      <title>New Lagrangian dual algorithms for solving the continuous nonlinear resource allocation problem</title>
      <link>https://arxiv.org/abs/2411.01899</link>
      <description>arXiv:2411.01899v1 Announce Type: new 
Abstract: The continuous nonlinear resource allocation problem has broad applications in various fields such as information and communication, transportation, and finance, and this problem often arises as a subproblem in complex programming. Traditional algorithms, however, typically impose monotonicity assumptions, which limits their applicability. In this paper, we propose two novel Lagrangian dual algorithms that solve this problem without such assumptions. By leveraging the problem's convexity, we update the Lagrange multiplier at each iteration based on the current values of the objective and constraint functions. Additionally, we exploit the separability of the problem, allowing the Lagrangian dual problem to be decomposed into n one-dimensional tractable subproblems, significantly enhancing computational efficiency. We also provide a convergence analysis for the proposed algorithms. Extensive numerical experiments demonstrate that the proposed algorithms consistently achieve optimal solutions and significantly enhance computational efficiency, outperforming existing state-of-the-art methods by at least two orders of magnitude in most test problems, particularly in non-quadratic programming problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01899v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixiang Hu, Caixia Kou</dc:creator>
    </item>
    <item>
      <title>Robust stochastic optimization via regularized PHA: application to Energy Management Systems</title>
      <link>https://arxiv.org/abs/2411.02015</link>
      <description>arXiv:2411.02015v1 Announce Type: new 
Abstract: This paper deals with robust stochastic optimal control problems. The main contribution is an extension of the Progressive Hedging Algorithm (PHA) that enhances outof-sample robustness while preserving numerical complexity. This extension consists of taking up the widespread practice in machine learning of variance penalization into stochastic optimal control problems. Using the Douglas-Rachford splitting method, the author developed a Regularized Progressive Hedging Algorithm (RPHA) with the same numerical complexity as the standard PHA and better out-of-sample performances. In addition, the authors propose a three-step control framework consisting of a random scenario generation method, followed by a scenario reduction algorithm, and a scenario-based optimal control computation using the RPHA. Finally, the authors test the proposed method to simulate a stationary battery's Energy Management System (EMS) using ground truth measurements of electricity consumption and production from a mainly commercial building in Solaize, France. This simulation shows that the proposed method is more efficient than a classical Model Predictive Control (MPC) strategy, which is, in turn, more efficient than the standard PHA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02015v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Malisani (IFPEN), Adrien Spagnol (IFPEN), Vivien Smis-Michel (IFPEN)</dc:creator>
    </item>
    <item>
      <title>Spurious local minima in nonconvex sum-of-squares optimization</title>
      <link>https://arxiv.org/abs/2411.02208</link>
      <description>arXiv:2411.02208v1 Announce Type: new 
Abstract: We study spurious second-order stationary points and local minima in a nonconvex low-rank formulation of sum-of-squares optimization on a real variety $X$. We reformulate the problem of finding a spurious local minimum in terms of syzygies of the underlying linear series, and also bring in topological tools to study this problem. When the variety $X$ is of minimal degree, there exist spurious second-order stationary points if and only if both the dimension and the codimension of the variety are greater than one, answering a question by Legat, Yuan, and Parrilo. Moreover, for surfaces of minimal degree, we provide sufficient conditions to exclude points from being spurious local minima. In particular, all second-order stationary points associated with infinite Gram matrices on the Veronese surface, corresponding to ternary quartics, lie on the boundary and can be written as a binary quartic, up to a linear change of coordinates, complementing work by Scheiderer on decompositions of ternary quartics as a sum of three squares. For general varieties of higher degree, we give examples and characterizations of spurious second-order stationary points in the interior, together with a restricted path algorithm that avoids such points with controlled step sizes, and numerical experiment results illustrating the empirical successes on plane cubic curves and Veronese varieties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02208v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigoriy Blekherman, Rainer Sinn, Mauricio Velasco, Shixuan Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control of an Industrial Power-to-Heat System with High-Temperature Heat Pump and Thermal Energy Storage</title>
      <link>https://arxiv.org/abs/2411.02211</link>
      <description>arXiv:2411.02211v1 Announce Type: new 
Abstract: The optimal control of sustainable energy supply systems, including renewable energies and energy storages, takes a central role in the decarbonization of industrial systems. However, the use of fluctuating renewable energies leads to fluctuations in energy generation and requires a suitable control strategy for the complex systems in order to ensure energy supply. In this paper, we consider an electrified power-to-heat system which is designed to supply heat in form of superheated steam for industrial processes. The system consists of a high-temperature heat pump for heat supply, a wind turbine (WT) for power generation, a sensible thermal energy storage (TES) for storing excess heat and a steam generator for providing steam. If the system's energy demand cannot be covered by electricity from the WT, additional electricity must be purchased from the power grid. For this system, we investigate the cost-optimal operation aiming to minimize the electricity cost from the grid by a suitable system control depending on the available wind power and the amount of energy stored in the TES. This is a decision making problem under uncertainties about the future prices for electricity from the grid and the future generation of wind power. The resulting stochastic optimal control problem is treated as finite horizon Markov decision process (MDP) for a multi-dimensional controlled state process. We first consider the classical backward recursion techniques for solving the associated dynamic programming equation for the value function and compute the optimal decision rule. Since that approach suffers from the curse of dimensionality we also apply Q-learning techniques that are able to provide a good approximate solution to the MDP within a reasonable time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02211v1</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Pilling, Martin B\"ahr, Ralf Wunderlich</dc:creator>
    </item>
    <item>
      <title>Novel operational algorithms for ride-pooling as on-demand feeder services</title>
      <link>https://arxiv.org/abs/2411.00787</link>
      <description>arXiv:2411.00787v1 Announce Type: cross 
Abstract: Ride-pooling (RP) service, as a form of shared mobility, enables multiple riders with similar itineraries to share the same vehicle and split the fee. This makes RP a promising on-demand feeder service for patrons with a common trip end in urban transportation. We propose the RP as Feeder (RPaF) services with tailored operational algorithms. Specifically, we have developed (i) a batch-based matching algorithm that pools a batch of requests within an optimized buffer distance to each RP vehicle; (ii) a dispatching algorithm that adaptively dispatches vehicles to pick up the matched requests for certain occupancy target; and (iii) a repositioning algorithm that relocates vehicles to unmatched requests based on their level of urgency. An agent-based microscopic simulation platform is designed to execute these operational algorithms (via the Operator module), generate spatially distributed random requests (Patron module), and account for traffic conditions (Vehicle module) in street networks. Extensive numerical experiments are conducted to showcase the effectiveness of RPaF services across various demand scenarios in typical morning rush hours. We compare RFaF with two on-demand feeder counterparts proposed in previous studies: Ride-Sharing as Feeder (RSaF) and Flexible-Route Feeder-Bus Transit (Flex-FBT). Comparisons reveal that given the same fleet size, RPaF generally outperforms RSaF in higher service rates (i.e., the percentage of requests served over all requests) and Flex-FBT in shorter average trip times for patrons. Lastly, we illustrate the implementation of RPaF in a real-world case study of the uptown Manhattan network (USA) using actual taxi trip data. The results demonstrate that RPaF effectively balances the level of service (service rate and patrons' average trip time) with operational costs (fleet size).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00787v1</guid>
      <category>cs.NI</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenbo Fan, Xiaotian Yan, Zhanbo Sun, Xiaohui Yang</dc:creator>
    </item>
    <item>
      <title>CRONOS: Enhancing Deep Learning with Scalable GPU Accelerated Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2411.01088</link>
      <description>arXiv:2411.01088v1 Announce Type: cross 
Abstract: We introduce the CRONOS algorithm for convex optimization of two-layer neural networks. CRONOS is the first algorithm capable of scaling to high-dimensional datasets such as ImageNet, which are ubiquitous in modern deep learning. This significantly improves upon prior work, which has been restricted to downsampled versions of MNIST and CIFAR-10. Taking CRONOS as a primitive, we then develop a new algorithm called CRONOS-AM, which combines CRONOS with alternating minimization, to obtain an algorithm capable of training multi-layer networks with arbitrary architectures. Our theoretical analysis proves that CRONOS converges to the global minimum of the convex reformulation under mild assumptions. In addition, we validate the efficacy of CRONOS and CRONOS-AM through extensive large-scale numerical experiments with GPU acceleration in JAX. Our results show that CRONOS-AM can obtain comparable or better validation accuracy than predominant tuned deep learning optimizers on vision and language tasks with benchmark datasets such as ImageNet and IMDb. To the best of our knowledge, CRONOS is the first algorithm which utilizes the convex reformulation to enhance performance on large-scale learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01088v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Miria Feng, Zachary Frangella, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Regret of exploratory policy improvement and $q$-learning</title>
      <link>https://arxiv.org/abs/2411.01302</link>
      <description>arXiv:2411.01302v1 Announce Type: cross 
Abstract: We study the convergence of $q$-learning and related algorithms introduced by Jia and Zhou (J. Mach. Learn. Res., 24 (2023), 161) for controlled diffusion processes. Under suitable conditions on the growth and regularity of the model parameters, we provide a quantitative error and regret analysis of both the exploratory policy improvement algorithm and the $q$-learning algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01302v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenpin Tang, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Differentiable Quantum Computing for Large-scale Linear Control</title>
      <link>https://arxiv.org/abs/2411.01391</link>
      <description>arXiv:2411.01391v1 Announce Type: cross 
Abstract: As industrial models and designs grow increasingly complex, the demand for optimal control of large-scale dynamical systems has significantly increased. However, traditional methods for optimal control incur significant overhead as problem dimensions grow. In this paper, we introduce an end-to-end quantum algorithm for linear-quadratic control with provable speedups. Our algorithm, based on a policy gradient method, incorporates a novel quantum subroutine for solving the matrix Lyapunov equation. Specifically, we build a quantum-assisted differentiable simulator for efficient gradient estimation that is more accurate and robust than classical methods relying on stochastic approximation. Compared to the classical approaches, our method achieves a super-quadratic speedup. To the best of our knowledge, this is the first end-to-end quantum application to linear control problems with provable quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01391v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Clayton, Jiaqi Leng, Gengzhi Yang, Yi-Ling Qiao, Ming C. Lin, Xiaodi Wu</dc:creator>
    </item>
    <item>
      <title>A New Error Analysis for Finite Element Methods for Elliptic Neumann Boundary Control Problems with Pointwise Control Constraints</title>
      <link>https://arxiv.org/abs/2411.01550</link>
      <description>arXiv:2411.01550v1 Announce Type: cross 
Abstract: We present a new error analysis for finite element methods for a linear-quadratic elliptic optimal control problem with Neumann boundary control and pointwise control constraints. It can be applied to standard finite element methods when the coefficient s in the elliptic operator are smooth and also to multiscale finite element methods when the coefficients are rough.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01550v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Susanne C. Brenner, Li-yeng Sung</dc:creator>
    </item>
    <item>
      <title>Denoising Diffusions with Optimal Transport: Localization, Curvature, and Multi-Scale Complexity</title>
      <link>https://arxiv.org/abs/2411.01629</link>
      <description>arXiv:2411.01629v1 Announce Type: cross 
Abstract: Adding noise is easy; what about denoising? Diffusion is easy; what about reverting a diffusion? Diffusion-based generative models aim to denoise a Langevin diffusion chain, moving from a log-concave equilibrium measure $\nu$, say isotropic Gaussian, back to a complex, possibly non-log-concave initial measure $\mu$. The score function performs denoising, going backward in time, predicting the conditional mean of the past location given the current. We show that score denoising is the optimal backward map in transportation cost. What is its localization uncertainty? We show that the curvature function determines this localization uncertainty, measured as the conditional variance of the past location given the current. We study in this paper the effectiveness of the diffuse-then-denoise process: the contraction of the forward diffusion chain, offset by the possible expansion of the backward denoising chain, governs the denoising difficulty. For any initial measure $\mu$, we prove that this offset net contraction at time $t$ is characterized by the curvature complexity of a smoothed $\mu$ at a specific signal-to-noise ratio (SNR) scale $r(t)$. We discover that the multi-scale curvature complexity collectively determines the difficulty of the denoising chain. Our multi-scale complexity quantifies a fine-grained notion of average-case curvature instead of the worst-case. Curiously, it depends on an integrated tail function, measuring the relative mass of locations with positive curvature versus those with negative curvature; denoising at a specific SNR scale is easy if such an integrated tail is light. We conclude with several non-log-concave examples to demonstrate how the multi-scale complexity probes the bottleneck SNR for the diffuse-then-denoise process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01629v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tengyuan Liang, Kulunu Dharmakeerthi, Takuya Koriyama</dc:creator>
    </item>
    <item>
      <title>Risk-sensitive control as inference with R\'enyi divergence</title>
      <link>https://arxiv.org/abs/2411.01827</link>
      <description>arXiv:2411.01827v1 Announce Type: cross 
Abstract: This paper introduces the risk-sensitive control as inference (RCaI) that extends CaI by using R\'{e}nyi divergence variational inference. RCaI is shown to be equivalent to log-probability regularized risk-sensitive control, which is an extension of the maximum entropy (MaxEnt) control. We also prove that the risk-sensitive optimal policy can be obtained by solving a soft Bellman equation, which reveals several equivalences between RCaI, MaxEnt control, the optimal posterior for CaI, and linearly-solvable control. Moreover, based on RCaI, we derive the risk-sensitive reinforcement learning (RL) methods: the policy gradient and the soft actor-critic. As the risk-sensitivity parameter vanishes, we recover the risk-neutral CaI and RL, which means that RCaI is a unifying framework. Furthermore, we give another risk-sensitive generalization of the MaxEnt control using R\'{e}nyi entropy regularization. We show that in both of our extensions, the optimal policies have the same structure even though the derivations are very different.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01827v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaito Ito, Kenji Kashima</dc:creator>
    </item>
    <item>
      <title>Global controllability of Boussinesq channel flows only through the temperature</title>
      <link>https://arxiv.org/abs/2411.02200</link>
      <description>arXiv:2411.02200v1 Announce Type: cross 
Abstract: We show the global approximate controllability of the Boussinesq system with viscosity and diffusion in a planar periodic channel by using only a temperature control supported in a thin strip. At the walls, a slip boundary condition is chosen for the fluid and the normal derivative of the temperature is assumed to vanish. This contributes a first global controllability result of such type for the Boussinesq system in the presence of non-periodic boundary conditions. We resort to a small-time scaling argument to control the vorticity through a large initial temperature. Moreover, relying on the special choice of the domain, we employ J.-M. Coron's return method in order to steer the temperature without significantly impacting the vorticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02200v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Rissel</dc:creator>
    </item>
    <item>
      <title>Towards safe Bayesian optimization with Wiener kernel regression</title>
      <link>https://arxiv.org/abs/2411.02253</link>
      <description>arXiv:2411.02253v1 Announce Type: cross 
Abstract: Bayesian Optimization (BO) is a data-driven strategy for minimizing/maximizing black-box functions based on probabilistic surrogate models. In the presence of safety constraints, the performance of BO crucially relies on tight probabilistic error bounds related to the uncertainty surrounding the surrogate model. For the case of Gaussian Process surrogates and Gaussian measurement noise, we present a novel error bound based on the recently proposed Wiener kernel regression. We prove that under rather mild assumptions, the proposed error bound is tighter than bounds previously documented in the literature which leads to enlarged safety regions. We draw upon a numerical example to demonstrate the efficacy of the proposed error bound in safe BO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02253v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oleksii Molodchyk, Johannes Teutsch, Timm Faulwasser</dc:creator>
    </item>
    <item>
      <title>Optimal consumption under a drawdown constraint over a finite horizon</title>
      <link>https://arxiv.org/abs/2207.07848</link>
      <description>arXiv:2207.07848v2 Announce Type: replace 
Abstract: This paper studies a finite horizon utility maximization problem on excessive consumption under a drawdown constraint. Our control problem is an extension of the one considered in Bahman et al. (2019) to the model with a finite horizon and an extension of the one considered in Jeon and Oh (2022) to the model with zero interest rate. Contrary to Bahman et al. (2019), we encounter a parabolic nonlinear HJB variational inequality with a gradient constraint, in which some time-dependent free boundaries complicate the analysis significantly. Meanwhile, our methodology is built on technical PDE arguments, which differs from the martingale approach in Jeon and Oh (2022). Using the dual transform and considering the auxiliary variational inequality with gradient and function constraints, we establish the existence and uniqueness of the classical solution to the HJB variational inequality after the dimension reduction, and the associated free boundaries can be characterized in analytical form. Consequently, the piecewise optimal feedback controls and the time-dependent thresholds for the ratio of wealth and historical consumption peak can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.07848v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoshan Chen, Xun Li, Fahuai Yi, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Mean Field Games with Major and Minor Agents: the Limiting Problem and Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2210.12660</link>
      <description>arXiv:2210.12660v2 Announce Type: replace 
Abstract: In this paper, we consider a mean field game (MFG) with a major and $N$ minor agents. We first consider the limiting problem and allow the coefficients to vary with the conditional distribution in a nonlinear way. We use the stochastic maximum principle to transform the limiting control problem into a system of two coupled conditional distribution dependent forward-backward stochastic differential equations (FBSDEs), and prove the existence and uniqueness result of the FBSDEs when the dependence between major agent and minor agents is sufficiently weak. We then use the solution of the limiting problem to construct an $\mathcal{O}(N^{-\frac{1}{2}})$-Nash equilibrium for the MFG with a major and $N$ minor agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12660v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyu Huang, Shanjian Tang</dc:creator>
    </item>
    <item>
      <title>Policy Iteration Reinforcement Learning Method for Continuous-Time Linear-Quadratic Mean-Field Control Problems</title>
      <link>https://arxiv.org/abs/2305.00424</link>
      <description>arXiv:2305.00424v3 Announce Type: replace 
Abstract: This paper employs a policy iteration reinforcement learning (RL) method to study continuous-time linear-quadratic mean-field control problems in infinite horizon. The drift and diffusion terms in the dynamics involve the states, the controls, and their conditional expectations. We investigate the stabilizability and convergence of the RL algorithm using a Lyapunov Recursion. Instead of solving a pair of coupled Riccati equations, the RL technique focuses on strengthening an auxiliary function and the cost functional as the objective functions and updating the new policy to compute the optimal control via state trajectories. A numerical example sheds light on the established theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00424v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Na Li, Xun Li, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Optimal Control of McKean-Vlasov equations with controlled stochasticity</title>
      <link>https://arxiv.org/abs/2305.09379</link>
      <description>arXiv:2305.09379v3 Announce Type: replace 
Abstract: In this article, we analyse the existence of an optimal feedback controller of stochastic optimal control problems governed by SDEs which have the control in the diffusion part. To this end, we consider the underlying Fokker-Planck equation to transform the stochastic optimal control problem into a deterministic problem with open-loop controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09379v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3934/eect.2024058</arxiv:DOI>
      <dc:creator>Luca Di Persio, Peter Kuchling</dc:creator>
    </item>
    <item>
      <title>Symplectic Discretization Approach for Developing New Proximal Point Algorithm</title>
      <link>https://arxiv.org/abs/2308.03986</link>
      <description>arXiv:2308.03986v4 Announce Type: replace 
Abstract: The rapid advancements in high-dimensional statistics and machine learning have increased the use of first-order methods. Many of these methods can be regarded as instances of the proximal point algorithm. Given the importance of the proximal point algorithm, there has been growing interest in developing its accelerated variants. However, some existing accelerated proximal point algorithms exhibit oscillatory behavior, which can impede their numerical convergence rate. In this paper, we first introduce an ODE system and demonstrate its \( o(1/t^2) \) convergence rate and weak convergence property. Next, we apply the Symplectic Euler Method to discretize the ODE and obtain a new accelerated proximal point algorithm, which we call the Symplectic Proximal Point Algorithm. The reason for using the Symplectic Euler Method is its ability to preserve the geometric structure of the ODEs. Theoretically, we demonstrate that the Symplectic Proximal Point Algorithm achieves an \( o(1/k^2) \) convergence rate and that the sequences generated by our method converge weakly to the solution set. Practically, our numerical experiments illustrate that the Symplectic Proximal Point Algorithm significantly reduces oscillatory behavior, leading to improved long-time behavior and faster numerical convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03986v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-xiang Yuan, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>Deep Learning for Two-Stage Robust Integer Optimization</title>
      <link>https://arxiv.org/abs/2310.04345</link>
      <description>arXiv:2310.04345v3 Announce Type: replace 
Abstract: Robust optimization is an established framework for modeling optimization problems with uncertain parameters. While static robust optimization is often criticized for being too conservative, two-stage (or adjustable) robust optimization (2RO) provides a less conservative alternative by allowing some decisions to be made after the uncertain parameters have been revealed. Unfortunately, in the case of integer decision variables, existing solution methods for 2RO typically fail to solve large-scale instances, limiting the applicability of this modeling paradigm to simple cases. We propose Neur2RO, a deep-learning-augmented instantiation of the column-and-constraint-generation (CCG) algorithm, which expands the applicability of the 2RO framework to large-scale instances with integer decisions in both stages. A custom-designed neural network is trained to estimate the optimal value and feasibility of the second-stage problem. The network can be incorporated into CCG, leading to more computationally tractable subproblems in each of its iterations. The resulting algorithm enjoys approximation guarantees which depend on the neural network's prediction error. In our experiments, Neur2RO produces high-quality solutions quickly, outperforming state-of-the-art methods on two-stage knapsack, capital budgeting, and facility location problems. Compared to existing methods, which often run for hours, Neur2RO finds better solutions in a few seconds or minutes. Our code is available at https://github.com/khalil-research/Neur2RO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04345v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Dumouchelle, Esther Julien, Jannis Kurtz, Elias B. Khalil</dc:creator>
    </item>
    <item>
      <title>A Stochastic Non-Zero-Sum Game of Controlling the Debt-to-GDP Ratio</title>
      <link>https://arxiv.org/abs/2311.17711</link>
      <description>arXiv:2311.17711v2 Announce Type: replace 
Abstract: We introduce a non-zero-sum game between a government and a legislative body to study the optimal level of debt. Each player, with different time preferences, can intervene on the stochastic dynamics of the debt-to-GDP ratio via singular stochastic controls, in view of minimizing non-continuously differentiable running costs. We completely characterise Nash equilibria in the class of Skorokhod-reflection-type policies. We highlight the importance of different time preferences resulting in qualitatively different type of equilibria. In particular, we show that, while it is always optimal for the government to devise an appropriate debt issuance policy, the legislator should optimally impose a debt ceiling only under relatively low discount rates and a laissez-faire policy can be optimal for high values of the legislator's discount rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17711v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Dammann, Neofytos Rodosthenous, St\'ephane Villeneuve</dc:creator>
    </item>
    <item>
      <title>Penalty-based Methods for Simple Bilevel Optimization under H\"{o}lderian Error Bounds</title>
      <link>https://arxiv.org/abs/2402.02155</link>
      <description>arXiv:2402.02155v2 Announce Type: replace 
Abstract: This paper investigates simple bilevel optimization problems where we minimize an upper-level objective over the optimal solution set of a convex lower-level objective. Existing methods for such problems either only guarantee asymptotic convergence, have slow sublinear rates, or require strong assumptions. To address these challenges, we propose a penalization framework that delineates the relationship between approximate solutions of the original problem and its reformulated counterparts. This framework accommodates varying assumptions regarding smoothness and convexity, enabling the application of specific methods with different complexity results. Specifically, when both upper- and lower-level objectives are composite convex functions, under an $\alpha$-H{\"o}lderian error bound condition and certain mild assumptions, our algorithm attains an $(\epsilon,\epsilon^{\beta})$-optimal solution of the original problem for any $\beta&gt; 0$ within $\mathcal{O}\left(\sqrt{{1}/{\epsilon^{\max\{\alpha,\beta\}}}}\right)$ iterations. The result can be improved further if the smooth part of the upper-level objective is strongly convex. We also establish complexity results when the upper- and lower-level objectives are general nonsmooth functions. Numerical experiments demonstrate the effectiveness of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02155v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengyu Chen, Xu Shi, Rujun Jiang, Jiulin Wang</dc:creator>
    </item>
    <item>
      <title>A Framework for Bilevel Optimization on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2402.03883</link>
      <description>arXiv:2402.03883v2 Announce Type: replace 
Abstract: Bilevel optimization has gained prominence in various applications. In this study, we introduce a framework for solving bilevel optimization problems, where the variables in both the lower and upper levels are constrained on Riemannian manifolds. We present several hypergradient estimation strategies on manifolds and analyze their estimation errors. Furthermore, we provide comprehensive convergence and complexity analyses for the proposed hypergradient descent algorithm on manifolds. We also extend our framework to encompass stochastic bilevel optimization and incorporate the use of general retraction. The efficacy of the proposed framework is demonstrated through several applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03883v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andi Han, Bamdev Mishra, Pratik Jawanpuria, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Shadowheart SGD: Distributed Asynchronous SGD with Optimal Time Complexity Under Arbitrary Computation and Communication Heterogeneity</title>
      <link>https://arxiv.org/abs/2402.04785</link>
      <description>arXiv:2402.04785v2 Announce Type: replace 
Abstract: We consider nonconvex stochastic optimization problems in the asynchronous centralized distributed setup where the communication times from workers to a server can not be ignored, and the computation and communication times are potentially different for all workers. Using an unbiassed compression technique, we develop a new method-Shadowheart SGD-that provably improves the time complexities of all previous centralized methods. Moreover, we show that the time complexity of Shadowheart SGD is optimal in the family of centralized methods with compressed communication. We also consider the bidirectional setup, where broadcasting from the server to the workers is non-negligible, and develop a corresponding method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04785v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Marta Pozzi, Ivan Ilin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity</title>
      <link>https://arxiv.org/abs/2402.06412</link>
      <description>arXiv:2402.06412v2 Announce Type: replace 
Abstract: Effective communication between the server and workers plays a key role in distributed optimization. In this paper, we focus on optimizing the server-to-worker communication, uncovering inefficiencies in prevalent downlink compression approaches. Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors. Theoretical analyses demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms. We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression. We introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number of workers increases. Theoretical findings align closely with empirical experiments, underscoring the efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06412v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaja Gruntkowska, Alexander Tyurin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>A note on stationarity in constrained optimization</title>
      <link>https://arxiv.org/abs/2402.09831</link>
      <description>arXiv:2402.09831v2 Announce Type: replace 
Abstract: Minimizing a smooth function f on a closed subset C leads to different notions of stationarity: Fr{\'e}chet stationarity, which carries a strong variational meaning, and criticality, which is defined through a closure process and involves the notion of limiting, or Mordukovitch, subdifferential. The latter is an optimality condition which may loose the variational meaning of Fr{\'e}chet stationarity in some settings. The purpose of this note is to illustrate that, while criticality is the appropriate notion in full generality, Fr{\'e}chet stationarity is typical in practical scenarios.We gather two results to illustrate this phenomenon. These results are essentially known and, our goal is to provide consize self contained arguments in the constrained optimization setting. First we show that if C is semi-algebraic, then for a generic smooth semi-algebraic function f , all critical points of f on C are actually Fr{\'e}chet stationary. Second we prove that for small step-sizes, all the accumulation points of the projected gradient algorithm are Fr{\'e}chet stationary, with an explicit global quadratic estimate of the remainder, avoiding potential critical points that are not Fr{\'e}chet stationary, and some bad local minima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09831v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edouard Pauwels (TSE-R)</dc:creator>
    </item>
    <item>
      <title>An SDP-based Branch-and-Cut Algorithm for Biclustering</title>
      <link>https://arxiv.org/abs/2403.11351</link>
      <description>arXiv:2403.11351v2 Announce Type: replace 
Abstract: Biclustering, also called co-clustering, block clustering, or two-way clustering, involves the simultaneous clustering of both the rows and columns of a data matrix into distinct groups, such that the rows and columns within a group display similar patterns. As a model problem for biclustering, we consider the $k$-densest-disjoint biclique problem, whose goal is to identify $k$ disjoint complete bipartite subgraphs (called bicliques) of a given weighted complete bipartite graph such that the sum of their densities is maximized. To address this problem, we present a tailored branch-and-cut algorithm. For the upper bound routine, we consider a semidefinite programming relaxation and propose valid inequalities to strengthen the bound. We solve this relaxation in a cutting-plane fashion using a first-order method. For the lower bound, we design a maximum weight matching rounding procedure that exploits the solution of the relaxation solved at each node. Computational results on both synthetic and real-world instances show that the proposed algorithm can solve instances approximately 20 times larger than those handled by general-purpose solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11351v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio M. Sudoso</dc:creator>
    </item>
    <item>
      <title>Optimization on a Finer Scale: Bounded Local Subgradient Variation Perspective</title>
      <link>https://arxiv.org/abs/2403.16317</link>
      <description>arXiv:2403.16317v2 Announce Type: replace 
Abstract: We initiate the study of nonsmooth optimization problems under bounded local subgradient variation, which postulates bounded difference between (sub)gradients in small local regions around points, in either average or maximum sense. The resulting class of objective functions encapsulates the classes of objective functions traditionally studied in optimization, which are defined based on either Lipschitz continuity of the objective or H\"{o}lder/Lipschitz continuity of its gradient. Further, the defined class contains functions that are neither Lipschitz continuous nor have a H\"{o}lder continuous gradient. When restricted to the traditional classes of optimization problems, the parameters defining the studied classes lead to more fine-grained complexity bounds, recovering traditional oracle complexity bounds in the worst case but generally leading to lower oracle complexity for functions that are not ``worst case.'' Some highlights of our results are that: (i) it is possible to obtain complexity results for both convex and nonconvex problems with the (local or global) Lipschitz constant being replaced by a constant of local subgradient variation and (ii) mean width of the subdifferential set around the optima plays a role in the complexity of nonsmooth optimization, particularly in parallel settings. A consequence of (ii) is that for any error parameter $\epsilon &gt; 0$, parallel oracle complexity of nonsmooth Lipschitz convex optimization is lower than its sequential oracle complexity by a factor $\tilde{\Omega}\big(\frac{1}{\epsilon}\big)$ whenever the objective function is piecewise linear with polynomially many pieces in the input size. This is particularly surprising as existing parallel complexity lower bounds are based on such classes of functions. The seeming contradiction is resolved by considering the region in which the algorithm is allowed to query the objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16317v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jelena Diakonikolas, Crist\'obal Guzm\'an</dc:creator>
    </item>
    <item>
      <title>Stabilization of a Class of Large-Scale Systems of Linear Hyperbolic PDEs via Continuum Approximation of Exact Backstepping Kernels</title>
      <link>https://arxiv.org/abs/2403.19455</link>
      <description>arXiv:2403.19455v2 Announce Type: replace 
Abstract: We establish that stabilization of a class of linear, hyperbolic partial differential equations (PDEs) with a large (nevertheless finite) number of components, can be achieved via employment of a backstepping-based control law, which is constructed for stabilization of a continuum version (i.e., as the number of components tends to infinity) of the PDE system. This is achieved by proving that the exact backstepping kernels, constructed for stabilization of the large-scale system, can be approximated (in certain sense such that exponential stability is preserved) by the backstepping kernels constructed for stabilization of a continuum version (essentially an infinite ensemble) of the original PDE system. The proof relies on construction of a convergent sequence of backstepping kernels that is defined such that each kernel matches the exact backstepping kernels (derived based on the original, large-scale system), in a piecewise constant manner with respect to an ensemble variable; while showing that they satisfy the continuum backstepping kernel equations. We present a numerical example that reveals that complexity of computation of stabilizing backstepping kernels may not scale with the number of components of the PDE state, when the kernels are constructed on the basis of the continuum version, in contrast to the case in which they are constructed on the basis of the original, large-scale system. In addition, we formally establish the connection between the solutions to the large-scale system and its continuum counterpart. Thus, this approach can be useful for design of computationally tractable, stabilizing backstepping-based control laws for large-scale PDE systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19455v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis</dc:creator>
    </item>
    <item>
      <title>QuITO v.2: Trajectory Optimization with Uniform Error Guarantees under Path Constraints</title>
      <link>https://arxiv.org/abs/2404.13681</link>
      <description>arXiv:2404.13681v2 Announce Type: replace 
Abstract: This article introduces a new transcription, change point localization, and mesh refinement scheme for direct optimization-based solutions and for uniform approximation of optimal control trajectories associated with a class of nonlinear constrained optimal control problems (OCPs). The base transcription algorithm for which we establish the refinement algorithm is a direct multiple shooting technique -- QuITO v.2 (Quasi-Interpolation based Trajectory Optimization). The mesh refinement technique consists of two steps -- localization of certain irregular regions in an optimal control trajectory via wavelets, followed by a targeted $h$-refinement approach around such regions of irregularity. Theoretical approximation guarantees on uniform grids are presented for optimal controls with certain regularity properties, along with guarantees of localization of change points by wavelet transform. Numerical illustrations are provided for control profiles involving discontinuities to show the effectiveness of the localization and refinement strategy. We also announce, and make freely available, a new software package based on QuITO v.2 along with all its functionalities for completeness. The package is available at: https://github.com/chatterjee-d/QuITOv2.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13681v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Ganguly, Rihan Aaron D'Silva, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Minimax problems for ensembles of control-affine systems</title>
      <link>https://arxiv.org/abs/2405.05782</link>
      <description>arXiv:2405.05782v5 Announce Type: replace 
Abstract: In this paper, we consider ensembles of control-affine systems in $\mathbb{R}^d$, and we study simultaneous optimal control problems related to the worst-case minimization. After proving that such problems admit solutions, denoting with $(\Theta^N)_N$ a sequence of compact sets that parametrize the ensembles of systems, we first show that the corresponding minimax optimal control problems are $\Gamma$-convergent whenever $(\Theta^N)_N$ has a limit with respect to the Hausdorff distance. Besides its independent interest, the previous result plays a crucial role for establishing the Pontryagin Maximum Principle (PMP) when the ensemble is parametrized by a set $\Theta$ consisting of infinitely many points. Namely, we first approximate $\Theta$ by finite and increasing-in-size sets $(\Theta^N)_N$ for which the PMP is known, and then we derive the PMP for the $\Gamma$-limiting problem. The same strategy can be pursued in applications, where we can reduce infinite ensembles to finite ones to compute the minimizers numerically. We bring as a numerical example the Schr\"odinger equation for a qubit with uncertain resonance frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05782v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>Freya PAGE: First Optimal Time Complexity for Large-Scale Nonconvex Finite-Sum Optimization with Heterogeneous Asynchronous Computations</title>
      <link>https://arxiv.org/abs/2405.15545</link>
      <description>arXiv:2405.15545v2 Announce Type: replace 
Abstract: In practical distributed systems, workers are typically not homogeneous, and due to differences in hardware configurations and network conditions, can have highly varying processing times. We consider smooth nonconvex finite-sum (empirical risk minimization) problems in this setup and introduce a new parallel method, Freya PAGE, designed to handle arbitrarily heterogeneous and asynchronous computations. By being robust to "stragglers" and adaptively ignoring slow computations, Freya PAGE offers significantly improved time complexity guarantees compared to all previous methods, including Asynchronous SGD, Rennala SGD, SPIDER, and PAGE, while requiring weaker assumptions. The algorithm relies on novel generic stochastic gradient collection strategies with theoretical guarantees that can be of interest on their own, and may be used in the design of future optimization methods. Furthermore, we establish a lower bound for smooth nonconvex finite-sum problems in the asynchronous setup, providing a fundamental time complexity limit. This lower bound is tight and demonstrates the optimality of Freya PAGE in the large-scale regime, i.e., when $\sqrt{m} \geq n$, where $n$ is # of workers, and $m$ is # of data samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15545v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Kaja Gruntkowska, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>On the Optimal Time Complexities in Decentralized Stochastic Asynchronous Optimization</title>
      <link>https://arxiv.org/abs/2405.16218</link>
      <description>arXiv:2405.16218v2 Announce Type: replace 
Abstract: We consider the decentralized stochastic asynchronous optimization setup, where many workers asynchronously calculate stochastic gradients and asynchronously communicate with each other using edges in a multigraph. For both homogeneous and heterogeneous setups, we prove new time complexity lower bounds under the assumption that computation and communication speeds are bounded. We develop a new nearly optimal method, Fragile SGD, and a new optimal method, Amelie SGD, that converge under arbitrary heterogeneous computation and communication speeds and match our lower bounds (up to a logarithmic factor in the homogeneous setting). Our time complexities are new, nearly optimal, and provably improve all previous asynchronous/synchronous stochastic methods in the decentralized setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16218v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>PSAHARA Utility Family: Modeling Non-monotone Risk Aversion and Convex Compensation in Incomplete Markets</title>
      <link>https://arxiv.org/abs/2406.00435</link>
      <description>arXiv:2406.00435v2 Announce Type: replace 
Abstract: In hedge funds, convex compensation schemes are adopted to stimulate a high-profit performance for portfolio managers. In economics, non-monotone risk aversion is proposed to argue that individuals may not be risk-averse when the wealth level is low. Combining these two ingredients, we study the optimal control strategy of the manager in incomplete markets. Generally, we propose a wide family of utility functions, the piecewise symmetric asymptotic hyperbolic absolute risk aversion (PSAHARA) utility, to model the two ingredients, containing both non-concavity and non-differentiability as some abnormalities. Technically, we propose an additional assumption and prove concavification techniques of non--concave utility functions with a left unbounded domain in incomplete markets. Next, we derive an explicit optimal control for the family of PSAHARA utilities. This control is expressed into a unified four-term structure, featuring the asymptotic Merton term. Furthermore, we provide a detailed asymptotic analysis and numerical illustration of the optimal portfolio. We obtain several key insights, including that the convex compensation still induces a great risk-taking behavior in the case that the preference is modeled by SAHARA utility. Finally, we conduct a real-data analysis of the U.S. stock market under the above model and conclude that the PSAHARA portfolio is very risk-seeking and leads to a high return and a high volatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00435v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Liu, Zhenyu Shen</dc:creator>
    </item>
    <item>
      <title>Robust nonlinear state-feedback control of second-order systems</title>
      <link>https://arxiv.org/abs/2406.14000</link>
      <description>arXiv:2406.14000v2 Announce Type: replace 
Abstract: This note proposes a novel nonlinear state feedback controller for perturbed second-order systems. In analogy to a linear proportional-derivative (PD) feedback control, the proposed nonlinear scheme uses the output state of interest and its time derivative, while achieving robust control in a finite time. The control has only one free design parameter, and the closed-loop system is shown to be uniformly asymptotically stable in the presence of matched disturbances. We derive a strict Lyapunov function for the closed-loop control system with a bounded exogenous perturbation, and use it for both the control parameter tuning and analysis of the finite-time convergence. Apart from the numerical results, a revealing experimental example is also shown in favor of the proposed control and in comparison with PD and sub-optimal nonlinear damping regulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14000v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>A global optimum-informed greedy algorithm for A-optimal experimental design</title>
      <link>https://arxiv.org/abs/2409.09963</link>
      <description>arXiv:2409.09963v2 Announce Type: replace 
Abstract: Optimal experimental design (OED) concerns itself with identifying ideal methods of data collection, e.g.~via sensor placement. The \emph{greedy algorithm}, that is, placing one sensor at a time, in an iteratively optimal manner, stands as an extremely robust and easily executed algorithm for this purpose. However, it is a priori unclear whether this algorithm leads to sub-optimal regimes. Taking advantage of the author's recent work on non-smooth convex optimality criteria for OED, we here present a framework for rejection of sub-optimal greedy indices, and study the numerical benefits this offers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09963v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Aarset</dc:creator>
    </item>
    <item>
      <title>Bishop-Phelps Type Scalarization for Vector Optimization in Real Topological-Linear Spaces</title>
      <link>https://arxiv.org/abs/2410.10026</link>
      <description>arXiv:2410.10026v2 Announce Type: replace 
Abstract: It is well-known that scalarization techniques (e.g., in the sense of Gerstewitz; Kasimbeyli; Pascoletti and Serafini; Zaffaroni) are useful for generating (weakly, properly) efficient solutions of vector optimization problems. One recognized approach is the conic scalarization method in vector optimization in real normed spaces proposed by Kasimbeyli (2010, SIAM J Optim 20), which is based on augmented dual cones and Bishop-Phelps type (norm-linear) scalarizing functions. In this paper, we present new results on cone separation in real topological-linear spaces by using Bishop-Phelps type separating cones / separating seminorm-linear functions. Moreover, we study some extensions of known scalarization results in vector optimization (in the sense of Eichfelder; Gerstewitz; Jahn; Kasimbeyli; Pascoletti and Serafini). On this basis, we propose a Bishop-Phelps type scalarization method for vector optimization problems in real topological-linear spaces, which can be seen as an extension of Kasimbeyli's conic scalarization method in real normed spaces. Within this framework, we derive new Bishop-Phelps type scalarization results for the concepts of weak efficiency and different types of proper efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10026v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian G\"unther, Bahareh Khazayel, Radu Strugariu, Christiane Tammer</dc:creator>
    </item>
    <item>
      <title>Optimality of Linear Policies for Distributionally Robust Linear Quadratic Gaussian Regulator with Stationary Distributions</title>
      <link>https://arxiv.org/abs/2410.22826</link>
      <description>arXiv:2410.22826v2 Announce Type: replace 
Abstract: We prove that linear policies remain optimal for solving the Linear Quadratic Gaussian regulation problem in face of worst-case process and measurement noise distributions, when these are independent, stationary, and known to be within a radius (in the Wasserstein sense) to some reference Gaussian noise distributions. When the reference noise distributions are not Gaussian, we provide a closed-form solution for the worst-case distributions. Our main result suggests a computational complexity that scales only with the dimensionality of the system, and provides a less conservative alternative to recent work in distributionally robust control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22826v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Lanzetti, Antonio Terpin, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning</title>
      <link>https://arxiv.org/abs/1908.08729</link>
      <description>arXiv:1908.08729v2 Announce Type: replace-cross 
Abstract: Many decision problems in science, engineering and economics are affected by uncertain parameters whose distribution is only indirectly observable through samples. The goal of data-driven decision-making is to learn a decision from finitely many training samples that will perform well on unseen test samples. This learning task is difficult even if all training and test samples are drawn from the same distribution -- especially if the dimension of the uncertainty is large relative to the training sample size. Wasserstein distributionally robust optimization seeks data-driven decisions that perform well under the most adverse distribution within a certain Wasserstein distance from a nominal distribution constructed from the training samples. In this tutorial we will argue that this approach has many conceptual and computational benefits. Most prominently, the optimal decisions can often be computed by solving tractable convex optimization problems, and they enjoy rigorous out-of-sample and asymptotic consistency guarantees. We will also show that Wasserstein distributionally robust optimization has interesting ramifications for statistical learning and motivates new approaches for fundamental learning tasks such as classification, regression, maximum likelihood estimation or minimum mean square error estimation, among others.</description>
      <guid isPermaLink="false">oai:arXiv.org:1908.08729v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, Soroosh Shafieezadeh-Abadeh</dc:creator>
    </item>
    <item>
      <title>Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects</title>
      <link>https://arxiv.org/abs/2208.04883</link>
      <description>arXiv:2208.04883v5 Announce Type: replace-cross 
Abstract: Interstellar objects (ISOs) are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous -- a deep learning-based guidance and control framework for encountering fast-moving objects, including ISOs, robustly, accurately, and autonomously in real time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a loss function directly penalizing the MPC state trajectory tracking error. We show that Neural-Rendezvous provides a high probability exponential bound on the expected spacecraft delivery error, the proof of which leverages stochastic incremental stability analysis. In particular, it is used to construct a non-negative function with a supermartingale property, explicitly accounting for the ISO state uncertainty and the local nature of nonlinear state estimation guarantees. In numerical simulations, Neural-Rendezvous is demonstrated to satisfy the expected error bound for 100 ISO candidates. This performance is also empirically validated using our spacecraft simulator and in high-conflict and distributed UAV swarm reconfiguration with up to 20 UAVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.04883v5</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G007671</arxiv:DOI>
      <dc:creator>Hiroyasu Tsukamoto, Soon-Jo Chung, Yashwanth Kumar Nakka, Benjamin Donitz, Declan Mages, Michel Ingham</dc:creator>
    </item>
    <item>
      <title>Collision probability reduction method for tracking control in automatic docking / berthing using reinforcement learning</title>
      <link>https://arxiv.org/abs/2212.06415</link>
      <description>arXiv:2212.06415v3 Announce Type: replace-cross 
Abstract: Automation of berthing maneuvers in shipping is a pressing issue as the berthing maneuver is one of the most stressful tasks seafarers undertake. Berthing control problems are often tackled via tracking a predefined trajectory or path. Maintaining a tracking error of zero under an uncertain environment is impossible; the tracking controller is nonetheless required to bring vessels close to desired berths. The tracking controller must prioritize the avoidance of tracking errors that may cause collisions with obstacles. This paper proposes a training method based on reinforcement learning for a trajectory tracking controller that reduces the probability of collisions with static obstacles. Via numerical simulations, we show that the proposed method reduces the probability of collisions during berthing maneuvers. Furthermore, this paper shows the tracking performance in a model experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.06415v3</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00773-023-00962-5</arxiv:DOI>
      <dc:creator>Kouki Wakita, Youhei Akimoto, Dimas M. Rachman, Yoshiki Miyauchi, Umeda Naoya, Atsuo Maki</dc:creator>
    </item>
    <item>
      <title>Effective Bilevel Optimization via Minimax Reformulation</title>
      <link>https://arxiv.org/abs/2305.13153</link>
      <description>arXiv:2305.13153v4 Announce Type: replace-cross 
Abstract: Bilevel optimization has found successful applications in various machine learning problems, including hyper-parameter optimization, data cleaning, and meta-learning. However, its huge computational cost presents a significant challenge for its utilization in large-scale problems. This challenge arises due to the nested structure of the bilevel formulation, where each hyper-gradient computation necessitates a costly inner optimization procedure. To address this issue, we propose a reformulation of bilevel optimization as a minimax problem, effectively decoupling the outer-inner dependency. Under mild conditions, we show these two problems are equivalent. Furthermore, we introduce a multi-stage gradient descent and ascent (GDA) algorithm to solve the resulting minimax problem with convergence guarantees. Extensive experimental results demonstrate that our method outperforms state-of-the-art bilevel methods while significantly reducing the computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13153v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Rui Pan, Renjie Pi, Jipeng Zhang</dc:creator>
    </item>
    <item>
      <title>A Stochastic Porous Media Schr{\"o}dinger Equation: Feynman-type Motivation, Well-Posedness and Control Interpretation</title>
      <link>https://arxiv.org/abs/2310.01017</link>
      <description>arXiv:2310.01017v2 Announce Type: replace-cross 
Abstract: This paper's aim is threefold. First, using Feynman's path approach to the derivation of theclassical Schr{\"o}dinger's equation in [6] and by introducing a slight path (or wave) dependency ofthe action, we derive a new class of equations of Schr{\"o}dinger type where the driving operatoris no longer the Laplace one but rather of complex porous media-type. Second, using suitableconcepts of monotonicity in the complex setting and on appropriate functional spaces, we showthe existence and uniqueness of the solution to this type of equation. In the formulation of ourequation, we adjoin possible measurement absolute errors translating in an additive Brownianperturbation and interactions between different waves translating in a mean-field (or McKean-Vlasov) dependency of drift coefficient. Finally, using Fitzpatrick's characterization of maximalmonotone operators (cf. [7]), we propose a Br{\'e}zis-Ekeland type characterization of the solutionof the deterministic equation via a control problem. This is envisaged as a possible way toovercome strict monotonicity requirements in the complex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01017v2</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioana Ciotir (LMI), Dan Goreac (LAMA), Juan Li, Xinru Zhang</dc:creator>
    </item>
    <item>
      <title>Real-time Estimation of DoS Duration and Frequency for Security Control</title>
      <link>https://arxiv.org/abs/2312.05852</link>
      <description>arXiv:2312.05852v2 Announce Type: replace-cross 
Abstract: In this paper, we develop a new denial-of-service (DoS) estimator, enabling defenders to identify duration and frequency parameters of any DoS attacker, except for three edge cases, exclusively using real-time data. The key advantage of the estimator lies in its capability to facilitate security control in a wide range of practical scenarios, even when the attacker's information is previously unknown. We demonstrate the advantage and application of our new estimator in the context of two classical control scenarios, namely consensus of multi-agent systems and impulsive stabilization of nonlinear systems, for illustration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05852v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Sun, Jianquan Lu, Daniel W. C. Ho, Lulu Li</dc:creator>
    </item>
    <item>
      <title>Localized Distributional Robustness in Submodular Multi-Task Subset Selection</title>
      <link>https://arxiv.org/abs/2404.03759</link>
      <description>arXiv:2404.03759v2 Announce Type: replace-cross 
Abstract: In this work, we approach the problem of multi-task submodular optimization with the perspective of local distributional robustness, within the neighborhood of a reference distribution which assigns an importance score to each task. We initially propose to introduce a regularization term which makes use of the relative entropy to the standard multi-task objective. We then demonstrate through duality that this novel formulation itself is equivalent to the maximization of a monotone increasing function composed with a submodular function, which may be efficiently carried out through standard greedy selection methods. This approach bridges the existing gap in the optimization of performance-robustness trade-offs in multi-task subset selection. To numerically validate our theoretical results, we test the proposed method in two different settings, one on the selection of satellites in low Earth orbit constellations in the context of a sensor selection problem involving weak-submodular functions, and the other on an image summarization task using neural networks involving submodular functions. Our method is compared with two other algorithms focused on optimizing the performance of the worst-case task, and on directly optimizing the performance on the reference distribution itself. We conclude that our novel formulation produces a solution that is locally distributional robust, and computationally inexpensive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03759v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ege C. Kaya, Abolfazl Hashemi</dc:creator>
    </item>
    <item>
      <title>Compressing Large Language Models using Low Rank and Low Precision Decomposition</title>
      <link>https://arxiv.org/abs/2405.18886</link>
      <description>arXiv:2405.18886v2 Announce Type: replace-cross 
Abstract: The prohibitive sizes of Large Language Models (LLMs) today make it difficult to deploy them on memory-constrained edge devices. This work introduces $\rm CALDERA$ -- a new post-training LLM compression algorithm that harnesses the inherent low-rank structure of a weight matrix $\mathbf{W}$ by approximating it via a low-rank, low-precision decomposition as $\mathbf{W} \approx \mathbf{Q} + \mathbf{L}\mathbf{R}$. Here, $\mathbf{L}$ and $\mathbf{R}$ are low rank factors, and the entries of $\mathbf{Q}$, $\mathbf{L}$ and $\mathbf{R}$ are quantized. The model is compressed by substituting each layer with its $\mathbf{Q} + \mathbf{L}\mathbf{R}$ decomposition, and the zero-shot performance of the compressed model is evaluated. Additionally, $\mathbf{L}$ and $\mathbf{R}$ are readily amenable to low-rank adaptation, consequently enhancing the zero-shot performance. $\rm CALDERA$ obtains this decomposition by formulating it as an optimization problem $\min_{\mathbf{Q},\mathbf{L},\mathbf{R}}\lVert(\mathbf{Q} + \mathbf{L}\mathbf{R} - \mathbf{W})\mathbf{X}^\top\rVert_{\rm F}^2$, where $\mathbf{X}$ is the calibration data, and $\mathbf{Q}, \mathbf{L}, \mathbf{R}$ are constrained to be representable using low-precision formats. Theoretical upper bounds on the approximation error of $\rm CALDERA$ are established using a rank-constrained regression framework, and the tradeoff between compression ratio and model performance is studied by analyzing the impact of target rank and quantization bit budget. Results illustrate that compressing LlaMa-$2$ $7$B/$13B$/$70$B and LlaMa-$3$ $8$B models using $\rm CALDERA$ outperforms existing post-training LLM compression techniques in the regime of less than $2.5$ bits per parameter. The implementation is available at: https://github.com/pilancilab/caldera.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18886v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajarshi Saha, Naomi Sagan, Varun Srivastava, Andrea J. Goldsmith, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>An Equivalence Between Static and Dynamic Regret Minimization</title>
      <link>https://arxiv.org/abs/2406.01577</link>
      <description>arXiv:2406.01577v2 Announce Type: replace-cross 
Abstract: We study the problem of dynamic regret minimization in online convex optimization, in which the objective is to minimize the difference between the cumulative loss of an algorithm and that of an arbitrary sequence of comparators. While the literature on this topic is very rich, a unifying framework for the analysis and design of these algorithms is still missing. In this paper we show that for linear losses, dynamic regret minimization is equivalent to static regret minimization in an extended decision space. Using this simple observation, we show that there is a frontier of lower bounds trading off penalties due to the variance of the losses and penalties due to variability of the comparator sequence, and provide a framework for achieving any of the guarantees along this frontier. As a result, we also prove for the first time that adapting to the squared path-length of an arbitrary sequence of comparators to achieve regret $R_{T}(u_{1},\dots,u_{T})\le O(\sqrt{T\sum_{t} \|u_{t}-u_{t+1}\|^{2}})$ is impossible. However, using our framework we introduce an alternative notion of variability based on a locally-smoothed comparator sequence $\bar u_{1}, \dots, \bar u_{T}$, and provide an algorithm guaranteeing dynamic regret of the form $R_{T}(u_{1},\dots,u_{T})\le \tilde O(\sqrt{T\sum_{i}\|\bar u_{i}-\bar u_{i+1}\|^{2}})$, while still matching in the worst case the usual path-length dependencies up to polylogarithmic terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01577v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Jacobsen, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>Gradient Descent on Logistic Regression with Non-Separable Data and Large Step Sizes</title>
      <link>https://arxiv.org/abs/2406.05033</link>
      <description>arXiv:2406.05033v2 Announce Type: replace-cross 
Abstract: We study gradient descent (GD) dynamics on logistic regression problems with large, constant step sizes. For linearly-separable data, it is known that GD converges to the minimizer with arbitrarily large step sizes, a property which no longer holds when the problem is not separable. In fact, the behaviour can be much more complex -- a sequence of period-doubling bifurcations begins at the critical step size $2/\lambda$, where $\lambda$ is the largest eigenvalue of the Hessian at the solution. Using a smaller-than-critical step size guarantees convergence if initialized nearby the solution: but does this suffice globally? In one dimension, we show that a step size less than $1/\lambda$ suffices for global convergence. However, for all step sizes between $1/\lambda$ and the critical step size $2/\lambda$, one can construct a dataset such that GD converges to a stable cycle. In higher dimensions, this is actually possible even for step sizes less than $1/\lambda$. Our results show that although local convergence is guaranteed for all step sizes less than the critical step size, global convergence is not, and GD may instead converge to a cycle depending on the initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05033v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Si Yi Meng, Antonio Orvieto, Daniel Yiming Cao, Christopher De Sa</dc:creator>
    </item>
    <item>
      <title>Stabilized Proximal-Point Methods for Federated Optimization</title>
      <link>https://arxiv.org/abs/2407.07084</link>
      <description>arXiv:2407.07084v2 Announce Type: replace-cross 
Abstract: In developing efficient optimization algorithms, it is crucial to account for communication constraints -- a significant challenge in modern Federated Learning. The best-known communication complexity among non-accelerated algorithms is achieved by DANE, a distributed proximal-point algorithm that solves local subproblems at each iteration and that can exploit second-order similarity among individual functions. However, to achieve such communication efficiency, the algorithm requires solving local subproblems sufficiently accurately resulting in slightly sub-optimal local complexity. Inspired by the hybrid-projection proximal-point method, in this work, we propose a novel distributed algorithm S-DANE. Compared to DANE, this method uses an auxiliary sequence of prox-centers while maintaining the same deterministic communication complexity. Moreover, the accuracy condition for solving the subproblem is milder, leading to enhanced local computation efficiency. Furthermore, S-DANE supports partial client participation and arbitrary stochastic local solvers, making it attractive in practice. We further accelerate S-DANE and show that the resulting algorithm achieves the best-known communication complexity among all existing methods for distributed convex optimization while still enjoying good local computation efficiency as S-DANE. Finally, we propose adaptive variants of both methods using line search, obtaining the first provably efficient adaptive algorithms that could exploit local second-order similarity without the prior knowledge of any parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07084v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>IID Prophet Inequality with Random Horizon: Going Beyond Increasing Hazard Rates</title>
      <link>https://arxiv.org/abs/2407.11752</link>
      <description>arXiv:2407.11752v2 Announce Type: replace-cross 
Abstract: Prophet inequalities are a central object of study in optimal stopping theory. In the iid model, a gambler sees values in an online fashion, sampled independently from a given distribution. Upon observing each value, the gambler either accepts it as a reward or irrevocably rejects it and proceeds to observe the next value. The goal of the gambler, who cannot see the future, is maximising the expected value of the reward while competing against the expectation of a prophet (the offline maximum). In other words, one seeks to maximise the gambler-to-prophet ratio of the expectations.
  This model has been studied with infinite, finite and unknown number of values. When the gambler faces a random number of values, the model is said to have random horizon. We consider the model in which the gambler is given a priori knowledge of the horizon's distribution. Alijani et al. (2020) designed a single-threshold algorithms achieving a ratio of $1/2$ when the random horizon has an increasing hazard rate and is independent of the values. We prove that with a single-threshold, a ratio of $1/2$ is actually achievable for several larger classes of horizon distributions, with the largest being known as the $\mathcal{G}$ class in reliability theory. Moreover, we extend this result to its dual, the $\overline{\mathcal{G}}$ class (which includes the decreasing hazard rate class), and to low-variance horizons. Finally, we construct the first example of a family of horizons, for which multiple thresholds are necessary to achieve a nonzero ratio. We establish that the Secretary Problem optimal stopping rule provides one such algorithm, paving the way towards the study of the model beyond single-threshold algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11752v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giordano Giambartolomei, Frederik Mallmann-Trenn, Raimundo Saona</dc:creator>
    </item>
    <item>
      <title>Gradient-Variation Online Learning under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2408.09074</link>
      <description>arXiv:2408.09074v2 Announce Type: replace-cross 
Abstract: Gradient-variation online learning aims to achieve regret guarantees that scale with variations in the gradients of online functions, which has been shown to be crucial for attaining fast convergence in games and robustness in stochastic optimization, hence receiving increased attention. Existing results often require the smoothness condition by imposing a fixed bound on gradient Lipschitzness, which may be unrealistic in practice. Recent efforts in neural network optimization suggest a generalized smoothness condition, allowing smoothness to correlate with gradient norms. In this paper, we systematically study gradient-variation online learning under generalized smoothness. We extend the classic optimistic mirror descent algorithm to derive gradient-variation regret by analyzing stability over the optimization trajectory and exploiting smoothness locally. Then, we explore universal online learning, designing a single algorithm with the optimal gradient-variation regrets for convex and strongly convex functions simultaneously, without requiring prior knowledge of curvature. This algorithm adopts a two-layer structure with a meta-algorithm running over a group of base-learners. To ensure favorable guarantees, we design a new Lipschitz-adaptive meta-algorithm, capable of handling potentially unbounded gradients while ensuring a second-order bound to effectively ensemble the base-learners. Finally, we provide the applications for fast-rate convergence in games and stochastic extended adversarial optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09074v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan-Feng Xie, Peng Zhao, Zhi-Hua Zhou</dc:creator>
    </item>
    <item>
      <title>Sequential Resource Trading Using Comparison-Based Gradient Estimation</title>
      <link>https://arxiv.org/abs/2408.11186</link>
      <description>arXiv:2408.11186v2 Announce Type: replace-cross 
Abstract: Autonomous agents interact with other agents of unknown preferences to share resources in their environment. We explore sequential trading for resource allocation in a setting where two greedily rational agents sequentially trade resources from a finite set of categories. Each agent has a utility function that depends on the amount of resources it possesses in each category. The offering agent makes trade offers to improve its utility without knowing the responding agent's utility function, and the responding agent only accepts offers that improve its utility. We present an algorithm for the offering agent to estimate the responding agent's gradient (preferences) and make offers based on previous acceptance or rejection responses. The algorithm's goal is to reach a Pareto-optimal resource allocation state while ensuring that the utilities of both agents improve after every accepted trade. We show that, after a finite number of consecutively rejected offers, the responding agent is at a near-optimal state, or the agents' gradients are closely aligned. We compare the proposed algorithm against various baselines in continuous and discrete trading scenarios and show that it improves the societal benefit with fewer offers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11186v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Surya Murthy, Mustafa O. Karabag, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Linear Partial Gromov-Wasserstein Embedding</title>
      <link>https://arxiv.org/abs/2410.16669</link>
      <description>arXiv:2410.16669v2 Announce Type: replace-cross 
Abstract: The Gromov Wasserstein (GW) problem, a variant of the classical optimal transport (OT) problem, has attracted growing interest in the machine learning and data science communities due to its ability to quantify similarity between measures in different metric spaces. However, like the classical OT problem, GW imposes an equal mass constraint between measures, which restricts its application in many machine learning tasks. To address this limitation, the partial Gromov-Wasserstein (PGW) problem has been introduced, which relaxes the equal mass constraint, enabling the comparison of general positive Radon measures. Despite this, both GW and PGW face significant computational challenges due to their non-convex nature. To overcome these challenges, we propose the linear partial Gromov-Wasserstein (LPGW) embedding, a linearized embedding technique for the PGW problem. For $K$ different metric measure spaces, the pairwise computation of the PGW distance requires solving the PGW problem $\mathcal{O}(K^2)$ times. In contrast, the proposed linearization technique reduces this to $\mathcal{O}(K)$ times. Similar to the linearization technique for the classical OT problem, we prove that LPGW defines a valid metric for metric measure spaces. Finally, we demonstrate the effectiveness of LPGW in practical applications such as shape retrieval and learning with transport-based embeddings, showing that LPGW preserves the advantages of PGW in partial matching while significantly enhancing computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16669v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yikun Bai, Abihith Kothapalli, Hengrong Du, Rocio Diaz Martin, Soheil Kolouri</dc:creator>
    </item>
    <item>
      <title>Provable Acceleration for Diffusion Models under Minimal Assumptions</title>
      <link>https://arxiv.org/abs/2410.23285</link>
      <description>arXiv:2410.23285v2 Announce Type: replace-cross 
Abstract: While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds are often limited by the high computational burden of score function evaluations. Despite the recent remarkable empirical advances in speeding up the score-based samplers, theoretical understanding of acceleration techniques remains largely limited. To bridge this gap, we propose a novel training-free acceleration scheme for stochastic samplers. Under minimal assumptions -- namely, $L^2$-accurate score estimates and a finite second-moment condition on the target distribution -- our accelerated sampler provably achieves $\varepsilon$-accuracy in total variation within $\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantly improving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity of standard score-based samplers. Notably, our convergence theory does not rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23285v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gen Li, Changxiao Cai</dc:creator>
    </item>
  </channel>
</rss>
