<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Feb 2026 05:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Correcting temporal bias in mobility data using time-use surveys</title>
      <link>https://arxiv.org/abs/2601.22330</link>
      <description>arXiv:2601.22330v1 Announce Type: new 
Abstract: GPS mobility data is a valuable source of behavioral measurement which is subject to systematic biases including the over- or under-representation of demographic groups, and variations in the quality of location sampling across time. In this paper, we address the challenge of temporal bias in mobility data, which can skew the representation of mobility behaviors due to the event-based nature of location data sampling. We use the American Time Use Survey (ATUS) to assess the accuracy of a place-based measure of economic segregation drawn from large-scale mobility data across 11 U.S. cities. We show that comparisons with high quality time use surveys such as the ATUS can validate behavioral insights from mobility data, while quantifying uncertainty and highlighting areas of relative instability in analytical findings. We also propose a temporal re-weighting method that can complement existing bias-mitigation techniques to improve the accuracy of conclusions drawn from GPS-based mobility data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22330v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah A. Sanchez, Hamish Gibbs, Takahiro Yabe, Daniel T. O'Brien, Esteban Moro</dc:creator>
    </item>
    <item>
      <title>Convergent Discovery of Critical Phenomena Mathematics Across Disciplines: A Cross-Domain Analysis</title>
      <link>https://arxiv.org/abs/2601.22389</link>
      <description>arXiv:2601.22389v1 Announce Type: new 
Abstract: Techniques for detecting critical phenomena -- phase transitions where correlation length diverges and small perturbations have large effects -- have been developed across at least eight fields of application over nine decades. We document this convergence pattern. The physicist's correlation length $\xi$, the cardiologist's DFA scaling exponent $\alpha$, the financial analyst's Hurst exponent $H$, and the machine learning engineer's spectral radius $\chi$ all measure correlation decay rate, detecting the same critical signatures under different notation. Citation analysis reveals minimal cross-domain awareness during the formative period (1987--2010): researchers in biomedicine, finance, machine learning, power systems, and traffic flow developed equivalent techniques independently, each with distinct notation and terminology. We present Metatron Dynamics, a framework derived from distributed systems engineering, as a candidate ninth independent discovery -- strengthening the convergence pattern while acknowledging that as authors of both the framework and this analysis, external validation would strengthen this claim. Correspondence testing on the 2D Ising model confirms that measures from multiple frameworks correctly identify the critical regime at $T_c = 2.269$. We argue that repeated independent discovery establishes criticality mathematics as fundamental public knowledge, with implications for cross-disciplinary education and research accessibility. Because these findings affect fields beyond mathematics and physics, we include a plain-language summary in Appendix B for non-specialist readers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22389v1</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruce Stephenson, Robin Macomber</dc:creator>
    </item>
    <item>
      <title>Correlation-Based Diagnostics of Social Contagion Dynamics in Multiplex Networks</title>
      <link>https://arxiv.org/abs/2601.22459</link>
      <description>arXiv:2601.22459v1 Announce Type: new 
Abstract: Multiplex contagion dynamics display localization phenomena in which spreading activity concentrates on a subset of layers, as well as delocalized regimes where layers behave collectively. We investigate how these regimes are encoded in temporal correlations of node activity. By deriving a closed-form mean-field expression for node autocorrelations in a contact-based social contagion multiplex model and validating it through simulations, we show that lag-one autocorrelations act as sensitive indicators of both activation and localization transitions. Our results establish temporal correlations as lightweight, structure-agnostic probes of multiplex spreading dynamics, particularly valuable in partially observable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22459v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joan Hern\`andez Tey, Emanuele Cozzo</dc:creator>
    </item>
    <item>
      <title>Missing links prediction: comparing machine learning with physics-rooted approaches</title>
      <link>https://arxiv.org/abs/2601.23061</link>
      <description>arXiv:2601.23061v1 Announce Type: new 
Abstract: An active research line within the broader field of network science is the one concerning link prediction. Close in scope to network reconstruction, link prediction targets specific connections with the aim of uncovering the missing ones, as well as predicting those most likely to emerge in the future, from the available information. In this paper, we consider two families of methods, i.e. those rooted in statistical physics and those based upon machine learning: the members of the first family identify missing links as the most probable non-observed ones, the probability coefficients being determined by solving maximum-entropy benchmarks over the accessible network structure; the members of the second family, instead, associate the presence of single edges to explanatory node-specific variables. Running likelihood-based models such as the Configuration Model, or one of its many fitness-based variants, in parallel with the Gradient Boosting Decision Tree algorithm reveals that the former's accuracy is comparable to (and sometimes slightly higher than) the latter's. Such a result confirms that white-box algorithms are viable competitors to the currently available black-box ones, being computationally faster and more interpretable than the latter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23061v1</guid>
      <category>physics.soc-ph</category>
      <category>physics.app-ph</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Santucci, Giulio Cimini, Tiziano Squartini</dc:creator>
    </item>
    <item>
      <title>A Universal Convolution-Based Pre-processor to Correct the Prevalence-Incidence Gap in SIR, SEIR, and SIRS Modeling</title>
      <link>https://arxiv.org/abs/2601.23077</link>
      <description>arXiv:2601.23077v1 Announce Type: new 
Abstract: Traditional compartmental models, including SIR, SEIR, and SIRS frameworks, remain the analytical standard for epidemic forecasting. However, real-world data validation consistently reveals significant predictive failures, such as peak underestimations of up to 50%. This research identifies a persistent fundamental methodological error: the calibration of prevalence-based (stock) models using raw daily incidence (flow) data without proper transformation. We propose an integrated protocol utilizing an exponentially weighted convolution to reconstruct active cases from reported incidence: $I(t) \approx \frac{1}{p} \int_{0}^{t} NDC(\tau) e^{-\gamma(t-\tau)} d\tau$. This transformation accounts for the recovery rate $\gamma$ and the ascertainment rate $p$. We demonstrate that increasing structural complexity, such as adding latency (SEIR) or waning immunity (SIRS), fails to resolve the incidence-prevalence gap. Simulation results show that without the proposed universal pre-processor, these advanced models inherit the systematic biases of misaligned data types, leading to significant errors in estimating latent periods and the "heavy tail" of endemicity. The proposed convolution transformation must serve as a universal prerequisite for any compartmental framework, bridging the gap between clinical reporting and mechanistic modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23077v1</guid>
      <category>physics.soc-ph</category>
      <category>physics.bio-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose de Jesus Bernal-Alvarado, David Delepine</dc:creator>
    </item>
    <item>
      <title>PPG-Based Heart Rate Accuracy in Diverse Populations: Investigating Inequities Across Body Composition and Skin Tones</title>
      <link>https://arxiv.org/abs/2601.22377</link>
      <description>arXiv:2601.22377v1 Announce Type: cross 
Abstract: Wearable devices are widely used for heart rate (HR) monitoring, yet their accuracy across diverse body compositions and skin tones remains uncertain. This study evaluated four wrist worn devices (Apple, Fitbit, Samsung, Garmin) in 58 Hispanic adults with Fitzpatrick skin types III to V during a cycling protocol alternating moderate (0.64 to 0.76 HRmax) and vigorous (0.77 to 0.95 HRmax) intensities. Criterion HR was obtained using a Polar H10 ECG, and accuracy was assessed using mean absolute error, mean absolute percentage error (MAPE), bias, and intraclass correlation coefficients. All devices showed significant deviation from criterion measures. Apple and Garmin demonstrated the lowest error, whereas Fitbit and Samsung exhibited greater inaccuracies. Higher BMI and darker skin tones were associated with increased MAPE. These biases disproportionately affect higher risk populations, underscoring the need for improved algorithms to ensure equitable health monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22377v1</guid>
      <category>physics.med-ph</category>
      <category>physics.optics</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Kostrna,  Jason,  Oparina,  Ekaterina,  Palacios,  Cristina,  Rodriguez, Andres J,  Pei,  JunZhu,  Ajmal,  Ajmal,  Ramella-Roman, Jessica C</dc:creator>
    </item>
    <item>
      <title>Body Fat, Skin Tone, and the Accuracy of Smartwatch Caloric Expenditure Estimates</title>
      <link>https://arxiv.org/abs/2601.22391</link>
      <description>arXiv:2601.22391v1 Announce Type: cross 
Abstract: Smartwatches are widely used to estimate caloric expenditure for weight management, clinical decision making, and public health monitoring. These devices combine photoplethysmography, accelerometry, and proprietary algorithms. However, prior studies report substantial error, and the influence of moderators such as skin tone and body fat percentage (BF) remains underexamined. This study tested whether smartwatch brand, BF, and Fitzpatrick skin type (III to V) predict caloric expenditure error relative to indirect calorimetry. Fifty eight Hispanic adults completed a single laboratory visit including a ten minute recumbent cycling protocol with alternating two minute moderate and vigorous intensity intervals, bracketed by rest and recovery. Participants wore four consumer devices: Apple Watch Series 8, Fitbit Sense 2, Samsung Galaxy Watch 5, and Garmin Forerunner 955. Energy expenditure was measured using a COSMED K5 metabolic system. After device specific data quality filtering, valid participant device pairings ranged from 44 to 52 per brand. One sample tests showed significant mean bias for three devices: Apple, Garmin, and Samsung. Fitbit showed no significant overall bias, although this depended on device specific outlier removal. Mean bias varied by brand, with Garmin and Samsung showing the largest overestimations. Mixed effects models revealed significant effects of device and BF, as well as a device by BF interaction, with physical activity energy expenditure error increasing as adiposity increased. Overall, common smartwatches substantially misestimate caloric expenditure compared with indirect calorimetry. Error varies by brand and worsens with higher body fat, highlighting limitations of current consumer wearables and the need for improved accuracy across diverse body types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22391v1</guid>
      <category>physics.med-ph</category>
      <category>physics.optics</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Kostrna, Ekaterina Oparina, Andres J. Rodriguez, JunZhu Pei, Ajmal Ajmal, Cristina Palacios, Jessica C. Ramella-Roman</dc:creator>
    </item>
    <item>
      <title>Culturally Grounded Personas in Large Language Models: Characterization and Alignment with Socio-Psychological Value Frameworks</title>
      <link>https://arxiv.org/abs/2601.22396</link>
      <description>arXiv:2601.22396v1 Announce Type: cross 
Abstract: Despite the growing utility of Large Language Models (LLMs) for simulating human behavior, the extent to which these synthetic personas accurately reflect world and moral value systems across different cultural conditionings remains uncertain. This paper investigates the alignment of synthetic, culturally-grounded personas with established frameworks, specifically the World Values Survey (WVS), the Inglehart-Welzel Cultural Map, and Moral Foundations Theory. We conceptualize and produce LLM-generated personas based on a set of interpretable WVS-derived variables, and we examine the generated personas through three complementary lenses: positioning on the Inglehart-Welzel map, which unveils their interpretation reflecting stable differences across cultural conditionings; demographic-level consistency with the World Values Survey, where response distributions broadly track human group patterns; and moral profiles derived from a Moral Foundations questionnaire, which we analyze through a culture-to-morality mapping to characterize how moral responses vary across different cultural configurations. Our approach of culturally-grounded persona generation and analysis enables evaluation of cross-cultural structure and moral variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22396v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Candida M. Greco, Lucio La Cava, Andrea Tagarelli</dc:creator>
    </item>
    <item>
      <title>Human versus Artificial Inteligence; a significant example in astrophysics, alas</title>
      <link>https://arxiv.org/abs/2601.23205</link>
      <description>arXiv:2601.23205v1 Announce Type: cross 
Abstract: There are two well documented models of gamma ray bursts (GRBs), the "Standard' model and the "Cannonball" model. They have often been reviewed [1] and sometimes compared [2]. Here, to avoid understandable biases, I show below the results of an experiment: letting an AI compare the data and the two models. All of what follows (but two references, two footnotes and the next sentence) is the result of asking Perplexity.ai to perform this confrontational task. It should be easy for an impartial reader to reach very clear conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23205v1</guid>
      <category>astro-ph.HE</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. De R\'ujula</dc:creator>
    </item>
    <item>
      <title>Modularity maximization and community detection in complex networks through recursive and hierarchical annealing in the D-Wave Advantage quantum processing units</title>
      <link>https://arxiv.org/abs/2410.07744</link>
      <description>arXiv:2410.07744v3 Announce Type: replace 
Abstract: Quantum adiabatic optimization has long been expected to outperform classical methods in solving NP-type problems. While this has been proven in certain experiments, its main applications still reside in academic problems where the size of the system to be solved would not represent an obstacle to any modern desktop computer. Here we develop a systematic procedure to find the global optima of the modularity function to discover community structure in complex networks solely relying on pure annealers rather than hybrid solutions. We bypass the one-hot encoding constraints by hierarchically and recursively encoding binary instances of the problem that can be solved without the need to guess the exact penalties for the Lagrange multipliers. We study the variability, and robustness of the annealing process as a function of network size, directness of connections, topology, and the resolution of the communities. We show how our approach produces meaningful and at least equally optimal solutions to state-of-the-art community detection algorithms while maintaining tractable computing times. Lastly, due to its recursive nature, the annealing process returns intermediate subdivisions thus offering interpretable rather than black-box solutions. These \textit{dendrograms} can be used to unveil normal and pathological hidden hierarchies in brain networks hence opening the door to clinical workflows. Overall, this represents a first step towards an applicable practice-oriented usage of pure quantum annealing potentially bridging two segregated communities in modern science and engineering; that of network science and quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07744v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joan Falc\'o-Roget, Kacper Jurek, Barbara Wojtarowicz, Karol Capa{\l}a, Katarzyna Rycerz</dc:creator>
    </item>
    <item>
      <title>Who Connects Global Aid? The Hidden Geometry of 10 Million Transactions</title>
      <link>https://arxiv.org/abs/2512.17243</link>
      <description>arXiv:2512.17243v2 Announce Type: replace 
Abstract: The global aid system functions as a complex and evolving ecosystem; yet widespread understanding of its structure remains largely limited to aggregate volume flows. Here we map the network topology of global aid using a dataset of unprecedented scale: over 10 million transaction records connecting 2,456 publishing organisations across 230 countries between 1967 and 2025. We apply bipartite projection and dimensionality reduction to reveal the geometry of the system and unveil hidden patterns. This exposes distinct functional clusters that are otherwise sparsely connected. We find that while governments and multilateral agencies provide the primary resources, a small set of knowledge brokers provide the critical connectivity. Universities and research foundations specifically act as essential bridges between disparate islands of implementers and funders. We identify a core solar system of 25 central actors who drive this connectivity including unanticipated brokers like J-PAL and the Hewlett Foundation. These findings demonstrate that influence in the aid ecosystem flows through structural connectivity as much as financial volume. Our results provide a new framework for donors to identify strategic partners that accelerate coordination and evidence diffusion across the global network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17243v2</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul X. McCarthy, Xian Gong, Marian-Andrei Rizoiu, Paolo Boldi</dc:creator>
    </item>
  </channel>
</rss>
