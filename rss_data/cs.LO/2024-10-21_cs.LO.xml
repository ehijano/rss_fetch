<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Oct 2024 03:29:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Tableaux for Automated Reasoning in Dependently-Typed Higher-Order Logic (Extended Version)</title>
      <link>https://arxiv.org/abs/2410.14232</link>
      <description>arXiv:2410.14232v1 Announce Type: new 
Abstract: Dependent type theory gives an expressive type system facilitating succinct formalizations of mathematical concepts. In practice, it is mainly used for interactive theorem proving with intensional type theories, with PVS being a notable exception. In this paper, we present native rules for automated reasoning in a dependently-typed version (DHOL) of classical higher-order logic (HOL). DHOL has an extensional type theory with an undecidable type checking problem which contains theorem proving. We implemented the inference rules as well as an automatic type checking mode in Lash, a fork of Satallax, the leading tableaux-based prover for HOL. Our method is sound and complete with respect to provability in DHOL. Completeness is guaranteed by the incorporation of a sound and complete translation from DHOL to HOL recently proposed by Rothgang et al. While this translation can already be used as a preprocessing step to any HOL prover, to achieve better performance, our system directly works in DHOL. Moreover, experimental results show that the DHOL version of Lash can outperform all major HOL provers executed on the translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14232v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-63498-7_6</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 12th International Joint Conference on Automated Reasoning, LNAI 14739, pp 86-104, 2024</arxiv:journal_reference>
      <dc:creator>Johannes Niederhauser, Chad E. Brown, Cezary Kaliszyk</dc:creator>
    </item>
    <item>
      <title>Identity-Preserving Lax Extensions and Where to Find Them</title>
      <link>https://arxiv.org/abs/2410.14440</link>
      <description>arXiv:2410.14440v1 Announce Type: new 
Abstract: Generic notions of bisimulation for various types of systems (nondeterministic, probabilistic, weighted etc.) rely on identity-preserving (normal) lax extensions of the functor encapsulating the system type, in the paradigm of universal coalgebra. It is known that preservation of weak pullbacks is a sufficient condition for a functor to admit a normal lax extension (the Barr extension, which in fact is then even strict); in the converse direction, nothing is currently known about necessary (weak) pullback preservation conditions for the existence of normal lax extensions. In the present work, we narrow this gap by showing on the one hand that functors admitting a normal lax extension preserve 1/4-iso pullbacks, i.e. pullbacks in which at least one of the projections is an isomorphism. On the other hand, we give sufficient conditions, showing that a functor admits a normal lax extension if it weakly preserves either 1/4-iso pullbacks and 4/4-epi pullbacks (i.e. pullbacks in which all morphisms are epic) or inverse images. We apply these criteria to concrete examples, in particular to functors modelling neighbourhood systems and weighted systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14440v1</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Goncharov, Dirk Hofmaan, Pedro Nora, Lutz Schr\"oder, Paul Wild</dc:creator>
    </item>
    <item>
      <title>Relational Connectors and Heterogeneous Bisimulations</title>
      <link>https://arxiv.org/abs/2410.14460</link>
      <description>arXiv:2410.14460v1 Announce Type: new 
Abstract: While behavioural equivalences among systems of the same type, such as Park/Milner bisimilarity of labelled transition systems, are an established notion, a systematic treatment of relationships between systems of different type is currently missing. We provide such a treatment in the framework of universal coalgebra, in which the type of a system (nondeterministic, probabilistic, weighted, game-based etc.) is abstracted as a set functor: We introduce relational connectors among set functors, which induce notions of heterogeneous (bi)simulation among coalgebras of the respective types. We give a number of constructions on relational connectors. In particular, we identify composition and converse operations on relational connectors; we construct corresponding identity relational connectors, showing that the latter generalize the standard Barr extension of weak-pullback-preserving functors; and we introduce a Kantorovich construction in which relational connectors are induced from relations between modalities. For Kantorovich relational connectors, one has a notion of dual-purpose modal logic interpreted over both system types, and we prove a corresponding Hennessy-Milner-type theorem stating that generalized (bi)similarity coincides with theory inclusion on finitely-branching systems. We apply these results to a number of example scenarios involving labelled transition systems with different label alphabets, probabilistic systems, and input/output conformances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14460v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Nora, Jurriaan Rot, Lutz Schr\"oder, Paul Wild</dc:creator>
    </item>
    <item>
      <title>Formal Explanations for Neuro-Symbolic AI</title>
      <link>https://arxiv.org/abs/2410.14219</link>
      <description>arXiv:2410.14219v1 Announce Type: cross 
Abstract: Despite the practical success of Artificial Intelligence (AI), current neural AI algorithms face two significant issues. First, the decisions made by neural architectures are often prone to bias and brittleness. Second, when a chain of reasoning is required, neural systems often perform poorly. Neuro-symbolic artificial intelligence is a promising approach that tackles these (and other) weaknesses by combining the power of neural perception and symbolic reasoning. Meanwhile, the success of AI has made it critical to understand its behaviour, leading to the development of explainable artificial intelligence (XAI). While neuro-symbolic AI systems have important advantages over purely neural AI, we still need to explain their actions, which are obscured by the interactions of the neural and symbolic components. To address the issue, this paper proposes a formal approach to explaining the decisions of neuro-symbolic systems. The approach hinges on the use of formal abductive explanations and on solving the neuro-symbolic explainability problem hierarchically. Namely, it first computes a formal explanation for the symbolic component of the system, which serves to identify a subset of the individual parts of neural information that needs to be explained. This is followed by explaining only those individual neural inputs, independently of each other, which facilitates succinctness of hierarchical formal explanations and helps to increase the overall performance of the approach. Experimental results for a few complex reasoning tasks demonstrate practical efficiency of the proposed approach, in comparison to purely neural systems, from the perspective of explanation size, explanation time, training time, model sizes, and the quality of explanations reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14219v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushmita Paul, Jinqiang Yu, Jip J. Dekker, Alexey Ignatiev, Peter J. Stuckey</dc:creator>
    </item>
    <item>
      <title>A Model Checker for Natural Strategic Ability</title>
      <link>https://arxiv.org/abs/2410.14374</link>
      <description>arXiv:2410.14374v1 Announce Type: cross 
Abstract: In the last two decades, Alternating-time Temporal Logic (ATL) has been proved to be very useful in modeling strategic reasoning for Multi-Agent Systems (MAS). However, this logic struggles to capture the bounded rationality inherent in human decision-making processes. To overcome these limitations, Natural Alternating-time Temporal Logic (NatATL) has been recently introduced. As an extension of ATL, NatATL incorporates bounded memory constraints into agents' strategies, which allows to resemble human cognitive limitations. In this paper, we present a model checker tool for NatATL specifications - both for memoryless strategies and strategies with recall - integrated into VITAMIN, an open-source model checker designed specifically for MAS verification. By embedding NatATL into VITAMIN, we transform theoretical advancements into a practical verification framework, enabling comprehensive analysis and validation of strategic reasoning in complex multi-agent environments. Our novel tool paves the way for applications in areas such as explainable AI and human-in-the-loop systems, highlighting NatATL's substantial potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14374v1</guid>
      <category>cs.MA</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Aruta, Vadim Malvone, Aniello Murano</dc:creator>
    </item>
    <item>
      <title>Algebraic Reasoning over Relational Structures</title>
      <link>https://arxiv.org/abs/2401.08445</link>
      <description>arXiv:2401.08445v4 Announce Type: replace 
Abstract: Many important computational structures involve an intricate interplay between algebraic features (given by operations on the underlying set) and relational features (taking account of notions such as order or distance). This paper investigates algebras over relational structures axiomatized by an infinitary Horn theory, which subsume, for example, partial algebras, various incarnations of ordered algebras, quantitative algebras introduced by Mardare, Panangaden, and Plotkin, and their recent extension to generalized metric spaces and lifted algebraic signatures by Mio, Sarkis, and Vignudelli. To this end, we develop the notion of clustered equation, which is inspired by Mardare et al.'s basic conditional equations in the theory of quantitative algebras, at the level of generality of arbitrary relational structures, and we prove that it is equivalent to an abstract categorical form of equation earlier introduced by Milius and Urbat. Our main results are a family of Birkhoff-type variety theorems (classifying the expressive power of clustered equations) and an exactness theorem (classifying abstract equations by a congruence property).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08445v4</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Jurka, Stefan Milius, Henning Urbat</dc:creator>
    </item>
    <item>
      <title>Structure-Aware Computing By Partial Quantifier Elimination</title>
      <link>https://arxiv.org/abs/2403.05928</link>
      <description>arXiv:2403.05928v5 Announce Type: replace 
Abstract: By structure-aware computing (SAC) we mean computing that is formula-specific i.e., takes into account the structure of the formula at hand. Virtually all efficient algorithms of hardware verification employ some form of SAC. We relate SAC to $\mathit{partial}$ $\mathit{quantifier}$ $\mathit{elimination}$ (PQE). The latter is a generalization of regular quantifier elimination where one can take a $\mathit{part}$ of the formula out of the scope of quantifiers. The objective of this paper is to emphasize the significance of studying PQE for enhancing the $\mathit{existing}$ methods of SAC and creating $\mathit{new}$ ones. First, we show that interpolation (that can be viewed as an instance of SAC) is a special case of PQE. Then we describe application of SAC by PQE to three different problems of hardware verification: property generation, equivalence checking and model checking. Besides, we discuss using SAC by PQE for SAT solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05928v5</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eugene Goldberg</dc:creator>
    </item>
    <item>
      <title>Constructive Interpolation and Concept-Based Beth Definability for Description Logics via Sequents</title>
      <link>https://arxiv.org/abs/2404.15840</link>
      <description>arXiv:2404.15840v3 Announce Type: replace 
Abstract: We introduce a constructive method applicable to a large number of description logics (DLs) for establishing the concept-based Beth definability property (CBP) based on sequent systems. Using the highly expressive DL RIQ as a case study, we introduce novel sequent calculi for RIQ-ontologies and show how certain interpolants can be computed from sequent calculus proofs, which permit the extraction of explicit definitions of implicitly definable concepts. To the best of our knowledge, this is the first sequent-based approach to computing interpolants and definitions within the context of DLs, as well as the first proof that RIQ enjoys the CBP. Moreover, due to the modularity of our sequent systems, our results hold for restrictions of RIQ, and are applicable to other DLs by suitable modifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15840v3</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>math.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.24963/ijcai.2024/386</arxiv:DOI>
      <dc:creator>Tim S. Lyon, Jonas Karge</dc:creator>
    </item>
    <item>
      <title>Non-deterministic, probabilistic, and quantum effects through the lens of event structures (Technical report)</title>
      <link>https://arxiv.org/abs/2408.14563</link>
      <description>arXiv:2408.14563v2 Announce Type: replace 
Abstract: In this paper, we consider event structures and their probabilistic and quantum extensions as originally defined by Winskel. If these structures have already been part of sophisticated computational models, they have rarely been directly studied as an immediate model of execution traces of programs. This paper offers such an analysis. We propose a simple imperative operational framework and show how to derive soundness and adequacy results with event structures considered as a semantics. We show how event structures naturally handle non-deterministic, probabilistic and quantum effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14563v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'itor Fernandes, Marc de Visme, Beno\^it Valiron</dc:creator>
    </item>
    <item>
      <title>Apartness relations between propositions</title>
      <link>https://arxiv.org/abs/2209.03920</link>
      <description>arXiv:2209.03920v3 Announce Type: replace-cross 
Abstract: We classify all apartness relations definable in propositional logics extending intuitionistic logic using Heyting algebra semantics. We show that every Heyting algebra which contains a non-trivial apartness term satisfies the weak law of excluded middle, and every Heyting algebra which contains a tight apartness term is in fact a Boolean algebra. This answers a question of E. Rijke regarding the correct notion of apartness for propositions, and yields a short classification of apartness terms that can occur in a Heyting algebra. We also show that Martin-L\"of Type Theory is not able to construct non-trivial apartness relations between propositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03920v3</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/malq.202300055</arxiv:DOI>
      <dc:creator>Zoltan A. Kocsis</dc:creator>
    </item>
    <item>
      <title>Preference-Based Planning in Stochastic Environments: From Partially-Ordered Temporal Goals to Most Preferred Policies</title>
      <link>https://arxiv.org/abs/2403.18212</link>
      <description>arXiv:2403.18212v2 Announce Type: replace-cross 
Abstract: Human preferences are not always represented via complete linear orders: It is natural to employ partially-ordered preferences for expressing incomparable outcomes. In this work, we consider decision-making and probabilistic planning in stochastic systems modeled as Markov decision processes (MDPs), given a partially ordered preference over a set of temporally extended goals. Specifically, each temporally extended goal is expressed using a formula in Linear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially ordered preference, we introduce order theory to map a preference over temporal goals to a preference over policies for the MDP. Accordingly, a most preferred policy under a stochastic ordering induces a stochastic nondominated probability distribution over the finite paths in the MDP. To synthesize a most preferred policy, our technical approach includes two key steps. In the first step, we develop a procedure to transform a partially ordered preference over temporal goals into a computational model, called preference automaton, which is a semi-automaton with a partial order over acceptance conditions. In the second step, we prove that finding a most preferred policy is equivalent to computing a Pareto-optimal policy in a multi-objective MDP that is constructed from the original MDP, the preference automaton, and the chosen stochastic ordering relation. Throughout the paper, we employ running examples to illustrate the proposed preference specification and solution approaches. We demonstrate the efficacy of our algorithm using these examples, providing detailed analysis, and then discuss several potential future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18212v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hazhar Rahmani, Abhishek N. Kulkarni, Jie Fu</dc:creator>
    </item>
    <item>
      <title>LeanAgent: Lifelong Learning for Formal Theorem Proving</title>
      <link>https://arxiv.org/abs/2410.06209</link>
      <description>arXiv:2410.06209v4 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have been successful in mathematical reasoning tasks such as formal theorem proving when integrated with interactive proof assistants like Lean. Existing approaches involve training or fine-tuning an LLM on a specific dataset to perform well on particular domains, such as undergraduate-level mathematics. These methods struggle with generalizability to advanced mathematics. A fundamental limitation is that these approaches operate on static domains, failing to capture how mathematicians often work across multiple domains and projects simultaneously or cyclically. We present LeanAgent, a novel lifelong learning framework for theorem proving that continuously generalizes to and improves on ever-expanding mathematical knowledge without forgetting previously learned knowledge. LeanAgent introduces several key innovations, including a curriculum learning strategy that optimizes the learning trajectory in terms of mathematical difficulty, a dynamic database for efficient management of evolving mathematical knowledge, and progressive training to balance stability and plasticity. LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics. It performs significantly better than the static LLM baseline, proving challenging theorems in domains like abstract algebra and algebraic topology while showcasing a clear progression of learning from basic concepts to advanced topics. In addition, we analyze LeanAgent's superior performance on key lifelong learning metrics. LeanAgent achieves exceptional scores in stability and backward transfer, where learning new tasks improves performance on previously learned tasks. This emphasizes LeanAgent's continuous generalizability and improvement, explaining its superior theorem-proving performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06209v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adarsh Kumarappan, Mo Tiwari, Peiyang Song, Robert Joseph George, Chaowei Xiao, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>How hard can it be? Quantifying MITRE attack campaigns with attack trees and cATM logic</title>
      <link>https://arxiv.org/abs/2410.06692</link>
      <description>arXiv:2410.06692v2 Announce Type: replace-cross 
Abstract: The landscape of cyber threats grows more complex by the day. Advanced Persistent Threats carry out systematic attack campaigns against which cybersecurity practitioners must defend. Examples of such organized attacks are operations Dream Job, Wocao, WannaCry or the SolarWinds Compromise. To evaluate which risks are most threatening, and which campaigns to prioritize against when defending, cybersecurity experts must be equipped with the right toolbox. In particular, they must be able to (a) obtain likelihood values for each attack campaign recorded in the wild and (b) reliably and transparently operationalize these values to carry out quantitative comparisons among campaigns. This will allow security experts to perform quantitatively-informed decision making that is transparent and accountable. In this paper we construct such a framework by: (1) quantifying the likelihood of attack campaigns via data-driven procedures on the MITRE knowledge base and (2) introducing a methodology for automatic modelling of MITRE intelligence data: this is complete in the sense that it captures any attack campaign via template attack tree models. (3) We further propose a computational framework to carry out this comparisons based on the cATM formal logic, and implement this into an open-source Python tool. Finally, we validate our approach by quantifying the likelihood of all MITRE campaigns, and comparing the likelihood of the Wocao and Dream Job MITRE campaigns -- generated with our proposed approach -- against "ad hoc" traditionally-built attack tree models, demonstrating how our methodology is substantially lighter in modelling effort, and still capable of capturing all the quantitative relevant data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06692v2</guid>
      <category>cs.CR</category>
      <category>cs.LO</category>
      <pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano M. Nicoletti, Milan Lopuha\"a-Zwakenberg, Mari\"elle Stoelinga, Fabio Massacci, Carlos E. Budde</dc:creator>
    </item>
  </channel>
</rss>
