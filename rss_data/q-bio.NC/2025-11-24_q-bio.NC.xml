<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Nov 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reassessing prediction in the brain: Pre-onset neural encoding during natural listening does not reflect pre-activation</title>
      <link>https://arxiv.org/abs/2412.19622</link>
      <description>arXiv:2412.19622v2 Announce Type: replace 
Abstract: Predictive processing theories propose that the brain continuously anticipates upcoming input. However, direct neural evidence for predictive pre-activation during natural language comprehension remains limited and debated. Previous studies using large language model (LLM)-based encoding models with fMRI and ECoG have reported pre-onset signals that appear to encode upcoming words, but these effects may instead reflect dependencies in the stimulus or autocorrelations in neural activity. Here, we re-examined this question by aligning LLM-derived word embeddings with neural activity recorded during naturalistic listening using magnetoencephalography (MEG) and electrocorticography (ECoG). We replicated pre-onset encoding effects previously observed in ECoG across both modalities, and found that they persist even after controlling for stimulus correlations. Crucially, temporal generalization analyses revealed no stable overlap between pre- and post-onset representations, indicating that pre-onset activity does not reflect pre-activation of the next word. Consistent with this, long-range predictive effects previously reported in fMRI did not replicate in our higher-temporal-resolution data. While we found no evidence for predictive pre-activation, we observed clear signatures of postdiction, with neural activity reflecting persistent encoding of prior words. These results suggest that reported apparent predictive signals do not reflect pre-activation of upcoming input. They call for caution in interpreting LLM-based encoding models and highlight the need for a more nuanced understanding of what constitutes "prediction" in language comprehension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19622v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahel Azizpour, Britta U. Westner, Jakub Szewczyk, Umut G\"u\c{c}l\"u, Linda Geerligs</dc:creator>
    </item>
    <item>
      <title>Emergence of psychopathological computations in large language models</title>
      <link>https://arxiv.org/abs/2504.08016</link>
      <description>arXiv:2504.08016v2 Announce Type: replace 
Abstract: Can large language models (LLMs) instantiate computations of psychopathology? An effective approach to the question hinges on addressing two factors. First, for conceptual validity, we require a general and computational account of psychopathology that is applicable to computational entities without biological embodiment or subjective experience. Second, psychopathological computations, derived from the adapted theory, need to be empirically identified within the LLM's internal processing. Thus, we establish a computational-theoretical framework to provide an account of psychopathology applicable to LLMs. Based on the framework, we conduct experiments demonstrating two key claims: first, that the computational structure of psychopathology exists in LLMs; and second, that executing this computational structure results in psychopathological functions. We further observe that as LLM size increases, the computational structure of psychopathology becomes denser and that the functions become more effective. Taken together, the empirical results corroborate our hypothesis that network-theoretic computations of psychopathology have already emerged in LLMs. This suggests that certain LLM behaviors mirroring psychopathology may not be a superficial mimicry but a feature of their internal processing. Our work shows the promise of developing a new powerful in silico model of psychopathology and also alludes to the possibility of safety threat from the AI systems with psychopathological behaviors in the near future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08016v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soo Yong Lee, Hyunjin Hwang, Taekwan Kim, Yuyeong Kim, Kyuri Park, Jaemin Yoo, Denny Borsboom, Kijung Shin</dc:creator>
    </item>
    <item>
      <title>Brain-Like Processing Pathways Form in Models With Heterogeneous Experts</title>
      <link>https://arxiv.org/abs/2506.02813</link>
      <description>arXiv:2506.02813v3 Announce Type: replace 
Abstract: The brain is made up of a vast set of heterogeneous regions that dynamically organize into pathways as a function of task demands. Examples of such pathways can be found in the interactions between cortical and subcortical networks during learning, or in sub-networks specializing for task characteristics such as difficulty or modality. Despite the large role these pathways play in cognition, the mechanisms through which brain regions organize into pathways remain unclear. In this work, we use an extension of the Heterogeneous Mixture-of-Experts architecture to show that heterogeneous regions do not form processing pathways by themselves, implying that the brain likely implements specific constraints which result in the reliable formation of pathways. We identify three biologically relevant inductive biases that encourage pathway formation: a routing cost imposed on the use of more complex regions, a scaling factor that reduces this cost when task performance is low, and randomized expert dropout. When comparing our resulting \textit{Mixture-of-Pathways} model with the brain, we observe that the artificial pathways in our model match how the brain uses cortical and subcortical systems to learn and solve tasks of varying difficulty. In summary, we introduce a novel framework for investigating how the brain forms task-specific pathways through inductive biases, and the effects these biases have on the behavior of Mixture-of-Experts models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02813v3</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Cook, Danyal Akarca, Rui Ponte Costa, Jascha Achterberg</dc:creator>
    </item>
    <item>
      <title>Forecasting Future Anatomies: Longitudinal Brain Mri-to-Mri Prediction</title>
      <link>https://arxiv.org/abs/2511.02558</link>
      <description>arXiv:2511.02558v2 Announce Type: replace-cross 
Abstract: Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02558v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Farki, Elaheh Moradi, Deepika Koundal, Jussi Tohka</dc:creator>
    </item>
  </channel>
</rss>
