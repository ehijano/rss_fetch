<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DM</link>
    <description>cs.DM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Probabilistic estimates of the diameters of the Rubik's Cube groups</title>
      <link>https://arxiv.org/abs/2404.07337</link>
      <description>arXiv:2404.07337v1 Announce Type: new 
Abstract: The diameter of the Cayley graph of the Rubik's Cube group is the fewest number of turns needed to solve the Cube from any initial configurations. For the 2$\times$2$\times$2 Cube, the diameter is 11 in the half-turn metric, 14 in the quarter-turn metric, 19 in the semi-quarter-turn metric, and 10 in the bi-quarter-turn metric. For the 3$\times$3$\times$3 Cube, the diameter was determined by Rikicki et al. to be 20 in the half-turn metric and 26 in the quarter-turn metric. This study shows that a modified version of the coupon collector's problem in probabilistic theory can predict the diameters correctly for both 2$\times$2$\times$2 and 3$\times$3$\times$3 Cubes insofar as the quarter-turn metric is adopted. In the half-turn metric, the diameters are overestimated by one and two, respectively, for the 2$\times$2$\times$2 and 3$\times$3$\times$3 Cubes, whereas for the 2$\times$2$\times$2 Cube in the semi-quarter-turn and bi-quarter-turn metrics, they are overestimated by two and underestimated by one, respectively. Invoking the same probabilistic logic, the diameters of the 4$\times$4$\times$4 and 5$\times$5$\times$5 Cubes are predicted to be 48 (41) and 68 (58) in the quarter-turn (half-turn) metric, whose precise determinations are far beyond reach of classical supercomputing. It is shown that the probabilistically estimated diameter is accurately approximated by $\ln N / \ln r + \ln N / r$, where $N$ is the number of configurations and $r$ is the branching ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07337v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>So Hirata</dc:creator>
    </item>
    <item>
      <title>Integrating On-demand Ride-sharing with Mass Transit at-Scale</title>
      <link>https://arxiv.org/abs/2404.07691</link>
      <description>arXiv:2404.07691v1 Announce Type: new 
Abstract: We are in the midst of a technology-driven transformation of the urban mobility landscape. However, unfortunately these new innovations are still dominated by car-centric personal mobility, which leads to concerns such as environmental sustainability, congestion, and equity. On the other hand, mass transit provides a means to move large amounts of travelers very efficiently, but is not very versatile and depends on an adequate concentration of demand. In this context, our overarching goal is to explore opportunities for new technologies such as ride-sharing to integrate with mass transit and provide a better service. More specifically, we envision a hybrid system that uses on-demand shuttles in conjunction with mass transit to move passengers efficiently, and provide an algorithmic framework for operational optimization. Our approach extends a state-of-the-art trip-vehicle assignment model to the multi-modal setting, where we develop a new integer-linear programming formulation to solve the problem efficiently. A comprehensive study covering five major cities in the United States based on real-world data is carried out to verify the advantages of such a system and the effectiveness of our algorithms. We show that our hybrid system provides significant improvements in comparison to a purely on-demand model by exploiting the efficiencies of the mass transit system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07691v1</guid>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danushka Edirimanna, Hins Hu, Samitha Samaranayake</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of Submodular Minimization under Uncertainty</title>
      <link>https://arxiv.org/abs/2404.07516</link>
      <description>arXiv:2404.07516v1 Announce Type: cross 
Abstract: This paper studies the computational complexity of a robust variant of a two-stage submodular minimization problem that we call Robust Submodular Minimizer. In this problem, we are given $k$ submodular functions $f_1,\dots,f_k$ over a set family $2^V$, which represent $k$ possible scenarios in the future when we will need to find an optimal solution for one of these scenarios, i.e., a minimizer for one of the functions. The present task is to find a set $X \subseteq V$ that is close to some optimal solution for each $f_i$ in the sense that some minimizer of $f_i$ can be obtained from $X$ by adding/removing at most $d$ elements for a given integer $d$. The main contribution of this paper is to provide a complete computational map of this problem with respect to parameters $k$ and $d$, which reveals a tight complexity threshold for both parameters: (1) Robust Submodular Minimizer can be solved in polynomial time when $k \leq 2$, but is NP-hard if $k$ is a constant with $k \geq 3$. (2) Robust Submodular Minimizer can be solved in polynomial time when $d=0$, but is NP-hard if $d$ is a constant with $d \geq 1$. (3) Robust Submodular Minimizer is fixed-parameter tractable when parameterized by $(k,d)$. We also show that if some submodular function $f_i$ has a polynomial number of minimizers, then the problem becomes fixed-parameter tractable when parameterized by $d$. We remark that all our hardness results hold even if each submodular function is given by a cut function of a directed graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07516v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naonori Kakimura, Ildik\'o Schlotter</dc:creator>
    </item>
    <item>
      <title>Poset Positional Games</title>
      <link>https://arxiv.org/abs/2404.07700</link>
      <description>arXiv:2404.07700v1 Announce Type: cross 
Abstract: We propose a generalization of positional games, supplementing them with a restriction on the order in which the elements of the board are allowed to be claimed. We introduce poset positional games, which are positional games with an additional structure -- a poset on the elements of the board. Throughout the game play, based on this poset and the set of the board elements that are claimed up to that point, we reduce the set of available moves for the player whose turn it is -- an element of the board can only be claimed if all the smaller elements in the poset are already claimed.
  We proceed to analyse these games in more detail, with a prime focus on the most studied convention, the Maker-Breaker games. First we build a general framework around poset positional games. Then, we perform a comprehensive study of the complexity of determining the game outcome, conditioned on the structure of the family of winning sets on the one side and the structure of the poset on the other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07700v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guillaume Bagan, Eric Duch\^ene, Florian Galliot, Valentin Gledel, Mirjana Mikala\v{c}ki, Nacim Oijid, Aline Parreau ad Milo\v{s} Stojakovi\'c</dc:creator>
    </item>
    <item>
      <title>An efficient uniqueness theorem for overcomplete tensor decomposition</title>
      <link>https://arxiv.org/abs/2404.07801</link>
      <description>arXiv:2404.07801v1 Announce Type: cross 
Abstract: We give a new, constructive uniqueness theorem for tensor decomposition. It applies to order 3 tensors of format $n \times n \times p$ and can prove uniqueness of decomposition for generic tensors up to rank $r=4n/3$ as soon as $p \geq 4$. One major advantage over Kruskal's uniqueness theorem is that our theorem has an algorithmic proof, and the resulting algorithm is efficient. Like the uniqueness theorem, it applies in the range $n \leq r \leq 4n/3$. As a result, we obtain the first efficient algorithm for overcomplete decomposition of generic tensors of order 3.
  For instance, prior to this work it was not known how to efficiently decompose generic tensors of format $n \times n \times n$ and rank $r=1.01n$ (or rank $r \leq (1+\epsilon) n$, for some constant $\epsilon &gt;0$). Efficient overcomplete decomposition of generic tensors of format $n \times n \times 3$ remains an open problem.
  Our results are based on the method of commuting extensions pioneered by Strassen for the proof of his $3n/2$ lower bound on tensor rank and border rank. In particular, we rely on an algorithm for the computation of commuting extensions recently proposed in a companion paper, and on the classical diagonalization-based "Jennrich algorithm" for undercomplete tensor decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07801v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Koiran</dc:creator>
    </item>
    <item>
      <title>Beyond recognizing well-covered graphs</title>
      <link>https://arxiv.org/abs/2404.07853</link>
      <description>arXiv:2404.07853v1 Announce Type: cross 
Abstract: We prove a number of results related to the computational complexity of recognizing well-covered graphs. Let $k$ and $s$ be positive integers and let $G$ be a graph. Then $G$ is said
  - $\mathbf{W_k}$ if for any $k$ pairwise disjoint independent vertex sets $A_1, \dots, A_k$ in $G$, there exist $k$ pairwise disjoint maximum independent sets $S_1, \dots,S_k$ in $G$ such that $A_i \subseteq S_i$ for $i \in [k]$.
  - $\mathbf{E_s}$ if every independent set in $G$ of size at most $s$ is contained in a maximum independent set in $G$.
  Chv\'atal and Slater (1993) and Sankaranarayana and Stewart (1992) famously showed that recognizing $\mathbf{W_1}$ graphs or, equivalently, well-covered graphs is coNP-complete. We extend this result by showing that recognizing $\mathbf{W_{k+1}}$ graphs in either $\mathbf{W_k}$ or $\mathbf{E_s}$ graphs is coNP-complete. This answers a question of Levit and Tankus (2023) and strengthens a theorem of Feghali and Marin (2024). We also show that recognizing $\mathbf{E_{s+1}}$ graphs is $\Theta_2^p$-complete even in $\mathbf{E_s}$ graphs, where $\Theta_2^p = \text{P}^{\text{NP}[\log]}$ is the class of problems solvable in polynomial time using a logarithmic number of calls to a SAT oracle. This strengthens a theorem of Berg\'e, Busson, Feghali and Watrigant (2023). We also obtain the complete picture of the complexity of recognizing chordal $\mathbf{W_k}$ and $\mathbf{E_s}$ graphs which, in particular, simplifies and generalizes a result of Dettlaff, Henning and Topp (2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07853v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carl Feghali, Malory Marin, R\'emi Watrigant</dc:creator>
    </item>
    <item>
      <title>On {\lambda}-backbone coloring of cliques with tree backbones in linear time</title>
      <link>https://arxiv.org/abs/2107.05772</link>
      <description>arXiv:2107.05772v3 Announce Type: replace 
Abstract: A $\lambda$-backbone coloring of a graph $G$ with its subgraph (also called a backbone) $H$ is a function $c \colon V(G) \rightarrow \{1,\dots, k\}$ ensuring that $c$ is a proper coloring of $G$ and for each $\{u,v\} \in E(H)$ it holds that $|c(u) - c(v)| \ge \lambda$. In this paper we propose a way to color cliques with tree and forest backbones in linear time that the largest color does not exceed $\max\{n, 2 \lambda\} + \Delta(H)^2 \lceil\log{n} \rceil$. This result improves on the previously existing approximation algorithms as it is $(\Delta(H)^2 \lceil\log{n} \rceil)$-absolutely approximate, i.e. with an additive error over the optimum. We also present an infinite family of trees $T$ with $\Delta(T) = 3$ for which the coloring of cliques with backbones $T$ require to use at least $\max\{n, 2 \lambda\} + \Omega(\log{n})$ colors for $\lambda$ close to $\frac{n}{2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.05772v3</guid>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Michalik, Krzysztof Turowski</dc:creator>
    </item>
    <item>
      <title>On approximating the rank of graph divisors</title>
      <link>https://arxiv.org/abs/2206.09662</link>
      <description>arXiv:2206.09662v2 Announce Type: replace-cross 
Abstract: Baker and Norine initiated the study of graph divisors as a graph-theoretic analogue of the Riemann-Roch theory for Riemann surfaces. One of the key concepts of graph divisor theory is the {\it rank} of a divisor on a graph. The importance of the rank is well illustrated by Baker's {\it Specialization lemma}, stating that the dimension of a linear system can only go up under specialization from curves to graphs, leading to a fruitful interaction between divisors on graphs and curves.
  Due to its decisive role, determining the rank is a central problem in graph divisor theory. Kiss and T\'othm\'eresz reformulated the problem using chip-firing games, and showed that computing the rank of a divisor on a graph is NP-hard via reduction from the Minimum Feedback Arc Set problem.
  In this paper, we strengthen their result by establishing a connection between chip-firing games and the Minimum Target Set Selection problem. As a corollary, we show that the rank is difficult to approximate to within a factor of $O(2^{\log^{1-\varepsilon}n})$ for any $\varepsilon &gt; 0$ unless $P=NP$. Furthermore, assuming the Planted Dense Subgraph Conjecture, the rank is difficult to approximate to within a factor of $O(n^{1/4-\varepsilon})$ for any $\varepsilon&gt;0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09662v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.disc.2023.113528</arxiv:DOI>
      <arxiv:journal_reference>Discrete Math. 346 (2023), no. 9, Paper No. 113528, 8 pp</arxiv:journal_reference>
      <dc:creator>Krist\'of B\'erczi, Hung P. Hoang, Lilla T\'othm\'er\'esz</dc:creator>
    </item>
    <item>
      <title>Swap cosystolic expansion</title>
      <link>https://arxiv.org/abs/2312.15325</link>
      <description>arXiv:2312.15325v2 Announce Type: replace-cross 
Abstract: We introduce and study swap cosystolic expansion, a new expansion property of simplicial complexes. We prove lower bounds for swap coboundary expansion of spherical buildings and use them to lower bound swap cosystolic expansion of the LSV Ramanujan complexes. Our motivation is the recent work (in a companion paper) showing that swap cosystolic expansion implies agreement theorems. Together the two works show that these complexes support agreement tests in the low acceptance regime.
  Swap cosystolic expansion is defined by considering, for a given complex $X$, its faces complex $F^r X$, whose vertices are $r$-faces of $X$ and where two vertices are connected if their disjoint union is also a face in $X$. The faces complex $F^r X$ is a derandomizetion of the product of $X$ with itself $r$ times. The graph underlying $F^rX$ is the swap walk of $X$, known to have excellent spectral expansion. The swap cosystolic expansion of $X$ is defined to be the cosystolic expansion of $F^r X$.
  Our main result is a $\exp(-O(\sqrt r))$ lower bound on the swap coboundary expansion of the spherical building and the swap cosystolic expansion of the LSV complexes. For more general coboundary expanders we show a weaker lower bound of $exp(-O(r))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15325v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>math.AT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yotam Dikstein, Irit Dinur</dc:creator>
    </item>
    <item>
      <title>Extremal minimal bipartite matching covered graphs</title>
      <link>https://arxiv.org/abs/2404.06445</link>
      <description>arXiv:2404.06445v2 Announce Type: replace-cross 
Abstract: A connected graph, on four or more vertices, is matching covered if every edge is present in some perfect matching. An ear decomposition theorem (similar to the one for $2$-connected graphs) exists for bipartite matching covered graphs due to Hetyei. From the results and proofs of Lov\'asz and Plummer, that rely on Hetyei's theorem, one may deduce that any minimal bipartite matching covered graph has at least $2(m-n+2)$ vertices of degree two (where minimal means that deleting any edge results in a graph that is not matching covered); such a graph is said to be extremal if it attains the stated lower bound.
  In this paper, we provide a complete characterization of the class of extremal minimal bipartite matching covered graphs. In particular, we prove that every such graph $G$ is obtained from two copies of a tree devoid of degree two vertices, say $T$ and $T'$, by adding edges -- each of which joins a leaf of $T$ with the corresponding leaf of $T'$.
  Apart from the aforementioned bound, there are four other bounds that appear in, or may be deduced from, the work of Lov\'asz and Plummer. Each of these bounds leads to a notion of extremality. In this paper, we obtain a complete characterization of all of these extremal classes and also establish relationships between them. Two of our characterizations are in the same spirit as the one stated above. For the remaining two extremal classes, we reduce each of them to one of the already characterized extremal classes using standard matching theoretic operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06445v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Kumar Mallik, Ajit A. Diwan, Nishad Kothari</dc:creator>
    </item>
  </channel>
</rss>
