<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Jun 2025 07:58:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Proximal Iterative Hard Thresholding Algorithm for Sparse Group $\ell_0$-Regularized Optimization with Box Constraint</title>
      <link>https://arxiv.org/abs/2506.00196</link>
      <description>arXiv:2506.00196v1 Announce Type: new 
Abstract: This paper investigates a general class of problems in which a lower bounded smooth convex function incorporating $\ell_{0}$ and $\ell_{2,0}$ regularization is minimized over a box constraint. Although such problems arise frequently in practical applications, their inherent non-convexity poses significant challenges for solution methods. In particular, we focus on the proximal operator associated with these regularizations, which incorporates both group-sparsity and element-wise sparsity terms. Besides, we introduce the concepts of $\tau$-stationary point and support optimal (SO) point then analyze their relationship with the minimizer of the considered problem. Based on the proximal operator, we propose a novel proximal iterative hard thresholding algorithm to solve the problem. Furthermore, we establish the global convergence and the computational complexity analysis of the proposed method. Finally, extensive experiments demonstrate the effectiveness and efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00196v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuge Ye, Qingna Li</dc:creator>
    </item>
    <item>
      <title>How hard is learning to cut? Trade-offs and sample complexity</title>
      <link>https://arxiv.org/abs/2506.00252</link>
      <description>arXiv:2506.00252v1 Announce Type: new 
Abstract: In the recent years, branch-and-cut algorithms have been the target of data-driven approaches designed to enhance the decision making in different phases of the algorithm such as branching, or the choice of cutting planes (cuts). In particular, for cutting plane selection two score functions have been proposed in the literature to evaluate the quality of a cut: branch-and-cut tree size and gap closed. In this paper, we present new sample complexity lower bounds, valid for both scores. We show that for a wide family of classes $\mathcal{F}$ that maps an instance to a cut, learning over an unknown distribution of the instances to minimize those scores requires at least (up to multiplicative constants) as many samples as learning from the same class function $\mathcal{F}$ any generic target function (using square loss). Our results also extend to the case of learning from a restricted set of cuts, namely those from the Simplex tableau. To the best of our knowledge, these constitute the first lower bounds for the learning-to-cut framework. We compare our bounds to known upper bounds in the case of neural networks and show they are nearly tight. We illustrate our results with a graph neural network selection evaluated on set covering and facility location integer programming models and we empirically show that the gap closed score is an effective proxy to minimize the branch-and-cut tree size. Although the gap closed score has been extensively used in the integer programming literature, this is the first principled analysis discussing both scores at the same time both theoretically and computationally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00252v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sammy Khalife, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>On the natural domain of Bregman operators</title>
      <link>https://arxiv.org/abs/2506.00465</link>
      <description>arXiv:2506.00465v1 Announce Type: new 
Abstract: The Bregman proximal mapping and Bregman-Moreau envelope are traditionally studied for functions defined on the entire space $\mathbb{R}^n$, even though these constructions depend only on the values of the function within (the interior of) the domain of the distance-generating function (dgf). While this convention is largely harmless in the convex setting, it leads to substantial limitations in the nonconvex case, as it fails to embrace important classes of functions such as relatively weakly convex ones. In this work, we revisit foundational aspects of Bregman analysis by adopting a domain-aware perspective: we define functions on the natural domain induced by the dgf and impose properties only relative to this set. This framework not only generalizes existing results but also rectifies and simplifies their statements and proofs. Several examples illustrate both the necessity of our assumptions and the advantages of this refined approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00465v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Themelis, Ziyuan Wang</dc:creator>
    </item>
    <item>
      <title>Preconditioned primal-dual dynamics in convex optimization: non-ergodic convergence rates</title>
      <link>https://arxiv.org/abs/2506.00501</link>
      <description>arXiv:2506.00501v1 Announce Type: new 
Abstract: We introduce and analyze a continuous primal-dual dynamical system in the context of the minimization problem $f(x)+g(Ax)$, where $f$ and $g$ are convex functions and $A$ is a linear operator. In this setting, the trajectories of the Arrow-Hurwicz continuous flow may not converge, accumulating at points that are not solutions. Our proposal is inspired by the primal-dual algorithm of Chambolle and Pock (2011), where convergence and splitting on the primal-dual variable are ensured by adequately preconditioning the proximal-point algorithm. We consider a family of preconditioners, which are allowed to depend on time and on the operator $A$, but not on the functions $f$ and $g$, and analyze asymptotic properties of the corresponding preconditioned flow. Fast convergence rates for the primal-dual gap and optimality of its (weak) limit points are obtained, in the general case, for asymptotically antisymmetric preconditioners, and, in the case of linearly constrained optimization problems, under milder hypotheses. Numerical examples support our theoretical findings, especially in favor of the antisymmetric preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00501v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vassilis Apidopoulos, Cesare Molinari, Juan Peypouquet, Silvia Villa</dc:creator>
    </item>
    <item>
      <title>Modeling and Optimal Control of Thermal Environment in Pig Houses</title>
      <link>https://arxiv.org/abs/2506.00502</link>
      <description>arXiv:2506.00502v1 Announce Type: new 
Abstract: The management of thermal environments in pig farming is crucial for optimizing animal health, productivity, and operational energy efficiency. This study introduces a novel thermal ventilation model (TVM) based on enthalpy balance, which integrates both temperature and humidity control to address the specific thermal regulation requirements of pig housing in regions characterized by high temperatures and humidity, such as Guangdong, China. These challenging environmental conditions can lead to heat stress in pigs, adversely affecting their health and productivity. The TVM provides a precise representation of thermal comfort by accounting for the combined effects of temperature and humidity. Building on the TVM, we formulate an optimization problem using Model Predictive Control (MPC), which dynamically adjusts ventilation rates in real-time by modifying weight factors to minimize energy consumption while keeping the temperature and humidity within the comfort zone of the pigs. The accuracy of the TVM is validated against real-world environmental data from pig housing facilities in Guangdong. The root mean square error of temperature in winter, spring and summer were 1.23, 0.81, and 0.60, demonstrating its reliability and robustness across diverse climatic conditions. Furthermore, simulation results show that the proposed MPC strategy significantly improves energy efficiency and environmental comfort, achieving a 100% comfort temperature zone in spring and 83% in summer, compared to 91% and 43% with traditional rule-based control, respectively. However, the model's energy consumption in summer (91.2 kWh) was higher than that of rule-based control (80.8 kWh), reflecting the trade-off between maintaining optimal comfort and energy efficiency under extreme conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00502v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingxin Wei, Jinrui Zhang, Peter Groot Koerkamp, Andre Aarnink, Congcong Sun</dc:creator>
    </item>
    <item>
      <title>Convergence rates of regularized quasi-Newton methods without strong convexity</title>
      <link>https://arxiv.org/abs/2506.00521</link>
      <description>arXiv:2506.00521v1 Announce Type: new 
Abstract: In this paper, we study convergence rates of the cubic regularized proximal quasi-Newton method (\csr) for solving non-smooth additive composite problems that satisfy the so-called Kurdyka-\L ojasiewicz (K\L ) property with respect to some desingularization function $\phi$ rather than strong convexity. After a number of iterations $k_0$, \csr\ exhibits non-asymptotic explicit super-linear convergence rates for any $k\geq k_0$. In particular, when $\phi(t)=ct^{1/2}$, Cubic SR1 PQN has a convergence rate of order $\left(\frac{C}{(k-k_0)^{1/2}}\right)^{(k-k_0)/2}$, where $k$ is the number of iterations and $C&gt;0$ is a constant. For the special case, i.e. functions which satisfy \L ojasiewicz inequality, the rate becomes global and non-asymptotic. This work presents, for the first time, non-asymptotic explicit convergence rates of regularized (proximal) SR1 quasi-Newton methods applied to non-convex non-smooth problems with K\L\ property. Actually, the rates are novel even in the smooth non-convex case. Notably, we achieve this without employing line search or trust region strategies, without assuming the Dennis-Mor\'e condition, without any assumptions on quasi-Newton metrics and without assuming strong convexity. Furthermore, for convex problems, we focus on a more tractable gradient regularized quasi-Newton method (\gsr) which can achieve results similar to those obtained with cubic regularization. We also demonstrate, for the first time, the non-asymptotic super-linear convergence rate of \gsr for solving convex problems with the help of the \L ojasiewicz inequality instead of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00521v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>${\varepsilon}$-optimality in reverse convex optimization</title>
      <link>https://arxiv.org/abs/2506.00638</link>
      <description>arXiv:2506.00638v1 Announce Type: new 
Abstract: We characterize approximate global optimal solutions (${\varepsilon}$-optima) to reverse optimization problems, namely, problems whose non-convex constraint is of the form $h(x) \geq 0$. This issue has not been addressed previously in the literature. Our idea consists of converting the reverse program into an unconstrained bicriteria DC program. The main condition presented is obtained in terms of Fenchel's ${\varepsilon}$-subdifferentials thanks to an earlier result in difference vector optimization by El Maghri. This extends and improves similar results from the literature dealing with exact (${\varepsilon} = 0$) solutions. Moreover, as we consider functions with extended values, our approach also applies to reverse problems subject to additional convex constraints, provided that Moreau-Rockafellar or Attouch-Br\'ezis constraint qualification conditions are satisfied. Similarly, new results for the special case of a nonlinear equality constraint $h(x) = 0$ are also obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00638v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. El Maghri, H. Sellak</dc:creator>
    </item>
    <item>
      <title>A Framework for Nonlinearly-Constrained Gradient-Enhanced Local Bayesian Optimization with Comparisons to Quasi-Newton Optimizers</title>
      <link>https://arxiv.org/abs/2506.00648</link>
      <description>arXiv:2506.00648v1 Announce Type: new 
Abstract: Bayesian optimization is a popular and versatile approach that is well suited to solve challenging optimization problems. Their popularity comes from their effective minimization of expensive function evaluations, their capability to leverage gradients, and their efficient use of noisy data. Bayesian optimizers have commonly been applied to global unconstrained problems, with limited development for many other classes of problems. In this paper, two alternative methods are developed that enable rapid and deep convergence of nonlinearly-constrained local optimization problems using a Bayesian optimizer. The first method uses an exact augmented Lagrangian and the second augments the minimization of the acquisition function to contain additional constraints. Both of these methods can be applied to nonlinear equality constraints, unlike most previous methods developed for constrained Bayesian optimizers. The new methods are applied with a gradient-enhanced Bayesian optimizer and enable deeper convergence for three nonlinearly-constrained unimodal optimization problems than previously developed methods for constrained Bayesian optimization. In addition, both new methods enable the Bayesian optimizer to reach a desired tolerance with fewer function evaluations than popular quasi-Newton optimizers from SciPy and MATLAB for problems with 2 to 30 variables. The Bayesian optimizer had similar results using both methods. It is recommended that users first try using the second method, which adds constraints to the acquisition function minimization, since its parameters are more intuitive to tune for new problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00648v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'e L. Marchildon, David W. Zingg</dc:creator>
    </item>
    <item>
      <title>Adversarial Reinforcement Learning: A Duality-Based Approach To Solving Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2506.00801</link>
      <description>arXiv:2506.00801v1 Announce Type: new 
Abstract: We propose an adversarial deep reinforcement learning (ADRL) algorithm for high-dimensional stochastic control problems. Inspired by the information relaxation duality, ADRL reformulates the control problem as a min-max optimization between policies and adversarial penalties, enforcing non-anticipativity while preserving optimality. Numerical experiments demonstrate ADRL's superior performance to yield tight dual gaps. Our results highlight the potential of ADRL as a robust computational framework for high-dimensional stochastic control in simulation-based optimization contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00801v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nan Chen, Mengzhou Liu, Xiaoyan Wang, Nanyi Zhang</dc:creator>
    </item>
    <item>
      <title>A geometric perspective of state estimation using Kalman filters</title>
      <link>https://arxiv.org/abs/2506.01086</link>
      <description>arXiv:2506.01086v1 Announce Type: new 
Abstract: Geometry of the state space is known to play a crucial role in many applications of Kalman filters, especially robotics and motion tracking. The Lie group-centric approach is currently very common, although a Riemannian approach has also been developed. In this work we explore the relationship between these two approaches and develop a novel description of Kalman filters based on affine connections that generalizes both commonly encountered descriptions. We illustrate the results on two test problems involving the special Euclidean group and the tangent bundle of a sphere in which the state is tracked by geometric variants of the extended Kalman filter and the unscented Kalman filter. The examples use a newly developed library GeometricKalman.jl. The new approach provides a greater freedom in selecting the structure of the state space for state estimation and can be easily integrated with standard techniques such as parameter estimation or covariance matrix estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01086v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mateusz Baran, Ronny Bergmann</dc:creator>
    </item>
    <item>
      <title>The Fastest Known First-Order Method for Minimizing Twice Continuously Differentiable Smooth Strongly Convex Functions</title>
      <link>https://arxiv.org/abs/2506.01168</link>
      <description>arXiv:2506.01168v1 Announce Type: new 
Abstract: We consider iterative gradient-based optimization algorithms applied to functions that are smooth and strongly convex. The fastest globally convergent algorithm for this class of functions is the Triple Momentum (TM) method. We show that if the objective function is also twice continuously differentiable, a new, faster algorithm emerges, which we call $C^2$-Momentum (C2M). We prove that C2M is globally convergent and that its worst-case convergence rate is strictly faster than that of TM, with no additional computational cost. We validate our theoretical findings with numerical examples, demonstrating that C2M outperforms TM when the objective function is twice continuously differentiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01168v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bryan Van Scoy, Laurent Lessard</dc:creator>
    </item>
    <item>
      <title>Turnpike property of linear quadratic control problems with unbounded control operators</title>
      <link>https://arxiv.org/abs/2506.01605</link>
      <description>arXiv:2506.01605v1 Announce Type: new 
Abstract: We establish the turnpike property for linear quadratic control problems for which the control operator is admissible and may be unbounded, under quite general and natural assumptions. The turnpike property has been well studied for bounded control operators, based on the theory of differential and algebraic Riccati equations. For unbounded control operators, there are only few results, limited to some special cases of hyperbolic systems in dimension one or to analytic semigroups. Our analysis is inspired by the pioneering work of Porretta and Zuazua \cite{PZ13}. We start by approximating the admissible control operator with a sequence of bounded ones. We then prove the convergence of the approximate problems to the initial one in a suitable sense. Establishing this convergence is the core of the paper. It requires to revisit in some sense the linear quadratic optimal control theory with admissible control operators, in which the roles of energy and adjoint states, and the connection between infinite-horizon and finite-horizon optimal control problems with an appropriate final cost are investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01605v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoai-Minh Nguyen, Emmanuel Tr\'elat</dc:creator>
    </item>
    <item>
      <title>Lipschitz-Free Mirror Descent Methods for Non-Smooth Optimization Problems</title>
      <link>https://arxiv.org/abs/2506.01681</link>
      <description>arXiv:2506.01681v1 Announce Type: new 
Abstract: The part of the analysis of the convergence rate of the mirror descent method that is connected with the adaptive time-varying step size rules due to Alkousa et al. (MOTOR 2024, pp. 3-18) is corrected. Moreover, a Lipschitz-free mirror descent method that achieves weak ergodic convergence is presented, generalizing the convergence results of the mirror descent method in the absence of the Lipschitz assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01681v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Yuan, Mohammad S. Alkousa</dc:creator>
    </item>
    <item>
      <title>Two-stage Distributionally Robust Optimization for Cross-dock Door Design</title>
      <link>https://arxiv.org/abs/2506.01694</link>
      <description>arXiv:2506.01694v1 Announce Type: new 
Abstract: The cross-dock door design problem consists of deciding the strip and stack doors and nominal capacity of an entity under uncertainty. Inbound commodity flow from origin nodes is assigned to the strip doors, it is consolidated in the entity, and the outbound flow is assigned to the stack ones for being delivered to destination nodes, at a minimum cost. The problem combines three highly computational difficulties, namely, NP-hard combinatorics, uncertainty in the main parameters and their probability distribution. Distributionally robust optimization is considered to deal with these uncertainties. Its related two-stage mixed binary quadratic model is presented for cross-dock problem-solving; the first stage decisions are related to the design of the entity; the second stage ones are related to the assignment of the commodity flow to the doors in a finite set of scenarios for the ambiguity set members. The goal is to minimize the highest total cost in the ambiguity set, subject to the constraint system for each of those members and the stochastic dominance risk averse functional. As far as we know, the challenging problem that results has not been addressed before, although its application field is a very broad one. Given the problem-solving difficulty, a scenario cluster decomposition and a min-max based matheuristic are proposed for obtaining lower and upper bounds, respectively. A computational study validates the proposal; it overperformances the straightforward use of the state-of-the-art solvers Cplex and Gurobi.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01694v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laureano F. Escudero, M. Araceli Gar\'in, Aitziber Unzueta</dc:creator>
    </item>
    <item>
      <title>Tight Convergence Rates in Gradient Mapping for the Difference-of-Convex Algorithm</title>
      <link>https://arxiv.org/abs/2506.01791</link>
      <description>arXiv:2506.01791v1 Announce Type: new 
Abstract: We establish new theoretical convergence guarantees for the difference-of-convex algorithm (DCA), where the second function is allowed to be weakly-convex, measuring progress via composite gradient mapping. Based on a tight analysis of two iterations of DCA, we identify six parameter regimes leading to sublinear convergence rates toward critical points and establish those rates by proving adapted descent lemmas. We recover existing rates for the standard difference-of-convex decompositions of nonconvex-nonconcave functions, while for all other curvature settings our results are new, complementing recently obtained rates on the gradient residual. Three of our sublinear rates are tight for any number of DCA iterations, while for the other three regimes we conjecture exact rates, using insights from the tight analysis of gradient descent and numerical validation using the performance estimation methodology. Finally, we show how the equivalence between proximal gradient descent (PGD) and DCA allows the derivation of exact PGD rates for any constant stepsize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01791v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Teodor Rotaru, Panagiotis Patrinos, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>An adaptive data sampling strategy for stabilizing dynamical systems via controller inference</title>
      <link>https://arxiv.org/abs/2506.01816</link>
      <description>arXiv:2506.01816v1 Announce Type: new 
Abstract: Learning stabilizing controllers from data is an important task in engineering applications; however, collecting informative data is challenging because unstable systems often lead to rapidly growing or erratic trajectories. In this work, we propose an adaptive sampling scheme that generates data while simultaneously stabilizing the system to avoid instabilities during the data collection. Under mild assumptions, the approach provably generates data sets that are informative for stabilization and have minimal size. The numerical experiments demonstrate that controller inference with the novel adaptive sampling approach learns controllers with up to one order of magnitude fewer data samples than unguided data generation. The results show that the proposed approach opens the door to stabilizing systems in edge cases and limit states where instabilities often occur and data collection is inherently difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01816v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen W. R. Werner, Benjamin Peherstorfer</dc:creator>
    </item>
    <item>
      <title>On the regularization property of Levenberg-Marquardt method with Singular Scaling for nonlinear inverse problems</title>
      <link>https://arxiv.org/abs/2506.00190</link>
      <description>arXiv:2506.00190v1 Announce Type: cross 
Abstract: Recently, in Applied Mathematics and Computation 474 (2024) 128688, a Levenberg-Marquardt method (LMM) with Singular Scaling was analyzed and successfully applied in parameter estimation problems in heat conduction where the use of a particular singular scaling matrix (semi-norm regularizer) provided approximate solutions of better quality than those of the classic LMM. Here we propose a regularization framework for the Levenberg-Marquardt method with Singular Scaling (LMMSS) applied to nonlinear inverse problems with noisy data. Assuming that the noise-free problem admits exact solutions (zero-residual case), we consider the LMMSS iteration where the regularization effect is induced by the choice of a possibly singular scaling matrix and an implicit control of the regularization parameter. The discrepancy principle is used to define a stopping index that ensures stability of the computed solutions with respect to data perturbations. Under a new Tangent Cone Condition, we prove that the iterates obtained with noisy data converge to a solution of the unperturbed problem as the noise level tends to zero. This work represents a first step toward the analysis of regularizing properties of the LMMSS method and extends previous results in the literature on regularizing LM-type methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00190v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafaela Filippozzi, Everton Boos, Douglas S. Gon\c{c}alves, Fermin S. V. Baz\'an</dc:creator>
    </item>
    <item>
      <title>Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model</title>
      <link>https://arxiv.org/abs/2506.00286</link>
      <description>arXiv:2506.00286v1 Announce Type: cross 
Abstract: In this paper we analyze the sample complexities of learning the optimal state-action value function $Q^*$ and an optimal policy $\pi^*$ in a discounted Markov decision process (MDP) where the agent has recursive entropic risk-preferences with risk-parameter $\beta\neq 0$ and where a generative model of the MDP is available. We provide and analyze a simple model based approach which we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which leads to $(\epsilon,\delta)$-PAC-bounds on $\|Q^*-Q^k\|$, and $\|V^*-V^{\pi_k}\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations and $\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have exponential dependence on the effective horizon $\frac{1}{1-\gamma}$ and the strength of this dependence grows with the learners risk-sensitivity $|\beta|$. We also provide two lower bounds which shows that exponential dependence on $|\beta|\frac{1}{1-\gamma}$ is unavoidable in both cases. The lower bounds reveal that the PAC-bounds are both tight in $\varepsilon$ and $\delta$ and that the PAC-bound on $Q$-learning is tight in the number of actions $A$, and that the PAC-bound on policy-learning is nearly tight in $A$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00286v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Mortensen, Mohammad Sadegh Talebi</dc:creator>
    </item>
    <item>
      <title>Full- and low-rank exponential midpoint schemes for forward and adjoint Lindblad equations</title>
      <link>https://arxiv.org/abs/2506.00346</link>
      <description>arXiv:2506.00346v1 Announce Type: cross 
Abstract: The Lindblad equation is a widely used quantum master equation to model the dynamical evolution of open quantum systems whose states are described by density matrices. This equation is also a fundamental building block to design optimal control functions. In this paper we develop full- and low-rank exponential midpoint integrators for solving both the forward and adjoint Lindblad equations. These schemes are applicable to optimize-then-discretize approaches for optimal control of open quantum systems. We show that the proposed schemes preserve positivity and trace unconditionally. Furthermore, convergence of these numerical schemes is proved theoretically and verified numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00346v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Chen, Alfio Borzi</dc:creator>
    </item>
    <item>
      <title>FSNet: Feasibility-Seeking Neural Network for Constrained Optimization with Guarantees</title>
      <link>https://arxiv.org/abs/2506.00362</link>
      <description>arXiv:2506.00362v1 Announce Type: cross 
Abstract: Efficiently solving constrained optimization problems is crucial for numerous real-world applications, yet traditional solvers are often computationally prohibitive for real-time use. Machine learning-based approaches have emerged as a promising alternative to provide approximate solutions at faster speeds, but they struggle to strictly enforce constraints, leading to infeasible solutions in practice. To address this, we propose the Feasibility-Seeking-Integrated Neural Network (FSNet), which integrates a feasibility-seeking step directly into its solution procedure to ensure constraint satisfaction. This feasibility-seeking step solves an unconstrained optimization problem that minimizes constraint violations in a differentiable manner, enabling end-to-end training and providing guarantees on feasibility and convergence. Our experiments across a range of different optimization problems, including both smooth/nonsmooth and convex/nonconvex problems, demonstrate that FSNet can provide feasible solutions with solution quality comparable to (or in some cases better than) traditional solvers, at significantly faster speeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00362v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang T. Nguyen, Priya L. Donti</dc:creator>
    </item>
    <item>
      <title>Deterministic Kalman filters for uncertain dynamical systems</title>
      <link>https://arxiv.org/abs/2506.00463</link>
      <description>arXiv:2506.00463v1 Announce Type: cross 
Abstract: The Kalman(-Bucy) filter is the natural choice for the state reconstruction of disturbed, linear dynamical systems based on flawed and incomplete measurements. Taking a deterministic viewpoint this work investigates possible extensions of the concept to systems with uncertain dynamics and noise covariances. In a theoretical analysis error bounds in terms of the variance of the uncertainties are derived. The article concludes with a numerical implementation of two example systems allowing for a comparison of the estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00463v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Kunisch, Jesper Schr\"oder</dc:creator>
    </item>
    <item>
      <title>Thinking Out of the Box: Hybrid SAT Solving by Unconstrained Continuous Optimization</title>
      <link>https://arxiv.org/abs/2506.00674</link>
      <description>arXiv:2506.00674v1 Announce Type: cross 
Abstract: The Boolean satisfiability (SAT) problem lies at the core of many applications in combinatorial optimization, software verification, cryptography, and machine learning. While state-of-the-art solvers have demonstrated high efficiency in handling conjunctive normal form (CNF) formulas, numerous applications require non-CNF (hybrid) constraints, such as XOR, cardinality, and Not-All-Equal constraints. Recent work leverages polynomial representations to represent such hybrid constraints, but it relies on box constraints that can limit the use of powerful unconstrained optimizers. In this paper, we propose unconstrained continuous optimization formulations for hybrid SAT solving by penalty terms. We provide theoretical insights into when these penalty terms are necessary and demonstrate empirically that unconstrained optimizers (e.g., Adam) can enhance SAT solving on hybrid benchmarks. Our results highlight the potential of combining continuous optimization and machine-learning-based methods for effective hybrid SAT solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00674v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiwei Zhang, Samy Wu Fung, Anastasios Kyrillidis, Stanley Osher, Moshe Y. Vardi</dc:creator>
    </item>
    <item>
      <title>Action Dependency Graphs for Globally Optimal Coordinated Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2506.00797</link>
      <description>arXiv:2506.00797v1 Announce Type: cross 
Abstract: Action-dependent individual policies, which incorporate both environmental states and the actions of other agents in decision-making, have emerged as a promising paradigm for achieving global optimality in multi-agent reinforcement learning (MARL). However, the existing literature often adopts auto-regressive action-dependent policies, where each agent's policy depends on the actions of all preceding agents. This formulation incurs substantial computational complexity as the number of agents increases, thereby limiting scalability. In this work, we consider a more generalized class of action-dependent policies, which do not necessarily follow the auto-regressive form. We propose to use the `action dependency graph (ADG)' to model the inter-agent action dependencies. Within the context of MARL problems structured by coordination graphs, we prove that an action-dependent policy with a sparse ADG can achieve global optimality, provided the ADG satisfies specific conditions specified by the coordination graph. Building on this theoretical foundation, we develop a tabular policy iteration algorithm with guaranteed global optimality. Furthermore, we integrate our framework into several SOTA algorithms and conduct experiments in complex environments. The empirical results affirm the robustness and applicability of our approach in more general scenarios, underscoring its potential for broader MARL challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00797v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianglin Ding, Jingcheng Tang, Gangshan Jing</dc:creator>
    </item>
    <item>
      <title>Constant-Factor Algorithms for Revenue Management with Consecutive Stays</title>
      <link>https://arxiv.org/abs/2506.00909</link>
      <description>arXiv:2506.00909v1 Announce Type: cross 
Abstract: We study network revenue management problems motivated by applications such as railway ticket sales and hotel room bookings. Request types that require a resource for consecutive stays sequentially arrive with known arrival probabilities. We investigate two scenarios: the reject-or-accept scenario, where the request can be fulfilled by any available resource, and the choice-based scenario, which generalizes the former by incorporating customer preferences through basic attraction models. We develop constant-factor approximation algorithms: $1-1/e$ for the reject-or-accept scenario and $0.125$ for the choice-based scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00909v1</guid>
      <category>econ.TH</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Hu, Tongwen Wu</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Random Time Horizons</title>
      <link>https://arxiv.org/abs/2506.00962</link>
      <description>arXiv:2506.00962v1 Announce Type: cross 
Abstract: We extend the standard reinforcement learning framework to random time horizons. While the classical setting typically assumes finite and deterministic or infinite runtimes of trajectories, we argue that multiple real-world applications naturally exhibit random (potentially trajectory-dependent) stopping times. Since those stopping times typically depend on the policy, their randomness has an effect on policy gradient formulas, which we (mostly for the first time) derive rigorously in this work both for stochastic and deterministic policies. We present two complementary perspectives, trajectory or state-space based, and establish connections to optimal control theory. Our numerical experiments demonstrate that using the proposed formulas can significantly improve optimization convergence compared to traditional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00962v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enric Ribera Borrell, Lorenz Richter, Christof Sch\"utte</dc:creator>
    </item>
    <item>
      <title>A Finite-Time Analysis of TD Learning with Linear Function Approximation without Projections nor Strong Convexity</title>
      <link>https://arxiv.org/abs/2506.01052</link>
      <description>arXiv:2506.01052v1 Announce Type: cross 
Abstract: We investigate the finite-time convergence properties of Temporal Difference (TD) learning with linear function approximation, a cornerstone algorithm in reinforcement learning. While prior work has established convergence guarantees, these results typically rely on the assumption that each iterate is projected onto a bounded set or that the learning rate is set according to the unknown strong convexity constant -- conditions that are both artificial and do not match the current practice.
  In this paper, we challenge the necessity of such assumptions and present a refined analysis of TD learning. We show that the simple projection-free variant converges with a rate of $\tilde{\mathcal{O}}(\frac{||\theta^*||^2_2}{\sqrt{T}})$, even in the presence of Markovian noise. Our analysis reveals a novel self-bounding property of the TD updates and exploits it to guarantee bounded iterates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01052v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei-Cheng Lee, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>Linear regression with overparameterized linear neural networks: Tight upper and lower bounds for implicit $\ell^1$-regularization</title>
      <link>https://arxiv.org/abs/2506.01143</link>
      <description>arXiv:2506.01143v1 Announce Type: cross 
Abstract: Modern machine learning models are often trained in a setting where the number of parameters exceeds the number of training samples. To understand the implicit bias of gradient descent in such overparameterized models, prior work has studied diagonal linear neural networks in the regression setting. These studies have shown that, when initialized with small weights, gradient descent tends to favor solutions with minimal $\ell^1$-norm - an effect known as implicit regularization. In this paper, we investigate implicit regularization in diagonal linear neural networks of depth $D\ge 2$ for overparameterized linear regression problems. We focus on analyzing the approximation error between the limit point of gradient flow trajectories and the solution to the $\ell^1$-minimization problem. By deriving tight upper and lower bounds on the approximation error, we precisely characterize how the approximation error depends on the scale of initialization $\alpha$. Our results reveal a qualitative difference between depths: for $D \ge 3$, the error decreases linearly with $\alpha$, whereas for $D=2$, it decreases at rate $\alpha^{1-\varrho}$, where the parameter $\varrho \in [0,1)$ can be explicitly characterized. Interestingly, this parameter is closely linked to so-called null space property constants studied in the sparse recovery literature. We demonstrate the asymptotic tightness of our bounds through explicit examples. Numerical experiments corroborate our theoretical findings and suggest that deeper networks, i.e., $D \ge 3$, may lead to better generalization, particularly for realistic initialization scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01143v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hannes Matt, Dominik St\"oger</dc:creator>
    </item>
    <item>
      <title>Near-feasible Fair Allocations in Two-sided Markets</title>
      <link>https://arxiv.org/abs/2506.01178</link>
      <description>arXiv:2506.01178v1 Announce Type: cross 
Abstract: We study resource allocation in two-sided markets from a fundamental perspective and introduce a general modeling and algorithmic framework to effectively incorporate the complex and multidimensional aspects of fairness. Our main technical contribution is to show the existence of a range of near-feasible resource allocations parameterized in different model primitives to give flexibility when balancing the different policymaking requirements, allowing policy designers to fix these values according to the specific application. To construct our near-feasible allocations, we start from a fractional resource allocation and perform an iterative rounding procedure to get an integer allocation. We show a simple yet flexible and strong sufficient condition for the target feasibility deviations to guarantee that the rounding procedure succeeds, exhibiting the underlying trade-offs between market capacities, agents' demand, and fairness. To showcase our framework's modeling and algorithmic capabilities, we consider three prominent market design problems: school allocation, stable matching with couples, and political apportionment. In each of them, we obtain strengthened guarantees on the existence of near-feasible allocations capturing the corresponding fairness notions, such as proportionality, envy-freeness, and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01178v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Andr\'es Moraga, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>A mean field game model with non-local spatial interactions and resources accumulation</title>
      <link>https://arxiv.org/abs/2506.01200</link>
      <description>arXiv:2506.01200v1 Announce Type: cross 
Abstract: We study a family of Mean Field Games arising in modeling the behavior of strategic economic agents which move across space maximizing their utility from consumption and have the possibility to accumulate resources for production (such as human capital). The resulting mean field game PDE system is not covered in the actual literature on the topic as it displays weaker assumptions on the regularity of the data (in particular Lipschitz continuity and boundedness of the objective are lost), state constraints, and a non-standard interaction term. We obtain a first result on the existence of solution of the mean field game PDE system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01200v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daria Ghilli, Fausto Gozzi, Cristiano Ricci, Giovanni Zanco</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Learning in Survival Analysis</title>
      <link>https://arxiv.org/abs/2506.01348</link>
      <description>arXiv:2506.01348v1 Announce Type: cross 
Abstract: We introduce an innovative approach that incorporates a Distributionally Robust Learning (DRL) approach into Cox regression to enhance the robustness and accuracy of survival predictions. By formulating a DRL framework with a Wasserstein distance-based ambiguity set, we develop a variant Cox model that is less sensitive to assumptions about the underlying data distribution and more resilient to model misspecification and data perturbations. By leveraging Wasserstein duality, we reformulate the original min-max DRL problem into a tractable regularized empirical risk minimization problem, which can be computed by exponential conic programming. We provide guarantees on the finite sample behavior of our DRL-Cox model. Moreover, through extensive simulations and real world case studies, we demonstrate that our regression model achieves superior performance in terms of prediction accuracy and robustness compared with traditional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01348v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeping Jin, Lauren Wise, Ioannis Paschalidis</dc:creator>
    </item>
    <item>
      <title>Update-Aware Robust Optimal Model Predictive Control for Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2506.01729</link>
      <description>arXiv:2506.01729v1 Announce Type: cross 
Abstract: Robust optimal or min-max model predictive control (MPC) approaches aim to guarantee constraint satisfaction over a known, bounded uncertainty set while minimizing a worst-case performance bound. Traditionally, these methods compute a trajectory that meets the desired properties over a fixed prediction horizon, apply a portion of the resulting input, and then re-solve the MPC problem using newly obtained measurements at the next time step. However, this approach fails to account for the fact that the control trajectory will be updated in the future, potentially leading to conservative designs. In this paper, we present a novel update-aware robust optimal MPC algorithm for decreasing horizon problems on nonlinear systems that explicitly accounts for future control trajectory updates. This additional insight allows our method to provably expand the feasible solution set and guarantee improved worst-case performance bounds compared to existing techniques. Our approach formulates the trajectory generation problem as a sequence of nested existence-constrained semi-infinite programs (SIPs), which can be efficiently solved using local reduction techniques. To demonstrate its effectiveness, we evaluate our approach on a planar quadrotor problem, where it clearly outperforms an equivalent method that does not account for future updates at the cost of increased computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01729v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J. Wehbeh, E. C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>MLorc: Momentum Low-rank Compression for Large Language Model Adaptation</title>
      <link>https://arxiv.org/abs/2506.01897</link>
      <description>arXiv:2506.01897v1 Announce Type: cross 
Abstract: With increasing size of large language models (LLMs), full-parameter fine-tuning imposes substantial memory demands. To alleviate this, we propose a novel memory-efficient training paradigm called Momentum Low-rank compression (MLorc). By directly compressing and reconstructing momentum rather than gradients, MLorc avoids imposing a fixed-rank constraint on weight update matrices and better preserves the training dynamics of full-parameter fine-tuning, in contrast to existing low-rank approaches such as LoRA and GaLore. Empirically, MLorc consistently outperforms other memory-efficient training methods, matches or even exceeds the performance of full fine-tuning with a small rank (e.g., $r=4$), and generalizes well across different optimizers -- all while not compromising time or memory efficiency. Furthermore, we provide a theoretical guarantee for its convergence under reasonable assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01897v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Shen, Yaxiang Zhang, Minhui Huang, Mengfan Xu, Jiawei Zhang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>A symmetric primal-dual algorithmic framework for saddle point problems</title>
      <link>https://arxiv.org/abs/2212.07587</link>
      <description>arXiv:2212.07587v3 Announce Type: replace 
Abstract: In this paper, we propose a new primal-dual algorithmic framework for a class of convex-concave saddle point problems frequently arising from image processing and machine learning. Our algorithmic framework updates the primal variable between the twice calculations of the dual variable, thereby appearing a symmetric iterative scheme, which is accordingly called the symmetric primal-dual algorithm (SPIDA). It is noteworthy that the subproblems of our SPIDA are equipped with Bregman proximal regularization terms, which make SPIDA versatile in the sense that it enjoys an algorithmic framework to understand the iterative schemes of some existing algorithms, such as the classical augmented Lagrangian method (ALM), linearized ALM, and Jacobian splitting algorithms for linearly constrained optimization problems. Besides, our algorithmic framework allows us to derive some customized versions so that SPIDA works as efficiently as possible for structured optimization problems. Theoretically, under some mild conditions, we prove the global convergence of SPIDA and estimate the linear convergence rate under a generalized error bound condition defined by Bregman distance. Finally, a series of numerical experiments on the basis pursuit, robust principal component analysis, and image restoration demonstrate that our SPIDA works well on synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.07587v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hongjin He, Kai Wang, Jintao Yu</dc:creator>
    </item>
    <item>
      <title>Nash Equilibria, Regularization and Computation in Optimal Transport-Based Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2303.03900</link>
      <description>arXiv:2303.03900v3 Announce Type: replace 
Abstract: We study optimal transport-based distributionally robust optimization problems where a fictitious adversary, often envisioned as nature, can choose the distribution of the uncertain problem parameters by reshaping a prescribed reference distribution at a finite transportation cost. In this framework, we show that robustification is intimately related to various forms of variation and Lipschitz regularization even if the transportation cost function fails to be (some power of) a metric. We also derive conditions for the existence and the computability of a Nash equilibrium between the decision-maker and nature, and we demonstrate numerically that nature's Nash strategy can be viewed as a distribution that is supported on remarkably deceptive adversarial samples. Finally, we identify practically relevant classes of optimal transport-based distributionally robust optimization problems that can be addressed with efficient gradient descent algorithms even if the loss function or the transportation cost function are nonconvex (but not both at the same time).</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03900v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soroosh Shafiee, Liviu Aolaritei, Florian D\"orfler, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Load Asymptotics and Dynamic Speed Optimization for the Greenest Path Problem: A Comprehensive Analysis</title>
      <link>https://arxiv.org/abs/2306.01687</link>
      <description>arXiv:2306.01687v2 Announce Type: replace 
Abstract: We study the effect of using high-resolution elevation data on the selection of the most fuel-efficient(greenest) path for different trucks in various urban environments.We adapt a variant of the Comprehensive Modal Emission Model(CMEM) to show that the optimal speed and the greenest path are slope dependent (dynamic).When there are no elevation changes in a road network, the most fuel-efficient path is the shortest path with a constant (static) optimal speed throughout.However, if the network is not flat, then the shortest path is not necessarily the greenest path, and the optimal driving speed is dynamic.We prove that the greenest path converges to an asymptotic greenest path as the payload approaches infinity and that this limiting path is attained for a finite load.In a set of extensive numerical experiments, we benchmark the CO2emissions reduction of our dynamic speed and the greenest path policies against policies that ignore elevation data.We use the geospatial data of 25major cities across 6continents.We observe numerically that the greenest path quickly diverges from the shortest path and attains the asymptotic greenest path even for moderate payloads.Based on an analysis of variance, the main determinants of the CO2emissions reduction potential are the variation of the road gradients along the shortest path as well as the relative elevation of the source from the target.Using speed data estimates for rush hour in New York City, we test CO2emissions reduction by comparing the greenest paths with optimized speeds against the fastest paths with traffic speed.We observe that selecting the greenest paths instead of the fastest paths can significantly reduce CO2emissions.Additionally,our results show that while speed optimization on uphill arcs can significantly help CO2reduction,the potential to leverage gravity for acceleration on downhill arcs is limited due to traffic congestion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01687v2</guid>
      <category>math.OC</category>
      <category>econ.EM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00291-024-00793-9</arxiv:DOI>
      <dc:creator>Poulad Moradi, Joachim Arts, Josu\'e C. Vel\'azquez-Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Moving Anchor Extragradient Methods For Smooth Structured Minimax Problems</title>
      <link>https://arxiv.org/abs/2308.12359</link>
      <description>arXiv:2308.12359v3 Announce Type: replace 
Abstract: This work introduces a moving anchor acceleration technique to extragradient algorithms for smooth structured minimax problems. The moving anchor is introduced as a generalization of the original algorithmic anchoring framework, i.e. the EAG method introduced in [32], in hope of further acceleration. We show that the optimal order of convergence in terms of worst-case complexity on the squared gradient, O(1/k2), is achieved by our new method (where k is the number of iterations). We have also extended our algorithm to a more general nonconvex-nonconcave class of saddle point problems using the framework of [14], which slightly generalizes [32]. We obtain similar order-optimal complexity results in this extended case. In both problem settings, numerical results illustrate the efficacy of our moving anchor algorithm variants, in particular by attaining the theoretical optimal convergence rate for first order methods, as well as suggesting a better optimized constant in the big O notation which surpasses the traditional fixed anchor methods in many cases. A proximal-point preconditioned version of our algorithms is also introduced and analyzed to match optimal theoretical convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12359v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>James K. Alcala, Yat Tin Chow, Mahesh Sunkula</dc:creator>
    </item>
    <item>
      <title>Mean-field games of speedy information access with observation costs</title>
      <link>https://arxiv.org/abs/2309.07877</link>
      <description>arXiv:2309.07877v3 Announce Type: replace 
Abstract: We investigate mean-field games (MFG) in which agents can actively control their speed of access to information. Specifically, the agents can dynamically decide to obtain observations with reduced delay by accepting higher observation costs. Agents seek to exploit their active information acquisition by making further decisions to influence their state dynamics so as to maximise rewards. In a mean-field equilibrium, each generic agent solves individually a partially observed Markov decision problem in which the way partial observations are obtained is itself subject to dynamic control actions, while no agent can improve unilaterally given the actions of all others. We formulate the mean-field game with controlled costly information access as an equivalent standard mean-field game on an augmented space, by utilizing a parameterisation of the belief state by a finite number of variables. With sufficient entropy regularisation, a fixed point iteration converges to the unique MFG equilibrium. Moreover, we derive an approximate $\varepsilon$-Nash equilibrium for a large but finite population size and small regularisation parameter. We illustrate our (extended) MFG of information access and of controls by an example from epidemiology, where medical testing results can be procured at different speeds and costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07877v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dirk Becherer, Christoph Reisinger, Jonathan Tam</dc:creator>
    </item>
    <item>
      <title>Data-driven h2 model reduction for linear discrete-time systems</title>
      <link>https://arxiv.org/abs/2401.05774</link>
      <description>arXiv:2401.05774v2 Announce Type: replace 
Abstract: We present a new framework of $h^{2}$ optimal model reduction for linear discrete-time systems. Our main contribution is to create optimal reduced-order models in the $h^{2}$-norm sense directly from the measurement data alone, without using the information of the original system. In particular, we focus on the fact that the gradient of the $h^{2}$ model reduction problem is expressed using the discrete-time Lyapunov equation and the discrete-time Sylvester equation, and derive the data-driven gradient. In the proposed algorithm, the initial point can be chosen as the output of the existing data-driven methods. In numerical experiments, we demonstrate that, for a modeling task in neuroscience, our method constructs a reduced-order model that outperforms DMDc in terms of the $h^2$-norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05774v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroki Sakamoto, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Algebraic Riccati Tensor Equations with Applications in Multilinear Control Systems</title>
      <link>https://arxiv.org/abs/2402.13491</link>
      <description>arXiv:2402.13491v3 Announce Type: replace 
Abstract: In a recent paper by Chen et al. [9], the authors initiated the control-theoretic study of a class of discrete-time multilinear time-invariant (MLTI) control systems, where system states, inputs, and outputs are all tensors endowed with the Einstein product. They established criteria for fundamental system-theoretic notions such as stability, reachability, and observability through tensor decomposition. Building on this new research direction, the purpose of our paper is to extend the study to continuous-time MLTI control systems. Specifically, we define Hamiltonian tensors and symplectic tensors, and we establish the Schur-Hamiltonian tensor decomposition and the symplectic tensor singular value decomposition (SVD). Based on these concepts, we propose the algebraic Riccati tensor equation (ARTE) and demonstrate that it has a unique positive semidefinite solution if the system is stabilizable and detectable. To find numerical solutions to the ARTE, we introduce a tensor-based Newton method. Additionally, we establish the tensor versions of the bounded real lemma and the small gain theorem. A first-order robustness analysis of the ARTE is also conducted. Finally, we provide a numerical example to illustrate the proposed theory and algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13491v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchao Wang, Yimin Wei, Guofeng Zhang, Shih Yu Chang</dc:creator>
    </item>
    <item>
      <title>Consensus-based algorithms for stochastic optimization problems</title>
      <link>https://arxiv.org/abs/2404.10372</link>
      <description>arXiv:2404.10372v3 Announce Type: replace 
Abstract: We address an optimization problem where the cost function is the expectation of a random mapping. To tackle the problem two approaches based on the approximation of the objective function by consensus-based particle optimization methods on the search space are developed. The resulting methods are mathematically analyzed using a mean-field approximation and their connection is established. Several numerical experiments show the validity of the proposed algorithms and investigate their rates of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10372v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sabrina Bonandin, Michael Herty</dc:creator>
    </item>
    <item>
      <title>Primal-dual proximal bundle and conditional gradient methods for convex problems</title>
      <link>https://arxiv.org/abs/2412.00585</link>
      <description>arXiv:2412.00585v3 Announce Type: replace 
Abstract: This paper studies the primal-dual convergence and iteration-complexity of proximal bundle methods for solving nonsmooth problems with convex structures. More specifically, we develop a family of primal-dual proximal bundle methods for solving convex nonsmooth composite optimization problems and establish the iteration-complexity in terms of a primal-dual gap. We also propose a class of proximal bundle methods for solving convex-concave nonsmooth composite saddle-point problems and establish the iteration-complexity to find an approximate saddle-point. This paper places special emphasis on the primal-dual perspective of the proximal bundle method. In particular, we discover an interesting duality between the conditional gradient method and the cutting-plane scheme used within the proximal bundle method. Leveraging this duality, we further develop novel variants of both the conditional gradient method and the cutting-plane scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00585v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>A General Solution to Bellman's Lost-in-a-forest Problem</title>
      <link>https://arxiv.org/abs/2412.10686</link>
      <description>arXiv:2412.10686v3 Announce Type: replace 
Abstract: We present a general solution and formulation framework to Bellman's lost-in-a-forest problem. The forest boundary is known and may take any shape. The starting point and the orientation are unspecified. We convert the problem into translation and rotation of the forest boundary. This transformation allows us to formulate this problem as a constrained minimization problem. Upon discretization, the problem becomes a variation of the traveling salesman problem or the Hamiltonian path problem. We leverage discrete optimization and derive several nontrivial results consistent with those from previous papers. This method is general, and we also extend the approach to related problems, including Moser's worm problem and the shortest opaque set problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10686v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhipeng Deng</dc:creator>
    </item>
    <item>
      <title>Inexact Proximal Point Algorithms for Zeroth-Order Global Optimization</title>
      <link>https://arxiv.org/abs/2412.11485</link>
      <description>arXiv:2412.11485v4 Announce Type: replace 
Abstract: This work concerns the zeroth-order global minimization of continuous nonconvex functions with a unique global minimizer and possibly multiple local minimizers. We formulate a theoretical framework for inexact proximal point (IPP) methods for global optimization, establishing convergence guarantees under mild assumptions when either deterministic or stochastic estimates of proximal operators are used. The quadratic regularization in the proximal operator and the scaling effect of a parameter $\delta&gt;0$ create a concentrated landscape of an associated Gibbs measure that is practically effective for sampling. The convergence of the expectation under the Gibbs measure as $\delta\to 0^+$ is established, and the convergence rate of $\mathcal O(\delta)$ is derived under additional assumptions. These results provide a theoretical foundation for evaluating proximal operators inexactly using sampling-based methods such as Monte Carlo (MC) integration. In addition, we propose a new approach based on tensor train (TT) approximation. This approach employs a randomized TT cross algorithm to efficiently construct a low-rank TT approximation of a discretized function using a small number of function evaluations, and we provide an error analysis for the TT-based estimation. We then propose two practical IPP algorithms, TT-IPP and MC-IPP. The TT-IPP algorithm leverages TT estimates of the proximal operators, while the MC-IPP algorithm employs MC integration to estimate the proximal operators. Both algorithms are designed to adaptively balance efficiency and accuracy in inexact evaluations of proximal operators. The effectiveness of the two algorithms is demonstrated through experiments on diverse benchmark functions and various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11485v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minxin Zhang, Fuqun Han, Yat Tin Chow, Stanley Osher, Hayden Schaeffer</dc:creator>
    </item>
    <item>
      <title>Stochastic interior-point methods for smooth conic optimization with applications</title>
      <link>https://arxiv.org/abs/2412.12987</link>
      <description>arXiv:2412.12987v2 Announce Type: replace 
Abstract: Conic optimization plays a crucial role in many machine learning (ML) problems. However, practical algorithms for conic constrained ML problems with large datasets are often limited to specific use cases, as stochastic algorithms for general conic optimization remain underdeveloped. To fill this gap, we introduce a stochastic interior-point method (SIPM) framework for general conic optimization, along with four novel SIPM variants leveraging distinct stochastic gradient estimators. Under mild assumptions, we establish the iteration complexity of our proposed SIPMs, which, up to a polylogarithmic factor, match the best-known results in stochastic unconstrained optimization. Finally, our numerical experiments on robust linear regression, multi-task relationship learning, and clustering data streams demonstrate the effectiveness and efficiency of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12987v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Zhanwang Deng</dc:creator>
    </item>
    <item>
      <title>A Note on the Convergence of Muon</title>
      <link>https://arxiv.org/abs/2502.02900</link>
      <description>arXiv:2502.02900v2 Announce Type: replace 
Abstract: In this note, we inspect the convergence of a new optimizer for pretraining LLMs, namely the Muon optimizer. Such an optimizer is closely related to a specialized steepest descent method where the update direction is the minimizer of the quadratic approximation of the objective function under spectral norm. We provide the convergence analysis on both versions of the optimizer and discuss its implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02900v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxiang Li, Mingyi Hong</dc:creator>
    </item>
    <item>
      <title>Local convergence analysis of stabilized sequential quadratic programming methods for optimization problems in Banach spaces</title>
      <link>https://arxiv.org/abs/2503.11998</link>
      <description>arXiv:2503.11998v2 Announce Type: replace 
Abstract: This paper presents a stabilized sequential quadratic programming (SQP) method for solving optimization problems in Banach spaces. The optimization problem considered in this study has a general form that enables us to represent various types of optimization problems and is particularly applicable to optimal control, obstacle, and shape optimization problems. Several SQP methods have been proposed for optimization problems in Banach spaces with specific structures; however, research on the local analysis of SQP-type methods for general problems, such as those considered in this study, is limited. We focus on the local behavior of the proposed stabilized SQP method and prove its local quadratic convergence under reasonable assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11998v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuya Yamakawa</dc:creator>
    </item>
    <item>
      <title>Bang-Bang Optimal Control of Vaccination in Metapopulation Epidemics with Linear Cost Structures</title>
      <link>https://arxiv.org/abs/2503.15154</link>
      <description>arXiv:2503.15154v4 Announce Type: replace 
Abstract: This paper investigates optimal vaccination strategies in a metapopulation epidemic model. We consider a linear cost to better capture operational considerations, such as the total number of vaccines or hospitalizations, in contrast to the standard quadratic cost assumption on the control. The model incorporates state and mixed control-state constraints, and we derive necessary optimality conditions based on Pontryagin's Maximum Principle. We use Pontryagin's result to rule out the possibility of the occurrence of singular arcs and to provide a full characterization of the optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15154v4</guid>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3575227</arxiv:DOI>
      <dc:creator>Lucas Machado Moschen, Maria Soledad Aronna</dc:creator>
    </item>
    <item>
      <title>Distances between finite-horizon linear behaviors</title>
      <link>https://arxiv.org/abs/2503.22849</link>
      <description>arXiv:2503.22849v2 Announce Type: replace 
Abstract: The paper introduces a class of distances for linear behaviors over finite time horizons. These distances allow for comparisons between finite-horizon linear behaviors represented by matrices of possibly different dimensions. They remain invariant under coordinate changes, rotations, and permutations, ensuring independence from input-output partitions. Moreover, they naturally encode complexity-misfit trade-offs for Linear Time-Invariant (LTI) behaviors, providing a principled solution to a longstanding puzzle in behavioral systems theory. The resulting framework characterizes modeling as a minimum distance problem, identifying the Most Powerful Unfalsified Model (MPUM) as optimal among all systems unfalsified by a given dataset. Finally, we illustrate the value of these metrics in a time series anomaly detection task, where their finer resolution yields superior performance over existing distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22849v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Padoan, Jeremy Coulson</dc:creator>
    </item>
    <item>
      <title>Fast Frank--Wolfe Algorithms with Adaptive Bregman Step-Size for Weakly Convex Functions</title>
      <link>https://arxiv.org/abs/2504.04330</link>
      <description>arXiv:2504.04330v3 Announce Type: replace 
Abstract: We propose a Frank--Wolfe (FW) algorithm with an adaptive Bregman step-size strategy for smooth adaptable (also called: relatively smooth) (weakly-) convex functions. This means that the gradient of the objective function is not necessarily Lipschitz continuous, and we only require the smooth adaptable property. Compared to existing FW algorithms, our assumptions are less restrictive. We establish convergence guarantees in various settings, such as sublinear to linear convergence rates, depending on the assumptions for convex and nonconvex objective functions. Assuming that the objective function is weakly convex and satisfies the local quadratic growth condition, we provide both local sublinear and local linear convergence regarding the primal gap. We also propose a variant of the away-step FW algorithm using Bregman distances over polytopes. We establish global faster (up to linear) convergence for convex optimization under the H\"{o}lder error bound condition and its local linear convergence for nonconvex optimization under the local quadratic growth condition. Numerical experiments demonstrate that our proposed FW algorithms outperform existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04330v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shota Takahashi, Sebastian Pokutta, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Optimal control of variable-exponent subdiffusion</title>
      <link>https://arxiv.org/abs/2505.17678</link>
      <description>arXiv:2505.17678v2 Announce Type: replace 
Abstract: This work investigates the optimal control of the variable-exponent subdiffusion, which extends the work [Gunzburger and Wang, {\it SIAM J. Control Optim.} 2019] to the variable-exponent case to account for the multiscale and crossover diffusion behavior. To resolve the difficulties caused by the leading variable-exponent operator, we adopt the convolution method to reformulate the model into an equivalent but more tractable form, and then prove the well-posedness and weighted regularity of the optimal control. As the convolution kernels in reformulated models are indefinite-sign, non-positive-definite, and non-monotonic, we adopt the discrete convolution kernel approach in numerical analysis to show the $O(\tau(1+|\ln\tau|)+h^2)$ accuracy of the schemes for state and adjoint equations. Numerical experiments are performed to substantiate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17678v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqun Li, Mengmeng Liu, Wenlin Qiu, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Graphon Mean Field Control</title>
      <link>https://arxiv.org/abs/2505.19664</link>
      <description>arXiv:2505.19664v2 Announce Type: replace 
Abstract: Motivated by recent interest in graphon mean field games and their applications, this paper provides a comprehensive probabilistic analysis of graphon mean field control (GMFC) problems, where the controlled dynamics are governed by a graphon mean field stochastic differential equation with heterogeneous mean field interactions. We formulate the GMFC problem with general graphon mean field dependence and establish the existence and uniqueness of the associated graphon mean field forward-backward stochastic differential equations (FBSDEs). We then derive a version of the Pontryagin stochastic maximum principle tailored to GMFC problems. Furthermore, we analyze the solvability of the GMFC problem for linear dynamics and study the continuity and stability of the graphon mean field FBSDEs under the optimal control profile. Finally, we show that the solution to the GMFC problem provides an approximately optimal solution for large systems with heterogeneous mean field interactions, based on a propagation of chaos result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19664v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Cao, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Quadratic convergence of an SQP method for some optimization problems with applications to control theory</title>
      <link>https://arxiv.org/abs/2505.22750</link>
      <description>arXiv:2505.22750v2 Announce Type: replace 
Abstract: We analyze a sequential quadratic programming algorithm for solving a class of abstract optimization problems. Assuming that the initial point is in an $L^2$ neighborhood of a local solution that satisfies no-gap second-order sufficient optimality conditions and a strict complementarity condition, we obtain stability and quadratic convergence in $L^q$ for all $q\in[p,\infty]$ where $p\geq 2$ depends on the problem. Many of the usual optimal control problems of partial differential equations fit into this abstract formulation. Some examples are given in the paper. Finally, a computational comparison with other versions of the SQP method is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22750v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Casas, Mariano Mateos</dc:creator>
    </item>
    <item>
      <title>Kaczmarz and Gauss-Seidel Algorithms with Volume Sampling</title>
      <link>https://arxiv.org/abs/2111.06931</link>
      <description>arXiv:2111.06931v3 Announce Type: replace-cross 
Abstract: The method of Alternating Projections (AP) is a fundamental iterative technique with applications to problems in machine learning, optimization and signal processing. Examples include the Gauss-Seidel algorithm which is used to solve large-scale regression problems and the Kaczmarz and projections onto convex sets (POCS) algorithms that are fundamental to iterative reconstruction. Progress has been made with regards to the questions of efficiency and rate of convergence in the randomized setting of the AP method. Here, we extend these results with volume sampling to block (batch) sizes greater than 1 and provide explicit formulas that relate the convergence rate bounds to the spectrum of the underlying system. These results, together with a trace formula and associated volume sampling, prove that convergence rates monotonically improve with larger block sizes, a feature that can not be guaranteed in general with uniform sampling (e.g., in SGD).</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.06931v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alireza Entezari, Arunava Banerjee, Leila Kalantari</dc:creator>
    </item>
    <item>
      <title>On the limit theory of mean field optimal stopping with non-Markov dynamics and common noise</title>
      <link>https://arxiv.org/abs/2310.00407</link>
      <description>arXiv:2310.00407v3 Announce Type: replace-cross 
Abstract: This paper focuses on a mean-field optimal stopping problem with non-Markov dynamics and common noise, inspired by Talbi, Touzi, and Zhang \cite{TalbiTouziZhang1,TalbiTouziZhang3}. The goal is to establish the limit theory and demonstrate the equivalence of the value functions between weak and strong formulations. The difference between the strong and weak formulations lies in the source of randomness determining the stopping time on a canonical space. In the strong formulation, the randomness of the stopping time originates from Brownian motions. In contrast, this may not necessarily be the case in the weak formulation. Additionally, a $(H)$-Hypothesis-type condition is introduced to guarantee the equivalence of the value functions. The limit theory encompasses the convergence of the value functions and solutions of the large population optimal stopping problem towards those of the mean-field limit, and it shows that every solution of the mean field optimal stopping problem can be approximated by solutions of the large population optimal stopping problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00407v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xihao He</dc:creator>
    </item>
    <item>
      <title>Extended Set-based Tasks for Multi-task Execution and Prioritization</title>
      <link>https://arxiv.org/abs/2310.16189</link>
      <description>arXiv:2310.16189v2 Announce Type: replace-cross 
Abstract: The ability of executing multiple tasks simultaneously is an important feature of redundant robotic systems. As a matter of fact, complex behaviors can often be obtained as a result of the execution of several tasks. Moreover, in safety-critical applications, tasks designed to ensure the safety of the robot and its surroundings have to be executed along with other nominal tasks. In such cases, it is also important to prioritize the former over the latter. In this paper, we formalize the definition of extended set-based tasks, i.e., tasks which can be executed by rendering subsets of the task space asymptotically stable or forward invariant using control barrier functions. We propose a formal mathematical representation of such tasks that allows for the execution of more complex and time-varying prioritized stacks of tasks using kinematic and dynamic robot models alike. We present an optimization-based framework which is computationally efficient, accounts for input bounds, and allows for the stable execution of time-varying prioritized stacks of extended set-based tasks. The proposed framework is validated using extensive simulations, quantitative comparisons to the state-of-the-art hierarchical quadratic programming, and experiments with robotic manipulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16189v2</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gennaro Notomista, Mario Selvaggio, Francesca Pagano, Mar\'ia Santos, Siddharth Mayya, Vincenzo Lippiello, Cristian Secchi</dc:creator>
    </item>
    <item>
      <title>Statistical Accuracy of Approximate Filtering Methods</title>
      <link>https://arxiv.org/abs/2402.01593</link>
      <description>arXiv:2402.01593v3 Announce Type: replace-cross 
Abstract: Estimating the statistics of the state of a dynamical system, from partial and noisy observations, is both mathematically challenging and finds wide application. Furthermore, the applications are of great societal importance, including problems such as probabilistic weather forecasting and prediction of epidemics. Particle filters provide a well-founded approach to the problem, leading to provably accurate approximations of the statistics. However these methods perform poorly in high dimensions. In 1994 the idea of ensemble Kalman filtering was introduced by Evensen, leading to a methodology that has been widely adopted in the geophysical sciences and also finds application to quite general inverse problems. However, ensemble Kalman filters have defied rigorous analysis of their statistical accuracy, except in the linear Gaussian setting. In this article we describe recent work which takes first steps to analyze the statistical accuracy of ensemble Kalman filters beyond the linear Gaussian setting. The subject is inherently technical, as it involves the evolution of probability measures according to a nonlinear and nonautonomous dynamical system; and the approximation of this evolution. It can nonetheless be presented in a fairly accessible fashion, understandable with basic knowledge of dynamical systems, numerical analysis and probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01593v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>J. A. Carrillo, F. Hoffmann, A. M. Stuart, U. Vaes</dc:creator>
    </item>
    <item>
      <title>Online Control of Linear Systems under Unbounded Noise</title>
      <link>https://arxiv.org/abs/2402.10252</link>
      <description>arXiv:2402.10252v2 Announce Type: replace-cross 
Abstract: This paper investigates the problem of controlling a linear system under possibly unbounded stochastic noise with unknown convex cost functions, known as an online control problem. In contrast to the existing work, which assumes the boundedness of noise, we show that an $ \tilde{O}(\sqrt{T}) $ high-probability regret can be achieved under unbounded noise, where $ T $ denotes the time horizon. Notably, the noise is only required to have a finite fourth moment. Moreover, when the costs are strongly convex and the noise is sub-Gaussian, we establish an $ O({\rm poly} (\log T)) $ regret bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10252v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaito Ito, Taira Tsuchiya</dc:creator>
    </item>
    <item>
      <title>A Tunable Universal Formula for Safety-Critical Control</title>
      <link>https://arxiv.org/abs/2403.06285</link>
      <description>arXiv:2403.06285v3 Announce Type: replace-cross 
Abstract: Sontag's universal formula is a widely used technique for stabilizing control through control Lyapunov functions. Recently, it has been extended to address safety-critical control by incorporating control barrier functions (CBFs). However, deriving a universal formula that satisfies requirements on essential properties, including safety, smoothness, and robustness against input disturbances, is still an open problem. To address this challenge, this paper introduces a novel solution - a tunable universal formula - by incorporating a (state-dependent) tunable term into Sontag's formula. This tunable term enables the regulation of safety-critical control performances, allowing the attainment of desired properties through a proper selection of tunable terms. Generally, the tunable universal formula can be seen as a controller that improves the quadratic program (QP)-synthesized controllers in terms of robustness and smoothness, while also reducing the conservatism (corresponding to robustness) in Sontag's formula. Furthermore, we extend the tunable universal formula to address safety-critical control problems with norm-bounded input constraints, showcasing its applicability across diverse control scenarios. Finally, we demonstrate the efficacy of our method through a two-link manipulator safe tracking example, investigating the essential properties including safety, smoothness, and robustness against input disturbances under various tunable terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06285v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Li, Zhiyong Sun, Patrick J. W. Koelewijn, Siep Weiland</dc:creator>
    </item>
    <item>
      <title>GeoAdaLer: Geometric Insights into Adaptive Stochastic Gradient Descent Algorithms</title>
      <link>https://arxiv.org/abs/2405.16255</link>
      <description>arXiv:2405.16255v2 Announce Type: replace-cross 
Abstract: The Adam optimization method has achieved remarkable success in addressing contemporary challenges in stochastic optimization. This method falls within the realm of adaptive sub-gradient techniques, yet the underlying geometric principles guiding its performance have remained shrouded in mystery, and have long confounded researchers. In this paper, we introduce GeoAdaLer (Geometric Adaptive Learner), a novel adaptive learning method for stochastic gradient descent optimization, which draws from the geometric properties of the optimization landscape. Beyond emerging as a formidable contender, the proposed method extends the concept of adaptive learning by introducing a geometrically inclined approach that enhances the interpretability and effectiveness in complex optimization scenarios</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16255v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chinedu Eleh, Masuzyo Mwanza, Ekene Aguegboh, Hans-Werner van Wyk</dc:creator>
    </item>
    <item>
      <title>Toward Global Convergence of Gradient EM for Over-Parameterized Gaussian Mixture Models</title>
      <link>https://arxiv.org/abs/2407.00490</link>
      <description>arXiv:2407.00490v2 Announce Type: replace-cross 
Abstract: We study the gradient Expectation-Maximization (EM) algorithm for Gaussian Mixture Models (GMM) in the over-parameterized setting, where a general GMM with $n&gt;1$ components learns from data that are generated by a single ground truth Gaussian distribution. While results for the special case of 2-Gaussian mixtures are well-known, a general global convergence analysis for arbitrary $n$ remains unresolved and faces several new technical barriers since the convergence becomes sub-linear and non-monotonic. To address these challenges, we construct a novel likelihood-based convergence analysis framework and rigorously prove that gradient EM converges globally with a sublinear rate $O(1/\sqrt{t})$. This is the first global convergence result for Gaussian mixtures with more than $2$ components. The sublinear convergence rate is due to the algorithmic nature of learning over-parameterized GMM with gradient EM. We also identify a new emerging technical challenge for learning general over-parameterized GMM: the existence of bad local regions that can trap gradient EM for an exponential number of steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00490v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weihang Xu, Maryam Fazel, Simon S. Du</dc:creator>
    </item>
    <item>
      <title>$\Gamma$-Limsup estimate for a nonlocal approximation of the Willmore functional</title>
      <link>https://arxiv.org/abs/2407.06102</link>
      <description>arXiv:2407.06102v2 Announce Type: replace-cross 
Abstract: We propose a possible nonlocal approximation of the Willmore functional, in the sense of Gamma-convergence, based on the first variation ot the fractional Allen-Cahn energies, and we prove the corresponding $\Gamma$-limsup estimate. Our analysis is based on the expansion of the fractional Laplacian in Fermi coordinates and fine estimates on the decay of higher order derivatives of the one-dimensional nonlocal optimal profile. This result is the nonlocal counterpart of that obtained by Bellettini and Paolini, where they proposed a phase-field approximation of the Willmore functional based on the first variation of the (local) Allen-Cahn energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06102v2</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hardy Chan, Mattia Freguglia, Marco Inversi</dc:creator>
    </item>
    <item>
      <title>Deflated Dynamics Value Iteration</title>
      <link>https://arxiv.org/abs/2407.10454</link>
      <description>arXiv:2407.10454v2 Announce Type: replace-cross 
Abstract: The Value Iteration (VI) algorithm is an iterative procedure to compute the value function of a Markov decision process, and is the basis of many reinforcement learning (RL) algorithms as well. As the error convergence rate of VI as a function of iteration $k$ is $O(\gamma^k)$, it is slow when the discount factor $\gamma$ is close to $1$. To accelerate the computation of the value function, we propose Deflated Dynamics Value Iteration (DDVI). DDVI uses matrix splitting and matrix deflation techniques to effectively remove (deflate) the top $s$ dominant eigen-structure of the transition matrix $\mathcal{P}^{\pi}$. We prove that this leads to a $\tilde{O}(\gamma^k |\lambda_{s+1}|^k)$ convergence rate, where $\lambda_{s+1}$is $(s+1)$-th largest eigenvalue of the dynamics matrix. We then extend DDVI to the RL setting and present Deflated Dynamics Temporal Difference (DDTD) algorithm. We empirically show the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10454v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jongmin Lee, Amin Rakhsha, Ernest K. Ryu, Amir-massoud Farahmand</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of Levenberg-Marquardt method with Singular Scaling for nonzero residue nonlinear least-squares problems</title>
      <link>https://arxiv.org/abs/2408.10370</link>
      <description>arXiv:2408.10370v2 Announce Type: replace-cross 
Abstract: Recently, a Levenberg-Marquardt method with Singular Scaling matrix, called LMMSS, was proposed and successfully applied in parameter estimation in heat conduction problems, where the choice of suitable singular scaling matrix resulted in better quality approximate solutions than those of the classical Levenberg-Marquardt. In this paper, we study convergence properties of LMMSS when applied to nonzero residual nonlinear least-squares problems. We show that the local convergence of the iterates depends both on the control of the gradient linearization error and on a suitable choice of the regularization parameter. Incidentally, we show that the rate of convergence is dictated by a measure of nonlinearity and residual size, so that if such a measure goes to zero quickly enough, the convergence can be superlinear, otherwise, in general, we show that not even linear convergence can be expected if such a measure is not small enough. Additionally, we propose a globalized version of the method and prove that any limit point of the generated sequence is stationary for the least-squares function. Some examples are provided to illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10370v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafaela Filippozzi, Everton Boos, Douglas Soares Gon\c{c}alves, Fermin Bazan</dc:creator>
    </item>
    <item>
      <title>End-to-end guarantees for indirect data-driven control of bilinear systems with finite stochastic data</title>
      <link>https://arxiv.org/abs/2409.18010</link>
      <description>arXiv:2409.18010v2 Announce Type: replace-cross 
Abstract: In this paper we propose an end-to-end algorithm for indirect data-driven control for bilinear systems with stability guarantees. We consider the case where the collected i.i.d. data is affected by probabilistic noise with possibly unbounded support and leverage tools from statistical learning theory to derive finite sample identification error bounds. To this end, we solve the bilinear identification problem by solving a set of linear and affine identification problems, by a particular choice of a control input during the data collection phase. We provide a priori as well as data-dependent finite sample identification error bounds on the individual matrices as well as ellipsoidal bounds, both of which are structurally suitable for control. Further, we integrate the structure of the derived identification error bounds in a robust controller design to obtain an exponentially stable closed-loop. By means of an extensive numerical study we showcase the interplay between the controller design and the derived identification error bounds. Moreover, we note appealing connections of our results to indirect data-driven control of general nonlinear systems through Koopman operator theory and discuss how our results may be applied in this setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18010v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Chatzikiriakos, Robin Str\"asser, Frank Allg\"ower, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Nonlinear Assimilation via Score-based Sequential Langevin Sampling</title>
      <link>https://arxiv.org/abs/2411.13443</link>
      <description>arXiv:2411.13443v3 Announce Type: replace-cross 
Abstract: This paper presents score-based sequential Langevin sampling (SSLS), a novel approach to nonlinear data assimilation within a recursive Bayesian filtering framework. The proposed method decomposes the assimilation process into alternating prediction and update steps, leveraging dynamic models for state prediction while incorporating observational data through score-based Langevin Monte Carlo during updates. To address challenges in posterior sampling, we introduce an annealing strategy within the update mechanism. We provide theoretical guarantees for SSLS convergence in total variation (TV) distance under certain conditions, providing insights into error behavior with respect to key hyper-parameters. Our numerical experiments across challenging scenarios -- including high-dimensional systems, strong nonlinearity, and sparse observations -- demonstrate the robust performance of the proposed method. Furthermore, SSLS effectively quantifies the uncertainty associated with the estimated states, making it particularly valuable for the error calibration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13443v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhao Ding, Chenguang Duan, Yuling Jiao, Jerry Zhijian Yang, Cheng Yuan, Pingwen Zhang</dc:creator>
    </item>
    <item>
      <title>Neural Operators for Predictor Feedback Control of Nonlinear Delay Systems</title>
      <link>https://arxiv.org/abs/2411.18964</link>
      <description>arXiv:2411.18964v3 Announce Type: replace-cross 
Abstract: Predictor feedback designs are critical for delay-compensating controllers in nonlinear systems. However, these designs are limited in practical applications as predictors cannot be directly implemented, but require numerical approximation schemes, which become computationally prohibitive when system dynamics are expensive to compute. To address this challenge, we recast the predictor design as an operator learning problem, and learn the predictor mapping via a neural operator. We prove the existence of an arbitrarily accurate neural operator approximation of the predictor operator. Under the approximated predictor, we achieve semiglobal practical stability of the closed-loop nonlinear delay system. The estimate is semiglobal in a unique sense - one can enlarge the set of initial states as desired, though this increases the difficulty of training a neural operator, which appears practically in the stability estimate. Furthermore, our analysis holds for any black-box predictor satisfying the universal approximation error bound. We demonstrate the approach by controlling a 5-link robotic manipulator with different neural operator models, achieving significant speedups compared to classic predictor feedback schemes while maintaining closed-loop stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18964v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Bhan, Peijia Qin, Miroslav Krstic, Yuanyuan Shi</dc:creator>
    </item>
    <item>
      <title>Learning Provably Improves the Convergence of Gradient Descent</title>
      <link>https://arxiv.org/abs/2501.18092</link>
      <description>arXiv:2501.18092v4 Announce Type: replace-cross 
Abstract: Learn to Optimize (L2O) trains deep neural network based solvers for optimization, achieving success in accelerating convex problems and improving non-convex solutions. However, L2O lacks rigorous theoretical backing for its own training convergence, as existing analyses often use unrealistic assumptions -- a gap this work highlights empirically. We bridge this gap by proving the training convergence of L2O models that learn Gradient Descent (GD) hyperparameters for quadratic programming, leveraging the Neural Tangent Kernel (NTK) theory. We propose a deterministic initialization strategy to support our theoretical results and promote stable training over extended optimization horizons by mitigating gradient explosion. Our L2O framework demonstrates over 50\% better optimality against GD and superior robustness over state-of-the-art L2O methods on synthetic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18092v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyu Song, Wei Lin, Hong Xu</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Entropy Search and Expected Improvement in Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2501.18756</link>
      <description>arXiv:2501.18756v2 Announce Type: replace-cross 
Abstract: Bayesian optimization is a widely used method for optimizing expensive black-box functions, with Expected Improvement being one of the most commonly used acquisition functions. In contrast, information-theoretic acquisition functions aim to reduce uncertainty about the function's optimum and are often considered fundamentally distinct from EI. In this work, we challenge this prevailing perspective by introducing a unified theoretical framework, Variational Entropy Search, which reveals that EI and information-theoretic acquisition functions are more closely related than previously recognized. We demonstrate that EI can be interpreted as a variational inference approximation of the popular information-theoretic acquisition function, named Max-value Entropy Search. Building on this insight, we propose VES-Gamma, a novel acquisition function that balances the strengths of EI and MES. Extensive empirical evaluations across both low- and high-dimensional synthetic and real-world benchmarks demonstrate that VES-Gamma is competitive with state-of-the-art acquisition functions and in many cases outperforms EI and MES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18756v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nuojin Cheng, Leonard Papenmeier, Stephen Becker, Luigi Nardi</dc:creator>
    </item>
    <item>
      <title>Efficient Over-parameterized Matrix Sensing from Noisy Measurements via Alternating Preconditioned Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.00463</link>
      <description>arXiv:2502.00463v3 Announce Type: replace-cross 
Abstract: We consider the noisy matrix sensing problem in the over-parameterization setting, where the estimated rank $r$ is larger than the true rank $r_\star$ of the target matrix $X_\star$. Specifically, our main objective is to recover a matrix $ X_\star \in \mathbb{R}^{n_1 \times n_2} $ with rank $ r_\star $ from noisy measurements using an over-parameterized factorization $ LR^\top $, where $ L \in \mathbb{R}^{n_1 \times r}, \, R \in \mathbb{R}^{n_2 \times r} $ and $ \min\{n_1, n_2\} \ge r &gt; r_\star $, with $ r_\star $ being unknown. Recently, preconditioning methods have been proposed to accelerate the convergence of matrix sensing problem compared to vanilla gradient descent, incorporating preconditioning terms $ (L^\top L + \lambda I)^{-1} $ and $ (R^\top R + \lambda I)^{-1} $ into the original gradient. However, these methods require careful tuning of the damping parameter $\lambda$ and are sensitive to step size. To address these limitations, we propose the alternating preconditioned gradient descent (APGD) algorithm, which alternately updates the two factor matrices, eliminating the need for the damping parameter $\lambda$ and enabling faster convergence with larger step sizes. We theoretically prove that APGD convergences to a near-optimal error at a linear rate. We further show that APGD can be extended to deal with other low-rank matrix estimation tasks, also with a theoretical guarantee of linear convergence. To validate the effectiveness and scalability of the proposed APGD, we conduct simulated and real-world experiments on a wide range of low-rank estimation problems, including noisy matrix sensing, weighted PCA, 1-bit matrix completion, and matrix completion. The extensive results demonstrate that APGD consistently achieves the fastest convergence and the lowest computation time compared to the existing alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00463v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Liu, Zhi Han, Yandong Tang, Shaojie Tang, Yao Wang</dc:creator>
    </item>
    <item>
      <title>New Lower Bounds for Stochastic Non-Convex Optimization through Divergence Decomposition</title>
      <link>https://arxiv.org/abs/2502.14060</link>
      <description>arXiv:2502.14060v2 Announce Type: replace-cross 
Abstract: We study fundamental limits of first-order stochastic optimization in a range of nonconvex settings, including L-smooth functions satisfying Quasar-Convexity (QC), Quadratic Growth (QG), and Restricted Secant Inequalities (RSI). While the convergence properties of standard algorithms are well-understood in deterministic regimes, significantly fewer results address the stochastic case, where only unbiased and noisy gradients are available. We establish new lower bounds on the number of noisy gradient queries to minimize these classes of functions, also showing that they are tight (up to a logarithmic factor) in all the relevant quantities characterizing each class. Our approach reformulates the optimization task as a function identification problem, leveraging divergence decomposition arguments to construct a challenging subclass that leads to sharp lower bounds. Furthermore, we present a specialized algorithm in the one-dimensional setting that achieves faster rates, suggesting that certain dimensional thresholds are intrinsic to the complexity of non-convex stochastic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14060v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mehdi Saad, Wei-Cheng Lee, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs</title>
      <link>https://arxiv.org/abs/2503.13193</link>
      <description>arXiv:2503.13193v3 Announce Type: replace-cross 
Abstract: We introduce the deep multi-FBSDE method for robust approximation of coupled forward-backward stochastic differential equations (FBSDEs), focusing on cases where the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To overcome the convergence issues, we consider a family of FBSDEs that are equivalent to the original problem in the sense that they satisfy the same associated partial differential equation (PDE). Our algorithm proceeds in two phases: first, we approximate the initial condition for the FBSDE family, and second, we approximate the original FBSDE using the initial condition approximated in the first phase. Numerical experiments show that our method converges even when the standard deep BSDE method does not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13193v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristoffer Andersson, Adam Andersson, Cornelis W. Oosterlee</dc:creator>
    </item>
    <item>
      <title>Modeling Cell Dynamics and Interactions with Unbalanced Mean Field Schr\"odinger Bridge</title>
      <link>https://arxiv.org/abs/2505.11197</link>
      <description>arXiv:2505.11197v2 Announce Type: replace-cross 
Abstract: Modeling the dynamics from sparsely time-resolved snapshot data is crucial for understanding complex cellular processes and behavior. Existing methods leverage optimal transport, Schr\"odinger bridge theory, or their variants to simultaneously infer stochastic, unbalanced dynamics from snapshot data. However, these approaches remain limited in their ability to account for cell-cell interactions. This integration is essential in real-world scenarios since intercellular communications are fundamental life processes and can influence cell state-transition dynamics. To address this challenge, we formulate the Unbalanced Mean-Field Schr\"odinger Bridge (UMFSB) framework to model unbalanced stochastic interaction dynamics from snapshot data. Inspired by this framework, we further propose CytoBridge, a deep learning algorithm designed to approximate the UMFSB problem. By explicitly modeling cellular transitions, proliferation, and interactions through neural networks, CytoBridge offers the flexibility to learn these processes directly from data. The effectiveness of our method has been extensively validated using both synthetic gene regulatory data and real scRNA-seq datasets. Compared to existing methods, CytoBridge identifies growth, transition, and interaction patterns, eliminates false transitions, and reconstructs the developmental landscape with greater accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11197v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhenyi Zhang, Zihan Wang, Yuhao Sun, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>A generalized global Hartman-Grobman theorem for asymptotically stable semiflows</title>
      <link>https://arxiv.org/abs/2505.21401</link>
      <description>arXiv:2505.21401v3 Announce Type: replace-cross 
Abstract: Recently, Kvalheim and Sontag provided a generalized global Hartman-Grobman theorem for equilibria under asymptotically stable continuous vector fields. By leveraging topological properties of Lyapunov functions, their theorem works without assuming hyperbolicity. We extend their theorem to a class of possibly discontinuous vector fields, in particular, to vector fields generating asymptotically stable semiflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21401v3</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
  </channel>
</rss>
