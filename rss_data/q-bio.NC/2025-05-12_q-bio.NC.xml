<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 May 2025 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>NeuroPal: A Clinically-Informed Multimodal LLM Assistant for Mental Health Combining Sleep Chronotherapy, Cognitive Behavioral Reframing, and Adaptive Phytochemical Intervention</title>
      <link>https://arxiv.org/abs/2505.06640</link>
      <description>arXiv:2505.06640v1 Announce Type: new 
Abstract: Due to time constraints, mental health professionals in China are unable to offer patients prolonged talk therapy, leaving a gap in care for patients with psychological disorders, including aberrant sleep and eating patterns, maladaptive explanatory styles, and gastrointestinal dysfunction. To bridge this gap in care and address these problems in a large-scale manner, we built NeuroPal, a large language model (LLM)-assistant that provides scalable, evidence-based interventions with three clinically validated modules: (1) a sleep chronotherapy planner to output personalized circadian rhythm correction protocols, (2) a cognitive-behavioral reframing engine grounded in CBT and humanistic principles to shift negative attributional biases, and (3) a biochemical regulation advisor to output phytotherapy formulations to regulate sleep-metabolism-gut-axis imbalances. In collaboration with Peking Union Medical College Hospital and Xiangya Hospital Central South University, we ran an RCT protocol with 513 participants with mood/anxiety disorders and showed statistically significant improvements towards primary endpoints (&gt; p&lt;.01). Experiment shows 37.2% drop in the Pittsburgh Sleep Quality Index (PSQI), 28.6% rise in positive affective word usages (LIWC analysis), and 23.4% improvement in patient-reported digestive comfort. The assistant also reached 89.1% adherence rates, significantly higher than the human-guided therapy intervention (72.3%) in matched controls. Our results indicate that an LLM-driven multimodal intervention is able to successfully bridge time-constrained clinical practice while preserving therapeutic effectiveness. For next steps, we plan to explore longitudinal outcome tracking and FDA/CFDA certification routes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06640v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoran Han</dc:creator>
    </item>
    <item>
      <title>3D Constraints on Local Motion to Detect Moving Objects</title>
      <link>https://arxiv.org/abs/2505.06686</link>
      <description>arXiv:2505.06686v1 Announce Type: new 
Abstract: As we move through the world, the pattern of light projected on our eyes is complex and dynamic, yet we are still able to distinguish between moving and stationary objects. We propose that humans accomplish this by exploiting constraints that self-motion imposes on retinal velocities. When an eye translates and rotates in a stationary 3D scene, the velocity at each retinal location is constrained to a line segment in the 2D space of retinal velocities. The slope and intercept of this segment is determined by the eye's translation and rotation, and the position along the segment is determined by the local scene depth. Since all possible velocities arising from a stationary scene must lie on this segment, velocities that are not must correspond to objects moving within the scene. We hypothesize that humans make use of these constraints by using deviations of local velocity from these constraint lines to detect moving objects. To test this, we used a virtual reality headset to present rich wide-field stimuli, simulating the visual experience of translating forward in several virtual environments with varied precision of depth information. Participants had to determine if a cued object moved relative to the scene. Consistent with the hypothesis, we found that performance depended on the deviation of the object velocity from the constraint segment, rather than a difference between retinal velocities of the object and its local surround. We also found that the endpoints of the constraint segment reflected the precision of depth information available in the different virtual environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06686v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hope Lutwak, Bas Rokers, Eero P. Simoncelli</dc:creator>
    </item>
    <item>
      <title>Full simulation on the dynamics of auditory synaptic fusion: Strong clustering of calcium channel might be the origin of the coherent release in the auditory hair cells</title>
      <link>https://arxiv.org/abs/2505.07273</link>
      <description>arXiv:2505.07273v1 Announce Type: new 
Abstract: The precise timing of synaptic transmission in auditory hair cells is important to hearing and speech recognition. Neurotransmitter release is an underlying step in translating sound. Thus, understanding nature of the synaptic fusion is key to understand the hearing mechanism. Extraordinary large excitatory postsynaptic currents (EPSCs) have been observed in the auditory hair cell synapse, and its origin has been controversial. It is not known yet whether the size and shape of the EPSCs are results of a big vesicle or many small vesicles. We report our numerical simulation of the vesicular fusion process from calcium channel process to the generation of EPSC currents. Our numerical experiments indicate that the origin of the large EPSC with its mysterious form is close to the scenario of the multivesicular release. The large EPSCs might be triggered by strong calcium channeling of the calcium channel clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07273v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaeyun Yoo, Kang-Hun Ahn</dc:creator>
    </item>
    <item>
      <title>From Brain to Motion: Harnessing Higher-Derivative Mechanics for Neural Control</title>
      <link>https://arxiv.org/abs/2505.07454</link>
      <description>arXiv:2505.07454v1 Announce Type: new 
Abstract: Optimal Feedback Control (OFC) provides a theoretical framework for goal-directed movements, where the nervous system adjusts actions based on sensory feedback. In OFC, the central nervous system (CNS) not only reacts to stimuli but proactively predicts and adjusts motor commands, minimizing errors and (often energetic) costs through internal models. OFC theory assumes that there exists a cost function that is optimized throughout one's movement. It is natural to assume that mechanical quantities should be involved in cost functions. This does not imply that the mechanical principles that govern human voluntary movements are necessarily Newtonian. Indeed, the undisputed efficiency of Newtonian mechanics to model and predict the motion of non-living systems does not guarantee its relevance to model human behavior. We propose that integrating principles from Lagrangian and Hamiltonian higher-derivative mechanics, i.e. dynamical models that go beyond Newtonian mechanics, provides a more natural framework to study the constraints hidden in human voluntary movement within OFC theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07454v1</guid>
      <category>q-bio.NC</category>
      <category>physics.class-ph</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>O. White, F. Buisseret, F. Dierick, N. Boulanger</dc:creator>
    </item>
    <item>
      <title>Possible mechanisms underlying time perception: decoupling internal and external time</title>
      <link>https://arxiv.org/abs/2505.07712</link>
      <description>arXiv:2505.07712v1 Announce Type: new 
Abstract: Alignment between subjective sense of time and chronological time can become skewed as a result of pharmacological interventions, neurodegenerative diseases (such as Parkinson's disease), or even in the moments preceding brain death. Despite increased understanding of mechanisms governing time perception and the activity of the "internal clock" (such as the functionality of the dopamine system in the basal ganglia of the midbrain), there currently exist no mathematical models that allow investigation of changes in time perception through formalizing the decoupling of "internal" and "external" time. Here we propose such a model using a parametrically heterogeneous power equation, and use it to investigate the critical case of indefinite increase in internal time following cardiac arrest and preceding brain death. We identify three critical parameters that determine time to brain death and provide an analysis of the relevant quantities. We hope that our model can lay foundation for further mathematical and theoretical exploration of this complex topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07712v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irina Kareva, Georgy Karev</dc:creator>
    </item>
    <item>
      <title>Skeletonization of neuronal processes using Discrete Morse techniques from computational topology</title>
      <link>https://arxiv.org/abs/2505.07754</link>
      <description>arXiv:2505.07754v1 Announce Type: new 
Abstract: To understand biological intelligence we need to map neuronal networks in vertebrate brains. Mapping mesoscale neural circuitry is done using injections of tracers that label groups of neurons whose axons project to different brain regions. Since many neurons are labeled, it is difficult to follow individual axons. Previous approaches have instead quantified the regional projections using the total label intensity within a region. However, such a quantification is not biologically meaningful. We propose a new approach better connected to the underlying neurons by skeletonizing labeled axon fragments and then estimating a volumetric length density. Our approach uses a combination of deep nets and the Discrete Morse (DM) technique from computational topology. This technique takes into account nonlocal connectivity information and therefore provides noise-robustness. We demonstrate the utility and scalability of the approach on whole-brain tracer injected data. We also define and illustrate an information theoretic measure that quantifies the additional information obtained, compared to the skeletonized tracer injection fragments, when individual axon morphologies are available. Our approach is the first application of the DM technique to computational neuroanatomy. It can help bridge between single-axon skeletons and tracer injections, two important data types in mapping neural networks in vertebrates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07754v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Samik Banerjee, Caleb Stam, Daniel J. Tward, Steven Savoia, Yusu Wang, Partha P. Mitra</dc:creator>
    </item>
    <item>
      <title>Evaluating Cognitive Assessment Tools:A Comparative Analysis of MMSE, RUDAS, SAGE, ADAS and MoCA for Early Dementia Detection</title>
      <link>https://arxiv.org/abs/2505.07246</link>
      <description>arXiv:2505.07246v1 Announce Type: cross 
Abstract: Early detection of dementia is very crucial to ensure treatment begins on time, however it is difficult to choose appropriate cognitive assessment tools because each test is designed differently and may not be tailored to the needs of a patient. This review compares five commonly used tests the Mini-Mental State Examination (MMSE), Rowland Universal Dementia Assessment Scale (RUDAS), Self-Administered Gerocognitive Examination (SAGE), Alzheimer's Disease Assessment Scale (ADAS), and Montreal Cognitive Assessment (MoCA). Each test has different criteria's and vary in their coverage of cognitive domains. MMSE focuses on memory and language but lacks in the evaluation of executive and visuospatial abilities. RUDAS and SAGE focus on memory, language and visual thinking while ADAS mainly targets memory, executive function and language. The MoCA is most complete as it focuses on areas like attention, memory skills, problem solving and visual skills. This review evaluates how accurate and reliable these tools are to help doctors decide the most efficient tool for diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07246v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saransh Naole, Dhriti Parikh, Sakshi Nayak, Swarna Priya Ramu</dc:creator>
    </item>
    <item>
      <title>Higher-Order Convolution Improves Neural Predictivity in the Retina</title>
      <link>https://arxiv.org/abs/2505.07620</link>
      <description>arXiv:2505.07620v1 Announce Type: cross 
Abstract: We present a novel approach to neural response prediction that incorporates higher-order operations directly within convolutional neural networks (CNNs). Our model extends traditional 3D CNNs by embedding higher-order operations within the convolutional operator itself, enabling direct modeling of multiplicative interactions between neighboring pixels across space and time. Our model increases the representational power of CNNs without increasing their depth, therefore addressing the architectural disparity between deep artificial networks and the relatively shallow processing hierarchy of biological visual systems. We evaluate our approach on two distinct datasets: salamander retinal ganglion cell (RGC) responses to natural scenes, and a new dataset of mouse RGC responses to controlled geometric transformations. Our higher-order CNN (HoCNN) achieves superior performance while requiring only half the training data compared to standard architectures, demonstrating correlation coefficients up to 0.75 with neural responses (against 0.80$\pm$0.02 retinal reliability). When integrated into state-of-the-art architectures, our approach consistently improves performance across different species and stimulus conditions. Analysis of the learned representations reveals that our network naturally encodes fundamental geometric transformations, particularly scaling parameters that characterize object expansion and contraction. This capability is especially relevant for specific cell types, such as transient OFF-alpha and transient ON cells, which are known to detect looming objects and object motion respectively, and where our model shows marked improvement in response prediction. The correlation coefficients for scaling parameters are more than twice as high in HoCNN (0.72) compared to baseline models (0.32).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07620v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Simone Azeglio, Victor Calbiague Garcia, Guilhem Glaziou, Peter Neri, Olivier Marre, Ulisse Ferrari</dc:creator>
    </item>
    <item>
      <title>Human foraging strategies flexibly adapt to resource distribution and time constraints</title>
      <link>https://arxiv.org/abs/2408.01350</link>
      <description>arXiv:2408.01350v4 Announce Type: replace 
Abstract: Foraging is a crucial activity, yet the extent to which humans employ flexible versus rigid strategies remains unclear. This study investigates how individuals adapt their foraging strategies in response to resource distribution and foraging time constraints. For this, we designed a video-game-like foraging task that requires participants to navigate a four-areas environment to collect coins from treasure boxes within a limited time. This task engages multiple cognitive abilities, such as navigation, learning, and memorization of treasure box locations. Findings indicate that participants adjust their foraging strategies -- encompassing both stay-or-leave decisions, such as the number of boxes opened in initial areas and behavioral aspects, such as the time to navigate from box to box -- depending on both resource distribution and foraging time. Additionally, they improved their performance over time as an effect of both enhanced navigation skills and adaptation of foraging strategies. Finally, participants' performance was initially distant from the reward-maximizing performance of optimal agents due to the learning process humans undergo; however, it approximated the optimal agent's performance towards the end of the task, without fully reaching it. These results highlight the flexibility of human foraging behavior and underscore the importance of employing optimality models and ecologically rich scenarios to study foraging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01350v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Valeria Simonelli, Davide Nuzzi, Gian Luca Lancia, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>Neural timescales from a computational perspective</title>
      <link>https://arxiv.org/abs/2409.02684</link>
      <description>arXiv:2409.02684v2 Announce Type: replace 
Abstract: Neural activity fluctuates over a wide range of timescales within and across brain areas. Experimental observations suggest that diverse neural timescales reflect information in dynamic environments. However, how timescales are defined and measured from brain recordings vary across the literature. Moreover, these observations do not specify the mechanisms underlying timescale variations, nor whether specific timescales are necessary for neural computation and brain function. Here, we synthesize three directions where computational approaches can distill the broad set of empirical observations into quantitative and testable theories: We review (i) how different data analysis methods quantify timescales across distinct behavioral states and recording modalities, (ii) how biophysical models provide mechanistic explanations for the emergence of diverse timescales, and (iii) how task-performing networks and machine learning models uncover the functional relevance of neural timescales. This integrative computational perspective thus complements experimental investigations, providing a holistic view on how neural timescales reflect the relationship between brain structure, dynamics, and behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02684v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roxana Zeraati, Anna Levina, Jakob H. Macke, Richard Gao</dc:creator>
    </item>
    <item>
      <title>Relationships between the degrees of freedom in the affine Gaussian derivative model for visual receptive fields and 2-D affine image transformations, with application to covariance properties of simple cells in the primary visual cortex</title>
      <link>https://arxiv.org/abs/2411.05673</link>
      <description>arXiv:2411.05673v3 Announce Type: replace 
Abstract: When observing the surface patterns of objects delimited by smooth surfaces, the projections of the surface patterns to the image domain will be subject to substantial variabilities, as induced by variabilities in the geometric viewing conditions, and as generated by either monocular or binocular imaging conditions, or by relative motions between the object and the observer over time. To first order of approximation, the image deformations of such projected surface patterns can be modelled as local linearizations in terms of local 2-D spatial affine transformations.
  This paper presents a theoretical analysis of relationships between the degrees of freedom in 2-D spatial affine image transformations and the degrees of freedom in the affine Gaussian derivative model for visual receptive fields. For this purpose, we first describe a canonical decomposition of 2-D affine transformations on a product form, closely related to a singular value decomposition, while in closed form, and which reveals the degrees of freedom in terms of (i) uniform scaling transformations, (ii) an overall amount of global rotation, (iii) a complementary non-uniform scaling transformation and (iv) a relative normalization to a preferred symmetry orientation in the image domain. Then, we show how these degrees of freedom relate to the degrees of freedom in the affine Gaussian derivative model.
  Finally, we use these theoretical results to consider whether we could regard the biological receptive fields in the primary visual cortex of higher mammals as being able to span the degrees of freedom of 2-D spatial affine transformations, based on interpretations of existing neurophysiological experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05673v3</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Data Integration with Fusion Searchlight: Classifying Brain States from Resting-state fMRI</title>
      <link>https://arxiv.org/abs/2412.10161</link>
      <description>arXiv:2412.10161v2 Announce Type: replace 
Abstract: Resting-state fMRI captures spontaneous neural activity characterized by complex spatiotemporal dynamics. Various metrics, such as local and global brain connectivity and low-frequency amplitude fluctuations, quantify distinct aspects of these dynamics. However, these measures are typically analyzed independently, overlooking their interrelations and potentially limiting analytical sensitivity. Here, we introduce the Fusion Searchlight (FuSL) framework, which integrates complementary information from multiple resting-state fMRI metrics. We demonstrate that combining these metrics enhances the accuracy of pharmacological treatment prediction from rs-fMRI data, enabling the identification of additional brain regions affected by sedation with alprazolam. Furthermore, we leverage explainable AI to delineate the differential contributions of each metric, which additionally improves spatial specificity of the searchlight analysis. Moreover, this framework can be adapted to combine information across imaging modalities or experimental conditions, providing a versatile and interpretable tool for data fusion in neuroimaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10161v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Wein, Marco Riebel, Lisa-Marie Brunner, Caroline Nothdurfter, Rainer Rupprecht, Jens V. Schwarzbach</dc:creator>
    </item>
    <item>
      <title>How the Stroop Effect Arises from Optimal Response Times in Laterally Connected Self-Organizing Maps</title>
      <link>https://arxiv.org/abs/2502.02831</link>
      <description>arXiv:2502.02831v3 Announce Type: replace 
Abstract: The Stroop effect refers to cognitive interference in a color-naming task: When the color and the word do not match, the response is slower and more likely to be incorrect. The Stroop task is used to assess cognitive flexibility, selective attention, and executive function. This paper implements the Stroop task with self-organizing maps (SOMs): Target color and the competing word are inputs for the semantic and lexical maps, associative connections bring color information to the lexical map, and lateral connections combine their effects over time. The model achieved an overall accuracy of 84.2%, with significantly fewer errors and faster responses in congruent compared to no-input and incongruent conditions. The model's effect is a side effect of optimizing response times, and can thus be seen as a cost associated with overall efficient performance. The model can further serve studying neurologically-inspired cognitive control and related phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02831v3</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Divya Prabhakaran, Uli Grasemann, Swathi Kiran, Risto Miikkulainen</dc:creator>
    </item>
    <item>
      <title>Large Language Models Think Too Fast To Explore Effectively</title>
      <link>https://arxiv.org/abs/2501.18009</link>
      <description>arXiv:2501.18009v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have emerged with many intellectual capacities. While numerous benchmarks assess their intelligence, limited attention has been given to their ability to explore--an essential capacity for discovering new information and adapting to novel environments in both natural and artificial systems. The extent to which LLMs can effectively explore, particularly in open-ended tasks, remains unclear. This study investigates whether LLMs can surpass humans in exploration during an open-ended task, using Little Alchemy 2 as a paradigm, where agents combine elements to discover new ones. Results show most LLMs underperform compared to humans, except for the o1 model, with traditional LLMs relying primarily on uncertainty-driven strategies, unlike humans who balance uncertainty and empowerment. Results indicate that traditional reasoning-focused LLMs, such as GPT-4o, exhibit a significantly faster and less detailed reasoning process, limiting their exploratory performance. In contrast, the DeepSeek reasoning model demonstrates prolonged, iterative thought processes marked by repetitive analysis of combinations and past trials, reflecting a more thorough and human-like exploration strategy. Representational analysis of the models with Sparse Autoencoders (SAE) revealed that uncertainty and choices are represented at earlier transformer blocks, while empowerment values are processed later, causing LLMs to think too fast and make premature decisions, hindering effective exploration. These findings shed light on the limitations of LLM exploration and suggest directions for improving their adaptability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18009v2</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lan Pan, Hanbo Xie, Robert C. Wilson</dc:creator>
    </item>
    <item>
      <title>Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of recurrent neural networks</title>
      <link>https://arxiv.org/abs/2504.19657</link>
      <description>arXiv:2504.19657v2 Announce Type: replace-cross 
Abstract: Reservoir computing is a powerful framework for real-time information processing, characterized by its high computational ability and quick learning, with applications ranging from machine learning to biological systems. In this paper, we demonstrate that the memory capacity of a reservoir recurrent neural network scales sublinearly with the number of readout neurons. To elucidate this phenomenon, we develop a theoretical framework for analytically deriving memory capacity, attributing the decaying growth of memory capacity to neuronal correlations. In addition, numerical simulations reveal that once memory capacity becomes sublinear, increasing the number of readout neurons successively enables nonlinear processing at progressively higher polynomial orders. Furthermore, our theoretical framework suggests that neuronal correlations govern not only memory capacity but also the sequential growth of nonlinear computational capabilities. Our findings establish a foundation for designing scalable and cost-effective reservoir computing, providing novel insights into the interplay among neuronal correlations, linear memory, and nonlinear processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19657v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shotaro Takasu, Toshio Aoyagi</dc:creator>
    </item>
  </channel>
</rss>
