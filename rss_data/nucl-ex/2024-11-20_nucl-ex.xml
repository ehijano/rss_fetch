<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nucl-ex updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nucl-ex</link>
    <description>nucl-ex updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nucl-ex" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Nov 2024 02:38:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beam-energy dependence of correlations between mean transverse momentum and anisotropic flow of charged particles in Au+Au collisions at RHIC</title>
      <link>https://arxiv.org/abs/2411.12101</link>
      <description>arXiv:2411.12101v1 Announce Type: new 
Abstract: The correlation between the mean transverse momentum, $[p_{\mathrm{T}}]$, and the squared anisotropic flow, $v^{2}_{n}$, on an event-by-event basis has been suggested to be influenced by the initial conditions in heavy-ion collisions. We present measurements of the variances and covariance of $[p_{\mathrm{T}}]$ and $v^{2}_{n}$, along with their dimensionless ratio, for Au+Au collisions at various beam energies: $\sqrt{\textit{s}_{NN}}$ $=$ 14.6, 19.6, 27, 54.4, and 200 GeV. Our measurements reveal a distinct energy-dependent behavior in the variances and covariance. In addition, the dimensionless ratio displays a similar behavior across different beam energies. We compare our measurements with hydrodynamic models and similar measurements from Pb+Pb collisions at the Large Hadron Collider (LHC). These findings provide valuable insights into the beam energy dependence of the specific shear viscosity ($\eta/s$) and initial-state effects, allowing for differentiating between different initial-state models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12101v1</guid>
      <category>nucl-ex</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator> The STAR Collaboration</dc:creator>
    </item>
    <item>
      <title>Variable Rate Neural Compression for Sparse Detector Data</title>
      <link>https://arxiv.org/abs/2411.11942</link>
      <description>arXiv:2411.11942v1 Announce Type: cross 
Abstract: High-energy large-scale particle colliders generate data at extraordinary rates. Developing real-time high-throughput data compression algorithms to reduce data volume and meet the bandwidth requirement for storage has become increasingly critical. Deep learning is a promising technology that can address this challenging topic. At the newly constructed sPHENIX experiment at the Relativistic Heavy Ion Collider, a Time Projection Chamber (TPC) serves as the main tracking detector, which records three-dimensional particle trajectories in a volume of a gas-filled cylinder. In terms of occupancy, the resulting data flow can be very sparse reaching $10^{-3}$ for proton-proton collisions. Such sparsity presents a challenge to conventional learning-free lossy compression algorithms, such as SZ, ZFP, and MGARD. In contrast, emerging deep learning-based models, particularly those utilizing convolutional neural networks for compression, have outperformed these conventional methods in terms of compression ratios and reconstruction accuracy. However, research on the efficacy of these deep learning models in handling sparse datasets, like those produced in particle colliders, remains limited. Furthermore, most deep learning models do not adapt their processing speeds to data sparsity, which affects efficiency. To address this issue, we propose a novel approach for TPC data compression via key-point identification facilitated by sparse convolution. Our proposed algorithm, BCAE-VS, achieves a $75\%$ improvement in reconstruction accuracy with a $10\%$ increase in compression ratio over the previous state-of-the-art model. Additionally, BCAE-VS manages to achieve these results with a model size over two orders of magnitude smaller. Lastly, we have experimentally verified that as sparsity increases, so does the model's throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11942v1</guid>
      <category>physics.ins-det</category>
      <category>cs.AI</category>
      <category>hep-ex</category>
      <category>nucl-ex</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Huang, Yeonju Go, Jin Huang, Shuhang Li, Xihaier Luo, Thomas Marshall, Joseph Osborn, Christopher Pinkenburg, Yihui Ren, Evgeny Shulga, Shinjae Yoo, Byung-Jun Yoon</dc:creator>
    </item>
    <item>
      <title>Radiative Corrections in Super Rosenbluth Experiments</title>
      <link>https://arxiv.org/abs/2402.14570</link>
      <description>arXiv:2402.14570v2 Announce Type: replace-cross 
Abstract: Super Rosenbluth experiments, elastic electron-proton scattering experiments that eschew traditional electron detection and opt instead for the detection of the recoiling proton, have several experimental advantages. One claimed advantage is that radiative corrections are more favorable, i.e., smaller and with less kinematic dependence. In this paper, we explore this claim by conducting Monte Carlo simulations of both Super Rosenbluth and traditional Rosenbluth experiments with different models of radiative effects. When using a model that employs the peaking approximation, we indeed confirm the reduced kinematic dependence of the radiative corrections. However, we find that more sophisticated models that avoid the peaking approximation are unable to produce numerically stable results, due to a large enhancement to the cross section for bremsstrahlung radiation from the proton when the momentum transfer, $Q^2$, approaches zero. Since this enhancement is not modelled in the peaking approximation, a more robust approach to radiative corrections in Super Rosenbluth experiments is needed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14570v2</guid>
      <category>hep-ph</category>
      <category>nucl-ex</category>
      <category>nucl-th</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quinn Stefan, Axel Schmidt</dc:creator>
    </item>
    <item>
      <title>Ab-initio electroweak corrections to superallowed $\beta$ decays and their impact on $V_{ud}$</title>
      <link>https://arxiv.org/abs/2405.18464</link>
      <description>arXiv:2405.18464v2 Announce Type: replace-cross 
Abstract: Radiative corrections are essential for an accurate determination of $V_{ud}$ from superallowed $\beta$ decays. In view of recent progress in the single-nucleon sector, the uncertainty is dominated by the theoretical description of nucleus-dependent effects, limiting the precision that can currently be achieved for $V_{ud}$. In this work, we provide a detailed account of the electroweak corrections to superallowed $\beta$ decays in effective field theory (EFT), including the power counting, potential and ultrasoft contributions, and factorization in the decay rate. We present a first numerical evaluation of the dominant corrections in light nuclei based on Quantum Monte Carlo methods, confirming the expectations from the EFT power counting. Finally, we discuss strategies how to extract from data the low-energy constants that parameterize short-distance contributions and whose values are not predicted by the EFT. Combined with advances in ab-initio nuclear-structure calculations, this EFT framework allows one to systematically address the dominant uncertainty in $V_{ud}$, as illustrated in detail for the $^{14}$O $\to$ $^{14}$N transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18464v2</guid>
      <category>nucl-th</category>
      <category>hep-ex</category>
      <category>hep-lat</category>
      <category>hep-ph</category>
      <category>nucl-ex</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevC.110.055502</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. C 110, 055502 (2024)</arxiv:journal_reference>
      <dc:creator>Vincenzo Cirigliano, Wouter Dekens, Jordy de Vries, Stefano Gandolfi, Martin Hoferichter, Emanuele Mereghetti</dc:creator>
    </item>
    <item>
      <title>Radiative corrections to superallowed $\beta$ decays in effective field theory</title>
      <link>https://arxiv.org/abs/2405.18469</link>
      <description>arXiv:2405.18469v2 Announce Type: replace-cross 
Abstract: The accuracy of $V_{ud}$ determinations from superallowed $\beta$ decays critically hinges on control over radiative corrections. Recently, substantial progress has been made on the single-nucleon, universal corrections, while nucleus-dependent effects, typically parameterized by a quantity $\delta_\text{NS}$, are much less well constrained. Here, we lay out a program to evaluate this correction from effective field theory (EFT), highlighting the dominant terms as predicted by the EFT power counting. Moreover, we compare the results to a dispersive representation of $\delta_\text{NS}$ and show that the expected momentum scaling applies even in the case of low-lying intermediate states. Our EFT framework paves the way towards ab-initio calculations of $\delta_\text{NS}$ and thereby addresses the dominant uncertainty in $V_{ud}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18469v2</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>hep-lat</category>
      <category>nucl-ex</category>
      <category>nucl-th</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.133.211801</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 133, 211801 (2024)</arxiv:journal_reference>
      <dc:creator>Vincenzo Cirigliano, Wouter Dekens, Jordy de Vries, Stefano Gandolfi, Martin Hoferichter, Emanuele Mereghetti</dc:creator>
    </item>
    <item>
      <title>New methods of neutrino and anti-neutrino detection from 0.115 to 105 MeV</title>
      <link>https://arxiv.org/abs/2411.05615</link>
      <description>arXiv:2411.05615v3 Announce Type: replace-cross 
Abstract: We have developed a neutrino detector with threshold energies from ~0.115 to 105 MeV in a clean detection mode almost completely void of accidental backgrounds. It was initially developed for the NASA $\nu$SOL project to put a solar neutrino detector very close to the Sun with 1,000 to 10,000 times higher solar neutrino flux than on Earth. Similar interactions have been found for anti-neutrinos, which were initially intended for Beta decay neutrinos from reactors, geological sources, or for nuclear security applications. These techniques work at the 1 to 100 MeV region for neutrinos from the ORNL Spallation Neutron Source or low energy accelerator neutrino and anti-neutrino production targets less than $\sim$100 MeV. The identification process is clean, with a double pulse detection signature within a time window between the first interaction producing the conversion electron or positron and the secondary gamma emission 100 ns to ~1 $\mu$s, which removes most accidental backgrounds. These new modes for neutrino and anti-neutrino detection of low energy neutrinos and anti-neutrinos could allow improvements to neutrino interaction measurements from an accelerator beam on a target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05615v3</guid>
      <category>physics.ins-det</category>
      <category>hep-ex</category>
      <category>nucl-ex</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nickolas Solomey, Mark Christl, Brian Doty, Jonathan Folkerts, Brooks Hartsock, Evgen Kuznetsco, Robert McTaggart, Holger Meyer, Tyler Nolan, Greg Pawloski, Daniel Reichart, Miguel Rodriguez-Otero, Dan Smith, Lisa Solomey</dc:creator>
    </item>
  </channel>
</rss>
