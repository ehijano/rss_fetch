<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Projection Approach to Nonparametric Significance and Conditional Independence Testing</title>
      <link>https://arxiv.org/abs/2602.15289</link>
      <description>arXiv:2602.15289v1 Announce Type: new 
Abstract: This paper develops a novel nonparametric significance test based on a tailored nonparametric-type projected weighting function that exhibits appealing theoretical and numerical properties. We derive the asymptotic properties of the proposed test and show that it can detect local alternatives at the parametric rate. Using the nonparametric orthogonal projection, we construct a computationally convenient multiplier bootstrap to obtain critical values from the case-dependent asymptotic null distribution. Compared with the existing literature, our approach overcomes the need for a stronger compact support assumption on the density of covariates arising from random denominators. We also extend the tailor-made projection procedure to test the conditional independence assumption. The simulation experiments further illustrate the advantages of our proposed method in testing significance and conditional independence in finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15289v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojun Song, Jichao Yuan</dc:creator>
    </item>
    <item>
      <title>Income Inequality and Economic Growth: A Meta-Analytic Approach</title>
      <link>https://arxiv.org/abs/2602.15690</link>
      <description>arXiv:2602.15690v1 Announce Type: new 
Abstract: The empirical literature on the relationship between income inequality and economic growth has produced highly heterogeneous and often conflicting results. This paper investigates the sources of this heterogeneity using a meta-analytic approach that systematically combines and analyzes evidence from relevant studies published between 1994 and 2025. We find an economically small but statistically significant negative average effect of income inequality on subsequent economic growth, together with strong evidence of substantial heterogeneity and selective publication based on statistical significance, but no evidence of systematic directional bias. To explain the observed heterogeneity, we estimate a meta-regression. The results indicate that both real-world characteristics and research design choices shape reported effect sizes. In particular, inequality measured net of taxes and transfers is associated with more negative growth effects, and the adverse impact of inequality is weaker - or even reversed - in high-income economies relative to developing countries. Methodological choices also matter: cross-sectional studies tend to report more negative estimates, while fixed-effects, instrumental-variable, and GMM estimators are associated with more positive estimates in panel settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15690v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lisa Cpretti, Lorenzo Tonni</dc:creator>
    </item>
    <item>
      <title>Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement</title>
      <link>https://arxiv.org/abs/2602.15312</link>
      <description>arXiv:2602.15312v1 Announce Type: cross 
Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15312v1</guid>
      <category>cs.CL</category>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stephan Ludwig, Peter J. Danaher, Xiaohao Yang, Yu-Ting Lin, Ehsan Abedin, Dhruv Grewal, Lan Du</dc:creator>
    </item>
    <item>
      <title>Fixed-Horizon Self-Normalized Inference for Adaptive Experiments via Martingale AIPW/DML with Logged Propensities</title>
      <link>https://arxiv.org/abs/2602.15559</link>
      <description>arXiv:2602.15559v1 Announce Type: cross 
Abstract: Adaptive randomized experiments update treatment probabilities as data accrue, but still require an end-of-study interval for the average treatment effect (ATE) at a prespecified horizon. Under adaptive assignment, propensities can keep changing, so the predictable quadratic variation of AIPW/DML score increments may remain random. When no deterministic variance limit exists, Wald statistics normalized by a single long-run variance target can be conditionally miscalibrated given the realized variance regime. We assume no interference, sequential randomization, i.i.d. arrivals, and executed overlap on a prespecified scored set, and we require two auditable pipeline conditions: the platform logs the executed randomization probability for each unit, and the nuisance regressions used to score unit $t$ are constructed predictably from past data only. These conditions make the centered AIPW/DML scores an exact martingale difference sequence. Using self-normalized martingale limit theory, we show that the Studentized statistic, with variance estimated by realized quadratic variation, is asymptotically N(0,1) at the prespecified horizon, even without variance stabilization. Simulations validate the theory and highlight when standard fixed-variance Wald reporting fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15559v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Saco</dc:creator>
    </item>
    <item>
      <title>The geometry of online conversations and the causal antecedents of conflictual discourse</title>
      <link>https://arxiv.org/abs/2602.15600</link>
      <description>arXiv:2602.15600v1 Announce Type: cross 
Abstract: This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15600v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.34796.22409</arxiv:DOI>
      <dc:creator>Carlo Santagiustina, Caterina Cruciani</dc:creator>
    </item>
    <item>
      <title>Causal Effect Estimation with Latent Textual Treatments</title>
      <link>https://arxiv.org/abs/2602.15730</link>
      <description>arXiv:2602.15730v1 Announce Type: cross 
Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15730v1</guid>
      <category>cs.CL</category>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omri Feldman, Amar Venugopal, Jann Spiess, Amir Feder</dc:creator>
    </item>
    <item>
      <title>Peer effect analysis with latent processes</title>
      <link>https://arxiv.org/abs/2511.02764</link>
      <description>arXiv:2511.02764v2 Announce Type: replace 
Abstract: I study peer effects that arise from irreversible decisions in the absence of a standard social equilibrium. I model a latent sequence of decisions in continuous time and obtain a closed-form expression for the likelihood, which allows to estimate proposed causal estimands. The method avoids linear-in-means regression by modeling the (possibly unobserved) realized direction of causality, whose probability is identified. I provide identification and estimation results under two settings, several networks and one large network, while allowing for various forms of peer effect heterogeneity. Under (strong) data requirements, it is possible to separate endogenous, contextual, and correlated effects while allowing for full heterogeneity and maximum likelihood methods where parameters lend themselves to standard inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02764v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Starck</dc:creator>
    </item>
    <item>
      <title>Difference-in-Differences in the Presence of Unknown Interference</title>
      <link>https://arxiv.org/abs/2512.21176</link>
      <description>arXiv:2512.21176v2 Announce Type: replace 
Abstract: The stable unit treatment value (SUTVA) is a crucial assumption in the Difference-in-Differences (DiD) research design. It rules out hidden versions of treatment and any sort of interference and spillover effects across units. Even if this is a strong assumption, it has not received much attention from DiD practitioners and, in many cases, it is not even explicitly stated as an assumption, especially the no-interference assumption. In this technical note, we investigate what the DiD estimand identifies in the presence of unknown interference. We show that the DiD estimand identifies a contrast of causal effects, but it is not informative on any of these causal effects separately, without invoking further assumptions. Then, we explore different sets of assumptions under which the DiD estimand becomes informative about specific causal effects. We illustrate these results by revisiting the seminal paper on minimum wages and employment by Card and Krueger (1994).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21176v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabrizia Mealli, Javier Viviens</dc:creator>
    </item>
    <item>
      <title>Cluster-Robust Inference for Quadratic Forms</title>
      <link>https://arxiv.org/abs/2602.13537</link>
      <description>arXiv:2602.13537v2 Announce Type: replace 
Abstract: This paper studies inference for quadratic forms of linear regression coefficients with clustered data and many covariates. Our framework covers three important special cases: instrumental variables regression with many instruments and controls, inference on variance components, and testing multiple restrictions in a linear regression. Na\"{\i}ve plug-in estimators are known to be biased. We study a leave-one-cluster-out estimator that is unbiased, and provide sufficient conditions for its asymptotic normality. For inference, we establish the consistency of a leave-three-cluster-out variance estimator under primitive conditions. In addition, we develop a novel leave-two-cluster-out variance estimator that is computationally simpler and guaranteed to be conservative under weaker conditions. Our analysis allows cluster sizes to diverge with the sample size, accommodates strong within-cluster dependence, and permits the dimension of the covariates to diverge with the sample size, potentially at the same rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13537v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Koles\'ar, Pengjin Min, Wenjie Wang, Yichong Zhang</dc:creator>
    </item>
    <item>
      <title>Modified Delayed Acceptance MCMC for Quasi-Bayesian Inference with Linear Moment Conditions</title>
      <link>https://arxiv.org/abs/2511.17117</link>
      <description>arXiv:2511.17117v5 Announce Type: replace-cross 
Abstract: We develop a computationally efficient framework for quasi-Bayesian inference based on linear moment conditions. The approach employs a delayed acceptance Markov chain Monte Carlo (DA-MCMC) algorithm that uses a surrogate target kernel and a proposal distribution derived from an approximate conditional posterior, thereby exploiting the structure of the quasi-likelihood. Two implementations are introduced. DA-MCMC-Exact fully incorporates prior information into the proposal distribution and maximizes per-iteration efficiency, whereas DA-MCMC-Approx omits the prior in the proposal to reduce matrix inversions, improving numerical stability and computational speed in higher dimensions. Simulation studies on heteroskedastic linear regressions show substantial gains over standard MCMC and conventional DA-MCMC baselines, measured by multivariate effective sample size per iteration and per second. The Approx variant yields the best overall throughput, while the Exact variant attains the highest per-iteration efficiency. Applications to two empirical instrumental variable regressions corroborate these findings: the Approx implementation scales to larger designs where other methods become impractical, while still delivering precise inference. Although developed for moment-based quasi-posteriors, the proposed approach also extends to risk-based quasi-Bayesian formulations when first-order conditions are linear and can be transformed analogously. Overall, the proposed algorithms provide a practical and robust tool for quasi-Bayesian analysis in statistical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17117v5</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Tanaka</dc:creator>
    </item>
    <item>
      <title>Quantile Vector Autoregression without Crossing</title>
      <link>https://arxiv.org/abs/2601.04663</link>
      <description>arXiv:2601.04663v2 Announce Type: replace-cross 
Abstract: This paper considers estimation and model selection of quantile vector autoregression (QVAR). Conventional quantile regression often yields undesirable crossing quantile curves, violating the monotonicity of quantiles. To address this issue, we propose a simplex quantile vector autoregression (SQVAR) framework, which transforms the autoregressive (AR) structure of the original QVAR model into a simplex, ensuring that the estimated quantile curves remain monotonic across all quantile levels. In addition, we impose the smoothly clipped absolute deviation (SCAD) penalty on the SQVAR model to mitigate the explosive nature of the parameter space. We further develop a Bayesian information criterion (BIC)-based procedure for selecting the optimal penalty parameter and introduce new frameworks for impulse response analysis of QVAR models. Finally, we establish asymptotic properties of the proposed method, including the convergence rate and asymptotic normality of the estimator, the consistency of AR order selection, and the validity of the BIC-based penalty selection. For illustration, we apply the proposed method to U.S. financial market data, highlighting the usefulness of our SQVAR method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04663v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomohiro Ando, Tadao Hoshino, Ruey Tsay</dc:creator>
    </item>
  </channel>
</rss>
