<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Oct 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust globally divergence-free weak Galerkin methods for unsteady incompressible convective Brinkman-Forchheimer equations</title>
      <link>https://arxiv.org/abs/2410.21289</link>
      <description>arXiv:2410.21289v1 Announce Type: new 
Abstract: This paper develops and analyzes a class of semi-discrete and fully discrete weak Galerkin finite element methods for unsteady incompressible convective Brinkman-Forchheimer equations. For the spatial discretization, the methods adopt the piecewise polynomials of degrees $m\ (m\geq1)$ and $m-1$ respectively to approximate the velocity and pressure inside the elements, and piecewise polynomials of degree $m$ to approximate their numerical traces on the interfaces of elements. In the fully discrete method, the backward Euler difference scheme is used to approximate the time derivative. The methods are shown to yield globally divergence-free velocity approximation. Optimal a priori error estimates in the energy norm and $L^2$ norm are established. A convergent linearized iterative algorithm is designed for solving the fully discrete system. Numerical experiments are provided to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21289v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojuan Wang, Jihong Xiao, Xiaoping Xie, Shiquan Zhang</dc:creator>
    </item>
    <item>
      <title>A Mathematical Analysis of Neural Operator Behaviors</title>
      <link>https://arxiv.org/abs/2410.21481</link>
      <description>arXiv:2410.21481v1 Announce Type: new 
Abstract: Neural operators have emerged as transformative tools for learning mappings between infinite-dimensional function spaces, offering useful applications in solving complex partial differential equations (PDEs). This paper presents a rigorous mathematical framework for analyzing the behaviors of neural operators, with a focus on their stability, convergence, clustering dynamics, universality, and generalization error. By proposing a list of novel theorems, we provide stability bounds in Sobolev spaces and demonstrate clustering in function space via gradient flow interpretation, guiding neural operator design and optimization. Based on these theoretical gurantees, we aim to offer clear and unified guidance in a single setting for the future design of neural operator-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21481v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vu-Anh Le, Mehmet Dik</dc:creator>
    </item>
    <item>
      <title>Scaled-up prediction of steady Navier-Stokes equation with component reduced order modeling</title>
      <link>https://arxiv.org/abs/2410.21534</link>
      <description>arXiv:2410.21534v1 Announce Type: new 
Abstract: Scaling up new scientific technologies from laboratory to industry often involves demonstrating performance on a larger scale. Computer simulations can accelerate design and predictions in the deployment process, though traditional numerical methods are computationally intractable even for intermediate pilot plant scales. Recently, component reduced order modeling method is developed to tackle this challenge by combining projection reduced order modeling and discontinuous Galerkin domain decomposition. However, while many scientific or engineering applications involve nonlinear physics, this method has been only demonstrated for various linear systems. In this work, the component reduced order modeling method is extended to steady Navier-Stokes flow, with application to general nonlinear physics in view. Large-scale, global domain is decomposed into combination of small-scale unit component. Linear subspaces for flow velocity and pressure are identified via proper orthogonal decomposition over sample snapshots collected at small scale unit component. Velocity bases are augmented with pressure supremizer, in order to satisfy inf-sup condition for stable pressure prediction. Two different nonlinear reduced order modeling methods are employed and compared for efficient evaluation of nonlinear advection: 3rd-order tensor projection operator and empirical quadrature procedure. The proposed method is demonstrated on flow over arrays of five different unit objects, achieving $23$ times faster prediction with less than $4\%$ relative error up to $256$ times larger scale domain than unit components. Furthermore, a numerical experiment with pressure supremizer strongly indicates the need of supremizer for stable pressure prediction. A comparison between tensorial approach and empirical quadrature procedure is performed, which suggests a slight advantage for empirical quadrature procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21534v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seung Whan Chung, Youngsoo Choi, Pratanu Roy, Thomas Roy, Tiras Y. Lin, Du T. Nguyen, Christopher Hahn, Eric B. Duoss, Sarah E. Baker</dc:creator>
    </item>
    <item>
      <title>Hybrid Adaptive Dual Reciprocity Method for Efficient Solution of Large-Scale Non-Linear Boundary Conditions</title>
      <link>https://arxiv.org/abs/2410.21567</link>
      <description>arXiv:2410.21567v1 Announce Type: new 
Abstract: This article proposes a hybrid adaptive numerical method based on the Dual Reciprocity Method (DRM) to solve problems with non-linear boundary conditions and large-scale problems, named Hybrid Adaptive Dual Reciprocity Method (H-DRM). The method uses a combination of DRM to handle non-homogeneous terms, iterative techniques to deal with non-linear boundary conditions, and an adaptive multiscale approach for large-scale problems. Additionally, the H-DRM incorporates local finite elements in critical regions of the domain. This method aims to improve computational efficiency and accuracy for problems involving complex geometry and non-linearities at the boundary, offering a robust solution for physical and engineering problems. Demonstrations and computational results are presented, validating the effectiveness of the method compared to other known methods through an iterative process of 7 million iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21567v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>R\^omulo Damasclin Chaves dos Santos, Jorge Henrique de Oliveira Sales</dc:creator>
    </item>
    <item>
      <title>Scalable physics-guided data-driven component model reduction for steady Navier-Stokes flow</title>
      <link>https://arxiv.org/abs/2410.21583</link>
      <description>arXiv:2410.21583v1 Announce Type: new 
Abstract: Computational physics simulation can be a powerful tool to accelerate industry deployment of new scientific technologies. However, it must address the challenge of computationally tractable, moderately accurate prediction at large industry scales, and training a model without data at such large scales. A recently proposed component reduced order modeling (CROM) tackles this challenge by combining reduced order modeling (ROM) with discontinuous Galerkin domain decomposition (DG-DD). While it can build a component ROM at small scales that can be assembled into a large scale system, its application is limited to linear physics equations. In this work, we extend CROM to nonlinear steady Navier-Stokes flow equation. Nonlinear advection term is evaluated via tensorial approach or empirical quadrature procedure. Application to flow past an array of objects at moderate Reynolds number demonstrates $\sim23.7$ times faster solutions with a relative error of $\sim 2.3\%$, even at scales $256$ times larger than the original problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21583v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seung Whan Chung, Youngsoo Choi, Pratanu Roy, Thomas Roy, Tiras Y. Lin, Du T. Nguyen, Christopher Hahn, Eric B. Duoss, Sarah E. Baker</dc:creator>
    </item>
    <item>
      <title>Tensor-based empirical interpolation method,\newline and its application in model reduction</title>
      <link>https://arxiv.org/abs/2410.21770</link>
      <description>arXiv:2410.21770v1 Announce Type: new 
Abstract: In general, matrix or tensor-valued functions are approximated using the method developed for vector-valued functions by transforming the matrix-valued function into vector form. This paper proposes a tensor-based interpolation method to approximate a matrix-valued function without transforming it into the vector form. The tensor-based technique has the advantage of reducing offline and online computation without sacrificing much accuracy. The proposed method is an extension of the empirical interpolation method (EIM) for tensor bases. This paper presents a necessary theoretical framework to understand the method's functioning and limitations. Our mathematical analysis establishes a key characteristic of the proposed method: it consistently generates interpolation points in the form of a rectangular grid. This observation underscores a fundamental limitation that applies to any matrix-based approach relying on widely used techniques like EIM or DEIM method. It has also been theoretically shown that the proposed method is equivalent to the DEIM method applied in each direction due to the rectangular grid structure of the interpolation points. The application of the proposed method is shown in the model reduction of the semi-linear matrix differential equation. We have compared the approximation result of our proposed method with the DEIM method used to approximate a vector-valued function. The comparison result shows that the proposed method takes less time, albeit with a minor compromise with accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21770v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brij Nandan Tripathi, Hanumant Singh Shekhawat, Seip Weiland</dc:creator>
    </item>
    <item>
      <title>Strong backward error analysis of stochastic Poisson integrators</title>
      <link>https://arxiv.org/abs/2410.21817</link>
      <description>arXiv:2410.21817v1 Announce Type: new 
Abstract: We address our attention to the numerical time discretization of stochastic Poisson systems via Poisson integrators. The aim of the investigation regards the backward error analysis of such integrators to reveal their ability of being structure-preserving, for long times of integration. In particular, we first provide stochastic modified equations suitable for such integrators and then we rigorously study them to prove accurate estimates on the long-term numerical error along the dynamics generated by stochastic Poisson integrators, with reference to the preservation of the random Hamiltonian conserved along the exact flow of the approximating Wong-Zakai Poisson system. Finally, selected numerical experiments confirm the effectiveness of the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21817v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raffaele D'Ambrosio, Stefano Di Giovacchino</dc:creator>
    </item>
    <item>
      <title>Secure numerical simulations using fully homomorphic encryption</title>
      <link>https://arxiv.org/abs/2410.21824</link>
      <description>arXiv:2410.21824v1 Announce Type: new 
Abstract: Data privacy is a significant concern in many environments today. This is particularly true if sensitive information, e.g., engineering, medical, or financial data, is to be processed on potentially insecure systems, as it is often the case in cloud computing. Fully homomorphic encryption (FHE) offers a potential solution to this problem, as it allows for secure computations on encrypted data. In this paper, we investigate the viability of using FHE for privacy-preserving numerical simulations of partial differential equations. We first give an overview of the CKKS scheme, a popular FHE method for computations with real numbers. This is followed by an introduction of our Julia packages OpenFHE.jl and SecureArithmetic.jl, which provide a Julia wrapper for the C++ library OpenFHE and offer a user-friendly interface for secure arithmetic operations. We then present a performance analysis of the CKKS scheme within OpenFHE, focusing on the error and efficiency of different FHE operations. Finally, we demonstrate the application of FHE to secure numerical simulations by implementing two finite difference schemes for the linear advection equation using the SecureArithmetic.jl package. Our results show that FHE can be used to perform cryptographically secure numerical simulations, but that the error and efficiency of FHE operations must be carefully considered when designing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21824v1</guid>
      <category>math.NA</category>
      <category>cs.CR</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arseniy Kholod, Yuriy Polyakov, Michael Schlottke-Lakemper</dc:creator>
    </item>
    <item>
      <title>A generalized Nystrom method with column sketching for low-rank approximation of nonsymmetric matrices</title>
      <link>https://arxiv.org/abs/2410.21829</link>
      <description>arXiv:2410.21829v1 Announce Type: new 
Abstract: This paper is concerned with the low-rank approximation for large-scale nonsymmetric matrices. Inspired by the classical Nystrom method, which is a popular method to find the low-rank approximation for symmetric positive semidefinite matrices, we explore an extension of the Nystrom method to approximate nonsymmetric matrices. The proposed method is a generalized Nystrom method with column sketching and shows its advantages in accuracy and speed without sacri cing stability. And the numerical experiments will illustrate the robustness of our new methods in finding a desired low-rank approximation of nonsymmetric matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21829v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yatian Wang, Hua Xiang, Chi Zhang, Songling Zhang</dc:creator>
    </item>
    <item>
      <title>Neural network representation of microflows with BGK model</title>
      <link>https://arxiv.org/abs/2410.21935</link>
      <description>arXiv:2410.21935v1 Announce Type: new 
Abstract: We consider the neural representation to solve the Boltzmann-BGK equation, especially focusing on the application in microscopic flow problems. A new dimension reduction model of the BGK equation with the flexible auxiliary distribution functions is first deduced to reduce the problem dimension. Then, a network-based ansatz that can approximate the dimension-reduced distribution with extremely high efficiency is proposed. Precisely, fully connected neural networks are utilized to avoid discretization in space and time. A specially designed loss function is employed to deal with the complex Maxwell boundary in microscopic flow problems. Moreover, strategies such as multi-scale input and Maxwellian splitting are applied to enhance the approximation efficiency further. Several classical numerical experiments, including 1D Couette flow and Fourier flow problems and 2D duct flow and in-out flow problems are studied to demonstrate the effectiveness of this neural representation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21935v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pei Zhang, Yanli Wang</dc:creator>
    </item>
    <item>
      <title>A preconditioning technique of Gauss--Legendre quadrature for the logarithm of symmetric positive definite matrices</title>
      <link>https://arxiv.org/abs/2410.22014</link>
      <description>arXiv:2410.22014v1 Announce Type: new 
Abstract: This note considers the computation of the logarithm of symmetric positive definite matrices using the Gauss--Legendre (GL) quadrature. The GL quadrature becomes slow when the condition number of the given matrix is large. In this note, we propose a technique dividing the matrix logarithm into two matrix logarithms, where the condition numbers of the divided logarithm arguments are smaller than that of the original matrix. Although the matrix logarithm needs to be computed twice, each computation can be performed more efficiently, and it potentially reduces the overall computational cost. It is shown that the proposed technique is effective when the condition number of the given matrix is approximately between $130$ and $3.0\times 10^5$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22014v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuminori Tatsuoka, Tomohiro Sogabe, Tomoya Kemmochi, Shao-Liang Zhang</dc:creator>
    </item>
    <item>
      <title>Error estimates for perturbed variational inequalities of the first kind</title>
      <link>https://arxiv.org/abs/2410.22052</link>
      <description>arXiv:2410.22052v1 Announce Type: new 
Abstract: In this paper, we derive a priori error estimates for variational inequalities of the first kind in an abstract framework. This is done by combining the first Strang Lemma and the Falk Theorem. The main application consists in the derivation of a priori error estimates for Galerkin methods, in which "variational crimes" may perturb the underlying variational inequality. Different types of perturbations are incorporated into the abstract framework and discussed by various examples. For instance, the perturbation caused by an inexact quadrature is examined in detail for the Laplacian obstacle problem. For this problem, guaranteed rates for the approximation error resulting from the use of higher-order finite elements are derived. In numerical experiments, the influence of the number of quadrature points on the approximation error and on the quadrature-related error itself is studied for several discretization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22052v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lothar Banz, Miriam Sch\"onauer, Andreas Schr\"oder</dc:creator>
    </item>
    <item>
      <title>On Regularisation of Coherent Imagery with Proximal Methods</title>
      <link>https://arxiv.org/abs/2410.22161</link>
      <description>arXiv:2410.22161v1 Announce Type: new 
Abstract: In complex-valued coherent inverse problems such as synthetic aperture radar (SAR), one may often have prior information only on the magnitude image which shows the features of interest such as strength of reflectivity. In contrast, there may be no more prior knowledge of the phase beyond it being a uniform random variable. However, separately regularising the magnitude, via some function \(G:=H(|\cdot|)\), would appear to lead to a potentially challenging non-linear phase fitting problem in each iteration of even a linear least-squares reconstruction problem. We show that under certain sufficient conditions the proximal map of such a function \(G\) may be calculated as a simple phase correction to that of \(H\). Further, we provide proximal map of (almost) arbitrary \(G:=H(|\cdot|)\) which does not meet these sufficient conditions. This may be calculated through a simple numerical scheme making use of the proximal map of \(H\) itself, and thus we provide a means to apply practically arbitrary regularisation functions to the magnitude when solving coherent reconstruction problems via proximal optimisation algorithms. This is demonstrated using publicly available real SAR data for generalised Tikhonov regularisation applied to multi-channel SAR, and both a simple level set formulation and total generalised variation applied to the standard single-channel case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22161v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>F. M. Watson, W. R. B. Lionheart, J. Hellier</dc:creator>
    </item>
    <item>
      <title>Regularization of Discrete Ill-Conditioned Problems Done Right -- I</title>
      <link>https://arxiv.org/abs/2410.22169</link>
      <description>arXiv:2410.22169v1 Announce Type: new 
Abstract: When solving rank-deficient or discrete ill-posed problems by regularization methods, the choice of the regularization parameter is crucial. It is also of interest, the regularization norm used in the selection of the solution. In this work, we propose a stabilization of the existing regularization methods to address the delicate task of choosing this parameter. The analysis we carried out is independent of the chosen regularization norm. Under an unperturbed data least squares problem and of a maximal rank matrix, the stabilized-regularized method we propose provides the minimal norm solution whatever the chosen positive regularization parameter. And under a perturbed data least squares problem, this approach provides increasingly accurate and stable approximations of the minimal norm solution with respect to a refined mesh and a huge regularization parameter (over-regularization). We also investigate standard rank-deficient and ill-posed numerical examples corroborating the theoretical analysis, where the accuracy and the stability of the proposed approach is widely discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22169v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ibrahima Dione</dc:creator>
    </item>
    <item>
      <title>An alternating low-rank projection approach for partial differential equations with random inputs</title>
      <link>https://arxiv.org/abs/2410.22183</link>
      <description>arXiv:2410.22183v1 Announce Type: new 
Abstract: It is known that standard stochastic Galerkin methods face challenges when solving partial differential equations (PDEs) with random inputs. These challenges are typically attributed to the large number of required physical basis functions and stochastic basis functions. Therefore, it becomes crucial to select effective basis functions to properly reduce the dimensionality of both the physical and stochastic approximation spaces. In this study, our focus is on the stochastic Galerkin approximation associated with generalized polynomial chaos (gPC). We delve into the low-rank approximation of the quasimatrix, whose columns represent the coefficients in the gPC expansions of the solution. We conduct an investigation into the singular value decomposition (SVD) of this quasimatrix, proposing a strategy to identify the rank required for a desired accuracy. Subsequently, we introduce both a simultaneous low-rank projection approach and an alternating low-rank projection approach to compute the low-rank approximation of the solution for PDEs with random inputs. Numerical results demonstrate the efficiency of our proposed methods for both diffusion and Helmholtz problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22183v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanjie Wang, Qifeng Liao</dc:creator>
    </item>
    <item>
      <title>GRINNs: Godunov-Riemann Informed Neural Networks for Learning Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2410.22193</link>
      <description>arXiv:2410.22193v1 Announce Type: new 
Abstract: We present GRINNs: numerical analysis-informed neural networks for the solution of inverse problems of non-linear systems of conservation laws. GRINNs are based on high-resolution Godunov schemes for the solution of the Riemann problem in hyperbolic Partial Differential Equations (PDEs). In contrast to other existing machine learning methods that learn the numerical fluxes of conservative Finite Volume methods, GRINNs learn the physical flux function per se. Due to their structure, GRINNs provide interpretable, conservative schemes, that learn the solution operator on the basis of approximate Riemann solvers that satisfy the Rankine-Hugoniot condition. The performance of GRINNs is assessed via four benchmark problems, namely the Burgers', the Shallow Water, the Lighthill-Whitham-Richards and the Payne-Whitham traffic flow models. The solution profiles of these PDEs exhibit shock waves, rarefactions and/or contact discontinuities at finite times. We demonstrate that GRINNs provide a very high accuracy both in the smooth and discontinuous regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22193v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitrios G. Patsatzis, Mario di Bernardo, Lucia Russo, Constantinos Siettos</dc:creator>
    </item>
    <item>
      <title>Long-term error analysis of low-regularity integrators for stochastic Schr$\ddot{\rm o}$dinger equations</title>
      <link>https://arxiv.org/abs/2410.22201</link>
      <description>arXiv:2410.22201v1 Announce Type: new 
Abstract: In this paper, we design non-resonant low-regularity numerical integrators for the cubic nonlinear stochastic Schr$\ddot{\rm o}$dinger equations (SNLSE). First, we begin with a mean-square convergence analysis for an explicit low-regularity stochastic integrator for the cubic SNLSE and, then, under the assumption of initial data of size $\mathcal{O}(\varepsilon), \varepsilon \in (0,1]$, following the {regularity compensation oscillation} technique \cite{sch0,ala,bao}, we provide rigorous long-term error estimates in the space $L^2(\Omega, H^\sigma), \sigma &gt;1/2$. Our findings reveal improved long-time behaviour allowing for an error of size
  $\mathcal{O}\left(\tau\cdot \varepsilon^{{\rm min}(4,2(q-2))}\right), q&gt;2$, up to time of size $\mathcal{O}(\varepsilon^{-2})$. Numerically findings confirm the superior long-time behaviour of our new schemes compared to classical numerical schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22201v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Di Giovacchino, Katharina Schratz</dc:creator>
    </item>
    <item>
      <title>Surface reconstruction from point cloud using a semi-Lagrangian scheme with local interpolator</title>
      <link>https://arxiv.org/abs/2410.22205</link>
      <description>arXiv:2410.22205v1 Announce Type: new 
Abstract: We propose a level set method to reconstruct unknown surfaces from point clouds, without assuming that the connections between points are known. We consider a variational formulation with a curvature constraint that minimizes the surface area weighted by the distance of the surface from the point cloud. More precisely we solve an equivalent advection-diffusion equation that governs the evolution of an initial surface described implicitly by a level set function. Among all the possible representations, we aim to compute the signed distance function at least in the vicinity of the reconstructed surface. The numerical method for the approximation of the solution is based on a semi-Lagrangian scheme whose main novelty consists in its coupling with a local interpolator instead of a global one, with the aim of saving computational costs. In particular, we resort to a multi-linear interpolator and to a Weighted Essentially Non-oscillatory one, to improve the accuracy of the reconstruction. Special attention has been paid to the localization of the method and to the development of fast algorithms that run in parallel, resulting in faster reconstruction and thus the opportunity to easily improve the resolution. A preprocessing of the point cloud data is also proposed to set the parameters of the method. Numerical tests in two and three dimensions are presented to evaluate the quality of the approximated solution and the efficiency of the algorithm in terms of computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22205v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Silvia Preda, Matteo Semplice</dc:creator>
    </item>
    <item>
      <title>Numerical solution of BVP for the incompressible Navier-Stokes equations at large Reynolds numbers</title>
      <link>https://arxiv.org/abs/2410.22268</link>
      <description>arXiv:2410.22268v1 Announce Type: new 
Abstract: The problems of numerical modeling of viscous incompressible fluid flows are widely considered in computational fluid dynamics. Stationary solutions of boundary value problems for the Navier-Stokes equations exist at large Reynolds numbers, but they are unstable and lead to transient or turbulent unsteady regimes. In addition, the solution of the boundary value problem at large values of Reynolds number may be non-unique. In this paper, we consider computational algorithms numerical algorithms for finding such stationary solutions. We use natural pressure-velocity variables under standard finite element approximation on triangular grids. Iterative methods with different linearizations of convective transport are used to test a two-dimensional problem of incompressible fluid flow in a square-section cavity with a movable top lid. The developed computational algorithm allowed us to obtain two solutions when the Reynolds number exceeds a critical value for flows in a cavity of semi-elliptical cross-section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22268v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D. V. Lomasov, P. N. Vabishchevich</dc:creator>
    </item>
    <item>
      <title>Deterministic complexity analysis of Hermitian eigenproblems</title>
      <link>https://arxiv.org/abs/2410.21550</link>
      <description>arXiv:2410.21550v1 Announce Type: cross 
Abstract: In this work we revisit the arithmetic and bit complexity of Hermitian eigenproblems. We first provide an analysis for the divide-and-conquer tridiagonal eigensolver of Gu and Eisenstat [GE95] in the Real RAM model, when accelerated with the Fast Multipole Method. The analysis asserts the claimed nearly-$O(n^2)$ complexity to compute a full diagonalization of a symmetric tridiagonal matrix. Combined with the tridiagonal reduction algorithm of Sch\"onhage [Sch72], it implies that a Hermitian matrix can be diagonalized deterministically in $O(n^{\omega}\log(n)+n^2\mathrm{polylog}(n/\epsilon))$ arithmetic operations, where $\omega\lesssim 2.371$ is the square matrix multiplication exponent. This improves the classic deterministic $O(n^3)$ diagonalization algorithms, and derandomizes the $ O(n^{\omega}\log^2(n/\epsilon))$ algorithm of [BGVKS, FOCS '20]. Ultimately, this has a direct application to the SVD, which is widely used as a subroutine in advanced algorithms, but its complexity and approximation guarantees are often unspecified.
  In finite precision, we show that Sch\"onhage's algorithm is stable in floating point using $O(\log(n/\epsilon))$ bits. Combined with the (rational arithmetic) algorithm of Bini and Pan [BP91], it provides a deterministic algorithm to compute all the eigenvalues of a Hermitian matrix in $O\left(n^{\omega}F\left(\log(n/\epsilon)\right)+n^2\mathrm{polylog}(n/\epsilon)\right)$ bit operations, where $F(b)\in\widetilde{O}(b)$ is the bit complexity of a single floating point operation on $b$ bits. This improves the best known $\widetilde{O}(n^3)$ deterministic and $O\left( n^{\omega}\log^2(n/\epsilon)F\left(\log^4(n/\epsilon)\log(n)\right)\right)$ randomized complexities. We conclude with some other useful subroutines such as computing spectral gaps, condition numbers, and spectral projectors, and few open problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21550v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aleksandros Sobczyk</dc:creator>
    </item>
    <item>
      <title>Multiple-beam Interference Spectroscopy: Instrument Analysis and Spectrum Reconstruction</title>
      <link>https://arxiv.org/abs/2410.21586</link>
      <description>arXiv:2410.21586v1 Announce Type: cross 
Abstract: Hyperspectral imaging systems based on multiple-beam interference (MBI), such as Fabry-Perot interferometry, are attracting interest due to their compact design, high throughput, and fine resolution. Unlike dispersive devices, which measure spectra directly, the desired spectra in interferometric systems are reconstructed from measured interferograms. Although the response of MBI devices is modeled by the Airy function, existing reconstruction techniques are often limited to Fourier-transform spectroscopy, which is tailored for two-beam interference (TBI). These methods impose limitations for MBI and are susceptible to non-idealities like irregular sampling and noise, highlighting the need for an in-depth numerical framework. To fill this gap, we propose a rigorous taxonomy of the TBI and MBI instrument description and propose a unified Bayesian formulation which both embeds the description of existing literature works and adds some of the real-world non-idealities of the acquisition process. Under this framework, we provide a comprehensive review of spectroscopy forward and inverse models. In the forward model, we propose a thorough analysis of the discretization of the continuous model and the ill-posedness of the problem. In the inverse model, we extend the range of existing solutions for spectrum reconstruction, framing them as an optimization problem. Specifically, we provide a progressive comparative analysis of reconstruction methods from more specific to more general scenarios, up to employing the proposed Bayesian framework with prior knowledge, such as sparsity constraints. Experiments on simulated and real data demonstrate the framework's flexibility and noise robustness. The code is available at https://github.com/mhmdjouni/inverspyctrometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21586v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamad Jouni, Daniele Picone, Mauro Dalla Mura</dc:creator>
    </item>
    <item>
      <title>Improved Spectral Density Estimation via Explicit and Implicit Deflation</title>
      <link>https://arxiv.org/abs/2410.21690</link>
      <description>arXiv:2410.21690v1 Announce Type: cross 
Abstract: We study algorithms for approximating the spectral density of a symmetric matrix $A$ that is accessed through matrix-vector product queries. By combining a previously studied Chebyshev polynomial moment matching method with a deflation step that approximately projects off the largest magnitude eigendirections of $A$ before estimating the spectral density, we give an $\epsilon\cdot\sigma_\ell(A)$ error approximation to the spectral density in the Wasserstein-$1$ metric using $O(\ell\log n+ 1/\epsilon)$ matrix-vector products, where $\sigma_\ell(A)$ is the $\ell^{th}$ largest singular value of $A$. In the common case when $A$ exhibits fast singular value decay, our bound can be much stronger than prior work, which gives an error bound of $\epsilon \cdot ||A||_2$ using $O(1/\epsilon)$ matrix-vector products. We also show that it is nearly tight: any algorithm giving error $\epsilon \cdot \sigma_\ell(A)$ must use $\Omega(\ell+1/\epsilon)$ matrix-vector products.
  We further show that the popular Stochastic Lanczos Quadrature (SLQ) method matches the above bound, even though SLQ itself is parameter-free and performs no explicit deflation. This bound explains the strong practical performance of SLQ, and motivates a simple variant of SLQ that achieves an even tighter error bound. Our error bound for SLQ leverages an analysis that views it as an implicit polynomial moment matching method, along with recent results on low-rank approximation with single-vector Krylov methods. We use these results to show that the method can perform implicit deflation as part of moment matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21690v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajarshi Bhattacharjee, Rajesh Jayaram, Cameron Musco, Christopher Musco, Archan Ray</dc:creator>
    </item>
    <item>
      <title>Numerical Boundary Control of Multi-Dimensional Hyperbolic Equations</title>
      <link>https://arxiv.org/abs/2410.21890</link>
      <description>arXiv:2410.21890v1 Announce Type: cross 
Abstract: Existing theoretical stabilization results for linear, hyperbolic multi-dimensional problems are extended to the discretized multi-dimensional problems. In contrast to existing theoretical and numerical analysis in the spatially one-dimensional case the effect of the numerical dissipation is analyzed and explicitly quantified. Further, using dimensional splitting, the numerical analysis is extended to the multi-dimensional case. The findings are confirmed by numerical simulations for low-order and high-order DG schemes both in the one-dimensional and two-dimensional case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21890v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Herty, Kai Hinzmann, Siegfried M\"uller, Ferdinand Thein</dc:creator>
    </item>
    <item>
      <title>On Eigenvector Approximation of Diagonalizable Random Matrices with Random Perturbations: Properties and Applications</title>
      <link>https://arxiv.org/abs/2410.21919</link>
      <description>arXiv:2410.21919v1 Announce Type: cross 
Abstract: We extend the result on the top eigenvalue of the i.i.d.\ matrix with fixed perturbations by Tao to random perturbations. In particular, we consider a setup that $\mathbf{M}=\mathbf{W}+\lambda\mathbf{u}\mathbf{u}^*$ with $\mathbf{W}$ drawn from a Ginibre Orthogonal Ensemble and the perturbation $\mathbf{u}$ drawn uniformly from $\mathcal{S}^{d-1}$. We provide several asymptotic properties about the eigenvalues and the top eigenvector of the random matrix, which can not be obtained trivially from the deterministic perturbation case.
  We also apply our results to extend the work of Max Simchowitz, which provides an optimal lower bound for approximating the eigenspace of a symmetric matrix. We present a \textit{query complexity} lower bound for approximating the eigenvector of any asymmetric but diagonalizable matrix $\mathbf{M}$ corresponding to the largest eigenvalue. We show that for every $\operatorname{gap}\in (0,1/2]$ and large enough dimension $d$, there exists a random matrix $\mathbf{M}$ with $\operatorname{gap}(\mathbf{M})=\Omega(\operatorname{gap})$, such that if a matrix-vector query product algorithm can identity a vector $\hat{\mathbf{v}}$ which satisfies $\left\|\hat{\mathbf{v}}-\mathbf{v}_1(\mathbf{M}) \right\|_2^2\le \operatorname{const}\times \operatorname{gap}$, it needs at least $\mathcal{O}\left(\frac{\log d}{\operatorname{gap}}\right)$ queries of matrix-vector products. In the inverse polynomial accuracy regime where $\epsilon \ge \frac{1}{\operatorname{poly}(d)}$, the complexity matches the upper bounds $\mathcal{O}\left(\frac{\log(d/\epsilon)}{\operatorname{gap}}\right)$, which can be obtained via the power method. As far as we know, it is the first lower bound for computing the eigenvector of an asymmetric matrix, which is far more complicated than in the symmetric case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21919v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Chen, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Finite Element Methods for the Stretching and Bending of Thin Structures with Folding</title>
      <link>https://arxiv.org/abs/2311.04810</link>
      <description>arXiv:2311.04810v2 Announce Type: replace 
Abstract: In [Bonito et al., J. Comput. Phys. (2022)], a local discontinuous Galerkin method was proposed for approximating the large bending of prestrained plates, and in [Bonito et al., IMA J. Numer. Anal. (2023)] the numerical properties of this method were explored. These works considered deformations driven predominantly by bending. Thus, a bending energy with a metric constraint was considered. We extend these results to the case of an energy with both a bending component and a nonconvex stretching component, and we also consider folding across a crease. The proposed discretization of this energy features a continuous finite element space, as well as a discrete Hessian operator. We establish the $\Gamma$-convergence of the discrete to the continuous energy and also present an energy-decreasing gradient flow for finding critical points of the discrete energy. Finally, we provide numerical simulations illustrating the convergence of minimizers and the capabilities of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04810v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Bonito, Diane Guignard, Angelique Morvant</dc:creator>
    </item>
    <item>
      <title>A shooting-Newton procedure for solving fractional terminal value problems</title>
      <link>https://arxiv.org/abs/2312.08516</link>
      <description>arXiv:2312.08516v5 Announce Type: replace 
Abstract: In this paper we consider the numerical solution of fractional terminal value problems (FDE-TVPs). In particular, the proposed procedure uses a Newton-type iteration which is particularly efficient when coupled with a recently-introduced step-by-step procedure for solving fractional initial value problems (FDE-IVPs), able to produce spectrally accurate solutions of FDE problems. Some numerical tests are reported to make evidence of its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08516v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luigi Brugnano, Gianmarco Gurioli, Felice Iavernaro</dc:creator>
    </item>
    <item>
      <title>How sharp are error bounds? --lower bounds on quadrature worst-case errors for analytic functions</title>
      <link>https://arxiv.org/abs/2401.07196</link>
      <description>arXiv:2401.07196v2 Announce Type: replace 
Abstract: Numerical integration over the real line for analytic functions is studied. Our main focus is on the sharpness of the error bounds. We first derive two general lower estimates for the worst-case integration error, and then apply these to establish lower bounds for various quadrature rules. These bounds turn out to be either novel or improve upon existing results, leading to lower bounds that closely match upper bounds for various formulas. Specifically, for the suitably truncated trapezoidal rule, we improve upon general lower bounds on the worst-case error obtained by Sugihara [\textit{Numer. Math.}, 75 (1997), pp.~379--395] and provide exceptionally sharp lower bounds apart from a polynomial factor, and in particular show that the worst-case error for the trapezoidal rule by Sugihara is not improvable by more than a polynomial factor. Additionally, our research reveals a discrepancy between the error decay of the trapezoidal rule and Sugihara's lower bound for general numerical integration rules, introducing a new open problem. Moreover, Gauss--Hermite quadrature is proven sub-optimal under the decay conditions on integrands we consider, a result not deducible from upper-bound arguments alone. Furthermore, to establish the near-optimality of the suitably scaled Gauss--Legendre and Clenshaw--Curtis quadratures, we generalize a recent result of Trefethen [\textit{SIAM Rev.}, 64 (2022), pp.~132--150] for the upper error bounds in terms of the decay conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07196v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1634163</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Numerical Analysis Vol. 62, Iss. 5 (2024)</arxiv:journal_reference>
      <dc:creator>Takashi Goda, Yoshihito Kazashi, Ken'ichiro Tanaka</dc:creator>
    </item>
    <item>
      <title>MOCCA: A Fast Algorithm for Parallel MRI Reconstruction Using Model Based Coil Calibration</title>
      <link>https://arxiv.org/abs/2403.12611</link>
      <description>arXiv:2403.12611v2 Announce Type: replace 
Abstract: We propose a new fast algorithm for simultaneous recovery of the coil sensitivities and of the magnetization image from incomplete Fourier measurements in parallel MRI. Our approach is based on a parameter model for the coil sensitivities using bivariate trigonometric polynomials of small degree. The derived MOCCA algorithm has low computational complexity of $O(N_c N^2 \log N)$ for $N \times N$ images and $N_c$ coils and achieves very good performance for incomplete MRI data. We present a complete mathematical analysis of the proposed reconstruction method. Further, we show that MOCCA achieves similarly good reconstruction results as ESPIRiT with a considerably smaller numerical effort which is due to the employed parameter model. Our numerical examples show that MOCCA can outperform several other reconstruction methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12611v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gerlind Plonka, Yannick Riebe</dc:creator>
    </item>
    <item>
      <title>Lattice Boltzmann for linear elastodynamics: periodic problems and Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2408.01081</link>
      <description>arXiv:2408.01081v2 Announce Type: replace 
Abstract: We propose a new second-order accurate lattice Boltzmann formulation for linear elastodynamics that is stable for arbitrary combinations of material parameters under a CFL-like condition. The construction of the numerical scheme uses an equivalent first-order hyperbolic system of equations as an intermediate step, for which a vectorial lattice Boltzmann formulation is introduced. The only difference to conventional lattice Boltzmann formulations is the usage of vector-valued populations, so that all computational benefits of the algorithm are preserved. Using the asymptotic expansion technique and the notion of pre-stability structures we further establish second-order consistency as well as analytical stability estimates. Lastly, we introduce a second-order consistent initialization of the populations as well as a boundary formulation for Dirichlet boundary conditions on 2D rectangular domains. All theoretical derivations are numerically verified by convergence studies using manufactured solutions and long-term stability tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01081v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2024.117469</arxiv:DOI>
      <dc:creator>Oliver Boolakee, Martin Geier, Laura De Lorenzis</dc:creator>
    </item>
    <item>
      <title>Adaptive Growing Randomized Neural Networks for Solving Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2408.17225</link>
      <description>arXiv:2408.17225v2 Announce Type: replace 
Abstract: Randomized neural network (RNN) methods have been proposed for solving various partial differential equations (PDEs), demonstrating high accuracy and efficiency. However, initializing the fixed parameters remains a challenging issue. Additionally, RNNs often struggle to solve PDEs with sharp or discontinuous solutions. In this paper, we propose a novel approach called Adaptive Growing Randomized Neural Network (AG-RNN) to address these challenges. First, we establish a parameter initialization strategy based on frequency information to construct the initial RNN. After obtaining a numerical solution from this initial network, we use the residual as an error indicator. Based on the error indicator, we introduce growth strategies that expand the neural network, making it wider and deeper to improve the accuracy of the numerical solution. A key feature of AG-RNN is its adaptive strategy for determining the weights and biases of newly added neurons, enabling the network to expand in both width and depth without requiring additional training. Instead, all weights and biases are generated constructively, significantly enhancing the network's approximation capabilities compared to conventional randomized neural network methods. In addition, a domain splitting strategy is introduced to handle the case of discontinuous solutions. Extensive numerical experiments are conducted to demonstrate the efficiency and accuracy of this innovative approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17225v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoning Dang, Fei Wang, Song Jiang</dc:creator>
    </item>
    <item>
      <title>Multilevel Bayesian Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2203.12961</link>
      <description>arXiv:2203.12961v4 Announce Type: replace-cross 
Abstract: In this article we consider Bayesian inference associated to deep neural networks (DNNs) and in particular, trace-class neural network (TNN) priors which can be preferable to traditional DNNs as (a) they are identifiable and (b) they possess desirable convergence properties. TNN priors are defined on functions with infinitely many hidden units, and have strongly convergent Karhunen-Loeve-type approximations with finitely many hidden units. A practical hurdle is that the Bayesian solution is computationally demanding, requiring simulation methods, so approaches to drive down the complexity are needed. In this paper, we leverage the strong convergence of TNN in order to apply Multilevel Monte Carlo (MLMC) to these models. In particular, an MLMC method that was introduced is used to approximate posterior expectations of Bayesian TNN models with optimal computational complexity, and this is mathematically proved. The results are verified with several numerical experiments on model problems arising in machine learning, including regression, classification, and reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.12961v4</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil K. Chada, Ajay Jasra, Kody J. H. Law, Sumeetpal S. Singh</dc:creator>
    </item>
    <item>
      <title>Invariant subspaces and PCA in nearly matrix multiplication time</title>
      <link>https://arxiv.org/abs/2311.10459</link>
      <description>arXiv:2311.10459v4 Announce Type: replace-cross 
Abstract: Approximating invariant subspaces of generalized eigenvalue problems (GEPs) is a fundamental computational problem at the core of machine learning and scientific computing. It is, for example, the root of Principal Component Analysis (PCA) for dimensionality reduction, data visualization, and noise filtering, and of Density Functional Theory (DFT), arguably the most popular method to calculate the electronic structure of materials. Given Hermitian $H,S\in\mathbb{C}^{n\times n}$, where $S$ is positive-definite, let $\Pi_k$ be the true spectral projector on the invariant subspace that is associated with the $k$ smallest (or largest) eigenvalues of the GEP $HC=SC\Lambda$, for some $k\in[n]$. We show that we can compute a matrix $\widetilde\Pi_k$ such that $\lVert\Pi_k-\widetilde\Pi_k\rVert_2\leq \epsilon$, in $O\left( n^{\omega+\eta}\mathrm{polylog}(n,\epsilon^{-1},\kappa(S),\mathrm{gap}_k^{-1}) \right)$ bit operations in the floating point model, for some $\epsilon\in(0,1)$, with probability $1-1/n$. Here, $\eta&gt;0$ is arbitrarily small, $\omega\lesssim 2.372$ is the matrix multiplication exponent, $\kappa(S)=\lVert S\rVert_2\lVert S^{-1}\rVert_2$, and $\mathrm{gap}_k$ is the gap between eigenvalues $k$ and $k+1$. To achieve such provable "forward-error" guarantees, our methods rely on a new $O(n^{\omega+\eta})$ stability analysis for the Cholesky factorization, and a smoothed analysis for computing spectral gaps, which can be of independent interest. Ultimately, we obtain new matrix multiplication-type bit complexity upper bounds for PCA problems, including classical PCA and (randomized) low-rank approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10459v4</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aleksandros Sobczyk, Marko Mladenovi\'c, Mathieu Luisier</dc:creator>
    </item>
    <item>
      <title>Approximation and perturbations of stable solutions to a stationary mean field game system</title>
      <link>https://arxiv.org/abs/2402.16377</link>
      <description>arXiv:2402.16377v4 Announce Type: replace-cross 
Abstract: This work introduces a new general approach for the numerical analysis of stable equilibria to second order  mean field games systems in cases where the uniqueness of solutions may fail. For the sake of simplicity, we focus on a simple stationary case. We propose an abstract framework to study these solutions by reformulating the mean field game system as an abstract equation in a Banach space. In this context, stable equilibria turn out to be regular solutions to this equation, meaning that the linearized system is well-posed. We provide three applications of this property: we study the sensitivity analysis of stable solutions, establish error estimates for their finite element approximations, and prove the local converge of Newton's method in infinite dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16377v4</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jules Berry (IRMAR, INSA Rennes, UR), Olivier Ley (IRMAR), Francisco J Silva (XLIM)</dc:creator>
    </item>
    <item>
      <title>The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models</title>
      <link>https://arxiv.org/abs/2405.17068</link>
      <description>arXiv:2405.17068v2 Announce Type: replace-cross 
Abstract: Langevin Dynamics is a Stochastic Differential Equation (SDE) central to sampling and generative modeling and is implemented via time discretization. Langevin Monte Carlo (LMC), based on the Euler-Maruyama discretization, is the simplest and most studied algorithm. LMC can suffer from slow convergence - requiring a large number of steps of small step-size to obtain good quality samples. This becomes stark in the case of diffusion models where a large number of steps gives the best samples, but the quality degrades rapidly with smaller number of steps. Randomized Midpoint Method has been recently proposed as a better discretization of Langevin dynamics for sampling from strongly log-concave distributions. However, important applications such as diffusion models involve non-log concave densities and contain time varying drift. We propose its variant, the Poisson Midpoint Method, which approximates a small step-size LMC with large step-sizes. We prove that this can obtain a quadratic speed up of LMC under very weak assumptions. We apply our method to diffusion models for image generation and show that it maintains the quality of DDPM with 1000 neural network calls with just 50-80 neural network calls and outperforms ODE based methods with similar compute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17068v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saravanan Kandasamy, Dheeraj Nagaraj</dc:creator>
    </item>
    <item>
      <title>Latent Neural Operator for Solving Forward and Inverse PDE Problems</title>
      <link>https://arxiv.org/abs/2406.03923</link>
      <description>arXiv:2406.03923v3 Announce Type: replace-cross 
Abstract: Neural operators effectively solve PDE problems from data without knowing the explicit equations, which learn the map from the input sequences of observed samples to the predicted values. Most existing works build the model in the original geometric space, leading to high computational costs when the number of sample points is large. We present the Latent Neural Operator (LNO) solving PDEs in the latent space. In particular, we first propose Physics-Cross-Attention (PhCA) transforming representation from the geometric space to the latent space, then learn the operator in the latent space, and finally recover the real-world geometric space via the inverse PhCA map. Our model retains flexibility that can decode values in any position not limited to locations defined in the training set, and therefore can naturally perform interpolation and extrapolation tasks particularly useful for inverse problems. Moreover, the proposed LNO improves both prediction accuracy and computational efficiency. Experiments show that LNO reduces the GPU memory by 50%, speeds up training 1.8 times, and reaches state-of-the-art accuracy on four out of six benchmarks for forward problems and a benchmark for inverse problem. Code is available at https://github.com/L-I-M-I-T/LatentNeuralOperator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03923v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tian Wang, Chuang Wang</dc:creator>
    </item>
    <item>
      <title>Modelling advection on distance-weighted directed networks</title>
      <link>https://arxiv.org/abs/2410.11352</link>
      <description>arXiv:2410.11352v2 Announce Type: replace-cross 
Abstract: In this paper we propose a model for describing advection dynamics on distance-weighted directed graphs. To this end we establish a set of key properties, or axioms, that a discrete advection operator should satisfy, and prove that there exists an essentially unique operator satisfying all such properties. Both infinite and finite networks are considered, as well as possible variants and extensions. We illustrate the proposed model through examples, both analytical and numerical, and we describe an application to the simulation of a traffic network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11352v2</guid>
      <category>cs.SI</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Benzi, Fabio Durastante, Francesco Zigliotto</dc:creator>
    </item>
  </channel>
</rss>
