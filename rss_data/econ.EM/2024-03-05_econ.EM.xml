<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Mar 2024 05:03:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Set-Valued Control Functions</title>
      <link>https://arxiv.org/abs/2403.00347</link>
      <description>arXiv:2403.00347v1 Announce Type: new 
Abstract: The control function approach allows the researcher to identify various causal effects of interest. While powerful, it requires a strong invertibility assumption, which limits its applicability. This paper expands the scope of the nonparametric control function approach by allowing the control function to be set-valued and derive sharp bounds on structural parameters. The proposed generalization accommodates a wide range of selection processes involving discrete endogenous variables, random coefficients, treatment selections with interference, and dynamic treatment selections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00347v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sukjin Han, Hiroaki Kaido</dc:creator>
    </item>
    <item>
      <title>Inference for Interval-Identified Parameters Selected from an Estimated Set</title>
      <link>https://arxiv.org/abs/2403.00422</link>
      <description>arXiv:2403.00422v1 Announce Type: new 
Abstract: Interval identification of parameters such as average treatment effects, average partial effects and welfare is particularly common when using observational data and experimental data with imperfect compliance due to the endogeneity of individuals' treatment uptake. In this setting, a treatment or policy will typically become an object of interest to the researcher when it is either selected from the estimated set of best-performers or arises from a data-dependent selection rule. In this paper, we develop new inference tools for interval-identified parameters chosen via these forms of selection. We develop three types of confidence intervals for data-dependent and interval-identified parameters, discuss how they apply to several examples of interest and prove their uniform asymptotic validity under weak assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00422v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sukjin Han, Adam McCloskey</dc:creator>
    </item>
    <item>
      <title>Prices and preferences in the electric vehicle market</title>
      <link>https://arxiv.org/abs/2403.00458</link>
      <description>arXiv:2403.00458v1 Announce Type: new 
Abstract: Although electric vehicles are less polluting than gasoline powered vehicles, adoption is challenged by higher procurement prices. Existing discourse emphasizes EV battery costs as being principally responsible for this price differential and widespread adoption is routinely conditioned upon battery costs declining. We scrutinize such reasoning by sourcing data on EV attributes and market conditions between 2011 and 2023. Our findings are fourfold. First, EV prices are influenced principally by the number of amenities, additional features, and dealer-installed accessories sold as standard on an EV, and to a lesser extent, by EV horsepower. Second, EV range is negatively correlated with EV price implying that range anxiety concerns may be less consequential than existing discourse suggests. Third, battery capacity is positively correlated with EV price, due to more capacity being synonymous with the delivery of more horsepower. Collectively, this suggests that higher procurement prices for EVs reflects consumer preference for vehicles that are feature dense and more powerful. Fourth and finally, accommodating these preferences have produced vehicles with lower fuel economy, a shift that reduces envisioned lifecycle emissions benefits by at least 3.26 percent, subject to the battery pack chemistry leveraged and the carbon intensity of the electrical grid. These findings warrant attention as decarbonization efforts increasingly emphasize electrification as a pathway for complying with domestic and international climate agreements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00458v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chung Yi See, Vasco Rato Santos, Lucas Woodley, Megan Yeo, Daniel Palmer, Shuheng Zhang, and Ashley Nunes</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Monte Carlo for Regression with High-Dimensional Categorical Data</title>
      <link>https://arxiv.org/abs/2107.08112</link>
      <description>arXiv:2107.08112v2 Announce Type: replace 
Abstract: Latent variable models are increasingly used in economics for high-dimensional categorical data like text and surveys. We demonstrate the effectiveness of Hamiltonian Monte Carlo (HMC) with parallelized automatic differentiation for analyzing such data in a computationally efficient and methodologically sound manner. Our new model, Supervised Topic Model with Covariates, shows that carefully modeling this type of data can have significant implications on conclusions compared to a simpler, frequently used, yet methodologically problematic, two-step approach. A simulation study and revisiting Bandiera et al. (2020)'s study of executive time use demonstrate these results. The approach accommodates thousands of parameters and doesn't require custom algorithms specific to each model, making it accessible for applied researchers</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.08112v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Szymon Sacher, Laura Battaglia, Stephen Hansen</dc:creator>
    </item>
    <item>
      <title>On Recoding Ordered Treatments as Binary Indicators</title>
      <link>https://arxiv.org/abs/2111.12258</link>
      <description>arXiv:2111.12258v4 Announce Type: replace 
Abstract: Researchers using instrumental variables to investigate ordered treatments often recode treatment into an indicator for any exposure. We investigate this estimand under the assumption that the instruments shift compliers from no treatment to some but not from some treatment to more. We show that when there are extensive margin compliers only (EMCO) this estimand captures a weighted average of treatment effects that can be partially unbundled into each complier group's potential outcome means. We also establish an equivalence between EMCO and a two-factor selection model and apply our results to study treatment heterogeneity in the Oregon Health Insurance Experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.12258v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan K. Rose, Yotam Shem-Tov</dc:creator>
    </item>
    <item>
      <title>Inference in IV models with clustered dependence, many instruments and weak identification</title>
      <link>https://arxiv.org/abs/2306.08559</link>
      <description>arXiv:2306.08559v2 Announce Type: replace 
Abstract: Data clustering reduces the effective sample size from the number of observations towards the number of clusters. For instrumental variable models I show that this reduced effective sample size makes the instruments more likely to be weak, in the sense that they contain little information about the endogenous regressor, and many, in the sense that their number is large compared to the sample size. Clustered data therefore increases the need for many and weak instrument robust tests. However, none of the previously developed many and weak instrument robust tests can be applied to this type of data as they all require independent observations. I therefore adapt two types of such tests to clustered data. First, I derive cluster jackknife Anderson-Rubin and score tests by removing clusters rather than individual observations from the statistics. Second, I propose a cluster many instrument Anderson-Rubin test which improves on the first type of tests by using a more optimal, but more complex, weighting matrix. I show that if the clusters satisfy an invariance assumption the higher complexity poses no problems. By revisiting a study on the effect of queenly reign on war I show the empirical relevance of the new tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08559v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes W. Ligtenberg</dc:creator>
    </item>
    <item>
      <title>Structural Estimation of Markov Decision Processes in High-Dimensional State Space with Finite-Time Guarantees</title>
      <link>https://arxiv.org/abs/2210.01282</link>
      <description>arXiv:2210.01282v3 Announce Type: replace-cross 
Abstract: We consider the task of estimating a structural model of dynamic decisions by a human agent based upon the observable history of implemented actions and visited states. This problem has an inherent nested structure: in the inner problem, an optimal policy for a given reward function is identified while in the outer problem, a measure of fit is maximized. Several approaches have been proposed to alleviate the computational burden of this nested-loop structure, but these methods still suffer from high complexity when the state space is either discrete with large cardinality or continuous in high dimensions. Other approaches in the inverse reinforcement learning (IRL) literature emphasize policy estimation at the expense of reduced reward estimation accuracy. In this paper we propose a single-loop estimation algorithm with finite time guarantees that is equipped to deal with high-dimensional state spaces without compromising reward estimation accuracy. In the proposed algorithm, each policy improvement step is followed by a stochastic gradient step for likelihood maximization. We show that the proposed algorithm converges to a stationary solution with a finite-time guarantee. Further, if the reward is parameterized linearly, we show that the algorithm approximates the maximum likelihood estimator sublinearly. Finally, by using robotics control problems in MuJoCo and their transfer settings, we show that the proposed algorithm achieves superior performance compared with other IRL and imitation learning benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.01282v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siliang Zeng, Mingyi Hong, Alfredo Garcia</dc:creator>
    </item>
  </channel>
</rss>
