<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Sep 2025 01:43:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Off-Policy Inference for M-Estimators Under Model Misspecification</title>
      <link>https://arxiv.org/abs/2509.14218</link>
      <description>arXiv:2509.14218v1 Announce Type: cross 
Abstract: When data are collected adaptively, such as in bandit algorithms, classical statistical approaches such as ordinary least squares and $M$-estimation will often fail to achieve asymptotic normality. Although recent lines of work have modified the classical approaches to ensure valid inference on adaptively collected data, most of these works assume that the model is correctly specified. We propose a method that provides valid inference for M-estimators that use adaptively collected bandit data with a (possibly) misspecified working model. A key ingredient in our approach is the use of flexible machine learning approaches to stabilize the variance induced by adaptive data collection. A major novelty is that our procedure enables the construction of valid confidence sets even in settings where treatment policies are unstable and non-converging, such as when there is no unique optimal arm and standard bandit algorithms are used. Empirical results on semi-synthetic datasets constructed from the Osteoarthritis Initiative demonstrate that the method maintains type I error control, while existing methods for inference in adaptive settings do not cover in the misspecified case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14218v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Leiner, Robin Dunn, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications</title>
      <link>https://arxiv.org/abs/2001.10488</link>
      <description>arXiv:2001.10488v4 Announce Type: replace 
Abstract: (The third edition corrects minor typos and adds 3 chapters synthesized from published papers plus an appendix on maximum entropy distributions.) The monograph investigates the misapplication of conventional statistical techniques to fat tailed distributions and looks for remedies, when possible.
  Switching from thin tailed to fat tailed distributions requires more than "changing the color of the dress". Traditional asymptotics deal mainly with either n=1 or $n=\infty$, and the real world is in between, under of the "laws of the medium numbers" --which vary widely across specific distributions. Both the law of large numbers and the generalized central limit mechanisms operate in highly idiosyncratic ways outside the standard Gaussian or Levy-Stable basins of convergence.
  A few examples:
  + The sample mean is rarely in line with the population mean, with effect on "naive empiricism", but can be sometimes be estimated via parametric methods.
  + The "empirical distribution" is rarely empirical.
  + Parameter uncertainty has compounding effects on statistical metrics.
  + Dimension reduction (principal components) fails.
  + Inequality estimators (GINI or quantile contributions) are not additive and produce wrong results.
  + Many "biases" found in psychology become entirely rational under more sophisticated probability distributions
  + Most of the failures of financial economics, econometrics, and behavioral economics can be attributed to using the wrong distributions.
  This book, the first volume of the Technical Incerto, weaves a narrative around published journal articles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.10488v4</guid>
      <category>stat.OT</category>
      <category>q-fin.RM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nassim Nicholas Taleb</dc:creator>
    </item>
  </channel>
</rss>
