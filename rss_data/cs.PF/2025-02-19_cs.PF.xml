<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 05:00:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Hybrid Amplitude-Phase Quantization for Multi-Antenna Relay System</title>
      <link>https://arxiv.org/abs/2502.12592</link>
      <description>arXiv:2502.12592v1 Announce Type: new 
Abstract: This letter explores relay quantization in multi-antenna quantize-forward (QF) relay systems. Existing methods, such as uniform phase quantization (U-PQ) and uniform amplitude-phase quantization (U-APQ), suffer from performance saturation and high memory demands. To overcome these limitations, we propose hybrid amplitude-phase quantization (H-APQ), which adaptively quantizes received signal amplitudes based on their relative magnitudes while applying uniform quantization to individual phases. H-APQ significantly reduces memory consumption at the relay while maintaining strong overall performance, offering an efficient solution for multiple-input multiple-output (MIMO) QF relay systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12592v1</guid>
      <category>cs.PF</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changdae Kim, Xianglan Jin</dc:creator>
    </item>
    <item>
      <title>Scalable Binary CUR Low-Rank Approximation Algorithm</title>
      <link>https://arxiv.org/abs/2502.11017</link>
      <description>arXiv:2502.11017v1 Announce Type: cross 
Abstract: This paper proposes a scalable binary CUR low-rank approximation algorithm that leverages parallel selection of representative rows and columns within a deterministic framework. By employing a blockwise adaptive cross approximation strategy, the algorithm efficiently identifies dominant components in large-scale matrices, thereby reducing computational costs. Numerical experiments on $16,384 \times 16,384$ matrices demonstrate remarkable scalability, with execution time decreasing from $12.37$ seconds using $2$ processes to $1.02$ seconds using $64$ processes. The tests on Hilbert matrices and synthetic low-rank matrices across various sizes demonstrate a near-optimal reconstruction accuracy. These results suggest a potential for practical application in large-scale matrix low-rank approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11017v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bowen Su</dc:creator>
    </item>
    <item>
      <title>Gem5-AcceSys: Enabling System-Level Exploration of Standard Interconnects for Novel Accelerators</title>
      <link>https://arxiv.org/abs/2502.12273</link>
      <description>arXiv:2502.12273v1 Announce Type: cross 
Abstract: The growing demand for efficient, high-performance processing in machine learning (ML) and image processing has made hardware accelerators, such as GPUs and Data Streaming Accelerators (DSAs), increasingly essential. These accelerators enhance ML and image processing tasks by offloading computation from the CPU to dedicated hardware. These accelerators rely on interconnects for efficient data transfer, making interconnect design crucial for system-level performance. This paper introduces Gem5-AcceSys, an innovative framework for system-level exploration of standard interconnects and configurable memory hierarchies. Using a matrix multiplication accelerator tailored for transformer workloads as a case study, we evaluate PCIe performance across diverse memory types (DDR4, DDR5, GDDR6, HBM2) and configurations, including host-side and device-side memory. Our findings demonstrate that optimized interconnects can achieve up to 80% of device-side memory performance and, in some scenarios, even surpass it. These results offer actionable insights for system architects, enabling a balanced approach to performance and cost in next-generation accelerator design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12273v1</guid>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qunyou Liu, Marina Zapater, David Atienza</dc:creator>
    </item>
    <item>
      <title>SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered CPUs</title>
      <link>https://arxiv.org/abs/2502.12444</link>
      <description>arXiv:2502.12444v1 Announce Type: cross 
Abstract: Large language models have high compute, latency, and memory requirements. While specialized accelerators such as GPUs and TPUs typically run these workloads, CPUs are more widely available and consume less energy. Accelerating LLMs with CPUs enables broader AI access at a lower cost and power consumption. This acceleration potential for CPUs is especially relevant during the memory-bound decoding stage of LLM inference, which processes one token at a time and is becoming increasingly utilized with reasoning models. We utilize Advanced Matrix Extensions (AMX) support on the latest Intel CPUs together with unstructured sparsity to achieve a $1.42 \times$ reduction in end-to-end latency compared to the current PyTorch implementation by applying our technique in linear layers. We provide a set of open-source customized sparse kernels that can speed up any PyTorch model by automatically replacing all linear layers with our custom sparse implementation. Furthermore, we demonstrate for the first time the use of unstructured sparsity in the attention computation achieving a $1.14 \times$ speedup over the current systems without compromising accuracy. Code: https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning/tree/main/SparAMX</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12444v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed F. AbouElhamayed, Jordan Dotzel, Yash Akhauri, Chi-Chih Chang, Sameh Gobriel, J. Pablo Mu\~noz, Vui Seng Chua, Nilesh Jain, Mohamed S. Abdelfattah</dc:creator>
    </item>
    <item>
      <title>Surrogate Modeling for Scalable Evaluation of Distributed Computing Systems for HEP Applications</title>
      <link>https://arxiv.org/abs/2502.12741</link>
      <description>arXiv:2502.12741v1 Announce Type: cross 
Abstract: The Worldwide LHC Computing Grid (WLCG) provides the robust computing infrastructure essential for the LHC experiments by integrating global computing resources into a cohesive entity. Simulations of different compute models present a feasible approach for evaluating future adaptations that are able to cope with future increased demands. However, running these simulations incurs a trade-off between accuracy and scalability. For example, while the simulator DCSim can provide accurate results, it falls short on scaling with the size of the simulated platform. Using Generative Machine Learning as a surrogate presents a candidate for overcoming this challenge.
  In this work, we evaluate the usage of three different Machine Learning models for the simulation of distributed computing systems and assess their ability to generalize to unseen situations. We show that those models can predict central observables derived from execution traces of compute jobs with approximate accuracy but with orders of magnitude faster execution times. Furthermore, we identify potentials for improving the predictions towards better accuracy and generalizability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12741v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>hep-ex</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Larissa Schmid, Maximilian Horzela, Valerii Zhyla, Manuel Giffels, G\"unter Quast, Anne Koziolek</dc:creator>
    </item>
    <item>
      <title>GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS</title>
      <link>https://arxiv.org/abs/2408.01584</link>
      <description>arXiv:2408.01584v3 Announce Type: replace-cross 
Abstract: Multi-agent learning algorithms have been successful at generating superhuman planning in various games but have had limited impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at scale, we present GPUDrive. GPUDrive is a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine capable of generating over a million simulation steps per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. Despite these low-level optimizations, GPUDrive is fully accessible through Python, offering a seamless and efficient workflow for multi-agent, closed-loop simulation. Using GPUDrive, we train reinforcement learning agents on the Waymo Open Motion Dataset, achieving efficient goal-reaching in minutes and scaling to thousands of scenarios in hours. We open-source the code and pre-trained agents at https://github.com/Emerge-Lab/gpudrive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01584v3</guid>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.GR</category>
      <category>cs.PF</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICLR 2025</arxiv:journal_reference>
      <dc:creator>Saman Kazemkhani, Aarav Pandya, Daphne Cornelisse, Brennan Shacklett, Eugene Vinitsky</dc:creator>
    </item>
    <item>
      <title>Cheesemap: A High-Performance Point-Indexing Data Structure for Neighbor Search in LiDAR Data</title>
      <link>https://arxiv.org/abs/2502.11602</link>
      <description>arXiv:2502.11602v2 Announce Type: replace-cross 
Abstract: Point cloud data, as the representation of three-dimensional spatial information, is a fundamental piece of information in various domains where indexing and querying these point clouds efficiently is crucial for tasks such as object recognition, autonomous navigation, and environmental modeling. In this paper, we present a comprehensive comparative analysis of various data structures combined with neighboring search methods across different types of point clouds. Additionally, we introduce a novel data structure, cheesemap, to handle 3D LiDAR point clouds. Exploring the sparsity and irregularity in the distribution of points, there are three flavors of the cheesemap: dense, sparse, and mixed. Results show that the cheesemap can outperform state-of-the-art data structures in terms of execution time per query, particularly for ALS (Aerial Laser Scanning) point clouds. Memory consumption is also minimal, especially in the sparse and mixed representations, making the cheesemap a suitable choice for applications involving three-dimensional point clouds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11602v2</guid>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruben Laso, Miguel Yermo</dc:creator>
    </item>
  </channel>
</rss>
