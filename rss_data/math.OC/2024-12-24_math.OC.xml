<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 02:30:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Corrigendum to "Balance of Communication and Convergence: Predefined-time Distributed Optimization Based on Zero-Gradient-Sum"</title>
      <link>https://arxiv.org/abs/2412.16163</link>
      <description>arXiv:2412.16163v1 Announce Type: new 
Abstract: This paper proposes a distributed optimization algorithm with a convergence time that can be assigned in advance according to task requirements. To this end, a sliding manifold is introduced to achieve the sum of local gradients approaching zero, based on which a distributed protocol is derived to reach a consensus minimizing the global cost. A novel approach for convergence analysis is derived in a unified settling time framework, resulting in an algorithm that can precisely converge to the optimal solution at the prescribed time. The method is interesting as it simply requires the primal states to be shared over the network, which implies less communication requirements. The result is extended to scenarios with time-varying objective function, by introducing local gradients prediction and non-smooth consensus terms. Numerical simulations are provided to corroborate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16163v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCYB.2024.3498323</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Cybernetics (2024) 1-11</arxiv:journal_reference>
      <dc:creator>Renyongkang Zhang, Ge Guo, Zeng-di Zhou</dc:creator>
    </item>
    <item>
      <title>Unified algebraic deviation of distribution factors in linear power flow</title>
      <link>https://arxiv.org/abs/2412.16164</link>
      <description>arXiv:2412.16164v1 Announce Type: new 
Abstract: Distribution factors are indispensable tools in the design and analysis of power transmission grids. Recently, they received a renewed interest in the field of topology optimization, leading to the definition of bus merge and bus split distribution factors. In this article, we introduce a unified derivation of the most relevant distribution factors based on matrix algebraic manipulations. This approach facilitates the generalization to more complex grid modification, in particular simultaneous switching events or bus splits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16164v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joost van Dijk, Nico Westerbeck, Lars Schewe, Andrea Benigni, Dirk Witthaut</dc:creator>
    </item>
    <item>
      <title>Estimating Varying Parameters in Dynamical Systems: A Modular Framework Using Switch Detection, Optimization, and Sparse Regression</title>
      <link>https://arxiv.org/abs/2412.16198</link>
      <description>arXiv:2412.16198v1 Announce Type: new 
Abstract: The estimation of static parameters in dynamical systems and control theory has been extensively studied, with significant progress made in estimating varying parameters in specific system types. Suppose, in the general case, we have data from a system with parameters that depend on an independent variable such as time or space. Further, suppose the system's model structure is known, but our aim is to identify functions describing parameter-varying elements as they change with respect to time or another variable. Focusing initially on the subclass of problems where parameters are discretely switching piecewise constant functions, we develop an algorithmic framework for detecting discrete parameter switches and fitting a piecewise constant model to data using optimization-based parameter estimation. Our modular framework allows for customization of switch detection, numerical integration, and optimization sub-steps to suit user requirements. Binary segmentation is used for switch detection, with Nelder-Mead and Powell methods employed for optimization. To address broader problems, we extend our framework using dictionary-based sparse regression with trigonometric and polynomial functions to obtain continuously varying parameter functions. Finally, we assess the framework's robustness to measurement noise. We demonstrate its capabilities across several examples, including time-varying promoter-gene expression, a genetic toggle switch, a parameter-switching manifold, the heat equation with a time-varying diffusion coefficient, and the advection-diffusion equation with a continuously varying parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16198v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jamiree Harrison, Enoch Yeung</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Stackelberg Mean Field Games and Teams with Arbitrary Population Sizes</title>
      <link>https://arxiv.org/abs/2412.16203</link>
      <description>arXiv:2412.16203v1 Announce Type: new 
Abstract: This paper addresses a linear-quadratic Stackelberg mean field (MF) games and teams problem with arbitrary population sizes, where the game among the followers is further categorized into two types: non-cooperative and cooperative, and the number of followers can be finite or infinite. The leader commences by providing its strategy, and subsequently, each follower optimizes its individual cost or social cost. A new de-aggregation method is applied to solve the problem, which is instrumental in determining the optimal strategy of followers to the leader's strategy. Unlike previous studies that focus on MF games and social optima, and yield decentralized asymptotically optimal strategies relative to the centralized strategy set, the strategies presented here are exact decentralized optimal strategies relative to the decentralized strategy set. This distinction is crucial as it highlights a shift in the approach to MF systems, emphasizing the precision and direct applicability of the strategies to the decentralized context. In the wake of the implementation of followers' strategies, the leader is confronted with an optimal control problem driven by high-dimensional forward-backward stochastic differential equations (FBSDEs). By variational analysis, we obtain the decentralized strategy for the leader. By applying the de-aggregation method and employing dimension expansion to decouple the high-dimensional FBSDEs, we are able to derive a set of decentralized Stackelberg-Nash or Stackelberg-team equilibrium solution for all players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16203v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wenyu Cong, Jingtao Shi, Bingchang Wang</dc:creator>
    </item>
    <item>
      <title>A matheuristic approach for an integrated lot-sizing and scheduling problem with a period-based learning effect</title>
      <link>https://arxiv.org/abs/2412.16222</link>
      <description>arXiv:2412.16222v1 Announce Type: new 
Abstract: This research investigates a multi-product capacitated lot-sizing and scheduling problem incorporating a novel type of learning effect, namely the period-based learning effect. This is inspired by a real case in a core analysis laboratory under a job shop setting. Accordingly, a Mixed-Integer Linear Programming (MILP) model is extended based on the big-bucket formulation, optimizing the total tardiness and overtime costs. Given the complexity of the problem, a cutting plane method is employed to simplify the model. Afterward, three matheuristic methods based on the rolling horizon approach are devised, incorporating two lower bounds and a local search heuristic. Lastly, to assess the effectiveness of the proposed solution approaches, computational experiments are conducted. The results demonstrate: 1) the simplified model performs effectively in terms of both solution quality and CPU time; and 2) while the model encounters challenges with large-scale instances, the proposed matheuristic methods achieve satisfactory outcomes; and 3) it can be inferred that the complexity of the models and solution methods are independent of the learning effect; however, the value of learning effect may impact the performance of the lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16222v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Rohaninejad, Behdin Vahedi-Nouri, Reza Tavakkoli-Moghaddam, Zden\v{e}k Hanz\'alek</dc:creator>
    </item>
    <item>
      <title>Low-rank matrix recovery via nonconvex optimization methods with application to errors-in-variables matrix regression</title>
      <link>https://arxiv.org/abs/2412.16263</link>
      <description>arXiv:2412.16263v1 Announce Type: new 
Abstract: We consider the nonconvex regularized method for low-rank matrix recovery. Under the assumption on the singular values of the parameter matrix, we provide the recovery bound for any stationary point of the nonconvex method by virtue of regularity conditions on the nonconvex loss function and the regularizer. This recovery bound can be much tighter than that of the convex nuclear norm regularized method when some of the singular values are larger than a threshold defined by the nonconvex regularizer. In addition, we consider the errors-in-variables matrix regression as an application of the nonconvex optimization method. Probabilistic consequences and the advantage of the nonoconvex method are demonstrated through verifying the regularity conditions for specific models with additive noise and missing data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16263v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Dongya Wu</dc:creator>
    </item>
    <item>
      <title>Efficient points in a sum of sets of alternatives</title>
      <link>https://arxiv.org/abs/2412.16331</link>
      <description>arXiv:2412.16331v1 Announce Type: new 
Abstract: The concept of efficiency plays a prominent role in the formal solution of decision problems that involve incomparable alternatives. This paper develops necessary and sufficient conditions for the efficient points in a sum of sets of alternatives to be identical to the efficient points in one of the summands. Some of the conditions cover both finite and infinite sets; others are shown to hold only for finite sets. A theorem with useful implications for multiple objective optimization is obtained as a corollary of our findings. Examples are provided that illustrate these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16331v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Mifrani</dc:creator>
    </item>
    <item>
      <title>Dissipative energy functionals of passive linear time-varying systems</title>
      <link>https://arxiv.org/abs/2412.16347</link>
      <description>arXiv:2412.16347v1 Announce Type: new 
Abstract: The concept of dissipativity plays a crucial role in the analysis of control systems. Dissipative energy functionals, also known as Hamiltonians, storage functions, or Lyapunov functions, depending on the setting, are extremely valuable to analyze and control the behavior of dynamical systems, but in general circumstances they are very difficult to compute, and not fully understood. In this paper we consider passive linear time-varying (LTV) systems, under very mild regularity assumptions, and their associated storage functions, as a necessary step to analyze general nonlinear systems. We demonstrate that every passive LTV system must have at least one time-varying positive semidefinite quadratic storage function, greatly reducing our search scope. Now focusing on quadratic storage functions, we analyze in detail their necessary regularity, which is lesser than continuous. Moreover, we prove that the rank of quadratic storage functions is nonincreasing in time, allowing us to introduce a novel null space decomposition, under much weaker assumptions than the one needed for general matrix functions. Additionally, we show a necessary kernel condition for the quadratic storage function, allowing us to reduce our search scope even further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16347v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Morandin, Dorothea Hinsen</dc:creator>
    </item>
    <item>
      <title>Relationship between dissipativity concepts for linear time-varying port-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2412.16396</link>
      <description>arXiv:2412.16396v1 Announce Type: new 
Abstract: The relationship between different dissipativity concepts for linear time-varying systems is studied, in particular between port-Hamiltonian systems, passive systems, and systems with nonnegative supply. It is shown that linear time-varying port-Hamiltonian systems are passive, have nonnegative supply rates, and solve (under different smoothness assumptions) Kalman-Yakubovich-Popov differential and integral inequalities. The converse relations are also studied in detail. In particular, sufficient conditions are presented to obtain a port-Hamiltonian representation starting from any of the other dissipativity concepts. Two applications are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16396v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karim Cherifi, Hannes Gernandt, Dorothea Hinsen, Volker Mehrmann, Riccardo Morandin</dc:creator>
    </item>
    <item>
      <title>Accelerated Methods with Compressed Communications for Distributed Optimization Problems under Data Similarity</title>
      <link>https://arxiv.org/abs/2412.16414</link>
      <description>arXiv:2412.16414v1 Announce Type: new 
Abstract: In recent years, as data and problem sizes have increased, distributed learning has become an essential tool for training high-performance models. However, the communication bottleneck, especially for high-dimensional data, is a challenge. Several techniques have been developed to overcome this problem. These include communication compression and implementation of local steps, which work particularly well when there is similarity of local data samples. In this paper, we study the synergy of these approaches for efficient distributed optimization. We propose the first theoretically grounded accelerated algorithms utilizing unbiased and biased compression under data similarity, leveraging variance reduction and error feedback frameworks. Our results are of record and confirmed by experiments on different average losses and datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16414v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Bylinkin, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>A Bayesian Composite Risk Approach for Stochastic Optimal Control and Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2412.16488</link>
      <description>arXiv:2412.16488v1 Announce Type: new 
Abstract: Inspired by \cite{shapiro2023episodic}, we consider a stochastic optimal control (SOC) and Markov decision process (MDP) where the risks arising from epistemic and aleatoric uncertainties are assessed using Bayesian composite risk (BCR) measures (\cite{qian2019composite}). The time dependence of the risk measures allows us to capture the decision maker's (DM) dynamic risk preferences opportunely as increasing information about both uncertainties is obtained. This makes the new BCR-SOC/MDP model more flexible than conventional risk-averse SOC/MDP models. Unlike \cite{shapiro2023episodic} where the control/action at each episode is based on the current state alone, the new model allows the control to depend on the probability distribution of the epistemic uncertainty, which reflects the fact that in many practical instances the cumulative information about epistemic uncertainty often affects the DM's belief about the future aleatoric uncertainty and hence the DM's action (\cite{strens2000bayesian}). The new modeling paradigm incorporates several existing SOC/MDP models including distributionally robust SOC/MDP models and Bayes-adaptive MDP models and generates so-called preference robust SOC/MDP models. Moreover, we derive conditions under which the BCR-SOC/MDP model is well-defined, demonstrate that BCR-SOC/MDP models can be solved using dynamic programming techniques. By using Bellman equations, we show that under some standard conditions, asymptotic convergence of the optimal values and optimal actions as the episode goes to infinity is achieved. Finally, we carry out numerical tests on a finite horizon spread betting problem and an inventory control problem to show the effectiveness of the proposed model and numerical schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16488v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Ma, Zhiping Chen, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>An Inexact Proximal Newton Method for Nonconvex Composite Minimization</title>
      <link>https://arxiv.org/abs/2412.16535</link>
      <description>arXiv:2412.16535v1 Announce Type: new 
Abstract: In this paper, we propose an inexact proximal Newton-type method for nonconvex composite problems. We establish the global convergence rate of the order \(\mathcal{O}(k^{-1/2})\) in terms of the minimal norm of the KKT residual mapping and the local superlinear convergence rate in terms of the sequence generated by the proposed algorithm under the higher-order metric \(q\)-subregularity property. When the Lipschitz constant of the corresponding gradient is known, we show that the proposed algorithm is well-defined without line search. Extensive numerical experiments on {the \(\ell_1\)-regularized Student's \(t\)-regression and the group penalized Student's \(t\)-regression} show that the performance of the proposed method is comparable to the state-of-the-art proximal Newton-type methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16535v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Zhu</dc:creator>
    </item>
    <item>
      <title>Two-person zero-sum stochastic linear quadratic control problems with Markov chains and fractional Brownian motion in infinite horizon</title>
      <link>https://arxiv.org/abs/2412.16538</link>
      <description>arXiv:2412.16538v1 Announce Type: new 
Abstract: This paper addresses a class of two-person zero-sum stochastic differential equations, which encompass Markov chains and fractional Brownian motion, and satisfy some monotonicity conditions over an infinite time horizon. Within the framework of forward-backward stochastic differential equations (FBSDEs) that describe system evolution, we extend the classical It$\rm\hat{o}$'s formula to accommodate complex scenarios involving Brownian motion, fractional Brownian motion, and Markov chains simultaneously. By applying the Banach fixed-point theorem and approximation methods respectively, we theoretically guarantee the existence and uniqueness of solutions for FBSDEs in infinite horizon. Furthermore, we apply the method for the first time to the optimal control problem in a two-player zero-sum game, deriving the optimal control strategies for both players by solving the FBSDEs system. Finally, we conduct an analysis of the impact of the cross-term
  $S(\cdot)$ in the cost function on the solution, revealing its crucial role in the optimization process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16538v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chang Liu, Hongtao Fan, Yajing Li</dc:creator>
    </item>
    <item>
      <title>A learning-based approach to stochastic optimal control under reach-avoid constraint</title>
      <link>https://arxiv.org/abs/2412.16561</link>
      <description>arXiv:2412.16561v1 Announce Type: new 
Abstract: We develop a model-free approach to optimally control stochastic, Markovian systems subject to a reach-avoid constraint. Specifically, the state trajectory must remain within a safe set while reaching a target set within a finite time horizon. Due to the time-dependent nature of these constraints, we show that, in general, the optimal policy for this constrained stochastic control problem is non-Markovian, which increases the computational complexity. To address this challenge, we apply the state-augmentation technique from arXiv:2402.19360, reformulating the problem as a constrained Markov decision process (CMDP) on an extended state space. This transformation allows us to search for a Markovian policy, avoiding the complexity of non-Markovian policies. To learn the optimal policy without a system model, and using only trajectory data, we develop a log-barrier policy gradient approach. We prove that under suitable assumptions, the policy parameters converge to the optimal parameters, while ensuring that the system trajectories satisfy the stochastic reach-avoid constraint with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16561v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tingting Ni, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>On uniform null controllability of transport-diffusion equations with vanishing viscosity limit</title>
      <link>https://arxiv.org/abs/2412.16660</link>
      <description>arXiv:2412.16660v1 Announce Type: new 
Abstract: This paper aims to address an interesting open problem, posed in the paper "Singular Optimal Control for a Transport-Diffusion Equation" of Sergio Guerrero and Gilles Lebeau in 2007. The problem involves studying the null controllability cost of a transport-diffusion equation with Neumann conditions, where the diffusivity coefficient is denoted by $\varepsilon&gt;0$ and the velocity by $\mathfrak{B}(x,t)$. Our objective is twofold. First, we investigate the scenario where each velocity trajectory $\mathfrak{B}$ originating from $\overline{\Omega}$ enters the control region in a shorter time at a fixed entry time. By employing Agmon and dissipation inequalities, and Carleman estimate in the case $\mathfrak{B}(x,t)$ is the gradient of a time-dependent scalar field, we establish that the control cost remains bounded for sufficiently small $\varepsilon$ and large control time. Secondly, we explore the case where at least one trajectory fails to enter the control region and remains in $\Omega$. In this scenario, we prove that the control cost explodes exponentially when the diffusivity approaches zero and the control time is sufficiently small for general velocity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16660v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fouad Et-Tahri, Jon Asier B\'arcena-Petisco, Idriss Boutaayamou, Lahcen Maniar</dc:creator>
    </item>
    <item>
      <title>Bi-Sparse Unsupervised Feature Selection</title>
      <link>https://arxiv.org/abs/2412.16819</link>
      <description>arXiv:2412.16819v1 Announce Type: new 
Abstract: To efficiently deal with high-dimensional datasets in many areas, unsupervised feature selection (UFS) has become a rising technique for dimension reduction. Even though there are many UFS methods, most of them only consider the global structure of datasets by embedding a single sparse regularization or constraint. In this paper, we introduce a novel bi-sparse UFS method, called BSUFS, to simultaneously characterize both global and local structures. The core idea of BSUFS is to incorporate $\ell_{2,p}$-norm and $\ell_q$-norm into the classical principal component analysis (PCA), which enables our proposed method to select relevant features and filter out irrelevant noise accurately. Here, the parameters $p$ and $q$ are within the range of [0,1). Therefore, BSUFS not only constructs a unified framework for bi-sparse optimization, but also includes some existing works as special cases. To solve the resulting non-convex model, we propose an efficient proximal alternating minimization (PAM) algorithm using Riemannian manifold optimization and sparse optimization techniques. Theoretically, PAM is proven to have global convergence, i.e., for any random initial point, the generated sequence converges to a critical point that satisfies the first-order optimality condition. Extensive numerical experiments on synthetic and real-world datasets demonstrate the effectiveness of our proposed BSUFS. Specifically, the average accuracy (ACC) is improved by at least 4.71% and the normalized mutual information (NMI) is improved by at least 3.14% on average compared to the existing UFS competitors. The results validate the advantages of bi-sparse optimization in feature selection and show its potential for other fields in image processing. Our code will be available at https://github.com/xianchaoxiu.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16819v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianchao Xiu, Chenyi Huang, Pan Shang, Wanquan Liu</dc:creator>
    </item>
    <item>
      <title>Maximum principle for discrete-time control systems driven by fractional noises and related backward stochastic difference equations</title>
      <link>https://arxiv.org/abs/2412.16821</link>
      <description>arXiv:2412.16821v1 Announce Type: new 
Abstract: In this paper, the optimal control for discrete-time systems driven by fractional noises is studied. A stochastic maximum principle is obtained by introducing a backward stochastic difference equation contains both fractional noises and the constructed white noises. The solution of the backward stochastic difference equations is also investigated. As an application, the linear quadratic case is considered to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16821v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuecai Han, Yuhang Li</dc:creator>
    </item>
    <item>
      <title>Linear Filtering for Discrete Time Systems Driven by Fractional Noises</title>
      <link>https://arxiv.org/abs/2412.16826</link>
      <description>arXiv:2412.16826v1 Announce Type: new 
Abstract: In this paper, we study the discrete time filtering problems for linear systems driven by fractional noises. The main difficulty comes from the non-Markovian of the noises. We construct the difference equation of the covariance process through the properties of the noises and transform the filtering problem to an optimal control problem. We obtain the necessary condition that the coefficients of the optimal filter should satisfy and show there is no consistent optimal filter, which is a significant difference from the classical Kalman filter. Finally, a simple example is considered to illustrate the main results. Further more, our method could also deal with systems driven by any other colored noises, as long as the self-covariation function is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16826v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuecai Han, Yuhang Li</dc:creator>
    </item>
    <item>
      <title>Tilt stability of a class of nonlinear semidefinite programs</title>
      <link>https://arxiv.org/abs/2412.16913</link>
      <description>arXiv:2412.16913v1 Announce Type: new 
Abstract: This paper concerns the tilt stability of local optimal solutions to a class of nonlinear semidefinite programs, which involves a twice continuously differentiable objective function and a convex feasible set. By leveraging the second subderivative of the extended-valued objective function and imposing a suitable restriction on the multiplier, we derive two point-based sufficient characterizations for tilt stability of local optimal solutions around which the objective function has positive semidefinite Hessians, and for a class of linear positive semidefinite cone constraint set, establish a point-based necessary characterization with a certain gap from the sufficient one. For this class of linear positive semidefinite cone constraint case, under a suitable restriction on the set of multipliers, we also establish a point-based sufficient and necessary characterization, which is weaker than the dual constraint nondegeneracy when the set of multipliers is singleton. As far as we know, this is the first work to study point-based sufficient and/or necessary characterizations for nonlinear semidefinite programs with convex constraint sets without constraint nondegeneracy conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16913v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulan Liu, Shaohua Pan, Shujun Bi</dc:creator>
    </item>
    <item>
      <title>Robust Adaptive Data-Driven Control of Positive Systems with Application to Learning in SSP Problems</title>
      <link>https://arxiv.org/abs/2412.17012</link>
      <description>arXiv:2412.17012v1 Announce Type: new 
Abstract: An adaptive data-driven controller is proposed and analysed for the class of infinite-horizon optimal control of positive linear system problems presented in (\cite{ohlin2024optimal}). This controller is synthesized from the solution of a ``data-driven algebraic equation" constructed from the model-free Bellman equation used in Q-learning. This algebraic equation is driven by data correlation matrices that does not scale in the number of data points, making for an efficient online implementation. As a result, a sufficient condition that ensures stability and robustness against unmodeled dynamics in the plant is extracted. The derived results also allows for a quantitative characterization of the interplay between explorations and robustness to unmodeled dynamics. The class of optimal control problems considered here bears equivalence to Stochastic Shortest Path (SSP) problems, allowing for a performance comparison between the proposed adaptive policy and model-free algorithms for learning the stochastic shortest path, as presented in the numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17012v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fethi Bencherki, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Competitive Facility Location with Market Expansion and Customer-centric Objective</title>
      <link>https://arxiv.org/abs/2412.17021</link>
      <description>arXiv:2412.17021v1 Announce Type: new 
Abstract: We study a competitive facility location problem, where customer behavior is modeled and predicted using a discrete choice random utility model. The goal is to strategically place new facilities to maximize the overall captured customer demand in a competitive marketplace. In this work, we introduce two novel considerations. First, the total customer demand in the market is not fixed but is modeled as an increasing function of the customers' total utilities. Second, we incorporate a new term into the objective function, aiming to balance the firm's benefits and customer satisfaction. Our new formulation exhibits a highly nonlinear structure and is not directly solved by existing approaches. To address this, we first demonstrate that, under a concave market expansion function, the objective function is concave and submodular, allowing for a $(1-1/e)$ approximation solution by a simple polynomial-time greedy algorithm. We then develop a new method, called Inner-approximation, which enables us to approximate the mixed-integer nonlinear problem (MINLP), with arbitrary precision, by an MILP without introducing additional integer variables. We further demonstrate that our inner-approximation method consistently yields lower approximations than the outer-approximation methods typically used in the literature. Moreover, we extend our settings by considering a\textit{ general (non-concave)} market-expansion function and show that the Inner-approximation mechanism enables us to approximate the resulting MINLP, with arbitrary precision, by an MILP. To further enhance this MILP, we show how to significantly reduce the number of additional binary variables by leveraging concave areas of the objective function. Extensive experiments demonstrate the efficiency of our approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17021v1</guid>
      <category>math.OC</category>
      <category>econ.EM</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cuong Le, Tien Mai, Ngan Ha Duong, Minh Hoang Ha</dc:creator>
    </item>
    <item>
      <title>Linear Convergence Rate in Convex Setup is Possible! Gradient Descent Method Variants under $(L_0,L_1)$-Smoothness</title>
      <link>https://arxiv.org/abs/2412.17050</link>
      <description>arXiv:2412.17050v1 Announce Type: new 
Abstract: The gradient descent (GD) method -- is a fundamental and likely the most popular optimization algorithm in machine learning (ML), with a history traced back to a paper in 1847 [Cauchy, 1847]. In this paper, we provide an improved convergence analysis of gradient descent and its variants, assuming generalized smoothness $(L_0,L_1)$. In particular, we show that GD has the following behavior of convergence in the convex setup: as long as $\|\nabla f(x^k)\| \geq \frac{L_0}{L_1}$ the algorithm has linear convergence, and approaching the solution $x^*$ such that $\|\nabla f(x^k)\| &lt; \frac{L_0}{L_1}$, has standard sublinear rate. Moreover, we show that this behavior of convergence is also common for its variants using different types of oracle: Normalized Gradient Descent as well as Clipped Gradient Descent (the case when the oracle has access to the full gradient $\nabla f(x)$); Random Coordinate Descent (when the oracle has access only to the gradient component $\nabla_{i} f(x)$); Random Coordinate Descent with Order Oracle (when the oracle has access only to the comparison value of the objective function $\text{sign} [f(y) - f(x)]$). In addition, we also analyze the behavior of convergence rate of GD algorithm in a strongly convex setup. Finally, we validate our theoretical results via numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17050v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Lobanov, Alexander Gasnikov, Eduard Gorbunov, Martin Tak\'ac</dc:creator>
    </item>
    <item>
      <title>Differentially Private Random Block Coordinate Descent</title>
      <link>https://arxiv.org/abs/2412.17054</link>
      <description>arXiv:2412.17054v1 Announce Type: new 
Abstract: Coordinate Descent (CD) methods have gained significant attention in machine learning due to their effectiveness in solving high-dimensional problems and their ability to decompose complex optimization tasks. However, classical CD methods were neither designed nor analyzed with data privacy in mind, a critical concern when handling sensitive information. This has led to the development of differentially private CD methods, such as DP-CD (Differentially Private Coordinate Descent) proposed by Mangold et al. (ICML 2022), yet a disparity remains between non-private CD and DP-CD methods. In our work, we propose a differentially private random block coordinate descent method that selects multiple coordinates with varying probabilities in each iteration using sketch matrices. Our algorithm generalizes both DP-CD and the classical DP-SGD (Differentially Private Stochastic Gradient Descent), while preserving the same utility guarantees. Furthermore, we demonstrate that better utility can be achieved through importance sampling, as our method takes advantage of the heterogeneity in coordinate-wise smoothness constants, leading to improved convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17054v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Abdurakhmon Sadiev, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>On incorporating variable consumption functions within energy-efficient parallel machine scheduling</title>
      <link>https://arxiv.org/abs/2412.17055</link>
      <description>arXiv:2412.17055v1 Announce Type: new 
Abstract: The increase in non-renewable energy consumption and CO2 emissions, especially in the manufacturing sector, is moving radical shifts in energy supply policies and production models. Renewable energy integration and regulated pricing policies require new and effective scheduling strategies, as highlighted by the emerging field of energy-efficient scheduling. In this paper, we aim to contribute to this field by addressing a scheduling problem where a set of jobs must be allocated to a set of machines over a discrete finite horizon and variable energy consumptions are required for job execution. Energy can be obtained by a renewable source or through transactions on the market. The goal is to minimize the total energy costs from the grid while scheduling all the jobs within the time horizon and adhering to an energy limit per time period. We introduce a novel time-indexed Mixed Integer Linear Programming (MILP) formulation capable of handling variable energy consumption functions, surpassing traditional models that assume constant energy usage of jobs. We then develop a matheuristic algorithm based on an Iterated Local Search (ILS) framework that exploits the MILP formulation for large neighborhood searches. We tested more than 200 instances with up to 200 jobs, 35 machines, and 120 time slots. The results show a good performance of both our methods and highlight the advantage of using the ILS when jobs are characterized by variable consumption functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17055v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mirko Mucciarini, Giulia Caselli, Daniele De Santis, Manuel Iori, Juan Jos\'e Miranda-Bront</dc:creator>
    </item>
    <item>
      <title>A Convergent ADMM Algorithm for Grain Boundary Energy Minimization</title>
      <link>https://arxiv.org/abs/2412.17058</link>
      <description>arXiv:2412.17058v1 Announce Type: new 
Abstract: In this paper, we study a constrained minimization problem that arise from materials science to determine the dislocation (line defect) structure of grain boundaries. The problems aims to minimize the energy of the grain boundary with dislocation structure subject to the constraint of Frank's formula. In this constrained minimization problem, the objective function, i.e., the grain boundary energy, is nonconvex and separable, and the constraints are linear. To solve this constrained minimization problem, we modify the alternating direction method of multipliers (ADMM) with an increasing penalty parameter. We provide a convergence analysis of the modified ADMM in this nonconvex minimization problem, with settings not considered by the existing ADMM convergence studies. Specifically, in the linear constraints, the coefficient matrix of each subvariable block is of full column rank. This property makes each subvariable minimization strongly convex if the penalty parameter is large enough, and contributes to the convergence of ADMM without any convex assumption on the entire objective function. We prove that the limit of the sequence from the modified ADMM is primal feasible and is the stationary point of the augmented Lagrangian function. Furthermore, we obtain sufficient conditions to show that the objective function is quasi-convex and thus it has a unique minimum over the given domain. Numerical examples are presented to validate the convergence of the algorithm, and results of the penalty method, the augmented Lagrangian method, and the modified ADMM are compared.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17058v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Wu, Luchan Zhang, Yang Xiang</dc:creator>
    </item>
    <item>
      <title>Second-order sufficient optimality conditions in the calculus of variations</title>
      <link>https://arxiv.org/abs/2412.17166</link>
      <description>arXiv:2412.17166v1 Announce Type: new 
Abstract: Some classic second-order sufficient optimality conditions in the calculus of variations are shown to be equivalent, while also introducing a new equivalent second-order condition which is extremely easy to apply: simply integrate a linear second-order initial value problem and check that the solution is positive over the problem domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17166v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William W. Hager</dc:creator>
    </item>
    <item>
      <title>Convexification of Multi-period Quadratic Programs with Indicators</title>
      <link>https://arxiv.org/abs/2412.17178</link>
      <description>arXiv:2412.17178v1 Announce Type: new 
Abstract: We study a multi-period convex quadratic optimization problem, where the state evolves dynamically as an affine function of the state, control, and indicator variables in each period. We begin by projecting out the state variables using linear dynamics, resulting in a mixed-integer quadratic optimization problem with a (block-) factorizable cost matrix. We discuss the properties of these matrices and derive a closed-form expression for their inverses. Employing this expression, we construct a closed convex hull representation of the epigraph of the quadratic cost over the feasible region in an extended space. Subsequently, we establish a tight second-order cone programming formulation with $\mathcal{O}(n^2)$ conic constraints. We further propose a polynomial-time algorithm based on a reformulation of the problem as a shortest path problem on a directed acyclic graph. To illustrate the applicability of our results across diverse domains, we present case studies in statistical learning and hybrid system control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17178v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jisun Lee, Andr\'es G\'omez, Alper Atamt\"urk</dc:creator>
    </item>
    <item>
      <title>Model-free stochastic linear quadratic design by semidefinite programming</title>
      <link>https://arxiv.org/abs/2412.17230</link>
      <description>arXiv:2412.17230v1 Announce Type: new 
Abstract: In this article, we study a model-free design approach for stochastic linear quadratic (SLQ) controllers. Based on the convexity of the SLQ dual problem and the Karush-Kuhn-Tucker (KKT) conditions, we find the relationship between the optimal point of the dual problem and the Q-function, which can be used to develop a novel model-free semidefinite programming (SDP) algorithm for deriving optimal control gain. This study provides a new optimization perspective for understanding Q-learning algorithms and lays a theoretical foundation for effective reinforcement learning (RL) algorithms. Finally, the effectiveness of the proposed model-free SDP algorithm is demonstrated by two case simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17230v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Guo, Xiushan Jiang, Weihai Zhang</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Distributionally Robust Solutions through Forecasting and Operations Decentralization</title>
      <link>https://arxiv.org/abs/2412.17257</link>
      <description>arXiv:2412.17257v1 Announce Type: new 
Abstract: Two-stage risk-averse distributionally robust optimization (DRO) problems are ubiquitous across many engineering and business applications. Despite their promising resilience, two-stage DRO problems are generally computationally intractable. To address this challenge, we propose a simple framework by decentralizing the decision-making process into two specialized teams: forecasting and operations. This decentralization aligns with prevalent organizational practices, in which the operations team uses the information communicated from the forecasting team as input to make decisions. We formalize this decentralized procedure as a bilevel problem to design a communicated distribution that can yield asymptotic optimal solutions to original two-stage risk-averse DRO problems. We identify an optimal solution that is surprisingly simple: The forecasting team only needs to communicate a two-point distribution to the operations team. Consequently, the operations team can solve a highly tractable and scalable optimization problem to identify asymptotic optimal solutions. Specifically, as the magnitude of the problem parameters (including the uncertain parameters and the first-stage capacity) increases to infinity at an appropriate rate, the cost ratio between our induced solution and the original optimal solution converges to one, indicating that our decentralized approach yields high-quality solutions. We compare our decentralized approach against the truncated linear decision rule approximation and demonstrate that our approach has broader applicability and superior computational efficiency while maintaining competitive performance. Using real-world sales data, we have demonstrated the practical effectiveness of our strategy. The finely tuned solution significantly outperforms traditional sample-average approximation methods in out-of-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17257v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Lin, Daniel Zhuoyu Long, Viet Anh Nguyen, Jin Qi</dc:creator>
    </item>
    <item>
      <title>Routing mobile health clinics: An integrated routing and resupply plan based on synchronization</title>
      <link>https://arxiv.org/abs/2412.17299</link>
      <description>arXiv:2412.17299v1 Announce Type: new 
Abstract: As an important means of providing medical services in developing countries and remote areas, Mobile Health Clinics (MHCs) focus on distributing medical supplies and providing basic health needs to underserved communities. In this paper, we propose a new model for the mobile health clinics with resupply from a truck and heterogeneous demand. In addition to the traditional routing decisions, our model also establishes en-route resupply plan. Adding the en-route resupply plan adds complexities to this problem as more constraints need to be added to accommodate for the synchronization between a fleet of MHCs and a resupply truck. We model this problem as a vehicle routing problem with multiple synchronization constraints and heterogeneous demand (VRPMSC-HD) and formulate a mixed integer linear programming (MILP). We propose a metaheuristic based on adaptive large neighborhood search (ALNS) with new operators to solve large-scale instances of the model. To demonstrate the value of the synchronization approach, we compare the total distance traveled by the mobile health clinics and the resupply truck and the arrival of the last mobile health clinic to the depot against a model where mobile health clinics are allowed to perform multiple trips to resupply from the depot. Our results reveal that despite the increase of 6.79% in traveled distance under the synchronization approach, the reduction in the latest arrival time is 16.06% on average. Implying that the utilization of the fleet of mobile health clinics can be significantly improved at the cost of extra traveling time when combining the traveling time of all the mobile health clinics and the resupply truck.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17299v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faisal Alkaabneh, Sam Jotham Sutharson</dc:creator>
    </item>
    <item>
      <title>Low Rank Convex Clustering For Matrix-Valued Observations</title>
      <link>https://arxiv.org/abs/2412.17328</link>
      <description>arXiv:2412.17328v1 Announce Type: new 
Abstract: Common clustering methods, such as $k$-means and convex clustering, group similar vector-valued observations into clusters. However, with the increasing prevalence of matrix-valued observations, which often exhibit low rank characteristics, there is a growing need for specialized clustering techniques for these data types. In this paper, we propose a low rank convex clustering model tailored for matrix-valued observations. Our approach extends the convex clustering model originally designed for vector-valued data to classify matrix-valued observations. Additionally, it serves as a convex relaxation of the low rank $k$-means method proposed by Z. Lyu, and D. Xia (arXiv:2207.04600). Theoretically, we establish exact cluster recovery for finite samples and asymptotic cluster recovery as the sample size approaches infinity. We also give a finite sample bound on prediction error in terms of centroid estimation, and further establish the prediction consistency. To make the model practically useful, we develop an efficient double-loop algorithm for solving it. Extensive numerical experiments are conducted to show the effectiveness of our proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17328v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meixia Lin, Yangjing Zhang</dc:creator>
    </item>
    <item>
      <title>An efficient gradient projection method for stochastic optimal control problem with expected integral state constraint</title>
      <link>https://arxiv.org/abs/2412.17363</link>
      <description>arXiv:2412.17363v1 Announce Type: new 
Abstract: In this work, we present an efficient gradient projection method for solving a class of stochastic optimal control problem with expected integral state constraint. The first order optimality condition system consisting of forward-backward stochastic differential equations and a variational equation is first derived. Then, an efficient gradient projection method with linear drift coefficient is proposed where the state constraint is guaranteed by constructing specific multiplier. Further, the Euler method is used to discretize the forward-backward stochastic differential equations and the associated conditional expectations are approximated by the least square Monte Carlo method, yielding the fully discrete iterative scheme. Error estimates of control and multiplier are presented, showing that the method admits first order convergence. Finally we present numerical examples to support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17363v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiming Wang, Wenbin Liu</dc:creator>
    </item>
    <item>
      <title>Quadratic obstructions to small-time local controllability for multi-input systems</title>
      <link>https://arxiv.org/abs/2412.17384</link>
      <description>arXiv:2412.17384v1 Announce Type: new 
Abstract: We present a necessary condition for the small-time local controllability of multi-input control-affine systems on $R^d$ . This condition is formulated on the vectors of $R^d$ resulting from the evaluation at zero of the Lie brackets of the vector fields: it involves both their direction and their amplitude. The proof is an adaptation to the multi-input case of a general method introduced by Beauchard and Marbach in the single-input case. It relies on a Magnus-type representation formula: the state is approximated by a linear combination of the evaluation at zero of the Lie brackets of the vector fields, whose coefficients are functionals of the time and the controls. Finally, obstructions to small-time local controllability result from interpolation inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17384v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Th\'eo Gherdaoui (ENS Rennes, IRMAR)</dc:creator>
    </item>
    <item>
      <title>Lipschitz Continuity Results for Minimax Solutions of Path-Dependent Hamilton--Jacobi Equations</title>
      <link>https://arxiv.org/abs/2412.17388</link>
      <description>arXiv:2412.17388v1 Announce Type: new 
Abstract: We consider a Cauchy problem for a (first-order) path-dependent Hamilton--Jacobi equation with coinvariant derivatives and a right-end boundary condition. Such problems arise naturally in the study of properties of the value functional in (deterministic) optimal control problems and differential games for time-delay systems. We prove that, under certain assumptions on the Hamiltonian and the boundary functional, a minimax (generalized) solution of the Cauchy problem satisfies Lipschitz conditions both in time and functional variables. In the latter case, Lipschitz conditions are formulated with respect to the uniform norm and some special norm of the space of continuous functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17388v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikhail I. Gomoyunov</dc:creator>
    </item>
    <item>
      <title>Towards An Unsupervised Learning Scheme for Efficiently Solving Parameterized Mixed-Integer Programs</title>
      <link>https://arxiv.org/abs/2412.17623</link>
      <description>arXiv:2412.17623v2 Announce Type: new 
Abstract: In this paper, we describe a novel unsupervised learning scheme for accelerating the solution of a family of mixed integer programming (MIP) problems. Distinct substantially from existing learning-to-optimize methods, our proposal seeks to train an autoencoder (AE) for binary variables in an unsupervised learning fashion, using data of optimal solutions to historical instances for a parametric family of MIPs. By a deliberate design of AE architecture and exploitation of its statistical implication, we present a simple and straightforward strategy to construct a class of cutting plane constraints from the decoder parameters of an offline-trained AE. These constraints reliably enclose the optimal binary solutions of new problem instances thanks to the representation strength of the AE. More importantly, their integration into the primal MIP problem leads to a tightened MIP with the reduced feasible region, which can be resolved at decision time using off-the-shelf solvers with much higher efficiency. Our method is applied to a benchmark batch process scheduling problem formulated as a mixed integer linear programming (MILP) problem. Comprehensive results demonstrate that our approach significantly reduces the computational cost of off-the-shelf MILP solvers while retaining a high solution quality. The codes of this work are open-sourced at https://github.com/qushiyuan/AE4BV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17623v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiyuan Qu, Fenglian Dong, Zhiwei Wei, Chao Shang</dc:creator>
    </item>
    <item>
      <title>Mixed extensions of generic finite games embedded into products of real projective spaces</title>
      <link>https://arxiv.org/abs/2412.17638</link>
      <description>arXiv:2412.17638v1 Announce Type: new 
Abstract: Finite games in normal form and their mixed extensions are a corner stone of noncooperative game theory. Often generic finite games and their mixed extensions are considered. But the properties which one expects in generic games and the existence of games with these properties are often treated only in passing. The paper considers strong properties and proves that generic games have these properties. The space of mixed strategy combinations is embedded in a natural way into a product of real projective spaces. All relevant hypersurfaces extend to this bigger space. The paper shows that for all games in the complement of a semialgebraic subset of codimension at least one all relevant hypersurfaces in the bigger space are smooth and maximally transversal. The proof uses the theorem of Sard and follows an argument of Khovanskii.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17638v1</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Claus Hertling, Matija Vujic</dc:creator>
    </item>
    <item>
      <title>Mean--Variance Portfolio Selection by Continuous-Time Reinforcement Learning: Algorithms, Regret Analysis, and Empirical Study</title>
      <link>https://arxiv.org/abs/2412.16175</link>
      <description>arXiv:2412.16175v1 Announce Type: cross 
Abstract: We study continuous-time mean--variance portfolio selection in markets where stock prices are diffusion processes driven by observable factors that are also diffusion processes yet the coefficients of these processes are unknown. Based on the recently developed reinforcement learning (RL) theory for diffusion processes, we present a general data-driven RL algorithm that learns the pre-committed investment strategy directly without attempting to learn or estimate the market coefficients. For multi-stock Black--Scholes markets without factors, we further devise a baseline algorithm and prove its performance guarantee by deriving a sublinear regret bound in terms of Sharpe ratio. For performance enhancement and practical implementation, we modify the baseline algorithm into four variants, and carry out an extensive empirical study to compare their performance, in terms of a host of common metrics, with a large number of widely used portfolio allocation strategies on S\&amp;P 500 constituents. The results demonstrate that the continuous-time RL strategies are consistently among the best especially in a volatile bear market, and decisively outperform the model-based continuous-time counterparts by significant margins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16175v1</guid>
      <category>q-fin.PM</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang, Yanwei Jia, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Optimization Insights into Deep Diagonal Linear Networks</title>
      <link>https://arxiv.org/abs/2412.16765</link>
      <description>arXiv:2412.16765v1 Announce Type: cross 
Abstract: Overparameterized models trained with (stochastic) gradient descent are ubiquitous in modern machine learning. These large models achieve unprecedented performance on test data, but their theoretical understanding is still limited. In this paper, we take a step towards filling this gap by adopting an optimization perspective. More precisely, we study the implicit regularization properties of the gradient flow "algorithm" for estimating the parameters of a deep diagonal neural network. Our main contribution is showing that this gradient flow induces a mirror flow dynamic on the model, meaning that it is biased towards a specific solution of the problem depending on the initialization of the network. Along the way, we prove several properties of the trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16765v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hippolyte Labarri\`ere, Cesare Molinari, Lorenzo Rosasco, Silvia Villa, Cristian Vega</dc:creator>
    </item>
    <item>
      <title>Euclidean distance discriminants and Morse attractors</title>
      <link>https://arxiv.org/abs/2412.16957</link>
      <description>arXiv:2412.16957v1 Announce Type: cross 
Abstract: Our study concerns the Euclidean distance function in case of complex plane curves. We decompose the ED discriminant into 3 parts which are responsible for the 3 types of behavior of the Morse points, and we find the structure of each one. In particular we shed light on the ``atypical discriminant'' which is due to the loss of Morse points at infinity.
  We find formulas for the number of Morse singularities which abut to the corresponding 3 types of attractors when moving the centre of the distance function toward a point of the discriminant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16957v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cezar Joi\c{t}a, Dirk Siersma, Mihai Tib\u{a}r</dc:creator>
    </item>
    <item>
      <title>Distributed Target Tracking based on Localization with Linear Time-Difference-of-Arrival Measurements: A Delay-Tolerant Networked Estimation Approach</title>
      <link>https://arxiv.org/abs/2412.16988</link>
      <description>arXiv:2412.16988v1 Announce Type: cross 
Abstract: This paper considers target tracking based on a beacon signal's time-difference-of-arrival (TDOA) to a group of cooperating sensors. The sensors receive a reflected signal from the target where the time-of-arrival (TOA) renders the distance information. The existing approaches include: (i) classic centralized solutions which gather and process the target data at a central unit, (ii) distributed solutions which assume that the target data is observable in the dense neighborhood of each sensor (to be filtered locally), and (iii) double time-scale distributed methods with high rates of communication/consensus over the network. This work, in order to reduce the network connectivity in (i)-(ii) and communication rate in (iii), proposes a distributed single time-scale technique, which can also handle heterogeneous constant data-exchange delays over the static sensor network. This work assumes only distributed observability (in contrast to local observability in some existing works categorized in (ii)), i.e., the target is observable globally over a (strongly) connected network. The (strong) connectivity further allows for survivable network and $q$-redundant observer design. Each sensor locally shares information and processes the received data in its immediate neighborhood via local linear-matrix-inequalities (LMI) feedback gains to ensure tracking error stability. The same gain matrix works in the presence of heterogeneous delays with no need of redesigning algorithms. Since most existing distributed estimation scenarios are linear (based on consensus), many works use linearization of the existing nonlinear TDOA measurement models where the output matrix is a function of the target position.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16988v1</guid>
      <category>eess.SY</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Themistoklis Charalambous</dc:creator>
    </item>
    <item>
      <title>Leveraging Neural Networks to Optimize Heliostat Field Aiming Strategies in Concentrating Solar Power Tower Plants</title>
      <link>https://arxiv.org/abs/2412.16995</link>
      <description>arXiv:2412.16995v1 Announce Type: cross 
Abstract: Concentrating Solar Power Tower (CSPT) plants rely on heliostat fields to focus sunlight onto a central receiver. Although simple aiming strategies, such as directing all heliostats to the receivers equator, can maximize energy collection, they often result in uneven flux distributions that lead to hotspots, thermal stresses, and reduced receiver lifetimes. This paper presents a novel, data-driven approach that integrates constraint learning, neural network-based surrogates, and mathematical optimization to overcome these challenges. The methodology learns complex heliostat-to-receiver flux interactions from simulation data, constructing a surrogate model that is embedded into a tractable optimization framework. By maximizing a tailored quality score that balances energy collection and flux uniformity, the approach yields smoothly distributed flux profiles and mitigates excessive thermal peaks. An iterative refinement process, guided by the trust region and progressive data sampling, ensures the surrogate model improves the obtained solution by exploring new spaces during the iterations. Results from a real CSPT case study demonstrate that the proposed approach surpasses conventional heuristic methods, offering flatter flux distributions and safer thermal conditions without a substantial loss in overall energy capture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16995v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Alc\'antara, Pablo Diaz-Cachinero, Alberto S\'anchez-Gonz\'alez, Carlos Ruiz</dc:creator>
    </item>
    <item>
      <title>Decoupled Functional Central Limit Theorems for Two-Time-Scale Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2412.17070</link>
      <description>arXiv:2412.17070v1 Announce Type: cross 
Abstract: In two-time-scale stochastic approximation (SA), two iterates are updated at different rates, governed by distinct step sizes, with each update influencing the other. Previous studies have demonstrated that the convergence rates of the error terms for these updates depend solely on their respective step sizes, a property known as decoupled convergence. However, a functional version of this decoupled convergence has not been explored. Our work fills this gap by establishing decoupled functional central limit theorems for two-time-scale SA, offering a more precise characterization of its asymptotic behavior. To achieve these results, we leverage the martingale problem approach and establish tightness as a crucial intermediate step. Furthermore, to address the interdependence between different time scales, we introduce an innovative auxiliary sequence to eliminate the primary influence of the fast-time-scale update on the slow-time-scale update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17070v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuze Han, Xiang Li, Jiadong Liang, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>MARINA-P: Superior Performance in Non-smooth Federated Optimization with Adaptive Stepsizes</title>
      <link>https://arxiv.org/abs/2412.17082</link>
      <description>arXiv:2412.17082v1 Announce Type: cross 
Abstract: Non-smooth communication-efficient federated optimization is crucial for many machine learning applications, yet remains largely unexplored theoretically. Recent advancements have primarily focused on smooth convex and non-convex regimes, leaving a significant gap in understanding the non-smooth convex setting. Additionally, existing literature often overlooks efficient server-to-worker communication (downlink), focusing primarily on worker-to-server communication (uplink). We consider a setup where uplink costs are negligible and focus on optimizing downlink communication by improving state-of-the-art schemes like EF21-P (arXiv:2209.15218) and MARINA-P (arXiv:2402.06412) in the non-smooth convex setting. We extend the non-smooth convex theory of EF21-P [Anonymous, 2024], originally developed for single-node scenarios, to the distributed setting, and extend MARINA-P to the non-smooth convex setting. For both algorithms, we prove an optimal $O(1/\sqrt{T})$ convergence rate and establish communication complexity bounds matching classical subgradient methods. We provide theoretical guarantees under constant, decreasing, and adaptive (Polyak-type) stepsizes. Our experiments demonstrate that MARINA-P with correlated compressors outperforms other methods in both smooth non-convex and non-smooth convex settings. This work presents the first theoretical results for distributed non-smooth optimization with server-to-worker compression, along with comprehensive analysis for various stepsize schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17082v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Sokolov, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Fast charging of an Ising spin pair quantum battery using optimal control</title>
      <link>https://arxiv.org/abs/2412.17087</link>
      <description>arXiv:2412.17087v1 Announce Type: cross 
Abstract: We consider the problem of maximizing the stored energy for a given charging duration in a quantum battery composed of a pair of spins-$1/2$ with Ising coupling starting from the spin-down state, using bounded transverse field control. We map this problem to an optimal control problem on a single qubit and using optimal control theory we show that, although a single bang pulse can quickly achieve considerable charging levels for relatively large upper control bounds, higher levels of stored energy including complete charging are accomplished by a bang-singular-bang pulse-sequence, where the intermediate singular pulse is an Off pulse. If the control is restricted between zero and a maximum value, the initial and final bang pulses attain the maximum bound but have different durations, while if it is restricted between symmetric negative and positive boundaries, the bang pulses have the same duration but opposite boundary values. For both cases we provide transcendental equations from which the durations of the individual pulses in the optimal pulse-sequence can be calculated. For the case of full charging we surprisingly find that the three ``switching" functions for the equivalent qubit problem become zero while the adjoint ket does not, in consistency with optimal control theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17087v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevA.110.052601</arxiv:DOI>
      <arxiv:journal_reference>Physical Review A 110, 052601 (2024)</arxiv:journal_reference>
      <dc:creator>Vasileios Evangelakos, Emmanuel Paspalakis, Dionisis Stefanatos</dc:creator>
    </item>
    <item>
      <title>Grams: Gradient Descent with Adaptive Momentum Scaling</title>
      <link>https://arxiv.org/abs/2412.17107</link>
      <description>arXiv:2412.17107v1 Announce Type: cross 
Abstract: We introduce \textbf{Gr}adient Descent with \textbf{A}daptive \textbf{M}omentum \textbf{S}caling (\textbf{Grams}), a novel optimization algorithm that decouples the direction and magnitude of parameter updates in deep learning. Unlike traditional optimizers that directly integrate momentum into updates, Grams separates the update direction, derived from current gradients, from momentum, which is used solely for adaptive magnitude scaling. This approach enables Grams to achieve improved loss descent compared to state-of-the-art cautious and momentum-based optimizers. We establish a global convergence guarantee for Grams and validate its effectiveness through extensive empirical evaluations. The results demonstrate Grams' superior performance, including faster convergence and better generalization, compared to widely-used optimizers such as Adam, Lion, and their cautious variants. Our results highlight Grams' potential as a transformative approach for efficient optimization in large-scale machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17107v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cao, Xiaoyu Li, Zhao Song</dc:creator>
    </item>
    <item>
      <title>Adam on Local Time: Addressing Nonstationarity in RL with Relative Adam Timesteps</title>
      <link>https://arxiv.org/abs/2412.17113</link>
      <description>arXiv:2412.17113v1 Announce Type: cross 
Abstract: In reinforcement learning (RL), it is common to apply techniques used broadly in machine learning such as neural network function approximators and momentum-based optimizers. However, such tools were largely developed for supervised learning rather than nonstationary RL, leading practitioners to adopt target networks, clipped policy updates, and other RL-specific implementation tricks to combat this mismatch, rather than directly adapting this toolchain for use in RL. In this paper, we take a different approach and instead address the effect of nonstationarity by adapting the widely used Adam optimiser. We first analyse the impact of nonstationary gradient magnitude -- such as that caused by a change in target network -- on Adam's update size, demonstrating that such a change can lead to large updates and hence sub-optimal performance. To address this, we introduce Adam-Rel. Rather than using the global timestep in the Adam update, Adam-Rel uses the local timestep within an epoch, essentially resetting Adam's timestep to 0 after target changes. We demonstrate that this avoids large updates and reduces to learning rate annealing in the absence of such increases in gradient magnitude. Evaluating Adam-Rel in both on-policy and off-policy RL, we demonstrate improved performance in both Atari and Craftax. We then show that increases in gradient norm occur in RL in practice, and examine the differences between our theoretical model and the observed data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17113v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Ellis, Matthew T. Jackson, Andrei Lupu, Alexander D. Goldie, Mattie Fellows, Shimon Whiteson, Jakob Foerster</dc:creator>
    </item>
    <item>
      <title>Fair and Accurate Regression: Strong Formulations and Algorithms</title>
      <link>https://arxiv.org/abs/2412.17116</link>
      <description>arXiv:2412.17116v1 Announce Type: cross 
Abstract: This paper introduces mixed-integer optimization methods to solve regression problems that incorporate fairness metrics. We propose an exact formulation for training fair regression models. To tackle this computationally hard problem, we study the polynomially-solvable single-factor and single-observation subproblems as building blocks and derive their closed convex hull descriptions. Strong formulations obtained for the general fair regression problem in this manner are utilized to solve the problem with a branch-and-bound algorithm exactly or as a relaxation to produce fair and accurate models rapidly. Moreover, to handle large-scale instances, we develop a coordinate descent algorithm motivated by the convex-hull representation of the single-factor fair regression problem to improve a given solution efficiently. Numerical experiments conducted on fair least squares and fair logistic regression problems show competitive statistical performance with state-of-the-art methods while significantly reducing training times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17116v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Deza, Andr\'es G\'omez, Alper Atamt\"urk</dc:creator>
    </item>
    <item>
      <title>A Coalition Game for On-demand Multi-modal 3D Automated Delivery System</title>
      <link>https://arxiv.org/abs/2412.17252</link>
      <description>arXiv:2412.17252v1 Announce Type: cross 
Abstract: We introduce a multi-modal autonomous delivery optimization framework as a coalition game for a fleet of UAVs and ADRs operating in two overlaying networks to address last-mile delivery in urban environments, including high-density areas, road-based routing, and real-world operational challenges. The problem is defined as multiple depot pickup and delivery with time windows constrained over operational restrictions, such as vehicle battery limitation, precedence time window, and building obstruction. Subsequently, the coalition game theory is applied to investigate cooperation structures among the modes to capture how strategic collaboration among vehicles can improve overall routing efficiency. To do so, a generalized reinforcement learning model is designed to evaluate the cost-sharing and allocation to different coalitions for which sub-additive property and non-empty core exist. Our methodology leverages an end-to-end deep multi-agent policy gradient method augmented by a novel spatio-temporal adjacency neighbourhood graph attention network and transformer architecture using a heterogeneous edge-enhanced attention model. Conducting several numerical experiments on last-mile delivery applications, the result from the case study in the city of Mississauga shows that despite the incorporation of an extensive network in the graph for two modes and a complex training structure, the model addresses realistic operational constraints and achieves high-quality solutions compared with the existing transformer-based and heuristics methods and can perform well on non-homogeneous data distribution, generalizes well on the different scale and configuration, and demonstrate a robust performance under stochastic scenarios subject to wind speed and direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17252v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farzan Moosavi, Bilal Farooq</dc:creator>
    </item>
    <item>
      <title>Subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2412.17318</link>
      <description>arXiv:2412.17318v1 Announce Type: cross 
Abstract: We present new convergence analyses for subspace correction methods for semicoercive and nearly semicoercive convex optimization problems, generalizing the theory of singular and nearly singular linear problems to the nonlinear domain. Our results demonstrate that the elegant theoretical framework developed for singular and nearly singular linear problems can be extended to semicoercive and nearly semicoercive convex optimization problems. For semicoercive problems, we show that the convergence rate can be estimated in terms of a seminorm stable decomposition over the subspaces and the kernel of the problem, aligning with the theory for singular linear problems. For nearly semicoercive problems, we establish a parameter-independent convergence rate, assuming the kernel of the semicoercive part can be decomposed into a sum of local kernels, which aligns with the theory for nearly singular problems. To demonstrate the applicability of our results, we provide convergence analyses of two-level additive Schwarz methods for solving a nonlinear Neumann boundary value problem and its perturbation within the proposed abstract framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17318v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Young-Ju Lee, Jongho Park</dc:creator>
    </item>
    <item>
      <title>Optimization in complex spaces with the Mixed Newton Method</title>
      <link>https://arxiv.org/abs/2207.04265</link>
      <description>arXiv:2207.04265v2 Announce Type: replace 
Abstract: We propose a second-order method for unconditional minimization of functions $f(z)$ of complex arguments. We call it the Mixed Newton Method due to the use of the mixed Wirtinger derivative $\frac{\partial^2f}{\partial\bar z\partial z}$ for computation of the search direction, as opposed to the full Hessian $\frac{\partial^2f}{\partial(z,\bar z)^2}$ in the classical Newton method. The method has been developed for specific applications in wireless network communications, but its global convergence properties are shown to be superior on a more general class of functions $f$, namely sums of squares of absolute values of holomorphic functions. In particular, for such objective functions minima are surrounded by attraction basins, while the iterates are repelled from other types of critical points. We provide formulas for the asymptotic convergence rate and show that in the scalar case the method reduces to the well-known complex Newton method for the search of zeros of holomorphic functions. In this case, it exhibits generically fractal global convergence patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.04265v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Bakhurin, Roland Hildebrand, Mohammad Alkousa, Alexander Titov, Nikita Yudin</dc:creator>
    </item>
    <item>
      <title>Anisotropic Proximal Gradient</title>
      <link>https://arxiv.org/abs/2210.15531</link>
      <description>arXiv:2210.15531v4 Announce Type: replace 
Abstract: This paper studies a novel algorithm for nonconvex composite minimization which can be interpreted in terms of dual space nonlinear preconditioning for the classical proximal gradient method. The proposed scheme can be applied to additive composite minimization problems whose smooth part exhibits an anisotropic descent inequality relative to a reference function. It is proved that the anisotropic descent property is closed under pointwise average if the Bregman distance generated by the conjugate reference function is jointly convex. More specifically, for the exponential reference function we prove its closedness under pointwise conic combinations. We analyze the method's asymptotic convergence and prove its linear convergence under an anisotropic proximal gradient dominance condition. Applications are discussed including exponentially regularized LPs and logistic regression with nonsmooth regularization. In numerical experiments we show significant improvements of the proposed method over its Euclidean counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.15531v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Modified parameter of Dai Liao conjugacy condition of the conjugate gradient method</title>
      <link>https://arxiv.org/abs/2304.06694</link>
      <description>arXiv:2304.06694v3 Announce Type: replace 
Abstract: The conjugate gradient (CG) method is widely used for solving nonlinear unconstrained optimization problems because it requires less memory to implement. In this paper, we propose a new parameter of the Dai Liao conjugacy condition of the CG method with the restart property, which depends on the Lipschitz constant and is related to the Hestenes Stiefel method. The proposed method satisfies the descent condition and global convergence properties for convex and non-convex functions. In the numerical experiment, we compare the new method with CG_Descent using more than 200 functions from the CUTEst library. The comparison results show that the new method outperforms CG Descent in terms of CPU time, number of iterations, number of gradient evaluations, and number of function evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06694v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Alhawarat</dc:creator>
    </item>
    <item>
      <title>Finite adaptability in two-stage robust optimization: asymptotic optimality and tractability</title>
      <link>https://arxiv.org/abs/2305.05399</link>
      <description>arXiv:2305.05399v4 Announce Type: replace 
Abstract: Two-stage robust optimization is a fundamental paradigm for modeling and solving optimization problems with uncertain parameters. A now classical method within this paradigm is finite adaptability, introduced by Bertsimas and Caramanis (IEEE Transactions on Automatic Control, 2010). It consists in restricting the recourse to a finite number $k$ of possible values. In this work, we point out that the continuity assumption they stated to ensure the convergence of the method when $k$ goes to infinity is not correct, and we propose an alternative assumption for which we prove the desired convergence. Bertsimas and Caramanis also established that finite adaptability is NP-hard, even in the special case when $k=2$, the variables are continuous, and only specific parameters are subject to uncertainty. We provide a theorem showing that this special case becomes polynomial when the uncertainty set is a polytope with a bounded number of vertices, and we extend this theorem for $k=3$ as well. On our way, we establish new geometric results on coverings of polytopes with convex sets, which might be interesting for their own sake.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05399v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Safia Kedad-Sidhoum, Anton Medvedev, Fr\'ed\'eric Meunier</dc:creator>
    </item>
    <item>
      <title>On generalized KKT points for the Motzkin-Straus program</title>
      <link>https://arxiv.org/abs/2305.08519</link>
      <description>arXiv:2305.08519v2 Announce Type: replace 
Abstract: In 1965, T. S. Motzkin and E. G. Straus established an elegant connection between the clique number of a graph and the global maxima of a quadratic program defined on the standard simplex. Over the years, this seminal finding has inspired a number of studies aimed at characterizing the properties of the (local and global) solutions of the Motzkin-Straus program. The result has also been generalized in various ways and has served as the basis for establishing new bounds on the clique number and developing powerful clique-finding heuristics. Despite the extensive work done on the subject, apart from a few exceptions, the existing literature pays little or no attention to the Karush-Kuhn-Tucker (KKT) points of the program. In the conviction that these points might reveal interesting structural properties of the graph underlying the program, this paper tries to fill in the gap. In particular, we study the generalized KKT points of a parameterized version of the Motzkin-Straus program, which are defined via a relaxation of the usual first-order optimality conditions, and we present a number of results that shed light on the symmetries and regularities of certain substructures associated with the underlying graph. These combinatorial structures are further analyzed using barycentric coordinates, thereby providing a link to a related quadratic program that encodes local structural properties of the graph. This turns out to be particularly useful in the study of the generalized KKT points associated with a certain class of graphs that generalize the notion of a star graph. Finally, we discuss the associations between the generalized KKT points of the Motzkin-Straus program and the so-called replicator dynamics, thereby offering an alternative, dynamical-system perspective on the results presented in the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08519v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10898-024-01457-2</arxiv:DOI>
      <arxiv:journal_reference>J Glob Optim (2024)</arxiv:journal_reference>
      <dc:creator>G. Beretta, A. Torcinovich, M. Pelillo</dc:creator>
    </item>
    <item>
      <title>Optimal control of stochastic delay differential equations: Optimal feedback controls</title>
      <link>https://arxiv.org/abs/2309.05029</link>
      <description>arXiv:2309.05029v4 Announce Type: replace 
Abstract: In this manuscript, we study optimal control problems for stochastic delay differential equations using the dynamic programming approach in Hilbert spaces via viscosity solutions of the associated Hamilton-Jacobi-Bellman equations. We show how to use the partial $C^{1,\alpha}$-regularity of the value function established in \cite{defeo_federico_swiech} to obtain optimal feedback controls. The main result of the paper is a verification theorem which provides a sufficient condition for optimality using the value function. We then discuss its applicability to the construction of optimal feedback controls. We provide an application to stochastic optimal advertising problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05029v4</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo, Andrzej \'Swi\k{e}ch</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Line Planning with Multiple Resource Constraints</title>
      <link>https://arxiv.org/abs/2311.03327</link>
      <description>arXiv:2311.03327v3 Announce Type: replace 
Abstract: We consider the problem of maximizing the total reward in a transportation system with $M$ buses that serve a set of Origin-Destination (OD) pairs. Each bus operates on at most one line selected from a set of candidate lines, where operating a line incurs multiple resource costs. The goal is to efficiently assign the buses to the lines to serve integral portions of given OD demands while respecting bus capacity, resource limits, and demand constraints. This model significantly generalizes line planning models in prior works by integrating candidate line assignments to buses, broader OD demand specifications, and considering multiple resource constraints.
  We propose randomized approximation algorithms addressing various problem scenarios. When line costs are zero, we achieve the optimal approximation ratio of $1 - \frac{1}{e}$, assuming $P \neq NP$. For instances with small line costs, the algorithm attains an approximation ratio of $1 - \frac{1}{e} - \eta$. In the most general case, we obtain an approximation ratio of $\frac{1}{2} - \frac{1}{2e} - \eta$. Additionally, we develop an approach ensuring a ratio of $1 - \frac{1}{e} - \eta$ while limiting resource overuse to at most $\tau$ units, where $\eta$ and $\tau$ are arbitrarily small constants.
  To demonstrate real-world applicability, we modify one of our algorithms to improve practical performance while maintaining a level of theoretical guarantees, and validate it using numerical simulations on real-world data. Results show that our algorithm produces high-quality solutions efficiently, outperforming commercial solvers on challenging instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03327v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyi Jiang, Igor Averbakh, Samitha Samaranayake</dc:creator>
    </item>
    <item>
      <title>Extended formulations for the integer hull of strictly $\Delta$-modular cographic polyhedral cones</title>
      <link>https://arxiv.org/abs/2311.06017</link>
      <description>arXiv:2311.06017v3 Announce Type: replace 
Abstract: Conforti et al. give a compact extended formulation for a class of bimodular-constrained integer programs, namely those that model the stable set polytope of a graph with no disjoint odd cycles. We extend their techniques to design compact extended formulations for the integer hull of translated polyhedral cones whose constraint matrix is strictly $\Delta$-modular and has rows that represent a cographic matroid. Our work generalizes the important special case from Conforti et al. concerning $4$-connected graphs with odd cycle transversal number at least $4$. We also discuss the necessity of our assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06017v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Paat, Zach Walsh, Luze Xu</dc:creator>
    </item>
    <item>
      <title>Anisotropic Proximal Point Algorithm</title>
      <link>https://arxiv.org/abs/2312.09834</link>
      <description>arXiv:2312.09834v3 Announce Type: replace 
Abstract: In this paper we study a nonlinear dual space preconditioning approach for the relaxed Proximal Point Algorithm (PPA) with application to monotone inclusions, called anisotropic PPA. The algorithm is an instance of Luque's nonlinear PPA wherein the nonlinear preconditioner is chosen as the gradient of a Legendre convex function. Since the preconditioned operator is nonmonotone in general, convergence cannot be shown using standard arguments, unless the preconditioner exhibits isotropy (preserves directions) as in existing literature. To address the broader applicability we show convergence along subsequences invoking a Bregman version of Fej\`er-monotonicity in the dual space. Via a nonlinear generalization of Moreau's decomposition for operators, we provide a dual interpretation of the algorithm in terms of a forward iteration applied to a $D$-firmly nonexpansive mapping which involves the Bregman resolvent. For a suitable preconditioner, convergence rates of arbitrary order are derived under a mild H\"older growth condition. Finally, we discuss an anisotropic generalization of the proximal augmented Lagrangian method obtained via the propsed scheme. This has strong connections to Rockafellar's generalized and sharp Lagrangian functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09834v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Higher-order Riemannian spline interpolation problems: a unified approach by gradient flows</title>
      <link>https://arxiv.org/abs/2312.10513</link>
      <description>arXiv:2312.10513v5 Announce Type: replace 
Abstract: This paper addresses the problems of spline interpolation on smooth Riemannian manifolds, with or without the inclusion of least-squares fitting. Our unified approach utilizes gradient flows for successively connected curves or networks, providing a novel framework for tackling these challenges. This method notably extends to the variational spline interpolation problem on Lie groups, which is frequently encountered in mechanical optimal control theory. As a result, our work contributes to both geometric control theory and statistical shape data analysis. We rigorously prove the existence of global solutions in H\"{o}lder spaces for the gradient flow and demonstrate that the asymptotic limits of these solutions validate the existence of solutions to the variational spline interpolation problem. This constructive proof also offers insights into potential numerical schemes for finding such solutions, reinforcing the practical applicability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10513v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chun-Chi Lin, Dung The Tran</dc:creator>
    </item>
    <item>
      <title>Deep Backward and Galerkin Methods for the Finite State Master Equation</title>
      <link>https://arxiv.org/abs/2403.04975</link>
      <description>arXiv:2403.04975v2 Announce Type: replace 
Abstract: This paper proposes and analyzes two neural network methods to solve the master equation for finite-state mean field games (MFGs). Solving MFGs provides approximate Nash equilibria for stochastic, differential games with finite but large populations of agents. The master equation is a partial differential equation (PDE) whose solution characterizes MFG equilibria for any possible initial distribution. The first method we propose relies on backward induction in a time component while the second method directly tackles the PDE without discretizing time. For both approaches, we prove two types of results: there exist neural networks that make the algorithms' loss functions arbitrarily small, and conversely, if the losses are small, then the neural networks are good approximations of the master equation's solution. We conclude the paper with numerical experiments on benchmark problems from the literature up to dimension 15, and a comparison with solutions computed by a classical method for fixed initial distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04975v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Cohen, Mathieu Lauri\`ere, Ethan Zell</dc:creator>
    </item>
    <item>
      <title>Optimal Control for Linear Systems with L1-norm cost</title>
      <link>https://arxiv.org/abs/2404.07913</link>
      <description>arXiv:2404.07913v2 Announce Type: replace 
Abstract: We study L 1 -optimal stabilization of linear systems with finite and infinite horizons. Main results concern the existence, uniqueness and structure of optimal solutions, and the robustness of optimal cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07913v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Agrachev, Bettina Kazandjian</dc:creator>
    </item>
    <item>
      <title>Optimal Interventions in Coupled-Activity Network Games: Application to Sustainable Forestry</title>
      <link>https://arxiv.org/abs/2404.13662</link>
      <description>arXiv:2404.13662v3 Announce Type: replace 
Abstract: We address the challenge of promoting sustainable practices in production forests managed by strategic entities (agents) that harvest agricultural commodities under concession agreements. These entities engage in activities that either follow sustainable production practices or expand into protected forests for agricultural growth, which leads to unsustainable production. Our study uses a network game model to design optimal pricing policies that incentivize sustainability and discourage environmentally harmful practices. Specifically, we model interactions between agents, capturing both intra-activity (within a single production activity) and cross-activity (between sustainable and unsustainable practices) influences on agent behavior. We solve the problem of maximizing welfare while adhering to budgetary and environmental constraints - particularly, limiting the aggregate level of unsustainable effort across all agents. Although this problem is NP-hard in general, we derive closed-form solutions for various realistic scenarios, including cases with regionally uniform pricing and the use of sustainability premiums or penalties. Remarkably, we find that it is possible to achieve both welfare improvement and reduction in unsustainable practices without reducing any agent's utility, even when there is no external budget for increasing premiums. We introduce a novel node centrality measure to identify agents whose decisions most influence aggregate unsustainable effort. Empirical validation confirms our theoretical findings, offering actionable insights for policymakers aiming to promote sustainable resource management in agricultural commodity markets. Our work has broader implications for addressing sustainability challenges in the presence of network effects, offering a framework for designing incentive structures that align economic objectives with environmental stewardship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13662v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Parasnis, Saurabh Amin</dc:creator>
    </item>
    <item>
      <title>Subgradient Selection Convergence Implies Uniform Subdifferential Set Convergence: And Other Tight Convergences Rates in Stochastic Convex Composite Minimization</title>
      <link>https://arxiv.org/abs/2405.10289</link>
      <description>arXiv:2405.10289v4 Announce Type: replace 
Abstract: In nonsmooth, nonconvex stochastic optimization, understanding the uniform convergence of subdifferential mappings is crucial for analyzing stationary points of sample average approximations of risk as they approach the population risk. Yet, characterizing this convergence remains a fundamental challenge. This work introduces a novel perspective by connecting the uniform convergence of subdifferential mappings to that of subgradient mappings as empirical risk converges to the population risk. We prove that, for stochastic weakly-convex objectives, and within any open set, a uniform bound on the convergence of subgradients -- chosen arbitrarily from the corresponding subdifferential sets -- translates to a uniform bound on the convergence of the subdifferential sets themselves, measured by the Hausdorff metric. Using this technique, we derive uniform convergence rates for subdifferential sets of stochastic convex-composite objectives. Our results do not rely on key distributional assumptions in the literature, such as the continuous differentiability of the population objective, yet still provide tight convergence rates. These guarantees lead to new insights into the nonsmooth landscapes of such objectives within finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10289v4</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Ruan</dc:creator>
    </item>
    <item>
      <title>A Single-Loop Stochastic Proximal Quasi-Newton Method for Large-Scale Nonsmooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2409.16971</link>
      <description>arXiv:2409.16971v2 Announce Type: replace 
Abstract: We propose a new stochastic proximal quasi-Newton method for minimizing the sum of two convex functions in the particular context that one of the functions is the average of a large number of smooth functions and the other one is nonsmooth. The new method integrates a simple single-loop SVRG (L-SVRG) technique for sampling the gradient and a stochastic limited-memory BFGS (L-BFGS) scheme for approximating the Hessian of the smooth function components. The globally linear convergence rate of the new method is proved under mild assumptions. It is also shown that the new method covers a proximal variant of the L-SVRG as a special case, and it allows for various generalizations through the integration with other variance reduction methods. For example, the L-SVRG can be replaced with the SAGA or SEGA in the proposed new method and thus other new stochastic proximal quasi-Newton methods with rigorously guaranteed convergence can be proposed accordingly. Moreover, we meticulously analyze the resulting nonsmooth subproblem at each iteration and utilize a compact representation of the L-BFGS matrix with the storage of some auxiliary matrices. As a result, we propose a very efficient and easily implementable semismooth Newton solver for solving the involved subproblems, whose arithmetic operation per iteration is merely order of $O(d)$, where d denotes the dimensionality of the problem. With this efficient inner solver, the new method performs well and its numerical efficiency is validated through extensive experiments on a regularized logistic regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16971v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongcun Song, Zimeng Wang, Xiaoming Yuan, Hangrui Yue</dc:creator>
    </item>
    <item>
      <title>A mean field Jacobi process for modeling sustainable tourism</title>
      <link>https://arxiv.org/abs/2409.20347</link>
      <description>arXiv:2409.20347v2 Announce Type: replace 
Abstract: A mean field Jacobi process governing the dynamics of the travel demand of agents is formulated and its application to sustainable tourism is investigated both mathematically and computationally. The bounded nature of the Jacobi diffusion process enables the categorization of tourism state with sustainable tourism state corresponding to an internal solution and overtourism state to a boundary solution. A stochastic control framework is introduced to design sustainable tourism under uncertainty, incorporating model distortion conditions owing to misspecification. The control problem is reduced to solving the optimality system of a stationary mean field game whose closed-form solution is derived under certain conditions. The optimality system can be computed numerically using the finite difference method under more general conditions. We present demonstrative examples of the mean field Jacobi process for different parameter values, illustrating both sustainable tourism and overtourism cases. Our findings suggest that the sustainable tourism state cannot be realized if the fluctuation or model misspecification is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20347v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>Stability and Performance Analysis on Self-dual Cones</title>
      <link>https://arxiv.org/abs/2411.12100</link>
      <description>arXiv:2411.12100v2 Announce Type: replace 
Abstract: In this paper, we consider nonsymmetric solutions to certain Lyapunov and Riccati equations and inequalities with coefficient matrices corresponding to cone-preserving dynamical systems. Most results presented here appear to be novel even in the special case of positive systems. First, we provide a simple eigenvalue criterion for a Sylvester equation to admit a cone-preserving solution. For a single system preserving a self-dual cone, this reduces to stability. Further, we provide a set of conditions equivalent to testing a given H-infinity norm bound, as in the bounded real lemma. These feature the stability of a coefficient matrix similar to the Hamiltonian, a solution to two conic inequalities, and a stabilizing cone-preserving solution to a nonsymmetric Riccati equation. Finally, we show that the H-infinity norm is attained at zero frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12100v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emil Vladu</dc:creator>
    </item>
    <item>
      <title>A Cone-preserving Solution to a Nonsymmetric Riccati Equation</title>
      <link>https://arxiv.org/abs/2411.14470</link>
      <description>arXiv:2411.14470v2 Announce Type: replace 
Abstract: In this paper, we provide the following simple equivalent condition for a nonsymmetric Algebraic Riccati Equation to admit a stabilizing cone-preserving solution: an associated coefficient matrix must be stable. The result holds under the assumption that said matrix be cross-positive on a proper cone, and it both extends and completes a corresponding sufficient condition for nonnegative matrices in the literature. Further, key to showing the above is the following result which we also provide: in order for a monotonically increasing sequence of cone-preserving matrices to converge, it is sufficient to be bounded above in a single vectorial direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14470v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emil Vladu, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Sparse Polynomial Matrix Optimization</title>
      <link>https://arxiv.org/abs/2411.15479</link>
      <description>arXiv:2411.15479v2 Announce Type: replace 
Abstract: A polynomial matrix inequality is a statement that a symmetric polynomial matrix is positive semidefinite over a given constraint set. Polynomial matrix optimization concerns minimizing the smallest eigenvalue of a symmetric polynomial matrix subject to a tuple of polynomial matrix inequalities. This work explores the use of sparsity methods in reducing the complexity of sum-of-squares based methods in verifying polynomial matrix inequalities or solving polynomial matrix optimization. In the unconstrained setting, Newton polytopes can be employed to sparsify the monomial basis, resulting in smaller semidefinite programs. In the general setting, we show how to exploit different types of sparsity (term sparsity, correlative sparsity, matrix sparsity) encoded in polynomial matrices to derive sparse semidefinite programming relaxations for polynomial matrix optimization. For term sparsity, one intriguing phenomenon is that the related block structures do not necessarily converge to the one determined by sign symmetries, which is significantly distinguished from the scalar case. For correlative sparsity, unlike the scalar case, we provide a counterexample showing that asymptotic convergence does not hold under the Archimedean condition and the running intersection property. By employing the theory of matrix-valued measures, we establish several results on detecting global optimality and retrieving optimal solutions under correlative sparsity. The effectiveness of sparsity methods on reducing computational complexity is demonstrated on various examples of polynomial matrix optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15479v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared Miller, Jie Wang, Feng Guo</dc:creator>
    </item>
    <item>
      <title>Primal-dual proximal bundle and conditional gradient methods for convex problems</title>
      <link>https://arxiv.org/abs/2412.00585</link>
      <description>arXiv:2412.00585v2 Announce Type: replace 
Abstract: This paper studies the primal-dual convergence and iteration-complexity of proximal bundle methods for solving nonsmooth problems with convex structures. More specifically, we develop a family of primal-dual proximal bundle methods for solving convex nonsmooth composite optimization problems and establish the iteration-complexity in terms of a primal-dual gap. We also propose a class of proximal bundle methods for solving convex-concave nonsmooth composite saddle-point problems and establish the iteration-complexity to find an approximate saddle-point. This paper places special emphasis on the primal-dual perspective of the proximal bundle method. In particular, we discover an interesting duality between the conditional gradient method and the cutting-plane scheme used within the proximal bundle method. Leveraging this duality, we further develop novel variants of both the conditional gradient method and the cutting-plane scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00585v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Solving Monge problem by Hilbert space embeddings of probability measures</title>
      <link>https://arxiv.org/abs/2412.03478</link>
      <description>arXiv:2412.03478v2 Announce Type: replace 
Abstract: We propose deep learning methods for classical Monge's optimal mass transportation problems, where where the distribution constraint is treated as penalty terms defined by the maximum mean discrepancy in the theory of Hilbert space embeddings of probability measures. We prove that the transport maps given by the proposed methods converge to optimal transport maps in the problem with $L^2$ cost. Several numerical experiments validate our methods. In particular, we show that our methods are applicable to large-scale Monge problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03478v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takafumi Saito, Yumiharu Nakano</dc:creator>
    </item>
    <item>
      <title>Global Optimization with A Power-Transformed Objective and Gaussian Smoothing</title>
      <link>https://arxiv.org/abs/2412.05204</link>
      <description>arXiv:2412.05204v2 Announce Type: replace 
Abstract: We propose a novel method that solves global optimization problems in two steps: (1) perform a (exponential) power-$N$ transformation to the not-necessarily differentiable objective function $f$ and get $f_N$, and (2) optimize the Gaussian-smoothed $f_N$ with stochastic approximations. Under mild conditions on $f$, for any $\delta&gt;0$, we prove that with a sufficiently large power $N_\delta$, this method converges to a solution in the $\delta$-neighborhood of $f$'s global optimum point. The convergence rate is $O(d^2\sigma^4\varepsilon^{-2})$, which is faster than both the standard and single-loop homotopy methods if $\sigma$ is pre-selected to be in $(0,1)$. In most of the experiments performed, our method produces better solutions than other algorithms that also apply smoothing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05204v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Xu</dc:creator>
    </item>
    <item>
      <title>A Two-Stage Pontryagin-Guided Neural Policy Optimization Framework for Merton's Portfolio Problem</title>
      <link>https://arxiv.org/abs/2412.13101</link>
      <description>arXiv:2412.13101v2 Announce Type: replace 
Abstract: We present a two-stage neural policy optimization framework for Merton's portfolio optimization problem that is rigorously aligned with Pontryagin's Maximum Principle (PMP). In Stage 1, we employ a discrete-time, backpropagation-through-time (BPTT)-based gradient scheme that converges to a stationary point of the parameterized control policy. Subsequently, in Stage 2, we refine this policy via a discrete-time, PMP-guided procedure, proven to converge to the Pontryagin-optimal solution. Central to our method is the approximation of adjoint variables from a policy-fixed backward stochastic differential equation (BSDE), yielding parameter gradients consistent with the PMP framework-all without explicitly solving the PMP-derived BSDE. As the policy parameters are iteratively updated, both the suboptimal adjoint variables and the neural network policies converge almost surely to their PMP-optimal counterparts. This ensures that the final learned policy is not only numerically robust but also provably optimal in the continuous-time sense. Our approach thus provides a theoretically grounded yet practically implementable solution, bridging modern deep learning techniques and classical optimal control theory for complex stochastic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13101v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonggyu Huh</dc:creator>
    </item>
    <item>
      <title>Augmenting Subspace Optimization Methods with Linear Bandits</title>
      <link>https://arxiv.org/abs/2412.14278</link>
      <description>arXiv:2412.14278v2 Announce Type: replace 
Abstract: We consider the framework of methods for unconstrained minimization that are, in each iteration, restricted to a model that is only a valid approximation to the objective function on some affine subspace containing an incumbent point. These methods are of practical interest in computational settings where derivative information is either expensive or impossible to obtain. Recent attention has been paid in the literature to employing randomized matrix sketching for generating the affine subspaces within this framework.
  We consider a relatively straightforward, deterministic augmentation of such a generic subspace optimization method. In particular, we consider a sequential optimization framework where actions consist of one-dimensional linear subspaces and rewards consist of (approximations to) the magnitudes of directional derivatives computed in the direction of the action subspace. Reward maximization in this context is consistent with maximizing lower bounds on descent guaranteed by first-order Taylor models. This sequential optimization problem can be analyzed through the lens of dynamic regret. We modify an existing linear upper confidence bound (UCB) bandit method and prove sublinear dynamic regret in the subspace optimization setting. We demonstrate the efficacy of employing this linear UCB method in a setting where forward-mode algorithmic differentiation can provide directional derivatives in arbitrary directions and in a derivative-free setting. For the derivative-free setting, we propose SS-POUNDers, an extension of the derivative-free optimization method POUNDers that employs the linear UCB mechanism to identify promising subspaces. Our numerical experiments suggest a preference, in either computational setting, for employing a linear UCB mechanism within a subspace optimization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14278v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matt Menickelly</dc:creator>
    </item>
    <item>
      <title>Provably Convergent Plug-and-play Proximal Block Coordinate Descent Method for Hyperspectral Anomaly Detection</title>
      <link>https://arxiv.org/abs/2412.14824</link>
      <description>arXiv:2412.14824v2 Announce Type: replace 
Abstract: Hyperspectral anomaly detection refers to identifying pixels in the hyperspectral images that have spectral characteristics significantly different from the background. In this paper, we introduce a novel model that represents the background information using a low-rank representation. We integrate an implicit proximal denoiser prior, associated with a deep learning based denoiser, within a plug-and-play (PnP) framework to effectively remove noise from the eigenimages linked to the low-rank representation. Anomalies are characterized using a generalized group sparsity measure, denoted as $\|\cdot\|_{2,\psi}$. To solve the resulting orthogonal constrained nonconvex nonsmooth optimization problem, we develop a PnP-proximal block coordinate descent (PnP-PBCD) method, where the eigenimages are updated using a proximal denoiser within the PnP framework. We prove that any accumulation point of the sequence generated by the PnP-PBCD method is a stationary point. We evaluate the effectiveness of the PnP-PBCD method on hyperspectral anomaly detection in scenarios with and without Gaussian noise contamination. The results demonstrate that the proposed method can effectively detect anomalous objects, outperforming the competing methods that may mistakenly identify noise as anomalies or misidentify the anomalous objects due to noise interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14824v2</guid>
      <category>math.OC</category>
      <category>eess.IV</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Liu, Shijie YU</dc:creator>
    </item>
    <item>
      <title>Global Convergence of SGD On Two Layer Neural Nets</title>
      <link>https://arxiv.org/abs/2210.11452</link>
      <description>arXiv:2210.11452v3 Announce Type: replace-cross 
Abstract: In this note, we consider appropriately regularized $\ell_2-$empirical risk of depth $2$ nets with any number of gates and show bounds on how the empirical loss evolves for SGD iterates on it -- for arbitrary data and if the activation is adequately smooth and bounded like sigmoid and tanh. This in turn leads to a proof of global convergence of SGD for a special class of initializations. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized loss functions on constant-sized neural nets which are "Villani functions" and thus be able to build on recent progress with analyzing SGD on such objectives. Most critically the amount of regularization required for our analysis is independent of the size of the net.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11452v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/imaiai/iaae035</arxiv:DOI>
      <dc:creator>Pulkit Gopalani, Anirbit Mukherjee</dc:creator>
    </item>
    <item>
      <title>Continuous Convexity Measures</title>
      <link>https://arxiv.org/abs/2306.02041</link>
      <description>arXiv:2306.02041v2 Announce Type: replace-cross 
Abstract: Methods for measuring convexity defects of compacts in R^n abound. However, none of the those measures seems to take into account continuity. Continuity in convexity measure is essential for optimization, stability analysis, global optimality, convergence analysis, and accurate modelling as it ensures robustness and facilitates the development of efficient algorithms for solving convex optimization problems. This paper revisits the axioms underlying convexity measures by enriching them with a continuity hypothesis in Hausdorff's sense. Having provided the concept's theoretical grounds we state a theorem underlining the necessity of restricting ourselves to non-point compacts. We then construct a continuous convexity measure and compare it to existing measures. Importante note : This work is not a research article. It is an undergraduate project undertaken as part of a computer science course at \'Ecole normale sup\'erieure. It should therefore not be considered as a peer reviewed research paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02041v2</guid>
      <category>math.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abel Douzal, Ferdinand Jacob\'e de Naurois</dc:creator>
    </item>
    <item>
      <title>The $\omega$-Condition Number: Applications to Optimal Preconditioning and Low Rank Generalized Jacobian Updating</title>
      <link>https://arxiv.org/abs/2308.13195</link>
      <description>arXiv:2308.13195v3 Announce Type: replace-cross 
Abstract: Preconditioning is essential in iterative methods for solving linear systems. It is also the implicit objective in updating approximations of Jacobians in optimization methods, e.g.,in quasi-Newton methods. Motivated by the latter, we study a nonclassic matrix condition number, the $\omega$-condition number, $\omega$ for short. $\omega$ is the ratio of the arithmetic and geometric means of the singular values, rather than largest and smallest. Moreover, unlike the latter classical $\kappa$ condition number, $\omega$ is not invariant under inversion, an important point that allows one to recall that it is the conditioning of the inverse that is important. Our study is in the context of optimal conditioning for: (i) low rank updating of generalized Jacobians arising in the context of nonsmooth Newton methods; and (ii) iterative methods for linear systems; (iia) clustering of eigenvalues; (iib) convergence rates; and (iic) estimating the actual condition of a linear system. We emphasize that the simple functions in $\omega$ allow one to exploit optimality conditions and derive explicit formulae for $\omega$-optimal preconditioners of special structure. Connections to partial Cholesky type sparse preconditioners are made that modify the iterates of Cholesky decomposition by including the entire diagonal at each iteration. Our results confirm the efficacy of using the $\omega$-condition number compared to the classical $\kappa$-condition number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13195v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woosuk L. Jung, David Torregrosa-Bel\'en, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>Risk-sensitive Markov Decision Process and Learning under General Utility Functions</title>
      <link>https://arxiv.org/abs/2311.13589</link>
      <description>arXiv:2311.13589v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) has gained substantial attention across diverse application domains and theoretical investigations. Existing literature on RL theory largely focuses on risk-neutral settings where the decision-maker learns to maximize the expected cumulative reward. However, in practical scenarios such as portfolio management and e-commerce recommendations, decision-makers often persist in heterogeneous risk preferences subject to outcome uncertainties, which can not be well-captured by the risk-neural framework. Incorporating these preferences can be approached through utility theory, yet the development of risk-sensitive RL under general utility functions remains an open question for theoretical exploration.
  In this paper, we consider a scenario where the decision-maker seeks to optimize a general utility function of the cumulative reward in the framework of a Markov decision process (MDP). To facilitate the Dynamic Programming Principle and Bellman equation, we enlarge the state space with an additional dimension that accounts for the cumulative reward. We propose a discretized approximation scheme to the MDP under enlarged state space, which is tractable and key for algorithmic design. We then propose a modified value iteration algorithm that employs an epsilon-covering over the space of cumulative reward. When a simulator is accessible, our algorithm efficiently learns a near-optimal policy with guaranteed sample complexity. In the absence of a simulator, our algorithm, designed with an upper-confidence-bound exploration approach, identifies a near-optimal policy while ensuring a guaranteed regret bound. Finally, we establish a novel theoretical regret lower bound for the risk-sensitive setting, and show that the regret of our algorithm matches this lower bound up to a small polynomial factor</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13589v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhengqi Wu, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery</title>
      <link>https://arxiv.org/abs/2401.02592</link>
      <description>arXiv:2401.02592v2 Announce Type: replace-cross 
Abstract: In this paper, we provide the first convergence guarantee for the factorization approach. Specifically, to avoid the scaling ambiguity and to facilitate theoretical analysis, we optimize over the so-called left-orthogonal TT format which enforces orthonormality among most of the factors. To ensure the orthonormal structure, we utilize the Riemannian gradient descent (RGD) for optimizing those factors over the Stiefel manifold. We first delve into the TT factorization problem and establish the local linear convergence of RGD. Notably, the rate of convergence only experiences a linear decline as the tensor order increases. We then study the sensing problem that aims to recover a TT format tensor from linear measurements. Assuming the sensing operator satisfies the restricted isometry property (RIP), we show that with a proper initialization, which could be obtained through spectral initialization, RGD also converges to the ground-truth tensor at a linear rate. Furthermore, we expand our analysis to encompass scenarios involving Gaussian noise in the measurements. We prove that RGD can reliably recover the ground truth at a linear rate, with the recovery error exhibiting only polynomial growth in relation to the tensor order. We conduct various experiments to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02592v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Michael B. Wakin, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Instrumental Variables Estimation</title>
      <link>https://arxiv.org/abs/2410.15634</link>
      <description>arXiv:2410.15634v2 Announce Type: replace-cross 
Abstract: Instrumental variables (IV) estimation is a fundamental method in econometrics and statistics for estimating causal effects in the presence of unobserved confounding. However, challenges such as untestable model assumptions and poor finite sample properties have undermined its reliability in practice. Viewing common issues in IV estimation as distributional uncertainties, we propose DRIVE, a distributionally robust IV estimation method. We show that DRIVE minimizes a square root variant of ridge regularized two stage least squares (TSLS) objective when the ambiguity set is based on a Wasserstein distance. In addition, we develop a novel asymptotic theory for this estimator, showing that it achieves consistency without requiring the regularization parameter to vanish. This novel property ensures that the estimator is robust to distributional uncertainties that persist in large samples. We further derive the asymptotic distribution of Wasserstein DRIVE and propose data-driven procedures to select the regularization parameter based on theoretical results. Simulation studies demonstrate the superior finite sample performance of Wasserstein DRIVE in terms of estimation error and out-of-sample prediction. Due to its regularization and robustness properties, Wasserstein DRIVE presents an appealing option when the practitioner is uncertain about model assumptions or distributional shifts in data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15634v2</guid>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaonan Qu, Yongchan Kwon</dc:creator>
    </item>
    <item>
      <title>Safe Paths and Sequences for Scalable ILPs in RNA Transcript Assembly Problems</title>
      <link>https://arxiv.org/abs/2411.03871</link>
      <description>arXiv:2411.03871v2 Announce Type: replace-cross 
Abstract: A common step at the core of many RNA transcript assembly tools is to find a set of weighted paths that best explain the weights of a DAG. While such problems easily become NP-hard, scalable solvers exist only for a basic error-free version of this problem, namely minimally decomposing a network flow into weighted paths.
  The main result of this paper is to show that we can achieve speedups of two orders of magnitude also for path-finding problems in the realistic setting (i.e., the weights do not induce a flow). We obtain these by employing the safety information that is encoded in the graph structure inside Integer Linear Programming (ILP) solvers for these problems. We first characterize the paths that appear in all path covers of the DAG, generalizing a graph reduction commonly used in the error-free setting (e.g. by Kloster et al. [ALENEX~2018]). Secondly, following the work of Ma, Zheng and Kingsford [RECOMB 2021], we characterize the \emph{sequences} of arcs that appear in all path covers of the DAG.
  We experiment with a path-finding ILP model (least squares) and with a more recent and accurate one. We use a variety of datasets originally created by Shao and Kingsford [TCBB, 2017], as well as graphs built from sequencing reads by the state-of-the-art tool for long-read transcript discovery, IsoQuant [Prjibelski et al., Nat.~Biotechnology~2023]. The ILPs armed with safe paths or sequences exhibit significant speed-ups over the original ones. On graphs with a large width, average speed-ups are in the range $50-160\times$ in the latter ILP model and in the range $100-1000\times$ in the least squares model.
  Our scaling techniques apply to any ILP whose solution paths are a path cover of the arcs of the DAG. As such, they can become a scalable building block of practical RNA transcript assembly tools, avoiding heuristic trade-offs currently needed on complex graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03871v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Sena, Alexandru I. Tomescu</dc:creator>
    </item>
  </channel>
</rss>
