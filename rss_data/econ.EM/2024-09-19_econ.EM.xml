<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Sep 2024 04:01:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Way to Synthetic Triple Difference</title>
      <link>https://arxiv.org/abs/2409.12353</link>
      <description>arXiv:2409.12353v1 Announce Type: new 
Abstract: This paper introduces a novel approach that combines synthetic control with triple difference to address violations of the parallel trends assumption. While synthetic control has been widely applied to improve causal estimates in difference-in-differences (DID) frameworks, its use in triple-difference models has been underexplored. By transforming triple difference into a DID structure, this paper extends the applicability of synthetic control to a triple-difference framework, enabling more robust estimates when parallel trends are violated across multiple dimensions. The empirical example focuses on China's "4+7 Cities" Centralized Drug Procurement pilot program. Based on the proposed procedure for synthetic triple difference, I find that the program can promote pharmaceutical innovation in terms of the number of patent applications even based on the recommended clustered standard error. This method contributes to improving causal inference in policy evaluations and offers a valuable tool for researchers dealing with heterogeneous treatment effects across subgroups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12353v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Castiel Chen Zhuang</dc:creator>
    </item>
    <item>
      <title>Parameters on the boundary in predictive regression</title>
      <link>https://arxiv.org/abs/2409.12611</link>
      <description>arXiv:2409.12611v1 Announce Type: new 
Abstract: We consider bootstrap inference in predictive (or Granger-causality) regressions when the parameter of interest may lie on the boundary of the parameter space, here defined by means of a smooth inequality constraint. For instance, this situation occurs when the definition of the parameter space allows for the cases of either no predictability or sign-restricted predictability. We show that in this context constrained estimation gives rise to bootstrap statistics whose limit distribution is, in general, random, and thus distinct from the limit null distribution of the original statistics of interest. This is due to both (i) the possible location of the true parameter vector on the boundary of the parameter space, and (ii) the possible non-stationarity of the posited predicting (resp. Granger-causing) variable. We discuss a modification of the standard fixed-regressor wild bootstrap scheme where the bootstrap parameter space is shifted by a data-dependent function in order to eliminate the portion of limiting bootstrap randomness attributable to the boundary, and prove validity of the associated bootstrap inference under non-stationarity of the predicting variable as the only remaining source of limiting bootstrap randomness. Our approach, which is initially presented in a simple location model, has bearing on inference in parameter-on-the-boundary situations beyond the predictive regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12611v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giuseppe Cavaliere, Iliyan Georgiev, Edoardo Zanelli</dc:creator>
    </item>
    <item>
      <title>Testing for equal predictive accuracy with strong dependence</title>
      <link>https://arxiv.org/abs/2409.12662</link>
      <description>arXiv:2409.12662v1 Announce Type: new 
Abstract: We analyse the properties of the Diebold and Mariano (1995) test in the presence of autocorrelation in the loss differential. We show that the power of the Diebold and Mariano (1995) test decreases as the dependence increases, making it more difficult to obtain statistically significant evidence of superior predictive ability against less accurate benchmarks. We also find that, after a certain threshold, the test has no power and the correct null hypothesis is spuriously rejected. Taken together, these results caution to seriously consider the dependence properties of the loss differential before the application of the Diebold and Mariano (1995) test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12662v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Coroneo, Fabrizio Iacone</dc:creator>
    </item>
  </channel>
</rss>
