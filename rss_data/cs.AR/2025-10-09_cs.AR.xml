<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 01:54:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On-Package Memory with Universal Chiplet Interconnect Express (UCIe): A Low Power, High Bandwidth, Low Latency and Low Cost Approach</title>
      <link>https://arxiv.org/abs/2510.06513</link>
      <description>arXiv:2510.06513v1 Announce Type: new 
Abstract: Emerging computing applications such as Artificial Intelligence (AI) are facing a memory wall with existing on-package memory solutions that are unable to meet the power-efficient bandwidth demands. We propose to enhance UCIe with memory semantics to deliver power-efficient bandwidth and cost-effective on-package memory solutions applicable across the entire computing continuum. We propose approaches by reusing existing LPDDR6 and HBM memory through a logic die that connects to the SoC using UCIe. We also propose an approach where the DRAM die natively supports UCIe instead of the LPDDR6 bus interface. Our approaches result in significantly higher bandwidth density (up to 10x), lower latency (up to 3x), lower power (up to 3x), and lower cost compared to existing HBM4 and LPDDR on-package memory solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06513v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>2025 Hot Interconnects</arxiv:journal_reference>
      <dc:creator>Debendra Das Sharma, Swadesh Choudhary, Peter Onufryk, Rob Pelt</dc:creator>
    </item>
    <item>
      <title>RTGS: Real-Time 3D Gaussian Splatting SLAM via Multi-Level Redundancy Reduction</title>
      <link>https://arxiv.org/abs/2510.06644</link>
      <description>arXiv:2510.06644v2 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) based Simultaneous Localization and Mapping (SLAM) systems can largely benefit from 3DGS's state-of-the-art rendering efficiency and accuracy, but have not yet been adopted in resource-constrained edge devices due to insufficient speed. Addressing this, we identify notable redundancies across the SLAM pipeline for acceleration. While conceptually straightforward, practical approaches are required to minimize the overhead associated with identifying and eliminating these redundancies. In response, we propose RTGS, an algorithm-hardware co-design framework that comprehensively reduces the redundancies for real-time 3DGS-SLAM on edge. To minimize the overhead, RTGS fully leverages the characteristics of the 3DGS-SLAM pipeline. On the algorithm side, we introduce (1) an adaptive Gaussian pruning step to remove the redundant Gaussians by reusing gradients computed during backpropagation; and (2) a dynamic downsampling technique that directly reuses the keyframe identification and alpha computing steps to eliminate redundant pixels. On the hardware side, we propose (1) a subtile-level streaming strategy and a pixel-level pairwise scheduling strategy that mitigates workload imbalance via a Workload Scheduling Unit (WSU) guided by previous iteration information; (2) a Rendering and Backpropagation (R&amp;B) Buffer that accelerates the rendering backpropagation by reusing intermediate data computed during rendering; and (3) a Gradient Merging Unit (GMU) to reduce intensive memory accesses caused by atomic operations while enabling pipelined aggregation. Integrated into an edge GPU, RTGS achieves real-time performance (&gt;= 30 FPS) on four datasets and three algorithms, with up to 82.5x energy efficiency over the baseline and negligible quality loss. Code is available at https://github.com/UMN-ZhaoLab/RTGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06644v2</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leshu Li, Jiayin Qin, Jie Peng, Zishen Wan, Huaizhi Qu, Ye Han, Pingqing Zheng, Hongsen Zhang, Yu Cao, Tianlong Chen, Yang Katie Zhao</dc:creator>
    </item>
    <item>
      <title>Hardware-Efficient CNNs: Interleaved Approximate FP32 Multipliers for Kernel Computation</title>
      <link>https://arxiv.org/abs/2510.06767</link>
      <description>arXiv:2510.06767v1 Announce Type: new 
Abstract: Single-precision floating point (FP32) data format, defined by the IEEE 754 standard, is widely employed in scientific computing, signal processing, and deep learning training, where precision is critical. However, FP32 multiplication is computationally expensive and requires complex hardware, especially for precisely handling mantissa multiplication. In practical applications like neural network inference, perfect accuracy is not always necessary, minor multiplication errors often have little impact on final accuracy. This enables trading precision for gains in area, power, and speed. This work focuses on CNN inference using approximate FP32 multipliers, where the mantissa multiplication is approximated by employing error-variant approximate compressors, that significantly reduce hardware cost. Furthermore, this work optimizes CNN performance by employing differently approximated FP32 multipliers and studying their impact when interleaved within the kernels across the convolutional layers. The placement and ordering of these approximate multipliers within each kernel are carefully optimized using the Non-dominated Sorting Genetic Algorithm-II, balancing the trade-off between accuracy and hardware efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06767v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bindu G Gowda (International Institute of Information Technology Bangalore), Yogesh Goyal (International Institute of Information Technology Bangalore), Yash Gupta (International Institute of Information Technology Bangalore), Madhav Rao (International Institute of Information Technology Bangalore)</dc:creator>
    </item>
    <item>
      <title>Cocoon: A System Architecture for Differentially Private Training with Correlated Noises</title>
      <link>https://arxiv.org/abs/2510.07304</link>
      <description>arXiv:2510.07304v1 Announce Type: new 
Abstract: Machine learning (ML) models memorize and leak training data, causing serious privacy issues to data owners. Training algorithms with differential privacy (DP), such as DP-SGD, have been gaining attention as a solution. However, DP-SGD adds a noise at each training iteration, which degrades the accuracy of the trained model. To improve accuracy, a new family of approaches adds carefully designed correlated noises, so that noises cancel out each other across iterations. We performed an extensive characterization study of these new mechanisms, for the first time to the best of our knowledge, and show they incur non-negligible overheads when the model is large or uses large embedding tables. Motivated by the analysis, we propose Cocoon, a hardware-software co-designed framework for efficient training with correlated noises. Cocoon accelerates models with embedding tables through pre-computing and storing correlated noises in a coalesced format (Cocoon-Emb), and supports large models through a custom near-memory processing device (Cocoon-NMP). On a real system with an FPGA-based NMP device prototype, Cocoon improves the performance by 2.33-10.82x(Cocoon-Emb) and 1.55-3.06x (Cocoon-NMP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07304v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Donghwan Kim, Xin Gu, Jinho Baek, Timothy Lo, Younghoon Min, Kwangsik Shin, Jongryool Kim, Jongse Park, Kiwan Maeng</dc:creator>
    </item>
    <item>
      <title>Evaluating Rapid Makespan Predictions for Heterogeneous Systems with Programmable Logic</title>
      <link>https://arxiv.org/abs/2510.06998</link>
      <description>arXiv:2510.06998v1 Announce Type: cross 
Abstract: Heterogeneous computing systems, which combine general-purpose processors with specialized accelerators, are increasingly important for optimizing the performance of modern applications. A central challenge is to decide which parts of an application should be executed on which accelerator or, more generally, how to map the tasks of an application to available devices. Predicting the impact of a change in a task mapping on the overall makespan is non-trivial. While there are very capable simulators, these generally require a full implementation of the tasks in question, which is particularly time-intensive for programmable logic. A promising alternative is to use a purely analytical function, which allows for very fast predictions, but abstracts significantly from reality. Bridging the gap between theory and practice poses a significant challenge to algorithm developers. This paper aims to aid in the development of rapid makespan prediction algorithms by providing a highly flexible evaluation framework for heterogeneous systems consisting of CPUs, GPUs and FPGAs, which is capable of collecting real-world makespan results based on abstract task graph descriptions. We analyze to what extent actual makespans can be predicted by existing analytical approaches. Furthermore, we present common challenges that arise from high-level characteristics such as data transfer overhead and device congestion in heterogeneous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06998v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Wilhelm, Franz Freitag, Max Tzschoppe, Thilo Pionteck</dc:creator>
    </item>
    <item>
      <title>From Neural Sensing to Stimulation: An Interdisciplinary Roadmap for Neurotechnology</title>
      <link>https://arxiv.org/abs/2510.07116</link>
      <description>arXiv:2510.07116v1 Announce Type: cross 
Abstract: Neurotechnologies are transforming how we measure, interpret, and modulate brain-body interactions, integrating real-time sensing, computation, and stimulation to enable precise physiological control. They hold transformative potential across clinical and non-clinical domains, from treating disorders to enhancing cognition and performance. Realizing this potential requires navigating complex, interdisciplinary challenges spanning neuroscience, materials science, device engineering, signal processing, computational modelling, and regulatory and ethical frameworks. This Perspective presents a strategic roadmap for neurotechnology development, created by early-career researchers, highlighting their role at the intersection of disciplines and their capacity to bridge traditional silos. We identify five cross-cutting trade-offs that constrain progress across functionality, scalability, adaptability, and translatability, and illustrate how technical domains influence their resolution. Rather than a domain-specific review, we focus on shared challenges and strategic opportunities that transcend disciplines. We propose a unified framework for collaborative innovation and education, highlight ethical and regulatory priorities, and outline a timeline for overcoming key bottlenecks. By aligning technical development with translational and societal needs, this roadmap aims to accelerate equitable, effective, and future-ready adaptive neurotechnologies, guiding coordinated efforts across the global research and innovation community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07116v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruben Ruiz-Mateos Serrano, Joe G Troughton, Nima Mirkhani, Natalia Martinez, Massimo Mariello, Jordan Tsigarides, Simon Williamson, Juan Sapriza, Ioana Susnoschi Luca, Antonio Dominguez-Alfaro, Estelle Cuttaz, Nicole Thompson, Sydney Swedick, Latifah Almulla, Amparo Guemes</dc:creator>
    </item>
    <item>
      <title>An opportunity to improve Data Center Efficiency: Optimizing the Server's Upgrade Cycle</title>
      <link>https://arxiv.org/abs/2510.05787</link>
      <description>arXiv:2510.05787v2 Announce Type: replace 
Abstract: This work aims to improve a data center's efficiency by optimizing the server upgrade plan: determine the optimal timing for replacing old servers with new ones. The opportunity presented by this approach is demonstrated through a study based on historical server data. The study establishes a significant opportunity to increase the QPS/(TCOxCO2) metric by formulating a global upgrade plan at the data center's design time covering its entire life cycle. This plan leverages information, such as server entry year, performance, and active power consumption for both existing and future servers. Our findings reveal that an optimal global upgrade plan, may involve upgrades at non fixed time periods and outperforms local upgrade plans. Local upgrade plans follow a fixed, equal-length cycle and make decisions based only on currently available server models. These local plans select the best available server at each upgrade cycle without accounting for future server releases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05787v2</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panagiota Nikolaou, Freddy Gabbay, Jawad Haj-Yahya, Yiannakis Sazeides</dc:creator>
    </item>
  </channel>
</rss>
