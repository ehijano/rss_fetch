<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Feb 2025 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dancing With Chains: Ideating Under Constraints With UIDEC in UI/UX Design</title>
      <link>https://arxiv.org/abs/2501.18748</link>
      <description>arXiv:2501.18748v1 Announce Type: new 
Abstract: UI/UX designers often work under constraints like brand identity, design norms, and industry guidelines. How these constraints impact designers' ideation and exploration processes should be addressed in creativity-support tools for design. Through an exploratory interview study, we identified three designer personas with varying views on having constraints in the ideation process, which guided the creation of UIDEC, a GenAI-powered tool for supporting creativity under constraints. UIDEC allows designers to specify project details, such as purpose, target audience, industry, and design styles, based on which it generates diverse design examples that adhere to these constraints, with minimal need to write prompts. In a user evaluation involving designers representing the identified personas, participants found UIDEC compatible with their existing ideation process and useful for creative inspiration, especially when starting new projects. Our work provides design implications to AI-powered tools that integrate constraints during UI/UX design ideation to support creativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18748v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713785</arxiv:DOI>
      <dc:creator>Atefeh Shokrizadeh, Boniface Bahati Tadjuidje, Shivam Kumar, Sohan Kamble, Jinghui Cheng</dc:creator>
    </item>
    <item>
      <title>Beyond Technological Usability: Exploratory Factor Analysis of the Comprehensive Assessment of Usability for Learning Technologies (CAUSLT) Scale</title>
      <link>https://arxiv.org/abs/2501.18754</link>
      <description>arXiv:2501.18754v1 Announce Type: new 
Abstract: Traditionally rooted in the domain of Human-Computer Interaction (HCI), usability has been primarily associated with the technological performance of a system's user interface. However, as learning technologies continue to advance, a pressing need exists to evaluate these tools from a broader perspective, encompassing not just technological but also pedagogical and sociocultural dimensions. The current paper delves into the multifaceted nature of usability in the context of Learning Design and Technology (LDT). We identified prevailing gaps in current usability research practices within LDT, notably the over-reliance on HCI-derived instruments that may not holistically capture the unique usability demands of learning technologies. To address these challenges, we embarked on the development and analysis of the Comprehensive Assessment of Usability Scale for Learning Technologies (CAUSLT). A total of 155 responses were collected and analyzed. Utilizing exploratory factor analysis, this study aimed to explore core constructs for the development of CAUSLT. Our findings underscore the importance and the critical need for a comprehensive usability evaluation framework tailored for learning technologies, setting the stage for more effective and user-centric educational tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18754v1</guid>
      <category>cs.HC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Lu, Matthew Schmidt, Jinnie Shin</dc:creator>
    </item>
    <item>
      <title>Vibr-eau: Emulating Fluid Behavior in Vessel Handling through Vibrotactile Actuators</title>
      <link>https://arxiv.org/abs/2501.18755</link>
      <description>arXiv:2501.18755v1 Announce Type: new 
Abstract: Existing methods of haptic feedback for virtual fluids are challenging to scale, lack durability for long-term rough use, and fail to fully capture the expressive haptic qualities of fluids. To overcome these limitations, we present Vibr-eau, a physical system designed to emulate the sensation of virtual fluids in vessels using vibrotactile actuators. Vibr-eau uses spatial and temporal vibrotactile feedback to create realistic haptic sensations within a 3D-printed vessel. When the users are in the virtual environment and interact with the physical vessel, vibration impulses are triggered and the user will feel like there is fluid in the vessel. We explore the impact of motor density, direct touch, and vibration strength on users' perception of virtual fluid sensations. User studies reveal that Vibr-eau effectively simulates dynamic weight shifts and fluid-like sensations, with participants reporting experiences closely resembling real-world interactions with fluids. Our findings contribute to the development of adaptable and scalable haptic applications for virtual fluids, providing insights into optimizing parameters for realistic and perceptually faithful simulated fluid experiences in VR environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18755v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Frank Wencheng Liu, Ryan Wirjadi, Yanjun Lyu, Shiling Dai, Byron Lahey, Assegid Kidane, Robert LiKamWa</dc:creator>
    </item>
    <item>
      <title>Pneutouch: Exploring the affordances and interactions of haptic inflatables through a wrist-worn interface</title>
      <link>https://arxiv.org/abs/2501.18764</link>
      <description>arXiv:2501.18764v1 Announce Type: new 
Abstract: Haptic sensations that align with virtual reality (VR) experiences have a profound impact on presence and enjoyment. There is potential to explore the dynamic capabilities of pneumatic inflatables to offer immersive sensations in virtual environments, including variations in shape, size, and stiffness. We introduce Pneutouch, an ungrounded and untethered wrist-worn device designed as a pneumatic haptic interface for VR interactions. Pneutouch's dynamic inflation ability enables programmable stiffness and shape change of haptic proxies. Additionally, multiple haptic proxies can be delivered into and out of the user's hand grasp. We describe the implementation of the Pneutouch device. We conducted user studies to demonstrate the affordances of pneumatic inflatables and assessed the device's efficacy in providing haptic feedback. With Pneutouch, our goal is to expand what can be touched in the virtual space and bring more immersion into virtual reality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18764v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Frank Wencheng Liu, Mason Manetta, Prasad Borkar, Byron Lahey, Assegid Kidane, Robert LiKamWa</dc:creator>
    </item>
    <item>
      <title>Beyond Automation: How UI/UX Designers Perceive AI as a Creative Partner in the Divergent Thinking Stages</title>
      <link>https://arxiv.org/abs/2501.18778</link>
      <description>arXiv:2501.18778v1 Announce Type: new 
Abstract: Divergent thinking activities, like research and ideation, are key drivers of innovation in UI/UX design. Existing research has explored AI's role in automating design tasks, but leaves a critical gap in understanding how AI specifically influences divergent thinking. To address this, we conducted interviews with 19 professional UI/UX designers, examining their use and perception of AI in these creative activities. We found that in this context, participants valued AI tools that offer greater control over ideation, facilitate collaboration, enhance efficiency to liberate creativity, and align with their visual habits. Our results indicated four key roles AI plays in supporting divergent thinking: aiding research, kick-starting creativity, generating design alternatives, and facilitating prototype exploration. Through this study, we provide insights into the evolving role of AI in the less-investigated area of divergent thinking in UI/UX design, offering recommendations for future AI tools that better support design innovation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18778v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713500</arxiv:DOI>
      <dc:creator>Abidullah Khan, Atefeh Shokrizadeh, Jinghui Cheng</dc:creator>
    </item>
    <item>
      <title>The Impact of AI on Jobs: HCI is Missing</title>
      <link>https://arxiv.org/abs/2501.18948</link>
      <description>arXiv:2501.18948v1 Announce Type: new 
Abstract: As artificial intelligence (AI) continues to reshape the workforce, its current trajectory raises pressing questions about its ultimate purpose. Why does job automation dominate the agenda, even at the expense of human agency and equity? This paper critiques the automation-centric paradigm, arguing that current reward structures -- focused on cost reduction rather than collaboration -- drive the overwhelming emphasis on task replacement in AI patents. Meanwhile, Human-Centered AI (HCAI) -- which envisions AI as a collaborator augmenting human capabilities and aligning with societal values -- remains a fugitive from the mainstream narrative. Despite its promise, HCAI has gone ``missing'', with little evidence of its principles translating into patents or real-world impact. To increase impact, actionable interventions are needed to disrupt existing incentive structures within the HCI community. We call for a shift in priorities to support translational research, foster cross-disciplinary collaboration, and promote metrics that reward tangible, real-world impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18948v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Constantinides, Daniele Quercia</dc:creator>
    </item>
    <item>
      <title>Direct On-Material Annotations for CNC Milling</title>
      <link>https://arxiv.org/abs/2501.18951</link>
      <description>arXiv:2501.18951v1 Announce Type: new 
Abstract: Creating custom artifacts with computer numerical control (CNC) milling machines typically requires mastery of complex computer-aided design (CAD) software. To eliminate this user barrier, we introduced Draw2Cut, a novel system that allows users to design and fabricate artifacts by sketching directly on physical materials. Draw2Cut employs a custom-drawing language to convert user-drawn lines, symbols, and colors into toolpaths, thereby enabling users to express their creative intent intuitively. The key features include real-time alignment between material and virtual toolpaths, a preview interface for validation, and an open-source platform for customization. Through technical evaluations and user studies, we demonstrate that \systemName lowers the entry barrier for personal fabrication, enabling novices to create customized artifacts with precision and ease. Our findings highlight the potential of the system to enhance creativity, engagement, and accessibility in CNC-based woodworking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18951v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xinyue Gui, Ding Xia, Wang Gao, Mustafa Doga Dogan, Maria Larsson, Takeo Igarashi</dc:creator>
    </item>
    <item>
      <title>From Soft Materials to Controllers with NeuroTouch: A Neuromorphic Tactile Sensor for Real-Time Gesture Recognition</title>
      <link>https://arxiv.org/abs/2501.19174</link>
      <description>arXiv:2501.19174v1 Announce Type: new 
Abstract: This work presents NeuroTouch, an optical-based tactile sensor that combines a highly deformable dome-shaped soft material with an integrated neuromorphic camera, leveraging frame-based and dynamic vision for gesture detection. Our approach transforms an elastic body into a rich and nuanced interactive controller by tracking markers printed on its surface with event-based methods and harnessing their trajectories through RANSAC-based techniques. To benchmark our framework, we have created a 25 min gesture dataset, which we make publicly available to foster research in this area. Achieving over 91% accuracy in gesture classification, a 3.41 mm finger localization distance error, and a 0.96 mm gesture intensity error, our real-time, lightweight, and low-latency pipeline holds promise for applications in video games, augmented/virtual reality, and accessible devices. This research lays the groundwork for advancements in gesture detection for vision-based soft-material input technologies. Dataset: Coming Soon, Video: Coming Soon</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19174v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Victor Hoffmann, Federico Paredes-Valles, Valentina Cavinato</dc:creator>
    </item>
    <item>
      <title>Users' Mental Models of Generative AI Chatbot Ecosystems</title>
      <link>https://arxiv.org/abs/2501.19211</link>
      <description>arXiv:2501.19211v1 Announce Type: new 
Abstract: The capability of GenAI-based chatbots, such as ChatGPT and Gemini, has expanded quickly in recent years, turning them into GenAI Chatbot Ecosystems. Yet, users' understanding of how such ecosystems work remains unknown. In this paper, we investigate users' mental models of how GenAI Chatbot Ecosystems work. This is an important question because users' mental models guide their behaviors, including making decisions that impact their privacy. Through 21 semi-structured interviews, we uncovered users' four mental models towards first-party (e.g., Google Gemini) and third-party (e.g., ChatGPT) GenAI Chatbot Ecosystems. These mental models centered around the role of the chatbot in the entire ecosystem. We further found that participants held a more consistent and simpler mental model towards third-party ecosystems than the first-party ones, resulting in higher trust and fewer concerns towards the third-party ecosystems. We discuss the design and policy implications based on our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19211v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3708359.3712125</arxiv:DOI>
      <dc:creator>Xingyi Wang, Xiaozheng Wang, Sunyup Park, Yaxing Yao</dc:creator>
    </item>
    <item>
      <title>Exploring Flow in Real-World Knowledge Work Using Discreet cEEGrid Sensors</title>
      <link>https://arxiv.org/abs/2501.19217</link>
      <description>arXiv:2501.19217v1 Announce Type: new 
Abstract: Flow, a state of deep task engagement, is associated with optimal experience and well-being, making its detection a prolific HCI research focus. While physiological sensors show promise for flow detection, most studies are lab-based. Furthermore, brain sensing during natural work remains unexplored due to the intrusive nature of traditional EEG setups. This study addresses this gap by using wearable, around-the-ear EEG sensors to observe flow during natural knowledge work, measuring EEG throughout an entire day. In a semi-controlled field experiment, participants engaged in academic writing or programming, with their natural flow experiences compared to those from a classic lab paradigm. Our results show that natural work tasks elicit more intense flow than artificial tasks, albeit with smaller experience contrasts. EEG results show a well-known quadratic relationship between theta power and flow across tasks, and a novel quadratic relationship between beta asymmetry and flow during complex, real-world tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19217v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael T. Knierim, Fabio Stano, Fabio Kurz, Antonius Heusch, Max L. Wilson</dc:creator>
    </item>
    <item>
      <title>Trust and Trustworthiness from Human-Centered Perspective in HRI -- A Systematic Literature Review</title>
      <link>https://arxiv.org/abs/2501.19323</link>
      <description>arXiv:2501.19323v1 Announce Type: new 
Abstract: The Industry 5.0 transition highlights EU efforts to design intelligent devices that can work alongside humans to enhance human capabilities, and such vision aligns with user preferences and needs to feel safe while collaborating with such systems take priority. This demands a human-centric research vision and requires a societal and educational shift in how we perceive technological advancements. To better understand this perspective, we conducted a systematic literature review focusing on understanding how trust and trustworthiness can be key aspects of supporting this move towards Industry 5.0. This review aims to overview the most common methodologies and measurements and collect insights about barriers and facilitators for fostering trustworthy HRI. After a rigorous quality assessment following the Systematic Reviews and Meta-Analyses guidelines, using rigorous inclusion criteria and screening by at least two reviewers, 34 articles were included in the review. The findings underscores the significance of trust and safety as foundational elements for promoting secure and trustworthy human-machine cooperation. Confirm that almost 30% of the revised articles do not present a definition of trust, which can be problematic as this lack of conceptual clarity can undermine research efforts in addressing this problem from a central perspective. It highlights that the choice of domain and area of application should influence the choice of methods and approaches to fostering trust in HRI, as those choices can significantly affect user preferences and their perceptions and assessment of robot capabilities. Additionally, this lack of conceptual clarity can be a potential barrier to fostering trust in HRI and explains the sometimes contradictory findings or choice of methods and instruments used to investigate trust in robots and other autonomous systems in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19323v1</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Debora Firmino de Souza, Sonia Sousa, Kadri Kristjuhan-Ling, Olga Dunajeva, Mare Roosileht, Avar Pentel, Mati M\~ottus, Mustafa Can \"Ozdemir, \v{Z}anna Grat\v{s}jova</dc:creator>
    </item>
    <item>
      <title>Human-Precision Medicine Interaction: Public Perceptions of Polygenic Risk Score for Genetic Health Prediction</title>
      <link>https://arxiv.org/abs/2501.19405</link>
      <description>arXiv:2501.19405v1 Announce Type: new 
Abstract: Precision Medicine (PM) transforms the traditional "one-drug-fits-all" paradigm by customising treatments based on individual characteristics, and is an emerging topic for HCI research on digital health. A key element of PM, the Polygenic Risk Score (PRS), uses genetic data to predict an individual's disease risk. Despite its potential, PRS faces barriers to adoption, such as data inclusivity, psychological impact, and public trust. We conducted a mixed-methods study to explore how people perceive PRS, formed of surveys (n=254) and interviews (n=11) with UK-based participants. The interviews were supplemented by interactive storyboards with the ContraVision technique to provoke deeper reflection and discussion. We identified ten key barriers and five themes to PRS adoption and proposed design implications for a responsible PRS framework. To address the complexities of PRS and enhance broader PM practices, we introduce the term Human-Precision Medicine Interaction (HPMI), which integrates, adapts, and extends HCI approaches to better meet these challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19405v1</guid>
      <category>cs.HC</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713567</arxiv:DOI>
      <dc:creator>Yuhao Sun, Albert Tenesa, John Vines</dc:creator>
    </item>
    <item>
      <title>Emancipatory Information Retrieval</title>
      <link>https://arxiv.org/abs/2501.19241</link>
      <description>arXiv:2501.19241v1 Announce Type: cross 
Abstract: Our world today is facing a confluence of several mutually reinforcing crises each of which intersects with concerns of social justice and emancipation. This paper is a provocation for the role of computer-mediated information access in our emancipatory struggles. We define emancipatory information retrieval as the study and development of information access methods that challenge various forms of human oppression, and situates its activities within broader collective emancipatory praxis. The term "emancipatory" here signifies the moral concerns of universal humanization of all peoples and the elimination of oppression to create the conditions under which we can collectively flourish. To develop an emancipatory research agenda for IR, in this paper we speculate about the practices that the community can adopt, enumerate some of the projects that the field should undertake, and discuss provocations to spark new ideas and directions for research. We challenge the field of information retrieval (IR) research to embrace humanistic values and commit to universal emancipation and social justice as part of our research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19241v1</guid>
      <category>cs.IR</category>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bhaskar Mitra</dc:creator>
    </item>
    <item>
      <title>SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments</title>
      <link>https://arxiv.org/abs/2501.19245</link>
      <description>arXiv:2501.19245v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) offers a general approach for modeling and training AI agents, including human-AI interaction scenarios. In this paper, we propose SHARPIE (Shared Human-AI Reinforcement Learning Platform for Interactive Experiments) to address the need for a generic framework to support experiments with RL agents and humans. Its modular design consists of a versatile wrapper for RL environments and algorithm libraries, a participant-facing web interface, logging utilities, deployment on popular cloud and participant recruitment platforms. It empowers researchers to study a wide variety of research questions related to the interaction between humans and RL agents, including those related to interactive reward specification and learning, learning from human feedback, action delegation, preference elicitation, user-modeling, and human-AI teaming. The platform is based on a generic interface for human-RL interactions that aims to standardize the field of study on RL in human contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19245v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H\"useyin Ayd{\i}n, Kevin Dubois-Godin, Libio Goncalvez Braz, Floris den Hengst, Kim Baraka, Mustafa Mert \c{C}elikok, Andreas Sauter, Shihan Wang, Frans A. Oliehoek</dc:creator>
    </item>
    <item>
      <title>Objective Metrics for Human-Subjects Evaluation in Explainable Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2501.19256</link>
      <description>arXiv:2501.19256v1 Announce Type: cross 
Abstract: Explanation is a fundamentally human process. Understanding the goal and audience of the explanation is vital, yet existing work on explainable reinforcement learning (XRL) routinely does not consult humans in their evaluations. Even when they do, they routinely resort to subjective metrics, such as confidence or understanding, that can only inform researchers of users' opinions, not their practical effectiveness for a given problem. This paper calls on researchers to use objective human metrics for explanation evaluations based on observable and actionable behaviour to build more reproducible, comparable, and epistemically grounded research. To this end, we curate, describe, and compare several objective evaluation methodologies for applying explanations to debugging agent behaviour and supporting human-agent teaming, illustrating our proposed methods using a novel grid-based environment. We discuss how subjective and objective metrics complement each other to provide holistic validation and how future work needs to utilise standardised benchmarks for testing to enable greater comparisons between research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19256v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Balint Gyevnar, Mark Towers</dc:creator>
    </item>
    <item>
      <title>Rethinking Model Evaluation as Narrowing the Socio-Technical Gap</title>
      <link>https://arxiv.org/abs/2306.03100</link>
      <description>arXiv:2306.03100v4 Announce Type: replace 
Abstract: The recent development of generative large language models (LLMs) poses new challenges for model evaluation that the research community and industry have been grappling with. While the versatile capabilities of these models ignite much excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in diverse downstream use cases can be satisfied by the given model (\textit{socio-technical gap}). By drawing on lessons about improving research realism from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world contexts and human requirements, and embrace diverse evaluation methods with an acknowledgment of trade-offs between realisms and pragmatic costs to conduct the evaluation. By mapping HCI and current NLG evaluation methods, we identify opportunities for evaluation methods for LLMs to narrow the socio-technical gap and pose open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03100v4</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Q. Vera Liao, Ziang Xiao</dc:creator>
    </item>
    <item>
      <title>Towards Sustainable Research Data Management in Human-Computer Interaction</title>
      <link>https://arxiv.org/abs/2307.10467</link>
      <description>arXiv:2307.10467v2 Announce Type: replace 
Abstract: We discuss important aspects of HCI research regarding Research Data Management (RDM) to achieve better publication processes and higher reuse of HCI research results. Various context elements of RDM for HCI are discussed, including examples of existing and emerging infrastructures for RDM. We briefly discuss existing approaches and come up with additional aspects which need to be addressed. This is to apply the so-called FAIR principle fully, which -- besides being findable and accessible -- also includes interoperability and reusability. We also discuss briefly the kind of research data types that play a role here and propose to build on existing work and involve the HCI scientific community to improve current practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10467v2</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>David Goedicke, Mark Colley, Sebastian S. Feger, Michael Goedicke, Bastian Pfleging, Wendy Ju</dc:creator>
    </item>
    <item>
      <title>"Cold, Calculated, and Condescending": How AI Identifies and Explains Ableism Compared to Disabled People</title>
      <link>https://arxiv.org/abs/2410.03448</link>
      <description>arXiv:2410.03448v2 Announce Type: replace 
Abstract: People with disabilities (PwD) regularly encounter ableist hate and microaggressions online. These spaces are generally moderated by machine learning models, but little is known about how effectively AI models identify ableist speech and how well their judgments align with PwD. To investigate this, we curated a first-of-its-kind dataset of 200 social media comments targeted towards PwD, and prompted state-of-the art AI models (i.e., Toxicity Classifiers, LLMs) to score toxicity and ableism for each comment, and explain their reasoning. Then, we recruited 190 participants to similarly rate and explain the harm, and evaluate LLM explanations. Our mixed-methods analysis highlighted a major disconnect: AI underestimated toxicity compared to PwD ratings, while its ableism assessments were sporadic and varied. Although LLMs identified some biases, its explanations were flawed--they lacked nuance, made incorrect assumptions, and appeared judgmental instead of educational. Going forward, we discuss challenges and opportunities in designing moderation systems for ableism, and advocate for the involvement of intersectional disabled perspectives in AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03448v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahika Phutane, Ananya Seelam, Aditya Vashistha</dc:creator>
    </item>
    <item>
      <title>SuiGPT MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract</title>
      <link>https://arxiv.org/abs/2410.15275</link>
      <description>arXiv:2410.15275v2 Announce Type: replace 
Abstract: The vision of Web3 is to improve user control over data and assets, but one challenge that complicates this vision is the prevalence of non-transparent, scam-prone applications and vulnerable smart contracts that put Web3 users at risk. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the SuiGPT Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code with prompt engineering.
  Our evaluation shows that MAD's output successfully passes original unit tests and achieves a 73.33% recompilation success rate on real-world smart contracts. Additionally, newer models tend to deliver improved performance, suggesting that MAD's approach will become increasingly effective as LLMs continue to advance.
  In a user study involving 12 developers, we found that MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, improving accessibility for understanding and auditing non-open-source smart contracts. Through qualitative interviews with these developers and Web3 projects, we further discussed the strengths and concerns of MAD.
  MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to easily and independently review and audit non-open-source smart contracts, fostering accountability and decentralization</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15275v2</guid>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3696410.3714790</arxiv:DOI>
      <dc:creator>Eason Chen, Xinyi Tang, Zimo Xiao, Chuangji Li, Shizhuo Li, Wu Tingguan, Siyun Wang, Kostas Kryptos Chalkias</dc:creator>
    </item>
    <item>
      <title>Privacy Leakage Overshadowed by Views of AI: A Study on Human Oversight of Privacy in Language Model Agent</title>
      <link>https://arxiv.org/abs/2411.01344</link>
      <description>arXiv:2411.01344v2 Announce Type: replace 
Abstract: Language model (LM) agents that act on users' behalf for personal tasks (e.g., replying emails) can boost productivity, but are also susceptible to unintended privacy leakage risks. We present the first study on people's capacity to oversee the privacy implications of the LM agents. By conducting a task-based survey (N=300), we investigate how people react to and assess the response generated by LM agents for asynchronous interpersonal communication tasks, compared with a response they wrote. We found that people may favor the agent response with more privacy leakage over the response they drafted or consider both good, leading to an increased harmful disclosure from 15.7% to 55.0%. We further identified six privacy profiles to characterize distinct patterns of concerns, trust, and privacy preferences in LM agents. Our findings shed light on designing agentic systems that enable privacy-preserving interactions and achieve bidirectional alignment on privacy preferences to help users calibrate trust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01344v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiping Zhang, Bingcan Guo, Tianshi Li</dc:creator>
    </item>
    <item>
      <title>Reexamining Technological Support for Genealogy Research, Collaboration, and Education</title>
      <link>https://arxiv.org/abs/2411.07869</link>
      <description>arXiv:2411.07869v3 Announce Type: replace 
Abstract: Genealogy, the study of family history and lineage, has seen tremendous growth over the past decade, fueled by technological advances such as home DNA testing and mass digitization of historical records. However, HCI research on genealogy practices is nascent, with the most recent major studies predating this transformation. In this paper, we present a qualitative study of the current state of technological support for genealogy research, collaboration, and education. Through semi-structured interviews with 20 genealogists with diverse expertise, we report on current practices, challenges, and success stories around how genealogists conduct research, collaborate, and learn skills. We contrast the experiences of amateurs and experts, describe the emerging importance of standardization and professionalization of the field, and stress the critical role of computer systems in genealogy education. We bridge studies of sensemaking and information literacy through this empirical study on genealogy research practices, and conclude by discussing how genealogy presents a unique perspective through which to study collective sensemaking and education in online communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07869v3</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3711053</arxiv:DOI>
      <dc:creator>Fei Shan, Kurt Luther</dc:creator>
    </item>
    <item>
      <title>Information Flows for Athletes' Health and Performance Data</title>
      <link>https://arxiv.org/abs/2412.05055</link>
      <description>arXiv:2412.05055v2 Announce Type: replace 
Abstract: Increasing numbers of athletes and sports teams use data collection technologies to improve athletic development and athlete health with the goal of improving competitive performance. Personal data privacy is managed but it is not always a priority for the coaches who are in charge of athletes. There is a pressing need to investigate what are appropriate information flows as described by contextual integrity for these data technologies and these use cases. We propose two main types of information flows for athletes' health and performance data -- team-centric and athlete-centric -- designed to characterize data used for the collective and individual physical, psychological and social development of athletes. We also present a scenario for applying differential privacy to athletes' data and propose two new information flows -- research-centric and community-centric &amp;mdash;which envision larger-scale, more collaborative sharing of athletes' data in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05055v2</guid>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brad Stenger, Yuanyuan Feng</dc:creator>
    </item>
    <item>
      <title>Visual Attention Based Cognitive Human-Robot Collaboration for Pedicle Screw Placement in Robot-Assisted Orthopedic Surgery</title>
      <link>https://arxiv.org/abs/2405.09359</link>
      <description>arXiv:2405.09359v2 Announce Type: replace-cross 
Abstract: Current orthopedic robotic systems largely focus on navigation, aiding surgeons in positioning a guiding tube but still requiring manual drilling and screw placement. The automation of this task not only demands high precision and safety due to the intricate physical interactions between the surgical tool and bone but also poses significant risks when executed without adequate human oversight. As it involves continuous physical interaction, the robot should collaborate with the surgeon, understand the human intent, and always include the surgeon in the loop. To achieve this, this paper proposes a new cognitive human-robot collaboration framework, including the intuitive AR-haptic human-robot interface, the visual-attention-based surgeon model, and the shared interaction control scheme for the robot. User studies on a robotic platform for orthopedic surgery are presented to illustrate the performance of the proposed method. The results demonstrate that the proposed human-robot collaboration framework outperforms full robot and full human control in terms of safety and ergonomics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09359v2</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/IROS58592.2024.10801930</arxiv:DOI>
      <dc:creator>Chen Chen, Qikai Zou, Yuhang Song, Mingrui Yu, Senqiang Zhu, Shiji Song, Xiang Li</dc:creator>
    </item>
    <item>
      <title>A Multi-Modal Explainability Approach for Human-Aware Robots in Multi-Party Conversation</title>
      <link>https://arxiv.org/abs/2407.03340</link>
      <description>arXiv:2407.03340v2 Announce Type: replace-cross 
Abstract: The addressee estimation (understanding to whom somebody is talking) is a fundamental task for human activity recognition in multi-party conversation scenarios. Specifically, in the field of human-robot interaction, it becomes even more crucial to enable social robots to participate in such interactive contexts. However, it is usually implemented as a binary classification task, restricting the robot's capability to estimate whether it was addressed \review{or not, which} limits its interactive skills. For a social robot to gain the trust of humans, it is also important to manifest a certain level of transparency and explainability. Explainable artificial intelligence thus plays a significant role in the current machine learning applications and models, to provide explanations for their decisions besides excellent performance. In our work, we a) present an addressee estimation model with improved performance in comparison with the previous state-of-the-art; b) further modify this model to include inherently explainable attention-based segments; c) implement the explainable addressee estimation as part of a modular cognitive architecture for multi-party conversation in an iCub robot; d) validate the real-time performance of the explainable model in multi-party human-robot interaction; e) propose several ways to incorporate explainability and transparency in the aforementioned architecture; and f) perform an online user study to analyze the effect of various explanations on how human participants perceive the robot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03340v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>eess.IV</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iveta Be\v{c}kov\'a, \v{S}tefan P\'oco\v{s}, Giulia Belgiovine, Marco Matarese, Omar Eldardeer, Alessandra Sciutti, Carlo Mazzola</dc:creator>
    </item>
    <item>
      <title>Characterizing the MrDeepFakes Sexual Deepfake Marketplace</title>
      <link>https://arxiv.org/abs/2410.11100</link>
      <description>arXiv:2410.11100v3 Announce Type: replace-cross 
Abstract: The prevalence of sexual deepfake material has exploded over the past several years. Attackers create and utilize deepfakes for many reasons: to seek sexual gratification, to harass and humiliate targets, or to exert power over an intimate partner. In part enabling this growth, several markets have emerged to support the buying and selling of sexual deepfake material. In this paper, we systematically characterize the most prominent and mainstream marketplace, MrDeepFakes. We analyze the marketplace economics, the targets of created media, and user discussions of how to create deepfakes, which we use to understand the current state-of-the-art in deepfake creation. Our work uncovers little enforcement of posted rules (e.g., limiting targeting to well-established celebrities), previously undocumented attacker motivations, and unexplored attacker tactics for acquiring resources to create sexual deepfakes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11100v3</guid>
      <category>cs.CY</category>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Catherine Han, Anne Li, Deepak Kumar, Zakir Durumeric</dc:creator>
    </item>
    <item>
      <title>Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems</title>
      <link>https://arxiv.org/abs/2501.17348</link>
      <description>arXiv:2501.17348v2 Announce Type: replace-cross 
Abstract: While theories of discourse and cognitive science have long recognized the value of unhurried pacing, recent dialogue research tends to minimize friction in conversational systems. Yet, frictionless dialogue risks fostering uncritical reliance on AI outputs, which can obscure implicit assumptions and lead to unintended consequences. To meet this challenge, we propose integrating positive friction into conversational AI, which promotes user reflection on goals, critical thinking on system response, and subsequent re-conditioning of AI systems. We hypothesize systems can improve goal alignment, modeling of user mental states, and task success by deliberately slowing down conversations in strategic moments to ask questions, reveal assumptions, or pause. We present an ontology of positive friction and collect expert human annotations on multi-domain and embodied goal-oriented corpora. Experiments on these corpora, along with simulated interactions using state-of-the-art systems, suggest incorporating friction not only fosters accountable decision-making, but also enhances machine understanding of user beliefs and goals, and increases task success rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17348v2</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mert \.Inan, Anthony Sicilia, Suvodip Dey, Vardhan Dongre, Tejas Srinivasan, Jesse Thomason, G\"okhan T\"ur, Dilek Hakkani-T\"ur, Malihe Alikhani</dc:creator>
    </item>
  </channel>
</rss>
