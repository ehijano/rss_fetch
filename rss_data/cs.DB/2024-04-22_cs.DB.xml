<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Apr 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Open Research Issues and Tools for Visualization and Big Data Analytics</title>
      <link>https://arxiv.org/abs/2404.12505</link>
      <description>arXiv:2404.12505v1 Announce Type: new 
Abstract: The new age of digital growth has marked all fields. This technological evolution has impacted data flows which have witnessed a rapid expansion over the last decade that makes the data traditional processing unable to catch up with the rapid flow of massive data. In this context, the implementation of a big data analytics system becomes crucial to make big data more relevant and valuable. Therefore, with these new opportunities appear new issues of processing very high data volumes requiring companies to look for big data-specialized solutions. These solutions are based on techniques to process these masses of information to facilitate decision-making. Among these solutions, we find data visualization which makes big data more intelligible allowing accurate illustrations that have become accessible to all. This paper examines the big data visualization project based on its characteristics, benefits, challenges and issues. The project, also, resulted in the provision of tools surging for beginners as well as well as experienced users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12505v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.12785/ijcds/150178</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Computing and Digital Systems, 15, 1103-1117, 2024</arxiv:journal_reference>
      <dc:creator>Rania Mkhinini Gahar, Olfa Arfaoui, Minyar Sassi Hidri</dc:creator>
    </item>
    <item>
      <title>Cocoon: Semantic Table Profiling Using Large Language Models</title>
      <link>https://arxiv.org/abs/2404.12552</link>
      <description>arXiv:2404.12552v1 Announce Type: new 
Abstract: Data profilers play a crucial role in the preprocessing phase of data analysis by identifying quality issues such as missing, extreme, or erroneous values. Traditionally, profilers have relied solely on statistical methods, which lead to high false positives and false negatives. For example, they may incorrectly flag missing values where such absences are expected and normal based on the data's semantic context. To address these, we introduce Cocoon, a data profiling system that integrates LLMs to imbue statistical profiling with semantics. Cocoon enhances traditional profiling methods by adding a three-step process: Semantic Context, Semantic Profile, and Semantic Review. Our user studies show that Cocoon is highly effective at accurately discerning whether anomalies are genuine errors requiring correction or acceptable variations based on the semantics for real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12552v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zezhou Huang, Eugene Wu</dc:creator>
    </item>
    <item>
      <title>Auto-Formula: Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations</title>
      <link>https://arxiv.org/abs/2404.12608</link>
      <description>arXiv:2404.12608v1 Announce Type: new 
Abstract: Spreadsheets are widely recognized as the most popular end-user programming tools, which blend the power of formula-based computation, with an intuitive table-based interface. Today, spreadsheets are used by billions of users to manipulate tables, most of whom are neither database experts nor professional programmers.
  Despite the success of spreadsheets, authoring complex formulas remains challenging, as non-technical users need to look up and understand non-trivial formula syntax. To address this pain point, we leverage the observation that there is often an abundance of similar-looking spreadsheets in the same organization, which not only have similar data, but also share similar computation logic encoded as formulas. We develop an Auto-Formula system that can accurately predict formulas that users want to author in a target spreadsheet cell, by learning and adapting formulas that already exist in similar spreadsheets, using contrastive-learning techniques inspired by "similar-face recognition" from compute vision.
  Extensive evaluations on over 2K test formulas extracted from real enterprise spreadsheets show the effectiveness of Auto-Formula over alternatives. Our benchmark data is available at https://github.com/microsoft/Auto-Formula to facilitate future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12608v1</guid>
      <category>cs.DB</category>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sibei Chen, Yeye He, Weiwei Cui, Ju Fan, Song Ge, Haidong Zhang, Dongmei Zhang, Surajit Chaudhuri</dc:creator>
    </item>
    <item>
      <title>LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency</title>
      <link>https://arxiv.org/abs/2404.12872</link>
      <description>arXiv:2404.12872v1 Announce Type: new 
Abstract: Query rewrite, which aims to generate more efficient queries by altering a SQL query's structure without changing the query result, has been an important research problem. In order to maintain equivalence between the rewritten query and the original one during rewriting, traditional query rewrite methods always rewrite the queries following certain rewrite rules. However, some problems still remain. Firstly, existing methods of finding the optimal choice or sequence of rewrite rules are still limited and the process always costs a lot of resources. Methods involving discovering new rewrite rules typically require complicated proofs of structural logic or extensive user interactions. Secondly, current query rewrite methods usually rely highly on DBMS cost estimators which are often not accurate. In this paper, we address these problems by proposing a novel method of query rewrite named LLM-R2, adopting a large language model (LLM) to propose possible rewrite rules for a database rewrite system. To further improve the inference ability of LLM in recommending rewrite rules, we train a contrastive model by curriculum to learn query representations and select effective query demonstrations for the LLM. Experimental results have shown that our method can significantly improve the query execution efficiency and outperform the baseline methods. In addition, our method enjoys high robustness across different datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12872v1</guid>
      <category>cs.DB</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaodonghui Li, Haitao Yuan, Huiming Wang, Gao Cong, Lidong Bing</dc:creator>
    </item>
    <item>
      <title>Influential Billboard Slot Selection under Zonal Influence Constraint</title>
      <link>https://arxiv.org/abs/2404.12913</link>
      <description>arXiv:2404.12913v1 Announce Type: new 
Abstract: Given billboard and trajectory database, finding a limited number of billboard slots for maximizing the influence is an important problem in the context of billboard advertisement. Most of the existing literature focused on the influential slot selection problem without considering any specific zonal influence constraint. To bridge this gap in this paper, we introduce and study the Influential Billboard Slot Selection Problem Under Zonal Influence Constraint. We propose a simple greedy approach to solve this problem. Though this method is easy to understand and simple to implement due to the excessive number of marginal gain computations, this method is not scalable. We design a branch and bound framework with two bound estimation techniques that divide the problem into different zones and integrate the zone-specific solutions to obtain a solution for the whole. We implement both the solution methodologies with real-world billboard and trajectory datasets and several experiments have been reported. We compare the performance of the proposed solution approaches with several baseline methods. The results show that the proposed approaches lead to more effective solutions with reasonable computational overhead than the baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12913v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Suman Banerjee, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL</title>
      <link>https://arxiv.org/abs/2404.12560</link>
      <description>arXiv:2404.12560v1 Announce Type: cross 
Abstract: The current state-of-the-art (SOTA) for automated text-to-SQL still falls well short of expert human performance as measured by execution accuracy (EX) on the BIRD-SQL benchmark. The most accurate methods are also slow and expensive. To advance the SOTA for text-to-SQL while reducing cost and improving speed, we explore the combination of low-cost fine tuning, novel methods for diverse retrieval-augmented generation (RAG) and new input and output formats that help large language models (LLMs) achieve higher EX. We introduce two new methods, Dubo-SQL v1 and v2. Dubo-SQL v1 sets a new record for EX on the holdout test set of BIRD-SQL. Dubo-SQL v2 achieves even higher performance on the BIRD-SQL dev set. Dubo-SQL v1 relies on LLMs from OpenAI, but uses the low-cost GPT-3.5 Turbo while exceeding the performance of the next-best model using OpenAI, which instead uses the more expensive GPT-4. Dubo-SQL v1 exceeds the performance of the next-best model using GPT-3.5 by over 20%. Dubo-SQL v2 uses GPT-4 Turbo and RAG in place of fine tuning to push EX higher.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12560v1</guid>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dayton G. Thorpe, Andrew J. Duberstein, Ian A. Kinsey</dc:creator>
    </item>
  </channel>
</rss>
