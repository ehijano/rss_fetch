<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Uniqueness Bias: Why It Matters, How to Curb It</title>
      <link>https://arxiv.org/abs/2408.07710</link>
      <description>arXiv:2408.07710v1 Announce Type: new 
Abstract: The paper explores "uniqueness bias," a behavioral bias defined as the tendency of planners and managers to see their decisions as singular. For the first time, uniqueness bias is correlated with forecasting accuracy and performance in real-world project investment decisions. We problematize the conventional framing of projects as unique and hypothesize that it leads to poor project performance. We test the thesis for a sample of 219 projects and find that perceived uniqueness is indeed highly statistically significantly associated with underperformance. Finally, we identify how decision makers can mitigate uniqueness bias in their projects through what Daniel Kahneman aptly called "decision hygiene," specifically reference class forecasting, premortems, similarity-based forecasting, and noise audits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07710v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bent Flyvbjerg, Alexander Budzier, M. D. Christodoulou, M. Zottoli</dc:creator>
    </item>
    <item>
      <title>Capturing the Complexity of Human Strategic Decision-Making with Machine Learning</title>
      <link>https://arxiv.org/abs/2408.07865</link>
      <description>arXiv:2408.07865v1 Announce Type: new 
Abstract: Understanding how people behave in strategic settings--where they make decisions based on their expectations about the behavior of others--is a long-standing problem in the behavioral sciences. We conduct the largest study to date of strategic decision-making in the context of initial play in two-player matrix games, analyzing over 90,000 human decisions across more than 2,400 procedurally generated games that span a much wider space than previous datasets. We show that a deep neural network trained on these data predicts people's choices better than leading theories of strategic behavior, indicating that there is systematic variation that is not explained by those theories. We then modify the network to produce a new, interpretable behavioral model, revealing what the original network learned about people: their ability to optimally respond and their capacity to reason about others are dependent on the complexity of individual games. This context-dependence is critical in explaining deviations from the rational Nash equilibrium, response times, and uncertainty in strategic decisions. More broadly, our results demonstrate how machine learning can be applied beyond prediction to further help generate novel explanations of complex human behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07865v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jian-Qiao Zhu, Joshua C. Peterson, Benjamin Enke, Thomas L. Griffiths</dc:creator>
    </item>
    <item>
      <title>When and Why is Persuasion Hard? A Computational Complexity Result</title>
      <link>https://arxiv.org/abs/2408.07923</link>
      <description>arXiv:2408.07923v1 Announce Type: cross 
Abstract: As generative foundation models improve, they also tend to become more persuasive, raising concerns that AI automation will enable governments, firms, and other actors to manipulate beliefs with unprecedented scale and effectiveness at virtually no cost. The full economic and social ramifications of this trend have been difficult to foresee, however, given that we currently lack a complete theoretical understanding of why persuasion is costly for human labor to produce in the first place. This paper places human and AI agents on a common conceptual footing by formalizing informational persuasion as a mathematical decision problem and characterizing its computational complexity. A novel proof establishes that persuasive messages are challenging to discover (NP-Hard) but easy to adopt if supplied by others (NP). This asymmetry helps explain why people are susceptible to persuasion, even in contexts where all relevant information is publicly available. The result also illuminates why litigation, strategic communication, and other persuasion-oriented activities have historically been so human capital intensive, and it provides a new theoretical basis for studying how AI will impact various industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07923v1</guid>
      <category>cs.CY</category>
      <category>cs.CC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Wojtowicz</dc:creator>
    </item>
    <item>
      <title>Bespoke scapegoats: Scientific advisory bodies and blame avoidance in the Covid-19 pandemic and beyond</title>
      <link>https://arxiv.org/abs/2310.04312</link>
      <description>arXiv:2310.04312v2 Announce Type: replace 
Abstract: Scholars have not asked why so many governments created ad hoc scientific advisory bodies (ahSABs) to address the Covid-19 pandemic instead of relying on existing public health infrastructure. We address this neglected question with an exploratory study of the US, UK, Sweden, Italy, Poland, and Uganda. Drawing on our case studies and the blame-avoidance literature, we find that ahSABs are created to excuse unpopular policies and take the blame should things go wrong. Thus, membership typically represents a narrow range of perspectives. An ahSAB is a good scapegoat because it does little to reduce government discretion and has limited ability to deflect blame back to government. Our explanation of our deviant case of Sweden, that did not create and ahSAB, reinforces our general principles. We draw the policy inference that ahSAB membership should be vetted by the legislature to ensure broad membership.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04312v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger Koppl, Kira Pronin, Nick Cowen, Marta Podemska-Mikluch, Pablo Paniagua Prieto</dc:creator>
    </item>
  </channel>
</rss>
