<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Jun 2024 04:01:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stackelberg Games with $k$-Submodular Function under Distributional Risk-Receptiveness and Robustness</title>
      <link>https://arxiv.org/abs/2406.13023</link>
      <description>arXiv:2406.13023v1 Announce Type: new 
Abstract: We study submodular optimization in adversarial context, applicable to machine learning problems such as feature selection using data susceptible to uncertainties and attacks. We focus on Stackelberg games between an attacker (or interdictor) and a defender where the attacker aims to minimize the defender's objective of maximizing a $k$-submodular function. We allow uncertainties arising from the success of attacks and inherent data noise, and address challenges due to incomplete knowledge of the probability distribution of random parameters. Specifically, we introduce Distributionally Risk-Averse $k$-Submodular Interdiction Problem (DRA $k$-SIP) and Distributionally Risk-Receptive $k$-Submodular Interdiction Problem (DRR $k$-SIP) along with finitely convergent exact algorithms for solving them. The DRA $k$-SIP solution allows risk-averse interdictor to develop robust strategies for real-world uncertainties. Conversely, DRR $k$-SIP solution suggests aggressive tactics for attackers, willing to embrace (distributional) risk to inflict maximum damage, identifying critical vulnerable components, which can be used for the defender's defensive strategies. The optimal values derived from both DRA $k$-SIP and DRR $k$-SIP offer a confidence interval-like range for the expected value of the defender's objective function, capturing distributional ambiguity. We conduct computational experiments using instances of feature selection and sensor placement problems, and Wisconsin breast cancer data and synthetic data, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13023v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seonghun Park, Manish Bansal</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Ensemble Filters for Linear Stochastic Systems with Poisson-Sampled Observations</title>
      <link>https://arxiv.org/abs/2406.13091</link>
      <description>arXiv:2406.13091v1 Announce Type: new 
Abstract: For continuous-time linear stochastic dynamical systems driven by Wiener processes, we consider the problem of designing ensemble filters when the observation process is randomly time-sampled. We propose a continuous-discrete McKean--Vlasov type diffusion process with additive Gaussian noise in observation model, which is used to describe the evolution of the individual particles in the ensemble. These particles are coupled through the empirical covariance and require less computations for implementation than the optimal ones based on solving Riccati differential equations. Using appropriate analysis tools, we show that the empirical mean and the sample covariance of the ensemble filter converges to the mean and covariance of the optimal filter if the mean sampling rate of the observation process satisfies certain bounds and as the number of particles tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13091v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aneel Tanwani, Olga Yufereva</dc:creator>
    </item>
    <item>
      <title>Data Value in Distribution System Operations</title>
      <link>https://arxiv.org/abs/2406.13148</link>
      <description>arXiv:2406.13148v1 Announce Type: new 
Abstract: The rise of advanced data technologies in electric power distribution systems enables operators to optimize operations but raises concerns about data security and consumer privacy. Resulting data protection mechanisms that alter or obfuscate datasets may invalidate the efficacy of data-driven decision-support tools and impact the value of these datasets to the decision-maker. This paper derives tools for distribution system operators to enrich data-driven operative decisions with information on data quality and, simultaneously, assess data usefulness in the context of this decision. To this end, we derive an AC optimal power flow model for radial distribution systems with data-informed stochastic parameters that internalize a data quality metric. We derive a tractable reformulation and discuss the marginal sensitivity of the optimal solution as a proxy for data value. Our model can capture clustered data provision, e.g., from resource aggregators, and internalize individual data quality information from each data provider. We use the IEEE 33-bus test system, examining scenarios with varying photovoltaic penetration, to demonstrate the application of our approach and discuss the relationship between data quality and its value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13148v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrnoush Ghazanfariharandi, Robert Mieth</dc:creator>
    </item>
    <item>
      <title>Stochastic Multi-objective Multi-trip AMR Routing Problem with Time Windows</title>
      <link>https://arxiv.org/abs/2406.13168</link>
      <description>arXiv:2406.13168v1 Announce Type: new 
Abstract: In recent years, with the rapidly aging population, alleviating the pressure on medical staff has become a critical issue. To improve the work efficiency of medical staff and reduce the risk of infection, we consider the multi-trip autonomous mobile robot (AMR) routing problem with the stochastic environment to find the solution to minimizing the total expected operating cost and maximizing the total service quality of patients so that each route violates the vehicle capacity and the time window with only a very small probability. The travel time of AMRs is stochastic affected by the surrounding environment, the demand for each ward is unknown until the AMR reaches the ward, and the service time is linearly related to the actual demand. We develop a population-based tabu search algorithm (PTS) that combines the genetic algorithm with the tabu search algorithm to solve the problem. Extensive numerical experiments were conducted on the modified Solomon instances to show that the PTS algorithm the efficient and reveals the impacts of the confidence level on the optimal solution, providing insights for the decision-maker to devise delivery schemes that trade-off the operating cost for patient satisfaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13168v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lulu Cheng, Ning Zhao</dc:creator>
    </item>
    <item>
      <title>Generalized Metric Subregularity with Applications to High-Order Regularized Newton Methods</title>
      <link>https://arxiv.org/abs/2406.13207</link>
      <description>arXiv:2406.13207v1 Announce Type: new 
Abstract: This paper pursues a twofold goal. First, we introduce and study in detail a new notion of variational analysis called generalized metric subregularity, which is a far-going extension of the conventional metric subregularity conditions. Our primary focus is on examining this concept concerning first-order and second-order stationary points. We develop an extended convergence framework that enables us to derive superlinear and quadratic convergence under the generalized metric subregularity condition, broadening the widely used KL convergence analysis framework. We present verifiable sufficient conditions to ensure the proposed generalized metric subregularity condition and provide examples demonstrating that the derived convergence rates are sharp. Second, we design a new high-order regularized Newton method with momentum steps, and apply the generalized metric subregularity to establish its superlinear convergence. Quadratic convergence is obtained under additional assumptions. Specifically, when applying the proposed method to solve the (nonconvex) over-parameterized compressed sensing model, we achieve global convergence with a quadratic local convergence rate towards a global minimizer under a strict complementarity condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13207v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guoyin Li, Boris Mordukhovich, Jiangxing Zhu</dc:creator>
    </item>
    <item>
      <title>Optimizing Inventory Management through Multiobjective Reverse Logistics with Environmental Impact</title>
      <link>https://arxiv.org/abs/2406.13226</link>
      <description>arXiv:2406.13226v1 Announce Type: new 
Abstract: We present novel mathematical models for inventory management within a reverse logistics system. Technological advancements, sustainability initiatives, and evolving customer behaviours have significantly increased the demand for repaired products. Our models account for varying demand levels for newly produced and repaired items. To optimize overall costs with constrained scenarios, we formulated mixed integer programming problems. Solution procedures for the proposed problems are introduced, and the accuracy of these solutions has been validated through numerical experiments. Additionally, we address the cost of waste disposal as an environmental concern. This paper develops a multiobjective mathematical model and provides an algorithm for the Pareto solution. Various scalarization techniques are utilized to identify the Pareto front, and a comparison of these techniques is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13226v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>I. B. Wadhawan, M. M. Rizvi</dc:creator>
    </item>
    <item>
      <title>Numerical Methods for Shape Optimal Design of Fluid-Structure Interaction Problems</title>
      <link>https://arxiv.org/abs/2406.13379</link>
      <description>arXiv:2406.13379v1 Announce Type: new 
Abstract: We consider the method of mappings for performing shape optimization for unsteady fluid-structure interaction (FSI) problems. In this work, we focus on the numerical implementation. We model the optimization problem such that it takes several theoretical results into account, such as regularity requirements on the transformations and a differential geometrical point of view on the manifold of shapes. Moreover, we discretize the problem such that we can compute exact discrete gradients. This allows for the use of general purpose optimization solvers. We focus on an FSI benchmark problem to validate our numerical implementation. The method is used to optimize parts of the outer boundary and the interface. The numerical simulations build on FEniCS, dolfin-adjoint and IPOPT. Moreover, as an additional theoretical result, we show that for a linear special case the adjoint attains the same structure as the forward problem but reverses the temporal flow of information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13379v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Haubner, Michael Ulbrich</dc:creator>
    </item>
    <item>
      <title>Unifying nonlinearly constrained nonconvex optimization</title>
      <link>https://arxiv.org/abs/2406.13454</link>
      <description>arXiv:2406.13454v1 Announce Type: new 
Abstract: Derivative-based iterative methods for nonlinearly constrained nonconvex optimization usually share common algorithmic components, such as strategies for computing a descent direction and mechanisms that promote global convergence. Based on this observation, we introduce an abstract framework based on four common ingredients that describes most derivative-based iterative methods and unifies their workflows. We then present Uno, a modular C++ solver that implements our abstract framework and allows the automatic generation of various strategy combinations with no programming effort from the user. Uno is meant to (1) organize mathematical optimization strategies into a coherent hierarchy; (2) offer a wide range of efficient and robust methods that can be compared for a given instance; (3) enable researchers to experiment with novel optimization strategies; and (4) reduce the cost of development and maintenance of multiple optimization solvers. Uno's software design allows user to compose new customized solvers for emerging optimization areas such as robust optimization or optimization problems with complementarity constraints, while building on reliable nonlinear optimization techniques. We demonstrate that Uno is highly competitive against state-of-the-art solvers filterSQP, IPOPT, SNOPT, MINOS, LANCELOT, LOQO, and CONOPT on a subset of 429 small problems from the CUTEst collection. Uno is available as open-source software under the MIT license at https://github.com/cvanaret/Uno .</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13454v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charlie Vanaret, Sven Leyffer</dc:creator>
    </item>
    <item>
      <title>On Computation of Approximate Solutions to Large-Scale Backstepping Kernel Equations via Continuum Approximation</title>
      <link>https://arxiv.org/abs/2406.13612</link>
      <description>arXiv:2406.13612v1 Announce Type: new 
Abstract: We provide two methods for computation of continuum backstepping kernels that arise in control of continua (ensembles) of linear hyperbolic PDEs and which can approximate backstepping kernels arising in control of a large-scale, PDE system counterpart (with computational complexity that does not grow with the number of state components of the large-scale system). In the first method, we identify a class of systems for which the solution to the continuum (and hence, also an approximate solution to the respective large-scale) kernel equations can be constructed in closed form. In the second method, we provide explicit formulae for the solution to the continuum kernels PDEs, employing a (triple) power series representation of the continuum kernel and establishing its convergence properties. In this case, we also provide means for reducing computational complexity by properly truncating the power series (in the powers of the ensemble variable). We also present numerical examples to illustrate computational efficiency/accuracy of the approaches, as well as to validate the stabilization properties of the approximate control kernels, constructed based on the continuum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13612v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis</dc:creator>
    </item>
    <item>
      <title>Global Solutions to Master Equations for Continuous Time Heterogeneous Agent Macroeconomic Models</title>
      <link>https://arxiv.org/abs/2406.13726</link>
      <description>arXiv:2406.13726v1 Announce Type: new 
Abstract: We propose and compare new global solution algorithms for continuous time heterogeneous agent economies with aggregate shocks. First, we approximate the agent distribution so that equilibrium in the economy can be characterized by a high, but finite, dimensional non-linear partial differential equation. We consider different approximations: discretizing the number of agents, discretizing the agent state variables, and projecting the distribution onto a finite set of basis functions. Second, we represent the value function using a neural network and train it to solve the differential equation using deep learning tools. We refer to the solution as an Economic Model Informed Neural Network (EMINN). The main advantage of this technique is that it allows us to find global solutions to high dimensional, non-linear problems. We demonstrate our algorithm by solving important models in the macroeconomics and spatial literatures (e.g. Krusell and Smith (1998), Khan and Thomas (2007), Bilal (2023)).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13726v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhouzhou Gu, Mathieu Lauri\`ere, Sebastian Merkel, Jonathan Payne</dc:creator>
    </item>
    <item>
      <title>Aubin Property and Strong Regularity Are Equivalent for Nonlinear Second-Order Cone Programming</title>
      <link>https://arxiv.org/abs/2406.13798</link>
      <description>arXiv:2406.13798v1 Announce Type: new 
Abstract: This paper solves a fundamental open problem in variational analysis on the equivalence between the Aubin property and the strong regularity for nonlinear second-order cone programming (SOCP) at a locally optimal solution. We achieve this by introducing a reduction approach to the Aubin property characterized by the Mordukhovich criterion and a lemma of alternative choices on cones to replace the S-lemma used in Outrata and Ram\'irez [SIAM J. Optim. 21 (2011) 789-823] and Opazo, Outrata, and Ram\'irez [SIAM J. Optim. 27 (2017) 2141-2151], where the same SOCP was considered under the strict complementarity condition except for possibly only one block of constraints. As a byproduct, we also offer a new approach to the well-known result of Dontchev and Rockafellar [SIAM J. Optim. 6 (1996) 1087-1105] on the equivalence of the two concepts in conventional nonlinear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13798v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Chen, Ruoning Chen, Defeng Sun, Junyuan Zhu</dc:creator>
    </item>
    <item>
      <title>Open Problem: Anytime Convergence Rate of Gradient Descent</title>
      <link>https://arxiv.org/abs/2406.13888</link>
      <description>arXiv:2406.13888v1 Announce Type: new 
Abstract: Recent results show that vanilla gradient descent can be accelerated for smooth convex objectives, merely by changing the stepsize sequence. We show that this can lead to surprisingly large errors indefinitely, and therefore ask: Is there any stepsize schedule for gradient descent that accelerates the classic $\mathcal{O}(1/T)$ convergence rate, at \emph{any} stopping time $T$?</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13888v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski, Ohad Shamir</dc:creator>
    </item>
    <item>
      <title>On the complexity of matrix Putinar's Positivstellensatz</title>
      <link>https://arxiv.org/abs/2406.13980</link>
      <description>arXiv:2406.13980v1 Announce Type: new 
Abstract: This paper studies the complexity of matrix Putinar's Positivstellensatz on the semialgebraic set that is given by the polynomial matrix inequality. Under the archimedeanness, we prove a polynomial bound on degrees of terms appearing in the representation of matrix Putinar's Positivstellensatz. Estimates on the exponent and constant are given. As a byproduct, a polynomial bound on the convergence rate of matrix sum-of-squares relaxations is obtained, which resolves an open question raised by Dinh and Pham. When the constraining set is unbounded (the archimedeanness fails), we also prove a similar bound for the matrix version of Putinar--Vasilescu's Positivstellensatz by exploiting homogenization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13980v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Huang</dc:creator>
    </item>
    <item>
      <title>Robust nonlinear state-feedback control of second-order systems</title>
      <link>https://arxiv.org/abs/2406.14000</link>
      <description>arXiv:2406.14000v1 Announce Type: new 
Abstract: This note proposes a novel nonlinear state feedback controller for perturbed second-order systems. In analogy to a linear proportional-derivative (PD) output feedback control, the proposed nonlinear scheme uses the output state of interest and its time derivative for a robust finite-time regulation. The control has only one free design parameter, and the closed-loop system is shown to be uniformly asymptotically stable in the presence of matched disturbances. We derive a strict Lyapunov function for the closed control loop with a bounded exogenous perturbation, and use it for both the control tuning and analysis of the finite-time convergence. Apart from the numerical results, a revealing experimental example is also shown in favor of the proposed control and in comparison with PD and sub-optimal nonlinear damping regulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14000v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>Primal-Dual Strategy (PDS) for Composite Optimization Over Directed graphs</title>
      <link>https://arxiv.org/abs/2406.14011</link>
      <description>arXiv:2406.14011v1 Announce Type: new 
Abstract: We investigate the distributed multi-agent sharing optimization problem in a directed graph, with a composite objective function consisting of a smooth function plus a convex (possibly non-smooth) function shared by all agents. While adhering to the network connectivity structure, the goal is to minimize the sum of smooth local functions plus a non-smooth function. The proposed Primal-Dual algorithm (PD) is similar to a previous algorithm \cite{b27}, but it has additional benefits. To begin, we investigate the problem in directed graphs, where agents can only communicate in one direction and the combination matrix is not symmetric. Furthermore, the combination matrix is changing over time, and the condition coefficient weights are produced using an adaptive approach. The strong convexity assumption, adaptive coefficient weights, and a new upper bound on step-sizes are used to demonstrate that linear convergence is possible. New upper bounds on step-sizes are derived under the strong convexity assumption and adaptive coefficient weights that are time-varying in the presence of both smooth and non-smooth terms. Simulation results show the efficacy of the proposed algorithm compared to some other algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14011v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajad Zandi, Mehdi Korki</dc:creator>
    </item>
    <item>
      <title>Distributed Event-Triggered Bandit Convex Optimization with Time-Varying Constraints</title>
      <link>https://arxiv.org/abs/2406.14060</link>
      <description>arXiv:2406.14060v1 Announce Type: new 
Abstract: This paper considers the distributed bandit convex optimization problem with time-varying inequality constraints over a network of agents, where the goal is to minimize network regret and cumulative constraint violation. Existing distributed online algorithms require that each agent broadcasts its decision to its neighbors at each iteration. To better utilize the limited communication resources, we propose a distributed event-triggered online primal--dual algorithm with two-point bandit feedback. Under several classes of appropriately chosen decreasing parameter sequences and non-increasing event-triggered threshold sequences, we establish dynamic network regret and network cumulative constraint violation bounds. These bounds are comparable to the results achieved by distributed event-triggered online algorithms with full-information feedback. Finally, a numerical example is provided to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14060v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunpeng Zhang, Xinlei Yi, Guanghui Wen, Ming Cao, Karl H. Johansson, Tianyou Chai, Tao Yang</dc:creator>
    </item>
    <item>
      <title>Connected Vehicle Data-driven Robust Optimization for Traffic Signal Timing: Modeling Traffic Flow Variability and Errors</title>
      <link>https://arxiv.org/abs/2406.14108</link>
      <description>arXiv:2406.14108v1 Announce Type: new 
Abstract: Recent advancements in Connected Vehicle (CV) technology have prompted research on leveraging CV data for more effective traffic management. Despite the low penetration rate, such detailed CV data has demonstrated great potential in improving traffic signal performance. However, existing studies share a common shortcoming in that they all ignore traffic flow estimation errors in their modeling process, which is inevitable due to the sampling observation nature of CVs. This study proposes a CV data-driven robust optimization framework for traffic signal timing accounting for both traffic flow variability and estimation errors. First, we propose a general CV data-driven optimization model that can be widely applied to various signalized intersection scenarios including under-/over-saturated and fixed-/real-time. Then, we propose a novel data-driven uncertainty set of arrival rates based on the bounds information derived from CVs, which circumvents the error-prone arrival rate estimation process. Finally, a CV data-driven robust optimization model (CV-RO) is formulated to explicitly handle arrival rate uncertainties. By means of the robust counterpart approach, this robust optimization problem can be equalized to a deterministic mixed-integer linear programming problem with an exact solution. The evaluation results highlight the superior performance of the CV-RO model compared to the deterministic model and traditional methods across various scenarios: different penetration rates, traffic demands, and control types. Notably, the CV-RO model demonstrates its excellence at lower CV penetration rates and in the presence of different traffic flow fluctuation levels, affirming its effectiveness and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14108v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaopeng Tan, Yue Ding, Kaidi Yang, Hong Zhu, Keshuang Tang</dc:creator>
    </item>
    <item>
      <title>Optimization over bounded-rank matrices through a desingularization enables joint global and local guarantees</title>
      <link>https://arxiv.org/abs/2406.14211</link>
      <description>arXiv:2406.14211v1 Announce Type: new 
Abstract: Convergence guarantees for optimization over bounded-rank matrices are delicate to obtain because the feasible set is a non-smooth and non-convex algebraic variety. Existing techniques include projected gradient descent, fixed-rank optimization (over the maximal-rank stratum), and the LR parameterization. They all lack either global guarantees (the ability to accumulate only at critical points) or fast local convergence (e.g., if the limit has non-maximal rank). We seek optimization algorithms that enjoy both.
  Khrulkov and Oseledets [2018] parameterize the bounded-rank variety via a desingularization to recast the optimization problem onto a smooth manifold. Building on their ideas, we develop a Riemannian geometry for this desingularization, also with care for numerical considerations. We use it to secure global convergence to critical points with fast local rates, for a large range of algorithms. On matrix completion tasks, we find that this approach is comparable to others, while enjoying better general-purpose theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14211v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Rebjock, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>Sparse Sub-gaussian Random Projections for Semidefinite Programming Relaxations</title>
      <link>https://arxiv.org/abs/2406.14249</link>
      <description>arXiv:2406.14249v1 Announce Type: new 
Abstract: Random projection, a dimensionality reduction technique, has been found useful in recent years for reducing the size of optimization problems. In this paper, we explore the use of sparse sub-gaussian random projections to approximate semidefinite programming (SDP) problems by reducing the size of matrix variables, thereby solving the original problem with much less computational effort. We provide some theoretical bounds on the quality of the projection in terms of feasibility and optimality that explicitly depend on the sparsity parameter of the projector. We investigate the performance of the approach for semidefinite relaxations appearing in polynomial optimization, with a focus on combinatorial optimization problems. In particular, we apply our method to the semidefinite relaxations of MAXCUT and MAX-2-SAT. We show that for large unweighted graphs, we can obtain a good bound by solving a projection of the semidefinite relaxation of MAXCUT. We also explore how to apply our method to find the stability number of four classes of imperfect graphs by solving a projection of the second level of the Lasserre Hierarchy. Overall, our computational experiments show that semidefinite programming problems appearing as relaxations of combinatorial optimization problems can be approximately solved using random projections as long as the number of constraints is not too large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14249v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Monse Guedes-Ayala, Pierre-Louis Poirion, Lars Schewe, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Inverse optimal control problem in the non autonomous linear-quadratic case</title>
      <link>https://arxiv.org/abs/2406.14270</link>
      <description>arXiv:2406.14270v1 Announce Type: new 
Abstract: Inverse optimal control problem emerges in different practical applications, where the goal is to design a cost function in order to approximate given optimal strategies of an expert. Typical application is in robotics for generation of human motions. In this paper we analyze a general class of non autonomous inverse linear quadratic problems. This class of problems is of particular interest because it arises as a linearization of a nonlinear problem around an optimal trajectory. The addressed questions are the injectivity of the inverse problem and the reconstruction. We show that the nonlinear problem admits the same characterization of the injectivity as the autonomous one. In the autonomous case we show moreover that the injectivity property is generic in the considered class. We also provide a numerical test of the reconstruction algorithm in the autonomous setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14270v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fr\'ed\'eric Jean, Sofya Maslovskaya</dc:creator>
    </item>
    <item>
      <title>Trim Turnpikes for Optimal Control Problems with Symmetries</title>
      <link>https://arxiv.org/abs/2406.14286</link>
      <description>arXiv:2406.14286v1 Announce Type: new 
Abstract: Motivated by mechanical systems with symmetries, we focus on optimal control problems possessing symmetries. Following recent works, which generalized the classical concept of static turnpike to manifold turnpike, we extend the exponential turnpike property to the exponential trim turnpike for control systems with symmetries induced by abelian or non-abelian groups. Our analysis is mainly based on the geometric reduction of control systems with symmetries. More concretely, we first reduce the control system on the quotient space and state the turnpike theorem for the reduced problem. Then we use the group properties to obtain the trim turnpike theorem for the full problem. Finally, we illustrate our results on the Kepler problem and the Rigid body problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14286v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kathrin Fla{\ss}kamp, Sofya Maslovskaya, Sina Ober-Bl\"obaum, Boris Wembe</dc:creator>
    </item>
    <item>
      <title>Symplectic Stiefel manifold: tractable metrics, second-order geometry and Newton's methods</title>
      <link>https://arxiv.org/abs/2406.14299</link>
      <description>arXiv:2406.14299v1 Announce Type: new 
Abstract: Optimization under the symplecticity constraint is an approach for solving various problems in quantum physics and scientific computing. Building on the results that this optimization problem can be transformed into an unconstrained problem on the symplectic Stiefel manifold, we construct geometric ingredients for Riemannian optimization with a new family of Riemannian metrics called tractable metrics and develop Riemannian Newton schemes. The newly obtained ingredients do not only generalize several existing results but also provide us with freedom to choose a suitable metric for each problem. To the best of our knowledge, this is the first try to develop the explicit second-order geometry and Newton's methods on the symplectic Stiefel manifold. For the Riemannian Newton method, we first consider novel operator-valued formulas for computing the Riemannian Hessian of a~cost function, which further allows the manifold to be endowed with a weighted Euclidean metric that can provide a preconditioning effect. We then solve the resulting Newton equation, as the central step of Newton's methods, directly via transforming it into a~saddle point problem followed by vectorization, or iteratively via applying any matrix-free iterative method either to the operator Newton equation or its saddle point formulation. Finally, we propose a hybrid Riemannian Newton optimization algorithm that enjoys both global convergence and quadratic/superlinear local convergence at the final stage. Various numerical experiments are presented to validate the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14299v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.SG</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Nguyen Thanh Son, Tatjana Stykel</dc:creator>
    </item>
    <item>
      <title>Fast Convergence to Second-Order Stationary Point through Random Subspace Optimization</title>
      <link>https://arxiv.org/abs/2406.14337</link>
      <description>arXiv:2406.14337v1 Announce Type: new 
Abstract: We propose the Random Subspace Homogenized Trust Region (RSHTR) method, which efficiently solves high-dimensional non-convex optimization problems by identifying descent directions within randomly selected subspaces. RSHTR provides the strongest theoretical guarantees among random subspace algorithms for non-convex optimization, achieving an $\varepsilon$-approximate first-order stationary point in $O(\varepsilon^{-3/2})$ iterations and converging locally at a linear rate. Furthermore, under rank-deficient conditions, RSHTR satisfies $\varepsilon$-approximate second-order necessary condition in $O(\varepsilon^{-3/2})$ iterations and exhibits a local quadratic convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14337v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rei Higuchi, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Learning rate adaptive stochastic gradient descent optimization methods: numerical simulations for deep learning methods for partial differential equations and convergence analyses</title>
      <link>https://arxiv.org/abs/2406.14340</link>
      <description>arXiv:2406.14340v1 Announce Type: new 
Abstract: It is known that the standard stochastic gradient descent (SGD) optimization method, as well as accelerated and adaptive SGD optimization methods such as the Adam optimizer fail to converge if the learning rates do not converge to zero (as, for example, in the situation of constant learning rates). Numerical simulations often use human-tuned deterministic learning rate schedules or small constant learning rates. The default learning rate schedules for SGD optimization methods in machine learning implementation frameworks such as TensorFlow and Pytorch are constant learning rates. In this work we propose and study a learning-rate-adaptive approach for SGD optimization methods in which the learning rate is adjusted based on empirical estimates for the values of the objective function of the considered optimization problem (the function that one intends to minimize). In particular, we propose a learning-rate-adaptive variant of the Adam optimizer and implement it in case of several neural network learning problems, particularly, in the context of deep learning approximation methods for partial differential equations such as deep Kolmogorov methods, physics-informed neural networks, and deep Ritz methods. In each of the presented learning problems the proposed learning-rate-adaptive variant of the Adam optimizer faster reduces the value of the objective function than the Adam optimizer with the default learning rate. For a simple class of quadratic minimization problems we also rigorously prove that a learning-rate-adaptive variant of the SGD optimization method converges to the minimizer of the considered minimization problem. Our convergence proof is based on an analysis of the laws of invariant measures of the SGD method as well as on a more general convergence analysis for SGD with random but predictable learning rates which we develop in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14340v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Dereich, Arnulf Jentzen, Adrian Riekert</dc:creator>
    </item>
    <item>
      <title>AGDA+: Proximal Alternating Gradient Descent Ascent Method With a Nonmonotone Adaptive Step-Size Search For Nonconvex Minimax Problems</title>
      <link>https://arxiv.org/abs/2406.14371</link>
      <description>arXiv:2406.14371v1 Announce Type: new 
Abstract: We consider double-regularized nonconvex-strongly concave (NCSC) minimax problems of the form $(P):\min_{x\in\mathcal{X}} \max_{y\in\mathcal{Y}}g(x)+f(x,y)-h(y)$, where $g$, $h$ are closed convex, $f$ is $L$-smooth in $(x,y)$ and strongly concave in $y$. We propose a proximal alternating gradient descent ascent method AGDA+ that can adaptively choose nonmonotone primal-dual stepsizes to compute an approximate stationary point for $(P)$ without requiring the knowledge of the global Lipschitz constant $L$. Using a nonmonotone step-size search (backtracking) scheme, AGDA+ stands out by its ability to exploit the local Lipschitz structure and eliminates the need for precise tuning of hyper-parameters. AGDA+ achieves the optimal iteration complexity of $\mathcal{O}(\epsilon^{-2})$ and it is the first step-size search method for NCSC minimax problems that require only $\mathcal{O}(1)$ calls to $\nabla f$ per backtracking iteration. The numerical experiments demonstrate its robustness and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14371v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Zhang, Qiushui Xu, Necdet Serhat Aybat</dc:creator>
    </item>
    <item>
      <title>Cross-Dimensional Mathematics: A Foundation For STP/STA</title>
      <link>https://arxiv.org/abs/2406.12920</link>
      <description>arXiv:2406.12920v1 Announce Type: cross 
Abstract: When investigating the set of matrices and vectors with mixed dimensions (MVMD), which are posed by cross-dimensional operators: semi-tensor product (STP) and semi-tensor addition (STA), the existing mathematical tools seem not very efficient. A new mathematical structure, called the mix-dimensional mathematics (MDM), is proposed. The MDM considered in this paper consists of three parts: hyper algebra, hyper geometry, and hyper Lie group/Lie algebra. Hyper algebra proposes some new algebraic structures such as hyper group, hyper ring, and hyper module over MVMDs. They have sets of classical groups, rings, and modules as their components and cross-dimensional connections among their components. Their basic properties are investigated. Hyper geometry starts from mixed dimensional Euclidian space, and hyper vector space. Then the hyper topological vector space, hyper inner product space, and hyper manifold are constructed. They have a joined cross-dimensional geometric structure. Finally, hyper metric space, topological hyper group and hyper Lie algebra are built gradually, and finally, their corresponding hyper Lie group is introduced. All these concepts are built over MVMDs, and to reach our purpose in addition to using existing STPs and STAs, a couple of most general STP and STA are introduced. Some existing structures/results about STPs/STAs have also been resumed and integrated into this MDM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12920v1</guid>
      <category>math.RA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daizhan Cheng</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Corporate Bond Trading: A Sell Side Perspective</title>
      <link>https://arxiv.org/abs/2406.12983</link>
      <description>arXiv:2406.12983v1 Announce Type: cross 
Abstract: A corporate bond trader in a typical sell side institution such as a bank provides liquidity to the market participants by buying/selling securities and maintaining an inventory. Upon receiving a request for a buy/sell price quote (RFQ), the trader provides a quote by adding a spread over a \textit{prevalent market price}. For illiquid bonds, the market price is harder to observe, and traders often resort to available benchmark bond prices (such as MarketAxess, Bloomberg, etc.). In \cite{Bergault2023ModelingLI}, the concept of \textit{Fair Transfer Price} for an illiquid corporate bond was introduced which is derived from an infinite horizon stochastic optimal control problem (for maximizing the trader's expected P\&amp;L, regularized by the quadratic variation). In this paper, we consider the same optimization objective, however, we approach the estimation of an optimal bid-ask spread quoting strategy in a data driven manner and show that it can be learned using Reinforcement Learning. Furthermore, we perform extensive outcome analysis to examine the reasonableness of the trained agent's behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12983v1</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Atkins, Ali Fathi, Sammy Assefa</dc:creator>
    </item>
    <item>
      <title>Accelerated Stochastic Min-Max Optimization Based on Bias-corrected Momentum</title>
      <link>https://arxiv.org/abs/2406.13041</link>
      <description>arXiv:2406.13041v1 Announce Type: cross 
Abstract: Lower-bound analyses for nonconvex strongly-concave minimax optimization problems have shown that stochastic first-order algorithms require at least $\mathcal{O}(\varepsilon^{-4})$ oracle complexity to find an $\varepsilon$-stationary point. Some works indicate that this complexity can be improved to $\mathcal{O}(\varepsilon^{-3})$ when the loss gradient is Lipschitz continuous. The question of achieving enhanced convergence rates under distinct conditions, remains unresolved. In this work, we address this question for optimization problems that are nonconvex in the minimization variable and strongly concave or Polyak-Lojasiewicz (PL) in the maximization variable. We introduce novel bias-corrected momentum algorithms utilizing efficient Hessian-vector products. We establish convergence conditions and demonstrate a lower iteration complexity of $\mathcal{O}(\varepsilon^{-3})$ for the proposed algorithms. The effectiveness of the method is validated through applications to robust logistic regression using real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13041v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyuan Cai, Sulaiman A. Alghunaim, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Enhancing supply chain security with automated machine learning</title>
      <link>https://arxiv.org/abs/2406.13166</link>
      <description>arXiv:2406.13166v1 Announce Type: cross 
Abstract: This study tackles the complexities of global supply chains, which are increasingly vulnerable to disruptions caused by port congestion, material shortages, and inflation. To address these challenges, we explore the application of machine learning methods, which excel in predicting and optimizing solutions based on large datasets. Our focus is on enhancing supply chain security through fraud detection, maintenance prediction, and material backorder forecasting. We introduce an automated machine learning framework that streamlines data analysis, model construction, and hyperparameter optimization for these tasks. By automating these processes, our framework improves the efficiency and effectiveness of supply chain security measures. Our research identifies key factors that influence machine learning performance, including sampling methods, categorical encoding, feature selection, and hyperparameter optimization. We demonstrate the importance of considering these factors when applying machine learning to supply chain challenges. Traditional mathematical programming models often struggle to cope with the complexity of large-scale supply chain problems. Our study shows that machine learning methods can provide a viable alternative, particularly when dealing with extensive datasets and complex patterns. The automated machine learning framework presented in this study offers a novel approach to supply chain security, contributing to the existing body of knowledge in the field. Its comprehensive automation of machine learning processes makes it a valuable contribution to the domain of supply chain management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13166v1</guid>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Lutfu S. Sua, Bahram Alidaee</dc:creator>
    </item>
    <item>
      <title>Measured-state conditioned recursive feasibility for stochastic model predictive control</title>
      <link>https://arxiv.org/abs/2406.13522</link>
      <description>arXiv:2406.13522v1 Announce Type: cross 
Abstract: In this paper, we address the problem of designing stochastic model predictive control (MPC) schemes for linear systems affected by unbounded disturbances. The contribution of the paper is twofold. First, motivated by the difficulty of guaranteeing recursive feasibility in this framework, due to the nonzero probability of violating chance-constraints in the case of unbounded noise, we introduce the novel definition of measured-state conditioned recursive feasibility in expectation. Second, we construct a stochastic MPC scheme, based on the introduction of ellipsoidal probabilistic reachable sets, which implements a closed-loop initialization strategy, i.e., the current measured-state is employed for initializing the optimization problem. This new scheme is proven to satisfy the novel definition of recursive feasibility, and its superiority with respect to open-loop initialization schemes, arising from the fact that one never neglects the information brought by the current measurement, is shown through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13522v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mirko Fiacchini, Martina Mammarella, Fabrizio Dabbene</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Infinite-Horizon Average-Reward MDPs with Multinomial Logistic Function Approximation</title>
      <link>https://arxiv.org/abs/2406.13633</link>
      <description>arXiv:2406.13633v1 Announce Type: cross 
Abstract: We study model-based reinforcement learning with non-linear function approximation where the transition function of the underlying Markov decision process (MDP) is given by a multinomial logistic (MNL) model. In this paper, we develop two algorithms for the infinite-horizon average reward setting. Our first algorithm \texttt{UCRL2-MNL} applies to the class of communicating MDPs and achieves an $\tilde{\mathcal{O}}(dD\sqrt{T})$ regret, where $d$ is the dimension of feature mapping, $D$ is the diameter of the underlying MDP, and $T$ is the horizon. The second algorithm \texttt{OVIFH-MNL} is computationally more efficient and applies to the more general class of weakly communicating MDPs, for which we show a regret guarantee of $\tilde{\mathcal{O}}(d^{2/5} \mathrm{sp}(v^*)T^{4/5})$ where $\mathrm{sp}(v^*)$ is the span of the associated optimal bias function.
  We also prove a lower bound of $\Omega(d\sqrt{DT})$ for learning communicating MDPs with MNL transitions of diameter at most $D$. Furthermore, we show a regret lower bound of $\Omega(dH^{3/2}\sqrt{K})$ for learning $H$-horizon episodic MDPs with MNL function approximation where $K$ is the number of episodes, which improves upon the best-known lower bound for the finite-horizon setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13633v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaehyun Park, Dabeen Lee</dc:creator>
    </item>
    <item>
      <title>A nonlocal approximation of the area in codimension two</title>
      <link>https://arxiv.org/abs/2406.13696</link>
      <description>arXiv:2406.13696v1 Announce Type: cross 
Abstract: For $s\in (0,1)$ we introduce a notion of fractional $s$-mass on $(n-2)$-dimensional closed, orientable surfaces in $\R^n$. Moreover, we prove its $\Gamma$-convergence, with respect to the flat topology, and pointwise convergence to the $(n-2)$-dimensional area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13696v1</guid>
      <category>math.DG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Caselli, Mattia Freguglia, Nicola Picenni</dc:creator>
    </item>
    <item>
      <title>Prescribed exponential stabilization of a one-layer neural network with delayed feedback: Insights in seizure prevention and neural control</title>
      <link>https://arxiv.org/abs/2406.13730</link>
      <description>arXiv:2406.13730v1 Announce Type: cross 
Abstract: This paper provides control-oriented delay-based modelling of a one-layer neural network of Hopfield-type subject to an external input designed as delayed feedback. The specificity of such a model is that it makes the considered neuron less susceptible to seizure caused by its inherent dynamic instability. This modelling exploits a recently set partial pole placement for linear functional differential equations, which relies on the coexistence of real spectral values, allowing the explicit prescription of the closed-loop solution's exponential decay. The proposed framework improves some pioneering and scarce results from the literature on the characterization of the exact solution's exponential decay when a simple real spectral value exists. Indeed, it improves neural stability when the inherent dynamic is stable and provides insights into the design of a one-layer neural network that can be stabilized exponentially with delayed feedback and with a prescribed decay rate regardless of whether the inherent neuron dynamic is stable or unstable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13730v1</guid>
      <category>math.SP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Islam Boussaada, Karim Trabelsi</dc:creator>
    </item>
    <item>
      <title>Exponential time differencing for matrix-valued dynamical systems</title>
      <link>https://arxiv.org/abs/2406.13761</link>
      <description>arXiv:2406.13761v1 Announce Type: cross 
Abstract: Matrix evolution equations occur in many applications, such as dynamical Lyapunov/Sylvester systems or Riccati equations in optimization and stochastic control, machine learning or data assimilation. In many cases, their tightest stability condition is coming from a linear term. Exponential time differencing (ETD) is known to produce highly stable numerical schemes by treating the linear term in an exact fashion. In particular, for stiff problems, ETD methods are a method of choice. We propose an extension of the class of ETD algorithms to matrix-valued dynamical equations. This allows us to produce highly efficient and stable integration schemes. We show their efficiency and applicability for a variety of real-world problems, from geophysical applications to dynamical problems in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13761v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nayef Shkeir, Tobias Sch\"afer, Tobias Grafke</dc:creator>
    </item>
    <item>
      <title>Symmetrically Fair Allocations of Indivisible Goods</title>
      <link>https://arxiv.org/abs/2406.13824</link>
      <description>arXiv:2406.13824v1 Announce Type: cross 
Abstract: We consider allocating indivisible goods with provable fairness guarantees that are satisfied regardless of which bundle of items each agent receives. Symmetrical allocations of this type are known to exist for divisible resources, such as consensus splitting of a cake into parts, each having equal value for all agents, ensuring that in any allocation of the cake slices, no agent would envy another. For indivisible goods, one analogous concept relaxes envy freeness to guarantee the existence of an allocation in which any bundle is worth as much as any other, up to the value of a bounded number of items from the other bundle. Previous work has studied the number of items that need to be removed. In this paper, we improve upon these bounds for the specific setting in which the number of bundles equals the number of agents.
  Concretely, we develop the theory of symmetrically envy free up to one good, or symEF1, allocations. We prove that a symEF1 allocation exists if the vertices of a related graph can be partitioned (colored) into as many independent sets as there are agents. This sufficient condition always holds for two agents, and for agents that have identical, disjoint, or binary valuations. We further prove conditions under which exponentially-many distinct symEF1 allocations exist. Finally, we perform computational experiments to study the incidence of symEF1 allocations as a function of the number of agents and items when valuations are drawn uniformly at random.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13824v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Johnston, Aleksandr M. Kazachkov</dc:creator>
    </item>
    <item>
      <title>A Catalyst Framework for the Quantum Linear System Problem via the Proximal Point Algorithm</title>
      <link>https://arxiv.org/abs/2406.13879</link>
      <description>arXiv:2406.13879v1 Announce Type: cross 
Abstract: Solving systems of linear equations is a fundamental problem, but it can be computationally intensive for classical algorithms in high dimensions. Existing quantum algorithms can achieve exponential speedups for the quantum linear system problem (QLSP) in terms of the problem dimension, but even such a theoretical advantage is bottlenecked by the condition number of the coefficient matrix. In this work, we propose a new quantum algorithm for QLSP inspired by the classical proximal point algorithm (PPA). Our proposed method can be viewed as a meta-algorithm that allows inverting a modified matrix via an existing \texttt{QLSP\_solver}, thereby directly approximating the solution vector instead of approximating the inverse of the coefficient matrix. By carefully choosing the step size $\eta$, the proposed algorithm can effectively precondition the linear system to mitigate the dependence on condition numbers that hindered the applicability of previous approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13879v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junhyung Lyle Kim, Nai-Hui Chia, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Adaptive Batch Size Strategies for Distributed Local Gradient Methods</title>
      <link>https://arxiv.org/abs/2406.13936</link>
      <description>arXiv:2406.13936v1 Announce Type: cross 
Abstract: Modern deep neural networks often require distributed training with many workers due to their large size. As worker numbers increase, communication overheads become the main bottleneck in data-parallel minibatch stochastic gradient methods with per-iteration gradient synchronization. Local gradient methods like Local SGD reduce communication by only syncing after several local steps. Despite understanding their convergence in i.i.d. and heterogeneous settings and knowing the importance of batch sizes for efficiency and generalization, optimal local batch sizes are difficult to determine. We introduce adaptive batch size strategies for local gradient methods that increase batch sizes adaptively to reduce minibatch gradient variance. We provide convergence guarantees under homogeneous data conditions and support our claims with image classification experiments, demonstrating the effectiveness of our strategies in training and generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13936v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Weijian Li, Chenwei Xu, Han Liu, Mladen Kolar</dc:creator>
    </item>
    <item>
      <title>Tracking solutions of time-varying variational inequalities</title>
      <link>https://arxiv.org/abs/2406.14059</link>
      <description>arXiv:2406.14059v1 Announce Type: cross 
Abstract: Tracking the solution of time-varying variational inequalities is an important problem with applications in game theory, optimization, and machine learning. Existing work considers time-varying games or time-varying optimization problems. For strongly convex optimization problems or strongly monotone games, these results provide tracking guarantees under the assumption that the variation of the time-varying problem is restrained, that is, problems with a sublinear solution path.  In this work we extend existing results in two ways:  In our first result, we provide tracking bounds for (1) variational inequalities with a sublinear solution path but not necessarily monotone functions, and (2) for periodic time-varying variational inequalities that do not necessarily have a sublinear solution path-length. Our second main contribution is an extensive study of the convergence behavior and trajectory of discrete dynamical systems of periodic time-varying VI. We show that these systems can exhibit provably chaotic behavior or can converge to the solution. Finally, we illustrate our theoretical results with experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14059v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H\'edi Hadiji (UvA), Sarah Sachs (UvA), Crist\'obal Guzm\'an (UC)</dc:creator>
    </item>
    <item>
      <title>Multi-objective optimization of the magnetic wiping process in dip-coating</title>
      <link>https://arxiv.org/abs/2406.14110</link>
      <description>arXiv:2406.14110v1 Announce Type: cross 
Abstract: Electromagnetic wiping systems allow to pre-meter the coating thickness of the liquid metal on a moving substrate. These systems have the potential to provide a more uniform coating and significantly higher production rates compared to pneumatic wiping, but they require substantially larger amounts of energy. This work presents a multi-objective optimization accounting for (1) maximal wiping efficiency (2) maximal smoothness of the wiping meniscus, and (3) minimal Joule heating. We present the Pareto front, identifying the best wiping conditions given a set of weights for the three competing objectives. The optimization was based on a 1D steady-state integral model, whose prediction scales according to the Hartmann number (Ha). The optimization uses a multi-gradient approach, with gradients computed with a combination of finite differences and variational methods. The results show that the wiping efficiency depends solely on Ha and not the magnetic field distribution. Moreover, we show that the liquid thickness becomes insensitive to the intensity of the magnetic field above a certain threshold and that the current distribution (hence the Joule heating) is mildly affected by the magnetic field's intensity and shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14110v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Fabio Pino, Benoit Scheid, Miguel Alfonso Mendez</dc:creator>
    </item>
    <item>
      <title>Proximal Interacting Particle Langevin Algorithms</title>
      <link>https://arxiv.org/abs/2406.14292</link>
      <description>arXiv:2406.14292v1 Announce Type: cross 
Abstract: We introduce a class of algorithms, termed Proximal Interacting Particle Langevin Algorithms (PIPLA), for inference and learning in latent variable models whose joint probability density is non-differentiable. Leveraging proximal Markov chain Monte Carlo (MCMC) techniques and the recently introduced interacting particle Langevin algorithm (IPLA), we propose several variants within the novel proximal IPLA family, tailored to the problem of estimating parameters in a non-differentiable statistical model. We prove nonasymptotic bounds for the parameter estimates produced by multiple algorithms in the strongly log-concave setting and provide comprehensive numerical experiments on various models to demonstrate the effectiveness of the proposed methods. In particular, we demonstrate the utility of the proposed family of algorithms on a toy hierarchical example where our assumptions can be checked, as well as on the problems of sparse Bayesian logistic regression, sparse Bayesian neural network, and sparse matrix completion. Our theory and experiments together show that PIPLA family can be the de facto choice for parameter estimation problems in latent variable models for non-differentiable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14292v1</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paula Cordero Encinar, Francesca R. Crucinio, O. Deniz Akyildiz</dc:creator>
    </item>
    <item>
      <title>Promise of Graph Sparsification and Decomposition for Noise Reduction in QAOA: Analysis for Trapped-Ion Compilations</title>
      <link>https://arxiv.org/abs/2406.14330</link>
      <description>arXiv:2406.14330v1 Announce Type: cross 
Abstract: We develop new approximate compilation schemes that significantly reduce the expense of compiling the Quantum Approximate Optimization Algorithm (QAOA) for solving the Max-Cut problem. Our main focus is on compilation with trapped-ion simulators using Pauli-$X$ operations and all-to-all Ising Hamiltonian $H_\text{Ising}$ evolution generated by Molmer-Sorensen or optical dipole force interactions, though some of our results also apply to standard gate-based compilations. Our results are based on principles of graph sparsification and decomposition; the former reduces the number of edges in a graph while maintaining its cut structure, while the latter breaks a weighted graph into a small number of unweighted graphs. Though these techniques have been used as heuristics in various hybrid quantum algorithms, there have been no guarantees on their performance, to the best of our knowledge. This work provides the first provable guarantees using sparsification and decomposition to improve quantum noise resilience and reduce quantum circuit complexity.
  For quantum hardware that uses edge-by-edge QAOA compilations, sparsification leads to a direct reduction in circuit complexity. For trapped-ion quantum simulators implementing all-to-all $H_\text{Ising}$ pulses, we show that for a $(1-\epsilon)$ factor loss in the Max-Cut approximation ($\epsilon&gt;0)$, our compilations improve the (worst-case) number of $H_\text{Ising}$ pulses from $O(n^2)$ to $O(n\log(n/\epsilon))$ and the (worst-case) number of Pauli-$X$ bit flips from $O(n^2)$ to $O\left(\frac{n\log(n/\epsilon)}{\epsilon^2}\right)$ for $n$-node graphs. We demonstrate significant reductions in noise are obtained in our new compilation approaches using theory and numerical calculations for trapped-ion hardware. We anticipate these approximate compilation techniques will be useful tools in a variety of future quantum computing experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14330v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jai Moondra, Philip C. Lotshaw, Greg Mohler, Swati Gupta</dc:creator>
    </item>
    <item>
      <title>Constrained $L^p$ Approximation of Shape Tensors and its Role for the Determination of Shape Gradients</title>
      <link>https://arxiv.org/abs/2406.14405</link>
      <description>arXiv:2406.14405v1 Announce Type: cross 
Abstract: This paper extends our earlier work [arXiv:2309.13595] on the $L^p$ approximation of the shape tensor by Laurain and Sturm. In particular, it is shown that the weighted $L^p$ distance to an affine space of admissible symmetric shape tensors satisfying a divergence constraint provides the shape gradient with respect to the $L^{p^\ast}$-norm (where $1/p + 1/p^\ast = 1$) of the elastic strain associated with the shape deformation. This approach allows the combination of two ingredients which have already been used successfully in numerical shape optimization: (i) departing from the Hilbert space framework towards the Lipschitz topology approximated by $W^{1,p^\ast}$ with $p^\ast &gt; 2$ and (ii) using the symmetric rather than the full gradient to define the norm. Similarly to [arXiv:2309.13595], the $L^p$ distance measures the shape stationarity by means of the dual norm of the shape derivative with respect to the above-mentioned $L^{p^\ast}$-norm of the elastic strain. Moreover, the Lagrange multiplier for the momentum balance constraint constitute the steepest descent deformation with respect to this norm. The finite element realization of this approach is done using the weakly symmetric PEERS element and its three-dimensional counterpart, respectively. The resulting piecewise constant approximation for the Lagrange multiplier is reconstructed to a shape gradient in $W^{1,p^\ast}$ and used in an iterative procedure towards the optimal shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14405v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Hetzel, Gerhard Starke</dc:creator>
    </item>
    <item>
      <title>Communication-efficient Vertical Federated Learning via Compressed Error Feedback</title>
      <link>https://arxiv.org/abs/2406.14420</link>
      <description>arXiv:2406.14420v1 Announce Type: cross 
Abstract: Communication overhead is a known bottleneck in federated learning (FL). To address this, lossy compression is commonly used on the information communicated between the server and clients during training. In horizontal FL, where each client holds a subset of the samples, such communication-compressed training methods have recently seen significant progress. However, in their vertical FL counterparts, where each client holds a subset of the features, our understanding remains limited. To address this, we propose an error feedback compressed vertical federated learning (EFVFL) method to train split neural networks. In contrast with previous communication-compressed methods for vertical FL, EFVFL does not require a vanishing compression error for the gradient norm to converge to zero for smooth nonconvex problems. By leveraging error feedback, our method can achieve a $\mathcal{O}(1/T)$ convergence rate in the full-batch case, improving over the state-of-the-art $\mathcal{O}(1/\sqrt{T})$ rate under $\mathcal{O}(1/\sqrt{T})$ compression error, and matching the rate of uncompressed methods. Further, when the objective function satisfies the Polyak-{\L}ojasiewicz inequality, our method converges linearly. In addition to improving convergence rates, our method also supports the use of private labels. Numerical experiments show that EFVFL significantly improves over the prior art, confirming our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14420v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Valdeira, Jo\~ao Xavier, Cl\'audia Soares, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Tradeoffs between convergence rate and noise amplification for momentum-based accelerated optimization algorithms</title>
      <link>https://arxiv.org/abs/2209.11920</link>
      <description>arXiv:2209.11920v3 Announce Type: replace 
Abstract: We study momentum-based first-order optimization algorithms in which the iterations utilize information from the two previous steps and are subject to an additive white noise. This setup uses noise to account for uncertainty in either gradient evaluation or iteration updates, and it includes Polyak's heavy-ball and Nesterov's accelerated methods as special cases. For strongly convex quadratic problems, we use the steady-state variance of the error in the optimization variable to quantify noise amplification and identify fundamental stochastic performance tradeoffs. Our approach utilizes the Jury stability criterion to provide a novel geometric characterization of conditions for linear convergence, and it reveals the relation between the noise amplification and convergence rate as well as their dependence on the condition number and the constant algorithmic parameters. This geometric insight leads to simple alternative proofs of standard convergence results and allows us to establish ``uncertainty principle'' of strongly convex optimization: for the two-step momentum method with linear convergence rate, the lower bound on the product between the settling time and noise amplification scales quadratically with the condition number. Our analysis also identifies a key difference between the gradient and iterate noise models: while the amplification of gradient noise can be made arbitrarily small by sufficiently decelerating the algorithm, the best achievable variance for the iterate noise model increases linearly with the settling time in the decelerating regime. Finally, we introduce two parameterized families of algorithms that strike a balance between noise amplification and settling time while preserving order-wise Pareto optimality for both noise models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11920v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hesameddin Mohammadi, Meisam Razaviyayn, Mihailo R. Jovanovi\'c</dc:creator>
    </item>
    <item>
      <title>A mechanism of three-dimensional quadratic termination for the gradient method with applications</title>
      <link>https://arxiv.org/abs/2212.07255</link>
      <description>arXiv:2212.07255v2 Announce Type: replace 
Abstract: Recent studies show that the two-dimensional quadratic termination property has great potential in improving performance of the gradient method. However, it is not clear whether higher-dimensional quadratic termination leads further benefits. In this paper, we provide an affirmative answer by introducing a mechanism of three-dimensional quadratic termination for the gradient method. A novel stepsize is derived from the mechanism such that a family of delayed gradient methods equipping with the novel stepsize have the three-dimensional quadratic termination property. When applied to the Barzilai--Borwein (BB) method, the novel stepsize does not require the use of any exact line search or the Hessian, and can be computed by stepsizes and gradient norms in previous iterations. Using long BB steps and some short steps associated with the novel stepsize in an adaptive manner, we develop an efficient gradient method for quadratic optimization and further extend it to general unconstrained optimization. Numerical experiments show that the three-dimensional quadratic termination property can significantly improve performance of the BB method, and the proposed method outperforms gradient methods that use stepsizes with the two-dimensional quadratic termination property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.07255v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yakui Huang, Yu-Hong Dai, Xin-Wei Liu</dc:creator>
    </item>
    <item>
      <title>Convergence Rate Bounds for the Mirror Descent Method: IQCs, Popov Criterion and Bregman Divergence</title>
      <link>https://arxiv.org/abs/2304.03886</link>
      <description>arXiv:2304.03886v3 Announce Type: replace 
Abstract: This paper presents a comprehensive convergence analysis for the mirror descent (MD) method, a widely used algorithm in convex optimization. The key feature of this algorithm is that it provides a generalization of classical gradient-based methods via the use of generalized distance-like functions, which are formulated using the Bregman divergence. Establishing convergence rate bounds for this algorithm is in general a non-trivial problem due to the lack of monotonicity properties in the composite nonlinearities involved. In this paper, we show that the Bregman divergence from the optimal solution, which is commonly used as a Lyapunov function for this algorithm, is a special case of Lyapunov functions that follow when the Popov criterion is applied to an appropriate reformulation of the MD dynamics. This is then used as a basis to construct an integral quadratic constraint (IQC) framework through which convergence rate bounds with reduced conservatism can be deduced. We also illustrate via examples that the convergence rate bounds derived can be tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03886v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Khaled Laib, Takeshi Hatanaka, Ioannis Lestas</dc:creator>
    </item>
    <item>
      <title>Distributed accelerated proximal conjugate gradient methods for multi-agent constrained optimization problems</title>
      <link>https://arxiv.org/abs/2306.04230</link>
      <description>arXiv:2306.04230v2 Announce Type: replace 
Abstract: The purpose of this paper is to introduce two new classes of accelerated distributed proximal conjugate gradient algorithms for multi-agent constrained optimization problems; given as minimization of a function decomposed as a sum of M number of smooth and M number of nonsmooth functions over the common fixed points of M number of nonlinear mappings. Exploiting the special properties of the cost component function of the objective function and the nonlinear mapping of the constraint problem of each agent, a new inertial accelerated incremental and parallel computing distributed algorithms will be presented based on the combinations of computations of proximal, conjugate gradient and Halpern methods. Some numerical experiments and comparisons are given to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04230v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anteneh Getachew Gebrie</dc:creator>
    </item>
    <item>
      <title>Linearizing Binary Optimization Problems Using Variable Posets for Ising Machines</title>
      <link>https://arxiv.org/abs/2307.05125</link>
      <description>arXiv:2307.05125v2 Announce Type: replace 
Abstract: Ising machines are next-generation computers expected to efficiently sample near-optimal solutions of combinatorial optimization problems. Combinatorial optimization problems are modeled as quadratic unconstrained binary optimization (QUBO) problems to apply an Ising machine. However, current state-of-the-art Ising machines still often fail to output near-optimal solutions due to the complicated energy landscape of QUBO problems. Furthermore, the physical implementation of Ising machines severely restricts the size of QUBO problems to be input as a result of limited hardware graph structures. In this study, we take a new approach to these challenges by injecting auxiliary penalties preserving the optimum, which reduces quadratic terms in QUBO objective functions. The process simultaneously simplifies the energy landscape of QUBO problems, allowing the search for near-optimal solutions, and makes QUBO problems sparser, facilitating encoding into Ising machines with restriction on the hardware graph structure. We propose linearization of QUBO problems using variable posets as an outcome of the approach. By applying the proposed method to synthetic QUBO instances and to multi-dimensional knapsack problems, we empirically validate the effects on enhancing minor-embedding of QUBO problems and the performance of Ising machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05125v2</guid>
      <category>math.OC</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TETC.2024.3403871</arxiv:DOI>
      <dc:creator>Kentaro Ohno, Nozomu Togawa</dc:creator>
    </item>
    <item>
      <title>Inverse Optimization for Routing Problems</title>
      <link>https://arxiv.org/abs/2307.07357</link>
      <description>arXiv:2307.07357v3 Announce Type: replace 
Abstract: We propose a method for learning decision-makers' behavior in routing problems using Inverse Optimization (IO). The IO framework falls into the supervised learning category and builds on the premise that the target behavior is an optimizer of an unknown cost function. This cost function is to be learned through historical data, and in the context of routing problems, can be interpreted as the routing preferences of the decision-makers. In this view, the main contributions of this study are to propose an IO methodology with a hypothesis function, loss function, and stochastic first-order algorithm tailored to routing problems. We further test our IO approach in the Amazon Last Mile Routing Research Challenge, where the goal is to learn models that replicate the routing preferences of human drivers, using thousands of real-world routing examples. Our final IO-learned routing model achieves a score that ranks 2nd compared with the 48 models that qualified for the final round of the challenge. Our examples and results showcase the flexibility and real-world potential of the proposed IO methodology to learn from decision-makers' decisions in routing problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07357v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Zattoni Scroccaro, Piet van Beek, Peyman Mohajerin Esfahani, Bilge Atasoy</dc:creator>
    </item>
    <item>
      <title>Convex semi-infinite programming algorithms with inexact separation oracles</title>
      <link>https://arxiv.org/abs/2307.14181</link>
      <description>arXiv:2307.14181v2 Announce Type: replace 
Abstract: Solving convex Semi-Infinite Programming (SIP) problems is challenging when the separation problem, i.e., the problem of finding the most violated constraint, is computationally hard. We propose to tackle this difficulty by solving the separation problem approximately, i.e., by using an inexact oracle. Our focus lies in two algorithms for SIP, namely the Cutting-Planes (CP) and the Inner-Outer Approximation (IOA) algorithms. We prove the CP convergence rate to be in O(1/k), where k is the number of calls to the limited-accuracy oracle, if the objective function is strongly convex. Compared to the CP algorithm, the advantage of the IOA algorithm is the feasibility of its iterates. In the case of a semi-infinite program with Quadratically Constrained Quadratic Programming separation problem, we prove the convergence of the IOA algorithm toward an optimal solution of the SIP problem despite the oracle's inexactness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14181v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Oustry, Martina Cerulli</dc:creator>
    </item>
    <item>
      <title>Time-inconsistent mean-field stopping problems: A regularized equilibrium approach</title>
      <link>https://arxiv.org/abs/2311.00381</link>
      <description>arXiv:2311.00381v2 Announce Type: replace 
Abstract: This paper studies the mean-field Markov decision process (MDP) with the centralized stopping under the non-exponential discount. The problem differs fundamentally from most existing studies on mean-field optimal control/stopping due to its time inconsistency by nature. We look for the subgame perfect relaxed equilibria, namely the randomized stopping policies that satisfy the time-consistent planning with future selves from the perspective of the social planner. On the other hand, unlike many previous studies on time-inconsistent stopping where the decreasing impatience plays a key role, we are interested in the general discount function without imposing any conditions. As a result, the study on the relaxed equilibrium becomes necessary as the pure-strategy equilibrium may not exist in general. We formulate relaxed equilibria as fixed points of a complicated operator, whose existence is challenging by a direct method. To overcome the obstacles, we first introduce the auxiliary problem under the entropy regularization on the randomized policy and the discount function, and establish the existence of the regularized equilibria as fixed points to an auxiliary operator via Schauder fixed point theorem. Next, we show that the regularized equilibrium converges as the regularization parameter $\lambda$ tends to $0$ and the limit corresponds to a fixed point to the original operator, and hence is a relaxed equilibrium. We also establish some connections between the mean-field MDP and the N-agent MDP when $N$ is sufficiently large in our time-inconsistent setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00381v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Yu, Fengyi Yuan</dc:creator>
    </item>
    <item>
      <title>ALEXR: An Optimal Single-Loop Algorithm for Convex Finite-Sum Coupled Compositional Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2312.02277</link>
      <description>arXiv:2312.02277v4 Announce Type: replace 
Abstract: This paper revisits a class of convex Finite-Sum Coupled Compositional Stochastic Optimization (cFCCO) problems with many applications, including group distributionally robust optimization (GDRO), learning with imbalanced data, reinforcement learning, and learning to rank. To better solve these problems, we introduce an efficient single-loop primal-dual block-coordinate proximal algorithm, dubbed ALEXR. This algorithm leverages block-coordinate stochastic mirror ascent updates for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO. Finally, we present lower complexity bounds to demonstrate that the convergence rates of ALEXR are optimal among first-order block-coordinate stochastic algorithms for the considered class of cFCCO problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02277v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bokun Wang, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Conjugate gradient methods without line search for multiobjective optimization</title>
      <link>https://arxiv.org/abs/2312.02461</link>
      <description>arXiv:2312.02461v2 Announce Type: replace 
Abstract: This paper addresses an unconstrained multiobjective optimization problem where two or more continuously differentiable functions have to be minimized. We delve into the conjugate gradient methods proposed by Lucambio P\'{e}rez and Prudente (SIAM J Optim, 28(3): 2690--2720, 2018) for this type of problem. Instead of the Wolfe-type line search procedure used in their work, we employ a fixed stepsize formula (or no-line-search scheme), which can mitigate the selection pressure caused by multiple inequalities and avoid the computational cost associated with objective function evaluations in specific applications. The no-line-search scheme is utilized to derive the condition of Zoutendijk's type. Global convergence encompasses the vector extensions of Fletcher-Reeves, conjugate descent, Dai-Yuan, Polak-Ribi\`{e}re-Polyak and Hestenes-Stiefel parameters, subject to certain mild assumptions. Additionally, numerical experiments are conducted to demonstrate the practical performance of the proposed stepsize rule, and comparative analyses are made with the multiobjective steepest descent methods using the Armijo line search and the multiobjective conjugate gradient methods using the Wolfe-type line search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02461v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Chen, Yong Zhao, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Nonlinear Inverse Optimal Transport: Identifiability of the Transport Cost from its Marginals and Optimal Values</title>
      <link>https://arxiv.org/abs/2312.05843</link>
      <description>arXiv:2312.05843v2 Announce Type: replace 
Abstract: The inverse optimal transport problem is to find the underlying cost function from the knowledge of optimal transport plans. While this amounts to solving a linear inverse problem, in this work we will be concerned with the nonlinear inverse problem to identify the cost function when only a set of marginals and its corresponding optimal values are given. We focus on absolutely continuous probability distributions with respect to the $d$-dimensional Lebesgue measure and classes of concave and convex cost functions. Our main result implies that the cost function is uniquely determined from the union of the ranges of the gradients of the optimal potentials. Since, in general, the optimal potentials may not be observed, we derive sufficient conditions for their identifiability - if an open set of marginals is observed, the optimal potentials are then identified via the value of the optimal costs. We conclude with a more in-depth study of this problem in the univariate case, where an explicit representation of the transport plan is available. Here, we link the notion of identifiability of the cost function with that of statistical completeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05843v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Michel Groppe, Axel Munk</dc:creator>
    </item>
    <item>
      <title>A divergence-based condition to ensure quantile improvement in black-box global optimization</title>
      <link>https://arxiv.org/abs/2402.01277</link>
      <description>arXiv:2402.01277v2 Announce Type: replace 
Abstract: Black-box global optimization aims at minimizing an objective function whose analytical form is not known. To do so, many state-of-the-art methods rely on sampling-based strategies, where sampling distributions are built in an iterative fashion, so that their mass concentrate where the objective function is low. Despite empirical success, the theoretical study of these methods remains difficult. In this work, we introduce a new framework, based on divergence-decrease conditions, to study and design black-box global optimization algorithms. Our approach allows to establish and quantify the improvement of proposals at each iteration, in terms of expected value or quantile of the objective. We show that the information-geometric optimization approach fits within our framework, yielding a new approach for its analysis. We also establish proposal improvement results for two novel algorithms, one related with the cross-entropy approach with mixture models, and another one using heavy-tailed sampling proposal distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01277v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Guilmeau, Emilie Chouzenoux, V\'ictor Elvira</dc:creator>
    </item>
    <item>
      <title>Quantitative asymptotic regularity of the VAM iteration with error terms for m-accretive operators in Banach spaces</title>
      <link>https://arxiv.org/abs/2402.17947</link>
      <description>arXiv:2402.17947v3 Announce Type: replace 
Abstract: In this paper we obtain, by using proof mining methods, quantitative results on the asymptotic regularity of the viscosity approximation method (VAM) with error terms for m-accretive operators in Banach spaces. For concrete instances of the parameter sequences, linear rates are computed by applying a lemma due to Sabach and Shtern.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17947v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Firmino, Laurentiu Leustean</dc:creator>
    </item>
    <item>
      <title>Estimates of the Kolmogorov n-width for nonlinear transformations with application to distributed-parameter control systems</title>
      <link>https://arxiv.org/abs/2403.06029</link>
      <description>arXiv:2403.06029v2 Announce Type: replace 
Abstract: This paper aims at characterizing the approximability of bounded sets in the range of nonlinear operators in Banach spaces by finite-dimensional linear varieties. In particular, the class of operators we consider includes the endpoint maps of nonlinear distributed-parameter control systems. We describe the relationship between the Kolmogorov n-width of a bounded subset and the width of its image under an essentially nonlinear transformation. We propose explicit estimates of the n-width in the space of images in terms of the affine part of the corresponding operator and the width of its nonlinear perturbation. These $n$-width estimates enable us to describe the reachable sets for infinite-dimensional bilinear control systems, with applications to controlling the Euler-Bernoulli beam using a contraction force and to a single-input Schr\"odinger equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06029v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Lihong Feng, Peter Benner</dc:creator>
    </item>
    <item>
      <title>Adaptive generalized conditional gradient method for multiobjective optimization</title>
      <link>https://arxiv.org/abs/2404.04174</link>
      <description>arXiv:2404.04174v2 Announce Type: replace 
Abstract: In this paper, we propose a generalized conditional gradient method for multiobjective optimization, which can be viewed as an improved extension of the classical Frank-Wolfe (conditional gradient) method for single-objective optimization. The proposed method works for both constrained and unconstrained benchmark multiobjective optimization problems, where the objective function is the summation of a smooth function and a possibly nonsmooth convex function. The method combines the so-called normalized descent direction as an adaptive procedure and the line search technique. We prove the convergence of the algorithm with respect to Pareto optimality under mild assumptions. The iteration complexity for obtaining an approximate Pareto critical point and the convergence rate in terms of a merit function is also analyzed. Finally, we report some numerical results, which demonstrate the feasibility and competitiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04174v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anteneh Getachew Gebrie, Ellen Hidemi Fukuda</dc:creator>
    </item>
    <item>
      <title>Approximability of the Containment Problem for Zonotopes and Ellipsotopes</title>
      <link>https://arxiv.org/abs/2404.11185</link>
      <description>arXiv:2404.11185v2 Announce Type: replace 
Abstract: The zonotope containment problem, i.e., whether one zonotope is contained in another, is a central problem in control theory. Applications include detecting faults and robustifying controllers by computing invariant sets, and obtain fixed points in reachability analysis. Despite the inherent co-NP-hardness of this problem, an approximation algorithm developed by S. Sadraddini and R. Tedrake has gained widespread recognition for its swift execution and consistent reliability in practice. In our study, we substantiate the precision of the algorithm with a definitive proof, elucidating the empirical accuracy observed in practice. Our proof hinges on establishing a connection between the containment problem and the computation of matrix norms, thereby enabling the extension of the approximation algorithm to encompass ellipsotopes -- a broader class of sets derived from zonotopes. We also explore the computational complexity of the ellipsotope containment problem with a focus on approximability. Finally, we present new methods to compute safe sets for linear dynamical systems, demonstrating the practical relevance of approximating the ellipsotope containment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11185v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Kulmburg, Lukas Sch\"afer, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>Stable Phase Retrieval with Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.10754</link>
      <description>arXiv:2405.10754v2 Announce Type: replace 
Abstract: In this paper, we aim to reconstruct an n-dimensional real vector from m phaseless measurements corrupted by an additive noise. We extend the noiseless framework developed in [15], based on mirror descent (or Bregman gradient descent), to deal with noisy measurements and prove that the procedure is stable to (small enough) additive noise. In the deterministic case, we show that mirror descent converges to a critical point of the phase retrieval problem, and if the algorithm is well initialized and the noise is small enough, the critical point is near the true vector up to a global sign change. When the measurements are i.i.d Gaussian and the signal-to-noise ratio is large enough, we provide global convergence guarantees that ensure that with high probability, mirror descent converges to a global minimizer near the true vector (up to a global sign change), as soon as the number of measurements m is large enough. The sample complexity bound can be improved if a spectral method is used to provide a good initial guess. We complement our theoretical study with several numerical results showing that mirror descent is both a computationally and statistically efficient scheme to solve the phase retrieval problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10754v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Jacques Godeme, Jalal Fadili, Claude Amra, Myriam Zerrad</dc:creator>
    </item>
    <item>
      <title>The Boolean polynomial polytope with multiple choice constraints</title>
      <link>https://arxiv.org/abs/2405.14207</link>
      <description>arXiv:2405.14207v2 Announce Type: replace 
Abstract: We consider a class of $0$-$1$ polynomial programming termed multiple choice polynomial programming (MCPP) where the constraint requires exact one component per subset of the partition to be $1$ after all the entries are partitioned. Compared to the unconstrained counterpart, there are few polyhedral studies of MCPP in general form. This paper serves as the first attempt to propose a polytope associated with a hypergraph to study MCPP, which is the convex hull of $0$-$1$ vectors satisfying multiple choice constraints and production constraints. With the help of the decomposability property, we obtain an explicit half-space representation of the MCPP polytope when the underlying hypergraph is $\alpha$-acyclic by induction on the number of hyperedges, which is an analogy of the acyclicity results on the multilinear polytope by Del Pia and Khajavirad (SIAM J Optim 28 (2018) 1049) when the hypergraph is $\gamma$-acyclic. We also present a necessary and sufficient condition for the inequalities lifted from the facet-inducing ones for the multilinear polytope to be still facet-inducing for the MCPP polytope. This result covers the particular cases by B\"armann, Martin and Schneider (SIAM J Optim 33 (2023) 2909).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14207v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sihong Shao, Yishan Wu</dc:creator>
    </item>
    <item>
      <title>On the Convergence of the Sinkhorn-Knopp Algorithm with Sparse Cost Matrices</title>
      <link>https://arxiv.org/abs/2405.20528</link>
      <description>arXiv:2405.20528v3 Announce Type: replace 
Abstract: Matrix scaling problems with sparse cost matrices arise frequently in various domains, such as optimal transport, image processing, and machine learning. The Sinkhorn-Knopp algorithm is a popular iterative method for solving these problems, but its convergence properties in the presence of sparsity have not been thoroughly analyzed. This paper presents a theoretical analysis of the convergence rate of the Sinkhorn-Knopp algorithm specifically for sparse cost matrices. We derive novel bounds on the convergence rate that explicitly depend on the sparsity pattern and the degree of nonsparsity of the cost matrix. These bounds provide new insights into the behavior of the algorithm and highlight the potential for exploiting sparsity to develop more efficient solvers. We also explore connections between our sparse convergence results and existing convergence results for dense matrices, showing that our bounds generalize the dense case. Our analysis reveals that the convergence rate improves as the matrix becomes less sparse and as the minimum entry of the cost matrix increases relative to its maximum entry. These findings have important practical implications, suggesting that the Sinkhorn-Knopp algorithm may be particularly well-suited for large-scale matrix scaling problems with sparse cost matrices arising in real-world applications. Future research directions include investigating tighter bounds based on more sophisticated sparsity patterns, developing algorithm variants that actively exploit sparsity, and empirically validating the benefits of our theoretical results on real-world datasets. This work advances our understanding of the Sinkhorn-Knopp algorithm for an important class of matrix scaling problems and lays the foundation for designing more efficient and scalable solutions in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20528v3</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Rafael Espinosa Mena</dc:creator>
    </item>
    <item>
      <title>Strong asymptotic convergence of an inertial primal-dual dynamical system with a slow damping controlled by a Tikhonov regularization term</title>
      <link>https://arxiv.org/abs/2406.08836</link>
      <description>arXiv:2406.08836v2 Announce Type: replace 
Abstract: We propose an inertial primal-dual dynamical system with a slow damping $\frac{\alpha}{t^q}$ controlled by a Tikhonov regularization term, where the inertial term is introduced only for the primal variable, for the linearly constrained convex optimization problem in Hilbert spaces. Under a suitable assumption on the underlying parameters, by a Lyapunov analysis approach, we prove the strong convergence of the trajectory of the proposed system to the minimal norm primal-dual solution of the problem, along with convergence rate results for the primal-dual gap, the objective residual and the feasibility violation. In Section 4, we perform some numerical experiments to illustrate the theoretical results. Finally, we give a conclusion in Section 5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08836v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting-Ting Zhu, Rong Hu, Ya-Ping Fang</dc:creator>
    </item>
    <item>
      <title>On Convergence and Rate of Convergence of Policy Improvement Algorithms</title>
      <link>https://arxiv.org/abs/2406.10959</link>
      <description>arXiv:2406.10959v2 Announce Type: replace 
Abstract: In this paper we provide a simple proof from scratch for the convergence of Policy Improvement Algorithm (PIA) for a continuous time entropy-regularized stochastic control problem. Such convergence has been established by Huang-Wang-Zhou(2023) by using sophisticated PDE estimates for the iterative PDEs involved in the PIA. Our approach builds on some Feynman-Kac type probabilistic representation formulae for solutions of PDEs and their derivatives. Moreover, in the infinite horizon model with a large discount factor and in the finite horizon model, we obtain the exponential rate of convergence with similar arguments. Finally, in the one dimensional setting, we extend the convergence result to the diffusion control case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10959v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Ma, Gaozhan Wang, Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>On the Differentiability of the Primal-Dual Interior-Point Method</title>
      <link>https://arxiv.org/abs/2406.11749</link>
      <description>arXiv:2406.11749v2 Announce Type: replace 
Abstract: Primal-Dual Interior-Point methods are capable of solving constrained convex optimization problems to tight tolerances in a fast and robust manner. The derivatives of the primal-dual solution with respect to the problem matrices can be computed using the implicit function theorem, enabling efficient differentiation of these optimizers for a fraction of the cost of the total solution time. In the presence of active inequality constraints, this technique is only capable of providing discontinuous subgradients that present a challenge to algorithms that rely on the smoothness of these derivatives. This paper presents a technique for relaxing primal-dual solutions with a logarithmic barrier to provide smooth derivatives near active inequality constraints, with the ability to specify a uniform and consistent amount of smoothing. We pair this with an efficient primal-dual interior-point algorithm for solving an always-feasible $\ell_1$-penalized variant of a convex quadratic program, eliminating the issues surrounding learning potentially infeasible problems. This parallelizable and smoothly differentiable solver is demonstrated on a range of robotics tasks where smoothing is important. An open source implementation in JAX is available at github.com/kevin-tracy/qpax.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11749v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Tracy, Zachary Manchester</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/1808.05671</link>
      <description>arXiv:1808.05671v4 Announce Type: replace-cross 
Abstract: Adaptive gradient methods are workhorses in deep learning. However, the convergence guarantees of adaptive gradient methods for nonconvex optimization have not been thoroughly studied. In this paper, we provide a fine-grained convergence analysis for a general class of adaptive gradient methods including AMSGrad, RMSProp and AdaGrad. For smooth nonconvex functions, we prove that adaptive gradient methods in expectation converge to a first-order stationary point. Our convergence rate is better than existing results for adaptive gradient methods in terms of dimension. In addition, we also prove high probability bounds on the convergence rates of AMSGrad, RMSProp as well as AdaGrad, which have not been established before. Our analyses shed light on better understanding the mechanism behind adaptive gradient methods in optimizing nonconvex objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:1808.05671v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongruo Zhou, Jinghui Chen, Yuan Cao, Ziyan Yang, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Beyond IID: data-driven decision-making in heterogeneous environments</title>
      <link>https://arxiv.org/abs/2206.09642</link>
      <description>arXiv:2206.09642v4 Announce Type: replace-cross 
Abstract: How should one leverage historical data when past observations are not perfectly indicative of the future, e.g., due to the presence of unobserved confounders which one cannot "correct" for? Motivated by this question, we study a data-driven decision-making framework in which historical samples are generated from unknown and different distributions assumed to lie in a heterogeneity ball with known radius and centered around the (also) unknown future (out-of-sample) distribution on which the performance of a decision will be evaluated. This work aims at analyzing the performance of central data-driven policies but also near-optimal ones in these heterogeneous environments and understanding key drivers of performance. We establish a first result which allows to upper bound the asymptotic worst-case regret of a broad class of policies. Leveraging this result, for any integral probability metric, we provide a general analysis of the performance achieved by Sample Average Approximation (SAA) as a function of the radius of the heterogeneity ball. This analysis is centered around the approximation parameter, a notion of complexity we introduce to capture how the interplay between the heterogeneity and the problem structure impacts the performance of SAA. In turn, we illustrate through several widely-studied problems -- e.g., newsvendor, pricing -- how this methodology can be applied and find that the performance of SAA varies considerably depending on the combinations of problem classes and heterogeneity. The failure of SAA for certain instances motivates the design of alternative policies to achieve rate-optimality. We derive problem-dependent policies achieving strong guarantees for the illustrative problems described above and provide initial results towards a principled approach for the design and analysis of general rate-optimal algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09642v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Besbes, Will Ma, Omar Mouchtaki</dc:creator>
    </item>
    <item>
      <title>Large-Scale Minimization of the Pseudospectral Abscissa</title>
      <link>https://arxiv.org/abs/2208.07540</link>
      <description>arXiv:2208.07540v4 Announce Type: replace-cross 
Abstract: This work concerns the minimization of the pseudospectral abscissa of a matrix-valued function dependent on parameters analytically. The problem is motivated by robust stability and transient behavior considerations for a linear control system that has optimization parameters. We describe a subspace procedure to cope with the setting when the matrix-valued function is of large size. The proposed subspace procedure solves a sequence of reduced problems obtained by restricting the matrix-valued function to small subspaces, whose dimensions increase gradually. It possesses desirable features such as a superlinear convergence exhibited by the decay in the errors of the minimizers of the reduced problems. In mathematical terms, the problem we consider is a large-scale nonconvex minimax eigenvalue optimization problem such that the eigenvalue function appears in the constraint of the inner maximization problem. Devising and analyzing a subspace framework for the minimax eigenvalue optimization problem at hand with the eigenvalue function in the constraint require special treatment that makes use of a Lagrangian and dual variables. There are notable advantages in minimizing the pseudospectral abscissa over maximizing the distance to instability or minimizing the $\mathcal{H}_\infty$ norm; the optimized pseudospectral abscissa provides quantitative information about the worst-case transient growth, and the initial guesses for the parameter values to optimize the pseudospectral abscissa can be arbitrary, unlike the case to optimize the distance to instability and $\mathcal{H}_\infty$ norm that would normally require initial guesses yielding asymptotically stable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07540v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicat Aliyev, Emre Mengi</dc:creator>
    </item>
    <item>
      <title>Robust $Q$-learning Algorithm for Markov Decision Processes under Wasserstein Uncertainty</title>
      <link>https://arxiv.org/abs/2210.00898</link>
      <description>arXiv:2210.00898v3 Announce Type: replace-cross 
Abstract: We present a novel $Q$-learning algorithm tailored to solve distributionally robust Markov decision problems where the corresponding ambiguity set of transition probabilities for the underlying Markov decision process is a Wasserstein ball around a (possibly estimated) reference measure. We prove convergence of the presented algorithm and provide several examples also using real data to illustrate both the tractability of our algorithm as well as the benefits of considering distributional robustness when solving stochastic optimal control problems, in particular when the estimated distributions turn out to be misspecified in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00898v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Julian Sester</dc:creator>
    </item>
    <item>
      <title>Fast Computation of Optimal Transport via Entropy-Regularized Extragradient Methods</title>
      <link>https://arxiv.org/abs/2301.13006</link>
      <description>arXiv:2301.13006v2 Announce Type: replace-cross 
Abstract: Efficient computation of the optimal transport distance between two distributions serves as an algorithm subroutine that empowers various applications. This paper develops a scalable first-order optimization-based method that computes optimal transport to within $\varepsilon$ additive accuracy with runtime $\widetilde{O}( n^2/\varepsilon)$, where $n$ denotes the dimension of the probability distributions of interest. Our algorithm achieves the state-of-the-art computational guarantees among all first-order methods, while exhibiting favorable numerical performance compared to classical algorithms like Sinkhorn and Greenkhorn. Underlying our algorithm designs are two key elements: (a) converting the original problem into a bilinear minimax problem over probability distributions; (b) exploiting the extragradient idea -- in conjunction with entropy regularization and adaptive learning rates -- to accelerate convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13006v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gen Li, Yanxi Chen, Yu Huang, Yuejie Chi, H. Vincent Poor, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>A GKP qubit protected by dissipation in a high-impedance superconducting circuit driven by a microwave frequency comb</title>
      <link>https://arxiv.org/abs/2304.01425</link>
      <description>arXiv:2304.01425v2 Announce Type: replace-cross 
Abstract: We propose a novel approach to generate, protect and control GKP qubits. It employs a microwave frequency comb parametrically modulating a Josephson circuit to enforce a dissipative dynamics of a high impedance circuit mode, autonomously stabilizing the finite-energy GKP code. The encoded GKP qubit is robustly protected against all dominant decoherence channels plaguing superconducting circuits but quasi-particle poisoning. In particular, noise from ancillary modes leveraged for dissipation engineering does not propagate at the logical level. In a state-of-the-art experimental setup, we estimate that the encoded qubit lifetime could extend two orders of magnitude beyond the break-even point, with substantial margin for improvement through progress in fabrication and control electronics. Qubit initialization, readout and control via Clifford gates can be performed while maintaining the code stabilization, paving the way toward the assembly of GKP qubits in a fault-tolerant quantum computing architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01425v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lev-Arcady Sellem, Alain Sarlette, Zaki Leghtas, Mazyar Mirrahimi, Pierre Rouchon, Philippe Campagne-Ibarcq</dc:creator>
    </item>
    <item>
      <title>Quantitative contraction rates for Sinkhorn algorithm: beyond bounded costs and compact marginals</title>
      <link>https://arxiv.org/abs/2304.04451</link>
      <description>arXiv:2304.04451v3 Announce Type: replace-cross 
Abstract: We show non-asymptotic exponential convergence of Sinkhorn iterates to the Schr\"odinger potentials, solutions of the quadratic Entropic Optimal Transport problem on $\mathbb{R}^d$. Our results hold under mild assumptions on the marginal inputs: in particular, we only assume that they admit an asymptotically positive log-concavity profile, covering as special cases log-concave distributions and bounded smooth perturbations of quadratic potentials. Up to the authors' knowledge, these are the first results which establish exponential convergence of Sinkhorn's algorithm in a general setting without assuming bounded cost functions or compactly supported marginals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04451v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Conforti, Alain Durmus, Giacomo Greco</dc:creator>
    </item>
    <item>
      <title>Immersion and Invariance-based Disturbance Observer and Its Application to Safe Control</title>
      <link>https://arxiv.org/abs/2309.06718</link>
      <description>arXiv:2309.06718v2 Announce Type: replace-cross 
Abstract: When the disturbance input matrix is nonlinear, existing disturbance observer design methods rely on the solvability of a partial differential equation or the existence of an output function with a uniformly well-defined disturbance relative degree, which can pose significant limitations. This note introduces a systematic approach for designing an Immersion and Invariance-based Disturbance Observer (IIDOB) that circumvents these strong assumptions. The proposed IIDOB ensures the disturbance estimation error is globally uniformly ultimately bounded by approximately solving a partial differential equation while compensating for the approximation error. Furthermore, by integrating IIDOB into the framework of control barrier functions, a filter-based safe control design method for control-affine systems with disturbances is established where the filter is used to generate an alternative disturbance estimation signal with a known derivative. Sufficient conditions are established to guarantee the safety of the disturbed systems. Simulation results demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06718v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>10.1109/TAC.2024.3416323</arxiv:journal_reference>
      <dc:creator>Yujie Wang, Xiangru Xu</dc:creator>
    </item>
    <item>
      <title>A nonparametric learning framework for nonlinear robust output regulation</title>
      <link>https://arxiv.org/abs/2309.14645</link>
      <description>arXiv:2309.14645v2 Announce Type: replace-cross 
Abstract: A nonparametric learning solution framework is proposed for the global nonlinear robust output regulation problem. We first extend the assumption that the steady-state generator is linear in the exogenous signal to the more relaxed assumption that it is polynomial in the exogenous signal. Additionally, a nonparametric learning framework is proposed to eliminate the construction of an explicit regressor, as required in the adaptive method, which can potentially simplify the implementation and reduce the computational complexity of existing methods. With the help of the proposed framework, the robust nonlinear output regulation problem can be converted into a robust non-adaptive stabilization problem for the augmented system with integral input-to-state stable (iISS) inverse dynamics. Moreover, a dynamic gain approach can adaptively raise the gain to a sufficiently large constant to achieve stabilization without requiring any a priori knowledge of the uncertainties appearing in the dynamics of the exosystem and the system. Furthermore, we apply the nonparametric learning framework to globally reconstruct and estimate multiple sinusoidal signals with unknown frequencies without the need for adaptive parametric techniques. An explicit nonlinear mapping can directly provide the estimated parameters, which will exponentially converge to the unknown frequencies. Finally, a feedforward control design is proposed to solve the linear output regulation problem using the nonparametric learning framework. Two simulation examples are provided to illustrate the effectiveness of the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14645v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shimin Wang, Martin Guay, Zhiyong Chen, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Agent Coordination via Contextual Regression (AgentCONCUR) for Data Center Flexibility</title>
      <link>https://arxiv.org/abs/2309.16792</link>
      <description>arXiv:2309.16792v2 Announce Type: replace-cross 
Abstract: A network of spatially distributed data centers can provide operational flexibility to power systems by shifting computing tasks among electrically remote locations. However, harnessing this flexibility in real-time through the standard optimization techniques is challenged by the need for sensitive operational datasets and substantial computational resources. To alleviate the data and computational requirements, this paper introduces a coordination mechanism based on contextual regression. This mechanism, abbreviated as AgentCONCUR, associates cost-optimal task shifts with public and trusted contextual data (e.g., real-time prices) and uses regression on this data as a coordination policy. Notably, regression-based coordination does not learn the optimal coordination actions from a labeled dataset. Instead, it exploits the optimization structure of the coordination problem to ensure feasible and cost-effective actions. A NYISO-based study reveals large coordination gains and the optimal features for the successful regression-based coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16792v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Dvorkin</dc:creator>
    </item>
    <item>
      <title>Critical Influence of Overparameterization on Sharpness-aware Minimization</title>
      <link>https://arxiv.org/abs/2311.17539</link>
      <description>arXiv:2311.17539v3 Announce Type: replace-cross 
Abstract: Training an overparameterized neural network can yield minimizers of different generalization capabilities despite the same level of training loss. Meanwhile, with evidence that suggests a strong correlation between the sharpness of minima and their generalization errors, increasing efforts have been made to develop optimization methods to explicitly find flat minima as more generalizable solutions. Despite its contemporary relevance to overparameterization, however, this sharpness-aware minimization (SAM) strategy has not been studied much yet as to exactly how it is affected by overparameterization. Hence, in this work, we analyze SAM under overparameterization of varying degrees and present both empirical and theoretical results that indicate a critical influence of overparameterization on SAM. At first, we conduct extensive numerical experiments across vision, language, graph, and reinforcement learning domains and show that SAM consistently improves with overparameterization. Next, we attribute this phenomenon to the interplay between the enlarged solution space and increased implicit bias from overparameterization. Further, we prove multiple theoretical benefits of overparameterization for SAM to attain (i) minima with more uniform Hessian moments compared to SGD, (ii) much faster convergence at a linear rate, and (iii) lower test error for two-layer networks. Last but not least, we discover that the effect of overparameterization is more significantly pronounced in practical settings of label noise and sparsity, and yet, sufficient regularization is necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17539v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungbin Shin, Dongyeop Lee, Maksym Andriushchenko, Namhoon Lee</dc:creator>
    </item>
    <item>
      <title>A Bandit Approach with Evolutionary Operators for Model Selection</title>
      <link>https://arxiv.org/abs/2402.05144</link>
      <description>arXiv:2402.05144v2 Announce Type: replace-cross 
Abstract: This work formulates model selection as an infinite-armed bandit problem, namely, a problem in which a decision maker iteratively selects one of an infinite number of fixed choices (i.e., arms) when the properties of each choice are only partially known at the time of allocation and may become better understood over time, via the attainment of rewards.Here, the arms are machine learning models to train and selecting an arm corresponds to a partial training of the model (resource allocation).The reward is the accuracy of the selected model after its partial training.We aim to identify the best model at the end of a finite number of resource allocations and thus consider the best arm identification setup. We propose the algorithm Mutant-UCB that incorporates operators from evolutionary algorithms into the UCB-E (Upper Confidence Bound Exploration) bandit algorithm introduced by Audiber et al.Tests carried out on three open source image classification data sets attest to the relevance of this novel combining approach, which outperforms the state-of-the-art for a fixed budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05144v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Margaux Br\'eg\`ere (LPSM), Julie Keisler (CRIStAL, EDF R\&amp;D)</dc:creator>
    </item>
    <item>
      <title>Optimization of array encoding for ultrasound imaging</title>
      <link>https://arxiv.org/abs/2403.00289</link>
      <description>arXiv:2403.00289v2 Announce Type: replace-cross 
Abstract: Objective: The transmit encoding model for synthetic aperture imaging is a robust and flexible framework for understanding the effects of acoustic transmission on ultrasound image reconstruction. Our objective is to use machine learning (ML) to construct scanning sequences, parameterized by time delays and apodization weights, that produce high-quality B-mode images. Approach: We use a custom ML model in PyTorch with simulated RF data from Field II to probe the space of possible encoding sequences for those that minimize a loss function that describes image quality. This approach is made computationally feasible by a novel formulation of the derivative for delay-and-sum beamforming. Main Results: When trained for a specified experimental setting (imaging domain, hardware restrictions, etc.), our ML model produces optimized encoding sequences that, when deployed in the REFoCUS imaging framework, improve a number of standard quality metrics over conventional sequences including resolution, field of view, and contrast. We demonstrate these results experimentally on both wire targets and a tissue-mimicking phantom. Significance: This work demonstrates that the set of commonly used encoding schemes represent only a narrow subset of those available. Additionally, it demonstrates the value for ML tasks in synthetic transmit aperture imaging to consider the beamformer within the model, instead of purely as a post-processing step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00289v2</guid>
      <category>physics.med-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6560/ad5249</arxiv:DOI>
      <arxiv:journal_reference>Phys. Med. Biol. 69 125024 (2024)</arxiv:journal_reference>
      <dc:creator>Jacob Spainhour, Korben Smart, Stephen Becker, Nick Bottenus</dc:creator>
    </item>
    <item>
      <title>Log-Scale Quantization in Distributed First-Order Methods: Gradient-based Learning from Distributed Data</title>
      <link>https://arxiv.org/abs/2406.00621</link>
      <description>arXiv:2406.00621v2 Announce Type: replace-cross 
Abstract: Decentralized strategies are of interest for learning from large-scale data over networks. This paper studies learning over a network of geographically distributed nodes/agents subject to quantization. Each node possesses a private local cost function, collectively contributing to a global cost function, which the proposed methodology aims to minimize. In contrast to many existing literature, the information exchange among nodes is quantized. We adopt a first-order computationally-efficient distributed optimization algorithm (with no extra inner consensus loop) that leverages node-level gradient correction based on local data and network-level gradient aggregation only over nearby nodes. This method only requires balanced networks with no need for stochastic weight design. It can handle log-scale quantized data exchange over possibly time-varying and switching network setups. We analyze convergence over both structured networks (for example, training over data-centers) and ad-hoc multi-agent networks (for example, training over dynamic robotic networks). Through analysis and experimental validation, we show that (i) structured networks generally result in a smaller optimality gap, and (ii) logarithmic quantization leads to smaller optimality gap compared to uniform quantization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00621v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Muhammad I. Qureshi, Mohammad Hossein Khalesi, Hamid R. Rabiee, Usman A. Khan</dc:creator>
    </item>
    <item>
      <title>Positive definiteness of fourth order three dimensional symmetric tensors</title>
      <link>https://arxiv.org/abs/2406.04010</link>
      <description>arXiv:2406.04010v3 Announce Type: replace-cross 
Abstract: For a 4th order 3-dimensional symmetric tensor with its entries $1$ or $-1$, we show the analytic sufficient and necessary conditions of its positive definiteness. By applying these conclusions, several strict inequalities is bulit for ternary quartic homogeneous polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04010v3</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Calibrating Neural Networks' parameters through Optimal Contraction in a Prediction Problem</title>
      <link>https://arxiv.org/abs/2406.10703</link>
      <description>arXiv:2406.10703v2 Announce Type: replace-cross 
Abstract: This study introduces a novel approach to ensure the existence and uniqueness of optimal parameters in neural networks. The paper details how a recurrent neural networks (RNN) can be transformed into a contraction in a domain where its parameters are linear. It then demonstrates that a prediction problem modeled through an RNN, with a specific regularization term in the loss function, can have its first-order conditions expressed analytically. This system of equations is reduced to two matrix equations involving Sylvester equations, which can be partially solved. We establish that, if certain conditions are met, optimal parameters exist, are unique, and can be found through a straightforward algorithm to any desired precision. Also, as the number of neurons grows the conditions of convergence become easier to fulfill. Feedforward neural networks (FNNs) are also explored by including linear constraints on parameters. According to our model, incorporating loops (with fixed or variable weights) will produce loss functions that train easier, because it assures the existence of a region where an iterative method converges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10703v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valdes Gonzalo</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Mirror Flow on Separable Data</title>
      <link>https://arxiv.org/abs/2406.12763</link>
      <description>arXiv:2406.12763v2 Announce Type: replace-cross 
Abstract: We examine the continuous-time counterpart of mirror descent, namely mirror flow, on classification problems which are linearly separable. Such problems are minimised `at infinity' and have many possible solutions; we study which solution is preferred by the algorithm depending on the mirror potential. For exponential tailed losses and under mild assumptions on the potential, we show that the iterates converge in direction towards a $\phi_\infty$-maximum margin classifier. The function $\phi_\infty$ is the $\textit{horizon function}$ of the mirror potential and characterises its shape `at infinity'. When the potential is separable, a simple formula allows to compute this function. We analyse several examples of potentials and provide numerical experiments highlighting our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12763v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Pesme, Radu-Alexandru Dragomir, Nicolas Flammarion</dc:creator>
    </item>
  </channel>
</rss>
