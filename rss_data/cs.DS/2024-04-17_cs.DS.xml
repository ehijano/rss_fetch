<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Traveling Tournament Problem: Improved Algorithms Based on Cycle Packing</title>
      <link>https://arxiv.org/abs/2404.10955</link>
      <description>arXiv:2404.10955v1 Announce Type: new 
Abstract: The Traveling Tournament Problem (TTP) is a well-known benchmark problem in the field of tournament timetabling, which asks us to design a double round-robin schedule such that each pair of teams plays one game in each other's home venue, minimizing the total distance traveled by all $n$ teams ($n$ is even). TTP-$k$ is the problem with one more constraint that each team can have at most $k$-consecutive home games or away games. In this paper, we investigate schedules for TTP-$k$ and analyze the approximation ratio of the solutions. Most previous schedules were constructed based on a Hamiltonian cycle of the graph. We will propose a novel construction based on a $k$-cycle packing. Then, combining our $k$-cycle packing schedule with the Hamiltonian cycle schedule, we obtain improved approximation ratios for TTP-$k$ with deep analysis. The case where $k=3$, TTP-3, is one of the most investigated cases. We improve the approximation ratio of TTP-3 from $(1.667+\varepsilon)$ to $(1.598+\varepsilon)$, for any $\varepsilon&gt;0$. For TTP-$4$, we improve the approximation ratio from $(1.750+\varepsilon)$ to $(1.700+\varepsilon)$. By a refined analysis of the Hamiltonian cycle construction, we also improve the approximation ratio of TTP-$k$ from $(\frac{5k-7}{2k}+\varepsilon)$ to $(\frac{5k^2-4k+3}{2k(k+1)}+\varepsilon)$ for any constant $k\geq 5$. Our methods can be extended to solve a variant called LDTTP-$k$ (TTP-$k$ where all teams are allocated on a straight line). We show that the $k$-cycle packing construction can achieve an approximation ratio of $(\frac{3k-3}{2k-1}+\varepsilon)$, which improves the approximation ratio of LDTTP-3 from $4/3$ to $(6/5+\varepsilon)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10955v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Zhao, Mingyu Xiao, Chao Xu</dc:creator>
    </item>
    <item>
      <title>On approximability of the Permanent of PSD matrices</title>
      <link>https://arxiv.org/abs/2404.10959</link>
      <description>arXiv:2404.10959v1 Announce Type: new 
Abstract: We study the complexity of approximating the permanent of a positive semidefinite matrix $A\in \mathbb{C}^{n\times n}$.
  1. We design a new approximation algorithm for $\mathrm{per}(A)$ with approximation ratio $e^{(0.9999 + \gamma)n}$, exponentially improving upon the current best bound of $e^{(1+\gamma-o(1))n}$ [AGOS17,YP22]. Here, $\gamma \approx 0.577$ is Euler's constant.
  2. We prove that it is NP-hard to approximate $\mathrm{per}(A)$ within a factor $e^{(\gamma-\epsilon)n}$ for any $\epsilon&gt;0$. This is the first exponential hardness of approximation for this problem. Along the way, we prove optimal hardness of approximation results for the $\|\cdot\|_{2\to q}$ ``norm'' problem of a matrix for all $-1 &lt; q &lt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10959v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farzam Ebrahimnejad, Ansh Nagda, Shayan Oveis Gharan</dc:creator>
    </item>
    <item>
      <title>Drawing Competitive Districts in Redistricting</title>
      <link>https://arxiv.org/abs/2404.10964</link>
      <description>arXiv:2404.10964v1 Announce Type: new 
Abstract: In the process of redistricting, one important metric is the number of competitive districts, that is, districts where both parties have a reasonable chance of winning a majority of votes. Competitive districts are important for achieving proportionality, responsiveness, and other desirable qualities; some states even directly list competitiveness in their legally-codified districting requirements. In this work, we discuss the problem of drawing plans with at least a fixed number of competitive districts. In addition to the standard, ``vote-band'' measure of competitivenesss (i.e., how close was the last election?), we propose a measure that explicitly considers ``swing voters'' - the segment of the population that may choose to vote either way, or not vote at all, in a given election. We present two main, contrasting results. First, from a computational complexity perspective, we show that the task of drawing plans with competitive districts is NP-hard, even on very natural instances where the districting task itself is easy (e.g., small rectangular grids of population-balanced cells). Second, however, we show that a simple hill-climbing procedure can in practice find districtings on real states in which all the districts are competitive. We present the results of the latter on the precinct-level graphs of the U.S. states of North Carolina and Arizona, and discuss trade-offs between competitiveness and other desirable qualities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10964v1</guid>
      <category>cs.DS</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Chuang, Oussama Hanguir, Clifford Stein</dc:creator>
    </item>
    <item>
      <title>Distribution-Free Testing of Decision Lists with a Sublinear Number of Queries</title>
      <link>https://arxiv.org/abs/2404.11103</link>
      <description>arXiv:2404.11103v1 Announce Type: new 
Abstract: We give a distribution-free testing algorithm for decision lists with $\tilde{O}(n^{11/12}/\varepsilon^3)$ queries. This is the first sublinear algorithm for this problem, which shows that, unlike halfspaces, testing is strictly easier than learning for decision lists. Complementing the algorithm, we show that any distribution-free tester for decision lists must make $\tilde{\Omega}(\sqrt{n})$ queries, or draw $\tilde{\Omega}(n)$ samples when the algorithm is sample-based.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11103v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Yumou Fei, Shyamal Patel</dc:creator>
    </item>
    <item>
      <title>Sinking an Algorithmic Isthmus: (1 + {\epsilon})-Approximate Min-Sum Subset Convolution</title>
      <link>https://arxiv.org/abs/2404.11364</link>
      <description>arXiv:2404.11364v1 Announce Type: new 
Abstract: Given functions $f$ and $g$ defined on the subset lattice of order $n$, their min-sum subset convolution, defined for all $S \subseteq [n]$ as \[
  (f \star g)(S) = \min_{T \subseteq S}\:\big(f(T) + g(S \setminus T)\big), \] is a fundamental tool in parameterized algorithms. However, since its na\"ive $O(3^n)$-time evaluation is also the fastest known, it has been used only in settings where the input functions have a bounded integer range $\{-M, \ldots, M\}$. In this case, the running time becomes $\tilde O(2^n M)$ by resorting to fast subset convolution in the sum-product ring. This is disadvantageous due to the dependence on $M$, limiting its practicality.
  In this light, we study whether the problem admits an $(1 + \varepsilon)$-approximation scheme in time independent of $M$. Our main result is the first $\tilde O(2^\frac{3n}{2} / \sqrt{\varepsilon})$-time algorithm for the $(1 + \varepsilon)$-approximate min-sum subset convolution. To show its applicability, we present $(1 + \varepsilon)$-approximation schemes in the same exponential time bound for several NP-hard problems using this convolution, such as the minimum-cost $k$-coloring problem -- in time $\tilde O(2^\frac{3n}{2} / \sqrt{\varepsilon})$, and the prize-collecting Steiner tree problem -- in time $\tilde O(2^\frac{3s^+}{2} / \sqrt{\varepsilon})$, where $n$ is the number of vertices and $s^+$ is the number of proper potential terminals. We also discuss two other applications in computational biology.
  Our algorithms lie at the intersection of two lines of research that have been considered separately: $\textit{sequence}$ and $\textit{subset}$ convolutions in semi-rings. In particular, we extend the recent framework of Bringmann, K\"unnemann, and W\k{e}grzycki [STOC 2019] to the context of subset convolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11364v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihail Stoian</dc:creator>
    </item>
    <item>
      <title>Testing Intersectingness of Uniform Families</title>
      <link>https://arxiv.org/abs/2404.11504</link>
      <description>arXiv:2404.11504v1 Announce Type: new 
Abstract: A set family ${\cal F}$ is called intersecting if every two members of ${\cal F}$ intersect, and it is called uniform if all members of ${\cal F}$ share a common size. A uniform family ${\cal F} \subseteq \binom{[n]}{k}$ of $k$-subsets of $[n]$ is $\varepsilon$-far from intersecting if one has to remove more than $\varepsilon \cdot \binom{n}{k}$ of the sets of ${\cal F}$ to make it intersecting. We study the property testing problem that given query access to a uniform family ${\cal F} \subseteq \binom{[n]}{k}$, asks to distinguish between the case that ${\cal F}$ is intersecting and the case that it is $\varepsilon$-far from intersecting. We prove that for every fixed integer $r$, the problem admits a non-adaptive two-sided error tester with query complexity $O(\frac{\ln n}{\varepsilon})$ for $\varepsilon \geq \Omega( (\frac{k}{n})^r)$ and a non-adaptive one-sided error tester with query complexity $O(\frac{\ln k}{\varepsilon})$ for $\varepsilon \geq \Omega( (\frac{k^2}{n})^r)$. The query complexities are optimal up to the logarithmic terms. For $\varepsilon \geq \Omega( (\frac{k^2}{n})^2)$, we further provide a non-adaptive one-sided error tester with optimal query complexity of $O(\frac{1}{\varepsilon})$. Our findings show that the query complexity of the problem differs substantially from that of testing intersectingness of non-uniform families, studied recently by Chen, De, Li, Nadimpalli, and Servedio (ITCS, 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11504v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ishay Haviv, Michal Parnas</dc:creator>
    </item>
    <item>
      <title>The EDGE Language: Extended General Einsums for Graph Algorithms</title>
      <link>https://arxiv.org/abs/2404.11591</link>
      <description>arXiv:2404.11591v1 Announce Type: new 
Abstract: In this work, we propose a unified abstraction for graph algorithms: the Extended General Einsums language, or EDGE. The EDGE language expresses graph algorithms in the language of tensor algebra, providing a rigorous, succinct, and expressive mathematical framework. EDGE leverages two ideas: (1) the well-known foundations provided by the graph-matrix duality, where a graph is simply a 2D tensor, and (2) the power and expressivity of Einsum notation in the tensor algebra world. In this work, we describe our design goals for EDGE and walk through the extensions we add to Einsums to support more complex operations common in graph algorithms. Additionally, we provide a few examples of how to express graph algorithms in our proposed notation. We hope that a single, mathematical notation for graph algorithms will (1) allow researchers to more easily compare different algorithms and different implementations of a graph algorithm; (2) enable developers to factor complexity by separating the concerns of what to compute (described with the extended Einsum notation) from the lower level details of how to compute; and (3) enable the discovery of different algorithmic variants of a problem through algebraic manipulations and transformations on a given EDGE expression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11591v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toluwanimi O. Odemuyiwa, Joel S. Emer, John D. Owens</dc:creator>
    </item>
    <item>
      <title>Private federated discovery of out-of-vocabulary words for Gboard</title>
      <link>https://arxiv.org/abs/2404.11607</link>
      <description>arXiv:2404.11607v1 Announce Type: new 
Abstract: The vocabulary of language models in Gboard, Google's keyboard application, plays a crucial role for improving user experience. One way to improve the vocabulary is to discover frequently typed out-of-vocabulary (OOV) words on user devices. This task requires strong privacy protection due to the sensitive nature of user input data. In this report, we present a private OOV discovery algorithm for Gboard, which builds on recent advances in private federated analytics. The system offers local differential privacy (LDP) guarantees for user contributed words. With anonymous aggregation, the final released words satisfy central differential privacy guarantees with $\epsilon = 0.315, \delta = 10^{-10}$ for OOV discovery in en-US (English in United States).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11607v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziteng Sun, Peter Kairouz, Haicheng Sun, Adria Gascon, Ananda Theertha Suresh</dc:creator>
    </item>
    <item>
      <title>Online Algorithms with Limited Data Retention</title>
      <link>https://arxiv.org/abs/2404.10997</link>
      <description>arXiv:2404.10997v1 Announce Type: cross 
Abstract: We introduce a model of online algorithms subject to strict constraints on data retention. An online learning algorithm encounters a stream of data points, one per round, generated by some stationary process. Crucially, each data point can request that it be removed from memory $m$ rounds after it arrives. To model the impact of removal, we do not allow the algorithm to store any information or calculations between rounds other than a subset of the data points (subject to the retention constraints). At the conclusion of the stream, the algorithm answers a statistical query about the full dataset. We ask: what level of performance can be guaranteed as a function of $m$?
  We illustrate this framework for multidimensional mean estimation and linear regression problems. We show it is possible to obtain an exponential improvement over a baseline algorithm that retains all data as long as possible. Specifically, we show that $m = \textsc{Poly}(d, \log(1/\epsilon))$ retention suffices to achieve mean squared error $\epsilon$ after observing $O(1/\epsilon)$ $d$-dimensional data points. This matches the error bound of the optimal, yet infeasible, algorithm that retains all data forever. We also show a nearly matching lower bound on the retention required to guarantee error $\epsilon$. One implication of our results is that data retention laws are insufficient to guarantee the right to be forgotten even in a non-adversarial world in which firms merely strive to (approximately) optimize the performance of their algorithms.
  Our approach makes use of recent developments in the multidimensional random subset sum problem to simulate the progression of stochastic gradient descent under a model of adversarial noise, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10997v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole Immorlica, Brendan Lucier, Markus Mobius, James Siderius</dc:creator>
    </item>
    <item>
      <title>On Learning Parities with Dependent Noise</title>
      <link>https://arxiv.org/abs/2404.11325</link>
      <description>arXiv:2404.11325v1 Announce Type: cross 
Abstract: In this expository note we show that the learning parities with noise (LPN) assumption is robust to weak dependencies in the noise distribution of small batches of samples. This provides a partial converse to the linearization technique of [AG11]. The material in this note is drawn from a recent work by the authors [GMR24], where the robustness guarantee was a key component in a cryptographic separation between reinforcement learning and supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11325v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Golowich, Ankur Moitra, Dhruv Rohatgi</dc:creator>
    </item>
    <item>
      <title>Finding $d$-Cuts in Graphs of Bounded Diameter, Graphs of Bounded Radius and $H$-Free Graphs</title>
      <link>https://arxiv.org/abs/2404.11389</link>
      <description>arXiv:2404.11389v1 Announce Type: cross 
Abstract: The $d$-Cut problem is to decide if a graph has an edge cut such that each vertex has at most $d$ neighbours at the opposite side of the cut. If $d=1$, we obtain the intensively studied Matching Cut problem. The $d$-Cut problem has been studied as well, but a systematic study for special graph classes was lacking. We initiate such a study and consider classes of bounded diameter, bounded radius and $H$-free graphs. We prove that for all $d\geq 2$, $d$-Cut is polynomial-time solvable for graphs of diameter $2$, $(P_3+P_4)$-free graphs and $P_5$-free graphs. These results extend known results for $d=1$. However, we also prove several NP-hardness results for $d$-Cut that contrast known polynomial-time results for $d=1$. Our results lead to full dichotomies for bounded diameter and bounded radius and to almost-complete dichotomies for $H$-free graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11389v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felicia Lucke, Ali Momeni, Dani\"el Paulusma, Siani Smith</dc:creator>
    </item>
    <item>
      <title>Online Bin Packing with Predictions</title>
      <link>https://arxiv.org/abs/2102.03311</link>
      <description>arXiv:2102.03311v3 Announce Type: replace 
Abstract: Bin packing is a classic optimization problem with a wide range of applications, from load balancing to supply chain management. In this work, we study the online variant of the problem, in which a sequence of items of various sizes must be placed into a minimum number of bins of uniform capacity. The online algorithm is enhanced with a (potentially erroneous) prediction concerning the frequency of item sizes in the sequence. We design and analyze online algorithms with efficient tradeoffs between the consistency (i.e., the competitive ratio assuming no prediction error) and the robustness (i.e., the competitive ratio under adversarial error), and whose performance degrades near-optimally as a function of the prediction error. This is the first theoretical and experimental study of online bin packing under competitive analysis, in the realistic setting of learnable predictions. Previous work addressed only extreme cases with respect to the prediction error, and relied on overly powerful and error-free oracles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.03311v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spyros Angelopoulos, Shahin Kamali, Kimia Shadkami</dc:creator>
    </item>
    <item>
      <title>Streaming Edge Coloring with Subquadratic Palette Size</title>
      <link>https://arxiv.org/abs/2305.07090</link>
      <description>arXiv:2305.07090v2 Announce Type: replace 
Abstract: In this paper, we study the problem of computing an edge-coloring in the (one-pass) W-streaming model. In this setting, the edges of an $n$-node graph arrive in an arbitrary order to a machine with a relatively small space, and the goal is to design an algorithm that outputs, as a stream, a proper coloring of the edges using the fewest possible number of colors.
  Behnezhad et al. [Behnezhad et al., 2019] devised the first non-trivial algorithm for this problem, which computes in $\tilde{O}(n)$ space a proper $O(\Delta^2)$-coloring w.h.p. (here $\Delta$ is the maximum degree of the graph). Subsequent papers improved upon this result, where latest of them [Ansari et al., 2022] shows that it is possible to deterministically compute an $O(\Delta^2/s)$-coloring in $O(ns)$ space. However, none of the improvements, succeeded in reducing the number of colors to $O(\Delta^{2-\epsilon})$ while keeping the same space bound of $\tilde{O}(n)$. In particular, no progress was made on the question of whether computing an $O(\Delta)$-coloring is possible with roughly $O(n)$ space, which was stated in [Behnezhad et al., 2019] to be a major open problem.
  In this paper we bypass the quadratic bound by presenting a new randomized $\tilde{O}(n)$-space algorithm that uses $\tilde{O}(\Delta^{1.5})$ colors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07090v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiri Chechik, Doron Mukhtar, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>Multidepot Capacitated Vehicle Routing with Improved Approximation Guarantees</title>
      <link>https://arxiv.org/abs/2308.14131</link>
      <description>arXiv:2308.14131v3 Announce Type: replace 
Abstract: The Multidepot Capacitated Vehicle Routing Problem (MCVRP) is a well-known variant of the classic Capacitated Vehicle Routing Problem (CVRP), where we need to route capacitated vehicles located in multiple depots to serve customers' demand such that each vehicle must return to the depot it starts, and the total traveling distance is minimized. There are three variants of MCVRP according to the property of the demand: unit-demand, splittable and unsplittable. We study approximation algorithms for $k$-MCVRP in metric graphs, where $k$ is the capacity of each vehicle. The best-known approximation ratios for the three versions are $4-\Theta(1/k)$, $4-\Theta(1/k)$, and $4$, respectively. We give a $(4-1/1500)$-approximation algorithm for unit-demand and splittable $k$-MCVRP, and a $(4-1/50000)$-approximation algorithm for unsplittable $k$-MCVRP. When $k$ is a fixed integer, we give a $(3+\ln2-\max\{\Theta(1/\sqrt{k}),1/9000\})$-approximation algorithm for the splittable and unit-demand cases, and a $(3+\ln2-\Theta(1/\sqrt{k}))$-approximation algorithm for the unsplittable case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14131v3</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Zhao, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Sparsity-Parameterised Dynamic Edge Colouring</title>
      <link>https://arxiv.org/abs/2311.10616</link>
      <description>arXiv:2311.10616v2 Announce Type: replace 
Abstract: We study the edge-colouring problem, and give efficient algorithms where the number of colours is parameterised by the graph's arboricity, $\alpha$. In a dynamic graph, subject to insertions and deletions, we give a deterministic algorithm that updates a proper $\Delta + O(\alpha)$ edge~colouring in $\operatorname{poly}(\log n)$ amortized time. Our algorithm is fully adaptive to the current value of the maximum degree and arboricity.
  In this fully-dynamic setting, the state-of-the-art edge-colouring algorithms are either a randomised algorithm using $(1 + \varepsilon)\Delta$ colours in $\operatorname{poly}(\log n, \epsilon^{-1})$ time per update, or the naive greedy algorithm which is a deterministic $2\Delta -1$ edge colouring with $\log(\Delta)$ update time.
  Compared to the $(1+\varepsilon)\Delta$ algorithm, our algorithm is deterministic and asymptotically faster, and when $\alpha$ is sufficiently small compared to $\Delta$, it even uses fewer colours. In particular, ours is the first $\Delta+O(1)$ edge-colouring algorithm for dynamic forests, and dynamic planar graphs, with polylogarithmic update time.
  Additionally, in the static setting, we show that we can find a proper edge colouring with $\Delta + 2\alpha$ colours in $O(m\log n)$ time. Moreover, the colouring returned by our algorithm has the following local property: every edge $uv$ is coloured with a colour in $\{1, \max\{deg(u), deg(v)\} + 2\alpha\}$. The time bound matches that of the greedy algorithm that computes a $2\Delta-1$ colouring of the graph's edges, and improves the number of colours when $\alpha$ is sufficiently small compared to $\Delta$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10616v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksander B. G. Christiansen, Eva Rotenberg, Juliette Vlieghe</dc:creator>
    </item>
    <item>
      <title>A basic lower bound for property testing</title>
      <link>https://arxiv.org/abs/2403.04999</link>
      <description>arXiv:2403.04999v2 Announce Type: replace 
Abstract: An $\epsilon$-test for any non-trivial property (one for which there are both satisfying inputs and inputs of large distance from the property) should use a number of queries that is at least inversely proportional in $\epsilon$. However, to the best of our knowledge there is no reference proof for this intuition. Such a proof is provided here. It is written so as to not require any prior knowledge of the related literature, and in particular does not use Yao's method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04999v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eldar Fischer</dc:creator>
    </item>
    <item>
      <title>Finding Decision Tree Splits in Streaming and Massively Parallel Models</title>
      <link>https://arxiv.org/abs/2403.19867</link>
      <description>arXiv:2403.19867v2 Announce Type: replace 
Abstract: In this work, we provide data stream algorithms that compute optimal splits in decision tree learning. In particular, given a data stream of observations $x_i$ and their labels $y_i$, the goal is to find the optimal split point $j$ that divides the data into two sets such that the mean squared error (for regression) or misclassification rate (for classification) is minimized. We provide various fast streaming algorithms that use sublinear space and a small number of passes for these problems. These algorithms can also be extended to the massively parallel computation model. Our work, while not directly comparable, complements the seminal work of Domingos and Hulten (KDD 2000).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19867v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huy Pham, Hoang Ta, Hoa T. Vu</dc:creator>
    </item>
    <item>
      <title>Motiflets -- Simple and Accurate Detection of Motifs in Time Series</title>
      <link>https://arxiv.org/abs/2206.03735</link>
      <description>arXiv:2206.03735v2 Announce Type: replace-cross 
Abstract: A time series motif intuitively is a short time series that repeats itself approximately the same within a larger time series. Such motifs often represent concealed structures, such as heart beats in an ECG recording, the riff in a pop song, or sleep spindles in EEG sleep data. Motif discovery (MD) is the task of finding such motifs in a given input series. As there are varying definitions of what exactly a motif is, a number of different algorithms exist. As central parameters they all take the length l of the motif and the maximal distance r between the motif's occurrences. In practice, however, especially suitable values for r are very hard to determine upfront, and found motifs show a high variability even for very similar r values. Accordingly, finding an interesting motif requires extensive trial-and-error.
  In this paper, we present a different approach to the MD problem. We define k-Motiflets as the set of exactly k occurrences of a motif of length l, whose maximum pairwise distance is minimal. This turns the MD problem upside-down: The central parameter of our approach is not the distance threshold r, but the desired number of occurrence k of the motif, which we show is considerably more intuitive and easier to set. Based on this definition, we present exact and approximate algorithms for finding k-Motiflets and analyze their complexity. To further ease the use of our method, we describe statistical tools to automatically determine meaningful values for its input parameters. By evaluation on several real-world data sets and comparison to four SotA MD algorithms, we show that our proposed algorithm is both quantitatively superior to its competitors, finding larger motif sets at higher similarity, and qualitatively better, leading to clearer and easier to interpret motifs without any need for manual tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.03735v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Sch\"afer, Ulf Leser</dc:creator>
    </item>
    <item>
      <title>Computing finite index congruences of finitely presented semigroups and monoids</title>
      <link>https://arxiv.org/abs/2302.06295</link>
      <description>arXiv:2302.06295v3 Announce Type: replace-cross 
Abstract: In this paper we describe an algorithm for computing the left, right, or 2-sided congruences of a finitely presented semigroup or monoid with finitely many classes, and alternative algorithm when the finitely presented semigroup or monoid is finite. We compare the two algorithms presented to existing algorithms and implementations. The first algorithm is a generalization of Sims' low index subgroup algorithm for finding the congruences of a monoid. The second algorithm involves determining the distinct principal congruences, and then finding all of their possible joins. Variations of this algorithm have been suggested in numerous contexts by numerous authors. We show how to utilise the theory of relative Green's relations, and a version of Schreier's Lemma for monoids, to reduce the number of principal congruences that must be generated as the first step of this approach. Both of the algorithms described in this paper are implemented in the GAP package Semigroups, and the first algorithm is available in the C++ library libsemigroups and in its python bindings libsemigroups_pybind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06295v3</guid>
      <category>math.RA</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Anagnostopoulou-Merkouri, Reinis Cirpons, James D. Mitchell, Maria Tsalakou</dc:creator>
    </item>
    <item>
      <title>Time Fairness in Online Knapsack Problems</title>
      <link>https://arxiv.org/abs/2305.13293</link>
      <description>arXiv:2305.13293v2 Announce Type: replace-cross 
Abstract: The online knapsack problem is a classic problem in the field of online algorithms. Its canonical version asks how to pack items of different values and weights arriving online into a capacity-limited knapsack so as to maximize the total value of the admitted items. Although optimal competitive algorithms are known for this problem, they may be fundamentally unfair, i.e., individual items may be treated inequitably in different ways. We formalize a practically-relevant notion of time fairness which effectively models a trade off between static and dynamic pricing in a motivating application such as cloud resource allocation, and show that existing algorithms perform poorly under this metric. We propose a parameterized deterministic algorithm where the parameter precisely captures the Pareto-optimal trade-off between fairness (static pricing) and competitiveness (dynamic pricing). We show that randomization is theoretically powerful enough to be simultaneously competitive and fair; however, it does not work well in experiments. To further improve the trade-off between fairness and competitiveness, we develop a nearly-optimal learning-augmented algorithm which is fair, consistent, and robust (competitive), showing substantial performance improvements in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13293v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Lechowicz, Rik Sengupta, Bo Sun, Shahin Kamali, Mohammad Hajiesmaili</dc:creator>
    </item>
    <item>
      <title>Composition in Differential Privacy for General Granularity Notions (Long Version)</title>
      <link>https://arxiv.org/abs/2308.14649</link>
      <description>arXiv:2308.14649v2 Announce Type: replace-cross 
Abstract: The composition theorems of differential privacy (DP) allow data curators to combine different algorithms to obtain a new algorithm that continues to satisfy DP. However, new granularity notions (i.e., neighborhood definitions), data domains, and composition settings have appeared in the literature that the classical composition theorems do not cover. For instance, the original parallel composition theorem does not translate well to general granularity notions. This complicates the opportunity of composing DP mechanisms in new settings and obtaining accurate estimates of the incurred privacy loss after composition.
  To overcome these limitations, we study the composability of DP in a general framework and for any kind of data domain or neighborhood definition. We give a general composition theorem in both independent and adaptive versions and we provide analogous composition results for approximate, zero-concentrated, and Gaussian DP. Besides, we study the hypothesis needed to obtain the best composition bounds. Our theorems cover both parallel and sequential composition settings. Importantly, they also cover every setting in between, allowing us to compute the final privacy loss of a composition with greatly improved accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14649v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patricia Guerra-Balboa, \`Alex Miranda-Pascual, Javier Parra-Arnau, Thorsten Strufe</dc:creator>
    </item>
    <item>
      <title>The Upper Clique Transversal Problem</title>
      <link>https://arxiv.org/abs/2309.14103</link>
      <description>arXiv:2309.14103v2 Announce Type: replace-cross 
Abstract: A clique transversal in a graph is a set of vertices intersecting all maximal cliques. The problem of determining the minimum size of a clique transversal has received considerable attention in the literature. In this paper, we initiate the study of the ''upper'' variant of this parameter, the upper clique transversal number, defined as the maximum size of a minimal clique transversal. We investigate this parameter from the algorithmic and complexity points of view, with a focus on various graph classes. We show that the corresponding decision problem is NP-complete in the classes of chordal graphs, chordal bipartite graphs, cubic planar bipartite graphs, and line graphs of bipartite graphs, but solvable in linear time in the classes of split graphs, proper interval graphs, and cographs, and in polynomial time for graphs of bounded cliquewidth. We conclude the paper with a number of open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14103v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Milani\v{c}, Yushi Uno</dc:creator>
    </item>
    <item>
      <title>Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems</title>
      <link>https://arxiv.org/abs/2311.04161</link>
      <description>arXiv:2311.04161v2 Announce Type: replace-cross 
Abstract: We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$, when the stochastic gradients have finite moments of order $\alpha \in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04161v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Puchkin, Eduard Gorbunov, Nikolay Kutuzov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Conditional lower bounds for sparse parameterized 2-CSP: A streamlined proof</title>
      <link>https://arxiv.org/abs/2311.05913</link>
      <description>arXiv:2311.05913v3 Announce Type: replace-cross 
Abstract: Assuming the Exponential Time Hypothesis (ETH), a result of Marx (ToC'10) implies that there is no $f(k)\cdot n^{o(k/\log k)}$ time algorithm that can solve 2-CSPs with $k$ constraints (over a domain of arbitrary large size $n$) for any computable function $f$. This lower bound is widely used to show that certain parameterized problems cannot be solved in time $f(k)\cdot n^{o(k/\log k)}$ time (assuming the ETH). The purpose of this note is to give a streamlined proof of this result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05913v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik C. S., D\'aniel Marx, Marcin Pilipczuk, U\'everton Souza</dc:creator>
    </item>
  </channel>
</rss>
