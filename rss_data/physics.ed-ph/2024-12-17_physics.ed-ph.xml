<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.ed-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.ed-ph</link>
    <description>physics.ed-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.ed-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2024 02:59:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Comparing Large Language Models for supervised analysis of students' lab notes</title>
      <link>https://arxiv.org/abs/2412.10610</link>
      <description>arXiv:2412.10610v1 Announce Type: new 
Abstract: We compare the application of Bag of Words, BERT, and various flavors of LLaMA machine learning models to perform large-scale analysis of written text grounded in a physics education research classification problem: identifying skills in students' typed lab notes through sentence-level labeling. We evaluate the models based on their resource use, performance metrics, and research outcomes when identifying skills in lab notes. We find that higher-resource models often, but not necessarily, perform better than lower-resource models. We also find that all models estimate similar trends in research outcomes, although the absolute values of the estimated measurements are not always within uncertainties of each other. We use the results to discuss relevant considerations for education researchers seeking to select a model type to use as a classifier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10610v1</guid>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebeckah K. Fussell, Megan Flynn, Anil Damle, Michael F. J. Fox, N. G. Holmes</dc:creator>
    </item>
    <item>
      <title>Generative AI as a lab partner: a case study</title>
      <link>https://arxiv.org/abs/2412.11300</link>
      <description>arXiv:2412.11300v1 Announce Type: new 
Abstract: Generative AI tools, including the popular ChatGPT, have made a clear mark on discourses related to future work and education practices. Previous research in science education has highlighted the potential for generative AI in various education-related areas, including generating valuable discussion material, solving physics problems, and acting as a tutor. However, little research has been done regarding the role of generative AI tools in laboratory work, an essential part of science education, and physics education specifically. Here we show various ways in which high school students use ChatGPT during a physics laboratory session and discuss the relevance of using generative AI tools to investigate acoustic levitation and the speed of sound in air. The findings show agreement with previous research regarding the importance of educating students about the capabilities and limitations of using generative AI. Contrasting fruitful and problematic interactions with ChatGPT during lab sessions with seven lab groups involving 19 high school students made it possible to identify that ChatGPT can be a helpful tool in the physics laboratory. However, the teacher plays a crucial role in identifying students' needs and capabilities of understanding the potential and limitations of generative AI. As such, our findings show that generative AI tools may handle some questions and problems and thus demonstrate their potential to help distribute teachers' workload more equitably during laboratory sessions. Finally, this study serves as an important point of discussion regarding the ways in which students need support and training to efficiently utilize generative AI to further their learning of physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11300v1</guid>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Kilde-Westberg, Andreas Johansson, Jonas Enger</dc:creator>
    </item>
  </channel>
</rss>
