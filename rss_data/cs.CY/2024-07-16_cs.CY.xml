<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 01:52:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ChatGPT and Vaccine Hesitancy: A Comparison of English, Spanish, and French Responses Using a Validated Scale</title>
      <link>https://arxiv.org/abs/2407.09481</link>
      <description>arXiv:2407.09481v1 Announce Type: new 
Abstract: ChatGPT is a popular information system (over 1 billion visits in August 2023) that can generate natural language responses to user queries. It is important to study the quality and equity of its responses on health-related topics, such as vaccination, as they may influence public health decision-making. We use the Vaccine Hesitancy Scale (VHS) proposed by Shapiro et al.1 to measure the hesitancy of ChatGPT responses in English, Spanish, and French. We find that: (a) ChatGPT responses indicate less hesitancy than those reported for human respondents in past literature; (b) ChatGPT responses vary significantly across languages, with English responses being the most hesitant on average and Spanish being the least; (c) ChatGPT responses are largely consistent across different model parameters but show some variations across the scale factors (vaccine competency, risk). Results have implications for researchers interested in evaluating and improving the quality and equity of health-related web information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09481v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saubhagya Joshi, Eunbin Ha, Yonaira Rivera, Vivek K. Singh</dc:creator>
    </item>
    <item>
      <title>The Shadow: Coevolution Processes Between a Director, Actors and Avatars</title>
      <link>https://arxiv.org/abs/2407.09483</link>
      <description>arXiv:2407.09483v1 Announce Type: new 
Abstract: Andersen's tale The Shadow offers a theatrical situation confronting a Scholar to his Shadow. I program specific creatures that I called shadow avatar to stage the story with five of them and a physical narrator. Echoing Edmond Couchot's ideas about virtual people helping human beings to adapt to technological evolutions, I describe dynamics of coevolution characterizing the relationship between a director, actors, and shadow avatars during the process of staging The Shadow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09483v1</guid>
      <category>cs.CY</category>
      <category>cs.GR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3632776.3632788</arxiv:DOI>
      <arxiv:journal_reference>ARTECH 2023: 11th International Conference on Digital and Interactive Arts, Nov 2023, Faro, Portugal. pp.23-32</arxiv:journal_reference>
      <dc:creator>Georges Gagner\'e (INREV)</dc:creator>
    </item>
    <item>
      <title>IT Enabling Factors in a new Industry Design: Open Banking and Digital Economy</title>
      <link>https://arxiv.org/abs/2407.09487</link>
      <description>arXiv:2407.09487v1 Announce Type: new 
Abstract: The fourth industrial revolution promotes the integration of Information Technology (IT) and strategic resources. New IT demands and uses have been leading to changes in business processes and corporate governance. Lately, the financial industry has adopted a new integrated banking model known as Open Banking (OB) and the advent of cryptocurrencies has led to the Digital Economy (DE) materialization. Considering these facts, this paper expects to point out through literature review some IT enabling factors that allow the conception of a new industry design (or governance) specifically in the financial industry illustrated by the cases of the Open Banking and Digital Economy. This paper is structured mostly on literature review, accompanied by results, discussions, and finally, conclusions are presented. It was found five potential enabling factors. Keywords: Digital Economy, Information Technology (IT), Open Banking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09487v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carlos Alberto Durigan Junior, Kumiko Oshio Kissimoto, Fernando Jose Barbin Laurindo</dc:creator>
    </item>
    <item>
      <title>Mining individual daily commuting patterns of dockless bike-sharing users: a two-layer framework integrating spatiotemporal flow clustering and rule-based decision trees</title>
      <link>https://arxiv.org/abs/2407.09820</link>
      <description>arXiv:2407.09820v1 Announce Type: new 
Abstract: The rise of dockless bike-sharing systems has led to increased interest in using bike-sharing data for urban transportation and travel behavior research. However, few studies have focused on the individual daily mobility patterns, hindering their alignment with the increasingly refined needs of urban active transportation planning. To bridge this gap, this study presents a two-layer framework, integrating improved flow clustering methods and multiple rule-based decision trees, to mine individual cyclists' daily home-work commuting patterns from vast dockless bike-sharing trip data with users' IDs. The effectiveness and applicability of the framework is demonstrated by over 200 million dockless bike-sharing trip records in Shenzhen. Ultimately, based on the mining results, we obtain two categories of bike-sharing commuters (i.e., 74.38% of Only-biking commuters and 25.62% of Biking-with-transit commuters) and some interesting findings about their daily commuting patterns. For instance, lots of bike-sharing commuters live near urban villages and old communities with lower costs of living, especially in the central city. Only-biking commuters have a higher proportion of overtime than Biking-with-transit commuters, and the Longhua Industrial Park, a manufacturing-oriented area, having the longest average working hours (over 10 hours per day). Massive commuters utilize bike-sharing for commuting to work more frequently than for returning home, which is closely related to the over-demand for bike-sharing around workplaces during commuting peak. Overall, this framework offers a cost-effective way to understand residents' non-motorized mobility patterns. Moreover, it paves the way for subsequent research on fine-scale cycling behaviors that consider demographic disparities in socio-economic attributes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09820v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caigang Zhuang, Shaoying Li, Xiaoping Liu</dc:creator>
    </item>
    <item>
      <title>To what extent is ChatGPT useful for language teacher lesson plan creation?</title>
      <link>https://arxiv.org/abs/2407.09974</link>
      <description>arXiv:2407.09974v1 Announce Type: new 
Abstract: The advent of generative AI models holds tremendous potential for aiding teachers in the generation of pedagogical materials. However, numerous knowledge gaps concerning the behavior of these models obfuscate the generation of research-informed guidance for their effective usage. Here we assess trends in prompt specificity, variability, and weaknesses in foreign language teacher lesson plans generated by zero-shot prompting in ChatGPT. Iterating a series of prompts that increased in complexity, we found that output lesson plans were generally high quality, though additional context and specificity to a prompt did not guarantee a concomitant increase in quality. Additionally, we observed extreme cases of variability in outputs generated by the same prompt. In many cases, this variability reflected a conflict between 20th century versus 21st century pedagogical practices. These results suggest that the training of generative AI models on classic texts concerning pedagogical practices may represent a currently underexplored topic with the potential to bias generated content towards teaching practices that have been long refuted by research. Collectively, our results offer immediate translational implications for practicing and training foreign language teachers on the use of AI tools. More broadly, these findings reveal the existence of generative AI output trends that have implications for the generation of pedagogical materials across a diversity of content areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09974v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Dornburg, Kristin Davin</dc:creator>
    </item>
    <item>
      <title>The GPT Surprise: Offering Large Language Model Chat in a Massive Coding Class Reduced Engagement but Increased Adopters Exam Performances</title>
      <link>https://arxiv.org/abs/2407.09975</link>
      <description>arXiv:2407.09975v1 Announce Type: new 
Abstract: Large language models (LLMs) are quickly being adopted in a wide range of learning experiences, especially via ubiquitous and broadly accessible chat interfaces like ChatGPT and Copilot. This type of interface is readily available to students and teachers around the world, yet relatively little research has been done to assess the impact of such generic tools on student learning. Coding education is an interesting test case, both because LLMs have strong performance on coding tasks, and because LLM-powered support tools are rapidly becoming part of the workflow of professional software engineers. To help understand the impact of generic LLM use on coding education, we conducted a large-scale randomized control trial with 5,831 students from 146 countries in an online coding class in which we provided some students with access to a chat interface with GPT-4. We estimate positive benefits on exam performance for adopters, the students who used the tool, but over all students, the advertisement of GPT-4 led to a significant average decrease in exam participation. We observe similar decreases in other forms of course engagement. However, this decrease is modulated by the student's country of origin. Offering access to LLMs to students from low human development index countries increased their exam participation rate on average. Our results suggest there may be promising benefits to using LLMs in an introductory coding class, but also potential harms for engagement, which makes their longer term impact on student success unclear. Our work highlights the need for additional investigations to help understand the potential impact of future adoption and integration of LLMs into classrooms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09975v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Allen Nie, Yash Chandak, Miroslav Suzara, Malika Ali, Juliette Woodrow, Matt Peng, Mehran Sahami, Emma Brunskill, Chris Piech</dc:creator>
    </item>
    <item>
      <title>Artificial intelligence and machine learning applications for cultured meat</title>
      <link>https://arxiv.org/abs/2407.09982</link>
      <description>arXiv:2407.09982v1 Announce Type: new 
Abstract: Cultured meat has the potential to provide a complementary meat industry with reduced environmental, ethical, and health impacts. However, major technological challenges remain which require time- and resource-intensive research and development efforts. Machine learning has the potential to accelerate cultured meat technology by streamlining experiments, predicting optimal results, and reducing experimentation time and resources. However, the use of machine learning in cultured meat is in its infancy. This review covers the work available to date on the use of machine learning in cultured meat and explores future possibilities. We address four major areas of cultured meat research and development: establishing cell lines, cell culture media design, microscopy and image analysis, and bioprocessing and food processing optimization. This review aims to provide the foundation necessary for both cultured meat and machine learning scientists to identify research opportunities at the intersection between cultured meat and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09982v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael E. Todhunter (Todhunter Scientifics, Minneapolis, MN, USA), Sheikh Jubair (Alberta Machine Intelligence Institute, Edmonton, AB, Canada), Ruchika Verma (Alberta Machine Intelligence Institute, Edmonton, AB, Canada), Rikard Saqe (University of Waterloo, Waterloo, ON, Canada), Kevin Shen (University of Waterloo, Waterloo, ON, Canada), Breanna Duffy (New Harvest, Sacramento, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Unleashing Excellence through Inclusion: Navigating the Engagement-Performance Paradox</title>
      <link>https://arxiv.org/abs/2407.09987</link>
      <description>arXiv:2407.09987v1 Announce Type: new 
Abstract: People who feel that they do not belong (or their voice is not heard at work) commonly become disengaged, unproductive, and pessimistic. Inclusive work environments aspire to close these gaps to increase employee satisfaction while reducing absenteeism and turnover. But there is always a job to be done, and under time and resource constraints, democratic approaches can result in reduced quality and unacceptable delays. Teams need actionable guidance to incorporate inclusive practices that will directly impact effectiveness. This paper contributes to the literature on quality and performance management by developing a conceptual model of inclusion that directly (and positively) impacts performance, and identifies eight factors that workgroups must address to create and maintain inclusive, high performing environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09987v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Radziwill, Morgan C. Benton</dc:creator>
    </item>
    <item>
      <title>AI and the Iterable Epistopics of Risk</title>
      <link>https://arxiv.org/abs/2407.10236</link>
      <description>arXiv:2407.10236v2 Announce Type: new 
Abstract: Abstract. The risks AI presents to society are broadly understood to be manageable through general calculus, i.e., general frameworks designed to enable those involved in the development of AI to apprehend and manage risk, such as AI impact assessments, ethical frameworks, emerging international standards, and regulations. This paper elaborates how risk is apprehended and managed by a regulator, developer and cyber-security expert. It reveals that risk and risk management is dependent on mundane situated practices not encapsulated in general calculus. Situated practice surfaces iterable epistopics, revealing how those involved in the development of AI know and subsequently respond to risk and uncover major challenges in their work. The ongoing discovery and elaboration of epistopics of risk in AI a) furnishes a potential program of interdisciplinary inquiry, b) provides AI developers with a means of apprehending risk, and c) informs the ongoing evolution of general calculus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10236v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andy Crabtree, Glenn McGarry, Lachlan Urquhart</dc:creator>
    </item>
    <item>
      <title>Towards Green AI: Current status and future research</title>
      <link>https://arxiv.org/abs/2407.10237</link>
      <description>arXiv:2407.10237v1 Announce Type: new 
Abstract: The immense technological progress in artificial intelligence research and applications is increasingly drawing attention to the environmental sustainability of such systems, a field that has been termed Green AI. With this contribution we aim to broaden the discourse on Green AI by investigating the current status of approaches to both environmental assessment and ecodesign of AI systems. We propose a life-cycle-based system thinking approach that accounts for the four key elements of these software-hardware-systems: model, data, server, and cloud. We conduct an exemplary estimation of the carbon footprint of relevant compute hardware and highlight the need to further investigate methods for Green AI and ways to facilitate wide-spread adoption of its principles. We envision that AI could be leveraged to mitigate its own environmental challenges, which we denote as AI4greenAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10237v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Clemm, Lutz Stobbe, Kishan Wimalawarne, Jan Druschke</dc:creator>
    </item>
    <item>
      <title>What is Reproducibility in Artificial Intelligence and Machine Learning Research?</title>
      <link>https://arxiv.org/abs/2407.10239</link>
      <description>arXiv:2407.10239v1 Announce Type: new 
Abstract: In the rapidly evolving fields of Artificial Intelligence (AI) and Machine Learning (ML), the reproducibility crisis underscores the urgent need for clear validation methodologies to maintain scientific integrity and encourage advancement. The crisis is compounded by the prevalent confusion over validation terminology. Responding to this challenge, we introduce a validation framework that clarifies the roles and definitions of key validation efforts: repeatability, dependent and independent reproducibility, and direct and conceptual replicability. This structured framework aims to provide AI/ML researchers with the necessary clarity on these essential concepts, facilitating the appropriate design, conduct, and interpretation of validation studies. By articulating the nuances and specific roles of each type of validation study, we hope to contribute to a more informed and methodical approach to addressing the challenges of reproducibility, thereby supporting the community's efforts to enhance the reliability and trustworthiness of its research findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10239v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Abhyuday Desai, Mohamed Abdelhamid, Nakul R. Padalkar</dc:creator>
    </item>
    <item>
      <title>Reimagining AI in Social Work: Practitioner Perspectives on Incorporating Technology in their Practice</title>
      <link>https://arxiv.org/abs/2407.10244</link>
      <description>arXiv:2407.10244v1 Announce Type: new 
Abstract: There has been a surge in the number and type of AI tools being tested and deployed within both national and local government in the UK, including within the social care sector. Given the many ongoing and planned future developments, the time is ripe to review and reflect on the state of AI in social care. We do so by conducting semi-structured interviews with UK-based social work professionals about their experiences and opinions of past and current AI systems. Our aim is to understand what systems would practitioners like to see developed and how. We find that all our interviewees had overwhelmingly negative past experiences of technology in social care, unanimous aversion to algorithmic decision systems in particular, but also strong interest in AI applications that could allow them to spend less time on administrative tasks. In response to our findings, we offer a series of concrete recommendations, which include commitment to participatory design, as well as the necessity of regaining practitioner trust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10244v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katie Wassal, Carolyn Ashurst, Jiri Hron, Miri Zilka</dc:creator>
    </item>
    <item>
      <title>CourseAssist: Pedagogically Appropriate Question Answering System for Computer Science Education</title>
      <link>https://arxiv.org/abs/2407.10246</link>
      <description>arXiv:2407.10246v1 Announce Type: new 
Abstract: The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-3.5 have demonstrated potential in assisting students through question-answering, educators have significant concerns about students misusing LLMs or LLMs misleading students with inaccurate answers. This paper introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist leverages retrieval-augmented generation along with user intent classification and post-processing to ensure that responses align with specific course learning goals, thereby addressing the pedagogical appropriateness of LLMs in educational settings. I evaluate CourseAssist against a baseline of GPT 3.5 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. This work not only highlights the importance of deliberate design considerations in LLM-based educational tools but also opens up avenues for future research, particularly in understanding user interactions with such systems in real-world scenarios and integrating human educators into LLM-based tutoring systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10246v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ty Feng</dc:creator>
    </item>
    <item>
      <title>Strategic Integration of Artificial Intelligence in the C-Suite: The Role of the Chief AI Officer</title>
      <link>https://arxiv.org/abs/2407.10247</link>
      <description>arXiv:2407.10247v1 Announce Type: new 
Abstract: The integration of Artificial Intelligence (AI) into corporate strategy has become a pivotal focus for organizations aiming to maintain a competitive advantage in the digital age. As AI reshapes business operations and drives innovation, the need for specialized leadership to effectively manage these changes becomes increasingly apparent. In this paper, I explore the role of the Chief AI Officer (CAIO) within the C-suite, emphasizing the necessity of this position for successful AI strategy, integration, and governance. I analyze future scenarios based on current trends in three key areas: the AI Economy, AI Organization, and Competition in the Age of AI. These explorations lay the foundation for identifying the antecedents (environmental, structural, and strategic factors) that justify the inclusion of a CAIO in top management teams. This sets the stage for a comprehensive examination of the CAIO's role and the broader implications of AI leadership. This paper advances the discussion on AI leadership by providing a rationale for the strategic integration of AI at the executive level and examining the role of the Chief AI Officer within organizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10247v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Schmitt</dc:creator>
    </item>
    <item>
      <title>Improving On-Time Undergraduate Graduation Rate For Undergraduate Students Using Predictive Analytics</title>
      <link>https://arxiv.org/abs/2407.10253</link>
      <description>arXiv:2407.10253v1 Announce Type: new 
Abstract: The on-time graduation rate among universities in Puerto Rico is significantly lower than in the mainland United States. This problem is noteworthy because it leads to substantial negative consequences for the student, both socially and economically, the educational institution and the local economy. This project aims to develop a predictive model that accurately detects students early in their academic pursuit at risk of not graduating on time. Various predictive models are developed to do this, and the best model, the one with the highest performance, is selected. Using a dataset containing information from 24432 undergraduate students at the University of Puerto Rico at Mayaguez, the predictive performance of the models is evaluated in two scenarios: Group I includes both the first year of college and pre-college factors, and Group II only considers pre-college factors. Overall, for both scenarios, the boosting model, trained on the oversampled dataset, is the most successful at predicting who will not graduate on time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10253v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramineh Lopez-Yazdani, Roberto Rivera</dc:creator>
    </item>
    <item>
      <title>The Elephant in the Room -- Why AI Safety Demands Diverse Teams</title>
      <link>https://arxiv.org/abs/2407.10254</link>
      <description>arXiv:2407.10254v1 Announce Type: new 
Abstract: We consider that existing approaches to AI "safety" and "alignment" may not be using the most effective tools, teams, or approaches. We suggest that an alternative and better approach to the problem may be to treat alignment as a social science problem, since the social sciences enjoy a rich toolkit of models for understanding and aligning motivation and behavior, much of which could be repurposed to problems involving AI models, and enumerate reasons why this is so. We introduce an alternate alignment approach informed by social science tools and characterized by three steps: 1. defining a positive desired social outcome for human/AI collaboration as the goal or "North Star," 2. properly framing knowns and unknowns, and 3. forming diverse teams to investigate, observe, and navigate emerging challenges in alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10254v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Rostcheck, Lara Scheibling</dc:creator>
    </item>
    <item>
      <title>Towards An Online Incremental Approach to Predict Students Performance</title>
      <link>https://arxiv.org/abs/2407.10256</link>
      <description>arXiv:2407.10256v1 Announce Type: new 
Abstract: Analytical models developed in offline settings with pre-prepared data are typically used to predict students' performance. However, when data are available over time, this learning method is not suitable anymore. Online learning is increasingly used to update the online models from stream data. A rehearsal technique is typically used, which entails re-training the model on a small training set that is updated each time new data is received.
  The main challenge in this regard is the construction of the training set with appropriate data samples to maintain good model performance. Typically, a random selection of samples is made, which can deteriorate the model's performance. In this paper, we propose a memory-based online incremental learning approach for updating an online classifier that predicts student performance using stream data. The approach is based on the use of the genetic algorithm heuristic while respecting the memory space constraints as well as the balance of class labels. In contrast to random selection, our approach improves the stability of the analytical model by promoting diversity when creating the training set. As a proof of concept, we applied it to the open dataset OULAD. Our approach achieves a notable improvement in model accuracy, with an enhancement of nearly 10% compared to the current state-of-the-art, while maintaining a relatively low standard deviation in accuracy, ranging from 1% to 2.1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10256v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chahrazed Labba, Anne Boyer</dc:creator>
    </item>
    <item>
      <title>Modern Information Technologies in Scientific Research and Educational Activities</title>
      <link>https://arxiv.org/abs/2407.10296</link>
      <description>arXiv:2407.10296v1 Announce Type: new 
Abstract: The monograph summarizes and analyzes the current state of scientific research in the field of interactive artificial intelligence systems, text generation systems, diagnostics of the competitiveness of specialists, in the areas of correct color rendering in image formation, informatization of the work of graduate students, accessible technology for creating three-dimensional 3D models. The monograph will be useful both to specialists and employees of companies working in the IT field, as well as teachers, masters, students and graduate students of higher educational institutions, as well as anyone interested in issues related to information technology. The monograph was compiled based on the results of the 16-th international scientific and practical conference Information technologies and automation - 2023, which took place in October 2023 at Odessa National University of Technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10296v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.31274/isudp.2024.151</arxiv:DOI>
      <dc:creator>Kyrylo Malakhov, Vadislav Kaverinskiy, Liliia Ivanova, Oleksandr Romanyuk, Oksana Romaniuk, Svitlana Voinova, Sergii Kotlyk, Oksana Sokolova</dc:creator>
    </item>
    <item>
      <title>Systematic analysis of the effectiveness of adding human mobility data to covid-19 case prediction linear models</title>
      <link>https://arxiv.org/abs/2407.10304</link>
      <description>arXiv:2407.10304v1 Announce Type: new 
Abstract: Human mobility data has been extensively used in covid-19 case prediction models. Nevertheless, related work has questioned whether mobility data really helps that much. We present a systematic analysis across mobility datasets and prediction lookaheads and reveal that adding mobility data to predictive models improves model performance only for about two months at the onset of the testing period, and that performance improvements -- measured as predicted vs. actual correlation improvement over non-mobility baselines -- are at most 0.3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10304v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saad Mohammad Abrar, Naman Awasthi, Daniel Smolyak, Vanessa Frias-Martinez</dc:creator>
    </item>
    <item>
      <title>Elements Of Legislation For Artificial Intelligence Systems</title>
      <link>https://arxiv.org/abs/2407.10305</link>
      <description>arXiv:2407.10305v1 Announce Type: new 
Abstract: The significant part of the operational context for autonomous company management systems is the regulatory and legal environment in which corporations operate. In order to create a dedicated operational context for autonomous artificial intelligence systems, the wording of local regulatory documents can be simultaneously presented in two versions: for use by people and for use by autonomous systems. In this case, the artificial intelligence system will get a well-defined operational context that allows such a system to perform functions within the required standards. Local regulations that provide basis for the joint work of individuals and autonomous artificial intelligence systems can form the grounds for the relevant legislation governing the development and implementation of autonomous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10305v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5121/ijscai.2024.13203</arxiv:DOI>
      <arxiv:journal_reference>International Journal on Soft Computing, Artificial Intelligence and Applications (IJSCAI), Vol.13, No.2, May 2024</arxiv:journal_reference>
      <dc:creator>Anna Romanova</dc:creator>
    </item>
    <item>
      <title>Impact of Different Infrastructures and Traffic Scenarios on Behavioral and Physiological Responses of E-scooter Users</title>
      <link>https://arxiv.org/abs/2407.10310</link>
      <description>arXiv:2407.10310v1 Announce Type: new 
Abstract: As micromobility devices such as e-scooters gain global popularity, emergency departments around the world have observed a rising trend in related injuries. However, the majority of current research on e-scooter safety relies heavily on surveys, news reports, and data from vendors, with a noticeable scarcity of naturalistic studies examining the effects of riders' behaviors and physiological responses. Therefore, this paper aims to study the responses of e-scooter users under different infrastructures and scenarios through naturalistic riding experiments. The findings indicate that different speed profiles, infrastructural elements, and traffic scenarios significantly influence riding dynamics. The experimental results also reveal that e-scooters face amplified safety challenges when navigating through areas with speed variations and without dedicated riding spaces. The study underscores the importance of considering infrastructure design and its influence on e-scooter safety, providing insights that could inform future urban planning and policy-making to enhance the safety of these increasingly popular vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10310v1</guid>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dong Chen, Arman Hosseini, Arik Smith, David Xiang, Arsalan Heydarian, Omid Shoghli, Bradford Campbell</dc:creator>
    </item>
    <item>
      <title>Public Discourse about COVID-19 Vaccinations: A Computational Analysis of the Relationship between Public Concerns and Policies</title>
      <link>https://arxiv.org/abs/2407.10321</link>
      <description>arXiv:2407.10321v1 Announce Type: new 
Abstract: Societies worldwide have witnessed growing rifts separating advocates and opponents of vaccinations and other COVID-19 countermeasures. With the rollout of vaccination campaigns, German-speaking regions exhibited much lower vaccination uptake than other European regions. While Austria, Germany, and Switzerland (the DACH region) caught up over time, it remains unclear which factors contributed to these changes. Scrutinizing public discourses can help shed light on the intricacies of vaccine hesitancy and inform policy-makers tasked with making far-reaching decisions: policies need to effectively curb the spread of the virus while respecting fundamental civic liberties and minimizing undesired consequences. This study draws on Twitter data to analyze the topics prevalent in the public discourse. It further maps the topics to different phases of the pandemic and policy changes to identify potential drivers of change in public attention. We use a hybrid pipeline to detect and analyze vaccination-related tweets using topic modeling, sentiment analysis, and a minimum of social scientific domain knowledge to analyze the discourse about vaccinations in the light of the COVID-19 pandemic in the DACH region. We show that skepticism regarding the severity of the COVID-19 virus and towards efficacy and safety of vaccines were among the prevalent topics in the discourse on Twitter but that the most attention was given to debating the theme of freedom and civic liberties. Especially during later phases of the pandemic, when implemented policies restricted the freedom of unvaccinated citizens, increased vaccination uptake could be observed. At the same time, increasingly negative and polarized sentiments emerge in the discourse. This suggests that these policies might have effectively attenuated vaccination hesitancy but were not successfully dispersing citizens' doubts and concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10321v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Katarina Boland, Christopher Starke, Felix Bensmann, Frank Marcinkowski, Stefan Dietze</dc:creator>
    </item>
    <item>
      <title>Building Collaborative Learning: Exploring Social Annotation in Introductory Programming</title>
      <link>https://arxiv.org/abs/2407.10322</link>
      <description>arXiv:2407.10322v1 Announce Type: new 
Abstract: The increasing demand for software engineering education presents learning challenges in courses due to the diverse range of topics that require practical applications, such as programming or software design, all of which are supported by group work and interaction. Social Annotation (SA) is an approach to teaching that can enhance collaborative learning among students. In SA, both students and teachers utilize platforms like Feedback Fruits, Perusall, and Diigo to collaboratively annotate and discuss course materials. This approach encourages students to share their thoughts and answers with their peers, fostering a more interactive learning environment. We share our experience of implementing social annotation via Perusall as a preparatory tool for lectures in an introductory programming course aimed at undergraduate students in Software Engineering. We report the impact of Perusall on the examination results of 112 students. Our results show that 81% of students engaged in meaningful social annotation successfully passed the course. Notably, the proportion of students passing the exam tends to rise as they complete more Perusall assignments. In contrast, only 56% of students who did not participate in Perusall discussions managed to pass the exam. We did not enforce mandatory Perusall participation in the course. Yet, the feedback from our course evaluation questionnaire reveals that most students ranked Perusall among their favorite components of the course and that their interest in the subject has increased.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10322v1</guid>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Gomes de Oliveira Neto, Felix Dobslaw</dc:creator>
    </item>
    <item>
      <title>Generative Discrimination: What Happens When Generative AI Exhibits Bias, and What Can Be Done About It</title>
      <link>https://arxiv.org/abs/2407.10329</link>
      <description>arXiv:2407.10329v1 Announce Type: new 
Abstract: As generative Artificial Intelligence (genAI) technologies proliferate across sectors, they offer significant benefits but also risk exacerbating discrimination. This chapter explores how genAI intersects with non-discrimination laws, identifying shortcomings and suggesting improvements. It highlights two main types of discriminatory outputs: (i) demeaning and abusive content and (ii) subtler biases due to inadequate representation of protected groups, which may not be overtly discriminatory in individual cases but have cumulative discriminatory effects. For example, genAI systems may predominantly depict white men when asked for images of people in important jobs.
  This chapter examines these issues, categorizing problematic outputs into three legal categories: discriminatory content; harassment; and legally hard cases like unbalanced content, harmful stereotypes or misclassification. It argues for holding genAI providers and deployers liable for discriminatory outputs and highlights the inadequacy of traditional legal frameworks to address genAI-specific issues. The chapter suggests updating EU laws, including the AI Act, to mitigate biases in training and input data, mandating testing and auditing, and evolving legislation to enforce standards for bias mitigation and inclusivity as technology advances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10329v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Philipp Hacker (European University Viadrina), Brent Mittelstadt (University of Oxford), Frederik Zuiderveen Borgesius (Radboud University), Sandra Wachter (University of Oxford)</dc:creator>
    </item>
    <item>
      <title>Ontology-driven Reinforcement Learning for Personalized Student Support</title>
      <link>https://arxiv.org/abs/2407.10332</link>
      <description>arXiv:2407.10332v1 Announce Type: new 
Abstract: In the search for more effective education, there is a widespread effort to develop better approaches to personalize student education. Unassisted, educators often do not have time or resources to personally support every student in a given classroom. Motivated by this issue, and by recent advancements in artificial intelligence, this paper presents a general-purpose framework for personalized student support, applicable to any virtual educational system such as a serious game or an intelligent tutoring system. To fit any educational situation, we apply ontologies for their semantic organization, combining them with data collection considerations and multi-agent reinforcement learning. The result is a modular system that can be adapted to any virtual educational software to provide useful personalized assistance to students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10332v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Hare, Ying Tang</dc:creator>
    </item>
    <item>
      <title>Mapping the Scholarship of Dark Pattern Regulation: A Systematic Review of Concepts, Regulatory Paradigms, and Solutions from an Interdisciplinary Perspective</title>
      <link>https://arxiv.org/abs/2407.10340</link>
      <description>arXiv:2407.10340v1 Announce Type: new 
Abstract: Dark patterns, design tricks used on online interfaces to manipulate users decision-making process, have raised public concerns. However, research on regulation of dark pattern remains underdeveloped and scattered, particularly regarding scholars views on the concept, regulatory paradigms, and solutions. Following PRISMA guidelines, this paper systematically reviews the formats and content of regulatory discussions on dark patterns from the interdisciplinary scholarship of Law and Human-Computer Interaction. A total of 65 studies were analysed through content and thematic analysis. This study synthesises the unique trends and characteristics of legal scholarship on dark patterns, identifying five root problems and triple layered harms. It critiques current regulations in terms of legal theories and sectoral legislations, highlighting their inadequacies in addressing dark patterns. The paper also critically examines existing proposed solutions, including paradigmatic shifts in legal doctrines, refinements to existing frameworks, technical design-embedded solutions, and accountability measures for design practices. This research critically discusses the current barriers to effective dark pattern regulations and explores promising regulatory solutions. The difficulty in identifying the normative nature of various forms of dark patterns, in identifying evident and actionable harm, and the expanding scope of dark patterns connotation inherently hinders effective regulation. However, technical design-embedded solutions, accountability frameworks, and practical design guidelines offer potential routes for more proactive regulation, while legal pluralism stands as a promising macro-level change in regulatory paradigms for dark pattern regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10340v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiwei Yi, Zihao Li</dc:creator>
    </item>
    <item>
      <title>Perceptions of Entrepreneurship Among Graduate Students: Challenges, Opportunities, and Cultural Biases</title>
      <link>https://arxiv.org/abs/2407.10367</link>
      <description>arXiv:2407.10367v1 Announce Type: new 
Abstract: The purpose of the paper is to examine the perceptions of entrepreneurship of graduate students enrolled in a digital-oriented entrepreneurship course, focusing on the challenges and opportunities related to starting a business. In today's digital era, businesses heavily depend on tailored software solutions to facilitate their operational processes, foster expansion, and enhance their competitive edge, thus assuming, to a certain degree, the characteristics of software companies. For data gathering, we used online exploratory surveys. The findings indicated that although entrepreneurship was considered an attractive option by students, very few of them declared that they intended to start a business soon. The main issues raised by the students were internal traits and external obstacles, such as lack of resources and support. Gender discrimination and cultural biases persist, limiting opportunities and equality for women. In terms of gender, women face limited representation in leadership roles, are expected to do more unpaid 'family work', are perceived as less capable in ding business, and need to prove their skills. Even if women are less discriminated now, both genders agree that women still face discrimination in business domain. In terms of percentages, women mentioned gender discrimination in higher percentages. Addressing these issues requires awareness, education, and policy changes to ensure fair treatment and opportunities for women.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10367v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5220/0012606000003693</arxiv:DOI>
      <dc:creator>Manuela Andreea Petrescu, Dan Mircea Suciu</dc:creator>
    </item>
    <item>
      <title>The Perceived Learning Behaviors and Assessment Techniques of First-Year Students in Computer Science: An Empirical Study</title>
      <link>https://arxiv.org/abs/2407.10368</link>
      <description>arXiv:2407.10368v1 Announce Type: new 
Abstract: The objective of our study is to ascertain the present learning behaviors, driving forces, and assessment techniques as perceived by first-year students, and to examine them through the lens of the most recent developments (pandemic, shift to remote instruction, return to in-person instruction). Educators and educational institutions can create a more accommodating learning environment that takes into account the varied needs and preferences of students by recognizing and implementing these findings, which will ultimately improve the quality of education as a whole. Students believe that in-person instruction is the most effective way to learn, with exercise-based learning, group instruction, and pair programming. Our research indicates that, for evaluation methods, there is a preference for practical and written examinations. Our findings also underscore the importance of incorporating real-world scenarios, encouraging interactive learning approaches, and creating engaging educational environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10368v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5220/0012674000003693</arxiv:DOI>
      <dc:creator>Manuela Andreea Petrescu, Tudor Dan Mihoc</dc:creator>
    </item>
    <item>
      <title>A Robust Governance for the AI Act: AI Office, AI Board, Scientific Panel, and National Authorities</title>
      <link>https://arxiv.org/abs/2407.10369</link>
      <description>arXiv:2407.10369v1 Announce Type: new 
Abstract: Regulation is nothing without enforcement. This particularly holds for the dynamic field of emerging technologies. Hence, this article has two ambitions. First, it explains how the EU's new Artificial Intelligence Act (AIA) will be implemented and enforced by various institutional bodies, thus clarifying the governance framework of the AIA. Second, it proposes a normative model of governance, providing recommendations to ensure uniform and coordinated execution of the AIA and the fulfilment of the legislation. Taken together, the article explores how the AIA may be implemented by national and EU institutional bodies, encompassing longstanding bodies, such as the European Commission, and those newly established under the AIA, such as the AI Office. It investigates their roles across supranational and national levels, emphasizing how EU regulations influence institutional structures and operations. These regulations may not only directly dictate the structural design of institutions but also indirectly request administrative capacities needed to enforce the AIA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10369v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Claudio Novelli, Philipp Hacker, Jessica Morley, Jarle Trondal, Luciano Floridi</dc:creator>
    </item>
    <item>
      <title>The Silent Curriculum: How Does LLM Monoculture Shape Educational Content and Its Accessibility?</title>
      <link>https://arxiv.org/abs/2407.10371</link>
      <description>arXiv:2407.10371v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) ascend in popularity, offering information with unprecedented convenience compared to traditional search engines, we delve into the intriguing possibility that a new, singular perspective is being propagated. We call this the "Silent Curriculum," where our focus shifts towards a particularly impressionable demographic: children, who are drawn to the ease and immediacy of acquiring knowledge through these digital oracles. In this exploration, we delve into the sociocultural ramifications of LLMs, which, through their nuanced responses, may be subtly etching their own stereotypes, an algorithmic or AI monoculture. We hypothesize that the convergence of pre-training data, fine-tuning datasets, and analogous guardrails across models may have birthed a distinct cultural lens. We unpack this concept through a short experiment navigating children's storytelling, occupational-ethnic biases, and self-diagnosed annotations, to find that there exists strong cosine similarity (0.87) of biases across these models, suggesting a similar perspective of ethnic stereotypes in occupations. This paper invites a reimagining of LLMs' societal role, especially as the new information gatekeepers, advocating for a paradigm shift towards diversity-rich landscapes over unintended monocultures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10371v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aman Priyanshu, Supriti Vijay</dc:creator>
    </item>
    <item>
      <title>Laypeople's Egocentric Perceptions of Copyright for AI-Generated Art</title>
      <link>https://arxiv.org/abs/2407.10546</link>
      <description>arXiv:2407.10546v1 Announce Type: new 
Abstract: Recent breakthroughs in generative AI (GenAI) have fueled debates concerning the status of AI-generated creations under copyright law. This research investigates laypeople's perceptions ($N$ = 424) of AI-generated art concerning factors associated with copyright protection. Inspired by prior work suggesting that people show egocentric biases when evaluating their own creative outputs, we also test if the same holds for AI-generated art. Namely, we study the differences between the perceptions of those who have something to gain from copyright protection -- creators of AI-generated art -- and uninvested third parties.
  To answer our research questions, we held an incentivized AI art competition, in which some participants used a GenAI model to generate images for consideration while others evaluated these submissions. We find that participants are most likely to attribute authorship and copyright over AI-generated images to the users who prompted the AI system to generate the image and the artists whose creations were used for training the AI model. We also find that participants egocentrically favored their own art over other participants' art and rated their own creations higher than other people evaluated them. Moreover, our results suggest that people judge their own AI-generated art more favorably with respect to some factors (creativity and effort) but not others (skills). Our findings have implications for future debates concerning the potential copyright protection of AI-generated outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10546v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Lima, Nina Grgi\'c-Hla\v{c}a, Elissa Redmiles</dc:creator>
    </item>
    <item>
      <title>Socioeconomic factors of national representation in the global film festival circuit: skewed toward the large and wealthy, but small countries can beat the odds</title>
      <link>https://arxiv.org/abs/2407.10755</link>
      <description>arXiv:2407.10755v2 Announce Type: new 
Abstract: This study analyzes how economic, demographic, and geographic factors predict the representation of different countries in the global film festival circuit. It relies on the combination of several open access datasets, including festival programming information from the Cinando platform of the Cannes Film Market, covering more than 30,000 screenings of over 20,000 films in almost 600 festivals across the world over a decade. It is shown that while the festival screen is indeed dominated by films from large affluent countries, the bias is nevertheless not fully proportional to the large demographic and economic disparities across the world, and that several small countries perform better than expected. It is further analyzed via computational simulations how much including films from smaller countries contributes to cultural diversity, and how countries differ in cultural "trade balance" dynamics, revealing differences between net exporters and importers of festival films. This research underscores the importance of balanced representation in film festivals and the public value of increasing cultural diversity. The data-driven insights and approaches to quantitative festival program and cultural event analytics are hoped to be useful for both the academic community as well as film festival organizers and policymakers aiming to foster more inclusive and diverse cultural landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10755v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andres Karjus</dc:creator>
    </item>
    <item>
      <title>Exploring the Factors of "AI Guilt" Among Students -- Are You Guilty of Using AI in Your Homework?</title>
      <link>https://arxiv.org/abs/2407.10777</link>
      <description>arXiv:2407.10777v1 Announce Type: new 
Abstract: This study explores the phenomenon of "AI guilt" among secondary school students, a form of moral discomfort arising from the use of AI tools in academic tasks traditionally performed by humans. Through qualitative methodologies, the research examines the factors contributing to AI guilt, its social and psychological impacts, and its implications for educational practices. The findings revealed three main dimensions for AI guilt - perceived laziness and authenticity, fear of judgment, and identity and self-efficacy concerns. The findings suggest a need to redefine academic integrity and shift our mindset to reconsider what we should value in education. The study also emphasizes the importance of ethical guidelines and educational support and provides implications to help students navigate the complexities of AI in education, reducing feelings of guilt while enhancing learning outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10777v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cecilia Ka Yuk Chan</dc:creator>
    </item>
    <item>
      <title>Innovation Resistance Theory in Action: Unveiling Barriers to Open Government Data Adoption by Public Organizations to Unlock Open Data Innovation</title>
      <link>https://arxiv.org/abs/2407.10883</link>
      <description>arXiv:2407.10883v1 Announce Type: new 
Abstract: Open Government Data (OGD) plays a pivotal role in fostering data-driven innovation and sustainability across various sectors. Despite its potential, many public organizations are reluctant to share their data openly. While existing research has explored factors impacting the public organizations intention to share OGD, there is a paucity of research applying theoretical models to investigate the resistance by public organizations to making government data publicly available. This study addresses the gap by developing an Innovation Resistance Theory (IRT) model tailored to OGD that allows identifying predictors of resistance among public agencies. We develop an initial model based on literature and refine it through interviews with 21 public agencies across six countries. The final model describes 39 barriers related to usage, value, risks, tradition, and image. The findings contribute to the literature by adapting IRT to the context of OGD, an area where its application has been notably limited. As such, this study addresses the growing demand for novel theoretical frameworks to examine OGD adoption barriers. Practical insights are provided to support policymakers in creating data ecosystems that encourage data openness and address challenges in OGD adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10883v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasija Nikiforova, Antoine Clarinval, Anneke Zuiderwijk, Daniel Rudmark, Petar Milic, Katrin Rajam\"ae-Soosaar</dc:creator>
    </item>
    <item>
      <title>Leveraging LLM-Respondents for Item Evaluation: a Psychometric Analysis</title>
      <link>https://arxiv.org/abs/2407.10899</link>
      <description>arXiv:2407.10899v1 Announce Type: new 
Abstract: Effective educational measurement relies heavily on the curation of well-designed item pools (i.e., possessing the right psychometric properties). However, item calibration is time-consuming and costly, requiring a sufficient number of respondents for the response process. We explore using six different LLMs (GPT-3.5, GPT-4, Llama 2, Llama 3, Gemini-Pro, and Cohere Command R Plus) and various combinations of them using sampling methods to produce responses with psychometric properties similar to human answers. Results show that some LLMs have comparable or higher proficiency in College Algebra than college students. No single LLM mimics human respondents due to narrow proficiency distributions, but an ensemble of LLMs can better resemble college students' ability distribution. The item parameters calibrated by LLM-Respondents have high correlations (e.g. &gt; 0.8 for GPT-3.5) compared to their human calibrated counterparts, and closely resemble the parameters of the human subset (e.g. 0.02 Spearman correlation difference). Several augmentation strategies are evaluated for their relative performance, with resampling methods proving most effective, enhancing the Spearman correlation from 0.89 (human only) to 0.93 (augmented human).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10899v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunting Liu, Shreya Bhandari, Zachary A. Pardos</dc:creator>
    </item>
    <item>
      <title>Blockchain Governance: An Empirical Analysis of User Engagement on DAOs</title>
      <link>https://arxiv.org/abs/2407.10945</link>
      <description>arXiv:2407.10945v1 Announce Type: new 
Abstract: In this note, we examine voting on four major blockchain DAOs: Aave, Compound, Lido and Uniswap. Using data directly collected from the Ethereum blockchain, we examine voter activity.
  We find that in most votes, the "minimal quorum," i.e., the smallest number of active voters who could swing the vote is quite small.
  To understand who is actually driving these DAOs, we use data from the Ethereum Name Service (ENS), Sybil.org, and Compound, to divide voters into different categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10945v1</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brett Falk, Tasneem Pathan, Andrew Rigas, Gerry Tsoukalas</dc:creator>
    </item>
    <item>
      <title>GPTutor: Great Personalized Tutor with Large Language Models for Personalized Learning Content Generation</title>
      <link>https://arxiv.org/abs/2407.09484</link>
      <description>arXiv:2407.09484v1 Announce Type: cross 
Abstract: We developed GPTutor, a pioneering web application designed to revolutionize personalized learning by leveraging the capabilities of Generative AI at scale. GPTutor adapts educational content and practice exercises to align with individual students' interests and career goals, enhancing their engagement and understanding of critical academic concepts. The system uses a serverless architecture to deliver personalized and scalable learning experiences. By integrating advanced Chain-of-Thoughts prompting methods, GPTutor provides a personalized educational journey that not only addresses the unique interests of each student but also prepares them for future professional success. This demo paper presents the design, functionality, and potential of GPTutor to foster a more engaging and effective educational environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09484v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eason Chen, Jia-En Lee, Jionghao Lin, Kenneth Koedinger</dc:creator>
    </item>
    <item>
      <title>MuseCL: Predicting Urban Socioeconomic Indicators via Multi-Semantic Contrastive Learning</title>
      <link>https://arxiv.org/abs/2407.09523</link>
      <description>arXiv:2407.09523v1 Announce Type: cross 
Abstract: Predicting socioeconomic indicators within urban regions is crucial for fostering inclusivity, resilience, and sustainability in cities and human settlements. While pioneering studies have attempted to leverage multi-modal data for socioeconomic prediction, jointly exploring their underlying semantics remains a significant challenge. To address the gap, this paper introduces a Multi-Semantic Contrastive Learning (MuseCL) framework for fine-grained urban region profiling and socioeconomic prediction. Within this framework, we initiate the process by constructing contrastive sample pairs for street view and remote sensing images, capitalizing on the similarities in human mobility and Point of Interest (POI) distribution to derive semantic features from the visual modality. Additionally, we extract semantic insights from POI texts embedded within these regions, employing a pre-trained text encoder. To merge the acquired visual and textual features, we devise an innovative cross-modality-based attentional fusion module, which leverages a contrastive mechanism for integration. Experimental results across multiple cities and indicators consistently highlight the superiority of MuseCL, demonstrating an average improvement of 10% in $R^2$ compared to various competitive baseline models. The code of this work is publicly available at https://github.com/XixianYong/MuseCL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09523v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xixian Yong, Xiao Zhou</dc:creator>
    </item>
    <item>
      <title>Balancing the Scales: Reinforcement Learning for Fair Classification</title>
      <link>https://arxiv.org/abs/2407.10629</link>
      <description>arXiv:2407.10629v1 Announce Type: cross 
Abstract: Fairness in classification tasks has traditionally focused on bias removal from neural representations, but recent trends favor algorithmic methods that embed fairness into the training process. These methods steer models towards fair performance, preventing potential elimination of valuable information that arises from representation manipulation. Reinforcement Learning (RL), with its capacity for learning through interaction and adjusting reward functions to encourage desired behaviors, emerges as a promising tool in this domain. In this paper, we explore the usage of RL to address bias in imbalanced classification by scaling the reward function to mitigate bias. We employ the contextual multi-armed bandit framework and adapt three popular RL algorithms to suit our objectives, demonstrating a novel approach to mitigating bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10629v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leon Eshuijs, Shihan Wang, Antske Fokkens</dc:creator>
    </item>
    <item>
      <title>Prompt Selection Matters: Enhancing Text Annotations for Social Sciences with Large Language Models</title>
      <link>https://arxiv.org/abs/2407.10645</link>
      <description>arXiv:2407.10645v1 Announce Type: cross 
Abstract: Large Language Models have recently been applied to text annotation tasks from social sciences, equalling or surpassing the performance of human workers at a fraction of the cost. However, no inquiry has yet been made on the impact of prompt selection on labelling accuracy. In this study, we show that performance greatly varies between prompts, and we apply the method of automatic prompt optimization to systematically craft high quality prompts. We also provide the community with a simple, browser-based implementation of the method at https://prompt-ultra.github.io/ .</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10645v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis Abraham, Charles Arnal, Antoine Marie</dc:creator>
    </item>
    <item>
      <title>Transforming Agency. On the mode of existence of Large Language Models</title>
      <link>https://arxiv.org/abs/2407.10735</link>
      <description>arXiv:2407.10735v2 Announce Type: cross 
Abstract: This paper investigates the ontological characterization of Large Language Models (LLMs) like ChatGPT. Between inflationary and deflationary accounts, we pay special attention to their status as agents. This requires explaining in detail the architecture, processing, and training procedures that enable LLMs to display their capacities, and the extensions used to turn LLMs into agent-like systems. After a systematic analysis we conclude that a LLM fails to meet necessary and sufficient conditions for autonomous agency in the light of embodied theories of mind: the individuality condition (it is not the product of its own activity, it is not even directly affected by it), the normativity condition (it does not generate its own norms or goals), and, partially the interactional asymmetry condition (it is not the origin and sustained source of its interaction with the environment). If not agents, then ... what are LLMs? We argue that ChatGPT should be characterized as an interlocutor or linguistic automaton, a library-that-talks, devoid of (autonomous) agency, but capable to engage performatively on non-purposeful yet purpose-structured and purpose-bounded tasks. When interacting with humans, a "ghostly" component of the human-machine interaction makes it possible to enact genuine conversational experiences with LLMs. Despite their lack of sensorimotor and biological embodiment, LLMs textual embodiment (the training corpus) and resource-hungry computational embodiment, significantly transform existing forms of human agency. Beyond assisted and extended agency, the LLM-human coupling can produce midtended forms of agency, closer to the production of intentional agency than to the extended instrumentality of any previous technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10735v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xabier E. Barandiaran, Lola S. Almendros</dc:creator>
    </item>
    <item>
      <title>The Missing Link: Allocation Performance in Causal Machine Learning</title>
      <link>https://arxiv.org/abs/2407.10779</link>
      <description>arXiv:2407.10779v1 Announce Type: cross 
Abstract: Automated decision-making (ADM) systems are being deployed across a diverse range of critical problem areas such as social welfare and healthcare. Recent work highlights the importance of causal ML models in ADM systems, but implementing them in complex social environments poses significant challenges. Research on how these challenges impact the performance in specific downstream decision-making tasks is limited. Addressing this gap, we make use of a comprehensive real-world dataset of jobseekers to illustrate how the performance of a single CATE model can vary significantly across different decision-making scenarios and highlight the differential influence of challenges such as distribution shifts on predictions and allocations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10779v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Unai Fischer-Abaigar, Christoph Kern, Frauke Kreuter</dc:creator>
    </item>
    <item>
      <title>Vehicle-to-grid for car sharing -- A simulation study for 2030</title>
      <link>https://arxiv.org/abs/2311.07349</link>
      <description>arXiv:2311.07349v2 Announce Type: replace 
Abstract: The proliferation of car sharing services in recent years presents a promising avenue for advancing sustainable transportation. Beyond merely reducing car ownership rates, these systems can play a pivotal role in bolstering grid stability through the provision of ancillary services via vehicle-to-grid (V2G) technologies - a facet that has received limited attention in previous research. In this study, we analyze the potential of V2G in car sharing by designing future scenarios for a national-scale service in Switzerland. We propose an agent-based simulation pipeline that considers population changes as well as different business strategies of the car sharing service, and we demonstrate its successful application for simulating scenarios for 2030. To imitate car sharing user behavior, we develop a data-driven mode choice model. Our analysis reveals important differences in the examined scenarios, such as higher vehicle utilization rates for a reduced fleet size as well as in a scenario featuring new car sharing stations. These disparities translate into variations in the power flexibility of the fleet available for ancillary services, ranging from 12 to 50 MW, depending on the scenario and the time of the day. Furthermore, we conduct a case study involving a subset of the car sharing fleet, incorporating real-world electricity pricing data. The case study substantiates the existence of a sweet spot involving monetary gains for both power grid operators and fleet owners. Our findings provide guidelines to decision makers and underscore the pressing need for regulatory enhancements concerning power trading within the realm of car sharing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07349v2</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nina Wiedemann, Yanan Xin, Vasco Medici, Lorenzo Nespoli, Esra Suel, Martin Raubal</dc:creator>
    </item>
    <item>
      <title>Metaverse Identity: Core Principles and Critical Challenges</title>
      <link>https://arxiv.org/abs/2406.08029</link>
      <description>arXiv:2406.08029v2 Announce Type: replace 
Abstract: This paper explores the core principles that should guide the construction and governance of identity in the metaverse and identifies the critical challenges that need to be addressed. Drawing on multidisciplinary theories and perspectives, we define metaverse identity and propose two core principles for understanding its intrinsic characteristics and impacts: Equivalence and Alignment, and Fusion and Expansiveness. The first principle asserts that metaverse identities should align with real-world norms and standards, which is crucial for establishing guidelines and safeguarding rights. The second principle emphasizes the need for seamless integration and boundless expansion of metaverse identities, transcending real-world limitations to accommodate diverse needs and foster inclusive participation. We argue that these two principles are vital for ensuring the accountability, inclusiveness, and consistency in the emerging metaverse era. Additionally, we identify five critical challenges: Identity Interoperability, Legal Implications, Privacy and Identity Management, Deepfakes and Synthetic Identities, and Identity Fragmentation and Psychological Well-being. We discuss potential strategies to navigate these challenges. The paper concludes by underscoring the importance of a proactive and collaborative approach to shaping the future of metaverse identity. As the metaverse continues to evolve, it is imperative that we understand and address the principles and challenges surrounding identity in this uncharted territory and work collectively to build a metaverse that fosters responsible identity construction and expression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08029v2</guid>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Liang Yang, Yan Xu, Pan Hui</dc:creator>
    </item>
    <item>
      <title>Finding Fake News Websites in the Wild</title>
      <link>https://arxiv.org/abs/2407.07159</link>
      <description>arXiv:2407.07159v2 Announce Type: replace 
Abstract: The battle against the spread of misinformation on the Internet is a daunting task faced by modern society. Fake news content is primarily distributed through digital platforms, with websites dedicated to producing and disseminating such content playing a pivotal role in this complex ecosystem. Therefore, these websites are of great interest to misinformation researchers. However, obtaining a comprehensive list of websites labeled as producers and/or spreaders of misinformation can be challenging, particularly in developing countries. In this study, we propose a novel methodology for identifying websites responsible for creating and disseminating misinformation content, which are closely linked to users who share confirmed instances of fake news on social media. We validate our approach on Twitter by examining various execution modes and contexts. Our findings demonstrate the effectiveness of the proposed methodology in identifying misinformation websites, which can aid in gaining a better understanding of this phenomenon and enabling competent entities to tackle the problem in various areas of society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07159v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leandro Araujo, Joao M. M. Couto, Luiz Felipe Nery, Isadora C. Rodrigues, Jussara M. Almeida, Julio C. S. Reis, Fabricio Benevenuto</dc:creator>
    </item>
    <item>
      <title>Industry Risk Assessment via Hierarchical Financial Data Using Stock Market Sentiment Indicators</title>
      <link>https://arxiv.org/abs/2303.02707</link>
      <description>arXiv:2303.02707v2 Announce Type: replace-cross 
Abstract: Risk assessment across industries is paramount for ensuring a robust and sustainable economy. While previous studies have relied heavily on official statistics for their accuracy, they often lag behind real-time developments. Addressing this gap, our research endeavors to integrate market microstructure theory with AI technologies to refine industry risk predictions. This paper presents an approach to analyzing industry trends leveraging real-time stock market data and generative small language models (SLMs). By enhancing the timeliness of risk assessments and delving into the influence of non-traditional factors such as market sentiment and investor behavior, we strive to develop a more holistic and dynamic risk assessment model. One of the key challenges lies in the inherent noise in raw data, which can compromise the precision of statistical analyses. Moreover, textual data about industry analysis necessitates a deeper understanding facilitated by pre-trained language models. To tackle these issues, we propose a dual-pronged approach to industry trend analysis: explicit and implicit analysis. For explicit analysis, we employ a hierarchical data analysis methodology that spans the industry and individual listed company levels. This strategic breakdown helps mitigate the impact of data noise, ensuring a more accurate portrayal of industry dynamics. In parallel, we introduce implicit analysis, where we pre-train an SML to interpret industry trends within the context of current news events. This approach leverages the extensive knowledge embedded in the pre-training corpus, enabling a nuanced understanding of industry trends and their underlying drivers. Experimental results based on our proposed methodology demonstrate its effectiveness in delivering robust industry trend analyses, underscoring its potential to revolutionize risk assessment practices across industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02707v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyin Zhu</dc:creator>
    </item>
    <item>
      <title>Bias and Fairness in Large Language Models: A Survey</title>
      <link>https://arxiv.org/abs/2309.00770</link>
      <description>arXiv:2309.00770v3 Announce Type: replace-cross 
Abstract: Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this paper, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly-available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00770v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, Nesreen K. Ahmed</dc:creator>
    </item>
    <item>
      <title>ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation</title>
      <link>https://arxiv.org/abs/2401.06310</link>
      <description>arXiv:2401.06310v3 Announce Type: replace-cross 
Abstract: Recent studies have shown that Text-to-Image (T2I) model generations can reflect social stereotypes present in the real world. However, existing approaches for evaluating stereotypes have a noticeable lack of coverage of global identity groups and their associated stereotypes. To address this gap, we introduce the ViSAGe (Visual Stereotypes Around the Globe) dataset to enable the evaluation of known nationality-based stereotypes in T2I models, across 135 nationalities. We enrich an existing textual stereotype resource by distinguishing between stereotypical associations that are more likely to have visual depictions, such as `sombrero', from those that are less visually concrete, such as 'attractive'. We demonstrate ViSAGe's utility through a multi-faceted evaluation of T2I generations. First, we show that stereotypical attributes in ViSAGe are thrice as likely to be present in generated images of corresponding identities as compared to other attributes, and that the offensiveness of these depictions is especially higher for identities from Africa, South America, and South East Asia. Second, we assess the stereotypical pull of visual depictions of identity groups, which reveals how the 'default' representations of all identity groups in ViSAGe have a pull towards stereotypical depictions, and that this pull is even more prominent for identity groups from the Global South. CONTENT WARNING: Some examples contain offensive stereotypes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06310v3</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshita Jha, Vinodkumar Prabhakaran, Remi Denton, Sarah Laszlo, Shachi Dave, Rida Qadri, Chandan K. Reddy, Sunipa Dev</dc:creator>
    </item>
    <item>
      <title>Discovering Latent Themes in Social Media Messaging: A Machine-in-the-Loop Approach Integrating LLMs</title>
      <link>https://arxiv.org/abs/2403.10707</link>
      <description>arXiv:2403.10707v2 Announce Type: replace-cross 
Abstract: Grasping the themes of social media content is key to understanding the narratives that influence public opinion and behavior. The thematic analysis goes beyond traditional topic-level analysis, which often captures only the broadest patterns, providing deeper insights into specific and actionable themes such as "public sentiment towards vaccination", "political discourse surrounding climate policies," etc. In this paper, we introduce a novel approach to uncovering latent themes in social media messaging. Recognizing the limitations of the traditional topic-level analysis, which tends to capture only overarching patterns, this study emphasizes the need for a finer-grained, theme-focused exploration. Traditional theme discovery methods typically involve manual processes and a human-in-the-loop approach. While valuable, these methods face challenges in scalability, consistency, and resource intensity in terms of time and cost. To address these challenges, we propose a machine-in-the-loop approach that leverages the advanced capabilities of Large Language Models (LLMs). To demonstrate our approach, we apply our framework to contentious topics, such as climate debate and vaccine debate. We use two publicly available datasets: (1) the climate campaigns dataset of 21k Facebook ads and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads. Our quantitative and qualitative analysis shows that our methodology yields more accurate and interpretable results compared to the baselines. Our results not only demonstrate the effectiveness of our approach in uncovering latent themes but also illuminate how these themes are tailored for demographic targeting in social media contexts. Additionally, our work sheds light on the dynamic nature of social media, revealing the shifts in the thematic focus of messaging in response to real-world events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10707v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tunazzina Islam, Dan Goldwasser</dc:creator>
    </item>
    <item>
      <title>Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy</title>
      <link>https://arxiv.org/abs/2404.10259</link>
      <description>arXiv:2404.10259v2 Announce Type: replace-cross 
Abstract: The widespread use of social media has led to a surge in popularity for automated methods of analyzing public opinion. Supervised methods are adept at text categorization, yet the dynamic nature of social media discussions poses a continual challenge for these techniques due to the constant shifting of the focus. On the other hand, traditional unsupervised methods for extracting themes from public discourse, such as topic modeling, often reveal overarching patterns that might not capture specific nuances. Consequently, a significant portion of research into social media discourse still depends on labor-intensive manual coding techniques and a human-in-the-loop approach, which are both time-consuming and costly. In this work, we study the problem of discovering arguments associated with a specific theme. We propose a generic LLMs-in-the-Loop strategy that leverages the advanced capabilities of Large Language Models (LLMs) to extract latent arguments from social media messaging. To demonstrate our approach, we apply our framework to contentious topics. We use two publicly available datasets: (1) the climate campaigns dataset of 14k Facebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of 9k Facebook ads with 14 themes. Additionally, we design a downstream task as stance prediction by leveraging talking points in climate debates. Furthermore, we analyze demographic targeting and the adaptation of messaging based on real-world events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10259v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tunazzina Islam, Dan Goldwasser</dc:creator>
    </item>
    <item>
      <title>Evaluating Algorithmic Bias in Models for Predicting Academic Performance of Filipino Students</title>
      <link>https://arxiv.org/abs/2405.09821</link>
      <description>arXiv:2405.09821v2 Announce Type: replace-cross 
Abstract: Algorithmic bias is a major issue in machine learning models in educational contexts. However, it has not yet been studied thoroughly in Asian learning contexts, and only limited work has considered algorithmic bias based on regional (sub-national) background. As a step towards addressing this gap, this paper examines the population of 5,986 students at a large university in the Philippines, investigating algorithmic bias based on students' regional background. The university used the Canvas learning management system (LMS) in its online courses across a broad range of domains. Over the period of three semesters, we collected 48.7 million log records of the students' activity in Canvas. We used these logs to train binary classification models that predict student grades from the LMS activity. The best-performing model reached AUC of 0.75 and weighted F1-score of 0.79. Subsequently, we examined the data for bias based on students' region. Evaluation using three metrics: AUC, weighted F1-score, and MADD showed consistent results across all demographic groups. Thus, no unfairness was observed against a particular student group in the grade predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09821v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.12729936</arxiv:DOI>
      <dc:creator>Valdemar \v{S}v\'abensk\'y, M\'elina Verger, Maria Mercedes T. Rodrigo, Clarence James G. Monterozo, Ryan S. Baker, Miguel Zenon Nicanor Lerias Saavedra, S\'ebastien Lall\'e, Atsushi Shimada</dc:creator>
    </item>
    <item>
      <title>Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP</title>
      <link>https://arxiv.org/abs/2405.17159</link>
      <description>arXiv:2405.17159v2 Announce Type: replace-cross 
Abstract: Personal names simultaneously differentiate individuals and categorize them in ways that are important in a given society. While the natural language processing community has thus associated personal names with sociodemographic characteristics in a variety of tasks, researchers have engaged to varying degrees with the established methodological problems in doing so. To guide future work that uses names and sociodemographic characteristics, we provide an overview of relevant research: first, we present an interdisciplinary background on names and naming. We then survey the issues inherent to associating names with sociodemographic attributes, covering problems of validity (e.g., systematic error, construct validity), as well as ethical concerns (e.g., harms, differential impact, cultural insensitivity). Finally, we provide guiding questions along with normative recommendations to avoid validity and ethical pitfalls when dealing with names and sociodemographic characteristics in natural language processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17159v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vagrant Gautam, Arjun Subramonian, Anne Lauscher, Os Keyes</dc:creator>
    </item>
    <item>
      <title>ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs</title>
      <link>https://arxiv.org/abs/2406.18120</link>
      <description>arXiv:2406.18120v2 Announce Type: replace-cross 
Abstract: Motivated by the widespread increase in the phenomenon of code-switching between Egyptian Arabic and English in recent times, this paper explores the intricacies of machine translation (MT) and automatic speech recognition (ASR) systems, focusing on translating code-switched Egyptian Arabic-English to either English or Egyptian Arabic. Our goal is to present the methodologies employed in developing these systems, utilizing large language models such as LLama and Gemma. In the field of ASR, we explore the utilization of the Whisper model for code-switched Egyptian Arabic recognition, detailing our experimental procedures including data preprocessing and training techniques. Through the implementation of a consecutive speech-to-text translation system that integrates ASR with MT, we aim to overcome challenges posed by limited resources and the unique characteristics of the Egyptian Arabic dialect. Evaluation against established metrics showcases promising results, with our methodologies yielding a significant improvement of $56\%$ in English translation over the state-of-the-art and $9.3\%$ in Arabic translation. Since code-switching is deeply inherent in spoken languages, it is crucial that ASR systems can effectively handle this phenomenon. This capability is crucial for enabling seamless interaction in various domains, including business negotiations, cultural exchanges, and academic discourse. Our models and code are available as open-source resources. Code: \url{http://github.com/ahmedheakl/arazn-llm}}, Models: \url{http://huggingface.co/collections/ahmedheakl/arazn-llm-662ceaf12777656607b9524e}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18120v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Heakl, Youssef Zaghloul, Mennatullah Ali, Rania Hossam, Walid Gomaa</dc:creator>
    </item>
    <item>
      <title>ResumeAtlas: Revisiting Resume Classification with Large-Scale Datasets and Large Language Models</title>
      <link>https://arxiv.org/abs/2406.18125</link>
      <description>arXiv:2406.18125v2 Announce Type: replace-cross 
Abstract: The increasing reliance on online recruitment platforms coupled with the adoption of AI technologies has highlighted the critical need for efficient resume classification methods. However, challenges such as small datasets, lack of standardized resume templates, and privacy concerns hinder the accuracy and effectiveness of existing classification models. In this work, we address these challenges by presenting a comprehensive approach to resume classification. We curated a large-scale dataset of 13,389 resumes from diverse sources and employed Large Language Models (LLMs) such as BERT and Gemma1.1 2B for classification. Our results demonstrate significant improvements over traditional machine learning approaches, with our best model achieving a top-1 accuracy of 92\% and a top-5 accuracy of 97.5\%. These findings underscore the importance of dataset quality and advanced model architectures in enhancing the accuracy and robustness of resume classification systems, thus advancing the field of online recruitment practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18125v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Heakl, Youssef Mohamed, Noran Mohamed, Aly Elsharkawy, Ahmed Zaky</dc:creator>
    </item>
    <item>
      <title>What Do People Think about Sentient AI?</title>
      <link>https://arxiv.org/abs/2407.08867</link>
      <description>arXiv:2407.08867v2 Announce Type: replace-cross 
Abstract: With rapid advances in machine learning, many people in the field have been discussing the rise of digital minds and the possibility of artificial sentience. Future developments in AI capabilities and safety will depend on public opinion and human-AI interaction. To begin to fill this research gap, we present the first nationally representative survey data on the topic of sentient AI: initial results from the Artificial Intelligence, Morality, and Sentience (AIMS) survey, a preregistered and longitudinal study of U.S. public opinion that began in 2021. Across one wave of data collection in 2021 and two in 2023 (total N = 3,500), we found mind perception and moral concern for AI well-being in 2021 were higher than predicted and significantly increased in 2023: for example, 71% agree sentient AI deserve to be treated with respect, and 38% support legal rights. People have become more threatened by AI, and there is widespread opposition to new technologies: 63% support a ban on smarter-than-human AI, and 69% support a ban on sentient AI. Expected timelines are surprisingly short and shortening with a median forecast of sentient AI in only five years and artificial general intelligence in only two years. We argue that, whether or not AIs become sentient, the discussion itself may overhaul human-computer interaction and shape the future trajectory of AI technologies, including existential risks and opportunities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08867v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacy Reese Anthis, Janet V. T. Pauketat, Ali Ladak, Aikaterina Manoli</dc:creator>
    </item>
  </channel>
</rss>
