<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2025 03:20:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Implications of Artificial Intelligence on Health Data Privacy and Confidentiality</title>
      <link>https://arxiv.org/abs/2501.01639</link>
      <description>arXiv:2501.01639v2 Announce Type: new 
Abstract: The rapid integration of artificial intelligence (AI) in healthcare is revolutionizing medical diagnostics, personalized medicine, and operational efficiency. However, alongside these advancements, significant challenges arise concerning patient data privacy, ethical considerations, and regulatory compliance. This paper examines the dual impact of AI on healthcare, highlighting its transformative potential and the critical need for safeguarding sensitive health information. It explores the role of the Health Insurance Portability and Accountability Act (HIPAA) as a regulatory framework for ensuring data privacy and security, emphasizing the importance of robust safeguards and ethical standards in AI-driven healthcare. Through case studies, including AI applications in diabetic retinopathy, oncology, and the controversies surrounding data sharing, this study underscores the ethical and legal complexities of AI implementation. A balanced approach that fosters innovation while maintaining patient trust and privacy is imperative. The findings emphasize the importance of continuous education, transparency, and adherence to regulatory frameworks to harness AI's full potential responsibly and ethically in healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01639v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ahmad Momani</dc:creator>
    </item>
    <item>
      <title>Mapping Compliance: A Taxonomy for Political Content Analysis under the EU's Digital Electoral Framework</title>
      <link>https://arxiv.org/abs/2501.01738</link>
      <description>arXiv:2501.01738v1 Announce Type: new 
Abstract: The rise of digital platforms has transformed political campaigning, introducing complex regulatory challenges. This paper presents a comprehensive taxonomy for analyzing political content in the EU's digital electoral landscape, aligning with the requirements set forth in new regulations, such as the Digital Services Act. Using a legal doctrinal methodology, we construct a detailed codebook that enables systematic content analysis across user-generated and political ad content to assess compliance with regulatory mandates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01738v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marie-Therese Sekwenz, Rita Gsenger</dc:creator>
    </item>
    <item>
      <title>From Occasional to Steady: Habit Formation Insights From a Comprehensive Fitness Study</title>
      <link>https://arxiv.org/abs/2501.01779</link>
      <description>arXiv:2501.01779v1 Announce Type: new 
Abstract: Exercising regularly is widely recognized as a cornerstone of health, yet the challenge of sustaining consistent exercise habits persists. Understanding the factors that influence the formation of these habits is crucial for developing effective interventions. This study utilizes data from Mars Athletic Club, T\"urkiye's largest sports chain, to investigate the dynamics of gym attendance and habit formation. The general problem addressed by this study is identifying the critical periods and factors that contribute to the successful establishment of consistent exercise routines among gym-goers. Here we show that there are specific periods during which gym attendance is most crucial for habit formation. By developing a survival metric based on gym attendance patterns, we pinpoint these critical periods and segment members into distinct clusters based on their visit patterns. Our analysis reveals significant differences in how various subgroups respond to interventions, such as group classes, personal trainer sessions, and visiting different clubs. Using causal inference analysis, we demonstrate that personalized guidance and social dynamics are key drivers of sustained long-term engagement. By systematically examining these variables and considering the specific characteristics of different clusters, our research demonstrates the importance of a tailored, multi-dimensional approach to promoting exercise habits, which integrates social dynamics, personalized guidance, and strategic interventions to sustain long-term engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01779v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.SI</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ege Demirci, Efe Tuzun, Ahmet Furkan Un, Taner Giray Sonmez, Onur Varol</dc:creator>
    </item>
    <item>
      <title>A Metasemantic-Metapragmatic Framework for Taxonomizing Multimodal Communicative Alignment</title>
      <link>https://arxiv.org/abs/2501.01535</link>
      <description>arXiv:2501.01535v1 Announce Type: cross 
Abstract: Drawing on contemporary pragmatist philosophy and linguistic theories on cognition, meaning, and communication, this paper presents a dynamic, metasemantic-metapragmatic taxonomy for grounding and conceptualizing human-like multimodal communicative alignment. The framework is rooted in contemporary developments of the three basic communicative capacities initially identified by American logician and pragmatist philosopher Charles Sanders Peirce: iconic (sensory and perceptual qualities), indexical (contextual and sociocultural associations), and rule-like (symbolic and intuitive reasoning). Expanding on these developments, I introduce the concept of indexical contextualization and propose the principle of "contextualization directionality" for characterizing the crucial metapragmatic capacity for maintaining, navigating, or transitioning between semantic and pragmatic modes of multimodal communication. I contend that current cognitive-social computational and engineering methodologies disproportionately emphasize the semantic/metasemantic domain, overlooking the pivotal role of metapragmatic indexicality in traversing the semantic-pragmatic spectrum of communication. The framework's broader implications for intentionality, identity, affect, and ethics in within-modal and cross-modal human-machine alignment are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01535v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugene Yu Ji</dc:creator>
    </item>
    <item>
      <title>FairSense: Long-Term Fairness Analysis of ML-Enabled Systems</title>
      <link>https://arxiv.org/abs/2501.01665</link>
      <description>arXiv:2501.01665v1 Announce Type: cross 
Abstract: Algorithmic fairness of machine learning (ML) models has raised significant concern in the recent years. Many testing, verification, and bias mitigation techniques have been proposed to identify and reduce fairness issues in ML models. The existing methods are model-centric and designed to detect fairness issues under static settings. However, many ML-enabled systems operate in a dynamic environment where the predictive decisions made by the system impact the environment, which in turn affects future decision-making. Such a self-reinforcing feedback loop can cause fairness violations in the long term, even if the immediate outcomes are fair. In this paper, we propose a simulation-based framework called FairSense to detect and analyze long-term unfairness in ML-enabled systems. Given a fairness requirement, FairSense performs Monte-Carlo simulation to enumerate evolution traces for each system configuration. Then, FairSense performs sensitivity analysis on the space of possible configurations to understand the impact of design options and environmental factors on the long-term fairness of the system. We demonstrate FairSense's potential utility through three real-world case studies: Loan lending, opioids risk scoring, and predictive policing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01665v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yining She, Sumon Biswas, Christian K\"astner, Eunsuk Kang</dc:creator>
    </item>
    <item>
      <title>Can Synthetic Data be Fair and Private? A Comparative Study of Synthetic Data Generation and Fairness Algorithms</title>
      <link>https://arxiv.org/abs/2501.01785</link>
      <description>arXiv:2501.01785v1 Announce Type: cross 
Abstract: The increasing use of machine learning in learning analytics (LA) has raised significant concerns around algorithmic fairness and privacy. Synthetic data has emerged as a dual-purpose tool, enhancing privacy and improving fairness in LA models. However, prior research suggests an inverse relationship between fairness and privacy, making it challenging to optimize both. This study investigates which synthetic data generators can best balance privacy and fairness, and whether pre-processing fairness algorithms, typically applied to real datasets, are effective on synthetic data. Our results highlight that the DEbiasing CAusal Fairness (DECAF) algorithm achieves the best balance between privacy and fairness. However, DECAF suffers in utility, as reflected in its predictive accuracy. Notably, we found that applying pre-processing fairness algorithms to synthetic data improves fairness even more than when applied to real data. These findings suggest that combining synthetic data generation with fairness pre-processing offers a promising approach to creating fairer LA models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01785v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinyi Liu, Oscar Deho, Farhad Vadiee, Mohammad Khalil, Srecko Joksimovic, George Siemens</dc:creator>
    </item>
    <item>
      <title>Telegram as a Battlefield: Kremlin-related Communications during the Russia-Ukraine Conflict</title>
      <link>https://arxiv.org/abs/2501.01884</link>
      <description>arXiv:2501.01884v1 Announce Type: cross 
Abstract: Telegram emerged as a crucial platform for both parties during the conflict between Russia and Ukraine. Per its minimal policies for content moderation, Pro-Kremlin narratives and potential misinformation were spread on Telegram, while anti-Kremlin narratives with related content were also propagated, such as war footage, troop movements, maps of bomb shelters, and air raid warnings. This paper presents a dataset of posts from both pro-Kremlin and anti-Kremlin Telegram channels, collected over a period spanning a year before and a year after the Russian invasion. The dataset comprises 404 pro-Kremlin channels with 4,109,645 posts and 114 anti-Kremlin channels with 1,117,768 posts. We provide details on the data collection process, processing methods, and dataset characterization. Lastly, we discuss the potential research opportunities this dataset may enable researchers across various disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01884v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Apaar Bawa, Ugur Kursuncu, Dilshod Achilov, Valerie L. Shalin, Nitin Agarwal, Esra Akbas</dc:creator>
    </item>
    <item>
      <title>Exploring Equality: An Investigation into Custom Loss Functions for Fairness Definitions</title>
      <link>https://arxiv.org/abs/2501.01889</link>
      <description>arXiv:2501.01889v1 Announce Type: cross 
Abstract: This paper explores the complex tradeoffs between various fairness metrics such as equalized odds, disparate impact, and equal opportunity and predictive accuracy within COMPAS by building neural networks trained with custom loss functions optimized to specific fairness criteria. This paper creates the first fairness-driven implementation of the novel Group Accuracy Parity (GAP) framework, as theoretically proposed by Gupta et al. (2024), and applies it to COMPAS. To operationalize and accurately compare the fairness of COMPAS models optimized to differing fairness ideals, this paper develops and proposes a combinatory analytical procedure that incorporates Pareto front and multivariate analysis, leveraging data visualizations such as violin graphs. This paper concludes that GAP achieves an enhanced equilibrium between fairness and accuracy compared to COMPAS's current nationwide implementation and alternative implementations of COMPAS optimized to more traditional fairness definitions. While this paper's algorithmic improvements of COMPAS significantly augment its fairness, external biases undermine the fairness of its implementation. Practices such as predictive policing and issues such as the lack of transparency regarding COMPAS's internal workings have contributed to the algorithm's historical injustice. In conjunction with developments regarding COMPAS's predictive methodology, legal and institutional changes must happen for COMPAS's just deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01889v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gordon Lee, Simeon Sayer</dc:creator>
    </item>
    <item>
      <title>ChatGPT's advice drives moral judgments with or without justification</title>
      <link>https://arxiv.org/abs/2501.01897</link>
      <description>arXiv:2501.01897v1 Announce Type: cross 
Abstract: Why do users follow moral advice from chatbots? A chatbot is not an authoritative moral advisor, but it can generate seemingly plausible arguments. Users do not follow reasoned more readily than unreasoned advice, though, we find in an experiment. However, this is also true if we attribute advice to a moral advisor, not a chatbot. Hence, it seems that advice offers users a cheap way to escape from a moral dilemma. This is a concern that chatbots do not raise, but they exacerbate it as they make advice easily accessible. We conclude that it takes ethical in addition to digital literacy to harness users against moral advice from chatbots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01897v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Kruegel, Andreas Ostermaier, Matthias Uhl</dc:creator>
    </item>
    <item>
      <title>Characterizing the MrDeepFakes Sexual Deepfake Marketplace</title>
      <link>https://arxiv.org/abs/2410.11100</link>
      <description>arXiv:2410.11100v2 Announce Type: replace 
Abstract: The prevalence of sexual deepfake material has exploded over the past several years. Attackers create and utilize deepfakes for many reasons: to seek sexual gratification, to harass and humiliate targets, or to exert power over an intimate partner. In part supporting this growth, several markets have emerged to support the buying and selling of sexual deepfake material. In this paper, we systematically characterize the most prominent and mainstream marketplace, MrDeepFakes. We analyze the marketplace economics, the targets of created media, and user discussions of how to create deepfakes, which we use to understand the current state-of-the-art in deepfake creation. Our work uncovers little enforcement of posted rules (e.g., limiting targeting to well-established celebrities), previously undocumented attacker motivations, and unexplored attacker tactics for acquiring resources to create sexual deepfakes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11100v2</guid>
      <category>cs.CY</category>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Catherine Han, Anne Li, Deepak Kumar, Zakir Durumeric</dc:creator>
    </item>
    <item>
      <title>The State of Data Curation at NeurIPS: An Assessment of Dataset Development Practices in the Datasets and Benchmarks Track</title>
      <link>https://arxiv.org/abs/2410.22473</link>
      <description>arXiv:2410.22473v2 Announce Type: replace 
Abstract: Data curation is a field with origins in librarianship and archives, whose scholarship and thinking on data issues go back centuries, if not millennia. The field of machine learning is increasingly observing the importance of data curation to the advancement of both applications and fundamental understanding of machine learning models - evidenced not least by the creation of the Datasets and Benchmarks track itself. This work provides an analysis of dataset development practices at NeurIPS through the lens of data curation. We present an evaluation framework for dataset documentation, consisting of a rubric and toolkit developed through a literature review of data curation principles. We use the framework to assess the strengths and weaknesses in current dataset development practices of 60 datasets published in the NeurIPS Datasets and Benchmarks track from 2021-2023. We summarize key findings and trends. Results indicate greater need for documentation about environmental footprint, ethical considerations, and data management. We suggest targeted strategies and resources to improve documentation in these areas and provide recommendations for the NeurIPS peer-review process that prioritize rigorous data curation in ML. Finally, we provide results in the format of a dataset that showcases aspects of recommended data curation practices. Our rubric and results are of interest for improving data curation practices broadly in the field of ML as well as to data curation and science and technology studies scholars studying practices in ML. Our aim is to support continued improvement in interdisciplinary research on dataset practices, ultimately improving the reusability and reproducibility of new datasets and benchmarks, enabling standardized and informed human oversight, and strengthening the foundation of rigorous and responsible ML research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22473v2</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eshta Bhardwaj, Harshit Gujral, Siyi Wu, Ciara Zogheib, Tegan Maharaj, Christoph Becker</dc:creator>
    </item>
    <item>
      <title>Grand Challenges in Immersive Technologies for Cultural Heritage</title>
      <link>https://arxiv.org/abs/2412.02853</link>
      <description>arXiv:2412.02853v4 Announce Type: replace 
Abstract: Cultural heritage, a testament to human history and civilization, has gained increasing recognition for its significance in preservation and dissemination. The integration of immersive technologies has transformed how cultural heritage is presented, enabling audiences to engage with it in more vivid, intuitive, and interactive ways. However, the adoption of these technologies also brings a range of challenges and potential risks. This paper presents a systematic review, with an in-depth analysis of 177 selected papers. We comprehensively examine and categorize current applications, technological approaches, and user devices in immersive cultural heritage presentations, while also highlighting the associated risks and challenges. Furthermore, we identify areas for future research in the immersive presentation of cultural heritage. Our goal is to provide a comprehensive reference for researchers and practitioners, enhancing understanding of the technological applications, risks, and challenges in this field, and encouraging further innovation and development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02853v4</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanbing Wang, Junyan Du, Yue Li, Lie Zhang, Xiang Li</dc:creator>
    </item>
    <item>
      <title>Automating Work Orders and Tracking Winter Snow Plows and Patrol Vehicles with Telematics Data</title>
      <link>https://arxiv.org/abs/2501.01128</link>
      <description>arXiv:2501.01128v2 Announce Type: replace 
Abstract: Winter road maintenance is a critical priority for the Indiana Department of Transportation, which manages an extensive fleet across thousands of lane miles. The current manual tracking of snowplow workloads is inefficient and prone to errors. To address these challenges, we developed an in-browser web application that automates the creation and verification of work orders using a large-scale GPS dataset from telematics systems. The application processes millions of GPS data points from hundreds of vehicles over winter, significantly reducing manual labor and minimizing errors. Key features include geohashing for efficient road segment identification, detailed segment-level work records, and robust visualization of vehicle movements, even on repeated routes. Our proposed solution has the potential to enhance the accuracy and granularity of work records, support more effective resource allocation, ensure timely compensation for drivers, alleviate administrative burdens, and allow managers to focus on strategic planning and real-time challenges. The web application can be accessed at https://github.com/oats-center/arrtrack/</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01128v2</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anugunj Naman, Aaron Ault, Yaguang Zhang, James Krogmeier</dc:creator>
    </item>
    <item>
      <title>Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study</title>
      <link>https://arxiv.org/abs/2408.14438</link>
      <description>arXiv:2408.14438v4 Announce Type: replace-cross 
Abstract: The emergence of large language models such as ChatGPT, Gemini, and others highlights the importance of evaluating their diverse capabilities, ranging from natural language understanding to code generation. However, their performance on spatial tasks has not been thoroughly assessed. This study addresses this gap by introducing a new multi-task spatial evaluation dataset designed to systematically explore and compare the performance of several advanced models on spatial tasks. The dataset includes twelve distinct task types, such as spatial understanding and simple route planning, each with verified and accurate answers. We evaluated multiple models, including OpenAI's gpt-3.5-turbo, gpt-4-turbo, gpt-4o, ZhipuAI's glm-4, Anthropic's claude-3-sonnet-20240229, and MoonShot's moonshot-v1-8k, using a two-phase testing approach. First, we conducted zero-shot testing. Then, we categorized the dataset by difficulty and performed prompt-tuning tests. Results show that gpt-4o achieved the highest overall accuracy in the first phase, with an average of 71.3%. Although moonshot-v1-8k slightly underperformed overall, it outperformed gpt-4o in place name recognition tasks. The study also highlights the impact of prompt strategies on model performance in specific tasks. For instance, the Chain-of-Thought (CoT) strategy increased gpt-4o's accuracy in simple route planning from 12.4% to 87.5%, while a one-shot strategy improved moonshot-v1-8k's accuracy in mapping tasks from 10.1% to 76.3%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14438v4</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liuchang Xu, Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen Wu, Xinyue Ye, Hailin Feng, Zhenhong Du</dc:creator>
    </item>
  </channel>
</rss>
