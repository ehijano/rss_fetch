<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Jan 2026 05:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enforcing Temporal Constraints for LLM Agents</title>
      <link>https://arxiv.org/abs/2512.23738</link>
      <description>arXiv:2512.23738v1 Announce Type: cross 
Abstract: LLM-based agents are deployed in safety-critical applications, yet current guardrail systems fail to prevent violations of temporal safety policies, requirements that govern the ordering and sequencing of agent actions. For instance, agents may access sensitive data before authenticating users or process refunds to unauthorized payment methods, violations that require reasoning about sequences of action rather than an individual action. Existing guardrails rely on imprecise natural language instructions or post-hoc monitoring, and provide no formal guarantees that agents will satisfy temporal constraints. We present Agent-C, a novel framework that provides run-time guarantees ensuring LLM agents adhere to formal temporal safety properties. Agent-C introduces a domain-specific language for expressing temporal properties (e.g., authenticate before accessing data), translates specifications to first-order logic, and uses SMT solving to detect non-compliant agent actions during token generation. When the LLM attempts to generate a non-compliant tool call, Agent-C leverages constrained generation techniques to ensure that every action generated by the LLM complies with the specification, and to generate a compliant alternative to a non-compliant agent action. We evaluate Agent-C across two real-world applications: retail customer service and airline ticket reservation system, and multiple language models (open and closed-source). Our results demonstrate that Agent-C achieves perfect safety (100% conformance, 0% harm), while improving task utility compared to state-of-the-art guardrails and unrestricted agents. On SoTA closed-source models, Agent-C improves conformance (77.4% to 100% for Claude Sonnet 4.5 and 83.7% to 100% for GPT-5), while simultaneously increasing utility (71.8% to 75.2% and 66.1% to 70.6%, respectively), representing a new SoTA frontier for reliable agentic reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23738v1</guid>
      <category>cs.PL</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adharsh Kamath, Sishen Zhang, Calvin Xu, Shubham Ugare, Gagandeep Singh, Sasa Misailovic</dc:creator>
    </item>
    <item>
      <title>Developing controlled natural language for formal specification patterns using AI assistants</title>
      <link>https://arxiv.org/abs/2512.24159</link>
      <description>arXiv:2512.24159v1 Announce Type: cross 
Abstract: Using an AI assistant, we developed a method for systematically constructing controlled natural language for requirements based on formal specification patterns containing logical attributes. The method involves three stages: 1) compiling a generalized natural language requirement pattern that utilizes all attributes of the formal specification template; 2) generating, using the AI assistant, a corpus of natural language requirement patterns, reduced by partially evaluating attributes (the developed prompt utilizes the generalized template, attribute definitions, and specific formal semantics of the requirement patterns); and 3) formalizing the syntax of the controlled natural language based on an analysis of the grammatical structure of the resulting patterns. The method has been tested for event-driven temporal requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24159v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalia Garanina, Vladimir Zyubin, Igor Anureev</dc:creator>
    </item>
    <item>
      <title>LeanCat: A Benchmark Suite for Formal Category Theory in Lean (Part I: 1-Categories)</title>
      <link>https://arxiv.org/abs/2512.24796</link>
      <description>arXiv:2512.24796v1 Announce Type: cross 
Abstract: Large language models (LLMs) have made rapid progress in formal theorem proving, yet current benchmarks under-measure the kind of abstraction and library-mediated reasoning that organizes modern mathematics. In parallel with FATE's emphasis on frontier algebra, we introduce LeanCat, a Lean benchmark for category-theoretic formalization -- a unifying language for mathematical structure and a core layer of modern proof engineering -- serving as a stress test of structural, interface-level reasoning. Part I: 1-Categories contains 100 fully formalized statement-level tasks, curated into topic families and three difficulty tiers via an LLM-assisted + human grading process. The best model solves 8.25% of tasks at pass@1 (32.50%/4.17%/0.00% by Easy/Medium/High) and 12.00% at pass@4 (50.00%/4.76%/0.00%). We also evaluate LeanBridge which use LeanExplore to search Mathlib, and observe consistent gains over single-model baselines. LeanCat is intended as a compact, reusable checkpoint for tracking both AI and human progress toward reliable, research-level formalization in Lean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24796v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <category>math.CT</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rongge Xu, Hui Dai, Yiming Fu, Jiedong Jiang, Tianjiao Nie, Hongwei Wang, Junkai Wang, Holiverse Yang, Jiatong Yang, Zhi-Hao Zhang</dc:creator>
    </item>
    <item>
      <title>[Draft] High-order estimation-based properties and high-order observers for labeled finite-state automata</title>
      <link>https://arxiv.org/abs/2408.06141</link>
      <description>arXiv:2408.06141v3 Announce Type: replace 
Abstract: In this paper, we consider labeled finite-state automata (LFSAs), extend some state estimation-based properties from a single agent to a finite ordered set of agents. We also extend the notion of observer to \emph{high-order observer} using our \emph{concurrent composition}. As a result, a general framework for characterizing high-order estimation-based properties is built, in which each agent infers its preceding agent's estimation via all agents in front. The high-order observer plays the role of a basic tool to verify such properties.
  In more detail, in our general framework, the system's structure is publicly known to all agents $A_1,\dots,A_n$; each agent $A_i$ has its own observable event set $E_i$, and additionally knows all its preceding agents' observable events but can only observe its own observable events. The intuitive meaning of our high-order observer is to characterize what agent $A_n$ knows about what $A_{n-1}$ knows about \dots what $A_2$ knows about $A_1$'s state estimate of the system. This general framework can be regarded as an automata representation of dynamic epistemic logic. Compared with the classical representation of dynamic epistemic logic based on fragments of logic, our representation has advantages in property verification and flexibly changing agents to enforce properties. As case studies, this general framework applies to basic properties such as current-state opacity, strong current-state opacity, regular-language-based opacity, critical observability, high-order opacity, etc. Special cases for which verification can be done more efficiently are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06141v3</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuize Zhang, Xiaoguang Han, Alessandro Giua, Carla Seatzu</dc:creator>
    </item>
  </channel>
</rss>
