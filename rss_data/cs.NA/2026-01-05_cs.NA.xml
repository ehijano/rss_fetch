<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 03:30:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Finite element exterior calculus for time-dependent Hamiltonian partial differential equations</title>
      <link>https://arxiv.org/abs/2601.00103</link>
      <description>arXiv:2601.00103v1 Announce Type: new 
Abstract: The success of symplectic integrators for Hamiltonian ODEs has led to a decades-long program of research seeking analogously structure-preserving numerical methods for Hamiltonian PDEs. In this paper, we construct a large class of such methods by combining finite element exterior calculus (FEEC) for spatial semidiscretization with symplectic integrators for time discretization. The resulting methods satisfy a local multisymplectic conservation law in space and time, which generalizes the symplectic conservation law of Hamiltonian ODEs, and which carries finer information about Hamiltonian structure than other approaches based on global function spaces. We give particular attention to conforming FEEC methods and hybridizable discontinuous Galerkin (HDG) methods. The theory and methods are illustrated by application to the semilinear Hodge wave equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00103v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ari Stern, Enrico Zampa</dc:creator>
    </item>
    <item>
      <title>Affine Invariant Langevin Dynamics for rare-event sampling</title>
      <link>https://arxiv.org/abs/2601.00107</link>
      <description>arXiv:2601.00107v1 Announce Type: new 
Abstract: We introduce an affine invariant Langevin dynamics (ALDI) framework for the efficient estimation of rare events in nonlinear dynamical systems. Rare events are formulated as Bayesian inverse problems through a nonsmooth limit-state function whose zero level set characterises the event of interest. To overcome the nondifferentiability of this function, we propose a smooth approximation that preserves the failure set and yields a posterior distribution satisfying the small-noise limit. The resulting potential is sampled by ALDI, a (derivative-free) interacting particle system whose affine invariance allows it to adapt to the local anisotropy of the posterior.
  We demonstrate the performance of the method across a hierarchy of benchmarks, namely two low-dimensional examples (an algebraic problem with convex geometry and a dynamical problem of saddle-type instability) and a point-vortex model for atmospheric blockings. In all cases, ALDI concentrates near the relevant near-critical sets and provides accurate proposal distributions for self-normalised importance sampling. The framework is computationally robust, potentially gradient-free, and well-suited for complex forward models with strong geometric anisotropy. These results highlight ALDI as a promising tool for rare-event estimation in unstable regimes of dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00107v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deepyaman Chakraborty, Ruben Harris, Rupert Klein, Guillermo Olic\'on-M\'endez, Sebastian Reich, Claudia Schillings</dc:creator>
    </item>
    <item>
      <title>Fast Ewald Summation with Prolates for Charged Systems in the NPT Ensemble</title>
      <link>https://arxiv.org/abs/2601.00161</link>
      <description>arXiv:2601.00161v1 Announce Type: new 
Abstract: We present an NPT extension of Ewald summation with prolates (ESP), a spectrally accurate and scalable particle-mesh method for molecular dynamics simulations of periodic, charged systems. Building on the recently introduced ESP framework, this work focuses on rigorous and thermodynamically consistent pressure/stress evaluation in the isothermal--isobaric ensemble. ESP employs prolate spheroidal wave functions as both splitting and spreading kernels, reducing the Fourier grid size needed to reach a prescribed pressure accuracy compared with current widely used mesh-Ewald methods based on Gaussian splitting and B-spline spreading. We derive a unified pressure-tensor formulation applicable to isotropic, semi-isotropic, anisotropic, and fully flexible cells, and show that the long-range pressure can be evaluated with a single forward FFT followed by diagonal scaling, whereas force evaluation requires both forward and inverse transforms. We provide production implementations in LAMMPS and GROMACS and validate pressure and force accuracy on bulk water, LiTFSI ionic liquids, and a transmembrane system. Benchmarks on up to $3\times 10^3$ CPU cores demonstrate strong scaling and reduced communication cost at matched accuracy, particularly for NPT pressure evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00161v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.chem-ph</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuyang Liang, Libin Lu, Shidong Jiang</dc:creator>
    </item>
    <item>
      <title>Temporal Two-Grid Compact Difference Scheme for Benjamin-Bona-Mahony-Burgers Equation</title>
      <link>https://arxiv.org/abs/2601.00193</link>
      <description>arXiv:2601.00193v1 Announce Type: new 
Abstract: This paper proposes a temporal two-grid compact difference (TTCD) scheme for solving the Benjamin-Bona-Mahony-Burgers (BBMB) equation with initial and periodic boundary conditions. The method consists of three main steps: first, solving a nonlinear system on a coarse time grid of size $\tau_c$; then obtaining a coarse approximation on the fine time grid of size $\tau_f$ via linear Lagrange interpolation; and finally solving a linearized scheme on the fine grid to obtain the corrected solution. The TTCD scheme reduces computational cost without sacrificing accuracy. Moreover, using the energy method, we rigorously prove the conservation property, unique solvability, convergence, and stability of the proposed scheme. It is shown that the method achieves convergence of order $\mathcal{O}(\tau_c^2 + \tau_f^2 + h^4)$ in the maximum norm, where $h$ is space step size. Finally, some numerical experiments are provided to demonstrate the effectiveness and feasibility of the proposed strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00193v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lisen Ding, Xiangyi Peng, Dongling Wang</dc:creator>
    </item>
    <item>
      <title>Spectral Schur analysis of structured moment matrices for quadratic histopolation</title>
      <link>https://arxiv.org/abs/2601.00301</link>
      <description>arXiv:2601.00301v1 Announce Type: new 
Abstract: In this paper we study parameter-dependent structured moment matrices with a canonical block form arising from weighted quadratic histopolation on simplicial meshes. For a strictly positive density on a simplex, we construct compatible face densities and an orthogonal decomposition of the quadratic polynomial space into face and interior components, which induces a natural face-interior block structure. A reduced Schur complement is identified that fully characterizes enrichment and well-posedness and provides a sharp spectral stability result. We show that this quantity coincides with the square root of the smallest eigenvalue of a low-dimensional symmetric positive definite operator. This matrix-based viewpoint yields simple spectral criteria for the invertibility of local moment systems and motivates spectrally preferable choices of face and interior bases with improved conditioning. Using the resulting degrees of freedom together with density and scaling parameters as design variables, we formulate a small eigenvalue optimization problem aimed at improving stability and reducing the condition number of the global reconstruction system. Three-dimensional experiments on uniform and quasi-uniform simplicial meshes illustrate the predicted stability, conditioning, and convergence behaviour of the enriched quadratic reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00301v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allal Guessab, Federico Nudo</dc:creator>
    </item>
    <item>
      <title>A weak Galerkin least squares finite element method for linear convection equations in non-divergence form</title>
      <link>https://arxiv.org/abs/2601.00399</link>
      <description>arXiv:2601.00399v1 Announce Type: new 
Abstract: This article develops a weak Galerkin least-squares (WG--LS) finite element method for first-order linear convection equations in non-divergence form. The method is formulated using discontinuous finite element functions and does not require any coercivity assumption on the convection vector or reaction coefficient. The resulting discrete problem leads to a symmetric and positive definite linear system and is applicable to general polygonal and polyhedral meshes. Under minimal regularity assumptions on the coefficients, optimal-order error estimates are established for the WG--LS approximation in a suitable energy norm. Numerical experiments are presented to confirm the theoretical convergence results and to demonstrate the accuracy and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00399v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chunmei Wang, Shangyou Zhang</dc:creator>
    </item>
    <item>
      <title>Guaranteed stability bounds for second-order PDE problems satisfying a Garding inequality</title>
      <link>https://arxiv.org/abs/2601.00404</link>
      <description>arXiv:2601.00404v1 Announce Type: new 
Abstract: We propose an algorithm to numerically determined whether a second-order linear PDE problem satisfying a Garding inequality is well-posed. This algorithm further provides a lower bound to the inf-sup constant of the weak formulation, which may in turn be used for a posteriori error estimation purposes. Our numerical lower bound is based on two discrete singular value problems involving a Lagrange finite element discretization coupled with an a posteriori error estimator based on flux reconstruction techniques. We show that if the finite element discretization is sufficiently rich, our lower bound underestimates the optimal constant only by a factor roughly equal to two.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00404v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Chaumont-Frelet</dc:creator>
    </item>
    <item>
      <title>Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs</title>
      <link>https://arxiv.org/abs/2601.00672</link>
      <description>arXiv:2601.00672v1 Announce Type: new 
Abstract: In this paper, we study the finite element operator network (FEONet), an operator-learning method for parametric problems, originally introduced in J. Y. Lee, S. Ko, and Y. Hong, Finite Element Operator Network for Solving Elliptic-Type Parametric PDEs, SIAM J. Sci. Comput., 47(2), C501-C528, 2025. FEONet realizes the parameter-to-solution map on a finite element space and admits a training procedure that does not require training data, while exhibiting high accuracy and robustness across a broad class of problems. However, its computational cost increases and accuracy may deteriorate as the number of elements grows, posing notable challenges for large-scale problems. In this paper, we propose a new sparse network architecture motivated by the structure of the finite elements to address this issue. Throughout extensive numerical experiments, we show that the proposed sparse network achieves substantial improvements in computational cost and efficiency while maintaining comparable accuracy. We also establish theoretical results demonstrating that the sparse architecture can approximate the target operator effectively and provide a stability analysis ensuring reliable training and prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00672v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seungchan Ko, Jiyeon Kim, Dongwook Shin</dc:creator>
    </item>
    <item>
      <title>A Unified Trace-Optimization Framework for Multidimensionality Reduction</title>
      <link>https://arxiv.org/abs/2601.00729</link>
      <description>arXiv:2601.00729v1 Announce Type: new 
Abstract: This paper presents a comprehensive overview of several multidimensional reduction methods focusing on Multidimensional Principal Component Analysis (MPCA), Multilinear Orthogonal Neighborhood Preserving Projection (MONPP), Multidimensional Locally Linear Embedding (MLLE), and Multidimensional Laplacian Eigenmaps (MLE). These techniques are formulated within a unified framework based on trace optimization, where the dimensionality reduction problem is expressed as maximization or minimization problems. In addition to the linear MPCA and MONPP approaches, kernel-based extensions of these methods also are presented. The latter methods make it possible to capture nonlinear relations between high-dimensional data. A comparative analysis highlights the theoretical foundations, assumptions, and computational efficiency of each method, as well as their practical applicability. The study provides insights and guidelines for selecting an appropriate dimensionality reduction technique suited to the application at hand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00729v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mohamed El Guide, Alaa El Ichi, Khalide Jbilou, Lothar Reichel, Hessah Alqahtani</dc:creator>
    </item>
    <item>
      <title>Full grid solution for multi-asset options pricing with tensor networks</title>
      <link>https://arxiv.org/abs/2601.00009</link>
      <description>arXiv:2601.00009v1 Announce Type: cross 
Abstract: Pricing multi-asset options via the Black-Scholes PDE is limited by the curse of dimensionality: classical full-grid solvers scale exponentially in the number of underlyings and are effectively restricted to three assets. Practitioners typically rely on Monte Carlo methods for computing complex instrument involving multiple correlated underlyings. We show that quantized tensor trains (QTT) turn the d-asset Black-Scholes PDE into a tractable high-dimensional problem on a personal computer. We construct QTT representations of the operator, payoffs, and boundary conditions with ranks that scale polynomially in d and polylogarithmically in the grid size, and build two solvers: a time-stepping algorithm for European and American options and a space-time algorithm for European options. We compute full-grid prices and Greeks for correlated basket and max-min options in three to five dimensions with high accuracy. The methods introduced can comfortably be pushed to full-grid solutions on 10-15 underlyings, with further algorithmic optimization and more compute power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00009v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Arenstein, Michael Kastoryano</dc:creator>
    </item>
    <item>
      <title>Active learning for data-driven reduced models of parametric differential systems with Bayesian operator inference</title>
      <link>https://arxiv.org/abs/2601.00038</link>
      <description>arXiv:2601.00038v1 Announce Type: cross 
Abstract: This work develops an active learning framework to intelligently enrich data-driven reduced-order models (ROMs) of parametric dynamical systems, which can serve as the foundation of virtual assets in a digital twin. Data-driven ROMs are explainable, computationally efficient scientific machine learning models that aim to preserve the underlying physics of complex dynamical simulations. Since the quality of data-driven ROMs is sensitive to the quality of the limited training data, we seek to identify training parameters for which using the associated training data results in the best possible parametric ROM. Our approach uses the operator inference methodology, a regression-based strategy which can be tailored to particular parametric structure for a large class of problems. We establish a probabilistic version of parametric operator inference, casting the learning problem as a Bayesian linear regression. Prediction uncertainties stemming from the resulting probabilistic ROM solutions are used to design a sequential adaptive sampling scheme to select new training parameter vectors that promote ROM stability and accuracy globally in the parameter domain. We conduct numerical experiments for several nonlinear parametric systems of partial differential equations and compare the results to ROMs trained on random parameter samples. The results demonstrate that the proposed adaptive sampling strategy consistently yields more stable and accurate ROMs than random sampling does under the same computational budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00038v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shane A. McQuarrie, Mengwu Guo, Anirban Chaudhuri</dc:creator>
    </item>
    <item>
      <title>A POD-DeepONet Framework for Forward and Inverse Design of 2D Photonic Crystals</title>
      <link>https://arxiv.org/abs/2601.00199</link>
      <description>arXiv:2601.00199v1 Announce Type: cross 
Abstract: We develop a reduced-order operator-learning framework for forward and inverse band-structure design of two-dimensional photonic crystals with binary, pixel-based $p4m$-symmetric unit cells. We construct a POD--DeepONet surrogate for the discrete band map along the standard high-symmetry path by coupling a POD trunk extracted from high-fidelity finite-element band snapshots with a neural branch network that predicts reduced coefficients. This architecture yields a compact and differentiable forward model that is tailored to the underlying Bloch eigenvalue discretization. We establish continuity of the discrete band map on the relaxed design space and prove a uniform approximation property of the POD--DeepONet surrogate, leading to a natural decomposition of the total surrogate error into POD truncation and network approximation contributions. Building on this forward surrogate, we formulate two end-to-end neural inverse design procedures, namely dispersion-to-structure and band-gap inverse design, with training objectives that combine data misfit, binarity promotion, and supervised regularization to address the intrinsic non-uniqueness of the inverse mapping and to enable stable gradient-based optimization in the relaxed space. Our numerical results show that the proposed framework achieves accurate forward predictions and produces effective inverse designs on practical high-contrast, pixel-based photonic layouts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00199v1</guid>
      <category>physics.optics</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yueqi Wang, Guanglian Li, Guang Lin</dc:creator>
    </item>
    <item>
      <title>A Deep Learning-Enhanced Fourier Method for the Multi-Frequency Inverse Source Problem with Sparse Far-Field Data</title>
      <link>https://arxiv.org/abs/2601.00427</link>
      <description>arXiv:2601.00427v1 Announce Type: cross 
Abstract: This paper introduces a hybrid computational framework for the multi-frequency inverse source problem governed by the Helmholtz equation. By integrating a classical Fourier method with a deep convolutional neural network, we address the challenges inherent in sparse and noisy far-field data. The Fourier method provides a physics-informed, low-frequency approximation of the source, which serves as the input to a U-Net. The network is trained to map this coarse approximation to a high-fidelity source reconstruction, effectively suppressing truncation artifacts and recovering fine-scale geometric details. To enhance computational efficiency and robustness, we propose a high-to-low noise transfer learning strategy: a model pre-trained on high-noise regimes captures global topological features, offering a robust initialization for fine-tuning on lower-noise data. Numerical experiments demonstrate that the framework achieves accurate reconstructions with noise levels up to 100%, significantly outperforms traditional spectral methods under sparse measurement constraints, and generalizes well to unseen source geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00427v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Chen, Yan Chang, Yukun Guo, Yuliang Wang</dc:creator>
    </item>
    <item>
      <title>Precision Autotuning for Linear Solvers via Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2601.00728</link>
      <description>arXiv:2601.00728v2 Announce Type: cross 
Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00728v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erin Carson, Xinye Chen</dc:creator>
    </item>
    <item>
      <title>Stochastic dual coordinate descent with adaptive heavy ball momentum for linearly constrained convex optimization</title>
      <link>https://arxiv.org/abs/2307.16702</link>
      <description>arXiv:2307.16702v4 Announce Type: replace 
Abstract: The problem of finding a solution to the linear system $Ax = b$ with certain minimization properties arises in numerous scientific and engineering areas. In the era of big data, the stochastic optimization algorithms become increasingly significant due to their scalability for problems of unprecedented size. This paper focuses on the problem of minimizing a strongly convex function subject to linear constraints. We consider the dual formulation of this problem and adopt the stochastic coordinate descent to solve it. The proposed algorithmic framework, called adaptive stochastic dual coordinate descent, utilizes sampling matrices sampled from user-defined distributions to extract gradient information. Moreover, it employs Polyak's heavy ball momentum acceleration with adaptive parameters learned through iterations, overcoming the limitation of the heavy ball momentum method that it requires prior knowledge of certain parameters, such as the singular values of a matrix. With these extensions, the framework is able to recover many well-known methods in the context, including the randomized sparse Kaczmarz method, the randomized regularized Kaczmarz method, the linearized Bregman iteration, and a variant of the conjugate gradient (CG) method. Additionally, we introduce an equivalent formulation that, in certain cases, substantially reduces the need for full-dimensional vector operations introduced by the momentum term. We prove that, with strongly admissible objective function, the proposed method converges linearly in expectation. Numerical experiments are provided to confirm our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16702v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Zeng, Deren Han, Yansheng Su, Jiaxin Xie</dc:creator>
    </item>
    <item>
      <title>Preconditioning for time-harmonic Maxwell's equations using the Laguerre transform</title>
      <link>https://arxiv.org/abs/2309.11023</link>
      <description>arXiv:2309.11023v3 Announce Type: replace 
Abstract: A method of numerically solving the Maxwell equations is considered for modeling harmonic electromagnetic fields. The vector finite element method makes it possible to obtain a physically consistent discretization of the differential equations. However, solving large systems of linear algebraic equations with indefinite ill-conditioned matrices is a challenge. The high order of the matrices limits the capabilities of the Gaussian method to solve such systems, since this requires large RAM and much calculation. To reduce these requirements, an iterative preconditioned algorithm based on integral Laguerre transform in time is used. This approach allows using multigrid algorithms and, as a result, needs less RAM compared to the direct methods of solving systems of linear algebraic equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11023v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew V. Terekhov</dc:creator>
    </item>
    <item>
      <title>Stability and Convergence of HDG Schemes under Minimal Regularity</title>
      <link>https://arxiv.org/abs/2310.18448</link>
      <description>arXiv:2310.18448v2 Announce Type: replace 
Abstract: Convergence and compactness properties of approximate solutions to elliptic partial differential computed with the hybridized discontinuous Galerkin (HDG) are established. While it is known that solutions computed using the HDG scheme converge at optimal rates to smooth solutions, this does not establish the stability of the method or convergence to solutions with minimal regularity. The compactness and convergence results show that the HDG scheme can be utilized for the solution of nonlinear problems and linear problems with non-smooth coefficients on domains with reentrant corners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18448v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>SIAM Journal on Numerical Analysis 63 (2025), 2048-2071</arxiv:journal_reference>
      <dc:creator>Jiannan Jiang, Noel J. Walkington, Yukun Yue</dc:creator>
    </item>
    <item>
      <title>A reconstructed discontinuous approximation for distributed elliptic control problems</title>
      <link>https://arxiv.org/abs/2512.08353</link>
      <description>arXiv:2512.08353v2 Announce Type: replace 
Abstract: In this paper, we present and analyze an interior penalty discontinuous Galerkin method for the distributed elliptic optimal control problems. It is based on a reconstructed discontinuous approximation which admits arbitrarily high-order approximation space with only one unknown per element. Applying this method, we develop a proper discretization scheme that approximates the state and adjoint variables in the approximation space. Our main contributions are twofold: (1) the derivation of both a priori and a posteriori error estimates of the $L^2$-norm and the energy norms, and (2) the implementation of an efficiently solvable discrete system, which is solved via a linearly convergent projected gradient descent method. Numerical experiments are provided to verify the convergence order in a priori error estimate and the efficiency of a posteriori error estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08353v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ruo Li, Haoyang Liu, Jun Yin</dc:creator>
    </item>
    <item>
      <title>Sufficient and Necessary Conditions for Eckart-Young like Result for Tubal Tensors</title>
      <link>https://arxiv.org/abs/2512.24405</link>
      <description>arXiv:2512.24405v2 Announce Type: replace 
Abstract: A valuable feature of the tubal tensor framework is that many familiar constructions from matrix algebra carry over to tensors, including SVD and notions of rank. Most importantly, it has been shown that for a specific family of tubal products, an Eckart-Young type theorem holds, i.e., the best low-rank approximation of a tensor under the Frobenius norm is obtained by truncating its tubal SVD. In this paper, we provide a complete characterization of the family of tubal products that yield an Eckart-Young type result. We demonstrate the practical implications of our theoretical findings by conducting experiments with video data and data-driven dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24405v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uria Mor</dc:creator>
    </item>
    <item>
      <title>Tannenbaum's gain-margin optimization meets Polyak's heavy-ball algorithm</title>
      <link>https://arxiv.org/abs/2409.19882</link>
      <description>arXiv:2409.19882v3 Announce Type: replace-cross 
Abstract: This paper highlights an apparent, yet relatively unknown link between algorithm design in optimization theory and controller synthesis in robust control. Specifically, quadratic optimization can be recast as a regulation problem within the framework of $\mathcal{H}_\infty$ control. From this vantage point, the optimality of Polyak's fastest heavy-ball algorithm can be ascertained as a solution to a gain margin optimization problem. The approach is independent of Polyak's original and brilliant argument, and relies on foundational work by Tannenbaum, who introduced and solved gain margin optimization via Nevanlinna--Pick interpolation theory. The link between first-order optimization methods and robust control sheds new light on the limits of algorithmic performance of such methods, and suggests a framework where similar computational tasks can be systematically studied and algorithms optimized. In particular, it raises the question as to whether periodically scheduled algorithms can achieve faster rates for quadratic optimization, in a manner analogous to periodic control that extends the gain margin beyond that of time-invariant control. This turns out not to be the case, due to the analytic obstruction of a transmission zero that is inherent in causal schemes. Interestingly, this obstruction can be removed with implicit algorithms, cast as feedback regulation problems with causal, but not strictly causal dynamics, thereby devoid of the transmission zero at infinity and able to achieve superior convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19882v3</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuwei Wu, Jie Chen, Mihailo R. Jovanovi\'c, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Fast Symbolic Integer-Linear Spectra</title>
      <link>https://arxiv.org/abs/2410.09053</link>
      <description>arXiv:2410.09053v3 Announce Type: replace-cross 
Abstract: Here we contribute a fast symbolic eigenvalue solver for matrices whose eigenvalues are $\mathbb{Z}$-linear combinations of their entries, alongside efficient general and stochastic $M^{X}$ generators. Users can interact with a few degrees of freedom to create linear operators, making high-dimensional symbolic analysis feasible for when numerical analyses are insufficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09053v3</guid>
      <category>math.RA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonny Luntzel, Abraham Miller</dc:creator>
    </item>
    <item>
      <title>Some Patterns of Duplications in the outputs of Mersenne Twister Pseudorandom Number Generator MT19937</title>
      <link>https://arxiv.org/abs/2512.21678</link>
      <description>arXiv:2512.21678v2 Announce Type: replace-cross 
Abstract: The Mersenne Twister MT19937 pseudorandom number generator, introduced by the last two authors in 1998, is still widely used. It passes all existing statistical tests, except for the linear complexity test, which measures the ratio of the even-odd of the number of 1's among specific bits (and hence should not be important for most applications). Harase reported that MT19937 is rejected by some birthday-spacing tests, which are rather artificially designed. In this paper, we report that MT19937 fails in a natural test based on the distribution of run-lengths on which we found an identical value in the output 32-bit integers. The number of observations of the run-length 623 is some 40 times larger than the expectation (and than the numbers of the observations of 622 and 624, etc.), which implies that the corresponding p-value is almost 0.
  We mathematically analyze the phenomena, and obtain a theorem which explains these failures. It seems not to be a serious defect of MT19937, because finding the defect requires astronomical efforts. Still, the phenomena should be reported to the academic society relating to pseudorandom number generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21678v2</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alain Schumacher, Takuji Nishimura, Makoto Matsumoto</dc:creator>
    </item>
  </channel>
</rss>
