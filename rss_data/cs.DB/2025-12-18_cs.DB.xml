<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Dec 2025 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>MS-Index: Fast Top-k Subsequence Search for Multivariate Time Series under Euclidean Distance</title>
      <link>https://arxiv.org/abs/2512.14723</link>
      <description>arXiv:2512.14723v1 Announce Type: new 
Abstract: Modern applications frequently collect and analyze temporal data in the form of multivariate time series (MTS) -- time series that contain multiple channels. A common task in this context is subsequence search, which involves identifying all MTS that contain subsequences highly similar to a query time series. In practical scenarios, not all channels of an MTS are relevant to every query. For instance, airplane sensors may gather data on a plethora of components and subsystems, but only a few of these are relevant to a specific query, such as identifying the cause of a malfunctioning landing gear, or a specific flight maneuver. Consequently, the relevant query channels are often specified at query time. In this work, we introduce the Multivariate Subsequence Index (MS-Index), a novel algorithm for nearest neighbor MTS subsequence search under Euclidean distance that supports ad-hoc selection of query channels. The algorithm is exact and demonstrates query performance that scales sublinearly to the number of query channels. We examine the properties of \name with a thorough experimental evaluation over 34 datasets, and show that it outperforms the state-of-the-art one to two orders of magnitude for both raw and normalized subsequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14723v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.14778/3773749.3773751</arxiv:DOI>
      <dc:creator>Jens E. d'Hondt, Teun Kortekaas, Odysseas Papapetrou, Themis Palpanas</dc:creator>
    </item>
    <item>
      <title>Extracting node comparison insights for the interactive exploration of property graphs</title>
      <link>https://arxiv.org/abs/2512.15157</link>
      <description>arXiv:2512.15157v1 Announce Type: new 
Abstract: While scoring nodes in graphs to understand their importance (e.g., in terms of centrality) has been investigated for decades, comparing nodes in property graphs based on their properties has not, to our knowledge, yet been addressed. In this paper, we propose an approach to automatically extract comparison of nodes in property graphs, to support the interactive exploratory analysis of said graphs. We first present a way of devising comparison indicators using the context of nodes to be compared. Then, we formally define the problem of using these indicators to group the nodes so that the comparisons extracted are both significant and not straightforward. We propose various heuristics for solving this problem. Our tests on real property graph databases show that simple heuristics can be used to obtain insights within minutes while slower heuristics are needed to obtain insights of higher quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15157v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristina Aguiar, Jacques Chabin, Alexandre Chanson, Mirian Halfeld-Ferrari, Nicolas Hiot, Nicolas Labroche, Patrick Marcel, Ver\'onika Peralta, Felipe Vasconcelos</dc:creator>
    </item>
    <item>
      <title>Graph Pattern-based Association Rules Evaluated Under No-repeated-anything Semantics in the Graph Transactional Setting</title>
      <link>https://arxiv.org/abs/2512.15308</link>
      <description>arXiv:2512.15308v1 Announce Type: new 
Abstract: We introduce graph pattern-based association rules (GPARs) for directed labeled multigraphs such as RDF graphs. GPARs support both generative tasks, where a graph is extended, and evaluative tasks, where the plausibility of a graph is assessed. The framework goes beyond related formalisms such as graph functional dependencies, graph entity dependencies, relational association rules, graph association rules, multi-relation and path association rules, and Horn rules. Given a collection of graphs, we evaluate graph patterns under no-repeated-anything semantics, which allows the topology of a graph to be taken into account more effectively. We define a probability space and derive confidence, lift, leverage, and conviction in a probabilistic setting. We further analyze how these metrics relate to their classical itemset-based counterparts and identify conditions under which their characteristic properties are preserved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15308v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Basil Ell</dc:creator>
    </item>
    <item>
      <title>Revisiting Task-Oriented Dataset Search in the Era of Large Language Models: Challenges, Benchmark, and Solution</title>
      <link>https://arxiv.org/abs/2512.15363</link>
      <description>arXiv:2512.15363v1 Announce Type: new 
Abstract: The search for suitable datasets is the critical "first step" in data-driven research, but it remains a great challenge. Researchers often need to search for datasets based on high-level task descriptions. However, existing search systems struggle with this task due to ambiguous user intent, task-to-dataset mapping and benchmark gaps, and entity ambiguity. To address these challenges, we introduce KATS, a novel end-to-end system for task-oriented dataset search from unstructured scientific literature. KATS consists of two key components, i.e., offline knowledge base construction and online query processing. The sophisticated offline pipeline automatically constructs a high-quality, dynamically updatable task-dataset knowledge graph by employing a collaborative multi-agent framework for information extraction, thereby filling the task-to-dataset mapping gap. To further address the challenge of entity ambiguity, a unique semantic-based mechanism is used for task entity linking and dataset entity resolution. For online retrieval, KATS utilizes a specialized hybrid query engine that combines vector search with graph-based ranking to generate highly relevant results. Additionally, we introduce CS-TDS, a tailored benchmark suite for evaluating task-oriented dataset search systems, addressing the critical gap in standardized evaluation. Experiments on our benchmark suite show that KATS significantly outperforms state-of-the-art retrieval-augmented generation frameworks in both effectiveness and efficiency, providing a robust blueprint for the next generation of dataset discovery systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15363v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixin Wei, Yucan Guo, Jinyang Li, Xiaolin Han, Xiaolong Jin, Chenhao Ma</dc:creator>
    </item>
    <item>
      <title>ArcBERT: An LLM-based Search Engine for Exploring Integrated Multi-Omics Metadata</title>
      <link>https://arxiv.org/abs/2512.15365</link>
      <description>arXiv:2512.15365v1 Announce Type: new 
Abstract: Traditional search applications within Research Data Management (RDM) ecosystems are crucial in helping users discover and explore the structured metadata from the research datasets. Typically, text search engines require users to submit keyword-based queries rather than using natural language. However, using Large Language Models (LLMs) trained on domain-specific content for specialized natural language processing (NLP) tasks is becoming increasingly common. We present ArcBERT, an LLM-based system designed for integrated metadata exploration. ArcBERT understands natural language queries and relies on semantic matching, unlike traditional search applications. Notably, ArcBERT also understands the structure and hierarchies within the metadata, enabling it to handle diverse user querying patterns effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15365v1</guid>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gajendra Doniparthi, Shashank Balu Pandhare, Stefan De{\ss}loch, Timo M\"uhlhaus</dc:creator>
    </item>
    <item>
      <title>ProvSQL: A General System for Keeping Track of the Provenance and Probability of Data</title>
      <link>https://arxiv.org/abs/2504.12058</link>
      <description>arXiv:2504.12058v3 Announce Type: replace 
Abstract: We present the data model, design choices, and performance of ProvSQL, a general and easy-to-deploy provenance tracking and probabilistic database system implemented as a PostgreSQL extension. ProvSQL's data and query models closely reflect that of a large core of SQL, including multiset semantics, the full relational algebra, and aggregation. A key part of its implementation relies on generic provenance circuits stored in memory-mapped files. We propose benchmarks to measure the overhead of provenance and probabilistic evaluation and demonstrate its scalability and competitiveness with respect to other state-of-the-art systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12058v3</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICDE 2026</arxiv:journal_reference>
      <dc:creator>Aryak Sen, Silviu Maniu, Pierre Senellart</dc:creator>
    </item>
    <item>
      <title>Downsizing Diffusion Models for Cardinality Estimation</title>
      <link>https://arxiv.org/abs/2510.20681</link>
      <description>arXiv:2510.20681v2 Announce Type: replace 
Abstract: Learned cardinality estimation requires accurate model designs to capture the local characteristics of probability distributions. However, existing models may fail to accurately capture complex, multilateral dependencies between attributes. Diffusion models, meanwhile, can succeed in estimating image distributions with thousands of dimensions, making them promising candidates, but their heavy weight and high latency prohibit effective implementation. We seek to make diffusion models more lightweight by introducing Accelerated Diffusion Cardest (ADC), the first "downsized" diffusion model framework for efficient, high-precision cardinality estimation. ADC utilizes a hybrid architecture that integrates a Gaussian Mixture-Bayesnet selectivity estimator with a score-based density estimator to perform precise Monte Carlo integration. Addressing the issue of prohibitive inference latencies common in large generative models, we provide theoretical advancements concerning the asymptotic behavior of score functions as time $t$ approaches zero and convergence rate estimates as $t$ increases, enabling the adaptation of score-based diffusion models to the moderate dimensionalities and stringent latency requirements of database systems.
  Through experiments conducted against five learned estimators, including the state-of-the-art Naru, we demonstrate that ADC offer superior robustness when handling datasets with multilateral dependencies, which cannot be effectively summarized using pairwise or triple-wise correlations. In fact, ADC is 10 times more accurate than Naru on such datasets. Additionally, ADC achieves competitive accuracy comparable to Naru across all tested datasets while maintaining latency half that of Naru's and requiring minimal storage (&lt;350KB) on most datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20681v2</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinhe Mu, Zhaoqi Zhou, Zaijiu Shang, Chuan Zhou, Gang Fu, Guiying Yan, Guoliang Li, Zhiming Ma</dc:creator>
    </item>
    <item>
      <title>Stress-Testing Causal Claims via Cardinality Repairs</title>
      <link>https://arxiv.org/abs/2512.02491</link>
      <description>arXiv:2512.02491v2 Announce Type: replace 
Abstract: Causal analyses derived from observational data underpin high-stakes decisions in domains such as healthcare, public policy, and economics. Yet such conclusions can be surprisingly fragile: even minor data errors - duplicate records, or entry mistakes - may drastically alter causal relationships. This raises a fundamental question: how robust is a causal claim to small, targeted modifications in the data? Addressing this question is essential for ensuring the reliability, interpretability, and reproducibility of empirical findings. We introduce SubCure, a framework for robustness auditing via cardinality repairs. Given a causal query and a user-specified target range for the estimated effect, SubCure identifies a small set of tuples or subpopulations whose removal shifts the estimate into the desired range. This process not only quantifies the sensitivity of causal conclusions but also pinpoints the specific regions of the data that drive those conclusions. We formalize this problem under both tuple- and pattern-level deletion settings and show both are NP-complete. To scale to large datasets, we develop efficient algorithms that incorporate machine unlearning techniques to incrementally update causal estimates without retraining from scratch. We evaluate SubCure across four real-world datasets covering diverse application domains. In each case, it uncovers compact, high-impact subsets whose removal significantly shifts the causal conclusions, revealing vulnerabilities that traditional methods fail to detect. Our results demonstrate that cardinality repair is a powerful and general-purpose tool for stress-testing causal analyses and guarding against misleading claims rooted in ordinary data imperfections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02491v2</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yarden Gabbay, Haoquan Guan, Shaull Almagor, El Kindi Rezig, Brit Youngmann, Babak Salimi</dc:creator>
    </item>
    <item>
      <title>Efficient Candidate-Free R-S Set Similarity Joins with Filter-and-Verification Trees on MapReduce</title>
      <link>https://arxiv.org/abs/2506.03893</link>
      <description>arXiv:2506.03893v3 Announce Type: replace-cross 
Abstract: Given two different collections of sets R and S, the exact R-S set similarity join (R-S Join) finds all set pairs with similarity no less than a given threshold, which has widespread applications. Existing algorithms accelerate large-scale R-S Joins using a two-stage filter-and-verification framework along with the parallel and distributed MapReduce framework, however, they suffer from excessive candidate set pairs (candidates), leading to significant I/O and verification overhead. This paper proposes novel candidate-free R-S Join (CF-RS-Join) algorithms that integrate filtering and verification into a single stage through the filter-and-verification tree (FVT) and its linear variant (LFVT). First, CF-RS-Join with FVT (CF-RS-Join/FVT) is proposed to leverage an innovative FVT structure that compresses elements and associated sets in memory, enabling single-stage processing that eliminates candidate generation, enables fast lookups, and reduces database scans. Correctness proofs are provided. Second, CF-RS-Join with LFVT (CF-RS-Join/LFVT) is proposed to exploit a more compact Linear FVT, which compresses non-branching paths into single nodes and stores them in linear arrays for optimized traversal. Third, MR-CF-RS-Join/FVT and MR-CF-RS-Join/LFVT are proposed to extend our approaches using MapReduce for parallel processing. Extensive experiments have been conducted on the proposed algorithms against state-of-the-art (SOTA) baselines in terms of execution time, scalability, memory usage, and disk usage. The results show that MR-CF-RS-Join/LFVT outperforms the runner-up by up to 1.37x-15.78x on 7 real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03893v3</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhong Feng, Fangcao Jian, Yixuan Cao, Xiaobin Jian, Jia Wang, Haiyue Feng, Chunyan Miao</dc:creator>
    </item>
    <item>
      <title>HI-SQL: Optimizing Text-to-SQL Systems through Dynamic Hint Integration</title>
      <link>https://arxiv.org/abs/2506.18916</link>
      <description>arXiv:2506.18916v2 Announce Type: replace-cross 
Abstract: Text-to-SQL generation bridges the gap between natural language and databases, enabling users to query data without requiring SQL expertise. While large language models (LLMs) have significantly advanced the field, challenges remain in handling complex queries that involve multi-table joins, nested conditions, and intricate operations. Existing methods often rely on multi-step pipelines that incur high computational costs, increase latency, and are prone to error propagation. To address these limitations, we propose HI-SQL, a pipeline that incorporates a novel hint generation mechanism utilizing historical query logs to guide SQL generation. By analyzing prior queries, our method generates contextual hints that focus on handling the complexities of multi-table and nested operations. These hints are seamlessly integrated into the SQL generation process, eliminating the need for costly multi-step approaches and reducing reliance on human-crafted prompts. Experimental evaluations on multiple benchmark datasets demonstrate that our approach significantly improves query accuracy of LLM-generated queries while ensuring efficiency in terms of LLM calls and latency, offering a robust and practical solution for enhancing Text-to-SQL systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18916v2</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/IJCNN64981.2025.11227320</arxiv:DOI>
      <arxiv:journal_reference>2025 International Joint Conference on Neural Networks (IJCNN)</arxiv:journal_reference>
      <dc:creator>Ganesh Parab, Zishan Ahmad, Dagnachew Birru</dc:creator>
    </item>
    <item>
      <title>MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity (Extension)</title>
      <link>https://arxiv.org/abs/2511.12061</link>
      <description>arXiv:2511.12061v2 Announce Type: replace-cross 
Abstract: Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12061v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichen Lai, Hua Lu, Huan Li, Jialiang Li, Christian S. Jensen</dc:creator>
    </item>
  </channel>
</rss>
