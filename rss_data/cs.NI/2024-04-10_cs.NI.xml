<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Apr 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deterministic and Probabilistic P4-Enabled Lightweight In-Band Network Telemetry</title>
      <link>https://arxiv.org/abs/2404.06582</link>
      <description>arXiv:2404.06582v1 Announce Type: new 
Abstract: In-band network telemetry (INT), empowered by programmable dataplanes such as P4, comprises a viable approach to network monitoring and telemetry analysis. However, P4-INT as well as other existing frameworks for INT yield a substantial transmission overhead, which grows linearly with the number of hops and the number of telemetry values. To address this issue, we present a deterministic and a probabilistic technique for lightweight INT, termed as DLINT and PLINT,respectively. In particular, DLINT exercises per-flow aggregation by spreading the telemetry values across the packets of a flow. DLINT relies on switch coordination through the use of per-flow telemetry states, maintained within P4 switches. Furthermore, DLINT utilizes Bloom Filters (BF) in order to compress the state lookup tables within P4 switches. On the other hand, PLINT employs a probabilistic approach based on reservoir sampling. PLINT essentially empowers every INT node to insert telemetry values with equal probability within each packet. Our evaluation results corroborate that both proposed techniques alleviate the transmission overhead of P4-INT, while maintaining a high degree of monitoring accuracy. In addition, we perform a comparative evaluation between DLINT and PLINT. DLINT is more effective in conveying path traces to the telemetry server, whereas PLINT detects more promptly path updates exploiting its more efficient INT header space utilization</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06582v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSM.2023.3301839</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Network and Service Management, 2023</arxiv:journal_reference>
      <dc:creator>Konstantinos Papadopoulos, Panagiotis Papadimitriou, Chrysa Papagianni</dc:creator>
    </item>
    <item>
      <title>Resource Management in RIS-Assisted Rate Splitting Multiple Access for Next Generation (xG) Wireless Communications: Models, State-of-the-Art, and Future Directions</title>
      <link>https://arxiv.org/abs/2404.06604</link>
      <description>arXiv:2404.06604v1 Announce Type: new 
Abstract: Next generation wireless networks require more stringent performance levels.
  New technologies such as Reconfigurable intelligent surfaces (RISs) and rate-splitting multiple access (RSMA) are candidates for meeting some of the performance requirements, including higher user rates at reduced costs.
  RSMA provides a new way of mixing the messages of multiple users, and the RIS provides a controllable wireless environment.
  This paper provides a comprehensive survey on the various aspects of the synergy between reconfigurable intelligent surfaces (RISs) and rate splitting multiple access (RSMA) for next-generation (xG) wireless communications systems.
  In particular, the paper studies more than 60 articles considering over 20 different system models where the RIS-aided RSMA system shows performance advantage (in terms of sum-rate or outage probability) over traditional RSMA models.
  These models include reflective RIS, simultaneously transmitting and reflecting surfaces (STAR-RIS), as well as transmissive surfaces.
  The state-of-the-art resource management methods for RIS-assisted RSMA communications employ traditional optimization techniques and/or machine learning techniques.
  We outline major research challenges and multiple future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06604v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Aboumahmoud, Ekram Hossain, \\Amine Mezghani</dc:creator>
    </item>
    <item>
      <title>Responsible Federated Learning in Smart Transportation: Outlooks and Challenges</title>
      <link>https://arxiv.org/abs/2404.06777</link>
      <description>arXiv:2404.06777v1 Announce Type: new 
Abstract: Integrating artificial intelligence (AI) and federated learning (FL) in smart transportation has raised critical issues regarding their responsible use. Ensuring responsible AI is paramount for the stability and sustainability of intelligent transportation systems. Despite its importance, research on the responsible application of AI and FL in this domain remains nascent, with a paucity of in-depth investigations into their confluence. Our study analyzes the roles of FL in smart transportation, as well as the promoting effect of responsible AI on distributed smart transportation. Lastly, we discuss the challenges of developing and implementing responsible FL in smart transportation and propose potential solutions. By integrating responsible AI and federated learning, intelligent transportation systems are expected to achieve a higher degree of intelligence, personalization, safety, and transparency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06777v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiaowen Huang, Tao Huang, Shushi Gu, Shuguang Zhao, Guanglin Zhang</dc:creator>
    </item>
    <item>
      <title>EMF Mitigation via 5G and 6G MAC Scheduling</title>
      <link>https://arxiv.org/abs/2404.06830</link>
      <description>arXiv:2404.06830v1 Announce Type: new 
Abstract: High antenna directivity allows for high throughput transmission but also increases the exposure to electromagnetic field (EMF) of the end-users. Health regulations impose limitations on the incident power density, that generate a negative impact on network performance. In this work we focus at the slot-by-slot operations of a cellular Medium Access Control (MAC) scheduler to constrain the short-term EMF exposure upon real-time resource allocation, minimizing the impacts on network performance. We assume that the long-term EMF exposure is controlled by a proper outer-loop technique, that is not the object of this paper. Due to the minimal computational complexity allowed in MAC scheduling, existing solutions allowing practical implementation are few and focused at sub-optimal approaches curbing radio resource allocation. Our contribution is the derivation of a computationally efficient water-filling solution to allocate power and - then - resources, with a feasible integration of the necessary algorithms in the operations of a 5G MAC scheduler. We finally evaluate our proposal versus the prior art approaches with system level simulations with realistic modeling of physical and MAC level cellular procedures. We conclude that our proposal can control EMF with considerable less impact on network performance, making it a standout candidate for 5G and future 6G MAC scheduler implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06830v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Silvio Mandelli, Lorenzo Maggi, Bill Zheng, Christophe Grangeat, Azra Zejnilagic</dc:creator>
    </item>
    <item>
      <title>PACP: Priority-Aware Collaborative Perception for Connected and Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2404.06891</link>
      <description>arXiv:2404.06891v1 Announce Type: new 
Abstract: Surrounding perceptions are quintessential for safe driving for connected and autonomous vehicles (CAVs), where the Bird's Eye View has been employed to accurately capture spatial relationships among vehicles. However, severe inherent limitations of BEV, like blind spots, have been identified. Collaborative perception has emerged as an effective solution to overcoming these limitations through data fusion from multiple views of surrounding vehicles. While most existing collaborative perception strategies adopt a fully connected graph predicated on fairness in transmissions, they often neglect the varying importance of individual vehicles due to channel variations and perception redundancy. To address these challenges, we propose a novel Priority-Aware Collaborative Perception (PACP) framework to employ a BEV-match mechanism to determine the priority levels based on the correlation between nearby CAVs and the ego vehicle for perception. By leveraging submodular optimization, we find near-optimal transmission rates, link connectivity, and compression metrics. Moreover, we deploy a deep learning-based adaptive autoencoder to modulate the image reconstruction quality under dynamic channel conditions. Finally, we conduct extensive studies and demonstrate that our scheme significantly outperforms the state-of-the-art schemes by 8.27% and 13.60%, respectively, in terms of utility and precision of the Intersection over Union.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06891v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengru Fang, Senkang Hu, Haonan An, Yuang Zhang, Jingjing Wang, Hangcheng Cao, Xianhao Chen, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>Agent-driven Generative Semantic Communication for Remote Surveillance</title>
      <link>https://arxiv.org/abs/2404.06997</link>
      <description>arXiv:2404.06997v1 Announce Type: new 
Abstract: In the era of 6G, featuring compelling visions of intelligent transportation system, digital twins, remote surveillance is poised to become a ubiquitous practice. The substantial data volume and frequent updates present challenges in wireless networks. To address this, we propose a novel agent-driven generative semantic communication (A-GSC) framework based on reinforcement learning. In contrast to the existing research on semantic communication (SemCom), which mainly focuses on semantic compression or semantic sampling, we seamlessly cascade both together by jointly considering the intrinsic attributes of source information and the contextual information regarding the task. Notably, the introduction of the generative artificial intelligence (GAI) enables the independent design of semantic encoders and decoders. In this work, we develop an agent-assisted semantic encoder leveraging the knowledge based soft actor-critic algorithm, which can track the semantic changes, channel condition, and sampling intervals, so as to perform adaptive semantic sampling. Accordingly, we design a semantic decoder with both predictive and generative capabilities, which consists of two tailored modules. Moreover, the effectiveness of the designed models has been verified based on the dataset generated from CDNet2014, and the performance gain of the overall A-GSC framework in both energy saving and reconstruction accuracy have been demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06997v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wanting Yang, Zehui Xiong, Yanli Yuan, Wenchao Jiang, Tony Q. S. Quek, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>BONES: Near-Optimal Neural-Enhanced Video Streaming</title>
      <link>https://arxiv.org/abs/2310.09920</link>
      <description>arXiv:2310.09920v2 Announce Type: replace-cross 
Abstract: Accessing high-quality video content can be challenging due to insufficient and unstable network bandwidth. Recent advances in neural enhancement have shown promising results in improving the quality of degraded videos through deep learning. Neural-Enhanced Streaming (NES) incorporates this new approach into video streaming, allowing users to download low-quality video segments and then enhance them to obtain high-quality content without violating the playback of the video stream. We introduce BONES, an NES control algorithm that jointly manages the network and computational resources to maximize the quality of experience (QoE) of the user. BONES formulates NES as a Lyapunov optimization problem and solves it in an online manner with near-optimal performance, making it the first NES algorithm to provide a theoretical performance guarantee. Comprehensive experimental results indicate that BONES increases QoE by 5\% to 20\% over state-of-the-art algorithms with minimal overhead. Our code is available at https://github.com/UMass-LIDS/bones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09920v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingdong Wang, Simran Singh, Jacob Chakareski, Mohammad Hajiesmaili, Ramesh K. Sitaraman</dc:creator>
    </item>
    <item>
      <title>AI-Enabled System for Efficient and Effective Cyber Incident Detection and Response in Cloud Environments</title>
      <link>https://arxiv.org/abs/2404.05602</link>
      <description>arXiv:2404.05602v2 Announce Type: replace-cross 
Abstract: The escalating sophistication and volume of cyber threats in cloud environments necessitate a paradigm shift in strategies. Recognising the need for an automated and precise response to cyber threats, this research explores the application of AI and ML and proposes an AI-powered cyber incident response system for cloud environments. This system, encompassing Network Traffic Classification, Web Intrusion Detection, and post-incident Malware Analysis (built as a Flask application), achieves seamless integration across platforms like Google Cloud and Microsoft Azure. The findings from this research highlight the effectiveness of the Random Forest model, achieving an accuracy of 90% for the Network Traffic Classifier and 96% for the Malware Analysis Dual Model application. Our research highlights the strengths of AI-powered cyber security. The Random Forest model excels at classifying cyber threats, offering an efficient and robust solution. Deep learning models significantly improve accuracy, and their resource demands can be managed using cloud-based TPUs and GPUs. Cloud environments themselves provide a perfect platform for hosting these AI/ML systems, while container technology ensures both efficiency and scalability. These findings demonstrate the contribution of the AI-led system in guaranteeing a robust and scalable cyber incident response solution in the cloud.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05602v2</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Ashfaaq M. Farzaan, Mohamed Chahine Ghanem, Ayman El-Hajjar, Deepthi N. Ratnayake</dc:creator>
    </item>
  </channel>
</rss>
