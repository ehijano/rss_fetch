<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Mar 2025 05:25:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the resolution and linear optimization problems subject to a system of bipolar fuzzy relational equalities defined with continuous Archimedean t-norms</title>
      <link>https://arxiv.org/abs/2503.05874</link>
      <description>arXiv:2503.05874v1 Announce Type: new 
Abstract: This paper considers the linear objective function optimization with respect to a more general class of bipolar fuzzy relational equations, where the fuzzy compositions are defined by an arbitrary continuous Archimedean t-norm. In addition, a faster method for finding a global optimum is proposed that, unlike the previous work, does not require obtaining all local optimal solutions and classifying the constraints. Analytical concepts and properties of the Archimedean bipolar fuzzy equations are investigated and two necessary conditions are presented to conceptualize the feasibility of the problem. It is shown that the feasible solution set can be resulted by a union of the finite number of compact sets, where each compact set is obtained by a function. Moreover, to accelerate identification of the mentioned compact sets (and therefore, to speed up solution finding), four simplification techniques are presented, which are based on either omitting redundant constraints and/or eliminating unknowns by assigning them a fixed value. Also, three additional simplification techniques are given to reduce the search domain by removing some parts of the feasible region that do not contain optimal solutions. Subsequently, a method is proposed to find an optimal solution for the current linear optimization problems. The proposed method consists of two accelerative strategies that are used during the problem solving process. By the first strategy, the method neglects some candidate solutions that are not optimal, by considering only a subset of admissible functions. As for the second strategy, a branch-and-bound method is used to delete non-optimal branches. Then, the method is summarized in an algorithm that represents all essential steps of the solution and finally, the whole method is applied in an example that has been chosen in such a way that the various situations are illustrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05874v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amin Ghodousian, Mohammad Sedigh Chopannavaz, Witold Pedrycz</dc:creator>
    </item>
    <item>
      <title>Detecting Destabilizing Nonlinearities in Absolute Stability Analysis of Discrete-Time Feedback Systems</title>
      <link>https://arxiv.org/abs/2503.05875</link>
      <description>arXiv:2503.05875v1 Announce Type: new 
Abstract: This paper is concerned with the absolute stability analysis of discrete-time feedback systems with slope-restricted nonlinearities. By employing static O'Shea-Zames-Falb multipliers in the framework of integral quadratic constraints, we can obtain a certificate for the absolute stability in the form of a linear matrix inequality (LMI). However, since this LMI certificate is only a sufficient condition, we cannot draw any definite conclusion if the LMI turns out to be infeasible. To address this issue, we focus on the dual LMI that is feasible if and only if the original (primal) LMI is infeasible. As the main result, if the dual solution satisfies a certain rank condition, we prove that we can detect a destabilizing nonlinearity within the assumed class of slope-restricted nonlinearities as well as a non-zero equilibrium point of the resulting feedback system, thereby we can conclude that the system of interest is never absolutely stable. The effectiveness of the technical results is demonstrated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05875v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hibiki Gyotoku, Tsuyoshi Yuno, Yoshio Ebihara, Dimitri Peaucelle, Sophie Tarbouriech, Victor Magron</dc:creator>
    </item>
    <item>
      <title>Ergodic-Risk Constrained Policy Optimization: The Linear Quadratic Case</title>
      <link>https://arxiv.org/abs/2503.05878</link>
      <description>arXiv:2503.05878v1 Announce Type: new 
Abstract: Risk-sensitive control balances performance with resilience to unlikely events in uncertain systems. This paper introduces ergodic-risk criteria, which capture long-term cumulative risks through probabilistic limit theorems. By ensuring the dynamics exhibit strong ergodicity, we demonstrate that the time-correlated terms in these limiting criteria converge even with potentially heavy-tailed process noises as long as the noise has a finite fourth moment. Building upon this, we proposed the ergodic-risk constrained policy optimization which incorporates an ergodic-risk constraint to the classical Linear Quadratic Regulation (LQR) framework. We then propose a primal-dual policy optimization method that optimizes the average performance while satisfying the ergodic-risk constraints. Numerical results demonstrate that the new risk-constrained LQR not only optimizes average performance but also limits the asymptotic variance associated with the ergodic-risk criterion, making the closed-loop system more robust against sporadic large fluctuations in process noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05878v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahriar Talebi, Na Li</dc:creator>
    </item>
    <item>
      <title>Nonlocal Stochastic Optimal Control for Diffusion Processes: Existence, Maximum Principle and Financial Applications</title>
      <link>https://arxiv.org/abs/2503.05912</link>
      <description>arXiv:2503.05912v1 Announce Type: new 
Abstract: This paper investigates the optimal control problem for a class of parabolic equations where the diffusion coefficient is influenced by a control function acting nonlocally. Specifically, we consider the optimization of a cost functional that incorporates a controlled probability density evolving under a Fokker-Planck equation with state-dependent drift and diffusion terms. The control variable is subject to spatial convolution through a kernel, inducing nonlocal interactions in both drift and diffusion terms. We establish the existence of optimal controls under appropriate convexity and regularity conditions, leveraging compactness arguments in function spaces. A maximum principle is derived to characterize the optimal control explicitly, revealing its dependence on the adjoint state and the nonlocal structure of the system. We further provide a rigorous financial application in the context of mean-variance portfolio optimization, where both the asset drift and volatility are controlled nonlocally, leading to an integral representation of the optimal investment strategy. The results offer a mathematically rigorous framework for optimizing diffusion-driven systems with spatially distributed control effects, broadening the applicability of nonlocal control methods to stochastic optimization and financial engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05912v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefana-Lucia Anita, Luca Di Persio</dc:creator>
    </item>
    <item>
      <title>Choosing Augmentation Parameters in OSQP- A New Approach based on Conjugate Directions</title>
      <link>https://arxiv.org/abs/2503.05941</link>
      <description>arXiv:2503.05941v1 Announce Type: new 
Abstract: This work proposes a new method to select the augmentation parameters in the operator splitting quadratic program (OSQP) algorithm so as to reduce the computation time of overall algorithm. The selection is based upon the information of conjugate directions of the coefficient matrix of a linear system of equations present in the algorithm. This selection makes it possible to cache these conjugate directions, instead of computing them at each iteration, resulting in faster computation of the solution of the linear system thus reducing the overall computation time. This reduction is demonstrated by a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05941v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avinash Kumar</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming in Ordered Vector Space</title>
      <link>https://arxiv.org/abs/2503.06055</link>
      <description>arXiv:2503.06055v1 Announce Type: new 
Abstract: Recent approaches to the theory of dynamic programming view dynamic programs as families of policy operators acting on partially ordered sets. In this paper, we extend these ideas by shifting from arbitrary partially ordered sets to ordered vector space. The advantage of working in this setting is that ordered vector spaces have well integrated algebric and order structure, which leads to sharper fixed point results. These fixed point results can then be exploited to obtain strong optimality properties. We illustrate our results through a range of applications, including new findings for several useful models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06055v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nisha Peng, John Stachurski</dc:creator>
    </item>
    <item>
      <title>An adaptive ADMM with regularized spectral penalty for sparse portfolio selection</title>
      <link>https://arxiv.org/abs/2503.06185</link>
      <description>arXiv:2503.06185v1 Announce Type: new 
Abstract: The mean-variance (MV) model is the core of modern portfolio theory. Nevertheless, it suffers from the over-fitting problem due to the estimation errors of model parameters. We consider the $\ell_{1}$ regularized MV model, which adds an $\ell_{1}$ regularization term in the objective to prevent over-fitting and promote sparsity of solutions. By investigating the relationship between sample size and over-fitting, we propose an initial regularization parameter scheme in the $\ell_{1}$ regularized MV model. Then we propose an adaptive parameter tuning strategy to control the amount of short sales. ADMM is a well established algorithm whose performance is affected by the penalty parameter. In this paper, a penalty parameter scheme based on regularized Barzilai-Borwein step size is proposed, and the modified ADMM is used to solve the $\ell_{1}$ regularized MV problem. Numerical results verify the effectiveness of the two types of parameters proposed in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06185v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Xu</dc:creator>
    </item>
    <item>
      <title>Broyden quasi-Newton secant-type method for solving constrained mixed generalized equations</title>
      <link>https://arxiv.org/abs/2503.06206</link>
      <description>arXiv:2503.06206v1 Announce Type: new 
Abstract: This paper presents a novel variant of the Broyden quasi-Newton secant-type method aimed at solving constrained mixed generalized equations, which can include functions that are not necessarily differentiable. The proposed method integrates the classical secant approach with techniques inspired by the Conditional Gradient method to handle constraints effectively. We establish local convergence results by applying the contraction mapping principle. Specifically, under assumptions of Lipschitz continuity, a modified Broyden update for derivative approximation, and the metric regularity property, we show that the algorithm generates a well-defined sequence that converges locally at a Q-linear rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06206v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. C. da Silva Junior, O. P. Ferreira, G. N. Silva</dc:creator>
    </item>
    <item>
      <title>Modified Bregman Golden Ratio Algorithm for Mixed Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2503.06285</link>
      <description>arXiv:2503.06285v1 Announce Type: new 
Abstract: In this article, we provide a modification to the Bregman Golden Ratio Algorithm (B-GRAAL). We analyze the B-GRAAL algorithm with a new step size rule, where the step size increases after a certain number of iterations and does not require prior knowledge of the global Lipschitz constant of the cost operator. Under suitable assumptions, we establish the global iterate convergence as well as the R-linear rate of convergence of the modified algorithm. The numerical performance of the proposed approach is validated for the matrix game problem and the sparse logistic regression problem in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06285v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gourav Kumar, V. Vetrivel</dc:creator>
    </item>
    <item>
      <title>Null controllability for semi-discrete stochastic semilinear parabolic equations</title>
      <link>https://arxiv.org/abs/2503.06440</link>
      <description>arXiv:2503.06440v1 Announce Type: new 
Abstract: The global null controllability of stochastic semilinear parabolic equations with globally Lipschitz nonlinearities has been addressed in recent literature. However, there are no results concerning their numerical approximation and the behavior of discrete controls when the discretization parameter goes to zero. This paper is intended to studying the null controllability for semi-discrete stochastic semilinear parabolic equations, where the spatial variable is discretized with finite difference scheme and the time is kept as a continuous variable. The proof is based on a new refined semi-discrete Carleman estimate and Banach fixed point method. The main novelty here is that the Carleman parameters and discretization parameter are made explicit and are then used in a Banach fixed point method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06440v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Wang, Qingmei Zhao</dc:creator>
    </item>
    <item>
      <title>Global Convergence and Rate Analysis of the Steepest Descent Method for Uncertain Multiobjective Optimization via a Robust Optimization Approach</title>
      <link>https://arxiv.org/abs/2503.06476</link>
      <description>arXiv:2503.06476v1 Announce Type: new 
Abstract: In this article, we extend our previous work (Applicable Analysis, 2024, pp. 1-25) on the steepest descent method for uncertain multiobjective optimization problems. While that study established local convergence, it did not address global convergence and the rate of convergence of the steepest descent algorithm. To bridge this gap, we provide rigorous proofs for both global convergence and the linear convergence rate of the steepest descent algorithm. Global convergence analysis strengthens the theoretical foundation of the steepest descent method for uncertain multiobjective optimization problems, offering deeper insights into its efficiency and robustness across a broader class of optimization problems. These findings enhance the method's practical applicability and contribute to the advancement of robust optimization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06476v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shubham Kumar, Nihar Kumar Mahato, Debdas Ghosh</dc:creator>
    </item>
    <item>
      <title>Robust Optimization Approach for Solving Uncertain Multiobjective Optimization Problems Using the Projected Gradient Method</title>
      <link>https://arxiv.org/abs/2503.06509</link>
      <description>arXiv:2503.06509v1 Announce Type: new 
Abstract: Numerous real-world applications of uncertain multiobjective optimization problems (UMOPs) can be found in science, engineering, business, and management. To handle the solution of uncertain optimization problems, robust optimization is a relatively new field. An extended version of the projected gradient method (PGM) for a deterministic smooth multiobjective optimization problem (MOP) is presented in the current study as a PGM for UMOP. An objective-wise worst-case cost (OWWC) type robust counterpart is considered, and the PGM is used to solve a UMOP by using OWWC. A projected gradient descent algorithm is created using theoretical findings. It is demonstrated that the projected gradient descent algorithm's generated sequence converges to the robust counterpart's weak Pareto optimal solution, which will be the robust weak Pareto optimal solution for UMOP. Under a few reasonable presumptions, the projected gradient descent algorithm's full convergent behavior is also justified. Finally, numerical tests are presented to validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06509v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shubham Kumar, Nihar Kumar Mahatoa, Debdas Ghosh</dc:creator>
    </item>
    <item>
      <title>On Solving Minimization and Min-Max Problems by First-Order Methods with Relative Error in Gradients</title>
      <link>https://arxiv.org/abs/2503.06628</link>
      <description>arXiv:2503.06628v1 Announce Type: new 
Abstract: First-order methods for minimization and saddle point (min-max) problems are one of the cornerstones of modern ML. The majority of works obtain favorable complexity guarantees of such methods assuming that exact gradient information is available. At the same time, even the use floating-point representation of real numbers already leads to relative error in all the computations. Relative errors arise also in such applications as bilevel optimization, inverse problems, derivative-free optimization, inexact proximal methods. This paper answers several theoretical open questions on first-order optimization methods under relative errors. We propose an explicit single-loop accelerated gradient method that preserves optimal convergence rate under maximal possible relative error in the gradient and explore the tradeoff between the relative error and deterioration in the linear convergence rate. We further explore similar questions for saddle point problems showing that a variant of gradient descent-ascent and the extragradient method are robust to such errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06628v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Vasin, Valery Krivchenko, Dmitry Kovalev, Fedyor Stonyakin, Nazari Tupitsa, Pavel Dvurechensky, Mohammad Alkousa, Nikita Kornilov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>An exponentially stable discrete-time primal-dual algorithm for distributed constrained optimization</title>
      <link>https://arxiv.org/abs/2503.06662</link>
      <description>arXiv:2503.06662v1 Announce Type: new 
Abstract: This paper studies a distributed algorithm for constrained consensus optimization that is obtained by fusing the Arrow-Hurwicz-Uzawa primal-dual gradient method for centralized constrained optimization and the Wang-Elia method for distributed unconstrained optimization. It is shown that the optimal primal-dual point is a semiglobally exponentially stable equilibrium for the algorithm, which implies linear convergence. The analysis is based on the separation between a slow centralized optimization dynamics describing the evolution of the average estimate toward the optimum, and a fast dynamics describing the evolution of the consensus error over the network. These two dynamics are mutually coupled, and the stability analysis builds on control theoretic tools such as time-scale separation, Lyapunov theory, and the small-gain principle. Our analysis approach highlights that the consensus dynamics can be seen as a fast, parasite one, and that stability of the distributed algorithm is obtained as a robustness consequence of the semiglobal exponential stability properties of the centralized method. This perspective can be used to enable other significant extensions, such as time-varying networks or delayed communication, that can be seen as ``perturbations" of the centralized algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06662v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaoxing Ren, Michelangelo Bin, Ivano Notarnicola, Thomas Parisini</dc:creator>
    </item>
    <item>
      <title>Necessary conditions for approximate solutions of vector and set optimization problems with variable domination structure</title>
      <link>https://arxiv.org/abs/2503.06681</link>
      <description>arXiv:2503.06681v1 Announce Type: new 
Abstract: We consider vector and set optimization problems with respect to variable domination structures given by set-valued mappings acting between the preimage space and the image space of the objective mapping, as well as by set-valued mappings with the same input and output space, that coincides with the image space of the objective mapping. The aim of this paper is to derive necessary conditions for approximately nondominated points of problems with a single-valued objective function, employing an extension of Ekeland's Variational Principle for problems with respect to variable domination structures in terms of generalized differentiation in the sense of Mordukhovich. For set-valued objective mappings, we derive necessary conditions for approximately nondominated points of problems with variable domination structure taking into account the incompatibility between openness and optimality and a directional openness result for the sum of set-valued maps. We describe the necessary conditions for approximately nondominated points of set optimization problems with variable domination structure in terms of the limiting (Mordukhovich) generalized differentiation objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06681v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Durea, Christian G\"unther, Radu Strugariu, Christiane Tammer</dc:creator>
    </item>
    <item>
      <title>Optimistic Noise-Aware Sequential Quadratic Programming for Equality Constrained Optimization with Rank-Deficient Jacobians</title>
      <link>https://arxiv.org/abs/2503.06702</link>
      <description>arXiv:2503.06702v1 Announce Type: new 
Abstract: We propose and analyze a sequential quadratic programming algorithm for minimizing a noisy nonlinear smooth function subject to noisy nonlinear smooth equality constraints. The algorithm uses a step decomposition strategy and, as a result, is robust to potential rank-deficiency in the constraints, allows for two different step size strategies, and has an early stopping mechanism. Under the linear independence constraint qualification, convergence is established to a neighborhood of a first-order stationary point, where the radius of the neighborhood is proportional to the noise levels in the objective function and constraints. Moreover, in the rank-deficient setting, the merit parameter may converge to zero, and convergence to a neighborhood of an infeasible stationary point is established. Numerical experiments demonstrate the efficiency and robustness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06702v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albert S. Berahas, Jiahao Shi, Baoyu Zhou</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control of an Epidemic Under Partial Information</title>
      <link>https://arxiv.org/abs/2503.06804</link>
      <description>arXiv:2503.06804v1 Announce Type: new 
Abstract: In this paper, we address a social planner's optimal control problem for a partially observable stochastic epidemic model. The control measures include social distancing, testing, and vaccination. Using a diffusion approximation for the state dynamics of the epidemic, we apply filtering arguments to transform the partially observable stochastic optimal control problem into an optimal control problem with complete information. This transformed problem is treated as a Markov decision process. The associated Bellman equation is solved numerically using optimal quantization methods for approximating the expectations involved to mitigate the curse of dimensionality. We implement two approaches, the first involves state discretization coupled with linear interpolation of the value function at non-grid points. The second utilizes a parametrization of the value function with educated ansatz functions. Extensive numerical experiments are presented to demonstrate the efficacy of both methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06804v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Mbouandi Njiasse, Florent Ouabo Kamkumo, Ralf Wunderlich</dc:creator>
    </item>
    <item>
      <title>Generic linear convergence for algorithms of non-linear least squares over smooth varieties</title>
      <link>https://arxiv.org/abs/2503.06877</link>
      <description>arXiv:2503.06877v1 Announce Type: new 
Abstract: In applications, a substantial number of problems can be formulated as non-linear least squares problems over smooth varieties. Unlike the usual least squares problem over a Euclidean space, the non-linear least squares problem over a variety can be challenging to solve and analyze, even if the variety itself is simple. Geometrically, this problem is equivalent to projecting a point in the ambient Euclidean space onto the image of the given variety under a non-linear map. It is the singularities of the image that make both the computation and the analysis difficult. In this paper, we prove that under some mild assumptions, these troublesome singularities can always be avoided. This enables us to establish a linear convergence rate for iterative sequences generated by algorithms satisfying some standard assumptions. We apply our general results to the low-rank partially orthogonal tensor approximation problem. As a consequence, we obtain the linear convergence rate for a classical APD-ALS method applied to a generic tensor, without any further assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06877v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenglong Hu, Ke Ye</dc:creator>
    </item>
    <item>
      <title>Co-optimization of Short- and Long-term Decisions for the Transmission Grid's Resilience to Flooding</title>
      <link>https://arxiv.org/abs/2503.06909</link>
      <description>arXiv:2503.06909v1 Announce Type: new 
Abstract: We present and analyze a three-stage stochastic optimization model that integrates output from a geoscience-based flood model with a power flow model for transmission grid resilience planning against flooding. The proposed model coordinates the decisions made across multiple stages of resilience planning and recommends an optimal allocation of the overall resilience investment budget across short- and long-term measures. While doing so, the model balances the cost of investment in both short- and long-term measures against the cost of load shed that results from unmitigated flooding forcing grid components go out-of-service. We also present a case study for the Texas Gulf Coast region to demonstrate how the proposed model can provide insights into various grid resilience questions. Specifically, we demonstrate that for a comprehensive yet reasonable range of economic values assigned to load loss, we should make significant investments in the permanent hardening of substations such that we achieve near-zero load shed. We also show that not accounting for short-term measures while making decisions about long-term measures can lead to significant overspending. Furthermore, we demonstrate that a technological development enabling to protect substations on short notice before imminent hurricanes could vastly influence and reduce the total investment budget that would otherwise be allocated for more expensive substation hardening. Lastly, we also show that for a wide range of values associated with the cost of mitigative long-term measures, the proportion allocated to such measures dominates the overall resilience spending.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06909v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashutosh Shukla, Erhan Kutanoglu, John Hasenbein</dc:creator>
    </item>
    <item>
      <title>Inverse single facility location problem in the plane with variable coordinates</title>
      <link>https://arxiv.org/abs/2503.07016</link>
      <description>arXiv:2503.07016v1 Announce Type: new 
Abstract: In traditional facility location problems, a set of points is provided, and the objective is to determine the best location for a new facility based on criteria such as minimizing cost, time, and distances between clients and facilities. Conversely, inverse single facility location problems focus on adjusting the problem's parameters at minimal cost to make a specific point optimal. In this paper, we present an algorithm for the general case of the inverse single facility location problem with variable coordinates in a two-dimensional space. We outline the optimality conditions of this algorithm. Additionally, we examine the specific case namely the inverse minisum single facility location problem and test the algorithm on various instances. The results demonstrate the algorithm's effectiveness in these scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07016v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nazanin Tour-Savadkoohi, Jafar Fathali</dc:creator>
    </item>
    <item>
      <title>Sensitivity of Online Feedback Optimization to time-varying parameters</title>
      <link>https://arxiv.org/abs/2503.07030</link>
      <description>arXiv:2503.07030v1 Announce Type: new 
Abstract: Online Feedback Optimization uses optimization algorithms as dynamic systems to design optimal control inputs. The results obtained from Online Feedback Optimization depend on the setup of the chosen optimization algorithm. In this work we analyse the sensitivity of Online Feedback Optimization to the parameters of projected gradient descent as the algorithm of choice. We derive closed-form expressions for sensitivities of the objective function with respect to the parameters of the projected gradient and to time-varying model mismatch. The formulas are then used for analysis of model mismatch in a gas lift optimization problem. The results of the case study indicate that the sensitivity of Online Feedback Optimization to the model mismatch depends on how long the controller has been running, with decreasing sensitivity to mismatch in individual timesteps for long operation times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07030v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Zagorowska, Lars Imsland</dc:creator>
    </item>
    <item>
      <title>The Optimal Control Problem of Fully Coupled FBSDEs Driven by Sub-diffusion with Applications</title>
      <link>https://arxiv.org/abs/2503.07034</link>
      <description>arXiv:2503.07034v1 Announce Type: new 
Abstract: This paper is devoted to an optimal control problem of fully coupled forward-backward stochastic differential equations driven by sub-diffusion, whose solutions are not Markov processes. The stochastic maximum principle is obtained, where the control domain may not be convex and the diffusion term is independent of the control variable. Additionally, problem with state constraint is researched by using Ekeland's variational principle. The theoretical results obtained are applied to a cash management optimization problem in bear market, and the optimal strategy is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07034v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chenhui Hao, Jingtao Shi, Shuaiqi Zhang</dc:creator>
    </item>
    <item>
      <title>Data-driven stabilization of polynomial systems using density functions</title>
      <link>https://arxiv.org/abs/2503.07092</link>
      <description>arXiv:2503.07092v1 Announce Type: new 
Abstract: This paper studies data-driven stabilization of a class of unknown polynomial systems using data corrupted by bounded noise. Existing work addressing this problem has focused on designing a controller and a Lyapunov function so that a certain state-dependent matrix is negative definite, which ensures asymptotic stability of all closed-loop systems compatible with the data. However, as we demonstrate in this paper, considering the negative definiteness of this matrix introduces conservatism, which limits the applicability of current approaches. To tackle this issue, we develop a new method for the data-driven stabilization of polynomial systems using the concept of density functions. The control design consists of two steps. Firstly, a dual Lyapunov theorem is used to formulate a sum of squares program that allows us to compute a rational state feedback controller for all systems compatible with the data. By the dual Lyapunov theorem, this controller ensures that the trajectories of the closed-loop system converge to zero for almost all initial states. Secondly, we propose a method to verify whether the designed controller achieves asymptotic stability of all closed-loop systems compatible with the data. Apart from reducing conservatism of existing methods, the proposed approach can also readily take into account prior knowledge on the system parameters. A key technical result developed in this paper is a new type of S-lemma for a specific class of matrices that, in contrast to the classical S-lemma, avoids the use of multipliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07092v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huayuan Huang, M. Kanat Camlibel, Raffaella Carloni, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>Numerical solution of optimal control problems using quadratic transport regularization</title>
      <link>https://arxiv.org/abs/2503.07105</link>
      <description>arXiv:2503.07105v1 Announce Type: new 
Abstract: We address optimal control problems on the space of measures for an objective containing a smooth functional and an optimal transport regularization. That is, the quadratic Monge-Kantorovich distance between a given prior measure and the control is penalized in the objective. We consider optimality conditions and reparametrize the problem using the celebrated structure theorem by Brenier. The optimality conditions can be formulated as a piecewise differentiable equation. This is utilized to formulate solution algorithms and to analyze their local convergence properties. We present a numerical example to illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07105v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Borchard, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Optimal control problems with free right end point</title>
      <link>https://arxiv.org/abs/2503.07134</link>
      <description>arXiv:2503.07134v1 Announce Type: new 
Abstract: This paper is dedicated to the elementary proof of Pontryagins maximum principle for problems with free right end point. The proof for the standard problem is taken from the monography of Ioffe and Tichomirov. We assume piecewise continuous controls and the proof turns out to be very simple. We generalize the concept to the problem of optimal multiprocesses, to control problems with delays and to the control of Volterra integral equations. Furthermore, we discuss the problem on infinite horizon. Moreover, we state Arrow type sufficiency conditions. The optimality conditions are demonstrated on illustrative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07134v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nico Tauchnitz</dc:creator>
    </item>
    <item>
      <title>Strat{\'e}gies de contr{\^o}le pour les {\'e}oliennes flottantes : {\'e}tat de l'art et perspectives</title>
      <link>https://arxiv.org/abs/2503.07138</link>
      <description>arXiv:2503.07138v1 Announce Type: new 
Abstract: The floating wind turbines sector has great energy potential. However, minimizing the movement of the structure under the combined effect of wind and waves while ensuring maximum power extraction over a wide operating range is one of the main challenges for the control of these turbines. This paper presents a review of control methods for floating wind turbines from the recent literature. The limitations of these controllers are discussed, before introducing a presentation of several promising data-based methods. In particular, this paper focuses on artificial intelligence techniques associated with data-based control methods. Finally, the CREATIF project dealing with real-time simulation of floating wind turbines and their intelligent controls is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07138v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Flavie Didier (FEMTO-ST), Salah Laghrouche (FEMTO-ST), Daniel Depernet (FEMTO-ST)</dc:creator>
    </item>
    <item>
      <title>Optimal Operation of Renewable Energy Communities under Demand Response Programs</title>
      <link>https://arxiv.org/abs/2503.07149</link>
      <description>arXiv:2503.07149v1 Announce Type: new 
Abstract: Within the context of renewable energy communities, this paper focuses on optimal operation of producers equipped with energy storage systems in the presence of demand response. A novel strategy for optimal scheduling of the storage systems of the community members under price-volume demand response programs, is devised. The underlying optimization problem is designed as a low-complexity mixed-integer linear program that scales well with the community size. Once the optimal solution is found, an algorithm for distributing the demand response rewards is introduced in order to guarantee fairness among participants. The proposed approach ensures increased benefits for producers joining a community compared to standalone operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07149v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gianni Bianchini, Marco Casini, Milad Gholami</dc:creator>
    </item>
    <item>
      <title>Global and Robust Optimisation for Non-Convex Quadratic Programs</title>
      <link>https://arxiv.org/abs/2503.07310</link>
      <description>arXiv:2503.07310v1 Announce Type: new 
Abstract: This paper presents a novel algorithm integrating global and robust optimisation methods to solve continuous non-convex quadratic problems under convex uncertainty sets. The proposed Robust spatial branch-and-bound (RsBB) algorithm combines the principles of spatial branch-and-bound (sBB) with robust cutting planes. We apply the RsBB algorithm to quadratically constrained quadratic programming (QCQP) pooling problems, utilising McCormick envelopes to obtain convex lower bounds. The performance of the RsBB algorithm is compared with state-of-the-art methods that rely on global solvers. As computational test bed for our proposed approach we focus on pooling problems under different types and sizes of uncertainty sets. The findings of our work highlight the efficiency of the RsBB algorithm in terms of computational time and optimality convergence and provide insights to the advantages of combining robustness and optimality search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07310v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asimina Marousi, Vassilis M. Charitopoulos</dc:creator>
    </item>
    <item>
      <title>Decision-Dependent Stochastic Optimization: The Role of Distribution Dynamics</title>
      <link>https://arxiv.org/abs/2503.07324</link>
      <description>arXiv:2503.07324v1 Announce Type: new 
Abstract: Distribution shifts have long been regarded as troublesome external forces that a decision-maker should either counteract or conform to. An intriguing feedback phenomenon termed decision dependence arises when the deployed decision affects the environment and alters the data-generating distribution. In the realm of performative prediction, this is encoded by distribution maps parameterized by decisions due to strategic behaviors. In contrast, we formalize an endogenous distribution shift as a feedback process featuring nonlinear dynamics that couple the evolving distribution with the decision. Stochastic optimization in this dynamic regime provides a fertile ground to examine the various roles played by dynamics in the composite problem structure. To this end, we develop an online algorithm that achieves optimal decision-making by both adapting to and shaping the dynamic distribution. Throughout the paper, we adopt a distributional perspective and demonstrate how this view facilitates characterizations of distribution dynamics and the optimality and generalization performance of the proposed algorithm. We showcase the theoretical results in an opinion dynamics context, where an opportunistic party maximizes the affinity of a dynamic polarized population, and in a recommender system scenario, featuring performance optimization with discrete distributions in the probability simplex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07324v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyu He, Saverio Bolognani, Florian D\"orfler, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>A Universally Optimal Primal-Dual Method for Minimizing Heterogeneous Compositions</title>
      <link>https://arxiv.org/abs/2503.07566</link>
      <description>arXiv:2503.07566v1 Announce Type: new 
Abstract: This paper proposes a universal, optimal algorithm for convex minimization problems of the composite form $g_0(x)+h(g_1(x),\dots, g_m(x)) + u(x)$. We allow each $g_j$ to independently range from being nonsmooth Lipschitz to smooth, from convex to strongly convex, described by notions of H\"older continuous gradients and uniform convexity. Note that, although the objective is built from a heterogeneous combination of such structured components, it does not necessarily possess smoothness, Lipschitzness, or any favorable structure overall other than convexity. Regardless, we provide a universal optimal method in terms of oracle access to (sub)gradients of each $g_j$. The key insight enabling our optimal universal analysis is the construction of two new constants, the Approximate Dualized Aggregate smoothness and strong convexity, which combine the benefits of each heterogeneous structure into single quantities amenable to analysis. As a key application, fixing $h$ as the nonpositive indicator function, this model readily captures functionally constrained minimization $g_0(x)+u(x)$ subject to $g_j(x)\leq 0$. In particular, our algorithm and analysis are directly inspired by the smooth constrained minimization method of Zhang and Lan and consequently recover and generalize their accelerated guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07566v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Zoll, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Practical Topics in Optimization</title>
      <link>https://arxiv.org/abs/2503.05882</link>
      <description>arXiv:2503.05882v1 Announce Type: cross 
Abstract: In an era where data-driven decision-making and computational efficiency are paramount, optimization plays a foundational role in advancing fields such as mathematics, computer science, operations research, machine learning, and beyond. From refining machine learning models to improving resource allocation and designing efficient algorithms, optimization techniques serve as essential tools for tackling complex problems. This book aims to provide both an introductory guide and a comprehensive reference, equipping readers with the necessary knowledge to understand and apply optimization methods within their respective fields.
  Our primary goal is to demystify the inner workings of optimization algorithms, including black-box and stochastic optimizers, by offering both formal and intuitive explanations. Starting from fundamental mathematical principles, we derive key results to ensure that readers not only learn how these techniques work but also understand when and why to apply them effectively. By striking a careful balance between theoretical depth and practical application, this book serves a broad audience, from students and researchers to practitioners seeking robust optimization strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05882v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Lu</dc:creator>
    </item>
    <item>
      <title>An implicit shock tracking method for simulation of shock-dominated flows over complex domains using mesh-based parametrizations</title>
      <link>https://arxiv.org/abs/2503.05892</link>
      <description>arXiv:2503.05892v1 Announce Type: cross 
Abstract: A mesh-based parametrization is a parametrization of a geometric object that is defined solely from a mesh of the object, e.g., without an analytical expression or computer-aided design (CAD) representation of the object. In this work, we propose a mesh-based parametrization of an arbitrary $d'$-dimensional object embedded in a $d$-dimensional space using tools from high-order finite elements. Using mesh-based parametrizations, we construct a boundary-preserving parametrization of the nodal coordinates of a computational mesh that ensures all nodes remain on all their original boundaries. These boundary-preseving parametrizations allow the nodes of the mesh to move only in ways that will not change the computational domain. They also ensure nodes will not move between boundaries, which would cause issues assigning boundary conditions for partial differential equation simulations and lead to inaccurate geometry representations for non-smooth boundary transitions. Finally, we integrate boundary-preserving, mesh-based parametrizations into high-order implicit shock tracking, an optimization-based discontinuous Galerkin method that moves nodes to align mesh faces with non-smooth flow features to represent them perfectly with inter-element jumps, leaving the intra-element polynomial basis to represent smooth regions of the flow with high-order accuracy. Mesh-based parametrizations enable implicit shock tracking simulations of shock-dominated flows over geometries without simple analytical parametrizations. Several demonstrations of mesh-based parametrizations are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05892v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander M. Perez Reyes, Matthew J. Zahr</dc:creator>
    </item>
    <item>
      <title>Learning about passivity from data</title>
      <link>https://arxiv.org/abs/2503.05989</link>
      <description>arXiv:2503.05989v1 Announce Type: cross 
Abstract: This paper presents a data-driven methodology to estimate the storage function of a passive system. The methodology consists in parametrizing the storage function with a dictionary then running a linear program. Results on a benchmark are presented to illustrate its properties, including its robustness to noise. Various uses of the storage function that do not require knowledge of a model are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05989v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexandre Sanfelici Bazanella</dc:creator>
    </item>
    <item>
      <title>Optimization models for needle placement in 3D-printed masks for high dose rate brachytherapy</title>
      <link>https://arxiv.org/abs/2503.06000</link>
      <description>arXiv:2503.06000v1 Announce Type: cross 
Abstract: High dose rate brachytherapy (HDR-BT) is an appealing treatment option for superficial cancers that permits the delivery of higher local doses than other radiation modalities without a significant increase in toxicity. In order for HDR-BT to be used in these situations, needles through which the radiation source is passed must be strategically placed in close proximity to the patient's body. Currently, this crucial step is performed manually by physicians or medical physicists. The use of 3D-printed masks customized for individual patients has been advocated as a way to more precisely and securely position these needles, with the potential of producing better and safer treatment plans. In this paper, we propose optimization approaches for positioning needles within 3D-printed masks for HDR-BT, focusing on skin cancers. We numerically show that the models we propose efficiently generate more homogeneous plans than those derived manually and provide an alternative to manual placement that can save planning time and enhance plan quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06000v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nasim Mirzavand Boroujeni, Jean-Philippe P. Richard, David Sterling, Christopher Wilke</dc:creator>
    </item>
    <item>
      <title>Natural Gradient Descent for Control</title>
      <link>https://arxiv.org/abs/2503.06070</link>
      <description>arXiv:2503.06070v1 Announce Type: cross 
Abstract: This paper bridges optimization and control, and presents a novel closed-loop control framework based on natural gradient descent, offering a trajectory-oriented alternative to traditional cost-function tuning. By leveraging the Fisher Information Matrix, we formulate a preconditioned gradient descent update that explicitly shapes system trajectories. We show that, in sharp contrast to traditional controllers, our approach provides flexibility to shape the system's low-level behavior. To this end, the proposed method parameterizes closed-loop dynamics in terms of stationary covariance and an unknown cost function, providing a geometric interpretation of control adjustments. We establish theoretical stability conditions. The simulation results on a rotary inverted pendulum benchmark highlight the advantages of natural gradient descent in trajectory shaping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06070v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramin Esmzad, Farnaz Adib Yaghmaie, Hamidreza Modares</dc:creator>
    </item>
    <item>
      <title>The uniqueness of Lyapunov rank among symmetric cones</title>
      <link>https://arxiv.org/abs/2503.06143</link>
      <description>arXiv:2503.06143v1 Announce Type: cross 
Abstract: The Lyapunov rank of a cone is the dimension of the Lie algebra of its automorphism group. It is invariant under linear isomorphism and in general not unique - two or more non-isomorphic cones can share the same Lyapunov rank. It is therefore not possible in general to identify cones using Lyapunov rank. But suppose we look only among symmetric cones. Are there any that can be uniquely identified (up to isomorphism) by their Lyapunov ranks? We provide a complete answer for irreducible cones and make some progress in the general case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06143v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Michael Orlitzky, Giovanni Barbarino</dc:creator>
    </item>
    <item>
      <title>Momentum-based Distributed Resource Scheduling Optimization Subject to Sector-Bound Nonlinearity and Latency</title>
      <link>https://arxiv.org/abs/2503.06167</link>
      <description>arXiv:2503.06167v1 Announce Type: cross 
Abstract: This paper proposes an accelerated consensus-based distributed iterative algorithm for resource allocation and scheduling. The proposed gradient-tracking algorithm introduces an auxiliary variable to add momentum towards the optimal state. We prove that this solution is all-time feasible, implying that the coupling constraint always holds along the algorithm iterative procedure; therefore, the algorithm can be terminated at any time. This is in contrast to the ADMM-based solutions that meet constraint feasibility asymptotically. Further, we show that the proposed algorithm can handle possible link nonlinearity due to logarithmically-quantized data transmission (or any sign-preserving odd sector-bound nonlinear mapping). We prove convergence over uniformly-connected dynamic networks (i.e., a hybrid setup) that may occur in mobile and time-varying multi-agent networks. Further, the latency issue over the network is addressed by proposing delay-tolerant solutions. To our best knowledge, accelerated momentum-based convergence, nonlinear linking, all-time feasibility, uniform network connectivity, and handling (possible) time delays are not altogether addressed in the literature. These contributions make our solution practical in many real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06167v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Zulfiya R. Gabidullina, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Optimal Output Feedback Learning Control for Discrete-Time Linear Quadratic Regulation</title>
      <link>https://arxiv.org/abs/2503.06226</link>
      <description>arXiv:2503.06226v1 Announce Type: cross 
Abstract: This paper studies the linear quadratic regulation (LQR) problem of unknown discrete-time systems via dynamic output feedback learning control. In contrast to the state feedback, the optimality of the dynamic output feedback control for solving the LQR problem requires an implicit condition on the convergence of the state observer. Moreover, due to unknown system matrices and the existence of observer error, it is difficult to analyze the convergence and stability of most existing output feedback learning-based control methods. To tackle these issues, we propose a generalized dynamic output feedback learning control approach with guaranteed convergence, stability, and optimality performance for solving the LQR problem of unknown discrete-time linear systems. In particular, a dynamic output feedback controller is designed to be equivalent to a state feedback controller. This equivalence relationship is an inherent property without requiring convergence of the estimated state by the state observer, which plays a key role in establishing the off-policy learning control approaches. By value iteration and policy iteration schemes, the adaptive dynamic programming based learning control approaches are developed to estimate the optimal feedback control gain. In addition, a model-free stability criterion is provided by finding a nonsingular parameterization matrix, which contributes to establishing a switched iteration scheme. Furthermore, the convergence, stability, and optimality analyses of the proposed output feedback learning control approaches are given. Finally, the theoretical results are validated by two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06226v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kedi Xiea, Martin Guay, Shimin Wang, Fang Deng, Maobin Lu</dc:creator>
    </item>
    <item>
      <title>Higher Order Reduced Rank Regression</title>
      <link>https://arxiv.org/abs/2503.06528</link>
      <description>arXiv:2503.06528v1 Announce Type: cross 
Abstract: Reduced Rank Regression (RRR) is a widely used method for multi-response regression. However, RRR assumes a linear relationship between features and responses. While linear models are useful and often provide a good approximation, many real-world problems involve more complex relationships that cannot be adequately captured by simple linear interactions. One way to model such relationships is via multilinear transformations. This paper introduces Higher Order Reduced Rank Regression (HORRR), an extension of RRR that leverages multi-linear transformations, and as such is capable of capturing nonlinear interactions in multi-response regression. HORRR employs tensor representations for the coefficients and a Tucker decomposition to impose multilinear rank constraints as regularization akin to the rank constraints in RRR. Encoding these constraints as a manifold allows us to use Riemannian optimization to solve this HORRR problems. We theoretically and empirically analyze the use of Riemannian optimization for solving HORRR problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06528v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leia Greenberg, Haim Avron</dc:creator>
    </item>
    <item>
      <title>Automated Proof of Polynomial Inequalities via Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.06592</link>
      <description>arXiv:2503.06592v1 Announce Type: cross 
Abstract: Polynomial inequality proving is fundamental to many mathematical disciplines and finds wide applications in diverse fields. Current traditional algebraic methods are based on searching for a polynomial positive definite representation over a set of basis. However, these methods are limited by truncation degree. To address this issue, this paper proposes an approach based on reinforcement learning to find a {Krivine-basis} representation for proving polynomial inequalities. Specifically, we formulate the inequality proving problem as a linear programming (LP) problem and encode it as a basis selection problem using reinforcement learning (RL), achieving a non-negative {Krivine basis}. Moreover, a fast multivariate polynomial multiplication method based on Fast Fourier Transform (FFT) is employed to enhance the efficiency of action space search. Furthermore, we have implemented a tool called {APPIRL} (Automated Proof of Polynomial Inequalities via Reinforcement Learning). Experimental evaluation on benchmark problems demonstrates the feasibility and effectiveness of our approach. In addition, {APPIRL} has been successfully applied to solve the maximum stable set problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06592v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Banglong Liu, Niuniu Qi, Xia Zeng, Lydia Dehbi, Zhengfeng Yang</dc:creator>
    </item>
    <item>
      <title>Precise Insulin Delivery for Artificial Pancreas: A Reinforcement Learning Optimized Adaptive Fuzzy Control Approach</title>
      <link>https://arxiv.org/abs/2503.06701</link>
      <description>arXiv:2503.06701v1 Announce Type: cross 
Abstract: This paper explores the application of reinforcement learning to optimize the parameters of a Type-1 Takagi-Sugeno fuzzy controller, designed to operate as an artificial pancreas for Type 1 diabetes. The primary challenge in diabetes management is the dynamic nature of blood glucose levels, which are influenced by several factors such as meal intake and timing. Traditional controllers often struggle to adapt to these changes, leading to suboptimal insulin administration. To address this issue, we employ a reinforcement learning agent tasked with adjusting 27 parameters of the Takagi-Sugeno fuzzy controller at each time step, ensuring real-time adaptability. The study's findings demonstrate that this approach significantly enhances the robustness of the controller against variations in meal size and timing, while also stabilizing glucose levels with minimal exogenous insulin. This adaptive method holds promise for improving the quality of life and health outcomes for individuals with Type 1 diabetes by providing a more responsive and precise management tool. Simulation results are given to highlight the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06701v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Mameche, Abdelhadi Abedou, Taqwa Mezaache, Mohamed Tadjine</dc:creator>
    </item>
    <item>
      <title>Recursive Estimation for Dynamical Systems with Measurement Bias, Outliers and Constraints</title>
      <link>https://arxiv.org/abs/2503.06825</link>
      <description>arXiv:2503.06825v1 Announce Type: cross 
Abstract: This paper describes recursive algorithms for state estimation of linear dynamical systems when measurements are noisy with unknown bias and/or outliers. For situations with noisy and biased measurements, algorithms are proposed that minimize $\epsilon$ insensitive loss function. In this approach which is often used in Support Vector Machines, small errors are ignored making the algorithm less sensitive to measurement bias. Apart from $\epsilon$ insensitive quadratic loss function, estimation algorithms are also presented for $\epsilon$ insensitive Huber M loss function which provides good performance in presence of both small noises as well as outliers. The advantage of Huber cost function based estimator in presence of outliers is due to the fact the error penalty function switches from quadratic to linear for errors beyond a certain threshold. For both objective functions, estimation algorithms are extended to cases when there are additional constraints on states and exogenous signals such as known range of some states or exogenous signals or measurement noises. Interestingly, the filtering algorithms are recursive and structurally similar to Kalman filter with the main difference being that the updates based on the new measurement ("innovation term") are based on solution of a quadratic optimization problem with linear constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06825v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Krishan Mohan Nagpal</dc:creator>
    </item>
    <item>
      <title>On the Wasserstein alignment problem</title>
      <link>https://arxiv.org/abs/2503.06838</link>
      <description>arXiv:2503.06838v1 Announce Type: cross 
Abstract: Suppose we are given two metric spaces and a family of continuous transformations from one to the other. Given a probability distribution on each of these two spaces - namely the source and the target measures - the Wasserstein alignment problem seeks the transformation that minimizes the optimal transport cost between its pushforward of the source distribution and the target distribution, ensuring the closest possible alignment in a probabilistic sense. Examples of interest include two distributions on two Euclidean spaces $\mathbb{R}^n$ and $\mathbb{R}^d$, and we want a spatial embedding of the $n$-dimensional source measure in $\mathbb{R}^d$ that is closest in some Wasserstein metric to the target distribution on $\mathbb{R}^d$. Similar data alignment problems also commonly arise in shape analysis and computer vision. In this paper we show that this nonconvex optimal transport projection problem admits a convex Kantorovich-type dual. This allows us to characterize the set of projections and devise a linear programming algorithm. For certain special examples, such as orthogonal transformations on Euclidean spaces of unequal dimensions and the $2$-Wasserstein cost, we characterize the covariance of the optimal projections. Our results also cover the generalization when we penalize each transformation by a function. An example is the inner product Gromov-Wasserstein distance minimization problem which has recently gained popularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06838v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soumik Pal, Bodhisattva Sen, Ting-Kam Leonard Wong</dc:creator>
    </item>
    <item>
      <title>Data-Driven Sequential Sampling for Tail Risk Mitigation</title>
      <link>https://arxiv.org/abs/2503.06913</link>
      <description>arXiv:2503.06913v1 Announce Type: cross 
Abstract: Given a finite collection of stochastic alternatives, we study the problem of sequentially allocating a fixed sampling budget to identify the optimal alternative with a high probability, where the optimal alternative is defined as the one with the smallest value of extreme tail risk. We particularly consider a situation where these alternatives generate heavy-tailed losses whose probability distributions are unknown and may not admit any specific parametric representation. In this setup, we propose data-driven sequential sampling policies that maximize the rate at which the likelihood of falsely selecting suboptimal alternatives decays to zero. We rigorously demonstrate the superiority of the proposed methods over existing approaches, which is further validated via numerical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06913v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dohyun Ahn, Taeho Kim</dc:creator>
    </item>
    <item>
      <title>Are System Optimal Dynamic Flows Implementable by Tolls?</title>
      <link>https://arxiv.org/abs/2503.07387</link>
      <description>arXiv:2503.07387v1 Announce Type: cross 
Abstract: A seminal result of [Fleischer et al. and Karakostas and Kolliopulos, both FOCS 2004] states that system optimal multi-commodity static network flows are always implementable as tolled Wardrop equilibrium flows even if users have heterogeneous value-of-time sensitivities. Their proof uses LP-duality to characterize the general implementability of network flows by tolls. For the much more complex setting of $\textit{dynamic flows}$, [Graf et al., SODA 2025] identified necessary and sufficient conditions for a dynamic $s$-$d$ flow to be implementable as a tolled dynamic equilibrium. They used the machinery of (infinite-dimensional) strong duality to obtain their characterizations. Their work, however, does not answer the question of whether system optimal dynamic network flows are implementable by tolls.
  We consider this question for a general dynamic flow model involving multiple commodities with individual source-destination pairs, fixed inflow rates and heterogeneous valuations of travel time and money spent. We present both a positive and a, perhaps surprising, negative result: For the negative result, we provide a network with multiple source and destination pairs in which under the Vickrey queuing model no system optimal flow is implementable -- even if all users value travel times and spent money the same. Our counter-example even shows that the ratio of the achievable equilibrium travel times by using tolls and of the system optimal travel times can be unbounded. For the single-source, single-destination case, we show that if the traversal time functions are suitably well-behaved (as is the case, for example, in the Vickrey queuing model), any system optimal flow is implementable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07387v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Graf, Tobias Harks, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>PER-DPP Sampling Framework and Its Application in Path Planning</title>
      <link>https://arxiv.org/abs/2503.07411</link>
      <description>arXiv:2503.07411v1 Announce Type: cross 
Abstract: Autonomous navigation in intelligent mobile systems represents a core research focus within artificial intelligence-driven robotics. Contemporary path planning approaches face constraints in dynamic environmental responsiveness and multi-objective task scalability, limiting their capacity to address growing intelligent operation requirements. Decision-centric reinforcement learning frameworks, capitalizing on their unique strengths in adaptive environmental interaction and self-optimization, have gained prominence in advanced control system research. This investigation introduces methodological improvements to address sample homogeneity challenges in reinforcement learning experience replay mechanisms. By incorporating determinant point processes (DPP) for diversity assessment, we develop a dual-criteria sampling framework with adaptive selection protocols. This approach resolves representation bias in conventional prioritized experience replay (PER) systems while preserving algorithmic interoperability, offering improved decision optimization for dynamic operational scenarios. Key contributions comprise: Develop a hybrid sampling paradigm (PER-DPP) combining priority sequencing with diversity maximization.Based on this,create an integrated optimization scheme (PER-DPP-Elastic DQN) merging diversity-aware sampling with adaptive step-size regulation. Comparative simulations in 2D navigation scenarios demonstrate that the elastic step-size component temporarily delays initial convergence speed but synergistically enhances final-stage optimization with PER-DPP integration. The synthesized method generates navigation paths with optimized length efficiency and directional stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07411v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Junzhe Wang</dc:creator>
    </item>
    <item>
      <title>Efficient data-driven flow modeling for accurate passive scalar advection in submesoscale domains</title>
      <link>https://arxiv.org/abs/2503.07452</link>
      <description>arXiv:2503.07452v1 Announce Type: cross 
Abstract: Knowing the sea surface velocity field is essential for various applications, such as search and rescue operations and oil spill monitoring, where understanding the movement of objects or substances is critical. However, obtaining an accurate approximation of these advection processes is challenging, even with modern measuring equipment, such as high-frequency radar or advanced simulations based on oceanic flow models. Therefore this paper presents a data-driven framework to approximate sea surface velocity from spatially distributed observations, thus enabling efficient probability advection modeling across submesoscale domains. The system approximates transient flows by leveraging quasi-steady flow assumptions. To overcome the limitations of point measurements in capturing domain-wide circulation, the method employs a fusion of two simplified 2D flow models to approximate submesoscale dynamics, enabling complete velocity field reconstruction from scattered data. To ensure reliable flow dynamics, the approach iteratively adjusts boundary conditions in numerical simulations to align the simulated flow with observations. Experimental validation in Kvarner Bay using GPS-tracked drifters confirmed the system's ability to replace computationally intensive transient simulations by approximating flow fields based on model simplifications. The results demonstrate its efficiency across domains, making it a practical tool for real-world submesoscale applications requiring swift passive scalar advection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07452v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karlo Jakac, Luka Lan\v{c}a, Ante Sikirica, Stefan Ivi\'c</dc:creator>
    </item>
    <item>
      <title>Global maximum principle for optimal control of stochastic Volterra equations with singular kernels: An infinite dimensional approach</title>
      <link>https://arxiv.org/abs/2503.07514</link>
      <description>arXiv:2503.07514v1 Announce Type: cross 
Abstract: In this paper, we consider optimal control problems of stochastic Volterra equations (SVEs) with singular kernels, where the control domain is not necessarily convex. We establish a global maximum principle by means of the spike variation technique. To do so, we first show a Taylor type expansion of the controlled SVE with respect to the spike variation, where the convergence rates of the remainder terms are characterized by the singularity of the kernels. Next, assuming additional structure conditions for the kernels, we convert the variational SVEs appearing in the expansion to their infinite dimensional lifts. Then, we derive first and second order adjoint equations in form of infinite dimensional backward stochastic evolution equations (BSEEs) on weighted $L^2$ spaces. Moreover, we show the well-posedness of the new class of BSEEs on weighted $L^2$ spaces in a general setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07514v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yushi Hamaguchi</dc:creator>
    </item>
    <item>
      <title>Scaffold with Stochastic Gradients: New Analysis with Linear Speed-Up</title>
      <link>https://arxiv.org/abs/2503.07594</link>
      <description>arXiv:2503.07594v1 Announce Type: cross 
Abstract: This paper proposes a novel analysis for the Scaffold algorithm, a popular method for dealing with data heterogeneity in federated learning. While its convergence in deterministic settings--where local control variates mitigate client drift--is well established, the impact of stochastic gradient updates on its performance is less understood. To address this problem, we first show that its global parameters and control variates define a Markov chain that converges to a stationary distribution in the Wasserstein distance. Leveraging this result, we prove that Scaffold achieves linear speed-up in the number of clients up to higher-order terms in the step size. Nevertheless, our analysis reveals that Scaffold retains a higher-order bias, similar to FedAvg, that does not decrease as the number of clients increases. This highlights opportunities for developing improved stochastic federated learning algorithms</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07594v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Mangold, Alain Durmus, Aymeric Dieuleveut, Eric Moulines</dc:creator>
    </item>
    <item>
      <title>Multi-Iteration Stochastic Optimizers</title>
      <link>https://arxiv.org/abs/2011.01718</link>
      <description>arXiv:2011.01718v4 Announce Type: replace 
Abstract: We here introduce Multi-Iteration Stochastic Optimizers, a novel class of first-order stochastic optimizers where the relative $L^2$ error is estimated and controlled using successive control variates along the path of iterations. By exploiting the correlation between iterates, control variates may reduce the estimator's variance so that an accurate estimation of the mean gradient becomes computationally affordable. We name the estimator of the mean gradient Multi-Iteration stochastiC Estimator (MICE). In principle, MICE can be flexibly coupled with any first-order stochastic optimizer, given its non-intrusive nature. Our generic algorithm adaptively decides which iterates to keep in its index set. We present an error analysis of MICE and a convergence analysis of Multi-Iteration Stochastic Optimizers for different classes of problems, including some non-convex cases. Within the smooth, strongly convex setting, we show that to approximate a minimizer with accuracy $tol$, SGD-MICE requires, on average, $O(tol^{-1})$ stochastic gradient evaluations, while SGD with adaptive batch sizes requires $O(tol^{-1} \log(tol^{-1}))$, correspondingly. Moreover, in a numerical evaluation, SGD-MICE achieved tol with less than 3% the number of gradient evaluations than adaptive batch SGD. The MICE estimator provides a straightforward stopping criterion based on the gradient norm that is validated in consistency tests. To assess the efficiency of MICE, we present several examples in which we use SGD-MICE and Adam-MICE. We include one example based on a stochastic adaptation of the Rosenbrock function and logistic regression training for various datasets. When compared to SGD, SAG, SAGA, SVRG, and SARAH, the Multi-Iteration Stochastic Optimizers reduced, without the need to tune parameters for each example, the gradient sampling cost in all cases tested, also being competitive in runtime in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.01718v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andre Carlon, Luis Espath, Rafael Lopez, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Entropic Risk-Averse Generalized Momentum Methods</title>
      <link>https://arxiv.org/abs/2204.11292</link>
      <description>arXiv:2204.11292v4 Announce Type: replace 
Abstract: In the context of first-order algorithms subject to random gradient noise, we study the trade-offs between the convergence rate (which quantifies how fast the initial conditions are forgotten) and the "risk" of suboptimality, i.e. deviations from the expected suboptimality. We focus on a general class of momentum methods (GMM) which recover popular methods such as gradient descent (GD), accelerated gradient descent (AGD), and heavy-ball (HB) method as special cases depending on the choice of GMM parameters. We use well-known risk measures "entropic risk" and "entropic value at risk" to quantify the risk of suboptimality. For strongly convex smooth minimization, we first obtain new convergence rate results for GMM with a unified theory that is also applicable to both AGD and HB, improving some of the existing results for HB. We then provide explicit bounds on the entropic risk and entropic value at risk of suboptimality at a given iterate which also provides direct bounds on the probability that the suboptimality exceeds a given threshold based on Chernoff's inequality. Our results unveil fundamental trade-offs between the convergence rate and the risk of suboptimality. We then plug the entropic risk and convergence rate estimates we obtained in a computationally tractable optimization framework and propose entropic risk-averse GMM (RA-GMM) and entropic risk-averse AGD (RA-AGD) methods which can select the GMM parameters to systematically trade-off the entropic value at risk with the convergence rate. We show that RA-AGD and RA-GMM lead to improved performance on quadratic optimization and logistic regression problems compared to the standard choice of parameters. To our knowledge, our work is the first to resort to coherent measures to design the parameters of momentum methods in a systematic manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.11292v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bugra Can, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>Get rid of your constraints and reparametrize: A study in NNLS and implicit bias</title>
      <link>https://arxiv.org/abs/2207.08437</link>
      <description>arXiv:2207.08437v3 Announce Type: replace 
Abstract: Over the past years, there has been significant interest in understanding the implicit bias of gradient descent optimization and its connection to the generalization properties of overparametrized neural networks. Several works observed that when training linear diagonal networks on the square loss for regression tasks (which corresponds to overparametrized linear regression) gradient descent converges to special solutions, e.g., non-negative ones. We connect this observation to Riemannian optimization and view overparametrized GD with identical initialization as a Riemannian GD. We use this fact for solving non-negative least squares (NNLS), an important problem behind many techniques, e.g., non-negative matrix factorization. We show that gradient flow on the reparametrized objective converges globally to NNLS solutions, providing convergence rates also for its discretized counterpart. Unlike previous methods, we do not rely on the calculation of exponential maps or geodesics. We further show accelerated convergence using a second-order ODE, lending itself to accelerated descent methods. Finally, we establish the stability against negative perturbations and discuss generalization to other constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.08437v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung-Hsu Chou, Johannes Maly, Claudio Mayrink Verdun, Bernardo Freitas Paulo da Costa, Heudson Mirandola</dc:creator>
    </item>
    <item>
      <title>Efficient and Near-Optimal Online Portfolio Selection</title>
      <link>https://arxiv.org/abs/2209.13932</link>
      <description>arXiv:2209.13932v2 Announce Type: replace 
Abstract: In the problem of online portfolio selection as formulated by Cover (1991), the trader repeatedly distributes her capital over $ d $ assets in each of $ T &gt; 1 $ rounds, with the goal of maximizing the total return. Cover proposed an algorithm, termed Universal Portfolios, that performs nearly as well as the best (in hindsight) static assignment of a portfolio, with an $ O(d\log(T)) $ regret in terms of the logarithmic return. Without imposing any restrictions on the market this guarantee is known to be worst-case optimal, and no other algorithm attaining it has been discovered so far. Unfortunately, Cover's algorithm crucially relies on computing certain $ d $-dimensional integral which must be approximated in any implementation; this results in a prohibitive $ \tilde O(d^4(T+d)^{14}) $ per-round runtime for the fastest known implementation due to Kalai and Vempala (2002). We propose an algorithm for online portfolio selection that admits essentially the same regret guarantee as Universal Portfolios -- up to a constant factor and replacement of $ \log(T) $ with $ \log(T+d) $ -- yet has a drastically reduced runtime of $ \tilde O(d^2(T+d)) $ per round. The selected portfolio minimizes the current logarithmic loss regularized by the log-determinant of its Hessian -- equivalently, the hybrid logarithmic-volumetric barrier of the polytope specified by the asset return vectors. As such, our work reveals surprising connections of online portfolio selection with two classical topics in optimization theory: cutting-plane and interior-point algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13932v2</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R\'emi J\'ez\'equel, Dmitrii M. Ostrovskii, Pierre Gaillard</dc:creator>
    </item>
    <item>
      <title>Entropic mean-field min-max problems via Best Response flow</title>
      <link>https://arxiv.org/abs/2306.03033</link>
      <description>arXiv:2306.03033v4 Announce Type: replace 
Abstract: We investigate the convergence properties of a continuous-time optimization method, the \textit{Mean-Field Best Response} flow, for solving convex-concave min-max games with entropy regularization. We introduce suitable Lyapunov functions to establish exponential convergence to the unique mixed Nash equilibrium. Additionally, we demonstrate the convergence of the fictitious play flow as a by-product of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03033v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00245-025-10246-6</arxiv:DOI>
      <dc:creator>Razvan-Andrei Lascu, Mateusz B. Majka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>Optimal strategies for Wolbachia mosquito replacement technique: influence of the carrying capacity on spatial releases</title>
      <link>https://arxiv.org/abs/2309.04192</link>
      <description>arXiv:2309.04192v2 Announce Type: replace 
Abstract: This work is devoted to the mathematical study of an optimization problem regarding control strategies of mosquito population in a heterogeneous environment. Mosquitoes are well-known vectors of diseases. For some diseases, such as dengue, it has been found that mosquitoes have a reduced vector capacity when carrying the endosymbiotic bacterium Wolbachia. We consider a mathematical model of a replacement technique consisting in rearing and releasing Wolbachia-infected mosquitoes to replace the wild population. Our goal is to optimize the release protocol to maximize replacement effectiveness in a spatially inhomogeneous environment. Using a scalar model with space-dependent carrying capacity, we explore the existence and properties of an optimal release profile maximizing the replacement across the domain. In particular, neglecting mosquito mobility and under some assumptions on the biological parameters, we characterize the optimal releasing strategy for a short time horizon, and we reduce the case of a long time horizon to a one-dimensional optimization problem. Our theoretical results are illustrated with several numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04192v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Almeida, Jes\'us Bellver Arnau, Gwena\"el Peltier, Nicolas Vauchelet</dc:creator>
    </item>
    <item>
      <title>Convergence of the Chambolle-Pock Algorithm in the Absence of Monotonicity</title>
      <link>https://arxiv.org/abs/2312.06540</link>
      <description>arXiv:2312.06540v3 Announce Type: replace 
Abstract: The Chambolle-Pock algorithm (CPA), also known as the primal-dual hybrid gradient method, has gained popularity over the last decade due to its success in solving large-scale convex structured problems. This work extends its convergence analysis for problems with varying degrees of (non)monotonicity, quantified through a so-called oblique weak Minty condition on the associated primal-dual operator. Our results reveal novel stepsize and relaxation parameter ranges which do not only depend on the norm of the linear mapping, but also on its other singular values. In particular, in nonmonotone settings, in addition to the classical stepsize conditions, extra bounds on the stepsizes and relaxation parameters are required. On the other hand, in the strongly monotone setting, the relaxation parameter is allowed to exceed the classical upper bound of two. Moreover, we build upon the recently introduced class of semimonotone operators, providing sufficient convergence conditions for CPA when the individual operators are semimonotone. Since this class of operators encompasses traditional operator classes including (hypo)- and co(hypo)-monotone operators, this analysis recovers and extends existing results for CPA. Tightness of the proposed stepsize ranges is demonstrated through several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06540v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brecht Evens, Puya Latafat, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Online estimation of the inverse of the Hessian for stochastic optimization with application to universal stochastic Newton algorithms</title>
      <link>https://arxiv.org/abs/2401.10923</link>
      <description>arXiv:2401.10923v3 Announce Type: replace 
Abstract: This paper addresses second-order stochastic optimization for estimating the minimizer of a convex function written as an expectation. A direct recursive estimation technique for the inverse Hessian matrix using a Robbins-Monro procedure is introduced. This approach enables to drastically reduces computational complexity. Above all, it allows to develop universal stochastic Newton methods and investigate the asymptotic efficiency of the proposed approach. This work so expands the application scope of secondorder algorithms in stochastic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10923v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Godichon-Baggioni (LPSM), Wei Lu (LMI), Bruno Portier (LMI)</dc:creator>
    </item>
    <item>
      <title>Quadratically Regularized Optimal Transport: Existence and Multiplicity of Potentials</title>
      <link>https://arxiv.org/abs/2404.06847</link>
      <description>arXiv:2404.06847v3 Announce Type: replace 
Abstract: The optimal transport problem with quadratic regularization is useful when sparse couplings are desired. The density of the optimal coupling is described by two functions called potentials; equivalently, potentials can be defined as a solution of the dual problem. We prove the existence of potentials for a general square-integrable cost. Potentials are not necessarily unique, a phenomenon directly related to sparsity of the optimal support. For discrete problems, we describe the family of all potentials based on the connected components of the support, for a graph-theoretic notion of connectedness. On the other hand, we show that continuous problems have unique potentials under standard regularity assumptions, regardless of sparsity. Using potentials, we prove that the optimal support is indeed sparse for small regularization parameter in a continuous setting with quadratic cost, which seems to be the first theoretical guarantee for sparsity in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06847v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcel Nutz</dc:creator>
    </item>
    <item>
      <title>Equitable Routing -- Rethinking the Multiple Traveling Salesman Problem</title>
      <link>https://arxiv.org/abs/2404.08157</link>
      <description>arXiv:2404.08157v4 Announce Type: replace 
Abstract: The Multiple Traveling Salesman Problem (MTSP) generalizes the Traveling Salesman Problem (TSP) by introducing multiple salesmen tasked with visiting a set of targets from a single depot, ensuring each target is visited exactly once while minimizing total tour length. A key variant, the min-max MTSP, seeks to balance workloads by minimizing the longest tour among salesmen. However, this problem is challenging to solve optimally due to weak lower bounds from linear relaxations. This paper introduces two novel parametric variants of the MTSP, termed "fair-MTSP". One variant is modeled as a Mixed-Integer Second Order Cone Program (MISOCP), and the other as a Mixed Integer Linear Program (MILP). Both variants aim to distribute tour lengths equitably among salesmen while minimizing overall costs. We develop algorithms to achieve global optimality for these fair-MTSP variants. We present computational results based on benchmark and real-world scenarios, particularly in electric vehicle fleet management and routing. Furthermore, we also show that the algorithmic approaches presented for the fair-MTSP variants can be directly used to obtain the Pareto-front of a bi-objective optimization problem where one objective focuses on minimizing the total tour length and the other focuses on balancing the tour lengths of the individual tours. The findings support fair-MTSP as a promising alternative to the min-max MTSP, emphasizing fairness in workload distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08157v4</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhay Singh Bhadoriya, Deepjyoti Deka, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Column generation for multistage stochastic mixed-integer nonlinear programs with discrete state variables</title>
      <link>https://arxiv.org/abs/2406.05052</link>
      <description>arXiv:2406.05052v2 Announce Type: replace 
Abstract: Stochastic programming provides a natural framework for modeling sequential optimization problems under uncertainty; however, the efficient solution of large-scale multistage stochastic programs remains a challenge, especially in the presence of discrete decisions and nonlinearities. In this work, we consider multistage stochastic mixed-integer nonlinear programs (MINLPs) with discrete state variables, which exhibit a decomposable structure that allows its solution using a column generation approach. Following a Dantzig-Wolfe reformulation, we apply column generation such that each pricing subproblem is an MINLP of much smaller size, making it more amenable to global MINLP solvers. We further propose a method for generating additional columns that satisfy the nonanticipativity constraints, leading to significantly improved convergence and optimal or near-optimal solutions for many large-scale instances in a reasonable computation time. The effectiveness of the tailored column generation algorithm is demonstrated via computational case studies on a multistage blending problem and a problem involving the routing of mobile generators in a power distribution network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05052v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tushar Rathi, Benjamin P. Riley, Angela Flores-Quiroz, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Bregman-divergence-based Arimoto-Blahut algorithm</title>
      <link>https://arxiv.org/abs/2408.05454</link>
      <description>arXiv:2408.05454v2 Announce Type: replace 
Abstract: We generalize the generalized Arimoto-Blahut algorithm to a general function defined over Bregman-divergence system. In existing methods, when linear constraints are imposed, each iteration needs to solve a convex minimization. Exploiting our obtained algorithm, we propose a minimization-free-iteration algorithm. This algorithm can be applied to classical and quantum rate-distortion theory. We numerically apply our method to the derivation of the optimal conditional distribution in the rate-distortion theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05454v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahito Hayashi</dc:creator>
    </item>
    <item>
      <title>Fitted Q-Iteration via Max-Plus-Linear Approximation</title>
      <link>https://arxiv.org/abs/2409.08422</link>
      <description>arXiv:2409.08422v3 Announce Type: replace 
Abstract: In this study, we consider the application of max-plus-linear approximators for Q-function in offline reinforcement learning of discounted Markov decision processes. In particular, we incorporate these approximators to propose novel fitted Q-iteration (FQI) algorithms with provable convergence. Exploiting the compatibility of the Bellman operator with max-plus operations, we show that the max-plus-linear regression within each iteration of the proposed FQI algorithm reduces to simple max-plus matrix-vector multiplications. We also consider the variational implementation of the proposed algorithm which leads to a per-iteration complexity that is independent of the number of samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08422v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Y. Liu, M. A. S. Kolarijani</dc:creator>
    </item>
    <item>
      <title>Exponential Convergence of Augmented Primal-dual Gradient Algorithms for Partially Strongly Convex Functions</title>
      <link>https://arxiv.org/abs/2410.02192</link>
      <description>arXiv:2410.02192v2 Announce Type: replace 
Abstract: We show that the augmented primal-dual gradient algorithms can achieve global exponential convergence with partially strongly convex functions. In particular, the objective function only needs to be strongly convex in the subspace satisfying the equality constraint and can be generally convex elsewhere, provided the global Lipschitz condition for the gradient is satisfied. This condition implies that states outside the equality subspace will converge towards it exponentially fast. The analysis is then applied to distributed optimization, where the partially strong convexity can be relaxed to the restricted secant inequality condition, which is not necessarily convex. This work unifies global exponential convergence results for some existing centralized and distributed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02192v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Optimizing $(L_0, L_1)$-Smooth Functions by Gradient Methods</title>
      <link>https://arxiv.org/abs/2410.10800</link>
      <description>arXiv:2410.10800v3 Announce Type: replace 
Abstract: We study gradient methods for optimizing $(L_0, L_1)$-smooth functions, a class that generalizes Lipschitz-smooth functions and has gained attention for its relevance in machine learning. We provide new insights into the structure of this function class and develop a principled framework for analyzing optimization methods in this setting. While our convergence rate estimates recover existing results for minimizing the gradient norm in nonconvex problems, our approach significantly improves the best-known complexity bounds for convex objectives. Moreover, we show that the gradient method with Polyak stepsizes and the normalized gradient method achieve nearly the same complexity guarantees as methods that rely on explicit knowledge of~$(L_0, L_1)$. Finally, we demonstrate that a carefully designed accelerated gradient method can be applied to $(L_0, L_1)$-smooth functions, further improving all previous results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10800v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Vankov, Anton Rodomanov, Angelia Nedich, Lalitha Sankar, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Fully First-Order Methods for Decentralized Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2410.19319</link>
      <description>arXiv:2410.19319v2 Announce Type: replace 
Abstract: This paper focuses on decentralized stochastic bilevel optimization (DSBO) where agents only communicate with their neighbors. We propose Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a novel algorithm that only requires first-order oracles that are much cheaper than second-order oracles widely adopted in existing works. We further provide a finite-time convergence analysis showing that for $n$ agents collaboratively solving the DSBO problem, the sample complexity of finding an $\epsilon$-stationary point in our algorithm is $\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known results of the single-agent counterpart with linear speedup. The numerical experiments demonstrate both the communication and training efficiency of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19319v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Xuxing Chen, Shiqian Ma, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Design Optimization with Limited Data for Char Combustion</title>
      <link>https://arxiv.org/abs/2411.01429</link>
      <description>arXiv:2411.01429v2 Announce Type: replace 
Abstract: This work presents a robust design optimization approach for a char combustion process in a limited-data setting, where simulations of the fluid-solid coupled system are computationally expensive. We integrate a polynomial dimensional decomposition (PDD) surrogate model into the design optimization and induce computational efficiency in three key areas. First, we transform the input random variables to have fixed probability measures, which eliminates the need to recalculate the PDD's basis functions associated with these probability quantities. Second, using the limited data available from a physics-based high-fidelity solver, we estimate the PDD coefficients via sparsity-promoting diffeomorphic modulation under observable response preserving homotopy regression. Third, we propose a single-pass surrogate model training that avoids the need to generate new training data and update the PDD coefficients during the derivative-free optimization. The results provide insights for optimizing process parameters to ensure consistently high energy production from char combustion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01429v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yulin Guo, Dongjin Lee, Boris Kramer</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient Descent Revisited</title>
      <link>https://arxiv.org/abs/2412.06070</link>
      <description>arXiv:2412.06070v4 Announce Type: replace 
Abstract: Stochastic gradient descent (SGD) has been a go-to algorithm for nonconvex stochastic optimization problems arising in machine learning. Its theory however often requires a strong framework to guarantee convergence properties. We hereby present a full scope convergence study of biased nonconvex SGD, including weak convergence, function-value convergence and global convergence, and also provide subsequent convergence rates and complexities, all under relatively mild conditions in comparison with literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06070v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azar Louzi</dc:creator>
    </item>
    <item>
      <title>Regularized neural network for general variational inequalities involving monotone couples of operators in Hilbert spaces</title>
      <link>https://arxiv.org/abs/2412.19054</link>
      <description>arXiv:2412.19054v2 Announce Type: replace 
Abstract: In this paper, based on the Tikhonov regularization technique, we study a monotone general variational inequality (GVI) by considering an associated strongly monotone GVI, depending on a regularization parameter $\alpha,$ such that the latter admits a unique solution $x_\alpha$ which tends to some solution of the initial GVI, as $\alpha \to 0.$ However, instead of solving the regularized GVI for each $\alpha$, which may be very expensive, we consider a neural network (also known as a dynamical system) associated with the regularized GVI and establish the existence and the uniqueness of the strong global solution to the corresponding Cauchy problem. An explicit discretization of this neural network leads to strongly convergent iterative regularization algorithms for monotone general variational inequality. Numerical tests are performed to show the effectiveness of the proposed methods.
  This work extends our recent results in [Anh, Hai, Optim. Eng. 25 (2024) 2295-2313] to more general setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19054v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Ky Anh, Trinh Ngoc Hai, Nguyen Van Manh</dc:creator>
    </item>
    <item>
      <title>Accelerated Extragradient-Type Methods -- Part 2: Generalization and Sublinear Convergence Rates under Co-Hypomonotonicity</title>
      <link>https://arxiv.org/abs/2501.04585</link>
      <description>arXiv:2501.04585v2 Announce Type: replace 
Abstract: Following the first part of our project, this paper comprehensively studies two types of extragradient-based methods: anchored extragradient and Nesterov's accelerated extragradient for solving [non]linear inclusions (and, in particular, equations), primarily under the Lipschitz continuity and the co-hypomonotonicity assumptions. We unify and generalize a class of anchored extragradient methods for monotone inclusions to a wider range of schemes encompassing existing algorithms as special cases. We establish $\mathcal{O}(1/k)$ last-iterate convergence rates on the residual norm of the underlying mapping for this general framework and then specialize it to obtain convergence guarantees for specific instances, where $k$ denotes the iteration counter. We extend our approach to a class of anchored Tseng's forward-backward-forward splitting methods to obtain a broader class of algorithms for solving co-hypomonotone inclusions. Again, we analyze $\mathcal{O}(1/k)$ last-iterate convergence rates for this general scheme and specialize it to obtain convergence results for existing and new variants. We generalize and unify Nesterov's accelerated extra-gradient method to a new class of algorithms that covers existing schemes as special instances while generating new variants. For these schemes, we can prove $\mathcal{O}(1/k)$ last-iterate convergence rates for the residual norm under co-hypomonotonicity, covering a class of nonmonotone problems. We propose another novel class of Nesterov's accelerated extragradient methods to solve inclusions. Interestingly, these algorithms achieve both $\mathcal{O}(1/k)$ and $o(1/k)$ last-iterate convergence rates, and also the convergence of iterate sequences under co-hypomonotonicity and Lipschitz continuity. Finally, we provide a set of numerical experiments encompassing different scenarios to validate our algorithms and theoretical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04585v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quoc Tran-Dinh, Nghia Nguyen-Trung</dc:creator>
    </item>
    <item>
      <title>Global Independence of Irrelevant Alternatives, State-Salient Decision Rules and the Strict Condorcet Choice Function</title>
      <link>https://arxiv.org/abs/2501.10986</link>
      <description>arXiv:2501.10986v2 Announce Type: replace 
Abstract: We present a simple proof of a well-known axiomatic characterization of state-salient decision rules, using Weak Dominance Criterion and Global Independence of Irrelevant Alternatives. Subsequently we provide a simple axiomatic characterization of the Strict-Condorcet choice function on the domain of all preference profiles that have a strict-Condorcet winner, assuming that if the first two ranks are occupied by the same two alternatives in all states of nature, then the chosen alternative will be the one from these two that is preferred to the other with probability greater than half-provided such an alternative exists. We also show that this result is not valid if we extend the domain to the set of all preference profiles that have a unique weak-Condorcet winner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10986v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>A New Lyapunov-like Stability Inequality with an \textit{Asymmetric} Matrix and Application to Suboptimal LQ Control Design (to be corrected)</title>
      <link>https://arxiv.org/abs/2502.11556</link>
      <description>arXiv:2502.11556v2 Announce Type: replace 
Abstract: The Lyapunov inequality is an indispensable tool for stability analysis in the linear control theory. This work proposes a new variant of this inequality where-in the constituent matrix is allowed to be asymmetric. After developing the stability conditions based on the proposed inequality for a class of linear systems, we utilize these conditions to derive new results for the suboptimal linear quadratic control problem where we characterize the cost of the stabilizing controllers. We also demonstrate, by a numerical example, that the proposed results can be easily molded for the structured suboptimal consensus protocol design for multi-agent system where we also see that the asymmetry condition of the design matrix turns up inherently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11556v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avinash Kumar</dc:creator>
    </item>
    <item>
      <title>A Deterministic and Linear Model of Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2502.17012</link>
      <description>arXiv:2502.17012v2 Announce Type: replace 
Abstract: We introduce a model of infinite horizon linear dynamic optimization and obtain results concerning existence of solution and satisfaction of the Euler condition and transversality condition being unconditionally sufficient for optimality of a trajectory. We show that the optimal value function is concave and continuous and the optimal trajectory satisfies the functional equation of dynamic programming. Linearity bites when it comes to the definition of optimal decision rules which can no longer be guaranteed to be single-valued. We show that the optimal decision rule is an upper semi-continuous correspondence. For linear cake-eating problems, we obtain monotonicity results for the optimal value function and a conditional monotonicity result for optimal decision rules. We also introduce the concept of a two-phase linear cake eating problem and obtain a necessary condition that must be satisfied by all solutions of such problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17012v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Optimal Control of General Nonlocal Epidemic Models with Age and Space Structure</title>
      <link>https://arxiv.org/abs/2503.01466</link>
      <description>arXiv:2503.01466v2 Announce Type: replace 
Abstract: We analyze a class of general nonlinear epidemic models with age and space structure, including a nonlocal infection term depending on age and space. After establishing the well-posedness of the state partial differential equation, we introduce a control parameter interpreted as a vaccination rate. Under certain conditions, we show that an optimal control exists and how it can be characterized by first-order optimality conditions. Finally, we present numerical examples of the optimal control problems governed by these models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01466v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Behzad Azmi, Nicolas Schlosser</dc:creator>
    </item>
    <item>
      <title>Identification of Feasible Regions Using R-Functions</title>
      <link>https://arxiv.org/abs/2503.05510</link>
      <description>arXiv:2503.05510v2 Announce Type: replace 
Abstract: The primary objective of flexibility analysis is to identify and define the feasibility region, which represents the range of operational conditions (e.g., variations in process parameters) that ensure safe, reliable, and feasible process performance. This work introduces a novel flexibility analysis method that requires only that model constraints (e.g., defining product Critical Quality Attributes or process Key Performance Indicators) be explicitly provided or approximated by a closed-form function, such as a multivariate polynomial model. The method is based on V.L. Rvachev's R-functions, enabling an explicit analytical representation of the feasibility region without relying on complex optimization-based approaches. R-functions offer a framework for describing intricate geometric shapes and performing operations on them using implicit functions and inequality constraints. The theory of R-functions facilitates the identification of feasibility regions through algebraic manipulation, making it a more practical alternative to traditional optimization-based methods. The effectiveness of the proposed approach is demonstrated using a suite of well-known test cases from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05510v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Segei Kucherenko, Nilay Shah, Oleksiy Klymenko</dc:creator>
    </item>
    <item>
      <title>Localized and degenerate controls for the incompressible Navier-Stokes system</title>
      <link>https://arxiv.org/abs/2212.01221</link>
      <description>arXiv:2212.01221v2 Announce Type: replace-cross 
Abstract: We consider the global approximate controllability of the two-dimensional incompressible Navier-Stokes system driven by a physically localized and degenerate force. In other words, the fluid is regulated via four scalar controls that depend only on time and appear as coefficients in an effectively constructed driving force supported in a given subdomain. Our idea consists of squeezing low mode controls into a small region, essentially by tracking their actions along the characteristic curves of a linearized vorticity equation. In this way, through explicit constructions and by connecting Coron's return method with recent concepts from geometric control, the original problem for the nonlinear Navier-Stokes system is reduced to one for a linear transport equation steered by a global force. This article can be viewed as an attempt to tackle a well-known open problem due to Agrachev.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01221v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/cpa.22246</arxiv:DOI>
      <dc:creator>Vahagn Nersesyan, Manuel Rissel</dc:creator>
    </item>
    <item>
      <title>Boundary Effects on the Controllability of Coupled KdV Systems</title>
      <link>https://arxiv.org/abs/2302.13443</link>
      <description>arXiv:2302.13443v2 Announce Type: replace-cross 
Abstract: We study the exact boundary controllability of a nonlinear coupled system of two Korteweg-de Vries equations on a bounded interval. The model describes the interactions of two weakly nonlinear gravity waves in a stratified fluid. Due to the nature of the system, six boundary conditions are required. However, to study the controllability property, we consider a different combination of the control inputs, with a maximum of four. Firstly, the results are obtained for the linearized system through a classical duality approach and some hidden regularity properties of the boundary terms. This approach reduces the controllability problem to the study of a spectral problem, which is solved by using the Paley-Wiener method introduced by Rosier. Then, the issue is to establish when a certain quotient of entire functions still turns out to be an entire function. It can be viewed as a problem of factoring an entire function that, depending on the control configuration, leads to the study of a transcendental equation. Finally, by using the contraction mapping theorem, we derive the local controllability for the full system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13443v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>F. A. Gallego, A. F. Pazoto, I. Rivas</dc:creator>
    </item>
    <item>
      <title>Learning time-scales in two-layers neural networks</title>
      <link>https://arxiv.org/abs/2303.00055</link>
      <description>arXiv:2303.00055v4 Announce Type: replace-cross 
Abstract: Gradient-based learning in multi-layer neural networks displays a number of striking features. In particular, the decrease rate of empirical risk is non-monotone even after averaging over large batches. Long plateaus in which one observes barely any progress alternate with intervals of rapid decrease. These successive phases of learning often take place on very different time scales. Finally, models learnt in an early phase are typically `simpler' or `easier to learn' although in a way that is difficult to formalize.
  Although theoretical explanations of these phenomena have been put forward, each of them captures at best certain specific regimes. In this paper, we study the gradient flow dynamics of a wide two-layer neural network in high-dimension, when data are distributed according to a single-index model (i.e., the target function depends on a one-dimensional projection of the covariates). Based on a mixture of new rigorous results, non-rigorous mathematical derivations, and numerical simulations, we propose a scenario for the learning dynamics in this setting. In particular, the proposed evolution exhibits separation of timescales and intermittency. These behaviors arise naturally because the population gradient flow can be recast as a singularly perturbed dynamical system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00055v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10208-024-09664-9</arxiv:DOI>
      <dc:creator>Rapha\"el Berthier, Andrea Montanari, Kangjie Zhou</dc:creator>
    </item>
    <item>
      <title>Quantum Langevin Dynamics for Optimization</title>
      <link>https://arxiv.org/abs/2311.15587</link>
      <description>arXiv:2311.15587v3 Announce Type: replace-cross 
Abstract: We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve optimization problems, particularly those non-convex objective functions that present substantial obstacles for traditional gradient descent algorithms. Specifically, we examine the dynamics of a system coupled with an infinite heat bath. This interaction induces both random quantum noise and a deterministic damping effect to the system, which nudge the system towards a steady state that hovers near the global minimum of objective functions. We theoretically prove the convergence of QLD in convex landscapes, demonstrating that the average energy of the system can approach zero in the low temperature limit with an exponential decay rate correlated with the evolution time. Numerically, we first show the energy dissipation capability of QLD by retracing its origins to spontaneous emission. Furthermore, we conduct detailed discussion of the impact of each parameter. Finally, based on the observations when comparing QLD with classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent QLD by making temperature and $\hbar$ time-dependent parameters, which can be theoretically proven to converge better than the time-independent case and also outperforms a series of state-of-the-art quantum and classical optimization algorithms in many non-convex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15587v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00220-025-05234-4</arxiv:DOI>
      <arxiv:journal_reference>Communications in Mathematical Physics 406 (2025), 52</arxiv:journal_reference>
      <dc:creator>Zherui Chen, Yuchen Lu, Hao Wang, Yizhou Liu, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Variational Entropy Search for Adjusting Expected Improvement</title>
      <link>https://arxiv.org/abs/2402.11345</link>
      <description>arXiv:2402.11345v2 Announce Type: replace-cross 
Abstract: Bayesian optimization is a widely used technique for optimizing black-box functions, with Expected Improvement (EI) being the most commonly utilized acquisition function in this domain. While EI is often viewed as distinct from other information-theoretic acquisition functions, such as entropy search (ES) and max-value entropy search (MES), our work reveals that EI can be considered a special case of MES when approached through variational inference (VI). In this context, we have developed the Variational Entropy Search (VES) methodology and the VES-Gamma algorithm, which adapts EI by incorporating principles from information-theoretic concepts. The efficacy of VES-Gamma is demonstrated across a variety of test functions and read datasets, highlighting its theoretical and practical utilities in Bayesian optimization scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11345v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nuojin Cheng, Stephen Becker</dc:creator>
    </item>
    <item>
      <title>The Implicit Bias of Heterogeneity towards Invariance: A Study of Multi-Environment Matrix Sensing</title>
      <link>https://arxiv.org/abs/2403.01420</link>
      <description>arXiv:2403.01420v4 Announce Type: replace-cross 
Abstract: Models are expected to engage in invariance learning, which involves distinguishing the core relations that remain consistent across varying environments to ensure the predictions are safe, robust and fair. While existing works consider specific algorithms to realize invariance learning, we show that model has the potential to learn invariance through standard training procedures. In other words, this paper studies the implicit bias of Stochastic Gradient Descent (SGD) over heterogeneous data and shows that the implicit bias drives the model learning towards an invariant solution. We call the phenomenon the implicit invariance learning. Specifically, we theoretically investigate the multi-environment low-rank matrix sensing problem where in each environment, the signal comprises (i) a lower-rank invariant part shared across all environments; and (ii) a significantly varying environment-dependent spurious component. The key insight is, through simply employing the large step size large-batch SGD sequentially in each environment without any explicit regularization, the oscillation caused by heterogeneity can provably prevent model learning spurious signals. The model reaches the invariant solution after certain iterations. In contrast, model learned using pooled SGD over all data would simultaneously learn both the invariant and spurious signals. Overall, we unveil another implicit bias that is a result of the symbiosis between the heterogeneity of data and modern algorithms, which is, to the best of our knowledge, first in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01420v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Xu, Yihong Gu, Cong Fang</dc:creator>
    </item>
    <item>
      <title>Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance</title>
      <link>https://arxiv.org/abs/2404.01436</link>
      <description>arXiv:2404.01436v3 Announce Type: replace-cross 
Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on the first-order term in the descent lemma, which is also a function of the gradient norm. We show that Adam with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. Our complexity results for both RMSProp and Adam match with the complexity lower bound established in \cite{arjevani2023lower}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01436v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Yi Zhou, Shaofeng Zou</dc:creator>
    </item>
    <item>
      <title>MGDA Converges under Generalized Smoothness, Provably</title>
      <link>https://arxiv.org/abs/2405.19440</link>
      <description>arXiv:2405.19440v5 Announce Type: replace-cross 
Abstract: Multi-objective optimization (MOO) is receiving more attention in various fields such as multi-task learning. Recent works provide some effective algorithms with theoretical analysis but they are limited by the standard $L$-smooth or bounded-gradient assumptions, which typically do not hold for neural networks, such as Long short-term memory (LSTM) models and Transformers. In this paper, we study a more general and realistic class of generalized $\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function of gradient norm. We revisit and analyze the fundamental multiple gradient descent algorithm (MGDA) and its stochastic version with double sampling for solving the generalized $\ell$-smooth MOO problems, which approximate the conflict-avoidant (CA) direction that maximizes the minimum improvement among objectives. We provide a comprehensive convergence analysis of these algorithms and show that they converge to an $\epsilon$-accurate Pareto stationary point with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between the updating direction and the CA direction) over all iterations, where totally $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are needed for deterministic and stochastic settings, respectively. We prove that they can also guarantee a tighter $\epsilon$-level CA distance in each iteration using more samples. Moreover, we analyze an efficient variant of MGDA named MGDA-FA using only $\mathcal{O}(1)$ time and space, while achieving the same performance guarantee as MGDA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19440v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Peiyao Xiao, Shaofeng Zou, Kaiyi Ji</dc:creator>
    </item>
    <item>
      <title>Robust Clustering on High-Dimensional Data with Stochastic Quantization</title>
      <link>https://arxiv.org/abs/2409.02066</link>
      <description>arXiv:2409.02066v5 Announce Type: replace-cross 
Abstract: This paper addresses the limitations of conventional vector quantization algorithms, particularly K-Means and its variant K-Means++, and investigates the Stochastic Quantization (SQ) algorithm as a scalable alternative for high-dimensional unsupervised and semi-supervised learning tasks. Traditional clustering algorithms often suffer from inefficient memory utilization during computation, necessitating the loading of all data samples into memory, which becomes impractical for large-scale datasets. While variants such as Mini-Batch K-Means partially mitigate this issue by reducing memory usage, they lack robust theoretical convergence guarantees due to the non-convex nature of clustering problems. In contrast, the Stochastic Quantization algorithm provides strong theoretical convergence guarantees, making it a robust alternative for clustering tasks. We demonstrate the computational efficiency and rapid convergence of the algorithm on an image classification problem with partially labeled data, comparing model accuracy across various ratios of labeled to unlabeled data. To address the challenge of high dimensionality, we employ a Triplet Network to encode images into low-dimensional representations in a latent space, which serve as a basis for comparing the efficiency of both the Stochastic Quantization algorithm and traditional quantization algorithms. Furthermore, we enhance the algorithm's convergence speed by introducing modifications with an adaptive learning rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02066v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.34229/1028-0979-2025-1-3</arxiv:DOI>
      <arxiv:journal_reference>International Scientific Technical Journal "Problems of Control and Informatics" 70 (2025) 32-48</arxiv:journal_reference>
      <dc:creator>Anton Kozyriev, Vladimir Norkin</dc:creator>
    </item>
    <item>
      <title>SGD with memory: fundamental properties and stochastic acceleration</title>
      <link>https://arxiv.org/abs/2410.04228</link>
      <description>arXiv:2410.04228v2 Announce Type: replace-cross 
Abstract: An important open problem is the theoretically feasible acceleration of mini-batch SGD-type algorithms on quadratic problems with power-law spectrum. In the non-stochastic setting, the optimal exponent $\xi$ in the loss convergence $L_t\sim C_Lt^{-\xi}$ is double that in plain GD and is achievable using Heavy Ball (HB) with a suitable schedule; this no longer works in the presence of mini-batch noise. We address this challenge by considering first-order methods with an arbitrary fixed number $M$ of auxiliary velocity vectors (*memory-$M$ algorithms*). We first prove an equivalence between two forms of such algorithms and describe them in terms of suitable characteristic polynomials. Then we develop a general expansion of the loss in terms of signal and noise propagators. Using it, we show that losses of stationary stable memory-$M$ algorithms always retain the exponent $\xi$ of plain GD, but can have different constants $C_L$ depending on their effective learning rate that generalizes that of HB. We prove that in memory-1 algorithms we can make $C_L$ arbitrarily small while maintaining stability. As a consequence, we propose a memory-1 algorithm with a time-dependent schedule that we show heuristically and experimentally to improve the exponent $\xi$ of plain SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04228v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Yarotsky, Maksim Velikanov</dc:creator>
    </item>
    <item>
      <title>Optimal Transport for Probabilistic Circuits</title>
      <link>https://arxiv.org/abs/2410.13061</link>
      <description>arXiv:2410.13061v2 Announce Type: replace-cross 
Abstract: We introduce a novel optimal transport framework for probabilistic circuits (PCs). While it has been shown recently that divergences between distributions represented as certain classes of PCs can be computed tractably, to the best of our knowledge, there is no existing approach to compute the Wasserstein distance between probability distributions given by PCs. We propose a Wasserstein-type distance that restricts the coupling measure of the associated optimal transport problem to be a probabilistic circuit. We then develop an algorithm for computing this distance by solving a series of small linear programs and derive the circuit conditions under which this is tractable. Furthermore, we show that we can easily retrieve the optimal transport plan between the PCs from the solutions to these linear programs. Lastly, we study the empirical Wasserstein distance between a PC and a dataset, and show that we can estimate the PC parameters to minimize this distance through an efficient iterative algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13061v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian Ciotinga, YooJung Choi</dc:creator>
    </item>
    <item>
      <title>Optimizing Posterior Samples for Bayesian Optimization via Rootfinding</title>
      <link>https://arxiv.org/abs/2410.22322</link>
      <description>arXiv:2410.22322v3 Announce Type: replace-cross 
Abstract: Bayesian optimization devolves the global optimization of a costly objective function to the global optimization of a sequence of acquisition functions. This inner-loop optimization can be catastrophically difficult if it involves posterior sample paths, especially in higher dimensions. We introduce an efficient global optimization strategy for posterior samples based on global rootfinding. It provides gradient-based optimizers with two sets of judiciously selected starting points, designed to combine exploration and exploitation. The number of starting points can be kept small without sacrificing optimization quality. Remarkably, even with just one point from each set, the global optimum is discovered most of the time. The algorithm scales practically linearly to high dimensions, breaking the curse of dimensionality. For Gaussian process Thompson sampling (GP-TS), we demonstrate remarkable improvement in both inner- and outer-loop optimization, surprisingly outperforming alternatives like EI and GP-UCB in most cases. Our approach also improves the performance of other posterior sample-based acquisition functions, such as variants of entropy search. Furthermore, we propose a sample-average formulation of GP-TS, which has a parameter to explicitly control exploitation and can be computed at the cost of one posterior sample. Our implementation is available at https://github.com/UQUH/TSRoots .</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22322v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taiwo A. Adebiyi, Bach Do, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency</title>
      <link>https://arxiv.org/abs/2411.03875</link>
      <description>arXiv:2411.03875v2 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03875v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Str\"asser, Julian Berberich, Frank Allg\"ower</dc:creator>
    </item>
  </channel>
</rss>
