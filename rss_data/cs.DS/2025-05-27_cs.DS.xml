<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 May 2025 01:54:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Performance report of heuristic algorithm that cracked the largest Gset Ising problems (G81 cut=14060)</title>
      <link>https://arxiv.org/abs/2505.18508</link>
      <description>arXiv:2505.18508v1 Announce Type: new 
Abstract: For the past 25 years, the Gset benchmark problems have challenged all manner of Ising and Max-Cut solvers. The largest of these problems have remained unsolved by any heuristic algorithm. In this report we provide data showing dramatically better speed and accuracy on these large sparse problems. Our newly discovered heuristic algorithm called Cosm reaches high (99.9% of best) solution quality orders of magnitude faster than the previous best heuristic solver results. Additionally, when afforded enough steps Cosm attains higher cuts than ever previously reported, specifically on instances G72 (cut=7008), G77 (cut=9940), and the 20,000-variable G81 (cut=14060). This report includes solution bitstrings so that the cuts can be independently validated. Remarkably, the new best solutions appear to be optimal. We believe the results are an early hint of disruptive opportunities for unconventional, hardware-centric approaches to algorithm discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18508v1</guid>
      <category>cs.DS</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.ET</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenneth M. Zick</dc:creator>
    </item>
    <item>
      <title>Notes on the Linear Algebraic View of Regularity Lemmas</title>
      <link>https://arxiv.org/abs/2505.18740</link>
      <description>arXiv:2505.18740v1 Announce Type: new 
Abstract: When regularity lemmas were first developed in the 1970s, they were described as results that promise a partition of any graph into a ``small'' number of parts, such that the graph looks ``similar'' to a random graph on its edge subsets going between parts. Regularity lemmas have been repeatedly refined and reinterpreted in the years since, and the modern perspective is that they can instead be seen as purely linear-algebraic results about sketching a large, complicated matrix with a smaller, simpler one. These matrix sketches then have a nice interpretation about partitions when applied to the adjacency matrix of a graph.
  In these notes we will develop regularity lemmas from scratch, under the linear-algebraic perspective, and then use the linear-algebraic versions to derive the familiar graph versions. We do not assume any prior knowledge of regularity lemmas, and we recap the relevant linear-algebraic definitions as we go, but some comfort with linear algebra will definitely be helpful to read these notes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18740v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Greg Bodwin, Tuong Le</dc:creator>
    </item>
    <item>
      <title>DNF Learning via Locally Mixing Random Walks</title>
      <link>https://arxiv.org/abs/2505.18839</link>
      <description>arXiv:2505.18839v1 Announce Type: new 
Abstract: We give two results on PAC learning DNF formulas using membership queries in the challenging "distribution-free" learning framework, where learning algorithms must succeed for an arbitrary and unknown distribution over $\{0,1\}^n$.
  (1) We first give a quasi-polynomial time "list-decoding" algorithm for learning a single term of an unknown DNF formula. More precisely, for any target $s$-term DNF formula $f = T_1 \vee \cdots \vee T_s$ over $\{0,1\}^n$ and any unknown distribution $D$ over $\{0,1\}^n$, our algorithm, which uses membership queries and random examples from $D$, runs in $\textsf{quasipoly}(n,s)$ time and outputs a list $L$ of candidate terms such that with high probability some term $T_i$ of $f$ belongs to $L$.
  (2) We then use result (1) to give a $\textsf{quasipoly}(n,s)$-time algorithm, in the distribution-free PAC learning model with membership queries, for learning the class of size-$s$ DNFs in which all terms have the same size. Our algorithm learns using a DNF hypothesis.
  The key tool used to establish result (1) is a new result on "locally mixing random walks," which, roughly speaking, shows that a random walk on a graph that is covered by a small number of expanders has a non-negligible probability of mixing quickly in a subset of these expanders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18839v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josh Alman, Shivam Nadimpalli, Shyamal Patel, Rocco A. Servedio</dc:creator>
    </item>
    <item>
      <title>Efficient Online Random Sampling via Randomness Recycling</title>
      <link>https://arxiv.org/abs/2505.18879</link>
      <description>arXiv:2505.18879v1 Announce Type: new 
Abstract: ``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a randomized algorithm to reduce its entropy requirements. This article presents a family of efficient randomness recycling algorithms for sampling a sequence $X_1, X_2, X_3, \dots$ of discrete random variables whose joint distribution follows an arbitrary stochastic process. We develop randomness recycling strategies to reduce the entropy cost of a variety of prominent sampling algorithms, which include uniform sampling, inverse transform sampling, lookup table sampling, alias sampling, and discrete distribution generating (DDG) tree sampling. Our method achieves an expected amortized entropy cost of $H(X_1,\dots,X_k)/k + \varepsilon$ input random bits per output sample using $O(\log(1/\varepsilon))$ space, which is arbitrarily close to the optimal Shannon entropy rate. The combination of space, time, and entropy properties of our method improve upon the Han and Hoshi interval algorithm and Knuth and Yao entropy-optimal algorithm for sampling a discrete random sequence. An empirical evaluation of the algorithm shows that it achieves state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator. Accompanying the manuscript is a performant random sampling library in the C programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18879v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas L. Draper, Feras A. Saad</dc:creator>
    </item>
    <item>
      <title>Fair-Count-Min: Frequency Estimation under Equal Group-wise Approximation Factor</title>
      <link>https://arxiv.org/abs/2505.18919</link>
      <description>arXiv:2505.18919v1 Announce Type: new 
Abstract: Frequency estimation in streaming data often relies on sketches like Count-Min (CM) to provide approximate answers with sublinear space. However, CM sketches introduce additive errors that disproportionately impact low-frequency elements, creating fairness concerns across different groups of elements. We introduce Fair-Count-Min, a frequency estimation sketch that guarantees equal expected approximation factors across element groups, thus addressing the unfairness issue. We propose a column partitioning approach with group-aware semi-uniform hashing to eliminate collisions between elements from different groups. We provide theoretical guarantees for fairness, analyze the price of fairness, and validate our theoretical findings through extensive experiments on real-world and synthetic datasets. Our experimental results show that Fair-Count-Min achieves fairness with minimal additional error and maintains competitive efficiency compared to standard CM sketches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18919v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nima Shahbazi, Stavros Sintos, Abolfazl Asudeh</dc:creator>
    </item>
    <item>
      <title>On Distributed Colouring of Hyperbolic Random Graphs</title>
      <link>https://arxiv.org/abs/2505.19109</link>
      <description>arXiv:2505.19109v1 Announce Type: new 
Abstract: We analyse the performance of simple distributed colouring algorithms under the assumption that the underlying graph is a hyperbolic random graph (HRG). The model of hyperbolic random graph encapsulates some algorithmic and structural properties that also emerge in many complex real-world networks like a power-law degree distribution. Following studies on algorithmic performances where the worst case is replaced by analysing the run time on a hyperbolic random graph, we investigate the number of rounds and the colour space required to colour a hyperbolic random graph in the distributed setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19109v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yannic Maus, Janosch Ruff</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Online Bipartite Fractional Matching</title>
      <link>https://arxiv.org/abs/2505.19252</link>
      <description>arXiv:2505.19252v1 Announce Type: new 
Abstract: Online bipartite matching is a fundamental problem in online optimization, extensively studied both in its integral and fractional forms due to its theoretical significance and practical applications, such as online advertising and resource allocation. Motivated by recent progress in learning-augmented algorithms, we study online bipartite fractional matching when the algorithm is given advice in the form of a suggested matching in each iteration. We develop algorithms for both the vertex-weighted and unweighted variants that provably dominate the naive "coin flip" strategy of randomly choosing between the advice-following and advice-free algorithms. Moreover, our algorithm for the vertex-weighted setting extends to the AdWords problem under the small bids assumption, yielding a significant improvement over the seminal work of Mahdian, Nazerzadeh, and Saberi (EC 2007, TALG 2012). Complementing our positive results, we establish a hardness bound on the robustness-consistency tradeoff that is attainable by any algorithm. We empirically validate our algorithms through experiments on synthetic and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19252v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davin Choo, Billy Jin, Yongho Shin</dc:creator>
    </item>
    <item>
      <title>Demand Selection for VRP with Emission Quota</title>
      <link>https://arxiv.org/abs/2505.19315</link>
      <description>arXiv:2505.19315v1 Announce Type: new 
Abstract: Combinatorial optimization (CO) problems are traditionally addressed using Operations Research (OR) methods, including metaheuristics. In this study, we introduce a demand selection problem for the Vehicle Routing Problem (VRP) with an emission quota, referred to as QVRP. The objective is to minimize the number of omitted deliveries while respecting the pollution quota. We focus on the demand selection part, called Maximum Feasible Vehicle Assignment (MFVA), while the construction of a routing for the VRP instance is solved using classical OR methods. We propose several methods for selecting the packages to omit, both from machine learning (ML) and OR. Our results show that, in this static problem setting, classical OR-based methods consistently outperform ML-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19315v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Farid Najar, Dominique Barth, Yann Strozecki</dc:creator>
    </item>
    <item>
      <title>Private Geometric Median in Nearly-Linear Time</title>
      <link>https://arxiv.org/abs/2505.20189</link>
      <description>arXiv:2505.20189v1 Announce Type: new 
Abstract: Estimating the geometric median of a dataset is a robust counterpart to mean estimation, and is a fundamental problem in computational geometry. Recently, [HSU24] gave an $(\varepsilon, \delta)$-differentially private algorithm obtaining an $\alpha$-multiplicative approximation to the geometric median objective, $\frac 1 n \sum_{i \in [n]} \|\cdot - \mathbf{x}_i\|$, given a dataset $\mathcal{D} := \{\mathbf{x}_i\}_{i \in [n]} \subset \mathbb{R}^d$. Their algorithm requires $n \gtrsim \sqrt d \cdot \frac 1 {\alpha\varepsilon}$ samples, which they prove is information-theoretically optimal. This result is surprising because its error scales with the \emph{effective radius} of $\mathcal{D}$ (i.e., of a ball capturing most points), rather than the worst-case radius. We give an improved algorithm that obtains the same approximation quality, also using $n \gtrsim \sqrt d \cdot \frac 1 {\alpha\epsilon}$ samples, but in time $\widetilde{O}(nd + \frac d {\alpha^2})$. Our runtime is nearly-linear, plus the cost of the cheapest non-private first-order method due to [CLM+16]. To achieve our results, we use subsampling and geometric aggregation tools inspired by FriendlyCore [TCK+22] to speed up the "warm start" component of the [HSU24] algorithm, combined with a careful custom analysis of DP-SGD's sensitivity for the geometric median objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20189v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Syamantak Kumar, Daogao Liu, Kevin Tian, Chutong Yang</dc:creator>
    </item>
    <item>
      <title>Improved and Oracle-Efficient Online $\ell_1$-Multicalibration</title>
      <link>https://arxiv.org/abs/2505.17365</link>
      <description>arXiv:2505.17365v1 Announce Type: cross 
Abstract: We study \emph{online multicalibration}, a framework for ensuring calibrated predictions across multiple groups in adversarial settings, across $T$ rounds. Although online calibration is typically studied in the $\ell_1$ norm, prior approaches to online multicalibration have taken the indirect approach of obtaining rates in other norms (such as $\ell_2$ and $\ell_{\infty}$) and then transferred these guarantees to $\ell_1$ at additional loss. In contrast, we propose a direct method that achieves improved and oracle-efficient rates of $\widetilde{\mathcal{O}}(T^{-1/3})$ and $\widetilde{\mathcal{O}}(T^{-1/4})$ respectively, for online $\ell_1$-multicalibration. Our key insight is a novel reduction of online \(\ell_1\)-multicalibration to an online learning problem with product-based rewards, which we refer to as \emph{online linear-product optimization} ($\mathtt{OLPO}$).
  To obtain the improved rate of $\widetilde{\mathcal{O}}(T^{-1/3})$, we introduce a linearization of $\mathtt{OLPO}$ and design a no-regret algorithm for this linearized problem. Although this method guarantees the desired sublinear rate (nearly matching the best rate for online calibration), it becomes computationally expensive when the group family \(\mathcal{H}\) is large or infinite, since it enumerates all possible groups. To address scalability, we propose a second approach to $\mathtt{OLPO}$ that makes only a polynomial number of calls to an offline optimization (\emph{multicalibration evaluation}) oracle, resulting in \emph{oracle-efficient} online \(\ell_1\)-multicalibration with a rate of $\widetilde{\mathcal{O}}(T^{-1/4})$. Our framework also extends to certain infinite families of groups (e.g., all linear functions on the context space) by exploiting a $1$-Lipschitz property of the \(\ell_1\)-multicalibration error with respect to \(\mathcal{H}\).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17365v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Ghuge, Vidya Muthukumar, Sahil Singla</dc:creator>
    </item>
    <item>
      <title>Simple parallel estimation of the partition ratio for Gibbs distributions</title>
      <link>https://arxiv.org/abs/2505.18324</link>
      <description>arXiv:2505.18324v1 Announce Type: cross 
Abstract: We consider the problem of estimating the partition function $Z(\beta)=\sum_x \exp(\beta(H(x))$ of a Gibbs distribution with the Hamiltonian $H:\Omega\rightarrow\{0\}\cup[1,n]$. As shown in [Harris &amp; Kolmogorov 2024], the log-ratio $q=\ln (Z(\beta_{\max})/Z(\beta_{\min}))$ can be estimated with accuracy $\epsilon$ using $O(\frac{q \log n}{\epsilon^2})$ calls to an oracle that produces a sample from the Gibbs distribution for parameter $\beta\in[\beta_{\min},\beta_{\max}]$. That algorithm is inherently sequential, or {\em adaptive}: the queried values of $\beta$ depend on previous samples. Recently, [Liu, Yin &amp; Zhang 2024] developed a non-adaptive version that needs $O( q (\log^2 n) (\log q + \log \log n + \epsilon^{-2}) )$ samples.
  We improve the number of samples to $O(\frac{q \log^2 n}{\epsilon^2})$ for a non-adaptive algorithm, and to $O(\frac{q \log n}{\epsilon^2})$ for an algorithm that uses just two rounds of adaptivity (matching the complexity of the sequential version). Furthermore, our algorithm simplifies previous techniques. In particular, we use just a single estimator, whereas methods in [Harris &amp; Kolmogorov 2024, Liu, Yin &amp; Zhang 2024] employ two different estimators for different regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18324v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David G. Harris, Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>Improved Regret and Contextual Linear Extension for Pandora's Box and Prophet Inequality</title>
      <link>https://arxiv.org/abs/2505.18828</link>
      <description>arXiv:2505.18828v1 Announce Type: cross 
Abstract: We study the Pandora's Box problem in an online learning setting with semi-bandit feedback. In each round, the learner sequentially pays to open up to $n$ boxes with unknown reward distributions, observes rewards upon opening, and decides when to stop. The utility of the learner is the maximum observed reward minus the cumulative cost of opened boxes, and the goal is to minimize regret defined as the gap between the cumulative expected utility and that of the optimal policy. We propose a new algorithm that achieves $\widetilde{O}(\sqrt{nT})$ regret after $T$ rounds, which improves the $\widetilde{O}(n\sqrt{T})$ bound of Agarwal et al. [2024] and matches the known lower bound up to logarithmic factors. To better capture real-life applications, we then extend our results to a natural but challenging contextual linear setting, where each box's expected reward is linear in some known but time-varying $d$-dimensional context and the noise distribution is fixed over time. We design an algorithm that learns both the linear function and the noise distributions, achieving $\widetilde{O}(nd\sqrt{T})$ regret. Finally, we show that our techniques also apply to the online Prophet Inequality problem, where the learner must decide immediately whether or not to accept a revealed reward. In both non-contextual and contextual settings, our approach achieves similar improvements and regret bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18828v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyan Liu, Ziyun Chen, Kun Wang, Haipeng Luo, Lillian J. Ratliff</dc:creator>
    </item>
    <item>
      <title>Grassroots Consensus</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v2 Announce Type: cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic and decentralized/plutocratic alike. Within the grassroots architecture, consensus is needed to realize platforms that employ digital social contracts, which are like smart contracts except that they are among people not accounts and are executed by these people's smartphones not by high-performance servers controlled by parties outside to the contract. Key envisioned grassroots platforms include sovereign democratic digital communities and federations, community banks and their grassroots cryptocurrencies, and digital cooperatives.
  The grassroots architecture can benefit from a consensus protocol that is (i) quiescent, (ii) efficient during low- and high-throughput, (iii) responsive, (iv) blocklace-based, (v) UDP-ready, and (vi) grassroots. The Grassroots Consensus protocol addresses all these requirements while having competitive performance in both low- and high-throughput scenarios and being one of the most concise and elegant consensus protocols for partial synchrony. It achieves that by building on two cutting-edge consensus protocols -- the quiescent high-performance Morpheus and the blocklace-based Cordial Miners, improving the latter's dissemination protocol and making it UDP-ready, and extending the protocol with a constitution and a constitutional amendment component, making it grassroots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v2</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>A Formal Analysis of Algorithms for Matroids and Greedoids</title>
      <link>https://arxiv.org/abs/2505.19816</link>
      <description>arXiv:2505.19816v1 Announce Type: cross 
Abstract: We present a formal analysis, in Isabelle/HOL, of optimisation algorithms for matroids, which are useful generalisations of combinatorial structures that occur in optimisation, and greedoids, which are a generalisation of matroids. Although some formalisation work has been done earlier on matroids, our work here presents the first formalisation of results on greedoids, and many results we formalise in relation to matroids are also formalised for the first time in this work. We formalise the analysis of a number of optimisation algorithms for matroids and greedoids. We also derive from those algorithms executable implementations of Kruskal's algorithm for minimum spanning trees, an algorithm for maximum cardinality matching for bi-partite graphs, and Prim's algorithm for computing minimum weight spanning trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19816v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Abdulaziz, Thomas Ammer, Shriya Meenakshisundaram, Adem Rimpapa</dc:creator>
    </item>
    <item>
      <title>Pathographs and some (un)decidability results</title>
      <link>https://arxiv.org/abs/2505.19871</link>
      <description>arXiv:2505.19871v1 Announce Type: cross 
Abstract: We introduce pathographs as a framework to study graph classes defined by forbidden structures, including forbidding induced subgraphs, minors, etc. Pathographs approximately generalize s-graphs of L\'ev\^eque--Lin--Maffray--Trotignon by the addition of two extra adjacency relations: one between subdivisible edges and vertices called spokes, and one between pairs of subdivisible edges called rungs. We consider the following decision problem: given a pathograph $\mathfrak{H}$ and a finite set of pathographs $\mathcal{F}$, is there an $\mathcal{F}$-free realization of $\mathfrak{H}$? This may be regarded as a generalization of the "graph class containment problem": given two graph classes $S$ and $S'$, is it the case that $S\subseteq S'$? We prove the pathograph realization problem is undecidable in general, but it is decidable in the case that $\mathfrak{H}$ has no rungs (but may have spokes), or if $\mathcal{F}$ is closed under adding edges, spokes, and rungs. We also discuss some potential applications to proving decomposition theorems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19871v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Carter, Nicolas Trotignon</dc:creator>
    </item>
    <item>
      <title>Bounding Width on Graph Classes of Constant Diameter</title>
      <link>https://arxiv.org/abs/2505.19926</link>
      <description>arXiv:2505.19926v1 Announce Type: cross 
Abstract: We determine if the width of a graph class ${\cal G}$ changes from unbounded to bounded if we consider only those graphs from ${\cal G}$ whose diameter is bounded. As parameters we consider treedepth, pathwidth, treewidth and clique-width, and as graph classes we consider classes defined by forbidding some specific graph $F$ as a minor, induced subgraph or subgraph, respectively. Our main focus is on treedepth for $F$-subgraph-free graphs of diameter at most~$d$ for some fixed integer $d$. We give classifications of boundedness of treedepth for $d\in \{4,5,\ldots\}$ and partial classifications for $d=2$ and $d=3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19926v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konrad K. Dabrowski, Tala Eagling-Vose, Noleen K\"ohler, Sebastian Ordyniak, Dani\"el Paulusma</dc:creator>
    </item>
    <item>
      <title>The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination</title>
      <link>https://arxiv.org/abs/2505.20177</link>
      <description>arXiv:2505.20177v1 Announce Type: cross 
Abstract: Inspired by recent work on learning with distribution shift, we give a general outlier removal algorithm called iterative polynomial filtering and show a number of striking applications for supervised learning with contamination: (1) We show that any function class that can be approximated by low-degree polynomials with respect to a hypercontractive distribution can be efficiently learned under bounded contamination (also known as nasty noise). This is a surprising resolution to a longstanding gap between the complexity of agnostic learning and learning with contamination, as it was widely believed that low-degree approximators only implied tolerance to label noise. (2) For any function class that admits the (stronger) notion of sandwiching approximators, we obtain near-optimal learning guarantees even with respect to heavy additive contamination, where far more than $1/2$ of the training set may be added adversarially. Prior related work held only for regression and in a list-decodable setting. (3) We obtain the first efficient algorithms for tolerant testable learning of functions of halfspaces with respect to any fixed log-concave distribution. Even the non-tolerant case for a single halfspace in this setting had remained open. These results significantly advance our understanding of efficient supervised learning under contamination, a setting that has been much less studied than its unsupervised counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20177v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam R. Klivans, Konstantinos Stavropoulos, Kevin Tian, Arsen Vasilyan</dc:creator>
    </item>
    <item>
      <title>Probabilistic Kernel Function for Fast Angle Testing</title>
      <link>https://arxiv.org/abs/2505.20274</link>
      <description>arXiv:2505.20274v1 Announce Type: cross 
Abstract: In this paper, we study the angle testing problem in high-dimensional Euclidean spaces and propose two projection-based probabilistic kernel functions, one designed for angle comparison and the other for angle thresholding. Unlike existing approaches that rely on random projection vectors drawn from Gaussian distributions, our approach leverages reference angles and employs a deterministic structure for the projection vectors. Notably, our kernel functions do not require asymptotic assumptions, such as the number of projection vectors tending to infinity, and can be both theoretically and experimentally shown to outperform Gaussian-distribution-based kernel functions. We further apply the proposed kernel function to Approximate Nearest Neighbor Search (ANNS) and demonstrate that our approach achieves a 2.5X ~ 3X higher query-per-second (QPS) throughput compared to the state-of-the-art graph-based search algorithm HNSW.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20274v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa</dc:creator>
    </item>
    <item>
      <title>Discrepancy Minimization in Input-Sparsity Time</title>
      <link>https://arxiv.org/abs/2210.12468</link>
      <description>arXiv:2210.12468v2 Announce Type: replace 
Abstract: A recent work by [Larsen, SODA 2023] introduced a faster combinatorial alternative to Bansal's SDP algorithm for finding a coloring $x \in \{-1, 1\}^n$ that approximately minimizes the discrepancy $\mathrm{disc}(A, x) := | A x |_{\infty}$ of a real-valued $m \times n$ matrix $A$. Larsen's algorithm runs in $\widetilde{O}(mn^2)$ time compared to Bansal's $\widetilde{O}(mn^{4.5})$-time algorithm, with a slightly weaker logarithmic approximation ratio in terms of the hereditary discrepancy of $A$ [Bansal, FOCS 2010]. We present a combinatorial $\widetilde{O}(\mathrm{nnz}(A) + n^3)$-time algorithm with the same approximation guarantee as Larsen's, optimal for tall matrices where $m = \mathrm{poly}(n)$. Using a more intricate analysis and fast matrix multiplication, we further achieve a runtime of $\widetilde{O}(\mathrm{nnz}(A) + n^{2.53})$, breaking the cubic barrier for square matrices and surpassing the limitations of linear-programming approaches [Eldan and Singh, RS&amp;A 2018]. Our algorithm relies on two key ideas: (i) a new sketching technique for finding a projection matrix with a short $\ell_2$-basis using implicit leverage-score sampling, and (ii) a data structure for efficiently implementing the iterative Edge-Walk partial-coloring algorithm [Lovett and Meka, SICOMP 2015], and using an alternative analysis to enable ''lazy'' batch updates with low-rank corrections. Our results nearly close the computational gap between real-valued and binary matrices, for which input-sparsity time coloring was recently obtained by [Jain, Sah and Sawhney, SODA 2023].</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12468v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yichuan Deng, Xiaoyu Li, Zhao Song, Omri Weinstein</dc:creator>
    </item>
    <item>
      <title>Discrepancy Algorithms for the Binary Perceptron</title>
      <link>https://arxiv.org/abs/2408.00796</link>
      <description>arXiv:2408.00796v2 Announce Type: replace 
Abstract: The binary perceptron problem asks us to find a sign vector in the intersection of independently chosen random halfspaces with intercept $-\kappa$. We analyze the performance of the canonical discrepancy minimization algorithms of Lovett-Meka and Rothvoss/Eldan-Singh for the asymmetric binary perceptron problem. We obtain new algorithmic results in the $\kappa = 0$ case and in the large-$|\kappa|$ case. In the $\kappa\to-\infty$ case, we additionally characterize the storage capacity and complement our algorithmic results with an almost-matching overlap-gap lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00796v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuangping Li, Tselil Schramm, Kangjie Zhou</dc:creator>
    </item>
    <item>
      <title>Tight analysis of the primal-dual method for edge-covering pliable set families</title>
      <link>https://arxiv.org/abs/2504.03910</link>
      <description>arXiv:2504.03910v2 Announce Type: replace 
Abstract: A classic result of Williamson, Goemans, Mihail, and Vazirani [STOC 1993: 708-717] states that the problem of covering an uncrossable set family by a min-cost edge set admits approximation ratio $2$, by a primal-dual algorithm with a reverse delete phase. Bansal, Cheriyan, Grout, and Ibrahimpur [ICALP 2023: 15:1-15:19] showed that this algorithm achieves approximation ratio $16$ for a larger class of so called $\gamma$-pliable set families, that have much weaker uncrossing properties. The approximation ratio $16$ was improved to $10$ by the author [WAOA 2025: 151-166]. Recently, Bansal [arXiv:2308.15714] stated approximation ratio $8$ for $\gamma$-pliable families and an improved approximation ratio $5$ for an important particular case of the family of cuts of size $&lt;k$ of a graph $H$, but his proof has an error. We will improve the approximation ratio to $7$ for the former case and give a simple proof of approximation ratio $6$ for the latter case. Furthermore, if $H$ is $\lambda$-edge-connected then we will show a slightly better approximation ratio $6-\frac{1}{\beta+1}$, where $\beta=\left\lfloor\frac{k-1}{\lceil(\lambda+1)/2\rceil}\right\rfloor$. Our analysis is supplemented by examples showing that these approximation ratios are tight for the primal-dual algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03910v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeev Nutov</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Distributed Edge Coloring with Fewer Colors</title>
      <link>https://arxiv.org/abs/2504.13003</link>
      <description>arXiv:2504.13003v2 Announce Type: replace 
Abstract: There is a huge difference in techniques and runtimes of distributed algorithms for problems that can be solved by a sequential greedy algorithm and those that cannot. A prime example of this contrast appears in the edge coloring problem: while $(2\Delta-1)$-edge coloring can be solved in $\mathcal{O}(\log^{\ast}(n))$ rounds on constant-degree graphs, the seemingly minor reduction to $(2\Delta-2)$ colors leads to an $\Omega(\log n)$ lower bound [Chang, He, Li, Pettie &amp; Uitto, SODA'18]. Understanding this sharp divide between very local problems and inherently more global ones remains a central open question in distributed computing and it is a core focus of this paper.
  As our main contribution we design a deterministic distributed $\mathcal{O}(\log n)$-round reduction from the $(2\Delta-2)$-edge coloring problem to the much easier $(2\Delta-1)$-edge coloring problem. This reduction is optimal, as the $(2\Delta-2)$-edge coloring problem admits an $\Omega(\log n)$ lower bound, whereas the $2\Delta-1$-edge coloring problem can be solved in $\mathcal{O}(\log^{\ast}n)$ rounds. By plugging in the $(2\Delta-1)$-edge coloring algorithms from [Balliu, Brandt, Kuhn &amp; Olivetti, PODC'22] running in $\mathcal{O}(\log^{12}\Delta + \log^{\ast} n)$ rounds, we obtain an optimal runtime of $\mathcal{O}(\log n)$ rounds as long as $\Delta = 2^{\mathcal{O}(\log^{1/12} n)}$. Furthermore, on general graphs our reduction improves the runtime from $\widetilde{\mathcal{O}}(\log^3 n)$ to $\widetilde{\mathcal{O}}(\log^{5/3} n)$.
  In addition, we also obtain an optimal $\mathcal{O}(\log \log n)$-round randomized reduction of $(2\Delta - 2)$-edge coloring to $(2\Delta - 1)$-edge coloring. Lastly, we obtain an $\mathcal{O}(\log_\Delta n)$-round reduction from the $(2\Delta-1)$-edge coloring, albeit to the somewhat harder maximal independent set (MIS) problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13003v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Jakob, Yannic Maus, Florian Schager</dc:creator>
    </item>
    <item>
      <title>persiansort : an alternative to mergesort inspired by persian rug</title>
      <link>https://arxiv.org/abs/2505.05775</link>
      <description>arXiv:2505.05775v2 Announce Type: replace 
Abstract: This paper introduces persiansort, new stable sorting algorithm inspired by Persian rug. Persiansort does not have the weaknesses of mergesort under scenarios involving nearly sorted and partially sorted data, also utilizing less auxiliary memory than mergesort and take advantage of runs. Initial experimental showed, this method is flexible, powerful and works better than mergesort in almost all types of data. Persiansort offers several advantages over merge methods, make it a potential replacement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05775v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Parviz Afereidoon</dc:creator>
    </item>
    <item>
      <title>Simpler and Faster Directed Low-Diameter Decompositions</title>
      <link>https://arxiv.org/abs/2505.10244</link>
      <description>arXiv:2505.10244v3 Announce Type: replace 
Abstract: We present a simpler and faster algorithm for low-diameter decompositions on directed graphs, matching the $O(\log n\log\log n)$ loss factor from Bringmann, Fischer, Haeupler, and Latypov (ICALP 2025) and improving the running time to $O((m+n\log\log n)\log^2n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10244v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Li</dc:creator>
    </item>
    <item>
      <title>Embeddable of hieroglyphs into torus</title>
      <link>https://arxiv.org/abs/2208.08692</link>
      <description>arXiv:2208.08692v4 Announce Type: replace-cross 
Abstract: We are interested in finding combinatorial criteria for embedding graphs into two-dimensional torus and using them in the embedding check algorithm. It is a well-known fact that any connected graph can be reduced to a one-vertex graph with loops and is homotopy equivalent to such a graph. If a connected graph has intersection of some edges, then some loops of one-vertex graph will also intersect. Therefore the problem of embedding graphs in some surface is equivalent to the question of embedding one-vertex graph in given surface. This paper considers a graph with rotation structure (not necessarily geometric) or rotation graph called hieroglyph. The equivalence of four conditions is proved: (1) embedding hieroglyph in the torus; (2) the absence of forbidden subgraphs in a hieroglyph; (3) some condition for the graph of loops; (4) the existence of a reduction of hieroglyph to one of the list of hieroglyphs. We also prove the existence of an algorithm with complexity $\mathcal{O}(n)$ that recognizes embedding hieroglyph in the torus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08692v4</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>math.GT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Berezin</dc:creator>
    </item>
    <item>
      <title>A Quantum Approximation Scheme for k-Means</title>
      <link>https://arxiv.org/abs/2308.08167</link>
      <description>arXiv:2308.08167v3 Announce Type: replace-cross 
Abstract: We give a quantum approximation scheme (i.e., $(1 + \varepsilon)$-approximation for every $\varepsilon &gt; 0$) for the classical $k$-means clustering problem in the QRAM model with a running time that has only polylogarithmic dependence on the number of data points. More specifically, given a dataset $V$ with $N$ points in $\mathbb{R}^d$ stored in QRAM data structure, our quantum algorithm runs in time $\tilde{O} \left( 2^{\tilde{O}(\frac{k}{\varepsilon})} \eta^2 d\right)$ and with high probability outputs a set $C$ of $k$ centers such that $cost(V, C) \leq (1+\varepsilon) \cdot cost(V, C_{OPT})$. Here $C_{OPT}$ denotes the optimal $k$-centers, $cost(.)$ denotes the standard $k$-means cost function (i.e., the sum of the squared distance of points to the closest center), and $\eta$ is the aspect ratio (i.e., the ratio of maximum distance to minimum distance). This is the first quantum algorithm with a polylogarithmic running time that gives a provable approximation guarantee of $(1+\varepsilon)$ for the $k$-means problem. Also, unlike previous works on unsupervised learning, our quantum algorithm does not require quantum linear algebra subroutines and has a running time independent of parameters (e.g., condition number) that appear in such procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08167v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ragesh Jaiswal</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Smallest Intersecting Balls</title>
      <link>https://arxiv.org/abs/2406.11369</link>
      <description>arXiv:2406.11369v2 Announce Type: replace-cross 
Abstract: We study a general smallest intersecting ball problem and its soft-margin variant in high-dimensional Euclidean spaces for input objects that are compact and convex. These two problems link and unify a series of fundamental problems in computational geometry and machine learning, including smallest enclosing ball, polytope distance, intersection radius, $\ell_1$-loss support vector machine, $\ell_1$-loss support vector data description, and so on. Leveraging our novel framework for solving zero-sum games over symmetric cones, we propose general approximation algorithms for the two problems, where implementation details are presented for specific inputs of convex polytopes, reduced polytopes, axis-aligned bounding boxes, balls, and ellipsoids. For most of these inputs, our algorithms are the first results in high-dimensional spaces, and also the first approximation methods. Experimental results show that our algorithms can solve large-scale input instances efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11369v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Zheng, Tiow-Seng Tan</dc:creator>
    </item>
    <item>
      <title>Algorithms and complexity for monitoring edge-geodetic sets in graphs</title>
      <link>https://arxiv.org/abs/2409.19067</link>
      <description>arXiv:2409.19067v2 Announce Type: replace-cross 
Abstract: A monitoring edge-geodetic set of a graph is a subset $M$ of its vertices such that for every edge $e$ in the graph, deleting $e$ increases the distance between at least one pair of vertices in $M$. We study the following computational problem \textsc{MEG-set}: given a graph $G$ and an integer $k$, decide whether $G$ has a monitoring edge geodetic set of size at most $k$. We prove that the problem is NP-hard even for 2-apex 3-degenerate graphs, improving a result by Haslegrave (Discrete Applied Mathematics 2023). Additionally, we prove that the problem cannot be solved in subexponential-time, assuming the Exponential-Time Hypothesis, even for 3-degenerate graphs. Further, we prove that the optimization version of the problem is APX-hard, even for 4-degenerate graphs. Complementing these hardness results, we prove that the problem admits a polynomial-time algorithm for interval graphs, a fixed-parameter tractable algorithm for general graphs with clique-width plus diameter as the parameter, and a fixed-parameter tractable algorithm for chordal graphs with treewidth as the parameter. We also provide an approximation algorithm with factor $\ln m\cdot OPT$ and $\sqrt{n\ln m}$ for the optimization version of the problem, where $m$ is the number of edges, $n$ the number of vertices, and $OPT$ is the size of a minimum monitoring edge-geodetic set of the input graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19067v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Florent Foucaud, Clara Marcille, R. B. Sandeep, Sagnik Sen, S Taruni</dc:creator>
    </item>
    <item>
      <title>A partition cover approach to tokenization</title>
      <link>https://arxiv.org/abs/2501.06246</link>
      <description>arXiv:2501.06246v2 Announce Type: replace-cross 
Abstract: Tokenization is the process of encoding strings into tokens of a fixed vocabulary size, and is widely utilized in Natural Language Processing applications. The leading tokenization algorithm today is Byte-Pair Encoding (BPE), which formulates the tokenization problem as a compression problem and tackles it by performing sequences of merges. In this work, we formulate tokenization as an optimization objective, show that it is NP-hard via a simple reduction from vertex cover, and propose a polynomial-time greedy algorithm GreedTok. Our formulation naturally relaxes to the well-studied weighted maximum coverage problem which has a simple $(1 - 1/e)$-approximation algorithm GreedWMC. Through empirical evaluations on real-world corpora, we show that GreedTok outperforms BPE and Unigram on compression and achieves a covering score comparable to GreedWMC. Finally, our extensive pre-training for two transformer-based language models with 1 billion parameters, comparing the choices of BPE and GreedTok as the tokenizer, shows that GreedTok achieves a lower bit per byte even when we control for either the total dataset proportion or total training tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06246v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia Peng Lim, Shawn Tan, Davin Choo, Hady W. Lauw</dc:creator>
    </item>
    <item>
      <title>Group Trip Planning Query Problem with Multimodal Journey</title>
      <link>https://arxiv.org/abs/2502.03144</link>
      <description>arXiv:2502.03144v2 Announce Type: replace-cross 
Abstract: In Group Trip Planning (GTP) Query Problem, we are given a city road network where a number of Points of Interest (PoI) have been marked with their respective categories (e.g., Cafeteria, Park, Movie Theater, etc.). A group of agents want to visit one PoI from every category from their respective starting location and once finished, they want to reach their respective destinations. This problem asks which PoI from every category should be chosen so that the aggregated travel cost of the group is minimized. This problem has been studied extensively in the last decade, and several solution approaches have been proposed. However, to the best of our knowledge, none of the existing studies have considered the different modalities of the journey, which makes the problem more practical. To bridge this gap, we introduce and study the GTP Query Problem with Multimodal Journey in this paper. Along with the other inputs of the GTP Query Problem, we are also given the different modalities of the journey that are available and their respective cost. Now, the problem is not only to select the PoIs from respective categories but also to select the modality of the journey. For this problem, we have proposed an efficient solution approach, which has been analyzed to understand their time and space requirements. A large number of experiments have been conducted using real-life datasets and the results have been reported. From the results, we observe that the PoIs and modality of journey recommended by the proposed solution approach lead to much less time and cost than the baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03144v2</guid>
      <category>cs.MA</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Suman Banerjee, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>Pcodec: Better Compression for Numerical Sequences</title>
      <link>https://arxiv.org/abs/2502.06112</link>
      <description>arXiv:2502.06112v2 Announce Type: replace-cross 
Abstract: We present Pcodec (Pco), a format and algorithm for losslessly compressing numerical (float or integer) sequences. Pco's core and most novel component is a binning algorithm that quickly converges to the true entropy of smoothly, independently, and identically distributed (SIID) integers. We mathematically prove this convergence with a practical bound. To accommodate data this is not SIID, Pco has two opinionated preprocessing steps. The first step, Pco's mode, decomposes the numbers into more smoothly distributed integer latent variables. The second step, delta encoding, makes the latents more independently and identically distributed. We demonstrate that Pco achieves 29-94% higher compression ratio than other numerical codecs on six real-world columnar datasets while using less compression time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06112v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Loncaric, Niels Jeppesen, Ben Zinberg</dc:creator>
    </item>
    <item>
      <title>Weighted Pseudorandom Generators for Read-Once Branching Programs via Weighted Pseudorandom Reductions</title>
      <link>https://arxiv.org/abs/2502.08272</link>
      <description>arXiv:2502.08272v2 Announce Type: replace-cross 
Abstract: We study weighted pseudorandom generators (WPRGs) and derandomizations for read-once branching programs (ROBPs). Denote $n$ and $w$ as the length and the width of a ROBP. We have the following results.
  For standard ROBPs, there exists an explicit $\varepsilon$-WPRG with seed length $$ O\left(\frac{\log n\log (nw)}{\max\left\{1,\log\log w-\log\log n\right\}}+\log w \left(\log\log\log w-\log\log\max\left\{2,\frac{\log w}{\log n/\varepsilon}\right\}\right)+\log(1/\varepsilon)\right).$$ When $n = w^{o(1)},$ this is better than the constructions in Hoza (RANDOM 2022), Cohen, Doron, Renard, Sberlo, and Ta-Shma (CCC 2021).Further, by using this result in a black-box way, we attain a WPRG for regular ROBPs with seed length $$O\left(\log n\left(\sqrt{\log(1/\varepsilon)}+\log w+\log\log n\right)+\log(1/\varepsilon)\right).$$ This slightly improves the result of Chen, Hoza, Lyu, Tal, and Wu (FOCS 2023) and matches the recent simultaneous and independent work of Chen and Ta-shma.
  For permutation ROBPs with unbounded widths and single accept nodes, there exists an explicit $\varepsilon$-WPRG with seed length $$ O\left( \log n\left( \log\log n + \sqrt{\log(1/\varepsilon)} \right)+\log(1/\varepsilon)\right). $$ This slightly improves the result of Chen, Hoza, Lyu, Tal, and Wu (FOCS 2023).
  For regular ROBPs with $n \leq 2^{O(\sqrt{\log w})}, \varepsilon = 1/\text{poly} w$, we give a derandomization within space $O(\log w)$, i.e. in $\mathbf{L}$ exactly.
  This is better than previous results of Ahmadinejad, Kelner, Murtagh, Peebles, Sidford, and Vadhan (FOCS 2020) in this regime, and we improves the time complexity from super-polynomial to standard polynomial.
  Our main method is based on a recursive application of weighted pseudorandom reductions, which is a natural notion that is used to simplify ROBPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08272v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kuan Cheng, Ruiyang Wu</dc:creator>
    </item>
    <item>
      <title>Non-unitary enhanced transfer efficiency in quantum walk search on complex networks</title>
      <link>https://arxiv.org/abs/2503.01762</link>
      <description>arXiv:2503.01762v2 Announce Type: replace-cross 
Abstract: The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this article, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. We study the transfer efficiency of the walker to a trapping site, using the search problem as a case study. Thus, our model offers no computational advantage for the search problem, but focuses on information transport in an open environment with a search Hamiltonian. The walker evolution is a mix between classical and quantum walk search dynamics. The balance between unitary and non-unitary dynamics is tuned with a parameter, and we numerically show that depending on the graph topology and the connectivity of the target element, this hybrid approach can outperform a purely classical or quantum evolution for reaching the trapping site. We show that this behavior is only observed in the presence of an extra trapping site, and that depending on the topology, the increase of non-unitary operations can be compensated by increasing the strength of the quantum walk exploration. This compensation comes at the cost of reducing or even suppressing the searching feature of the evolution. In that case, the unitary dynamics will only induce a regular quantum walk behavior. We also relate the optimal hybrid regime to the entropy's decay rate. As the introduction of non-unitary operations may be considered as noise, we interpret this phenomena as a noisy-assisted quantum evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01762v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ugo Nzongani, Andrea Simonetto, Giuseppe Di Molfetta</dc:creator>
    </item>
  </channel>
</rss>
