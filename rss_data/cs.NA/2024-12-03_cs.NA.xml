<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 02:52:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Numerical Approximation of the Karhunen-Lo\`{e}ve Expansion for Random Fields with Random Discrete Data</title>
      <link>https://arxiv.org/abs/2412.00027</link>
      <description>arXiv:2412.00027v1 Announce Type: new 
Abstract: In many applications, random fields reflect uncertain parameters, and often their moments are part of the modeling process and thus well known. However, there are practical situations where this is simply not the case. Therefore, we do not assume that we know moments or expansion terms of the random fields, but only have discretized samples of them. The main contribution of this paper concerns the approximation of the true covariance operator from these finite measurements. We derive explicit error estimates that include the finite-rank approximation error of the covariance operator, the Monte Carlo-type error for sampling in the stochastic domain, and the numerical discretization error in the physical domain. For this purpose, we use modern tapering covariance estimators adapted to high-dimensional applications, where the dimension is introduced by the resolution of the measurement process. This allows us to give sufficient conditions on the three discretization parameters to guarantee that the error is kept below a prescribed accuracy $\varepsilon$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00027v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Griebel, Guanglian Li, Christian Rieger</dc:creator>
    </item>
    <item>
      <title>Automatic discovery of optimal meta-solvers via multi-objective optimization</title>
      <link>https://arxiv.org/abs/2412.00063</link>
      <description>arXiv:2412.00063v1 Announce Type: new 
Abstract: We design two classes of ultra-fast meta-solvers for linear systems arising after discretizing PDEs by combining neural operators with either simple iterative solvers, e.g., Jacobi and Gauss-Seidel, or with Krylov methods, e.g., GMRES and BiCGStab, using the trunk basis of DeepONet as a coarse preconditioner. The idea is to leverage the spectral bias of neural networks to account for the lower part of the spectrum in the error distribution while the upper part is handled easily and inexpensively using relaxation methods or fine-scale preconditioners. We create a pareto front of optimal meta-solvers using a plurarilty of metrics, and we introduce a preference function to select the best solver most suitable for a specific scenario. This automation for finding optimal solvers can be extended to nonlinear systems and other setups, e.g. finding the best meta-solver for space-time in time-dependent PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00063v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngkyu Lee, Shanqing Liu, Jerome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>The Second Generation of the Convexification Method for a Coefficient Inverse Problem of the Epidemiology</title>
      <link>https://arxiv.org/abs/2412.00297</link>
      <description>arXiv:2412.00297v1 Announce Type: new 
Abstract: It is proposed to monitor spatial and temporal spreads of epidemics via solution of a Coefficient Inverse Problem for a system of three coupled nonlinear parabolic equations. A version of the second generation of the convexification numerical method is developed for this problem. On each iteration, a linear problem with the incomplete lateral Cauchy data is solved by the weighted Quasi-Reversibility Method, where the weight is the Carleman Weight Function (CWF). This is the function, which is involved as the weight in the Carleman estimate for the corresponding parabolic operator. Convergence analysis ensures the global convergence of this procedure. Numerical results demonstrate an accurate performance of this technique for noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00297v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael V. Klibanov, Trung Truong</dc:creator>
    </item>
    <item>
      <title>Energy-stable mixed finite element methods for the Rosensweig ferrofluid flow model</title>
      <link>https://arxiv.org/abs/2412.00360</link>
      <description>arXiv:2412.00360v1 Announce Type: new 
Abstract: In this paper, we consider mixed finite element semi-/full discretizations of the Rosensweig ferrofluid flow model. We first establish some regularity results for the model under several basic assumptions. Then we show that the energy stability of the weak solutions is preserved exactly for both the semi-discrete and fully discrete finite element solutions. Moreover, we prove the existence and uniqueness of the discrete solutions. We also derive optimal error estimates for the discrete schemes. Finally, we provide numerical experiments to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00360v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yongke Wu, Xiaoping Xie</dc:creator>
    </item>
    <item>
      <title>Implementation of neural network operators with applications to remote sensing data</title>
      <link>https://arxiv.org/abs/2412.00375</link>
      <description>arXiv:2412.00375v1 Announce Type: new 
Abstract: In this paper, we provide two algorithms based on the theory of multidimensional neural network (NN) operators activated by hyperbolic tangent sigmoidal functions. Theoretical results are recalled to justify the performance of the here implemented algorithms. Specifically, the first algorithm models multidimensional signals (such as digital images), while the second one addresses the problem of rescaling and enhancement of the considered data. We discuss several applications of the NN-based algorithms for modeling and rescaling/enhancement remote sensing data (represented as images), with numerical experiments conducted on a selection of remote sensing (RS) images from the (open access) RETINA dataset. A comparison with classical interpolation methods, such as bilinear and bicubic interpolation, shows that the proposed algorithms outperform the others, particularly in terms of the Structural Similarity Index (SSIM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00375v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Costarelli, Michele Piconi</dc:creator>
    </item>
    <item>
      <title>Bi-Band ECoGNet for ECoG Decoding on Classification Task</title>
      <link>https://arxiv.org/abs/2412.00378</link>
      <description>arXiv:2412.00378v1 Announce Type: new 
Abstract: In the application of brain-computer interface (BCI), being able to accurately decode brain signals is a critical task. For the multi-class classification task of brain signal ECoG, how to improve the classification accuracy is one of the current research hotspots. ECoG acquisition uses a high-density electrode array and a high sampling frequency, which makes ECoG data have a certain high similarity and data redundancy in the temporal domain, and also unique spatial pattern in spatial domain. How to effectively extract features is both exciting and challenging. Previous work found that visual-related ECoG can carry visual information via frequency and spatial domain. Based on this finding, we focused on using deep learning to design frequency and spatial feature extraction modules, and proposed a Bi-Band ECoGNet model based on deep learning. The main contributions of this paper are: 1) The Bi-BCWT (Bi-Band Channel-Wise Transform) neural network module is designed to replace the time-consume method MST, this module greatly improves the model calculation and data storage efficiency, and effectively increases the training speed; 2) The Bi-BCWT module can effectively take into account the information both in low-frequency and high-frequency domain, which is more conducive to ECoG multi-classification tasks; 3) ECoG is acquired using 2D electrode array, the newly designed 2D Spatial-Temporal feature encoder can extract the 2D spatial feature better. Experiments have shown that the unique 2D spatial data structure can effectively improve classification accuracy; 3) Compared with previous work, the Bi-Band ECoGNet model is smaller and has higher performance, with an accuracy increase of 1.24%, and the model training speed is increased by 6 times, which is more suitable for BCI applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00378v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changqing Ji, Keisuke Kawasaki, Isao Hasegwa, Takayuki Okatani</dc:creator>
    </item>
    <item>
      <title>Fractures and thin heterogeneities as Robin-Wentzell interface conditions</title>
      <link>https://arxiv.org/abs/2412.00443</link>
      <description>arXiv:2412.00443v1 Announce Type: new 
Abstract: We formally derive interface conditions for modeling fractures in Darcy flow problems and, more generally, thin inclusions in heterogeneous diffusion problems expressed as the divergence of a flux. Through a formal integration of the governing equations within the inclusions, we establish that the resulting interface conditions are of Wentzell type for the flux jump and Robin type for the flux average. Notably, the flux jump condition is unconventional, involving a tangential diffusion operator applied to the average of the solution across the interface.
  The corresponding weak formulation is introduced, offering a framework that is readily applicable to finite element discretizations. Extensive numerical validation highlights the robustness and versatility of the proposed modeling technique. The results demonstrate its effectiveness in accommodating a wide range of material properties, managing networks of inclusions, and naturally handling fractures with varying apertures -- all without requiring an explicit geometric representation of the fractures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00443v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Favino</dc:creator>
    </item>
    <item>
      <title>Mapped coercivity for the stationary Navier-Stokes equations and their finite element approximations</title>
      <link>https://arxiv.org/abs/2412.00494</link>
      <description>arXiv:2412.00494v1 Announce Type: new 
Abstract: This paper addresses the challenge of proving the existence of solutions for nonlinear equations in Banach spaces, focusing on the Navier-Stokes equations and discretizations of thom. Traditional methods, such as monotonicity-based approaches and fixed-point theorems, often face limitations in handling general nonlinear operators or finite element discretizations. A novel concept, mapped coercivity, provides a unifying framework to analyze nonlinear operators through a continuous mapping. We apply these ideas to saddle-point problems in Banach spaces, emphasizing both infinite-dimensional formulations and finite element discretizations. Our analysis includes stabilization techniques to restore coercivity in finite-dimensional settings, ensuring stability and existence of solutions. For linear problems, we explore the relationship between the inf-sup condition and mapped coercivity, using the Stokes equation as a case study. For nonlinear saddle-point systems, we extend the framework to mapped coercivity via surjective mappings, enabling concise proofs of existence of solutions for various stabilized Navier-Stokes finite element methods. These include Brezzi-Pitk\"aranta, a simple variant, and local projection stabilization (LPS) techniques, with extensions to convection-dominant flows. The proposed methodology offers a robust tool for analyzing nonlinear PDEs and their discretizations, bypassing traditional decompositions and providing a foundation for future developments in computational fluid dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00494v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roland Becker, Malte Braack</dc:creator>
    </item>
    <item>
      <title>Scalable nonlinear manifold reduced order model for dynamical systems</title>
      <link>https://arxiv.org/abs/2412.00507</link>
      <description>arXiv:2412.00507v1 Announce Type: new 
Abstract: The domain decomposition (DD) nonlinear-manifold reduced-order model (NM-ROM) represents a computationally efficient method for integrating underlying physics principles into a neural network-based, data-driven approach. Compared to linear subspace methods, NM-ROMs offer superior expressivity and enhanced reconstruction capabilities, while DD enables cost-effective, parallel training of autoencoders by partitioning the domain into algebraic subdomains. In this work, we investigate the scalability of this approach by implementing a "bottom-up" strategy: training NM-ROMs on smaller domains and subsequently deploying them on larger, composable ones. The application of this method to the two-dimensional time-dependent Burgers' equation shows that extrapolating from smaller to larger domains is both stable and effective. This approach achieves an accuracy of 1% in relative error and provides a remarkable speedup of nearly 700 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00507v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ivan Zanardi, Alejandro N. Diaz, Seung Whan Chung, Marco Panesi, Youngsoo Choi</dc:creator>
    </item>
    <item>
      <title>Imaging Anisotropic Conductivity from Internal Measurements with Mixed Least-Squares Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2412.00527</link>
      <description>arXiv:2412.00527v1 Announce Type: new 
Abstract: In this work we develop a novel algorithm, termed as mixed least-squares deep neural network (MLS-DNN), to recover an anisotropic conductivity tensor from the internal measurements of the solutions. It is based on applying the least-squares formulation to the mixed form of the elliptic problem, and approximating the internal flux and conductivity tensor simultaneously using deep neural networks. We provide error bounds on the approximations obtained via both population and empirical losses. The analysis relies on the canonical source condition, approximation theory of deep neural networks and statistical learning theory. We also present multiple numerical experiments to illustrate the performance of the method, and conduct a comparative study with the standard Galerkin finite element method and physics informed neural network. The results indicate that the method can accurately recover the anisotropic conductivity in both two- and three-dimensional cases, up to 10\% noise in the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00527v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Siyu Cen, Bangti Jin, Xiyao Li, Zhi Zhou</dc:creator>
    </item>
    <item>
      <title>A novel algorithm for the decomposition of non-stationary multidimensional and multivariate signals</title>
      <link>https://arxiv.org/abs/2412.00553</link>
      <description>arXiv:2412.00553v1 Announce Type: new 
Abstract: The decomposition of a signal is a fundamental tool in many fields of research, including signal processing, geophysics, astrophysics, engineering, medicine, and many more. By breaking down complex signals into simpler oscillatory components we can enhance the understanding and processing of the data, unveiling hidden information contained in them. Traditional methods, such as Fourier analysis and wavelet transforms, which are effective in handling mono-dimensional stationary signals struggle with non-stationary data sets and they require, this is the case of the wavelet, the selection of predefined basis functions. In contrast, the Empirical Mode Decomposition (EMD) method and its variants, such as Iterative Filtering (IF), have emerged as effective nonlinear approaches, adapting to signals without any need for a priori assumptions. To accelerate these methods, the Fast Iterative Filtering (FIF) algorithm was developed, and further extensions, such as Multivariate FIF (MvFIF) and Multidimensional FIF (FIF2), have been proposed to handle higher-dimensional data.
  In this work, we introduce the Multidimensional and Multivariate Fast Iterative Filtering (MdMvFIF) technique, an innovative method that extends FIF to handle data that vary simultaneously in space and time. This new algorithm is capable of extracting Intrinsic Mode Functions (IMFs) from complex signals that vary in both space and time, overcoming limitations found in prior methods. The potentiality of the proposed method is demonstrated through applications to artificial and real-life signals, highlighting its versatility and effectiveness in decomposing multidimensional and multivariate nonstationary signals. The MdMvFIF method offers a powerful tool for advanced signal analysis across many scientific and engineering disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00553v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Cavassi, Antonio Cicone, Enza Pellegrino, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Windowing Regularization Techniques for Unsteady Aerodynamic Shape Optimization</title>
      <link>https://arxiv.org/abs/2412.00604</link>
      <description>arXiv:2412.00604v1 Announce Type: new 
Abstract: Unsteady Aerodynamic Shape Optimization presents new challenges in terms of sensitivity analysis of time-dependent objective functions. In this work, we consider periodic unsteady flows governed by the URANS equations. Hence, the resulting output functions acting as objective or constraint functions of the optimization are themselves periodic with unknown period length, that may depend on the design parameter of said optimization. Sensitivity Analysis on the time-average of a function with these properties turns out to be difficult. Therefore, we explore methods to regularize the time average of such a function with the so called windowing-approach. Furthermore, we embed these regularizers into the discrete adjoint solver for the URANS equations of the multi-physics and optimization software SU2. Finally, we exhibit a comparison study between the classical non regularized optimization procedure and the ones enhanced with regularizers of different smoothness and show that the latter result in a more robust optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00604v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.J059983</arxiv:DOI>
      <dc:creator>Steffen Schotth\"ofer, Beckett Y. Zhou, Tim Albring, Nicolas R. Gauger</dc:creator>
    </item>
    <item>
      <title>Adaptive Basis-inspired Deep Neural Network for Solving Partial Differential Equations with Localized Features</title>
      <link>https://arxiv.org/abs/2412.00636</link>
      <description>arXiv:2412.00636v1 Announce Type: new 
Abstract: This paper proposes an Adaptive Basis-inspired Deep Neural Network (ABI-DNN) for solving partial differential equations with localized phenomena such as sharp gradients and singularities. Like the adaptive finite element method, ABI-DNN incorporates an iteration of "solve, estimate, mark, enhancement", which automatically identifies challenging regions and adds new neurons to enhance its capability. A key challenge is to force new neurons to focus on identified regions with limited understanding of their roles in approximation. To address this, we draw inspiration from the finite element basis function and construct the novel Basis-inspired Block (BI-block), to help understand the contribution of each block. With the help of the BI-block and the famous Kolmogorov Superposition Theorem, we first develop a novel fixed network architecture named the Basis-inspired Deep Neural Network (BI-DNN), and then integrate it into the aforementioned adaptive framework to propose the ABI-DNN. Extensive numerical experiments demonstrate that both BI-DNN and ABI-DNN can effectively capture the challenging singularities in target functions. Compared to PINN, BI-DNN attains significantly lower relative errors with a similar number of trainable parameters. When a specified tolerance is set, ABI-DNN can adaptively learn an appropriate architecture that achieves an error comparable to that of BI-DNN with the same structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00636v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Li, Yaqin Zhang, Yunqing Huang, Chenyue Xie, Xueshuang Xiang</dc:creator>
    </item>
    <item>
      <title>A unified framework for Trefftz-like discretization methods</title>
      <link>https://arxiv.org/abs/2412.00806</link>
      <description>arXiv:2412.00806v1 Announce Type: new 
Abstract: This paper presents a unifying framework for Trefftz-like methods, which allows the analysis and construction of discretization methods based on the decomposition into, and coupling of, local and global problems. We apply the framework to provide a comprehensive error analysis for the Embedded Trefftz discontinuous Galerkin method, for a wide range of second-order scalar elliptic partial differential equations and a scalar reaction-advection problem. We also analyze quasi-Trefftz methods with our framework and build bridges to other methods that are similar in virtue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00806v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip L. Lederer, Christoph Lehrenfeld, Paul Stocker, Igor Voulis</dc:creator>
    </item>
    <item>
      <title>A parallel Basis Update and Galerkin Integrator for Tree Tensor Networks</title>
      <link>https://arxiv.org/abs/2412.00858</link>
      <description>arXiv:2412.00858v1 Announce Type: new 
Abstract: Computing the numerical solution to high-dimensional tensor differential equations can lead to prohibitive computational costs and memory requirements. To reduce the memory and computational footprint, dynamical low-rank approximation (DLRA) has proven to be a promising approach. DLRA represents the solution as a low-rank tensor factorization and evolves the resulting low-rank factors in time. A central challenge in DLRA is to find time integration schemes that are robust to the arising small singular values. A robust parallel basis update &amp; Galerkin integrator, which simultaneously evolves all low-rank factors, has recently been derived for matrix differential equations. This work extends the parallel low-rank matrix integrator to Tucker tensors and general tree tensor networks, yielding an algorithm in which all bases and connecting tensors are evolved in parallel over a time step. We formulate the algorithm, provide a robust error bound, and demonstrate the efficiency of the new integrators for problems in quantum many-body physics, uncertainty quantification, and radiative transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00858v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianluca Ceruti, Jonas Kusch, Christian Lubich, Dominik Sulz</dc:creator>
    </item>
    <item>
      <title>Structured Backward Error for the WKB method</title>
      <link>https://arxiv.org/abs/2412.00861</link>
      <description>arXiv:2412.00861v1 Announce Type: new 
Abstract: The classical WKB method (also known as the WKBJ method, the LG method, or the phase integral method) for solving singularly perturbed linear differential equations has never, as far as we know, been looked at from the structured backward error (BEA) point of view. This is somewhat surprising, because a simple computation shows that for some important problems, the WKB method gives the exact solution of a problem of the same structure that can be expressed in finitely many terms. This kind of analysis can be extremely useful in assessing the validity of a solution provided by the WKB method. In this paper we show how to do this and explore some of the consequences, which include a new iterative algorithm to improve the quality of the WKB solution. We also explore a new hybrid method where the potential is approximated by Chebyshev polynomials, which can be implemented in a few lines of Chebfun.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00861v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robert M. Corless, Nicolas Fillion</dc:creator>
    </item>
    <item>
      <title>A Parareal exponential integrator finite element method for linear parabolic equations</title>
      <link>https://arxiv.org/abs/2412.01138</link>
      <description>arXiv:2412.01138v1 Announce Type: new 
Abstract: In this paper, for solving a class of linear parabolic equations in rectangular domains, we have proposed an efficient Parareal exponential integrator finite element method. The proposed method first uses the finite element approximation with continuous multilinear rectangular basis function for spatial discretization, and then takes the Runge-Kutta approach accompanied with Parareal framework for time integration of the resulting semi-discrete system to produce parallel-in-time numerical solution. Under certain regularity assumptions, fully-discrete error estimates in $L^2$-norm are derived for the proposed schemes with random interpolation nodes. Moreover, a fast solver can be provided based on tensor product spectral decomposition and fast Fourier transform (FFT), since the mass and coefficient matrices of the proposed method can be simultaneously diagonalized with an orthogonal matrix. A series of numerical experiments in various dimensions are also presented to validate the theoretical results and demonstrate the excellent performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01138v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianguo Huang, Yuejin Xu</dc:creator>
    </item>
    <item>
      <title>Training Stiff Neural Ordinary Differential Equations with Explicit Exponential Integration Methods</title>
      <link>https://arxiv.org/abs/2412.01181</link>
      <description>arXiv:2412.01181v1 Announce Type: new 
Abstract: Stiff ordinary differential equations (ODEs) are common in many science and engineering fields, but standard neural ODE approaches struggle to accurately learn these stiff systems, posing a significant barrier to widespread adoption of neural ODEs. In our earlier work, we addressed this challenge by utilizing single-step implicit methods for solving stiff neural ODEs. While effective, these implicit methods are computationally costly and can be complex to implement. This paper expands on our earlier work by exploring explicit exponential integration methods as a more efficient alternative. We evaluate the potential of these explicit methods to handle stiff dynamics in neural ODEs, aiming to enhance their applicability to a broader range of scientific and engineering problems. We found the integrating factor Euler (IF Euler) method to excel in stability and efficiency. While implicit schemes failed to train the stiff Van der Pol oscillator, the IF Euler method succeeded, even with large step sizes. However, IF Euler's first-order accuracy limits its use, leaving the development of higher-order methods for stiff neural ODEs an open research problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01181v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colby Fronk, Linda Petzold</dc:creator>
    </item>
    <item>
      <title>Variational formulation based on duality to solve partial differential equations: Use of B-splines and machine learning approximants</title>
      <link>https://arxiv.org/abs/2412.01232</link>
      <description>arXiv:2412.01232v1 Announce Type: new 
Abstract: Many partial differential equations (PDEs) such as Navier--Stokes equations in fluid mechanics, inelastic deformation in solids, and transient parabolic and hyperbolic equations do not have an exact, primal variational structure. Recently, a variational principle based on the dual (Lagrange multiplier) field was proposed. The essential idea in this approach is to treat the given PDE as constraints, and to invoke an arbitrarily chosen auxiliary potential with strong convexity properties to be optimized. This leads to requiring a convex dual functional to be minimized subject to Dirichlet boundary conditions on dual variables, with the guarantee that even PDEs that do not possess a variational structure in primal form can be solved via a variational principle. The vanishing of the first variation of the dual functional is, up to Dirichlet boundary conditions on dual fields, the weak form of the primal PDE problem with the dual-to-primal change of variables incorporated. We derive the dual weak form for the linear, one-dimensional, transient convection-diffusion equation. A Galerkin discretization is used to obtain the discrete equations, with the trial and test functions chosen as linear combination of either RePU activation functions (shallow neural network) or B-spline basis functions; the corresponding stiffness matrix is symmetric. For transient problems, a space-time Galerkin implementation is used with tensor-product B-splines as approximating functions. Numerical results are presented for the steady-state and transient convection-diffusion equation, and transient heat conduction. The proposed method delivers sound accuracy for ODEs and PDEs and rates of convergence are established in the $L^2$ norm and $H^1$ seminorm for the steady-state convection-diffusion problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01232v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N. Sukumar, Amit Acharya</dc:creator>
    </item>
    <item>
      <title>Optimal linear subdivision rules for noisy data</title>
      <link>https://arxiv.org/abs/2412.01287</link>
      <description>arXiv:2412.01287v1 Announce Type: new 
Abstract: Subdivision schemes are iterative processes that recursively refine data by applying subdivision rules. This paper introduces linear subdivision rules tailored to handle noisy data. A key innovation lies in determining the rule coefficients by solving an optimization problem aimed at minimizing the noise variance. The study addresses the general case, allowing for noise correlation among data with a non-uniform distribution. In fact, we show that the subdivision rules, proposed in [S. L\'opez-Ure\~na and D. F. Y\'a\~nez, J. Sci. Comput., 100(1) (2024)], are optimal for uncorrelated noise with non-uniform variance. Numerical experiments are provided to demonstrate the effectiveness of these optimal rules compared to other subdivision rules designed for noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01287v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio L\'opez Ure\~na, Dionisio F. Y\'a\~nez</dc:creator>
    </item>
    <item>
      <title>Virtual finite element and hyperbolic problems: the PAMPA algorithm</title>
      <link>https://arxiv.org/abs/2412.01341</link>
      <description>arXiv:2412.01341v1 Announce Type: new 
Abstract: In this paper, we explore the use of the Virtual Element Method concepts to solve scalar and system hyperbolic problems on general polygonal grids. The new schemes stem from the active flux approach \cite{AF1}, which combines the usage of point values at the element boundaries with an additional degree of freedom representing the average of the solution within each control volume. Along the lines of the family of residual distribution schemes introduced in \cite{Abgrall_AF,abgrall2023activefluxtriangularmeshes} to bridge the active flux technique, we devise novel third order accurate methods that rely on the VEM technology to discretize gradients of the numerical solution by means of a polynomial-free approximation, hence adopting a virtual basis that is locally defined for each element. The obtained discretization is globally continuous, and for nonlinear problems it needs a stabilization which is provided by the \textit{a posteriori} MOOD paradigm \cite{Mood1}. This is applied to both point and average values of the discrete solution. We show applications to scalar problems, as well as to the acoustics and Euler equations in 2D. The accuracy and the robustness of the proposed schemes are assessed against a suite of benchmarks involving smooth solutions, shock waves and other discontinuities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01341v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>R\'emi Abgrall, Yongle Liu, Walter Boscheri</dc:creator>
    </item>
    <item>
      <title>A deformation-based framework for learning solution mappings of PDEs defined on varying domains</title>
      <link>https://arxiv.org/abs/2412.01379</link>
      <description>arXiv:2412.01379v1 Announce Type: new 
Abstract: In this work, we establish a deformation-based framework for learning solution mappings of PDEs defined on varying domains. The union of functions defined on varying domains can be identified as a metric space according to the deformation, then the solution mapping is regarded as a continuous metric-to-metric mapping, and subsequently can be represented by another continuous metric-to-Banach mapping using two different strategies, referred to as the D2D framework and the D2E framework, respectively. We point out that such a metric-to-Banach mapping can be learned by neural networks, hence the solution mapping is accordingly learned. With this framework, a rigorous convergence analysis is built for the problem of learning solution mappings of PDEs on varying domains. As the theoretical framework holds based on several pivotal assumptions which need to be verified for a given specific problem, we study the star domains as a typical example, and other situations could be similarly verified. There are three important features of this framework: (1) The domains under consideration are not required to be diffeomorphic, therefore a wide range of regions can be covered by one model provided they are homeomorphic. (2) The deformation mapping is unnecessary to be continuous, thus it can be flexibly established via combining a primary identity mapping and a local deformation mapping. This capability facilitates the resolution of large systems where only local parts of the geometry undergo change. (3) If a linearity-preserving neural operator such as MIONet is adopted, this framework still preserves the linearity of the surrogate solution mapping on its source term for linear PDEs, thus it can be applied to the hybrid iterative method. We finally present several numerical experiments to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01379v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanshan Xiao, Pengzhan Jin, Yifa Tang</dc:creator>
    </item>
    <item>
      <title>Nonuniqueness of lattice Boltzmann schemes derived from finite difference methods</title>
      <link>https://arxiv.org/abs/2412.01494</link>
      <description>arXiv:2412.01494v1 Announce Type: new 
Abstract: Recently, the construction of finite difference schemes from lattice Boltzmann schemes has been rigorously analyzed [Bellotti et al. (2022), Numer. Math. 152, pp. 1-40]. It is thus known that any lattice Boltzmann scheme can be expressed in terms of a corresponding multi-step finite difference scheme on the conserved variables. In the present work, we provide counterexamples for the conjecture that any multi-step finite difference scheme has a unique lattice Boltzmann formulation. Based on that, we indicate the existence of equivalence classes for discretized relaxation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01494v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eliane Kummer, Stephan Simonis</dc:creator>
    </item>
    <item>
      <title>A note on indefinite matrix splitting and preconditioning</title>
      <link>https://arxiv.org/abs/2412.01554</link>
      <description>arXiv:2412.01554v1 Announce Type: new 
Abstract: The solution of systems of linear(ized) equations lies at the heart of many problems in Scientific Computing. In particular for systems of large dimension, iterative methods are a primary approach. Stationary iterative methods are generally based on a matrix splitting, whereas for polynomial iterative methods such as Krylov subspace iteration, the splitting matrix is the preconditioner. The smoother in a multigrid method is generally a stationary or polynomial iteration. Here we consider real symmetric indefinite and complex Hermitian indefinite coefficient matrices and prove that no splitting matrix can lead to a contractive stationary iteration unless the inertia is exactly preserved. This has consequences for preconditioning for indefinite systems and smoothing for multigrid as we further describe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01554v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andy Wathen</dc:creator>
    </item>
    <item>
      <title>A dynamic implicit 3D material point-to-rigid body contact approach for large deformation analysis</title>
      <link>https://arxiv.org/abs/2412.01565</link>
      <description>arXiv:2412.01565v1 Announce Type: new 
Abstract: Accurate and robust modelling of large deformation three dimensional contact interaction is an important area of engineering, but it is also challenging from a computational mechanics perspective. This is particularly the case when there is significant interpenetration and evolution of the contact surfaces, such as the case of a relatively rigid body interacting with a highly deformable body. The numerical challenges come from several non-linear sources: large deformation mechanics, history dependent material behaviour and slip/stick frictional contact. In this paper the Material Point Method (MPM) is adopted to represent the deformable material, combined with a discretised rigid body which provides an accurate representation of the contact surface. The three dimensional interaction between the bodies is detected though the use of domains associated with each material point. This provides a general and consistent representation of the extent of the deformable body without introducing boundary representation in the material point method. The dynamic governing equations allows the trajectory of the rigid body to evolve based on the interaction with the deformable body and the governing equations are solved within an efficient implicit framework. The performance of the method is demonstrated on a number of benchmark problems with analytical solutions. The method is also applied to the specific case of soil-structure interaction, using geotechnical centrifuge experimental data that confirms the veracity of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01565v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert E. Bird, Giuliano Pretti, William M. Coombs, Charles E. Augarde, Yaseen U. Sharif, Michael J. Brown, Gareth Carter, Catriona Macdonald, Kirstin Johnson</dc:creator>
    </item>
    <item>
      <title>Cycle-Free Polytopal Mesh Sweeping for Boltzmann Transport</title>
      <link>https://arxiv.org/abs/2412.01660</link>
      <description>arXiv:2412.01660v1 Announce Type: new 
Abstract: We introduce a novel property of bounded Voronoi tessellations that
  enables cycle-free mesh sweeping algorithms. We prove that a
  topological sort of the dual graph of any Voronoi tessellation is
  feasible in any flow direction and dimension, allowing
  straightforward application to discontinuous Galerkin (DG)
  discretisations of first-order hyperbolic partial differential
  equations and the Boltzmann Transport Equation (BTE) without
  requiring flux-cycle corrections.
  We also present an efficient algorithm to perform the topological
  sort on the dual mesh nodes, ensuring a valid sweep ordering. This
  result expands the applicability of DG methods for transport
  problems on polytopal meshes by providing a robust framework for
  scalable, parallelised solutions. To illustrate its effectiveness,
  we conduct a series of computational experiments showcasing a DG
  scheme for BTE, demonstrating both computational efficiency and
  adaptability to complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01660v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ansar Calloo, Matthew Evans, Henry Lockyer, Fran\c{c}ois Madiot, Tristan Pryer, Luca Zanetti</dc:creator>
    </item>
    <item>
      <title>Deep Guess acceleration for explainable image reconstruction in sparse-view CT</title>
      <link>https://arxiv.org/abs/2412.01703</link>
      <description>arXiv:2412.01703v1 Announce Type: new 
Abstract: Sparse-view Computed Tomography (CT) is an emerging protocol designed to reduce X-ray dose radiation in medical imaging. Traditional Filtered Back Projection algorithm reconstructions suffer from severe artifacts due to sparse data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms, though better at mitigating noise through regularization, are too computationally costly for clinical use. This paper introduces a novel technique, denoted as the Deep Guess acceleration scheme, using a trained neural network both to quicken the regularized MBIR and to enhance the reconstruction accuracy. We integrate state-of-the-art deep learning tools to initialize a clever starting guess for a proximal algorithm solving a non-convex model and thus computing an interpretable solution image in a few iterations. Experimental results on real CT images demonstrate the Deep Guess effectiveness in (very) sparse tomographic protocols, where it overcomes its mere variational counterpart and many data-driven approaches at the state of the art. We also consider a ground truth-free implementation and test the robustness of the proposed framework to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01703v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Loli Piccolomini, Davide Evangelista, Elena Morotti</dc:creator>
    </item>
    <item>
      <title>QuAKE: Speeding up Model Inference Using Quick and Approximate Kernels for Exponential Non-Linearities</title>
      <link>https://arxiv.org/abs/2412.00408</link>
      <description>arXiv:2412.00408v1 Announce Type: cross 
Abstract: As machine learning gets deployed more and more widely, and model sizes continue to grow, improving computational efficiency during model inference has become a key challenge. In many commonly used model architectures, including Transformers, a significant portion of the inference computation is comprised of exponential non-linearities such as Softmax. In this work, we develop QuAKE, a collection of novel operators that leverage certain properties of IEEE-754 floating point representations to quickly approximate the exponential function without requiring specialized hardware, extra memory, or precomputation. We propose optimizations that enhance the efficiency of QuAKE in commonly used exponential non-linearities such as Softmax, GELU, and the Logistic function. Our benchmarks demonstrate substantial inference speed improvements between 10% and 35% on server CPUs, and 5% and 45% on embedded and mobile-scale CPUs for a variety of model architectures and sizes. Evaluations of model performance on standard datasets and tasks from various domains show that QuAKE operators are able to provide sizable speed benefits with little to no loss of performance on downstream tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00408v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sai Kiran Narayanaswami, Gopalakrishnan Srinivasan, Balaraman Ravindran</dc:creator>
    </item>
    <item>
      <title>Convergence rate in the splitting-up method for rough differential equations</title>
      <link>https://arxiv.org/abs/2412.00432</link>
      <description>arXiv:2412.00432v1 Announce Type: cross 
Abstract: In this note we construct solutions to rough differential equations ${\rm d} Y = f(Y) \,{\rm d} X$ with a driver $X \in C^\alpha([0,T];\mathbb{R}^d)$, $\frac13 &lt; \alpha \le \frac12$, using a splitting-up scheme. We show convergence of our scheme to solutions in the sense of Davie by a new argument and give a rate of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00432v1</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter H. C. Pang</dc:creator>
    </item>
    <item>
      <title>Two Models for Surface Segmentation using the Total Variation of the Normal Vector</title>
      <link>https://arxiv.org/abs/2412.00445</link>
      <description>arXiv:2412.00445v1 Announce Type: cross 
Abstract: We consider the problem of surface segmentation, where the goal is to partition a surface represented by a triangular mesh. The segmentation is based on the similarity of the normal vector field to a given set of label vectors. We propose a variational approach and compare two different regularizers, both based on a total variation measure. The first regularizer penalizes the total variation of the assignment function directly, while the second regularizer penalizes the total variation in the label space. In order to solve the resulting optimization problems, we use variations of the split Bregman (ADMM) iteration adapted to the problem at hand. While computationally more expensive, the second regularizer yields better results in our experiments, in particular it removes noise more reliably in regions of constant curvature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00445v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lukas Baumg\"artner, Ronny Bergmann, Roland Herzog, Stephan Schmidt, Manuel Wei{\ss}</dc:creator>
    </item>
    <item>
      <title>Personal Sound Zones and Shielded Localized Communication through Active Acoustic Control</title>
      <link>https://arxiv.org/abs/2412.00456</link>
      <description>arXiv:2412.00456v1 Announce Type: cross 
Abstract: In this paper, we present a time domain extension of our strategy on manipulating radiated scalar Helmholtz fields and discuss two important applied scenarios, namely (1) creating personal sound zones inside a bounded domain and (2) shielded localized communication. Our strategy is based on the authors' previous works establishing the possibility and stability of controlling acoustic fields using an array of almost non-radiating coupling sources and presents a detailed Fourier synthesis approach towards a time-domain effect. We require that the array of acoustic sources creates the desired fields on the control regions while maintaining a zero field beyond a larger circumscribed sphere. This paper recalls the main theoretical results then presents the underlying Fourier synthesis paradigm and show, through relevant simulations, the performance of our strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00456v1</guid>
      <category>cs.SD</category>
      <category>cs.NA</category>
      <category>eess.AS</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Neil Jerome A. Egarguin, Daniel Onofrei</dc:creator>
    </item>
    <item>
      <title>Resilience Against Soft Faults through Adaptivity in Spectral Deferred Correction</title>
      <link>https://arxiv.org/abs/2412.00529</link>
      <description>arXiv:2412.00529v1 Announce Type: cross 
Abstract: As supercomputers grow in hardware complexity, their susceptibility to faults increases and measures need to be taken to ensure the correctness of results. Some numerical algorithms have certain characteristics that allow them to recover from some types of faults. It has been demonstrated that adaptive Runge-Kutta methods provide resilience against transient faults without adding computational cost. Using recent advances in adaptive step size selection for spectral deferred correction (SDC), an iterative numerical time stepping scheme that can produce methods of arbitrary order, we show that adaptive SDC can also detect and correct transient faults. Its performance is found to be comparable to that of the dedicated resilience strategy Hot Rod.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00529v1</guid>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Baumann, Sebastian G\"otschel, Thibaut Lunet, Daniel Ruprecht, Robert Speck</dc:creator>
    </item>
    <item>
      <title>Operator learning regularization for macroscopic permeability prediction in dual-scale flow problem</title>
      <link>https://arxiv.org/abs/2412.00579</link>
      <description>arXiv:2412.00579v1 Announce Type: cross 
Abstract: Liquid composites moulding is an important manufacturing technology for fibre reinforced composites, due to its cost-effectiveness. Challenges lie in the optimisation of the process due to the lack of understanding of key characteristic of textile fabrics - permeability. The problem of computing the permeability coefficient can be modelled as the well-known Stokes-Brinkman equation, which introduces a heterogeneous parameter $\beta$ distinguishing macropore regions and fibre-bundle regions. In the present work, we train a Fourier neural operator to learn the nonlinear map from the heterogeneous coefficient $\beta$ to the velocity field $u$, and recover the corresponding macroscopic permeability $K$. This is a challenging inverse problem since both the input and output fields span several order of magnitudes, we introduce different regularization techniques for the loss function and perform a quantitative comparison between them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00579v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christina Runkel, Sinan Xiao, Nicolas Boull\'e, Yang Chen</dc:creator>
    </item>
    <item>
      <title>Numerical Analysis of Cavitation Dynamics on Free Ogee Spillways Using the Volume of Fluid (VOF) Method</title>
      <link>https://arxiv.org/abs/2412.00695</link>
      <description>arXiv:2412.00695v1 Announce Type: cross 
Abstract: Simulating complex hydraulic conditions, particularly two-phase flows over spillway chutes, can be achieved with high accuracy using three-dimensional numerical models. This study investigates the potential for vacuum generation and cavitation phenomena on the Aghchai Dam service spillway through numerical simulations conducted in Flow-3D. The analysis focuses on two specific flow rates, 4400 and 1065 cubic meters per second, as determined by experimental data. The Volume of Fluid (VOF) method is employed to accurately calculate the free surface flow. Simulation results at a discharge rate of 4400 cubic meters per second indicate a high likelihood of cavitation at critical locations, including the ogee curve and the angle transition in the chute channel. These areas require specific mitigation measures to prevent cavitation-induced damage. In contrast, at the lower flow rate of 1065 cubic meters per second, the risk of cavitation is minimal due to reduced flow velocity and the absence of flow separation from the bed. The numerical findings align closely with empirical observations, demonstrating the reliability of the simulation approach in predicting cavitation behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00695v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parvaneh Nikrou, Sajjad Pirboudaghi</dc:creator>
    </item>
    <item>
      <title>Construction of generalized samplets in Banach spaces</title>
      <link>https://arxiv.org/abs/2412.00954</link>
      <description>arXiv:2412.00954v1 Announce Type: cross 
Abstract: Recently, samplets have been introduced as localized discrete signed measures which are tailored to an underlying data set. Samplets exhibit vanishing moments, i.e., their measure integrals vanish for all polynomials up to a certain degree, which allows for feature detection and data compression. In the present article, we extend the different construction steps of samplets to functionals in Banach spaces more general than point evaluations. To obtain stable representations, we assume that these functionals form frames with square-summable coefficients or even Riesz bases with square-summable coefficients. In either case, the corresponding analysis operator is injective and we obtain samplet bases with the desired properties by means of constructing an isometry of the analysis operator's image. Making the assumption that the dual of the Banach space under consideration is imbedded into the space of compactly supported distributions, the multilevel hierarchy for the generalized samplet construction is obtained by spectral clustering of a similarity graph for the functionals' supports. Based on this multilevel hierarchy, generalized samplets exhibit vanishing moments with respect to a given set of primitives within the Banach space. We derive an abstract localization result for the generalized samplet coefficients with respect to the samplets' support sizes and the approximability of the Banach space elements by the chosen primitives. Finally, we present three examples showcasing the generalized samplet framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00954v1</guid>
      <category>math.FA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Balazs, Michael Multerer</dc:creator>
    </item>
    <item>
      <title>Differential estimates for fast first-order multilevel nonconvex optimisation</title>
      <link>https://arxiv.org/abs/2412.01481</link>
      <description>arXiv:2412.01481v1 Announce Type: cross 
Abstract: With a view on bilevel and PDE-constrained optimisation, we develop iterative estimates $\widetilde{F'}(x^k)$ of $F'(x^k)$ for compositions $F :=J \circ S$, where $S$ is the solution mapping of the inner optimisation problem or PDE. The idea is to form a single-loop method by interweaving updates of the iterate $x^k$ by an outer optimisation method, with updates of the estimate by single steps of standard optimisation methods and linear system solvers. When the inner methods satisfy simple tracking inequalities, the differential estimates can almost directly be employed in standard convergence proofs for general forward-backward type methods. We adapt those proofs to a general inexact setting in normed spaces, that, besides our differential estimates, also covers mismatched adjoints and unreachable optimality conditions in measure spaces. As a side product of these efforts, we provide improved convergence results for nonconvex Primal-Dual Proximal Splitting (PDPS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01481v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Dizon, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>The Kolmogorov Superposition Theorem can Break the Curse of Dimensionality When Approximating High Dimensional Functions</title>
      <link>https://arxiv.org/abs/2112.09963</link>
      <description>arXiv:2112.09963v5 Announce Type: replace 
Abstract: We explain how to use Kolmogorov Superposition Theorem (KST) to break the curse of dimensionality when approximating a dense class of multivariate continuous functions. We first show that there is a class of functions called Kolmogorov-Lipschitz (KL) continuous in $C([0,1]^d)$ which can be approximated by a special ReLU neural network of two hidden layers with a dimension independent approximation rate $O(1/n)$ with approximation constant increasing quadratically in $d$. The number of parameters used in such neural network approximation equals to $(6d+2)n$. Next we introduce KB-splines by using linear B-splines to replace the outer function and smooth the KB-splines to have the so-called LKB-splines as the basis for approximation. Our numerical evidence shows that the curse of dimensionality is broken in the following sense: When using the standard discrete least squares (DLS) method to approximate a continuous function, there exists a pivotal set of points in $[0,1]^d$ with size at most $O(nd)$ such that the rooted mean squares error (RMSE) from the DLS based on the pivotal set is similar to the RMSE of the DLS based on the original set with size $O(n^d)$. The pivotal point set is chosen by using matrix cross approximation technique and the number of LKB-splines used for approximation is the same as the size of the pivotal data set. Therefore, we do not need too many basis functions as well as too many function values to approximate a high dimensional continuous function $f$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.09963v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming-Jun Lai, Zhaiming Shen</dc:creator>
    </item>
    <item>
      <title>Linear stability of discrete shock profiles for systems of conservation laws</title>
      <link>https://arxiv.org/abs/2311.02507</link>
      <description>arXiv:2311.02507v3 Announce Type: replace 
Abstract: We prove the linear orbital stability of spectrally stable stationary discrete shock profiles for conservative finite difference schemes applied to systems of conservation laws. The proof relies on an accurate description of the pointwise asymptotic behavior of the Green's function associated with those discrete shock profiles, improving on the result of Lafitte-Godillon [God03]. The main novelty of this stability result is that it applies to a fairly large family of schemes that introduce some artificial possibly high-order viscosity. The result is obtained under a sharp spectral assumption rather than by imposing a smallness assumption on the shock amplitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02507v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Coeuret</dc:creator>
    </item>
    <item>
      <title>Improving Efficiency of Parallel Across the Method Spectral Deferred Corrections</title>
      <link>https://arxiv.org/abs/2403.18641</link>
      <description>arXiv:2403.18641v2 Announce Type: replace 
Abstract: Parallel-across-the method time integration can provide small scale parallelism when solving initial value problems. Spectral deferred corrections (SDC) with a diagonal sweeper, which is closely related to iterated Runge-Kutta methods proposed by Van der Houwen and Sommeijer, can use a number of threads equal to the number of quadrature nodes in the underlying collocation method. However, convergence speed, efficiency and stability depends critically on the used coefficients. Previous approaches have used numerical optimization to find good parameters. Instead, we propose an ansatz that allows to find optimal parameters analytically. We show that the resulting parallel SDC methods provide stability domains and convergence order very similar to those of well established serial SDC variants. Using a model for computational cost that assumes 80% efficiency of an implementation of parallel SDC we show that our variants are competitive with serial SDC, previously published parallel SDC coefficients as well as Picard iteration, explicit RKM-4 and an implicit fourth-order diagonally implicit Runge-Kutta method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18641v2</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gayatri \v{C}aklovi\'c, Thibaut Lunet, Sebastian G\"otschel, Daniel Ruprecht</dc:creator>
    </item>
    <item>
      <title>A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints</title>
      <link>https://arxiv.org/abs/2304.03641</link>
      <description>arXiv:2304.03641v3 Announce Type: replace-cross 
Abstract: Nonsmooth composite optimization with orthogonality constraints has a wide range of applications in statistical learning and data science. However, this problem is challenging due to its nonsmooth objective and computationally expensive, non-convex constraints. In this paper, we propose a new approach called \textbf{OBCD}, which leverages Block Coordinate Descent to address these challenges. \textbf{OBCD} is a feasible method with a small computational footprint. In each iteration, it updates $k$ rows of the solution matrix, where $k \geq 2$, by globally solving a small nonsmooth optimization problem under orthogonality constraints. We prove that the limiting points of \textbf{OBCD}, referred to as (global) block-$k$ stationary points, offer stronger optimality than standard critical points. Furthermore, we show that \textbf{OBCD} converges to $\epsilon$-block-$k$ stationary points with an ergodic convergence rate of $\mathcal{O}(1/\epsilon)$. Additionally, under the Kurdyka-Lojasiewicz (KL) inequality, we establish the non-ergodic convergence rate of \textbf{OBCD}. We also extend \textbf{OBCD} by incorporating breakpoint searching methods for subproblem solving and greedy strategies for working set selection. Comprehensive experiments demonstrate the superior performance of our approach across various tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03641v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>A thresholding algorithm to Willmore-type flows via fourth order linear parabolic equation</title>
      <link>https://arxiv.org/abs/2311.13155</link>
      <description>arXiv:2311.13155v5 Announce Type: replace-cross 
Abstract: We propose a thresholding algorithm to Willmore-type flows in $\mathbb{R}^N$. This algorithm is constructed based on the asymptotic expansion of the solution to the initial value problem for a fourth order linear parabolic partial differential equation whose initial data is the indicator function on the compact set $\Omega_0$. The main results of this paper demonstrate that the boundary $\partial\Omega(t)$ of the new set $\Omega(t)$, generated by our algorithm, is included in $O(t)$-neighborhood of $\partial\Omega_0$ for small $t&gt;0$ and that the normal velocity from $ \partial\Omega_0 $ to $ \partial\Omega(t) $ is nearly equal to the $L^2$-gradient of Willmore-type energy for small $ t&gt;0 $. Finally, numerical examples of planar curves governed by the Willmore flow are provided by using our thresholding algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13155v5</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katsuyuki Ishii, Yoshihito Kohsaka, Nobuhito Miyake, Koya Sakakibara</dc:creator>
    </item>
    <item>
      <title>Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"</title>
      <link>https://arxiv.org/abs/2402.08711</link>
      <description>arXiv:2402.08711v3 Announce Type: replace-cross 
Abstract: A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in ``Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations". They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon &gt; 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08711v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Paulin, Peter A. Whalley</dc:creator>
    </item>
    <item>
      <title>Greedy Learning to Optimize with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2406.00260</link>
      <description>arXiv:2406.00260v4 Announce Type: replace-cross 
Abstract: Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant GPU memory usage. We parameterize the update such that parameter learning corresponds to solving a convex optimization problem at each iteration. In particular, we explore preconditioned gradient descent with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithm, convergence in the training set is proved even when the preconditioner is neither symmetric nor positive definite. Convergence on a class of unseen functions is also obtained, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioners demonstrate improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00260v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Fahy, Mohammad Golbabaee, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>A Novel Use of Pseudospectra in Mathematical Biology: Understanding HPA Axis Sensitivity</title>
      <link>https://arxiv.org/abs/2408.00845</link>
      <description>arXiv:2408.00845v2 Announce Type: replace-cross 
Abstract: The Hypothalamic-Pituitary-Adrenal (HPA) axis is a major neuroendocrine system, and its dysregulation is implicated in various diseases. This system also presents interesting mathematical challenges for modeling. We consider a nonlinear delay differential equation model and calculate pseudospectra of three different linearizations: a time-dependent Jacobian, linearization around the limit cycle, and dynamic mode decomposition (DMD) analysis of Koopman operators (global linearization). The time-dependent Jacobian provided insight into experimental phenomena, explaining why rats respond differently to perturbations during corticosterone secretion's upward versus downward slopes. We developed new mathematical techniques for the other two linearizations to calculate pseudospectra on Banach spaces and apply DMD to delay differential equations, respectively. These methods helped establish local and global limit cycle stability and study transients. Additionally, we discuss using pseudospectra to substantiate the model in experimental contexts and establish bio-variability via data-driven methods. This work is the first to utilize pseudospectra to explore the HPA axis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00845v2</guid>
      <category>math.SP</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.QM</category>
      <category>q-bio.SC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Catherine Drysdale, Matthew J. Colbrook</dc:creator>
    </item>
    <item>
      <title>Rectangular finite elements for modeling the mechanical behavior of auxetic materials</title>
      <link>https://arxiv.org/abs/2410.15922</link>
      <description>arXiv:2410.15922v2 Announce Type: replace-cross 
Abstract: This paper is devoted to the exploration of rectangular finite elements' ability to model the stress-strain state of isotropic and orthotropic materials with a negative Poisson's ratio, known as auxetic materials. By employing linear elasticity in the plane stress formulation, the research evaluates the linear compatible and the quadratic incompatible shape functions in describing the mechanical behavior of auxetic materials within a displacement-based finite element method under static shear conditions. Additionally, the analytical expression of an incompatible rectangular finite element is adapted to accommodate an orthotropic case. Hexachiral and re-entrant honeycomb structures, characterized by auxetic behavior, are modeled as continuous media with homogenized properties using analytical expressions for their effective material constants. The findings reveal that while the classical shape functions may be sufficient for displacement modeling, they are ineffective in accurately predicting the characteristic auxetic behavior and stress distributions in auxetic materials. In contrast, the incompatible shape functions prove to be effective in providing appropriate stress modeling in both cases. This work underscores the relevance of the incompatible rectangular finite elements in the analysis of advanced materials with a negative Poisson's ratio. It provides computationally efficient approaches for the calculation of auxetic honeycomb structures and multilayer composites based on them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15922v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. V. Mazaev</dc:creator>
    </item>
    <item>
      <title>A Simple Introduction to the SiMPL Method for Density-Based Topology Optimization</title>
      <link>https://arxiv.org/abs/2411.19421</link>
      <description>arXiv:2411.19421v2 Announce Type: replace-cross 
Abstract: We introduce a novel method for solving density-based topology optimization problems: Sigmoidal Mirror descent with a Projected Latent variable (SiMPL). The SiMPL method (pronounced as "the simple method") optimizes a design using only first-order derivative information of the objective function. The bound constraints on the density field are enforced with the help of the (negative) Fermi--Dirac entropy, which is also used to define a non-symmetric distance function called a Bregman divergence on the set of admissible designs. This Bregman divergence leads to a simple update rule that is further simplified with the help of a so-called latent variable. Because the SiMPL method involves discretizing the latent variable, it produces a sequence of pointwise-feasible iterates, even when high-order finite elements are used in the discretization. Numerical experiments demonstrate that the method outperforms other popular first-order optimization algorithms. To outline the general applicability of the technique, we include examples with (self-load) compliance minimization and compliant mechanism optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19421v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dohyun Kim, Boyan Stefanov Lazarov, Thomas M. Surowiec, Brendan Keith</dc:creator>
    </item>
  </channel>
</rss>
