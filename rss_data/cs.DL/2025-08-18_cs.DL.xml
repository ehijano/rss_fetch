<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Aug 2025 04:07:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Citation accuracy, citation noise, and citation bias: A foundation of citation analysis</title>
      <link>https://arxiv.org/abs/2508.12735</link>
      <description>arXiv:2508.12735v1 Announce Type: new 
Abstract: Citation analysis is widely used in research evaluation to assess the impact of scientific papers. These analyses rest on the assumption that citation decisions by authors are accurate, representing flow of knowledge from cited to citing papers. However, in practice, researchers often cite for reasons other than attributing intellectual credit to previous research. Citations made for rhetorical reasons or without reading the cited work compromise the value of citations as instrument for research evaluation. Past research on threats to the accuracy of citations has mainly focused on citation bias as the primary concern. In this paper, we argue that citation noise - the undesirable variance in citation decisions - represents an equally critical but underexplored challenge in citation analysis. We define and differentiate two types of citation noise: citation level noise and citation pattern noise. Each type of noise is described in terms of how it arises and the specific ways it can undermine the validity of citation-based research assessments. By conceptually differing citation noise from citation accuracy and citation bias, we propose a framework for the foundation of citation analysis. We discuss strategies and interventions to minimize citation noise, aiming to improve the reliability and validity of citation analysis in research evaluation. We recommend that the current professional reform movement in research evaluation such as the Coalition for Advancing Research Assessment (CoARA) pick up these strategies and interventions as an additional building block for careful, responsible use of bibliometric indicators in research evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12735v1</guid>
      <category>cs.DL</category>
      <category>stat.AP</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lutz Bornmann, Christian Leibel</dc:creator>
    </item>
    <item>
      <title>An open framework for archival, reproducible, and transparent science</title>
      <link>https://arxiv.org/abs/2504.08171</link>
      <description>arXiv:2504.08171v2 Announce Type: replace 
Abstract: Digital computational outputs are now ubiquitous in the research workflow and the way in which these data are stored and cataloged is becoming more standardized across fields of research. However, even with accessible data and code, the barrier to recreating figures and reproducing scientific findings remains high. What is generally missing is the computational environment and associated pipelines in which the data and code are executed to generate figures. The archival, reproducible, and transparent science (ARTS) open framework incorporates containers, version control systems, and persistent archives through which all data, code, and figures related to a research project can be stored together, easily recreated, and serve as an accessible platform for long-term sharing and validation. If the underlying principles behind this framework are broadly adopted, it will improve the reproducibility and transparency of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08171v2</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sabar Dasgupta, Paul Nuyujukian</dc:creator>
    </item>
    <item>
      <title>Behind the Byline: A Large-Scale Study of Scientific Author Contributions</title>
      <link>https://arxiv.org/abs/2505.06721</link>
      <description>arXiv:2505.06721v2 Announce Type: replace 
Abstract: Understanding how co-authors distribute credit is critical for accurately assessing scholarly collaboration. In this study, we uncover the implicit structures within scientific teamwork by systematically analyzing author contributions across a large corpus of research publications. We introduce a computational framework designed to convert free-text contribution statements into 14 standardized CRediT categories, identifying clear and consistent positional patterns in task assignments. By analyzing over 400,000 scientific articles from prominent sources such as PLOS One and Nature, we extracted and standardized more than 5.6 million author-task assignments corresponding to 1.58 million author mentions. Our analysis reveals substantial disparities in workload distribution. Notably, in small teams with three co-authors, the most engaged contributor performs over three times more tasks than the least engaged, a disparity that grows linearly with team size. This demonstrates a consistent pattern of central and peripheral roles within modern collaborative teams. Moreover, our analysis shows distinct positional biases in task allocation: technical responsibilities, such as software development and formal analysis, broadly fall to authors positioned earlier in the author list, whereas managerial tasks, including supervision and funding acquisition, increasingly concentrate among authors positioned toward the end. This gradient underscores a significant division of labor, where early-listed authors mainly undertake most hands-on activities. In contrast, senior authors mostly assume roles involving leadership and oversight. Our findings highlight the structured and hierarchical organization within scholarly collaborations, providing deeper insights into the specific roles and dynamics that govern academic teamwork</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06721v2</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Itai Assraf, Michael Fire</dc:creator>
    </item>
    <item>
      <title>Exploring Scholarly Data by Semantic Query on Knowledge Graph Embedding Space</title>
      <link>https://arxiv.org/abs/1909.08191</link>
      <description>arXiv:1909.08191v3 Announce Type: replace-cross 
Abstract: The trends of open science have enabled several open scholarly datasets which include millions of papers and authors. Managing, exploring, and utilizing such large and complicated datasets effectively are challenging. In recent years, the knowledge graph has emerged as a universal data format for representing knowledge about heterogeneous entities and their relationships. The knowledge graph can be modeled by knowledge graph embedding methods, which represent entities and relations as embedding vectors in semantic space, then model the interactions between these embedding vectors. However, the semantic structures in the knowledge graph embedding space are not well-studied, thus knowledge graph embedding methods are usually only used for knowledge graph completion but not data representation and analysis. In this paper, we propose to analyze these semantic structures based on the well-studied word embedding space and use them to support data exploration. We also define the semantic queries, which are algebraic operations between the embedding vectors in the knowledge graph embedding space, to solve queries such as similarity and analogy between the entities on the original datasets. We then design a general framework for data exploration by semantic queries and discuss the solution to some traditional scholarly data exploration tasks. We also propose some new interesting tasks that can be solved based on the uncanny semantic structures of the embedding space.</description>
      <guid isPermaLink="false">oai:arXiv.org:1909.08191v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hung Nghiep Tran, Atsuhiro Takasu</dc:creator>
    </item>
  </channel>
</rss>
