<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 03:47:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Edge Deployment of Small Language Models, a comprehensive comparison of CPU, GPU and NPU backends</title>
      <link>https://arxiv.org/abs/2511.22334</link>
      <description>arXiv:2511.22334v1 Announce Type: new 
Abstract: Edge computing processes data where it is generated, enabling faster decisions, lower bandwidth usage, and improved privacy. However, edge devices typically operate under strict constraints on processing power, memory, and energy consumption, making them unsuitable for large language models (LLMs). Fortunately, Small Language Models (SLMs) offer lightweight alternatives that bring AI inference to resource-constrained environments by significantly reducing computational cost while remaining suitable for specialization and customization. In this scenario, selecting the hardware platform that best balances performance and efficiency for SLM inference is challenging due to strict resource limitations. To address this issue, this study evaluates the inference performance and energy efficiency of commercial CPUs (Intel and ARM), GPUs (NVIDIA), and NPUs (RaiderChip) for running SLMs. GPUs, the usual platform of choice, are compared against commercial NPUs and recent multi-core CPUs. While NPUs leverage custom hardware designs optimized for computation, modern CPUs increasingly incorporate dedicated features targeting language-model workloads. Using a common execution framework and a suite of state-of-the-art SLMs, we analyze both maximum achievable performance and processing and energy efficiency across commercial solutions available for each platform. The results indicate that specialized backends outperform general-purpose CPUs, with NPUs achieving the highest performance by a wide margin. Bandwidth normalization proves essential for fair cross-architecture comparisons. Although low-power ARM processors deliver competitive results when energy usage is considered, metrics that combine performance and power (such as EDP) again highlight NPUs as the dominant architecture. These findings show that designs optimized for both efficiency and performance offer a clear advantage for edge workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22334v1</guid>
      <category>cs.PF</category>
      <category>cs.AI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Prieto, Pablo Abad</dc:creator>
    </item>
    <item>
      <title>What Is the Optimal Ranking Score Between Precision and Recall? We Can Always Find It and It Is Rarely $F_1$</title>
      <link>https://arxiv.org/abs/2511.22442</link>
      <description>arXiv:2511.22442v1 Announce Type: new 
Abstract: Ranking methods or models based on their performance is of prime importance but is tricky because performance is fundamentally multidimensional. In the case of classification, precision and recall are scores with probabilistic interpretations that are both important to consider and complementary. The rankings induced by these two scores are often in partial contradiction. In practice, therefore, it is extremely useful to establish a compromise between the two views to obtain a single, global ranking. Over the last fifty years or so,it has been proposed to take a weighted harmonic mean, known as the F-score, F-measure, or $F_\beta$. Generally speaking, by averaging basic scores, we obtain a score that is intermediate in terms of values. However, there is no guarantee that these scores lead to meaningful rankings and no guarantee that the rankings are good tradeoffs between these base scores. Given the ubiquity of $F_\beta$ scores in the literature, some clarification is in order. Concretely: (1) We establish that $F_\beta$-induced rankings are meaningful and define a shortest path between precision- and recall-induced rankings. (2) We frame the problem of finding a tradeoff between two scores as an optimization problem expressed with Kendall rank correlations. We show that $F_1$ and its skew-insensitive version are far from being optimal in that regard. (3) We provide theoretical tools and a closed-form expression to find the optimal value for $\beta$ for any distribution or set of performances, and we illustrate their use on six case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22442v1</guid>
      <category>cs.PF</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'ebastien Pi\'erard, Adrien Deli\`ege, Marc Van Droogenbroeck</dc:creator>
    </item>
    <item>
      <title>Motion-to-Motion Latency Measurement Framework for Connected and Autonomous Vehicle Teleoperation</title>
      <link>https://arxiv.org/abs/2511.22467</link>
      <description>arXiv:2511.22467v1 Announce Type: new 
Abstract: Latency is a key performance factor for the teleoperation of Connected and Autonomous Vehicles (CAVs). It affects how quickly an operator can perceive changes in the driving environment and apply corrective actions. Most existing work focuses on Glass-to-Glass (G2G) latency, which captures delays only in the video pipeline. However, there is no standard method for measuring Motion-to-Motion (M2M) latency, defined as the delay between the physical steering movement of the remote operator and the corresponding steering motion in the vehicle. This paper presents an M2M latency measurement framework that uses Hall-effect sensors and two synchronized Raspberry Pi~5 devices. The system records interrupt-based timestamps on both sides to estimate M2M latency, independently of the underlying teleoperation architecture. Precision tests show an accuracy of 10--15~ms, while field results indicate that actuator delays dominate M2M latency, with median values above 750~ms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22467v1</guid>
      <category>cs.PF</category>
      <category>cs.RO</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Provost, Faisal Hawlader, Mehdi Testouri, Rapha\"el Frank</dc:creator>
    </item>
    <item>
      <title>When AI Bends Metal: AI-Assisted Optimization of Design Parameters in Sheet Metal Forming</title>
      <link>https://arxiv.org/abs/2511.22302</link>
      <description>arXiv:2511.22302v1 Announce Type: cross 
Abstract: Numerical simulations have revolutionized the industrial design process by reducing prototyping costs, design iterations, and enabling product engineers to explore the design space more efficiently. However, the growing scale of simulations demands substantial expert knowledge, computational resources, and time. A key challenge is identifying input parameters that yield optimal results, as iterative simulations are costly and can have a large environmental impact. This paper presents an AI-assisted workflow that reduces expert involvement in parameter optimization through the use of Bayesian optimization. Furthermore, we present an active learning variant of the approach, assisting the expert if desired. A deep learning model provides an initial parameter estimate, from which the optimization cycle iteratively refines the design until a termination condition (e.g., energy budget or iteration limit) is met. We demonstrate our approach, based on a sheet metal forming process, and show how it enables us to accelerate the exploration of the design space while reducing the need for expert involvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22302v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Tarraf, Koutaiba Kassem-Manthey, Seyed Ali Mohammadi, Philipp Martin, Lukas Moj, Semih Burak, Enju Park, Christian Terboven, Felix Wolf</dc:creator>
    </item>
    <item>
      <title>3RSeT: Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison</title>
      <link>https://arxiv.org/abs/2511.22551</link>
      <description>arXiv:2511.22551v1 Announce Type: cross 
Abstract: Recent development in memory technologies has introduced Spin-Transfer Torque Magnetic RAM (STT-MRAM) as the most promising replacement for SRAMs in on-chip cache memories. Besides its lower leakage power, higher density, immunity to radiation-induced particles, and non-volatility, an unintentional bit flip during read operation, referred to as read disturbance error, is a severe reliability challenge in STT-MRAM caches. One major source of read disturbance error in STT-MRAM caches is simultaneous accesses to all tags for parallel comparison operation in a cache set, which has not been addressed in previous work. This paper first demonstrates that high read accesses to tag array extremely increase the read disturbance rate and then proposes a low-cost scheme, so-called Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison (3RSeT), to reduce the error rate by eliminating a significant portion of tag reads. 3RSeT proactively disables the tags that have no chance for hit, using low significant bits of the tags on each access request. Our evaluations using gem5 full-system cycle-accurate simulator show that 3RSeT reduces the read disturbance rate in the tag array by 71.8%, which results in 3.6x improvement in Mean Time To Failure (MTTF). In addition, the energy consumption is reduced by 62.1% without compromising performance and with less than 0.4% area overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22551v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elham Cheshmikhani, Hamed Farbeh, Hossein Asad</dc:creator>
    </item>
    <item>
      <title>PET Rapid Image Reconstruction Challenge (PETRIC)</title>
      <link>https://arxiv.org/abs/2511.22566</link>
      <description>arXiv:2511.22566v1 Announce Type: cross 
Abstract: Introduction: We describe the foundation of PETRIC, an image reconstruction challenge to minimise the computational runtime of related algorithms for Positron Emission Tomography (PET).
  Purpose: Although several similar challenges are well-established in the field of medical imaging, there have been no prior challenges for PET image reconstruction.
  Methods: Participants are provided with open-source software for implementation of their reconstruction algorithm(s). We define the objective function and reconstruct "gold standard" reference images, and provide metrics for quantifying algorithmic performance. We also received and curated phantom datasets (acquired with different scanners, radionuclides, and phantom types), which we further split into training and evaluation datasets. The automated computational framework of the challenge is released as open-source software.
  Results: Four teams with nine algorithms in total participated in the challenge. Their contributions made use of various tools from optimisation theory including preconditioning, stochastic gradients, and artificial intelligence. While most of the submitted approaches appear very similar in nature, their specific implementation lead to a range of algorithmic performance.
  Conclusion: As the first challenge for PET image reconstruction, PETRIC's solid foundations allow researchers to reuse its framework for evaluating new and existing image reconstruction methods on new or existing datasets. Variant versions of the challenge have and will continue to be launched in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22566v1</guid>
      <category>physics.med-ph</category>
      <category>cs.PF</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Casper da Costa-Luis, Matthias J. Ehrhardt, Christoph Kolbitsch, Evgueni Ovtchinnikov, Edoardo Pasca, Kris Thielemans, Charalampos Tsoumpas</dc:creator>
    </item>
    <item>
      <title>JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows</title>
      <link>https://arxiv.org/abs/2506.17084</link>
      <description>arXiv:2506.17084v2 Announce Type: replace-cross 
Abstract: In modern science, the growing complexity of large-scale scientific projects has led to an increasing reliance on cross-facility scientific workflows, where resources and expertise from multiple institutions and geographic locations are leveraged to accelerate scientific discovery. These workflows often require transmitting huge amounts of scientific data through wide-area networks. Although high-speed networks like ESnet and transfer services such as Globus have improved data mobility, several challenges remain. The sheer volume of data can overwhelm network bandwidth, widely used transport protocols such as TCP suffer from inefficiencies due to retransmissions triggered by packet loss, and existing fault-tolerance mechanisms like erasure coding introduce substantial overhead.
  In this paper, we propose JANUS, a resilient and adaptable data transmission approach designed for cross-facility scientific workflows. Unlike traditional TCP-based methods, JANUSleverages UDP, integrates erasure coding for fault tolerance, and combines it with error-bounded lossy compression to reduce overhead. This novel design allows users to balance data transmission time and accuracy, optimizing transfer performance based on specific scientific requirements. Additionally, JANUS dynamically adjusts erasure coding parameters in response to real-time network conditions, ensuring efficient data transfers even in fluctuating environments. We develop optimization models for determining ideal configurations and implement adaptive data transfer protocols to enhance reliability. Through extensive simulations and real-network experiments, we demonstrate that JANUS significantly improves transfer efficiency while maintaining data fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17084v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vladislav Esaulov, Jieyang Chen, Norbert Podhorszki, Fred Suter, Scott Klasky, Anu G Bourgeois, Lipeng Wan</dc:creator>
    </item>
  </channel>
</rss>
