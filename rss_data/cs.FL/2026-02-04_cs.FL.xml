<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 05:18:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Probabilistic Model-Checking Framework for Cognitive Assessment and Training</title>
      <link>https://arxiv.org/abs/2602.03643</link>
      <description>arXiv:2602.03643v1 Announce Type: new 
Abstract: Serious games have proven to be effective tools for screening cognitive impairments and supporting diagnosis in patients with neurodegenerative diseases like Alzheimer's and Parkinson's. They also offer cognitive training benefits. According to the DSM-5 classification, cognitive disorders are categorized as Mild Neurocognitive Disorders (mild NCDs) and Major Neurocognitive Disorders (Major NCDs). In this study, we focus on three patient groups: healthy, mild NCD, and Major NCD. We employ Discrete Time Markov Chains to model the behavior exhibited by each group while interacting with serious games. By applying model-checking techniques, we can identify discrepancies between expected and actual gameplay behavior. The primary contribution of this work is a novel theoretical framework designed to assess how a practitioner's confidence level in diagnosing a patient's Alzheimer's stage evolves with each game session (diagnosis support). Additionally, we propose an experimental protocol where the difficulty of subsequent game sessions is dynamically adjusted based on the patient's observed behavior in previous sessions (training support).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03643v1</guid>
      <category>cs.FL</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisabetta De Maria, Christopher Leturc</dc:creator>
    </item>
    <item>
      <title>Compiling Quantum Regular Language States</title>
      <link>https://arxiv.org/abs/2602.02698</link>
      <description>arXiv:2602.02698v1 Announce Type: cross 
Abstract: State preparation compilers for quantum computers typically sit at two extremes: general-purpose routines that treat the target as an opaque amplitude vector, and bespoke constructions for a handful of well-known state families. We ask whether a compiler can instead accept simple, structure-aware specifications while providing predictable resource guarantees. We answer this by designing and implementing a quantum state-preparation compiler for regular language states (RLS): uniform superpositions over bitstrings accepted by a regular description, and their complements. Users describe the target state via (i) a finite set of bitstrings, (ii) a regular expression, or (iii) a deterministic finite automaton (DFA), optionally with a complement flag. By translating the input to a DFA, minimizing it, and mapping it to an optimal matrix product state (MPS), the compiler obtains an intermediate representation (IR) that exposes and compresses hidden structure. The efficient DFA representation and minimization offloads expensive linear algebra computation in exchange of simpler automata manipulations. The combination of the regular-language frontend and this IR gives concise specifications not only for RLS but also for their complements that might otherwise require exponentially large state descriptions. This enables state preparation of an RLS or its complement with the same asymptotic resources and compile time. We outline two hardware-aware backends: SeqRLSP, which yields linear-depth, ancilla-free circuits for linear nearest-neighbor architectures via sequential generation, and TreeRLSP, which achieves logarithmic depth on all-to-all connectivity via a tree tensor network. We prove depth and gate-count bounds scaling with the system size and the state's maximal Schmidt rank, and we give explicit compile-time bounds that expose the benefit of our approach. We implement and evaluate the pipeline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02698v1</guid>
      <category>quant-ph</category>
      <category>cs.FL</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armando Bellante, Reinis Irmejs, Marta Florido-Llin\`as, Mar\'ia Cea Fern\'andez, Marianna Crupi, Matthew Kiser, J. Ignacio Cirac</dc:creator>
    </item>
    <item>
      <title>Reasoning about Reasoning: BAPO Bounds on Chain-of-Thought Token Complexity in LLMs</title>
      <link>https://arxiv.org/abs/2602.02909</link>
      <description>arXiv:2602.02909v1 Announce Type: cross 
Abstract: Inference-time scaling via chain-of-thought (CoT) reasoning is a major driver of state-of-the-art LLM performance, but it comes with substantial latency and compute costs. We address a fundamental theoretical question: how many reasoning tokens are required to solve a problem as input size grows? By extending the bounded attention prefix oracle (BAPO) model--an abstraction of LLMs that quantifies the information flow required to solve a task--we prove lower bounds on the CoT tokens required for three canonical BAPO-hard tasks: binary majority, triplet matching, and graph reachability. We show that each requires $\Omega(n)$ reasoning tokens when the input size is $n$. We complement these results with matching or near-matching upper bounds via explicit constructions. Finally, our experiments with frontier reasoning models show approximately linear reasoning token scaling on these tasks and failures when constrained to smaller reasoning budgets, consistent with our theoretical lower bounds. Together, our results identify fundamental bottlenecks in inference-time compute through CoT and offer a principled tool for analyzing optimal reasoning length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02909v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiran Tomlinson, Tobias Schnabel, Adith Swaminathan, Jennifer Neville</dc:creator>
    </item>
    <item>
      <title>A vector logic for intensional formal semantics</title>
      <link>https://arxiv.org/abs/2602.02940</link>
      <description>arXiv:2602.02940v1 Announce Type: cross 
Abstract: Formal semantics and distributional semantics are distinct approaches to linguistic meaning: the former models meaning as reference via model-theoretic structures; the latter represents meaning as vectors in high-dimensional spaces shaped by usage. This paper proves that these frameworks are structurally compatible for intensional semantics. We establish that Kripke-style intensional models embed injectively into vector spaces, with semantic functions lifting to (multi)linear maps that preserve composition. The construction accommodates multiple index sorts (worlds, times, locations) via a compound index space, representing intensions as linear operators. Modal operators are derived algebraically: accessibility relations become linear operators, and modal conditions reduce to threshold checks on accumulated values. For uncountable index domains, we develop a measure-theoretic generalization in which necessity becomes truth almost everywhere and possibility becomes truth on a set of positive measure, a non-classical logic natural for continuous parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02940v1</guid>
      <category>math.LO</category>
      <category>cs.CL</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Quigley</dc:creator>
    </item>
    <item>
      <title>Formal Evidence Generation for Assurance Cases for Robotic Software Models</title>
      <link>https://arxiv.org/abs/2602.03550</link>
      <description>arXiv:2602.03550v1 Announce Type: cross 
Abstract: Robotics and Autonomous Systems are increasingly deployed in safety-critical domains, so that demonstrating their safety is essential. Assurance Cases (ACs) provide structured arguments supported by evidence, but generating and maintaining this evidence is labour-intensive, error-prone, and difficult to keep consistent as systems evolve. We present a model-based approach to systematically generating AC evidence by embedding formal verification into the assurance workflow. The approach addresses three challenges: systematically deriving formal assertions from natural language requirements using templates, orchestrating multiple formal verification tools to handle diverse property types, and integrating formal evidence production into the workflow. Leveraging RoboChart, a domain-specific modelling language with formal semantics, we combine model checking and theorem proving in our approach. Structured requirements are automatically transformed into formal assertions using predefined templates, and verification results are automatically integrated as evidence. Case studies demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03550v1</guid>
      <category>cs.SE</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.RO</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fang Yan, Simon Foster, Ana Cavalcanti, Ibrahim Habli, James Baxter</dc:creator>
    </item>
    <item>
      <title>On Normality and Equidistribution for Separator Enumerators</title>
      <link>https://arxiv.org/abs/2602.01199</link>
      <description>arXiv:2602.01199v2 Announce Type: replace 
Abstract: A separator is a countable dense subset of $[0,1)$, and a separator enumerator is a naming scheme that assigns a real number in $[0,1)$ to each finite word so that the set of all named values is a separator. Mayordomo introduced separator enumerators to define $f$-normality and a relativized finite-state dimension $\dim^{f}_{\mathrm{FS}}(x)$, where finite-state dimension measures the asymptotic lower rate of finite-state information needed to approximate $x$ through its $f$-names. This framework extends classical base-$k$ normality, and Mayordomo showed that it supports a point-to-set principle for finite-state dimension. This representation-based viewpoint has since been developed further in follow-up work, including by Calvert et al., yielding strengthened randomness notions such as supernormal and highly normal numbers.
  Mayordomo posed the following open question: can $f$-normality be characterized via equidistribution properties of the sequence $\left(|\Sigma|^{n} a^{f}_{n}(x)\right)_{n=0}^{\infty}$, where $a^{f}_{n}(x)$ is the sequence of best approximations to $x$ from below induced by $f$? We give a strong negative answer: we construct computable separator enumerators $f_0,f_1$ and a point $x$ such that $a^{f_0}_{n}(x)=a^{f_1}_{n}(x)$ for all $n$, yet $\dim^{f_0}_{\mathrm{FS}}(x)=0$ while $\dim^{f_1}_{\mathrm{FS}}(x)=1$. Consequently, no criterion depending only on the sequence $\left(|\Sigma|^{n} a^{f}_{n}(x)\right)_{n=0}^{\infty}$ - in particular, no equidistribution property of this sequence - can characterize $f$-normality uniformly over all separator enumerators. On the other hand, for a natural finite-state coherent class of separator enumerators we recover a complete equidistribution characterization of $f$-normality. We also show that beyond finite-state coherence, this characterization can fail even for a separator enumerator computable in nearly linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01199v2</guid>
      <category>cs.FL</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subin Pulari</dc:creator>
    </item>
  </channel>
</rss>
