<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Apr 2024 19:06:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Prediction from compression for models with infinite memory, with applications to hidden Markov and renewal processes</title>
      <link>https://arxiv.org/abs/2404.15454</link>
      <description>arXiv:2404.15454v1 Announce Type: new 
Abstract: Consider the problem of predicting the next symbol given a sample path of length n, whose joint distribution belongs to a distribution class that may have long-term memory. The goal is to compete with the conditional predictor that knows the true model. For both hidden Markov models (HMMs) and renewal processes, we determine the optimal prediction risk in Kullback- Leibler divergence up to universal constant factors. Extending existing results in finite-order Markov models [HJW23] and drawing ideas from universal compression, the proposed estimator has a prediction risk bounded by redundancy of the distribution class and a memory term that accounts for the long-range dependency of the model. Notably, for HMMs with bounded state and observation spaces, a polynomial-time estimator based on dynamic programming is shown to achieve the optimal prediction risk {\Theta}(log n/n); prior to this work, the only known result of this type is O(1/log n) obtained using Markov approximation [Sha+18]. Matching minimax lower bounds are obtained by making connections to redundancy and mutual information via a reduction argument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15454v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanjun Han, Tianze Jiang, Yihong Wu</dc:creator>
    </item>
    <item>
      <title>Uncertainty, Imprecise Probabilities and Interval Capacity Measures on a Product Space</title>
      <link>https://arxiv.org/abs/2404.15484</link>
      <description>arXiv:2404.15484v1 Announce Type: new 
Abstract: In Basili and Pratelli (2024), a novel and coherent concept of interval probability measures has been introduced, providing a method for representing imprecise probabilities and uncertainty. Within the framework of set algebra, we introduced the concepts of weak complementation and interval probability measures associated with a family of random variables, which effectively capture the inherent uncertainty in any event. This paper conducts a comprehensive analysis of these concepts within a specific probability space. Additionally, we elaborate on an updating rule for events, integrating essential concepts of statistical independence, dependence, and stochastic dominance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15484v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marcello Basili, Luca Pratelli</dc:creator>
    </item>
    <item>
      <title>The Impact of Loss Estimation on Gibbs Measures</title>
      <link>https://arxiv.org/abs/2404.15649</link>
      <description>arXiv:2404.15649v1 Announce Type: new 
Abstract: In recent years, the shortcomings of Bayes posteriors as inferential devices has received increased attention. A popular strategy for fixing them has been to instead target a Gibbs measure based on losses that connect a parameter of interest to observed data. While existing theory for such inference procedures relies on these losses to be analytically available, in many situations these losses must be stochastically estimated using pseudo-observations. The current paper fills this research gap, and derives the first asymptotic theory for Gibbs measures based on estimated losses. Our findings reveal that the number of pseudo-observations required to accurately approximate the exact Gibbs measure depends on the rates at which the bias and variance of the estimated loss converge to zero. These results are particularly consequential for the emerging field of generalised Bayesian inference, for estimated intractable likelihoods, and for biased pseudo-marginal approaches. We apply our results to three Gibbs measures that have been proposed to deal with intractable likelihoods and model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15649v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David T. Frazier, Jeremias Knoblauch, Christopher Drovandi</dc:creator>
    </item>
    <item>
      <title>Autoregressive Networks with Dependent Edges</title>
      <link>https://arxiv.org/abs/2404.15654</link>
      <description>arXiv:2404.15654v1 Announce Type: new 
Abstract: We propose an autoregressive framework for modelling dynamic networks with dependent edges. It encompasses the models which accommodate, for example, transitivity, density-dependent and other stylized features often observed in real network data. By assuming the edges of network at each time are independent conditionally on their lagged values, the models, which exhibit a close connection with temporal ERGMs, facilitate both simulation and the maximum likelihood estimation in the straightforward manner. Due to the possible large number of parameters in the models, the initial MLEs may suffer from slow convergence rates. An improved estimator for each component parameter is proposed based on an iteration based on the projection which mitigates the impact of the other parameters (Chang et al., 2021, 2023). Based on a martingale difference structure, the asymptotic distribution of the improved estimator is derived without the stationarity assumption. The limiting distribution is not normal in general, and it reduces to normal when the underlying process satisfies some mixing conditions. Illustration with a transitivity model was carried out in both simulation and a real network data set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15654v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinyuan Chang, Qin Fang, Eric D. Kolaczyk, Peter W. MacDonald, Qiwei Yao</dc:creator>
    </item>
    <item>
      <title>Assessment of the quality of a prediction</title>
      <link>https://arxiv.org/abs/2404.15764</link>
      <description>arXiv:2404.15764v1 Announce Type: new 
Abstract: Shannon defined the mutual information between two variables. We illustrate why the true mutual information between a variable and the predictions made by a prediction algorithm is not a suitable measure of prediction quality, but the apparent Shannon mutual information (ASI) is; indeed it is the unique prediction quality measure with either of two very different lists of desirable properties, as previously shown by de Finetti and other authors. However, estimating the uncertainty of the ASI is a difficult problem, because of long and non-symmetric heavy tails to the distribution of the individual values of $j(x,y)=\log\frac{Q_y(x)}{P(x)}$ We propose a Bayesian modelling method for the distribution of $j(x,y)$, from the posterior distribution of which the uncertainty in the ASI can be inferred. This method is based on Dirichlet-based mixtures of skew-Student distributions. We illustrate its use on data from a Bayesian model for prediction of the recurrence time of prostate cancer. We believe that this approach is generally appropriate for most problems, where it is infeasible to derive the explicit distribution of the samples of $j(x,y)$, though the precise modelling parameters may need adjustment to suit particular cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15764v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roger Sewell, Elisabeth Crowe, Sharokh F. Shariat</dc:creator>
    </item>
    <item>
      <title>Optimal Experimental Design for Large-Scale Inverse Problems via Multi-PDE-constrained Optimization</title>
      <link>https://arxiv.org/abs/2404.15797</link>
      <description>arXiv:2404.15797v1 Announce Type: new 
Abstract: Accurate parameter dependent electro-chemical numerical models for lithium-ion batteries are essential in industrial application. The exact parameters of each battery cell are unknown and a process of estimation is necessary to infer them. The parameter estimation generates an accurate model able to reproduce real cell data. The field of optimal input/experimental design deals with creating the experimental settings facilitating the estimation problem. Here we apply two different input design algorithms that aim at maximizing the observability of the true, unknown parameters: in the first algorithm, we design the applied current and the starting voltage. This lets the algorithm collect information on different states of charge, but requires long experimental times (60 000 s). In the second algorithm, we generate a continuous current, composed of concatenated optimal intervals. In this case, the experimental time is shorter (7000 s) and numerical experiments with virtual data give an even better accuracy results, but experiments with real battery data reveal that the accuracy could decrease hundredfold. As the design algorithms are built independent of the model, the same results and motivation are applicable to more complex battery cell models and, moreover, to other applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15797v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Petrocchi, Matthias K. Scharrer, Franz Pichler, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Large-sample theory for inferential models: a possibilistic Bernstein--von Mises theorem</title>
      <link>https://arxiv.org/abs/2404.15843</link>
      <description>arXiv:2404.15843v1 Announce Type: new 
Abstract: The inferential model (IM) framework offers alternatives to the familiar probabilistic (e.g., Bayesian and fiducial) uncertainty quantification in statistical inference. Allowing this uncertainty quantification to be imprecise makes it possible to achieve exact validity and reliability. But is imprecision and exact validity compatible with attainment of the classical notions of statistical efficiency? The present paper offers an affirmative answer to this question via a new possibilistic Bernstein--von Mises theorem that parallels a fundamental result in Bayesian inference. Among other things, our result demonstrates that the IM solution is asymptotically efficient in the sense that its asymptotic credal set is the smallest that contains the Gaussian distribution whose variance agrees with the Cramer--Rao lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15843v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Martin, Jonathan P. Williams</dc:creator>
    </item>
    <item>
      <title>Robust Phase Retrieval by Alternating Minimization</title>
      <link>https://arxiv.org/abs/2404.15302</link>
      <description>arXiv:2404.15302v1 Announce Type: cross 
Abstract: We consider a least absolute deviation (LAD) approach to the robust phase retrieval problem that aims to recover a signal from its absolute measurements corrupted with sparse noise. To solve the resulting non-convex optimization problem, we propose a robust alternating minimization (Robust-AM) derived as an unconstrained Gauss-Newton method. To solve the inner optimization arising in each step of Robust-AM, we adopt two computationally efficient methods for linear programs. We provide a non-asymptotic convergence analysis of these practical algorithms for Robust-AM under the standard Gaussian measurement assumption. These algorithms, when suitably initialized, are guaranteed to converge linearly to the ground truth at an order-optimal sample complexity with high probability while the support of sparse noise is arbitrarily fixed and the sparsity level is no larger than $1/4$. Additionally, through comprehensive numerical experiments on synthetic and image datasets, we show that Robust-AM outperforms existing methods for robust phase retrieval offering comparable theoretical performance</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15302v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonho Kim, Kiryung Lee</dc:creator>
    </item>
    <item>
      <title>DPO: Differential reinforcement learning with application to optimal configuration search</title>
      <link>https://arxiv.org/abs/2404.15617</link>
      <description>arXiv:2404.15617v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) with continuous state and action spaces remains one of the most challenging problems within the field. Most current learning methods focus on integral identities such as value functions to derive an optimal strategy for the learning agent. In this paper, we instead study the dual form of the original RL formulation to propose the first differential RL framework that can handle settings with limited training samples and short-length episodes. Our approach introduces Differential Policy Optimization (DPO), a pointwise and stage-wise iteration method that optimizes policies encoded by local-movement operators. We prove a pointwise convergence estimate for DPO and provide a regret bound comparable with current theoretical works. Such pointwise estimate ensures that the learned policy matches the optimal path uniformly across different steps. We then apply DPO to a class of practical RL problems which search for optimal configurations with Lagrangian rewards. DPO is easy to implement, scalable, and shows competitive results on benchmarking experiments against several popular RL methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15617v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandrajit Bajaj, Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Unbiased Risk Estimation in the Normal Means Problem via Coupled Bootstrap Techniques</title>
      <link>https://arxiv.org/abs/2111.09447</link>
      <description>arXiv:2111.09447v3 Announce Type: replace 
Abstract: We develop a new approach for estimating the risk of an arbitrary estimator of the mean vector in the classical normal means problem. The key idea is to generate two auxiliary data vectors, by adding carefully constructed normal noise vectors to the original data. We then train the estimator of interest on the first auxiliary vector and test it on the second. In order to stabilize the risk estimate, we average this procedure over multiple draws of the synthetic noise vector. A key aspect of this coupled bootstrap (CB) approach is that it delivers an unbiased estimate of risk under no assumptions on the estimator of the mean vector, albeit for a modified and slightly "harder" version of the original problem, where the noise variance is elevated. We prove that, under the assumptions required for the validity of Stein's unbiased risk estimator (SURE), a limiting version of the CB estimator recovers SURE exactly. We then analyze a bias-variance decomposition of the error of the CB estimator, which elucidates the effects of the variance of the auxiliary noise and the number of bootstrap samples on the accuracy of the estimator. Lastly, we demonstrate that the CB estimator performs favorably in various simulated experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.09447v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalia L. Oliveira, Jing Lei, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance</title>
      <link>https://arxiv.org/abs/2310.03722</link>
      <description>arXiv:2310.03722v3 Announce Type: replace 
Abstract: In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma^2$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an "e-process" (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting confidence sequences, which have a curious polynomial dependence on the error probability $\alpha$ that we prove to be not only unavoidable, but (for universal inference) even better than the classical fixed-sample t-test. Numerical experiments are provided along the way to compare and contrast the various approaches, including some recent suboptimal ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03722v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Multiple change point detection in functional data with applications to biomechanical fatigue data</title>
      <link>https://arxiv.org/abs/2312.11108</link>
      <description>arXiv:2312.11108v3 Announce Type: replace 
Abstract: Injuries to the lower extremity joints are often debilitating, particularly for professional athletes. Understanding the onset of stressful conditions on these joints is therefore important in order to ensure prevention of injuries as well as individualised training for enhanced athletic performance. We study the biomechanical joint angles from the hip, knee and ankle for runners who are experiencing fatigue. The data is cyclic in nature and densely collected by body worn sensors, which makes it ideal to work with in the functional data analysis (FDA) framework.
  We develop a new method for multiple change point detection for functional data, which improves the state of the art with respect to at least two novel aspects. First, the curves are compared with respect to their maximum absolute deviation, which leads to a better interpretation of local changes in the functional data compared to classical $L^2$-approaches. Secondly, as slight aberrations are to be often expected in a human movement data, our method will not detect arbitrarily small changes but hunts for relevant changes, where maximum absolute deviation between the curves exceeds a specified threshold, say $\Delta &gt;0$. We recover multiple changes in a long functional time series of biomechanical knee angle data, which are larger than the desired threshold $\Delta$, allowing us to identify changes purely due to fatigue. In this work, we analyse data from both controlled indoor as well as from an uncontrolled outdoor (marathon) setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11108v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Bastian, Rupsa Basu, Holger Dette</dc:creator>
    </item>
    <item>
      <title>Combining exchangeable p-values</title>
      <link>https://arxiv.org/abs/2404.03484</link>
      <description>arXiv:2404.03484v2 Announce Type: replace 
Abstract: Significant recent progress has been made on deriving combination rules that can take as input a set of arbitrarily dependent p-values, and produce as output a single valid p-value. Here, we show that under the assumption of exchangeability of the p-values, many of those rules can be improved (made more powerful). While this observation by itself has practical implications (for example, under repeated tests involving data splitting), it also has implications for combining arbitrarily dependent p-values, since the latter can be made exchangeable by applying a uniformly random permutation. In particular, we derive several simple randomized combination rules for arbitrarily dependent p-values that are more powerful than their deterministic counterparts. For example, we derive randomized and exchangeable improvements of well known p-value combination rules like "twice the median" and "twice the average", as well as geometric and harmonic means. The main technical advance is to show that all these combination rules can be obtained by calibrating the p-values to e-values (using an $\alpha$-dependent calibrator), averaging those e-values, converting to a level $\alpha$ test using Markov's inequality, and finally obtaining p-values by combining this family of tests. The improvements are delivered via recent randomized and exchangeable variants of Markov's inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03484v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Gasparin, Ruodu Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Faithlessness in Gaussian graphical models</title>
      <link>https://arxiv.org/abs/2404.05306</link>
      <description>arXiv:2404.05306v2 Announce Type: replace 
Abstract: The implication problem for conditional independence (CI) asks whether the fact that a probability distribution obeys a given finite set of CI relations implies that a further CI statement also holds in this distribution. This problem has a long and fascinating history, cumulating in positive results about implications now known as the semigraphoid axioms as well as impossibility results about a general finite characterization of CI implications. Motivated by violation of faithfulness assumptions in causal discovery, we study the implication problem in the special setting where the CI relations are obtained from a directed acyclic graphical (DAG) model along with one additional CI statement. Focusing on the Gaussian case, we give a complete characterization of when such an implication is graphical by using algebraic techniques. Moreover, prompted by the relevance of strong faithfulness in statistical guarantees for causal discovery algorithms, we give a graphical solution for an approximate CI implication problem, in which we ask whether small values of one additional partial correlation entail small values for yet a further partial correlation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05306v2</guid>
      <category>math.ST</category>
      <category>math.AC</category>
      <category>math.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathias Drton, Leonard Henckel, Benjamin Hollering, Pratik Misra</dc:creator>
    </item>
  </channel>
</rss>
