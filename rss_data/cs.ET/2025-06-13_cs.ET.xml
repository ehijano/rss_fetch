<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 04:00:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Immersive Multimedia Communication: State-of-the-Art on eXtended Reality Streaming</title>
      <link>https://arxiv.org/abs/2506.10004</link>
      <description>arXiv:2506.10004v1 Announce Type: cross 
Abstract: Extended reality (XR) is rapidly advancing, and poised to revolutionize content creation and consumption. In XR, users integrate various sensory inputs to form a cohesive perception of the virtual environment. This survey reviews the state-of-the-art in XR streaming, focusing on multiple paradigms. To begin, we define XR and introduce various XR headsets along with their multimodal interaction methods to provide a foundational understanding. We then analyze XR traffic characteristics to highlight the unique data transmission requirements. We also explore factors that influence the quality of experience in XR systems, aiming to identify key elements for enhancing user satisfaction. Following this, we present visual attention-based optimization methods for XR streaming to improve efficiency and performance. Finally, we examine current applications and highlight challenges to provide insights into ongoing and future developments of XR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10004v1</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3721292</arxiv:DOI>
      <dc:creator>Haopeng Wang, Haiwei Dong, Abdulmotaleb El Saddik</dc:creator>
    </item>
    <item>
      <title>Quantum resources in resource management systems</title>
      <link>https://arxiv.org/abs/2506.10052</link>
      <description>arXiv:2506.10052v1 Announce Type: cross 
Abstract: Quantum computers are beginning to operate in high-performance computing (HPC) environments. Quantum can complement classical resources for specific workloads, but their adoption depends on integration into existing HPC infrastructure. Treating quantum devices as first-class resources allows for unified scheduling, improved usability, and support for hybrid quantum-classical applications. This paper presents the design architecture and reference implementation for quantum resources control using existing workload management systems. We introduce a suite of plugins for Slurm that enable integration of on-prem and cloud quantum computing resources into existing high-performance computing centers. The paper details the interface design, plugin concept and implementation, operational aspects for heterogeneous compute clusters, as well as considerations for other resource management systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10052v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iskandar Sitdikov, M. Emre Sahin, Utz Bacher, Aleksander Wennersteen, Andrew Damin, Mark Birmingham, Philippa Rubin, Stefano Mensa, Matthieu Moreau, Aurelien Nober, Hitomi Takahashi, Munetaka Ohtani</dc:creator>
    </item>
    <item>
      <title>A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild</title>
      <link>https://arxiv.org/abs/2506.10117</link>
      <description>arXiv:2506.10117v1 Announce Type: cross 
Abstract: Platforms and the law regulate digital content depicting minors (defined as individuals under 18 years of age) differently from other types of content. Given the sheer amount of content that needs to be assessed, machine learning-based automation tools are commonly used to detect content depicting minors. To our knowledge, no dataset or benchmark currently exists for detecting these identification methods in a multi-modal environment. To fill this gap, we release the Image-Caption Children in the Wild Dataset (ICCWD), an image-caption dataset aimed at benchmarking tools that detect depictions of minors. Our dataset is richer than previous child image datasets, containing images of children in a variety of contexts, including fictional depictions and partially visible bodies. ICCWD contains 10,000 image-caption pairs manually labeled to indicate the presence or absence of a child in the image. To demonstrate the possible utility of our dataset, we use it to benchmark three different detectors, including a commercial age estimation system applied to images. Our results suggest that child detection is a challenging task, with the best method achieving a 75.3% true positive rate. We hope the release of our dataset will aid in the design of better minor detection methods in a wide range of scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10117v1</guid>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klim Kireev, Ana-Maria Cre\c{t}u, Raphael Meier, Sarah Adel Bargal, Elissa Redmiles, Carmela Troncoso</dc:creator>
    </item>
    <item>
      <title>Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods</title>
      <link>https://arxiv.org/abs/2506.10420</link>
      <description>arXiv:2506.10420v1 Announce Type: cross 
Abstract: Edge computing breaks with traditional autoscaling due to strict resource constraints, thus, motivating more flexible scaling behaviors using multiple elasticity dimensions. This work introduces an agent-based autoscaling framework that dynamically adjusts both hardware resources and internal service configurations to maximize requirements fulfillment in constrained environments. We compare four types of scaling agents: Active Inference, Deep Q Network, Analysis of Structural Knowledge, and Deep Active Inference, using two real-world processing services running in parallel: YOLOv8 for visual recognition and OpenCV for QR code detection. Results show all agents achieve acceptable SLO performance with varying convergence patterns. While the Deep Q Network benefits from pre-training, the structural analysis converges quickly, and the deep active inference agent combines theoretical foundations with practical scalability advantages. Our findings provide evidence for the viability of multi-dimensional agent-based autoscaling for edge environments and encourage future work in this research direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10420v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Boris Sedlak, Alireza Furutanpey, Zihang Wang, V\'ictor Casamayor Pujol, Schahram Dustdar</dc:creator>
    </item>
    <item>
      <title>A Hybrid Heuristic Framework for Resource-Efficient Querying of Scientific Experiments Data</title>
      <link>https://arxiv.org/abs/2506.10422</link>
      <description>arXiv:2506.10422v1 Announce Type: cross 
Abstract: Scientific experiments and modern applications are generating large amounts of data every day. Most organizations utilize In-house servers or Cloud resources to manage application data and workload. The traditional database management system (DBMS) and HTAP systems spend significant time &amp; resources to load the entire dataset into DBMS before starting query execution. On the other hand, in-situ engines may reparse required data multiple times, increasing resource utilization and data processing costs. Additionally, over or under-allocation of resources also increases application running costs. This paper proposes a lightweight Resource Availability &amp;Workload aware Hybrid Framework (RAW-HF) to optimize querying raw data by utilizing existing finite resources efficiently. RAW-HF includes modules that help optimize the resources required to execute a given workload and maximize the utilization of existing resources. The impact of applying RAW-HF to real-world scientific dataset workloads like Sloan Digital Sky Survey (SDSS) and Linked Observation Data (LOD) presented over 90% and 85% reduction in workload execution time (WET) compared to widely used traditional DBMS PostgreSQL. The overall CPU, IO resource utilization, and WET have been reduced by 26%, 25%, and 26%, respectively, while improving memory utilization by 33%, compared to the state-of-the-art workload-aware partial loading technique (WA) proposed for hybrid systems. A comparison of MUAR technique used by RAW-HF with machine learning based resource allocation techniques like PCC is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10422v1</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mayank Patel, Minal Bhise</dc:creator>
    </item>
    <item>
      <title>From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations</title>
      <link>https://arxiv.org/abs/2506.10559</link>
      <description>arXiv:2506.10559v1 Announce Type: cross 
Abstract: Explaining why the species lives at a particular location is important for understanding ecological systems and conserving biodiversity. However, existing ecological workflows are fragmented and often inaccessible to non-specialists. We propose an end-to-end visual-to-causal framework that transforms a species image into interpretable causal insights about its habitat preference. The system integrates species recognition, global occurrence retrieval, pseudo-absence sampling, and climate data extraction. We then discover causal structures among environmental features and estimate their influence on species occurrence using modern causal inference methods. Finally, we generate statistically grounded, human-readable causal explanations from structured templates and large language models. We demonstrate the framework on a bee and a flower species and report early results as part of an ongoing project, showing the potential of the multimodal AI assistant backed up by a recommended ecological modeling practice for describing species habitat in human-understandable language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10559v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutong Zhou, Masahiro Ryo</dc:creator>
    </item>
    <item>
      <title>Receiving RISs: Enabling Channel Estimation and Autonomous Configuration</title>
      <link>https://arxiv.org/abs/2506.10662</link>
      <description>arXiv:2506.10662v1 Announce Type: cross 
Abstract: This chapter focuses on a hardware architecture for semi-passive Reconfigurable Intelligent Surfaces (RISs) and investigates its consideration for boosting the performance of Multiple-Input Multiple-Output (MIMO) communication systems. The architecture incorporates a single or multiple radio-frequency chains to receive pilot signals via tunable absorption phase profiles realized by the metasurface front end, as well as a controller encompassing a baseband processing unit to carry out channel estimation, and consequently, the optimization of the RIS reflection coefficients. A novel channel estimation protocol, according to which the RIS receives non-orthogonal training pilot sequences from two multi-antenna terminals via tunable absorption phase profiles, and then, estimates the respective channels via its signal processing unit, is presented. The channel estimates are particularly used by the RIS controller to design the capacity-achieving reflection phase configuration of the metasurface front end. The proposed channel estimation algorithm, which is based on the Alternating Direction Method of Multipliers (ADMM), profits from the RIS random spatial absorption sampling to capture the entire signal space, and exploits the beamspace sparsity and low-rank properties of extremely large MIMO channels, which is particularly relevant for communication systems at the FR3 band and above. Our extensive numerical investigations showcase the superiority of the proposed channel estimation technique over benchmark schemes for various system and RIS hardware configuration parameters, as well as the effectiveness of using channel estimates at the RIS side to dynamically optimize the possibly phase-quantized reflection coefficients of its unit elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10662v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>George C. Alexandropoulos, Konstantinos D. Katsanos, Evangelos Vlachos</dc:creator>
    </item>
    <item>
      <title>Learning Chaotic Dynamics with Neuromorphic Network Dynamics</title>
      <link>https://arxiv.org/abs/2506.10773</link>
      <description>arXiv:2506.10773v1 Announce Type: cross 
Abstract: This study investigates how dynamical systems may be learned and modelled with a neuromorphic network which is itself a dynamical system. The neuromorphic network used in this study is based on a complex electrical circuit comprised of memristive elements that produce neuro-synaptic nonlinear responses to input electrical signals. To determine how computation may be performed using the physics of the underlying system, the neuromorphic network was simulated and evaluated on autonomous prediction of a multivariate chaotic time series, implemented with a reservoir computing framework. Through manipulating only input electrodes and voltages, optimal nonlinear dynamical responses were found when input voltages maximise the number of memristive components whose internal dynamics explore the entire dynamical range of the memristor model. Increasing the network coverage with the input electrodes was found to suppress other nonlinear responses that are less conducive to learning. These results provide valuable insights into how a practical neuromorphic network device can be optimised for learning complex dynamical systems using only external control parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10773v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yinhao Xu, Georg A. Gottwald, Zdenka Kuncic</dc:creator>
    </item>
    <item>
      <title>Solving Power System Problems using Adiabatic Quantum Computing</title>
      <link>https://arxiv.org/abs/2504.06458</link>
      <description>arXiv:2504.06458v2 Announce Type: replace 
Abstract: This paper proposes a novel combinatorial optimization framework that reformulates existing power system problems into a format executable on quantum annealers. The proposed framework accommodates both normal and complex numbers and enables efficient handling of large-scale problems, thus ensuring broad applicability across power system problems. As a proof of concept, we demonstrate its applicability in two classical problems: (i) power system parameter identification, where we estimate the admittance matrix given voltage and current measurements, and (ii) power flow analysis, where we reformulate the nonlinear equations governing active and reactive power balance. The results show that the proposed framework effectively and efficiently solves both linear and nonlinear power system problems, and thus offers significant advantages in scenarios where traditional solvers face challenges, such as ill-conditioned systems and fault conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06458v2</guid>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeynab Kaseb, Matthias Moller, Peter Palensky, Pedro P. Vergara</dc:creator>
    </item>
    <item>
      <title>Understanding Human-AI Trust in Education</title>
      <link>https://arxiv.org/abs/2506.09160</link>
      <description>arXiv:2506.09160v2 Announce Type: replace-cross 
Abstract: As AI chatbots become increasingly integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity regarding whether students develop trust toward them as they would a human peer or instructor, based in interpersonal trust, or as they would any other piece of technology, based in technology trust. This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social technologies, leaving their applicability to anthropomorphic systems unclear. To address this gap, we investigate how human-like and system-like trusting beliefs comparatively influence students' perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness of an AI chatbot - factors associated with students' engagement and learning outcomes. Through partial least squares structural equation modeling, we found that human-like and system-like trust significantly influenced student perceptions, with varied effects. Human-like trust more strongly predicted trusting intention, while system-like trust better predicted behavioral intention and perceived usefulness. Both had similar effects on perceived enjoyment. Given the partial explanatory power of each type of trust, we propose that students develop a distinct form of trust with AI chatbots (human-AI trust) that differs from human-human and human-technology models of trust. Our findings highlight the need for new theoretical frameworks specific to human-AI trust and offer practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09160v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Griffin Pitts, Sanaz Motamedi</dc:creator>
    </item>
  </channel>
</rss>
