<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 01:54:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Using Code Snippets to Teach Programming Languages</title>
      <link>https://arxiv.org/abs/2506.00404</link>
      <description>arXiv:2506.00404v1 Announce Type: new 
Abstract: Coding is a fundamental skill required in the engineering discipline, and much work exists exploring better ways of teaching coding in the higher education context. In particular, Code Snippets (CSs) are approved to be an effective way of introducing programming language units to students. CSs are portions of source code of varying size and content. They can be used in a myriad of ways, one of which is to teach the code they contain as well as its function. To further explore the use of CSs, a pedagogical summer internship project was set up at the Warwick Manufacturing Group (WMG). The scope of the considerations for the study derives from an educational standpoint. Within the evaluations made, the focus was primarily given to pieces of information which proved to provide evidence pertaining to the methodology involved in either teaching or developing teaching materials. By taking the results produced into account from a pedagogical perspective, it was found that several qualities of popular code snippet tutorials which benefit or hinder the learning process, including code length, interactivity, further support, and quality of explanation. These qualities are then combined and used to present a plan for the design of an effective learning resource which makes use of code snippets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00404v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.31273/10.31273/9781911675167/1626</arxiv:DOI>
      <arxiv:journal_reference>Using Code Snippets to Teach Programming Languages. (2024). UK and Ireland Engineering Education Research Network Conference Proceedings 2023</arxiv:journal_reference>
      <dc:creator>Joshua Akingbade, Jianhua Yang, Mir Seyedebrahimi</dc:creator>
    </item>
    <item>
      <title>Pearl: Automatic Code Optimization Using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2506.01880</link>
      <description>arXiv:2506.01880v1 Announce Type: new 
Abstract: Compilers are crucial in optimizing programs and accelerating their execution. However, optimizing programs automatically using compilers is not trivial. Recent work has attempted to use reinforcement learning (RL) to solve this problem. It has limitations though. Current methods either do not support the optimization of general loop nests or can only be used to optimize loop nests seen during training. In this paper, we propose Pearl, a novel framework that uses deep reinforcement learning to automate compiler code optimization. It uses an RL agent to select the sequence of code optimizations a compiler should apply to make the input code run faster. This agent can optimize general loop nests and can generalize to programs unseen during training. To enable the optimization of general loop nests, we propose a novel representation of the action space that allows the RL agent to select on which part of the loop nest a given code optimization should be applied. Training RL agents for loop nest optimization is slow and data-intensive. We accelerate this process by caching results and pre-training the agent. Integrated with the Tiramisu compiler, our approach streamlines optimization and outperforms existing methods. To the best of our knowledge, Pearl is the first RL-based system to support general programs composed of loop nests manipulating tensors while still being able to generalize to programs unseen during training. It is also the first to support the class of polyhedral optimizations, a class of advanced loop nest optimizations. We evaluate Pearl on a set of benchmarks, and demonstrate competitive performance improvements over state-of-the-art compilers. Notably, Pearl achieves a geometric mean speedup of 2.02x compared to Tiramisu and 3.36x compared to Pluto.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01880v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Djamel Rassem Lamouri, Iheb Nassim Aouadj, Smail Kourta, Riyadh Baghdadi</dc:creator>
    </item>
    <item>
      <title>How Programming Concepts and Neurons Are Shared in Code Language Models</title>
      <link>https://arxiv.org/abs/2506.01074</link>
      <description>arXiv:2506.01074v1 Announce Type: cross 
Abstract: Several studies have explored the mechanisms of large language models (LLMs) in coding tasks, but most have focused on programming languages (PLs) in a monolingual setting. In this paper, we investigate the relationship between multiple PLs and English in the concept space of LLMs. We perform a few-shot translation task on 21 PL pairs using two Llama-based models. By decoding the embeddings of intermediate layers during this task, we observe that the concept space is closer to English (including PL keywords) and assigns high probabilities to English tokens in the second half of the intermediate layers. We analyze neuron activations for 11 PLs and English, finding that while language-specific neurons are primarily concentrated in the bottom layers, those exclusive to each PL tend to appear in the top layers. For PLs that are highly aligned with multiple other PLs, identifying language-specific neurons is not feasible. These PLs also tend to have a larger keyword set than other PLs and are closer to the model's concept space regardless of the input/output PL in the translation task. Our findings provide insights into how LLMs internally represent PLs, revealing structural patterns in the model's concept space. Code is available at https://github.com/cisnlp/code-specific-neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01074v1</guid>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Hossein Kargaran, Yihong Liu, Fran\c{c}ois Yvon, Hinrich Sch\"utze</dc:creator>
    </item>
    <item>
      <title>Compiler Optimization via LLM Reasoning for Efficient Model Serving</title>
      <link>https://arxiv.org/abs/2506.01374</link>
      <description>arXiv:2506.01374v1 Announce Type: cross 
Abstract: While model serving has unlocked unprecedented capabilities, the high cost of serving large-scale models continues to be a significant barrier to widespread accessibility and rapid innovation. Compiler optimizations have long driven substantial performance improvements, but existing compilers struggle with neural workloads due to the exponentially large and highly interdependent space of possible transformations. Although existing stochastic search techniques can be effective, they are often sample-inefficient and fail to leverage the structural context underlying compilation decisions. We set out to investigate the research question of whether reasoning with large language models (LLMs), without any retraining, can leverage the context-aware decision space of compiler optimization to significantly improve sample efficiency. To that end, we introduce a novel compilation framework (dubbed REASONING COMPILER) that formulates optimization as a sequential, context-aware decision process, guided by a large language model and structured Monte Carlo tree search (MCTS). The LLM acts as a proposal mechanism, suggesting hardware-aware transformations that reflect the current program state and accumulated performance feedback. Monte Carlo tree search (MCTS) incorporates the LLM-generated proposals to balance exploration and exploitation, facilitating structured, context-sensitive traversal of the expansive compiler optimization space. By achieving substantial speedups with markedly fewer samples than leading neural compilers, our approach demonstrates the potential of LLM-guided reasoning to transform the landscape of compiler optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01374v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sujun Tang, Christopher Priebe, Rohan Mahapatra, Lianhui Qin, Hadi Esmaeilzadeh</dc:creator>
    </item>
    <item>
      <title>Policy as Code, Policy as Type</title>
      <link>https://arxiv.org/abs/2506.01446</link>
      <description>arXiv:2506.01446v1 Announce Type: cross 
Abstract: Policies are designed to distinguish between correct and incorrect actions; they are types. But badly typed actions may cause not compile errors, but financial and reputational harm We demonstrate how even the most complex ABAC policies can be expressed as types in dependently typed languages such as Agda and Lean, providing a single framework to express, analyze, and implement policies. We then go head-to-head with Rego, the popular and powerful open-source ABAC policy language. We show the superior safety that comes with a powerful type system and built-in proof assistant. In passing, we discuss various access control models, sketch how to integrate in a future when attributes are distributed and signed (as discussed at the W3C), and show how policies can be communicated using just the syntax of the language. Our examples are in Agda.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01446v1</guid>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew D. Fuchs</dc:creator>
    </item>
    <item>
      <title>Charon: An Analysis Framework for Rust</title>
      <link>https://arxiv.org/abs/2410.18042</link>
      <description>arXiv:2410.18042v3 Announce Type: replace 
Abstract: With the explosion in popularity of the Rust programming language, a wealth of tools have recently been developed to analyze, verify, and test Rust programs. Alas, the Rust ecosystem remains relatively young, meaning that every one of these tools has had to re-implement difficult, time-consuming machinery to interface with the Rust compiler and its cargo build system, to hook into the Rust compiler's internal representation, and to expose an abstract syntax tree (AST) that is suitable for analysis rather than optimized for efficiency. We address this missing building block of the Rust ecosystem, and propose Charon, an analysis framework for Rust. Charon acts as a swiss-army knife for analyzing Rust programs, and deals with all of the tedium above, providing clients with a clean, stable AST that can serve as the foundation of many analyses. We demonstrate the usefulness of Charon through a series of case studies, ranging from a Rust verification framework (Aeneas), a compiler from Rust to C (Eurydice), and a novel taint-checker for cryptographic code. To drive the point home, we also re-implement a popular existing analysis (Rudra), and show that it can be replicated by leveraging the Charon framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18042v3</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Son Ho, Guillaume Boisseau, Lucas Franceschino, Yoann Prak, Aymeric Fromherz, Jonathan Protzenko</dc:creator>
    </item>
    <item>
      <title>SGL: A Structured Graphics Language</title>
      <link>https://arxiv.org/abs/2505.14690</link>
      <description>arXiv:2505.14690v2 Announce Type: replace 
Abstract: This paper introduces SGL, a graphics language that is aesthetically similar to SQL. SGL is based on traditional grammars of graphics, as well as Vega-Lite's composition algebra. SGL demonstrates that the grammatical approach to graphics lends itself naturally to a SQL-like language. As a graphical counterpart to SQL, SGL facilitates the addition of visualization capabilities to SQL query interfaces. This paper presents components of the SGL language alongside examples. Comparisons to SQL and existing grammars are made throughout to provide further clarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14690v2</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jon Chapman</dc:creator>
    </item>
    <item>
      <title>Can a domain-specific language improve program structure comprehension of data pipelines? A mixed-methods study</title>
      <link>https://arxiv.org/abs/2505.16764</link>
      <description>arXiv:2505.16764v2 Announce Type: replace 
Abstract: In many application domains, domain-specific languages can allow domain experts to contribute to collaborative projects more correctly and efficiently. To do so, they must be able to understand program structure from reading existing source code. With high-quality data becoming an increasingly important resource, the creation of data pipelines is an important application domain for domain-specific languages. We execute a mixed-method study consisting of a controlled experiment and a follow-up descriptive survey among the participants to understand the effects of a domain-specific language on bottom-up program understanding and generate hypotheses for future research. During the experiment, participants need the same time to solve program structure comprehension tasks, but are significantly more correct when using the domain-specific language. In the descriptive survey, participants describe reasons related to the programming language itself, such as a better pipeline overview, more enforced code structure, and a closer alignment to the mental model of a data pipeline. In addition, human factors such as less required programming experience and the ability to reuse experience from other data engineering tools are discussed. Based on these results, domain-specific languages are a promising tool for creating data pipelines that can increase correct understanding of program structure and lower barriers to entry for domain experts. Open questions exist to make more informed implementation decisions for domain-specific languages for data pipelines in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16764v2</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Heltweg, Georg-Daniel Schwarz, Dirk Riehle</dc:creator>
    </item>
    <item>
      <title>High-level quantum algorithm programming using Silq</title>
      <link>https://arxiv.org/abs/2409.10231</link>
      <description>arXiv:2409.10231v2 Announce Type: replace-cross 
Abstract: Quantum computing, with its vast potential, is fundamentally shaped by the intricacies of quantum mechanics, which both empower and constrain its capabilities. The development of a universal, robust quantum programming language has emerged as a key research focus in this rapidly evolving field. This paper explores Silq, a recent high-level quantum programming language, highlighting its strengths and unique features. We aim to share our insights on designing and implementing high-level quantum algorithms using Silq, demonstrating its practical applications and advantages for quantum programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10231v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktorija Bezganovic, Marco Lewis, Sadegh Soudjani, Paolo Zuliani</dc:creator>
    </item>
    <item>
      <title>Annotation-guided AoS-to-SoA conversions and GPU offloading with data views in C++</title>
      <link>https://arxiv.org/abs/2502.16517</link>
      <description>arXiv:2502.16517v2 Announce Type: replace-cross 
Abstract: The C++ programming language provides classes and structs as fundamental modeling entities. Consequently, C++ code tends to favour array-of-structs (AoS) for encoding data sequences, even though structure-of-arrays (SoA) yields better performance for some calculations. We propose a C++ language extension based on attributes that allows developers to guide the compiler in selecting memory arrangements, i.e.~to select the optimal choice between AoS and SoA dynamically depending on both the execution context and algorithm step. The compiler can then automatically convert data into the preferred format prior to the calculations and convert results back afterward. The compiler handles all the complexity of determining which data to convert and how to manage data transformations. Our implementation realises the compiler-extension for the new annotations in Clang and demonstrates their effectiveness through a smoothed particle hydrodynamics (SPH) code, which we evaluate on an Intel CPU, an ARM CPU, and a Grace-Hopper GPU. While the separation of concerns between data structure and operators is elegant and provides performance improvements, the new annotations do not eliminate the need for performance engineering. Instead, they challenge conventional performance wisdom and necessitate rethinking approaches how to write efficient implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16517v2</guid>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel K. Radtke, Tobias Weinzierl</dc:creator>
    </item>
    <item>
      <title>Descriptor: C++ Self-Admitted Technical Debt Dataset (CppSATD)</title>
      <link>https://arxiv.org/abs/2505.01136</link>
      <description>arXiv:2505.01136v2 Announce Type: replace-cross 
Abstract: In software development, technical debt (TD) refers to suboptimal implementation choices made by the developers to meet urgent deadlines and limited resources, posing challenges for future maintenance. Self-Admitted Technical Debt (SATD) is a sub-type of TD, representing specific TD instances ``openly admitted'' by the developers and often expressed through source code comments. Previous research on SATD has focused predominantly on the Java programming language, revealing a significant gap in cross-language SATD. Such a narrow focus limits the generalizability of existing findings as well as SATD detection techniques across multiple programming languages. Our work addresses such limitation by introducing CppSATD, a dedicated C++ SATD dataset, comprising over 531,000 annotated comments and their source code contexts. Our dataset can serve as a foundation for future studies that aim to develop SATD detection methods in C++, generalize the existing findings to other languages, or contribute novel insights to cross-language SATD research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01136v2</guid>
      <category>cs.SE</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuoc Pham, Murali Sridharan, Matteo Esposito, Valentina Lenarduzzi</dc:creator>
    </item>
    <item>
      <title>HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation</title>
      <link>https://arxiv.org/abs/2505.16978</link>
      <description>arXiv:2505.16978v2 Announce Type: replace-cross 
Abstract: Grammar plays a critical role in natural language processing and text/code generation by enabling the definition of syntax, the creation of parsers, and guiding structured outputs. Although large language models (LLMs) demonstrate impressive capabilities across domains, their ability to infer and generate grammars has not yet been thoroughly explored. In this paper, we aim to study and improve the ability of LLMs for few-shot grammar generation, where grammars are inferred from sets of a small number of positive and negative examples and generated in Backus-Naur Form. To explore this, we introduced a novel dataset comprising 540 structured grammar generation challenges, devised 6 metrics, and evaluated 8 various LLMs against it. Our findings reveal that existing LLMs perform sub-optimally in grammar generation. To address this, we propose an LLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar generation. HyGenar achieves substantial improvements in both the syntactic and semantic correctness of generated grammars across LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16978v2</guid>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle</dc:creator>
    </item>
    <item>
      <title>INTERLEAVE: A Faster Symbolic Algorithm for Maximal End Component Decomposition</title>
      <link>https://arxiv.org/abs/2505.20748</link>
      <description>arXiv:2505.20748v2 Announce Type: replace-cross 
Abstract: This paper presents a novel symbolic algorithm for the Maximal End Component (MEC) decomposition of a Markov Decision Process (MDP). The key idea behind our algorithm INTERLEAVE is to interleave the computation of Strongly Connected Components (SCCs) with eager elimination of redundant state-action pairs, rather than performing these computations sequentially as done by existing state-of-the-art algorithms. Even though our approach has the same complexity as prior works, an empirical evaluation of INTERLEAVE on the standardized Quantitative Verification Benchmark Set demonstrates that it solves 19 more benchmarks (out of 379) than the closest previous algorithm. On the 149 benchmarks that prior approaches can solve, we demonstrate a 3.81x average speedup in runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20748v2</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suguman Bansal, Ramneet Singh</dc:creator>
    </item>
    <item>
      <title>HiLDe: Intentional Code Generation via Human-in-the-Loop Decoding</title>
      <link>https://arxiv.org/abs/2505.22906</link>
      <description>arXiv:2505.22906v2 Announce Type: replace-cross 
Abstract: While AI programming tools hold the promise of increasing programmers' capabilities and productivity to a remarkable degree, they often exclude users from essential decision-making processes, causing many to effectively "turn off their brains" and over-rely on solutions provided by these systems. These behaviors can have severe consequences in critical domains, like software security. We propose Human-in-the-loop Decoding, a novel interaction technique that allows users to observe and directly influence LLM decisions during code generation, in order to align the model's output with their personal requirements. We implement this technique in HiLDe, a code completion assistant that highlights critical decisions made by the LLM and provides local alternatives for the user to explore. In a within-subjects study (N=18) on security-related tasks, we found that HiLDe led participants to generate significantly fewer vulnerabilities and better align code generation with their goals compared to a traditional code completion assistant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22906v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emmanuel Anaya Gonz\'alez, Raven Rothkopf, Sorin Lerner, Nadia Polikarpova</dc:creator>
    </item>
  </channel>
</rss>
