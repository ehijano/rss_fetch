<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Apr 2024 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Membrane Computing Approach to the Generalized Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2404.17671</link>
      <description>arXiv:2404.17671v1 Announce Type: new 
Abstract: In Evolutionary Game Theory (EGT), a population reaches a Nash equilibrium when none of the agents can improve its objective by solely changing its strategy on its own. Roughly speaking, this equilibrium is a protection against betrayal. Generalized Nash Equilibrium (GNE) is a more complex version of this idea with important implications in real-life problems in economics, wireless communication, the electricity market, or engineering among other areas. In this paper, we propose a first approach to GNE with Membrane Computing techniques and show how GNE problems can be modeled with P systems, bridging both areas and opening a door for a flow of problems and solutions in both directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17671v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alejandro Luque-Cerpa, Miguel A. Guti\'errez-Naranjo</dc:creator>
    </item>
    <item>
      <title>Allocating Mixed Goods with Customized Fairness and Indivisibility Ratio</title>
      <link>https://arxiv.org/abs/2404.18132</link>
      <description>arXiv:2404.18132v1 Announce Type: new 
Abstract: We consider the problem of fairly allocating a combination of divisible and indivisible goods. While fairness criteria like envy-freeness (EF) and proportionality (PROP) can always be achieved for divisible goods, only their relaxed versions, such as the ''up to one'' relaxations EF1 and PROP1, can be satisfied when the goods are indivisible. The ''up to one'' relaxations require the fairness conditions to be satisfied provided that one good can be completely eliminated or added in the comparison. In this work, we bridge the gap between the two extremes and propose ''up to a fraction'' relaxations for the allocation of mixed divisible and indivisible goods. The fraction is determined based on the proportion of indivisible goods, which we call the indivisibility ratio. The new concepts also introduce asymmetric conditions that are customized for individuals with varying indivisibility ratios. We provide both upper and lower bounds on the fractions of the modified item in order to satisfy the fairness criterion. Our results are tight up to a constant for EF and asymptotically tight for PROP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18132v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Li, Zihao Li, Shengxin Liu, Zekai Wu</dc:creator>
    </item>
    <item>
      <title>Fair Division of Indivisible Goods with Comparison-Based Queries</title>
      <link>https://arxiv.org/abs/2404.18133</link>
      <description>arXiv:2404.18133v1 Announce Type: new 
Abstract: We study the problem of fairly allocating $m$ indivisible goods to $n$ agents, where agents may have different preferences over the goods. In the traditional setting, agents' valuations are provided as inputs to the algorithm. In this paper, we study a new comparison-based query model where the algorithm presents two bundles of goods to an agent and the agent responds by telling the algorithm which bundle she prefers. We investigate the query complexity for computing allocations with several fairness notions including proportionality up to one good (PROP1), envy-freeness up to one good (EF1), and maximin share (MMS). Our main result is an algorithm that computes an allocation satisfying both PROP1 and $\frac12$-MMS within $O(\log m)$ queries with a constant number of $n$ agents. For identical and additive valuation, we present an algorithm for computing an EF1 allocation within $O(\log m)$ queries with a constant number of $n$ agents. To complement the positive results, we show that the lower bound of the query complexity for any of the three fairness notions is $\Omega(\log m)$ even with two agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18133v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolin Bu, Zihao Li, Shengxin Liu, Jiaxin Song, Biaoshuai Tao</dc:creator>
    </item>
    <item>
      <title>Decentralized Peer Review in Open Science: A Mechanism Proposal</title>
      <link>https://arxiv.org/abs/2404.18148</link>
      <description>arXiv:2404.18148v1 Announce Type: new 
Abstract: Peer review is a laborious, yet essential, part of academic publishing with crucial impact on the scientific endeavor. The current lack of incentives and transparency harms the credibility of this process. Researchers are neither rewarded for superior nor penalized for bad reviews. Additionally, confidential reports cause a loss of insights and make the review process vulnerable to scientific misconduct. We propose a community-owned and -governed system that 1) remunerates reviewers for their efforts, 2) publishes the (anonymized) reports for scrutiny by the community, 3) tracks reputation of reviewers and 4) provides digital certificates. Automated by transparent smart-contract blockchain technology, the system aims to increase quality and speed of peer review while lowering the chance and impact of erroneous judgements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18148v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andreas Finke, Thomas Hensel</dc:creator>
    </item>
    <item>
      <title>Controller Synthesis in Timed B\"uchi Automata: Robustness and Punctual Guards</title>
      <link>https://arxiv.org/abs/2404.18584</link>
      <description>arXiv:2404.18584v1 Announce Type: new 
Abstract: We consider the synthesis problem on timed automata with B\"uchi objectives, where delay choices made by a controller are subjected to small perturbations. Usually, the controller needs to avoid punctual guards, such as testing the equality of a clock to a constant. In this work, we generalize to a robustness setting that allows for punctual transitions in the automaton to be taken by controller with no perturbation. In order to characterize cycles that resist perturbations in our setting, we introduce a new structural requirement on the reachability relation along an accepting cycle of the automaton. This property is formulated on the region abstraction, and generalizes the existing characterization of winning cycles in the absence of punctual guards. We show that the problem remains within PSPACE despite the presence of punctual guards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18584v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beno\^it Barbot, Damien Busatto-Gaston, Catalin Dima, Youssouf Oualhadj</dc:creator>
    </item>
    <item>
      <title>Desirability and social rankings</title>
      <link>https://arxiv.org/abs/2404.18755</link>
      <description>arXiv:2404.18755v1 Announce Type: new 
Abstract: In coalitional games, a player $i$ is regarded as strictly more desirable than player $j$ if substituting $j$ with $i$ within any coalition leads to a strict augmentation in the value of certain coalitions, while preserving the value of the others. We adopt a property-driven approach to 'integrate' the notion of the desirability relation into a total relation by establishing sets of independent axioms leading to the characterization of solutionconcepts from the related literature. We focus on social ranking solutions consistent with the desirability relation and propose complementary sets of properties for the axiomatic characterization of five existing solutions: Ceteris Paribus (CP-)majority, lexicographic excellence (lex-cel), dual-lex, $L^{(1)}$ solution and its dual version $L^{(1)}_{*}$ . These characterizations reveal additional similarities among the five solutions and emphasize the essential characteristics that should be taken into account when selecting a social ranking. A practical scenario involving a bicameral legislature is studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18755v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Aleandri, Felix Fritz, Stefano Moretti</dc:creator>
    </item>
    <item>
      <title>Energy Storage Arbitrage in Two-settlement Markets: A Transformer-Based Approach</title>
      <link>https://arxiv.org/abs/2404.17683</link>
      <description>arXiv:2404.17683v1 Announce Type: cross 
Abstract: This paper presents an integrated model for bidding energy storage in day-ahead and real-time markets to maximize profits. We show that in integrated two-stage bidding, the real-time bids are independent of day-ahead settlements, while the day-ahead bids should be based on predicted real-time prices. We utilize a transformer-based model for real-time price prediction, which captures complex dynamical patterns of real-time prices, and use the result for day-ahead bidding design. For real-time bidding, we utilize a long short-term memory-dynamic programming hybrid real-time bidding model. We train and test our model with historical data from New York State, and our results showed that the integrated system achieved promising results of almost a 20\% increase in profit compared to only bidding in real-time markets, and at the same time reducing the risk in terms of the number of days with negative profits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17683v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Saud Alghumayjan, Jiajun Han, Ningkun Zheng, Ming Yi, Bolun Xu</dc:creator>
    </item>
    <item>
      <title>Explaining vague language</title>
      <link>https://arxiv.org/abs/2404.18154</link>
      <description>arXiv:2404.18154v1 Announce Type: cross 
Abstract: Why is language vague? Vagueness may be explained and rationalized if it can be shown that vague language is more useful to speaker and hearer than precise language. In a well-known paper, Lipman proposes a game-theoretic account of vagueness in terms of mixed strategy that leads to a puzzle: vagueness cannot be strictly better than precision at equilibrium. More recently, \'Egr\'e, Spector, Mortier and Verheyen have put forward a Bayesian account of vagueness establishing that using vague words can be strictly more informative than using precise words. This paper proposes to compare both results and to explain why they are not in contradiction. Lipman's definition of vagueness relies exclusively on a property of signaling strategies, without making any assumptions about the lexicon, whereas \'Egr\'e et al.'s involves a layer of semantic content. We argue that the semantic account of vagueness is needed, and more adequate and explanatory of vagueness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18154v1</guid>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul \'Egr\'e, Benjamin Spector</dc:creator>
    </item>
    <item>
      <title>A Characterization of Complexity in Public Goods Games</title>
      <link>https://arxiv.org/abs/2301.11580</link>
      <description>arXiv:2301.11580v2 Announce Type: replace 
Abstract: We complete the characterization of the computational complexity of equilibrium in public goods games on graphs. In this model, each vertex represents an agent deciding whether to produce a public good, with utility defined by a "best-response pattern" determining the best response to any number of productive neighbors. We prove that the equilibrium problem is NP-complete for every finite non-monotone best-response pattern. This answers the open problem of [Gilboa and Nisan, 2022], and completes the answer to a question raised by [Papadimitriou and Peng, 2021], for all finite best-response patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11580v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matan Gilboa</dc:creator>
    </item>
    <item>
      <title>Bidder Selection Problem in Position Auctions: A Fast and Simple Algorithm via Poisson Approximation</title>
      <link>https://arxiv.org/abs/2306.10648</link>
      <description>arXiv:2306.10648v2 Announce Type: replace 
Abstract: In the Bidder Selection Problem (BSP) there is a large pool of $n$ potential advertisers competing for ad slots on the user's web page. Due to strict computational restrictions, the advertising platform can run a proper auction only for a fraction $k&lt;n$ of advertisers. We consider the basic optimization problem underlying BSP: given $n$ independent prior distributions, how to efficiently find a subset of $k$ with the objective of either maximizing expected social welfare or revenue of the platform. We study BSP in the classic multi-winner model of position auctions for welfare and revenue objectives using the optimal (respectively, VCG mechanism, or Myerson's auction) format for the selected set of bidders. Previous PTAS results for BSP optimization were only known for single-item auctions and in case of [Segev and Singla 2021] for $l$-unit auctions. More importantly, all of these PTASes were computational complexity results with impractically large running times, which defeats the purpose of using these algorithms under severe computational constraints.
  We propose a novel Poisson relaxation of BSP for position auctions that immediately implies that 1) BSP is polynomial-time solvable up to a vanishingly small error as the problem size $k$ grows; 2) there is a PTAS for position auctions after combining our relaxation with the trivial brute force algorithm. Unlike all previous PTASes, we implemented our algorithm and did extensive numerical experiments on practically relevant input sizes. First, our experiments corroborate the previous experimental findings of Mehta et al. that a few simple heuristics used in practice perform surprisingly well in terms of approximation factor. Furthermore, our algorithm outperforms Greedy both in running time and approximation on medium and large-sized instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10648v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3589334.3645418</arxiv:DOI>
      <dc:creator>Nickolai Gravin, Yixuan Even Xu, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>As Soon as Possible but Rationally</title>
      <link>https://arxiv.org/abs/2403.00399</link>
      <description>arXiv:2403.00399v2 Announce Type: replace 
Abstract: This paper addresses complexity problems in rational verification and synthesis for multi-player games played on weighted graphs, where the objective of each player is to minimize the cost of reaching a specific set of target vertices. In these games, one player, referred to as the system, declares his strategy upfront. The other players, composing the environment, then rationally make their moves according to their objectives. The rational behavior of these responding players is captured through two models: they opt for strategies that either represent a Nash equilibrium or lead to a play with a Pareto-optimal cost tuple.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00399v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'eronique Bruy\`ere, Christophe Grandmont, Jean-Fran\c{c}ois Raskin</dc:creator>
    </item>
    <item>
      <title>Strategic Bidding in Knapsack Auctions</title>
      <link>https://arxiv.org/abs/2403.07928</link>
      <description>arXiv:2403.07928v2 Announce Type: replace 
Abstract: In the Knapsack Problem a set of indivisible objects, each with different values and sizes, must be packed into a fixed-size knapsack to maximize the total value. The knapsack problem is known to be an NP-hard problem even when there is full information regarding values and sizes. In many real-world situations, however, the values of objects are private information, which adds another dimension of complexity. In this paper we examine the knapsack problem with private information by investigating three practical auctions as possible candidates for payment rules in a setup where the knapsack owner sells the space to object owners via an auction. The three auctions are the discriminatory price, the generalized second-price and the uniform-price auctions. Using a Greedy algorithm for allocating objects, we analyze bidding behavior, revenue and efficiency of these three auctions using theory, lab experiments, and AI-enriched simulations. Our results suggest that the uniform-price auction has the highest level of truthful bidding and efficiency while the discriminatory price and the generalized second-price auctions are superior in terms of revenue generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07928v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peyman Khezr, Vijay Mohan, Lionel Page</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for ZK-Rollup Prover Markets</title>
      <link>https://arxiv.org/abs/2404.06495</link>
      <description>arXiv:2404.06495v2 Announce Type: replace 
Abstract: In ZK-Rollups, provers spend significant computational resources to generate validity proofs. Their costs should be compensated properly, so a sustainable prover market can form over time. Existing transaction fee mechanisms (TFMs) such as EIP-1559, however, do not work in this setting, as EIP-1559 only generates negligible revenue because of burning, while provers often create or purchase specialized hardware in hopes of creating long-term revenue from proving, somewhat reminiscent of proof-of-work miners in the case of chains like Bitcoin. In this paper, we explore the design of transaction fee mechanisms for prover markets. The desiderata for such mechanisms include efficiency (social welfare is maximized), incentive compatibility (it is rational to bid honestly), collusion resistance (no profitable collusion among provers exists), and off-chain agreement proofness (no profitable collusion between users and provers exists). To demonstrate the difficulties of our new setting, we put forward several simple strawman mechanisms, and show they suffer from notable deficiencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06495v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhao Wang, Lulu Zhou, Aviv Yaish, Fan Zhang, Ben Fisch, Benjamin Livshits</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence for Multi-Unit Auction design</title>
      <link>https://arxiv.org/abs/2404.15633</link>
      <description>arXiv:2404.15633v2 Announce Type: replace 
Abstract: Understanding bidding behavior in multi-unit auctions remains an ongoing challenge for researchers. Despite their widespread use, theoretical insights into the bidding behavior, revenue ranking, and efficiency of commonly used multi-unit auctions are limited. This paper utilizes artificial intelligence, specifically reinforcement learning, as a model free learning approach to simulate bidding in three prominent multi-unit auctions employed in practice. We introduce six algorithms that are suitable for learning and bidding in multi-unit auctions and compare them using an illustrative example. This paper underscores the significance of using artificial intelligence in auction design, particularly in enhancing the design of multi-unit auctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15633v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peyman Khezr, Kendall Taylor</dc:creator>
    </item>
    <item>
      <title>Voting with Partial Orders: The Plurality and Anti-Plurality Classes</title>
      <link>https://arxiv.org/abs/2404.17413</link>
      <description>arXiv:2404.17413v2 Announce Type: replace 
Abstract: The Plurality rule for linear orders selects the alternatives most frequently appearing in the first position of those orders, while the Anti-Plurality rule selects the alternatives least often occurring in the final position. We explore extensions of these rules to partial orders, offering axiomatic characterizations for these extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17413v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Fioravanti, Ulle Endriss</dc:creator>
    </item>
    <item>
      <title>Emergent specialization from participation dynamics and multi-learner retraining</title>
      <link>https://arxiv.org/abs/2206.02667</link>
      <description>arXiv:2206.02667v3 Announce Type: replace-cross 
Abstract: Numerous online services are data-driven: the behavior of users affects the system's parameters, and the system's parameters affect the users' experience of the service, which in turn affects the way users may interact with the system. For example, people may choose to use a service only for tasks that already works well, or they may choose to switch to a different service. These adaptations influence the ability of a system to learn about a population of users and tasks in order to improve its performance broadly. In this work, we analyze a class of such dynamics -- where users allocate their participation amongst services to reduce the individual risk they experience, and services update their model parameters to reduce the service's risk on their current user population. We refer to these dynamics as \emph{risk-reducing}, which cover a broad class of common model updates including gradient descent and multiplicative weights. For this general class of dynamics, we show that asymptotically stable equilibria are always segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in  (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.02667v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Dean, Mihaela Curmei, Lillian J. Ratliff, Jamie Morgenstern, Maryam Fazel</dc:creator>
    </item>
    <item>
      <title>ZeroSwap: Data-driven Optimal Market Making in DeFi</title>
      <link>https://arxiv.org/abs/2310.09413</link>
      <description>arXiv:2310.09413v3 Announce Type: replace-cross 
Abstract: Automated Market Makers (AMMs) are major centers of matching liquidity supply and demand in Decentralized Finance. Their functioning relies primarily on the presence of liquidity providers (LPs) incentivized to invest their assets into a liquidity pool. However, the prices at which a pooled asset is traded is often more stale than the prices on centralized and more liquid exchanges. This leads to the LPs suffering losses to arbitrage. This problem is addressed by adapting market prices to trader behavior, captured via the classical market microstructure model of Glosten and Milgrom. In this paper, we propose the first optimal Bayesian and the first model-free data-driven algorithm to optimally track the external price of the asset. The notion of optimality that we use enforces a zero-profit condition on the prices of the market maker, hence the name ZeroSwap. This ensures that the market maker balances losses to informed traders with profits from noise traders. The key property of our approach is the ability to estimate the external market price without the need for price oracles or loss oracles. Our theoretical guarantees on the performance of both these algorithms, ensuring the stability and convergence of their price recommendations, are of independent interest in the theory of reinforcement learning. We empirically demonstrate the robustness of our algorithms to changing market conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09413v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viraj Nadkarni, Jiachen Hu, Ranvir Rana, Chi Jin, Sanjeev Kulkarni, Pramod Viswanath</dc:creator>
    </item>
    <item>
      <title>Repetitive Dilemma Games in Distribution Information Using Interplay of Droop Quota: Meek's Method in Impact of Maximum Compensation and Minimum Cost Routes in Information Role of Marginal Contribution in Two-Sided Matching Markets</title>
      <link>https://arxiv.org/abs/2403.18837</link>
      <description>arXiv:2403.18837v2 Announce Type: replace-cross 
Abstract: This paper is a preliminary report of the research plan and a digest of the results and discussions. On research note explores the complex dynamics of fake news dissemination and fact-checking costs within the framework of information markets and analyzes the equilibrium between supply and demand using the concepts of droop quotas, Meek's method, and marginal contributions. By adopting a two-sided matching market perspective, we delve into scenarios in which markets are stable under the influence of fake news perceived as truth and those in which credibility prevails. Through the application of iterated dilemma game theory, we investigate the strategic choices of news providers affected by the costs associated with spreading fake news and fact-checking efforts. We further examine the maximum reward problem and strategies to minimize the cost path for spreading fake news, and consider a nuanced understanding of market segmentation into "cheap" and "premium" segments based on the nature of the information being spread. Our analysis uses mathematical models and computational processes to identify stable equilibrium points that ensure market stability in the face of deceptive information practices and provide insight into effective strategies to enhance the informational health of the market. Through this comprehensive approach, this paper aims for a more truthful and reliable perspective from which to observe information markets. This paper is partially an attempt to utilize "Generative AI" and was written with educational intent. There are currently no plans for it to become a peer-reviewed paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18837v2</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yasuko Kawahata</dc:creator>
    </item>
    <item>
      <title>Intrusion Tolerance for Networked Systems through Two-Level Feedback Control</title>
      <link>https://arxiv.org/abs/2404.01741</link>
      <description>arXiv:2404.01741v3 Announce Type: replace-cross 
Abstract: We formulate intrusion tolerance for a system with service replicas as a two-level optimal control problem. On the local level node controllers perform intrusion recovery, and on the global level a system controller manages the replication factor. The local and global control problems can be formulated as classical problems in operations research, namely, the machine replacement problem and the inventory replenishment problem. Based on this formulation, we design TOLERANCE, a novel control architecture for intrusion-tolerant systems. We prove that the optimal control strategies on both levels have threshold structure and design efficient algorithms for computing them. We implement and evaluate TOLERANCE in an emulation environment where we run 10 types of network intrusions. The results show that TOLERANCE can improve service availability and reduce operational cost compared with state-of-the-art intrusion-tolerant systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01741v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kim Hammar, Rolf Stadler</dc:creator>
    </item>
    <item>
      <title>Proof-of-Learning with Incentive Security</title>
      <link>https://arxiv.org/abs/2404.09005</link>
      <description>arXiv:2404.09005v2 Announce Type: replace-cross 
Abstract: Most concurrent blockchain systems rely heavily on the Proof-of-Work (PoW) or Proof-of-Stake (PoS) mechanisms for decentralized consensus and security assurance. However, the substantial energy expenditure stemming from computationally intensive yet meaningless tasks has raised considerable concerns surrounding traditional PoW approaches, The PoS mechanism, while free of energy consumption, is subject to security and economic issues. Addressing these issues, the paradigm of Proof-of-Useful-Work (PoUW) seeks to employ challenges of practical significance as PoW, thereby imbuing energy consumption with tangible value. While previous efforts in Proof of Learning (PoL) explored the utilization of deep learning model training SGD tasks as PoUW challenges, recent research has revealed its vulnerabilities to adversarial attacks and the theoretical hardness in crafting a byzantine-secure PoL mechanism. In this paper, we introduce the concept of incentive-security that incentivizes rational provers to behave honestly for their best interest, bypassing the existing hardness to design a PoL mechanism with computational efficiency, a provable incentive-security guarantee and controllable difficulty. Particularly, our work is secure against two attacks to the recent work of Jia et al. [2021], and also improves the computational overhead from $\Theta(1)$ to $O(\frac{\log E}{E})$. Furthermore, while most recent research assumes trusted problem providers and verifiers, our design also guarantees frontend incentive-security even when problem providers are untrusted, and verifier incentive-security that bypasses the Verifier's Dilemma. By incorporating ML training into blockchain consensus mechanisms with provable guarantees, our research not only proposes an eco-friendly solution to blockchain systems, but also provides a proposal for a completely decentralized computing power market in the new AI age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09005v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zishuo Zhao, Zhixuan Fang, Xuechao Wang, Xi Chen, Yuan Zhou</dc:creator>
    </item>
  </channel>
</rss>
