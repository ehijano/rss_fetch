<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 01:31:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Reinforcement Learning Framework for Mobility Control of gNBs in Dynamic Radio Access Networks</title>
      <link>https://arxiv.org/abs/2508.02960</link>
      <description>arXiv:2508.02960v1 Announce Type: new 
Abstract: The increasing complexity of wireless environments, characterized by user mobility and dynamic obstructions, poses challenges for the maintenance of Line-of-Sight (LoS) connectivity. Mobile base stations (gNBs) stand as a promising solution by physically relocating to restore or sustain LoS, thereby necessitating the development of intelligent algorithms for autonomous movement control.
  As part of the CONVERGE research project, which is developing an experimental chamber to integrate computer vision (CV) into mobile networks and enhance Quality of Service (QoS) in dynamic wireless environments, this paper presents two key contributions. First, we introduce the CONVERGE Chamber Simulator (CC-SIM), a 3D simulation environment for developing, training, and validating mobility control algorithms for mobile gNBs. CC-SIM models user and obstacle mobility, visual occlusion, and Radio Frequency (RF) propagation behavior. It supports both offline reinforcement learning and real-time testing through tight integration with a standalone 5G system via the OpenAirInterface (OAI) RF simulator, enabling validation under realistic network conditions.
  Second, leveraging CC-SIM, we develop a Deep Q-Network (DQN) agent that learns to reposition the gNB proactively in response to dynamic environmental changes. Experiments across three representative use cases show that the trained agent significantly reduces LoS blockage time - by up to 42% - when compared to static deployments. These results highlight the effectiveness of learning-based mobility control in adaptive next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02960v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pedro Duarte, Andr\'e Coelho, Manuel Ricardo</dc:creator>
    </item>
    <item>
      <title>A Survey of AI Agent Registry Solutions</title>
      <link>https://arxiv.org/abs/2508.03095</link>
      <description>arXiv:2508.03095v1 Announce Type: new 
Abstract: As As autonomous AI agents scale across cloud, enterprise, and decentralized environments, the need for standardized registry systems to support discovery, identity, and capability sharing has become essential. This paper surveys three prominent registry approaches each defined by a unique metadata model: MCP's mcp.json, A2A's Agent Card, and NANDA's AgentFacts. MCP uses a centralized metaregistry with GitHub authenticated publishing and structured metadata for server discovery. A2A enables decentralized interaction via JSON-based Agent Cards, discoverable through well-known URIs, curated catalogs, or direct configuration. NANDA Index introduces AgentFacts, a cryptographically verifiable and privacy-preserving metadata model designed for dynamic discovery, credentialed capabilities, and cross-domain interoperability. These approaches are compared across four dimensions: security, scalability, authentication, and maintainability. The paper concludes with suggestions and recommendations to guide future design and adoption of registry systems for the Internet of AI Agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03095v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditi Singh, Abul Ehtesham, Ramesh Raskar, Mahesh Lambe, Pradyumna Chari, Jared James Grogan, Abhishek Singh, Saket Kumar</dc:creator>
    </item>
    <item>
      <title>Using the NANDA Index Architecture in Practice: An Enterprise Perspective</title>
      <link>https://arxiv.org/abs/2508.03101</link>
      <description>arXiv:2508.03101v1 Announce Type: new 
Abstract: The proliferation of autonomous AI agents represents a paradigmatic shift from traditional web architectures toward collaborative intelligent systems requiring sophisticated mechanisms for discovery, authentication, capability verification, and secure collaboration across heterogeneous protocol environments. This paper presents a comprehensive framework addressing the fundamental infrastructure requirements for secure, trustworthy, and interoperable AI agent ecosystems. We introduce the NANDA (Networked AI Agents in a Decentralized Architecture) framework, providing global agent discovery, cryptographically verifiable capability attestation through AgentFacts, and cross-protocol interoperability across Anthropic's Modal Context Protocol (MCP), Google's Agent-to-Agent (A2A), Microsoft's NLWeb, and standard HTTPS communications. NANDA implements Zero Trust Agentic Access (ZTAA) principles, extending traditional Zero Trust Network Access (ZTNA) to address autonomous agent security challenges including capability spoofing, impersonation attacks, and sensitive data leakage. The framework defines Agent Visibility and Control (AVC) mechanisms enabling enterprise governance while maintaining operational autonomy and regulatory compliance. Our approach transforms isolated AI agents into an interconnected ecosystem of verifiable, trustworthy intelligent services, establishing foundational infrastructure for large-scale autonomous agent deployment across enterprise and consumer environments. This work addresses the critical gap between current AI agent capabilities and infrastructure requirements for secure, scalable, multi-agent collaboration, positioning the foundation for next-generation autonomous intelligent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03101v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sichao Wang, Ramesh Raskar, Mahesh Lambe, Pradyumna Chari, Rekha Singhal, Shailja Gupta, Rajesh Ranjan, Ken Huang</dc:creator>
    </item>
    <item>
      <title>NANDA Adaptive Resolver: Architecture for Dynamic Resolution of AI Agent Names</title>
      <link>https://arxiv.org/abs/2508.03113</link>
      <description>arXiv:2508.03113v1 Announce Type: new 
Abstract: AdaptiveResolver is a dynamic microservice architecture designed to address the limitations of static endpoint resolution for AI agent communication in distributed, heterogeneous environments. Unlike traditional DNS or static URLs, AdaptiveResolver enables context-aware, real-time selection of communication endpoints based on factors such as geographic location, system load, agent capabilities, and security threats. Agents advertise their Agent Name and context requirements through Agent Fact cards in an Agent Registry/Index. A requesting Agent discovers a Target Agent using the registry. The Requester Agent can then resolve the Target Agent Name to obtain a tailored communication channel to the agent based on actual environmental context between the agents. The architecture supports negotiation of trust, quality of service, and resource constraints, facilitating flexible, secure, and scalable agent-to-agent interactions that go beyond the classic client-server model. AdaptiveResolver provides a foundation for robust, future-proof agent communication that can evolve with increasing ecosystem complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03113v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Zinky, Hema Seshadri, Mahesh Lambe, Pradyumna Chari, Ramesh Raskar</dc:creator>
    </item>
    <item>
      <title>Scalability and Performance Evaluation of IEEE 802.11ah IoT Deployments: A Testbed Approach</title>
      <link>https://arxiv.org/abs/2508.03146</link>
      <description>arXiv:2508.03146v1 Announce Type: new 
Abstract: This work focuses on the development and assessment of modern wireless Internet of Things (IoT) architectures, with relevance to emerging 5G and beyond applications. To analyze the growing demands for data, and their impact, we built an IEEE 802.11ah (WiFi Halow) office testbed for real-world experimentation. This deployment allows us to uncover the practical performance and scalability limitations of such networks under various challenging scenarios. To the best of our knowledge, this is the first study to consider complex real-world IEEE 802.11ah implementations, aiming specifically to reveal unexpected performance behaviors, such as significant throughput degradation arising in closely deployed wireless links. Our findings show that intense network contention and Adjacent Channel Interference (ACI), drastically impact the performance of the wireless links involved. Beyond evaluating network performance, our experimental analysis also considers the energy consumption of the devices under test, offering a more holistic perspective on the feasibility of IEEE 802.11ah in real-world deployments. The effective disclosure of such unexpected phenomena, can lead to well planned decisions and energy consumption optimization across the IoT to Cloud continuum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03146v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kostas Chounos, Katerina Kyriakou, Thanasis Korakis</dc:creator>
    </item>
    <item>
      <title>Energy-efficient Federated Learning for UAV Communications</title>
      <link>https://arxiv.org/abs/2508.03171</link>
      <description>arXiv:2508.03171v1 Announce Type: new 
Abstract: In this paper, we propose an unmanned aerial vehicle (UAV)-assisted federated learning (FL) framework that jointly optimizes UAV trajectory, user participation, power allocation, and data volume control to minimize overall system energy consumption. We begin by deriving the convergence accuracy of the FL model under multiple local updates, enabling a theoretical understanding of how user participation and data volume affect FL learning performance. The resulting joint optimization problem is non-convex; to address this, we employ alternating optimization (AO) and successive convex approximation (SCA) techniques to convexify the non-convex constraints, leading to the design of an iterative energy consumption optimization (ECO) algorithm. Simulation results confirm that ECO consistently outperform existing baseline schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03171v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chien-Wei Fu, Meng-Lin Ku</dc:creator>
    </item>
    <item>
      <title>Directives for Function Offloading in 5G Networks Based on a Performance Characteristics Analysis</title>
      <link>https://arxiv.org/abs/2508.03287</link>
      <description>arXiv:2508.03287v1 Announce Type: new 
Abstract: Cloud-based offloading helps address energy consumption and performance challenges in executing resource-intensive vehicle algorithms. Utilizing 5G, with its low latency and high bandwidth, enables seamless vehicle-to-cloud integration. Currently, only non-standalone 5G is publicly available, and real-world applications remain underexplored compared to theoretical studies. This paper evaluates 5G non-standalone networks for cloud execution of vehicle functions, focusing on latency, Round Trip Time, and packet delivery. Tests used two AI-based algorithms -- emotion recognition and object recognition -- along an 8.8 km route in Baden-W\"urttemberg, Germany, encompassing urban, rural, and forested areas. Two platforms were analyzed: a cloudlet in Frankfurt and a cloud in Mannheim, employing various deployment strategies like conventional applications and containerized and container-orchestrated setups. Key findings highlight an average signal quality of 84 %, with no connectivity interruptions despite minor drops in built-up areas. Packet analysis revealed a Packet Error Rate below 0.1 % for both algorithms. Transfer times varied significantly depending on the geographical location and the backend servers' network connections, while processing times were mainly influenced by the computation hardware in use. Additionally, cloud offloading seems only be a suitable option, when a round trip time of more than 150 ms is possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03287v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Falk Dettinger, Matthias Wei{\ss}, Daniel Baumann, Martin Sommer, Michael Weyrich</dc:creator>
    </item>
    <item>
      <title>Bidirectional TLS Handshake Caching for Constrained Industrial IoT Scenarios</title>
      <link>https://arxiv.org/abs/2508.03321</link>
      <description>arXiv:2508.03321v1 Announce Type: new 
Abstract: While TLS has become the de-facto standard for end-to-end security, its use to secure critical communication in evolving industrial IoT scenarios is severely limited by prevalent resource constraints of devices and networks. Most notably, the TLS handshake to establish secure connections incurs significant bandwidth and processing overhead that often cannot be handled in constrained environments. To alleviate this situation, we present BiTHaC which realizes bidirectional TLS handshake caching by exploiting that significant parts of repeated TLS handshakes, especially certificates, are static. Thus, redundant information neither needs to be transmitted nor corresponding computations performed, saving valuable bandwidth and processing resources. By implementing BiTHaC for wolfSSL, we show that we can reduce the bandwidth consumption of TLS handshakes by up to 61.1% and the computational overhead by up to 8.5%, while incurring only well-manageable memory overhead and preserving the strict security guarantees of TLS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03321v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\"orn Bodenhausen, Simon Mangel, Thomas Vogt, Martin Henze</dc:creator>
    </item>
    <item>
      <title>Morphlux: Programmable chip-to-chip photonic fabrics in multi-accelerator servers for ML</title>
      <link>https://arxiv.org/abs/2508.03674</link>
      <description>arXiv:2508.03674v1 Announce Type: new 
Abstract: We optically interconnect accelerator chips (e.g., GPUs, TPUs) within compute servers using newly viable programmable chip-to-chip photonic fabrics. In contrast, today, commercial multi-accelerator compute servers that are workhorses of ML, use electrical interconnects to network accelerator chips in the server. However, recent trends have shown an interconnect bandwidth wall caused by accelerator FLOPS scaling at a faster rate than the bandwidth of the interconnect between accelerators in the same server. This has led to under-utilization and idling of GPU resources in cloud datacenters. We develop Morphlux, a server-scale programmable photonic fabric, to interconnect accelerators within servers. We show that augmenting state-of-the-art photonic ML-centric datacenters with Morphlux can improve the bandwidth of tenant compute allocations by up to 66% and reduce compute fragmentation by up to 70%. We develop a novel end-to-end hardware prototype of Morphlux to demonstrate these performance benefits, which translate to 1.72x improvement in training throughput of ML models. By rapidly programming the server-scale fabric in our hardware testbed, Morphlux can logically replace a failed accelerator chip in 1.2 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03674v1</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Rachee Singh</dc:creator>
    </item>
    <item>
      <title>Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks</title>
      <link>https://arxiv.org/abs/2508.02856</link>
      <description>arXiv:2508.02856v1 Announce Type: cross 
Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility to advanced beam-stealing attacks, posing a significant physical layer security threat. This paper introduces a novel framework employing an advanced Deep Reinforcement Learning (DRL) agent for proactive and adaptive defense against these sophisticated attacks. A key innovation is leveraging Integrated Sensing and Communications (ISAC) capabilities for active, intelligent threat assessment. The DRL agent, built on a Proximal Policy Optimization (PPO) algorithm, dynamically controls ISAC probing actions to investigate suspicious activities. We introduce an intensive curriculum learning strategy that guarantees the agent experiences successful detection during training to overcome the complex exploration challenges inherent to such a security-critical task. Consequently, the agent learns a robust and adaptive policy that intelligently balances security and communication performance. Numerical results demonstrate that our framework achieves a mean attacker detection rate of 92.8% while maintaining an average user SINR of over 13 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02856v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyed Bagher Hashemi Natanzi, Hossein Mohammadi, Bo Tang, Vuk Marojevic</dc:creator>
    </item>
    <item>
      <title>Heterogeneity-Oblivious Robust Federated Learning</title>
      <link>https://arxiv.org/abs/2508.03579</link>
      <description>arXiv:2508.03579v2 Announce Type: cross 
Abstract: Federated Learning (FL) remains highly vulnerable to poisoning attacks, especially under real-world hyper-heterogeneity, where clients differ significantly in data distributions, communication capabilities, and model architectures. Such heterogeneity not only undermines the effectiveness of aggregation strategies but also makes attacks more difficult to detect. Furthermore, high-dimensional models expand the attack surface. To address these challenges, we propose Horus, a heterogeneity-oblivious robust FL framework centered on low-rank adaptations (LoRAs). Rather than aggregating full model parameters, Horus inserts LoRAs into empirically stable layers and aggregates only LoRAs to reduce the attack uncover a key empirical observation that the input projection (LoRA-A) is markedly more stable than the output projection (LoRA-B) under heterogeneity and poisoning. Leveraging this, we design a Heterogeneity-Oblivious Poisoning Score using the features from LoRA-A to filter poisoned clients. For the remaining benign clients, we propose projection-aware aggregation mechanism to preserve collaborative signals while suppressing drifts, which reweights client updates by consistency with the global directions. Extensive experiments across diverse datasets, model architectures, and attacks demonstrate that Horus consistently outperforms state-of-the-art baselines in both robustness and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03579v2</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiyao Zhang, Jinyang Li, Qi Song, Miao Wang, Chungang Lin, Haitong Luo, Xuying Meng, Yujun Zhang</dc:creator>
    </item>
    <item>
      <title>Decoding and Engineering the Phytobiome Communication for Smart Agriculture</title>
      <link>https://arxiv.org/abs/2508.03584</link>
      <description>arXiv:2508.03584v1 Announce Type: cross 
Abstract: Smart agriculture applications, integrating technologies like the Internet of Things and machine learning/artificial intelligence (ML/AI) into agriculture, hold promise to address modern challenges of rising food demand, environmental pollution, and water scarcity. Alongside the concept of the phytobiome, which defines the area including the plant, its environment, and associated organisms, and the recent emergence of molecular communication (MC), there exists an important opportunity to advance agricultural science and practice using communication theory. In this article, we motivate to use the communication engineering perspective for developing a holistic understanding of the phytobiome communication and bridge the gap between the phytobiome communication and smart agriculture. Firstly, an overview of phytobiome communication via molecular and electrophysiological signals is presented and a multi-scale framework modeling the phytobiome as a communication network is conceptualized. Then, how this framework is used to model electrophysiological signals is demonstrated with plant experiments. Furthermore, possible smart agriculture applications, such as smart irrigation and targeted delivery of agrochemicals, through engineering the phytobiome communication are proposed. These applications merge ML/AI methods with the Internet of Bio-Nano-Things enabled by MC and pave the way towards more efficient, sustainable, and eco-friendly agricultural production. Finally, the implementation challenges, open research issues, and industrial outlook for these applications are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03584v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>q-bio.MN</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford</dc:creator>
    </item>
    <item>
      <title>What If, But Privately: Private Counterfactual Retrieval</title>
      <link>https://arxiv.org/abs/2508.03681</link>
      <description>arXiv:2508.03681v1 Announce Type: cross 
Abstract: Transparency and explainability are two important aspects to be considered when employing black-box machine learning models in high-stake applications. Providing counterfactual explanations is one way of catering this requirement. However, this also poses a threat to the privacy of the institution that is providing the explanation, as well as the user who is requesting it. In this work, we are primarily concerned with the user's privacy who wants to retrieve a counterfactual instance, without revealing their feature vector to the institution. Our framework retrieves the exact nearest neighbor counterfactual explanation from a database of accepted points while achieving perfect, information-theoretic, privacy for the user. First, we introduce the problem of private counterfactual retrieval (PCR) and propose a baseline PCR scheme that keeps the user's feature vector information-theoretically private from the institution. Building on this, we propose two other schemes that reduce the amount of information leaked about the institution database to the user, compared to the baseline scheme. Second, we relax the assumption of mutability of all features, and consider the setting of immutable PCR (I-PCR). Here, the user retrieves the nearest counterfactual without altering a private subset of their features, which constitutes the immutable set, while keeping their feature vector and immutable set private from the institution. For this, we propose two schemes that preserve the user's privacy information-theoretically, but ensure varying degrees of database privacy. Third, we extend our PCR and I-PCR schemes to incorporate user's preference on transforming their attributes, so that a more actionable explanation can be received. Finally, we present numerical results to support our theoretical findings, and compare the database leakage of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03681v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Meel, Mohamed Nomeir, Pasan Dissanayake, Sanghamitra Dutta, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Statistical QoS Provision in Business-Centric Networks</title>
      <link>https://arxiv.org/abs/2408.15609</link>
      <description>arXiv:2408.15609v2 Announce Type: replace 
Abstract: More refined resource management and Quality of Service (QoS) provisioning is a critical goal of wireless communication technologies. In this paper, we propose a novel Business-Centric Network (BCN) aimed at enabling scalable QoS provisioning, based on a cross-layer framework that captures the relationship between application, transport parameters, and channels. We investigate both continuous flow and event-driven flow models, presenting key QoS metrics such as throughput, delay, and reliability. By jointly considering power and bandwidth allocation, transmission parameters, and AP network topology across layers, we optimize weighted resource efficiency with statistical QoS provisioning. To address the coupling among parameters, we propose a novel deep reinforcement learning (DRL) framework, which is Collaborative Optimization among Heterogeneous Actors with Experience Sharing (COHA-ES). Power and sub-channel (SC) Actors representing multiple APs are jointly optimized under the unified guidance of a common critic. Additionally, we introduce a novel multithreaded experience-sharing mechanism to accelerate training and enhance rewards. Extensive comparative experiments validate the effectiveness of our DRL framework in terms of convergence and efficiency. Moreover, comparative analyses demonstrate the comprehensive advantages of the BCN structure in enhancing both spectral and energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15609v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Wu, Yuang Chen, Hancheng Lu</dc:creator>
    </item>
    <item>
      <title>SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate</title>
      <link>https://arxiv.org/abs/2411.08767</link>
      <description>arXiv:2411.08767v3 Announce Type: replace 
Abstract: Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional (3D) wireless channel modeling, driven by advances in graphical rendering. Current approaches struggle to accurately model beyond 5G (B5G) network signaling, which often operates at higher frequencies and is more susceptible to environmental conditions and changes. Existing online learning solutions require real-time environmental supervision during training, which is both costly and incompatible with GPU-based processing. In response, we propose a novel approach that redefines ray trajectory generation as a sequential decision-making problem, leveraging generative models to jointly learn the optical, physical, and signal properties within each designated environment. Our work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing Hierarchy (SANDWICH), an innovative offline, fully differentiable approach that can be trained entirely on GPUs. SANDWICH offers superior performance compared to existing online learning methods, outperforms the baseline by 4e^-2 radian in RT accuracy, and only fades 0.5 dB away from toplined channel gain estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08767v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yifei Jin, Ali Maatouk, Sarunas Girdzijauskas, Shugong Xu, Leandros Tassiulas, Rex Ying</dc:creator>
    </item>
    <item>
      <title>An Extensible Software Transport Layer for GPU Networking</title>
      <link>https://arxiv.org/abs/2504.17307</link>
      <description>arXiv:2504.17307v2 Announce Type: replace 
Abstract: Fast-evolving machine learning (ML) workloads have increasing requirements for networking. However, host network transport on RDMA NICs is hard to evolve, causing problems for ML workloads. For example, single-path RDMA traffic is prone to flow collisions that severely degrade collective communication performance. We present UCCL, an extensible software transport layer to evolve GPU networking. UCCL decouples the data path and control path of existing RDMA NICs and efficiently runs the control-path transport on host CPUs. This software extensibility brings in transport innovations that cannot be achieved in hardware for ML workloads, e.g., a multipath transport to resolve flow collisions. ML collectives atop UCCL achieve up to 4.5x higher performance compared to existing RDMA NICs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17307v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Zhou, Zhongjie Chen, Ziming Mao, ChonLam Lao, Shuo Yang, Pravein Govindan Kannan, Jiaqi Gao, Yilong Zhao, Yongji Wu, Kaichao You, Fengyuan Ren, Zhiying Xu, Costin Raiciu, Ion Stoica</dc:creator>
    </item>
    <item>
      <title>ATRO: A Fast Algorithm for Topology Engineering of Reconfigurable Datacenter Networks</title>
      <link>https://arxiv.org/abs/2507.13717</link>
      <description>arXiv:2507.13717v2 Announce Type: replace 
Abstract: Reconfigurable data center networks (DCNs) enhance traditional architectures with optical circuit switches (OCSs), enabling dynamic reconfiguration of inter-pod links, i.e., the logical topology. Optimizing this topology is crucial for adapting to traffic dynamics but is challenging due to its combinatorial nature. The complexity increases further when demands can be distributed across multiple paths, requiring joint optimization of topology and routing. We propose Alternating Topology and Routing Optimization (ATRO), a unified framework that supports both one-hop topology optimization (where traffic is routed via direct paths) and multi-hop joint optimization (where routing is also optimized). Although these settings differ in constraints, both are combinatorially hard and challenge solver-based methods. ATRO addresses both cases efficiently: in the one-hop case, it guarantees the global optimum via an accelerated binary search; in the multi-hop case, it alternates between topology and routing updates, with routing steps optionally accelerated by existing traffic engineering (TE) methods. ATRO supports warm-starting and improves solution quality monotonically across iterations. ATRO remains competitive even when paired with solver-free TE methods, forming a fully solver-free optimization pipeline that still outperforms prior approaches in runtime and maximum link utilization across diverse workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13717v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingming Mao, Qiaozhu Zhai, Ximeng Liu, Xinchi Han, Fafan li, Shizhen Zhao, Yuzhou Zhou, Zhen Yao, Xia Zhu</dc:creator>
    </item>
    <item>
      <title>Automatic Configuration Protocols for Optical Quantum Networks</title>
      <link>https://arxiv.org/abs/2504.19613</link>
      <description>arXiv:2504.19613v2 Announce Type: replace-cross 
Abstract: Before quantum networks can scale up to practical sizes, there are many deployment and configuration tasks that must be automated. Currently, quantum networking testbeds are largely manually configured: network nodes are constructed out of a combination of free-space and fiber optics before being connected to shared single-photon detectors, time-to-digital converters, and optical switches. Information about these connections must be tracked manually; mislabeling may result in experimental failure and protracted debugging sessions. In this paper, we propose protocols and algorithms to automate two such manual processes. First, we address the problem of automatically identifying connections between quantum network nodes and time-to-digital converters. Then, we turn to the more complex challenge of identifying the nodes attached to a quantum network's optical switches. Implementation of these protocols will help enable the development of other protocols necessary for quantum networks, such as network topology discovery, link quality monitoring, resource naming, and routing. We intend for this paper to serve as a roadmap for near-term implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19613v2</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Taherkhani, Andrew Todd, Kentaro Teramoto, Rodney Van Meter, Shota Nagayama</dc:creator>
    </item>
    <item>
      <title>The Starlink Robot: A Platform and Dataset for Mobile Satellite Communication</title>
      <link>https://arxiv.org/abs/2506.19781</link>
      <description>arXiv:2506.19781v3 Announce Type: replace-cross 
Abstract: The integration of satellite communication into mobile devices represents a paradigm shift in connectivity, yet the performance characteristics under motion and environmental occlusion remain poorly understood. We present the Starlink Robot, the first mobile robotic platform equipped with Starlink satellite internet, comprehensive sensor suite including upward-facing camera, LiDAR, and IMU, designed to systematically study satellite communication performance during movement. Our multi-modal dataset captures synchronized communication metrics, motion dynamics, sky visibility, and 3D environmental context across diverse scenarios including steady-state motion, variable speeds, and different occlusion conditions. This platform and dataset enable researchers to develop motion-aware communication protocols, predict connectivity disruptions, and optimize satellite communication for emerging mobile applications from smartphones to autonomous vehicles. In this work, we use LEOViz for real-time satellite tracking and data collection. The starlink robot project is available at https://github.com/StarlinkRobot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19781v3</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Boyi Liu, Qianyi Zhang, Qiang Yang, Jianhao Jiao, Jagmohan Chauhan, Dimitrios Kanoulas</dc:creator>
    </item>
  </channel>
</rss>
