<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Jun 2024 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Experimental Validation of Cooperative RSS-based Localization with Unknown Transmit Power, Path Loss Exponent, and Precise Anchor Location</title>
      <link>https://arxiv.org/abs/2406.14664</link>
      <description>arXiv:2406.14664v1 Announce Type: new 
Abstract: Received signal strength (RSS)--based cooperative localization has gained significant attention due to its straightforward system architectures and cost-effectiveness. In this paper, we propose Cooperative Localization Techniques (with Unknown Parameters), referred to as CTUP(s), which consider uncertainty in anchor nodes' locations and assume the transmit power and \textcolor{blue}{path loss exponent (PLE)} to be unknown. Unlike prior studies, CTUP(s) address unknowns by estimating these parameters, along with the location of target nodes. The non-convex and non-linear nature of the maximum likelihood (ML) estimator of the problem is addressed through relaxation techniques, employing Taylor series expansion, semidefinite relaxation (SDR), and the epigraph method. The resulting problem is solved using semidefinite second-order cone programming (SDP-SOCP), leveraging the precision of SDP and the simplicity of SOCP. We deployed an extensive network comprising 50 BLE nodes covering an area of 640~m $\times$ 180~m to gather RSS data. The precise location of the nodes is obtained using real-time kinematics global positioning system (RTK-GPS), which is treated as the ground truth. Furthermore, to replicate real-world scenarios, we recorded the positions of the anchor nodes using a standard GPS, thereby introducing uncertainty into the anchor node locations. Extensive simulation and hardware experimentation demonstrate the superior performance of CTUP compared to existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14664v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingquan Li, Bodhibrata Mukhopadhyay, Jiajie Xu, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Cost-Effective RF Fingerprinting Based on Hybrid CVNN-RF Classifier with Automated Multi-Dimensional Early-Exit Strategy</title>
      <link>https://arxiv.org/abs/2406.14869</link>
      <description>arXiv:2406.14869v1 Announce Type: new 
Abstract: While the Internet of Things (IoT) technology is booming and offers huge opportunities for information exchange, it also faces unprecedented security challenges. As an important complement to the physical layer security technologies for IoT, radio frequency fingerprinting (RFF) is of great interest due to its difficulty in counterfeiting. Recently, many machine learning (ML)-based RFF algorithms have emerged. In particular, deep learning (DL) has shown great benefits in automatically extracting complex and subtle features from raw data with high classification accuracy. However, DL algorithms face the computational cost problem as the difficulty of the RFF task and the size of the DNN have increased dramatically. To address the above challenge, this paper proposes a novel costeffective early-exit neural network consisting of a complex-valued neural network (CVNN) backbone with multiple random forest branches, called hybrid CVNN-RF. Unlike conventional studies that use a single fixed DL model to process all RF samples, our hybrid CVNN-RF considers differences in the recognition difficulty of RF samples and introduces an early-exit mechanism to dynamically process the samples. When processing "easy" samples that can be well classified with high confidence, the hybrid CVNN-RF can end early at the random forest branch to reduce computational cost. Conversely, subsequent network layers will be activated to ensure accuracy. To further improve the early-exit rate, an automated multi-dimensional early-exit strategy is proposed to achieve scheduling control from multiple dimensions within the network depth and classification category. Finally, our experiments on the public ADS-B dataset show that the proposed algorithm can reduce the computational cost by 83% while improving the accuracy by 1.6% under a classification task with 100 categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14869v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiayan Gan, Zhixing Du, Qiang Li, Huaizong Shao, Jingran Lin, Ye Pan, Zhongyi Wen, Shafei Wang</dc:creator>
    </item>
    <item>
      <title>Multi-beam Training for Near-field Communications in High-frequency Bands</title>
      <link>https://arxiv.org/abs/2406.14931</link>
      <description>arXiv:2406.14931v1 Announce Type: new 
Abstract: In this paper, we study efficient multi-beam training design for near-field communications to reduce the beam training overhead of conventional single-beam training methods. In particular, the array-division based multi-beam training method, which is widely used in far-field communications, cannot be directly applied to the near-field scenario, since different sub-arrays may observe different user angles and there exist coverage holes in the angular domain. To address these issues, we first devise a new near-field multi-beam codebook by sparsely activating a portion of antennas to form a sparse linear array (SLA), hence generating multiple beams simultaneously by effective exploiting the near-field grating-lobs. Next, a two-stage near-field beam training method is proposed, for which several candidate user locations are identified firstly based on multi-beam sweeping over time, followed by the second stage to further determine the true user location with a small number of single-beam sweeping. Finally, numerical results show that our proposed multi-beam training method significantly reduces the beam training overhead of conventional single-beam training methods, yet achieving comparable rate performance in data transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14931v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cong Zhou, Changsheng You, Zixuan Huang, Shuo Shi, Yi Gong, Chan-Byoung Chae, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Rate-Splitting Multiple Access for Overloaded Multi-group Multicast: A First Experimental Study</title>
      <link>https://arxiv.org/abs/2406.15217</link>
      <description>arXiv:2406.15217v1 Announce Type: new 
Abstract: Multi-group multicast (MGM) is an increasingly important form of multi-user wireless communications with several potential applications, such as video streaming, federated learning, safety-critical vehicular communications, etc. Rate-Splitting Multiple Access (RSMA) is a powerful interference management technique that can, in principle, achieve higher data rates and greater fairness for all types of multi-user wireless communications, including MGM. This paper presents the first-ever experimental evaluation of RSMA-based MGM, as well as the first-ever three-way comparison of RSMA-based, Space Divison Multiple Access (SDMA)-based and Non-Orthogonal Multiple Access (NOMA)-based MGM. Using a measurement setup involving a two-antenna transmitter and two groups of two single-antenna users per group, we consider the problem of realizing throughput (max-min) fairness across groups for each of three multiple access schemes, over nine experimental cases in a line-of-sight environment capturing varying levels of pathloss difference and channel correlation across the groups. Over these cases, we observe that RSMA-based MGM achieves fairness at a higher throughput for each group than SDMA- and NOMA-based MGM. These findings validate RSMA-based MGM's promised gains from the theoretical literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15217v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinze Lyu, Sundar Aditya, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Model-Based Learning for Network Clock Synchronization in Half-Duplex TDMA Networks</title>
      <link>https://arxiv.org/abs/2406.15258</link>
      <description>arXiv:2406.15258v1 Announce Type: new 
Abstract: Supporting increasingly higher rates in wireless networks requires highly accurate clock synchronization across the nodes. Motivated by this need, in this work we consider distributed clock synchronization for half-duplex (HD) TDMA wireless networks. We focus on pulse-coupling (PC)-based synchronization as it is practically advantageous for high-speed networks using low-power nodes. Previous works on PC-based synchronization for TDMA networks assumed full-duplex communications, and focused on correcting the clock phase at each node, without synchronizing clocks' frequencies. However, as in the HD regime corrections are temporally sparse, uncompensated clock frequency differences between the nodes result in large phase drifts between updates. Moreover, as the clocks determine the processing rates at the nodes, leaving the clocks' frequencies unsynchronized results in processing rates mismatch between the nodes, leading to a throughput reduction. Our goal in this work is to synchronize both clock frequency and clock phase across the clocks in HD TDMA networks, via distributed processing. The key challenges are the coupling between frequency correction and phase correction, and the lack of a computationally efficient analytical framework for determining the optimal correction signal at the nodes. We address these challenges via a DNN-aided nested loop structure in which the DNN are used for generating the weights applied to the loop input for computing the correction signal. This loop is operated in a sequential manner which decouples frequency and phase compensations, thereby facilitating synchronization of both parameters. Performance evaluation shows that the proposed scheme significantly improves synchronization accuracy compared to the conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15258v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Itay Zino, Ron Dabora, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>A novel optical assay system for bilirubin concentration measurement in whole blood</title>
      <link>https://arxiv.org/abs/2406.14816</link>
      <description>arXiv:2406.14816v1 Announce Type: cross 
Abstract: As a biomarker for liver disease, bilirubin has been utilized in prognostic scoring systems for cirrhosis. While laboratory-based methods are used to determine bilirubin levels in clinical settings, they do not readily lend themselves to applications outside of hospitals. Consequently, bilirubin monitoring for cirrhotic patients is often performed only intermittently; thus, episodes requiring clinical interventions could be missed. This work investigates the feasibility of measuring bilirubin concentration in whole porcine blood samples using dual-wavelength transmission measurement. A compact and low-cost dual-wavelength transmission measurement setup is developed and optimized to measure whole blood bilirubin concentrations. Using small volumes of whole porcine blood (72 {\mu}L), we measured the bilirubin concentration within a range corresponding to healthy individuals and cirrhotic patients (1.2-30 mg/dL). We demonstrate that bilirubin levels can be estimated with a positive correlation (R-square &gt; 0.95) and an accuracy of +/- 1.7 mg/dL, with higher reliability in cirrhotic bilirubin concentrations (&gt; 4 mg/dL), critical for high-risk patients. The optical and electronic components utilized are economical and can be readily integrated into a miniature, low-cost, and user-friendly system. This could provide a pathway for point-of-care monitoring of blood bilirubin outside of medical facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14816v1</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TBME.2021.3111150</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Biomedical Engineering 69.2 (2021): 983-990</arxiv:journal_reference>
      <dc:creator>Jean Pierre Ndabakuranye, Anushi E. Rajapaksa, Genia Burchall, Shiqiang Li, Steven Prawer, Arman Ahnood</dc:creator>
    </item>
    <item>
      <title>RIS-aided MIMO Beamforming: Piece-Wise Near-field Channel Model</title>
      <link>https://arxiv.org/abs/2406.14939</link>
      <description>arXiv:2406.14939v1 Announce Type: cross 
Abstract: This paper proposes a joint active and passive beamforming design for reconfigurable intelligent surface (RIS)-aided wireless communication systems, adopting a piece-wise near-field channel model. While a traditional near-field channel model, applied without any approximations, offers higher modeling accuracy than a far-field model, it renders the system design more sensitive to channel estimation errors (CEEs). As a remedy, we propose to adopt a piece-wise near-field channel model that leverages the advantages of the near-field approach while enhancing its robustness against CEEs. Our study analyzes the impact of different channel models, including the traditional near-field, the proposed piece-wise near-field and far-field channel models, on the interference distribution caused by CEEs and model mismatches. Subsequently, by treating the interference as noise, we formulate a joint active and passive beamforming design problem to maximize the spectral efficiency (SE). The formulated problem is then recast as a mean squared error (MSE) minimization problem and a suboptimal algorithm is developed to iteratively update the active and passive beamforming strategies. Simulation results demonstrate that adopting the piece-wise near-field channel model leads to an improved SE compared to both the near-field and far-field models in the presence of CEEs. Furthermore, the proposed piece-wise near-field model achieves a good trade-off between modeling accuracy and system's degrees of freedom (DoF).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14939v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weijian Chen, Zai Yang, Zhiqiang Wei, Derrick Wing Kwan Ng, Michail Matthaiou</dc:creator>
    </item>
    <item>
      <title>Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health</title>
      <link>https://arxiv.org/abs/2406.14953</link>
      <description>arXiv:2406.14953v1 Announce Type: cross 
Abstract: Photoplethysmography (PPG) is emerging as a crucial tool for monitoring human hemodynamics, with recent studies highlighting its potential in assessing vascular aging through deep learning. However, real-world age distributions are often imbalanced, posing significant challenges for deep learning models. In this paper, we introduce a novel, simple, and effective loss function named the Dist Loss to address deep imbalanced regression tasks. We trained a one-dimensional convolutional neural network (Net1D) incorporating the Dist Loss on the extensive UK Biobank dataset (n=502,389) to estimate vascular age from PPG signals and validate its efficacy in characterizing cardiovascular health. The model's performance was validated on a 40% held-out test set, achieving state-of-the-art results, especially in regions with small sample sizes. Furthermore, we divided the population into three subgroups based on the difference between predicted vascular age and chronological age: less than -10 years, between -10 and 10 years, and greater than 10 years. We analyzed the relationship between predicted vascular age and several cardiovascular events over a follow-up period of up to 10 years, including death, coronary heart disease, and heart failure. Our results indicate that the predicted vascular age has significant potential to reflect an individual's cardiovascular health status. Our code will be available at https://github.com/Ngk03/AI-vascular-age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14953v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangkun Nie, Qinghao Zhao, Gongzheng Tang, Jun Li, Shenda Hong</dc:creator>
    </item>
    <item>
      <title>Probabilistic and Differentiable Wireless Simulation with Geometric Transformers</title>
      <link>https://arxiv.org/abs/2406.14995</link>
      <description>arXiv:2406.14995v1 Announce Type: cross 
Abstract: Modelling the propagation of electromagnetic signals is critical for designing modern communication systems. While there are precise simulators based on ray tracing, they do not lend themselves to solving inverse problems or the integration in an automated design loop. We propose to address these challenges through differentiable neural surrogates that exploit the geometric aspects of the problem. We first introduce the Wireless Geometric Algebra Transformer (Wi-GATr), a generic backbone architecture for simulating wireless propagation in a 3D environment. It uses versatile representations based on geometric algebra and is equivariant with respect to E(3), the symmetry group of the underlying physics. Second, we study two algorithmic approaches to signal prediction and inverse problems based on differentiable predictive modelling and diffusion models. We show how these let us predict received power, localize receivers, and reconstruct the 3D environment from the received signal. Finally, we introduce two large, geometry-focused datasets of wireless signal propagation in indoor scenes. In experiments, we show that our geometry-forward approach achieves higher-fidelity predictions with less data than various baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14995v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Hehn, Markus Peschl, Tribhuvanesh Orekondy, Arash Behboodi, Johann Brehmer</dc:creator>
    </item>
    <item>
      <title>Optimal Transmit Signal Design for Multi-Target MIMO Sensing Exploiting Prior Information</title>
      <link>https://arxiv.org/abs/2406.15047</link>
      <description>arXiv:2406.15047v1 Announce Type: cross 
Abstract: In this paper, we study the transmit signal optimization in a multiple-input multiple-output (MIMO) radar system for sensing the angle information of multiple targets via their reflected echo signals. We consider a challenging and practical scenario where the angles to be sensed are unknown and random, while their probability information is known a priori for exploitation. First, we establish an analytical framework to quantify the multi-target sensing performance exploiting prior distribution information, by deriving the posterior Cram\'{e}r-Rao bound (PCRB) as a lower bound of the mean-squared error (MSE) matrix in sensing multiple unknown and random angles. Then, we formulate and study the transmit sample covariance matrix optimization problem to minimize the PCRB for the sum MSE in estimating all angles. By leveraging Lagrange duality theory, we analytically prove that the optimal transmit covariance matrix has a rank-one structure, despite the multiple angles to be sensed and the continuous feasible range of each angle. Moreover, we propose a sum-of-ratios iterative algorithm which can obtain the optimal solution to the PCRB-minimization problem with low complexity. Numerical results validate our results and the superiority of our proposed design over benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15047v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Yao, Shuowen Zhang</dc:creator>
    </item>
    <item>
      <title>Continuous Aperture Array (CAPA)-Based Wireless Communications: Capacity Characterization</title>
      <link>https://arxiv.org/abs/2406.15056</link>
      <description>arXiv:2406.15056v1 Announce Type: cross 
Abstract: The capacity limits of continuous-aperture array (CAPA)-based wireless communications are characterized. To this end, an analytically tractable transmission framework is established for both uplink and downlink CAPA systems. Based on this framework, closed-form expressions for the single-user channel capacity are derived. The results are further extended to a multiuser case by characterizing the capacity limits of a two-user channel and proposing the associated capacity-achieving decoding and encoding schemes. 1) For the uplink case, the sum-rate capacity and capacity region, as well as the capacity-achieving detectors, are derived. 2) For the downlink case, the uplink-downlink duality is established by deriving the uplink-to-downlink and downlink-to-uplink transformations under the same power constraint, based on which the optimal power allocation policy and the achieved sum-rate capacity and capacity region are characterized. To gain further insights, several case studies are presented by specializing the derived results into various array structures, including the planar CAPA, linear CAPA, and planar spatially discrete array (SPDA). Numerical results are provided to reveal that: i) the channel capacity achieved by CAPAs converges towards a finite upper bound as the aperture size increases; and ii) CAPAs offer significant capacity gains over the conventional SPDAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15056v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boqun Zhao, Chongjun Ouyang, Xingqi Zhang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Exploring Audio-Visual Information Fusion for Sound Event Localization and Detection In Low-Resource Realistic Scenarios</title>
      <link>https://arxiv.org/abs/2406.15160</link>
      <description>arXiv:2406.15160v1 Announce Type: cross 
Abstract: This study presents an audio-visual information fusion approach to sound event localization and detection (SELD) in low-resource scenarios. We aim at utilizing audio and video modality information through cross-modal learning and multi-modal fusion. First, we propose a cross-modal teacher-student learning (TSL) framework to transfer information from an audio-only teacher model, trained on a rich collection of audio data with multiple data augmentation techniques, to an audio-visual student model trained with only a limited set of multi-modal data. Next, we propose a two-stage audio-visual fusion strategy, consisting of an early feature fusion and a late video-guided decision fusion to exploit synergies between audio and video modalities. Finally, we introduce an innovative video pixel swapping (VPS) technique to extend an audio channel swapping (ACS) method to an audio-visual joint augmentation. Evaluation results on the Detection and Classification of Acoustic Scenes and Events (DCASE) 2023 Challenge data set demonstrate significant improvements in SELD performances. Furthermore, our submission to the SELD task of the DCASE 2023 Challenge ranks first place by effectively integrating the proposed techniques into a model ensemble.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15160v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ya Jiang, Qing Wang, Jun Du, Maocheng Hu, Pengfei Hu, Zeyan Liu, Shi Cheng, Zhaoxu Nian, Yuxuan Dong, Mingqi Cai, Xin Fang, Chin-Hui Lee</dc:creator>
    </item>
    <item>
      <title>Deep UAV Path Planning with Assured Connectivity in Dense Urban Setting</title>
      <link>https://arxiv.org/abs/2406.15225</link>
      <description>arXiv:2406.15225v1 Announce Type: cross 
Abstract: Unmanned Ariel Vehicle (UAV) services with 5G connectivity is an emerging field with numerous applications. Operator-controlled UAV flights and manual static flight configurations are major limitations for the wide adoption of scalability of UAV services. Several services depend on excellent UAV connectivity with a cellular network and maintaining it is challenging in predetermined flight paths. This paper addresses these limitations by proposing a Deep Reinforcement Learning (DRL) framework for UAV path planning with assured connectivity (DUPAC). During UAV flight, DUPAC determines the best route from a defined source to the destination in terms of distance and signal quality. The viability and performance of DUPAC are evaluated under simulated real-world urban scenarios using the Unity framework. The results confirm that DUPAC achieves an autonomous UAV flight path similar to base method with only 2% increment while maintaining an average 9% better connection quality throughout the flight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15225v1</guid>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiyong Oh, Syed M. Raza, Lusungu J. Mwasinga, Moonseong Kim, Hyunseung Choo</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of Deep Learning and Iterative Algorithms for Joint Channel Estimation and Signal Detection in OFDM Systems</title>
      <link>https://arxiv.org/abs/2303.03678</link>
      <description>arXiv:2303.03678v3 Announce Type: replace 
Abstract: Joint channel estimation and signal detection (JCESD) is crucial in orthogonal frequency division multiplexing (OFDM) systems, but traditional algorithms perform poorly in low signal-to-noise ratio (SNR) scenarios. Deep learning (DL) methods have been investigated, but concerns regarding computational expense and lack of validation in low-SNR settings remain. Hence, the development of a robust and low-complexity model that can deliver excellent performance across a wide range of SNRs is highly desirable. In this paper, we aim to establish a benchmark where traditional algorithms and DL methods are validated on different channel models, Doppler, and SNR settings, particularly focusing on the semi-blind setting. In particular, we propose a new DL model where the backbone network is formed by unrolling the iterative algorithm, and the hyperparameters are estimated by hypernetworks. Additionally, we adapt a lightweight DenseNet to the task of JCESD for comparison. We evaluate different methods in three aspects: generalization in terms of bit error rate (BER), robustness, and complexity. Our results indicate that DL approaches outperform traditional algorithms in the challenging low-SNR setting, while the iterative algorithm performs better in high-SNR settings. Furthermore, the iterative algorithm is more robust in the presence of carrier frequency offset, whereas DL methods excel when signals are corrupted by asymmetric Gaussian noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03678v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sigpro.2024.109554</arxiv:DOI>
      <arxiv:journal_reference>Signal Processing 223 (2024), 109554</arxiv:journal_reference>
      <dc:creator>Haocheng Ju, Haimiao Zhang, Lin Li, Xiao Li, Bin Dong</dc:creator>
    </item>
    <item>
      <title>Detecting Low Pass Graph Signals via Spectral Pattern: Sampling Complexity and Applications</title>
      <link>https://arxiv.org/abs/2306.01553</link>
      <description>arXiv:2306.01553v3 Announce Type: replace 
Abstract: This paper proposes a blind detection problem for low pass graph signals. Without assuming knowledge of the exact graph topology, we aim to detect if a set of graph signal observations are generated from a low pass graph filter. Our problem is motivated by the widely adopted assumption of low pass (a.k.a.~smooth) signals required by many existing works in graph signal processing (GSP), as well as the longstanding problem of network dynamics identification. Focusing on detecting low pass graph signals on modular graphs whose cutoff frequency coincides with the number of clusters in the graph, we propose to leverage the unique spectral pattern exhibited by such low pass graph signals. We analyze the sample complexity of these detectors considering the effects of graph filter's properties, random delays, and other parameters. We show novel applications of the blind detector on robustifying graph learning, identifying antagonistic ties in opinion dynamics, and detecting anomalies in power systems. Numerical experiments validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01553v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyue Zhang, Yiran He, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>A Geometry-based Stochastic Wireless Channel Model using Channel Images</title>
      <link>https://arxiv.org/abs/2312.06637</link>
      <description>arXiv:2312.06637v5 Announce Type: replace 
Abstract: Due to the high complexity of geometry-deterministic wireless channel modeling and the difficulty in its implementation, geometry-based stochastic channel modeling (GBSM) approaches have been used to evaluate wireless systems. This paper introduces a new method to model any GBSM by training a generative neural network using images formed by channel parameters. In this work, we obtain channel parameters from the ray-tracing simulation in a specific area and process them in the form of images to train any generative model. Through a case study, we confirm that the use of channel images completes the training of the generative model within 10 epochs. In addition, we show that the trained generative model based on channel images faithfully represents the distributions of the original data under the assigned conditions. Therefore, we argue that the proposed data-to-image methods will facilitate the modeling of GBSM using any generative neural network under general wireless conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06637v5</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seongjoon Kang</dc:creator>
    </item>
    <item>
      <title>A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers</title>
      <link>https://arxiv.org/abs/2402.10748</link>
      <description>arXiv:2402.10748v2 Announce Type: replace 
Abstract: Wearable systems for the continuous and real-time monitoring of cardiovascular diseases are becoming widespread and valuable assets in diagnosis and therapy. A promising approach for real-time analysis of the electrocardiographic (ECG) signal and the detection of heart conditions, such as arrhythmia, is represented by the transformer machine learning model. Transformers are powerful models for the classification of time series, although efficient implementation in the wearable domain raises significant design challenges, to combine adequate accuracy and a suitable complexity. In this work, we present a tiny transformer model for the analysis of the ECG signal, requiring only 6k parameters and reaching 98.97% accuracy in the recognition of the 5 most common arrhythmia classes from the MIT-BIH Arrhythmia database, assessed considering 8-bit integer inference as required for efficient execution on low-power microcontroller-based devices. We explored an augmentation-based training approach for improving the robustness against electrode motion artifacts noise, resulting in a worst-case post-deployment performance assessment of 98.36% accuracy. Suitability for wearable monitoring solutions is finally demonstrated through efficient deployment on the parallel ultra-low-power GAP9 processor, where inference execution requires 4.28ms and 0.09mJ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10748v2</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TBCAS.2024.3401858</arxiv:DOI>
      <dc:creator>Paola Busia, Matteo Antonio Scrugli, Victor Jean-Baptiste Jung, Luca Benini, Paolo Meloni</dc:creator>
    </item>
    <item>
      <title>Geometric Neural Network based on Phase Space for BCI-EEG decoding</title>
      <link>https://arxiv.org/abs/2403.05645</link>
      <description>arXiv:2403.05645v2 Announce Type: replace 
Abstract: The integration of Deep Learning (DL) algorithms on brain signal analysis is still in its nascent stages compared to their success in fields like Computer Vision, especially in Brain-Computer Interface (BCI), where the brain activity is decoded to control external devices without requiring muscle control. Electroencephalography (EEG) is a widely adopted choice for designing BCI systems due to its non-invasive and cost-effective nature and excellent temporal resolution. Still, it comes at the expense of limited training data, poor signal-to-noise, and a large variability across and within-subject recordings. Finally, setting up a BCI system with many electrodes takes a long time, hindering the widespread adoption of reliable DL architectures in BCIs outside research laboratories. To improve adoption, we need to improve user comfort using, for instance, reliable algorithms that operate with few electrodes. Approach: Our research aims to develop a DL algorithm that delivers effective results with a limited number of electrodes. Taking advantage of the Augmented Covariance Method with SPDNet, we propose the SPDNet$_{\psi}$ architecture and analyze its performance and computational impact, as well as the interpretability of the results. The evaluation is conducted on 5-fold cross-validation, using only three electrodes positioned above the Motor Cortex. The methodology was tested on nearly 100 subjects from several open-source datasets using the Mother Of All BCI Benchmark (MOABB) framework. Main results: The results of our SPDNet$_{\psi}$ demonstrate that the augmented approach combined with the SPDNet significantly outperforms all the current state-of-the-art DL architecture in MI decoding. Significance: This new architecture is explainable, with a low number of trainable parameters and a reduced carbon footprint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05645v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Igor Carrara, Bruno Aristimunha, Marie-Constance Corsi, Raphael Y. de Camargo, Sylvain Chevallier, Th\'eodore Papadopoulo</dc:creator>
    </item>
    <item>
      <title>Thin Film Reconfigurable Intelligent Surface for Harmonic Beam Steering</title>
      <link>https://arxiv.org/abs/2406.06343</link>
      <description>arXiv:2406.06343v2 Announce Type: replace 
Abstract: This letter explores an implementation of a novel thin film 1-by-4 reconfigurable intelligent surface (RIS) designed for future communication and sensing scenarios. Utilizing cost-effective inkjet printing methods and additive manufacturing, our approach significantly simplifies the RIS construction process and reduces production costs. The RIS, fabricated on a flexible and lightweight polyethylene terephthalate (PET) substrate, integrates antennas, switching circuitry, and a microcontroller unit (MCU), without a ground shield. This setup enables individual and simultaneous control of each RIS element, manipulating the captured carrier signal by reflecting and refracting its dominant harmonics. Beams of the harmonics can be steered to multiple desired directions at both front and back sides of the surface. Measurement results of the beam steering show that the RIS has the potential to enable RIS-aided communication and sensing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06343v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boxuan Xie, Aleksandr Kuznetsov, Lauri Mela, Jari Lietz\'en, Kalle Ruttik, Alp Karako\c{c}, Riku J\"antti</dc:creator>
    </item>
    <item>
      <title>On Lattice-Code based Multiple Access: Uplink Architecture and Algorithms</title>
      <link>https://arxiv.org/abs/2210.00778</link>
      <description>arXiv:2210.00778v2 Announce Type: replace-cross 
Abstract: This paper studies a lattice-code based multiple-access (LCMA) framework, and develops a package of processing techniques that are essential to its practical implementation. In the uplink, $K$ users encode their messages with the same ring coded modulation of $2^{m}$-PAM signaling. With it, the integer sum of multiple codewords belongs to the $n$-dimension lattice of the base code. Such property enables efficient \textit{algebraic binning} for computing linear combinations of $K$ users' messages. For the receiver, we devise two new algorithms, based on linear physical-layer network coding and linear filtering, to calculate the symbol-wise a posteriori probabilities (APPs) w.r.t. the $K$ streams of linear codeword combinations. The resultant APP streams are forwarded to the $q$-ary belief-propagation decoders, which parallelly compute $K$ streams of linear message combinations. Finally, by multiplying the inverse of the coefficient matrix, all users' messages are recovered. Even with single-stage parallel processing, LCMA is shown to support a remarkably larger number of users and exhibits improved frame error rate (FER) relative to existing NOMA systems such as IDMA and SCMA. Further, we propose a new multi-stage LCMA receiver relying on \emph{generalized matrix inversion}. With it, a near-capacity performance is demonstrated for a wide range of system loads. Numerical results demonstrate that the number of users that LCMA can support is no less than 350\% of the length of the spreading sequence or number of receive antennas. Since LCMA relaxes receiver iteration, off-the-shelf channel codes in standards can be directly utilized, avoiding the compatibility and convergence issue of channel code and detector in IDMA and SCMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00778v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Yang. Fangtao Yu, Qiuzhuo Chen, Rongke Liu</dc:creator>
    </item>
    <item>
      <title>A Low-Overhead Incorporation-Extrapolation based Few-Shot CSI Feedback Framework for Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2312.04062</link>
      <description>arXiv:2312.04062v2 Announce Type: replace-cross 
Abstract: Accurate channel state information (CSI) is essential for downlink precoding in frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems with orthogonal frequency-division multiplexing (OFDM). However, obtaining CSI through feedback from the user equipment (UE) becomes challenging with the increasing scale of antennas and subcarriers and leads to extremely high CSI feedback overhead. Deep learning-based methods have emerged for compressing CSI but these methods generally require substantial collected samples and thus pose practical challenges. Moreover, existing deep learning methods also suffer from dramatically growing feedback overhead owing to their focus on full-dimensional CSI feedback. To address these issues, we propose a low-overhead Incorporation-Extrapolation based Few-Shot CSI feedback Framework (IEFSF) for massive MIMO systems. An incorporation-extrapolation scheme for eigenvector-based CSI feedback is proposed to reduce the feedback overhead. Then, to alleviate the necessity of extensive collected samples and enable few-shot CSI feedback, we further propose a knowledge-driven data augmentation (KDDA) method and an artificial intelligence-generated content (AIGC) -based data augmentation method by exploiting the domain knowledge of wireless channels and by exploiting a novel generative model, respectively. Experimental results based on the DeepMIMO dataset demonstrate that the proposed IEFSF significantly reduces CSI feedback overhead by 64 times compared with existing methods while maintaining higher feedback accuracy using only several hundred collected samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04062v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binggui Zhou, Xi Yang, Jintao Wang, Shaodan Ma, Feifei Gao, Guanghua Yang</dc:creator>
    </item>
    <item>
      <title>Advancing Ultra-Reliable 6G: Transformer and Semantic Localization Empowered Robust Beamforming in Millimeter-Wave Communications</title>
      <link>https://arxiv.org/abs/2406.02000</link>
      <description>arXiv:2406.02000v2 Announce Type: replace-cross 
Abstract: Advancements in 6G wireless technology have elevated the importance of beamforming, especially for attaining ultra-high data rates via millimeter-wave (mmWave) frequency deployment. Although promising, mmWave bands require substantial beam training to achieve precise beamforming. While initial deep learning models that use RGB camera images demonstrated promise in reducing beam training overhead, their performance suffers due to sensitivity to lighting and environmental variations. Due to this sensitivity, Quality of Service (QoS) fluctuates, eventually affecting the stability and dependability of networks in dynamic environments. This emphasizes a critical need for more robust solutions. This paper proposes a robust beamforming technique to ensure consistent QoS under varying environmental conditions. An optimization problem has been formulated to maximize users' data rates. To solve the formulated NP-hard optimization problem, we decompose it into two subproblems: the semantic localization problem and the optimal beam selection problem. To solve the semantic localization problem, we propose a novel method that leverages the k-means clustering and YOLOv8 model. To solve the beam selection problem, we propose a novel lightweight hybrid architecture that utilizes various data sources and a weighted entropy-based mechanism to predict the optimal beams. Rapid and accurate beam predictions are needed to maintain QoS. A novel metric, Accuracy-Complexity Efficiency (ACE), has been proposed to quantify this. Six testing scenarios have been developed to evaluate the robustness of the proposed model. Finally, the simulation result demonstrates that the proposed model outperforms several state-of-the-art baselines regarding beam prediction accuracy, received power, and ACE in the developed test scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02000v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Avi Deb Raha, Kitae Kim, Apurba Adhikary, Mrityunjoy Gain, Choong Seon Hong</dc:creator>
    </item>
  </channel>
</rss>
