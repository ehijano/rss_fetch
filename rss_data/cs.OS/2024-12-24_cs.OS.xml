<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fast and Live Model Auto Scaling with O(1) Host Caching</title>
      <link>https://arxiv.org/abs/2412.17246</link>
      <description>arXiv:2412.17246v1 Announce Type: cross 
Abstract: Model autoscaling is the key mechanism to achieve serverless model-as-a-service, but it faces a fundamental trade-off between scaling speed and storage/memory usage to cache parameters, and cannot meet frequent scaling requirements across multiple hosts. The key problem is that data plane performance is slow, and scaled instances remain stopped while parameters are loading. We first show that data plane can be made fast with no/O(1) caching by loading parameters through the compute network between GPUs because: (1) its speed is comparable host cache and is underutilized; (2) scaling multiple instances requires no or O(1) caching with network-optimized multicast. Second, autoscaling can be made live by breaking the scaling abstraction from a coarse-grained instance-level to a fine-grained layer-level. This allows us to offload the layer computation from the overloaded serving instances to the scaled instance with cooperative execution, thus handles cases even when the compute network is not sufficiently fast. Our system BLITZSCALE reduces the serving tail latencies by up to 86% without caching, and we achieve comparable performance (or even better) to an optimal setup where all the parameters are cached at all the host for autoscaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17246v1</guid>
      <category>cs.DC</category>
      <category>cs.OS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dingyan Zhang, Haotian Wang, Yang Liu, Xingda Wei, Yizhou Shan, Rong Chen, Haibo Chen</dc:creator>
    </item>
    <item>
      <title>Integrating Artificial Intelligence into Operating Systems: A Comprehensive Survey on Techniques, Applications, and Future Directions</title>
      <link>https://arxiv.org/abs/2407.14567</link>
      <description>arXiv:2407.14567v2 Announce Type: replace 
Abstract: In the era of the Internet of Everything, operating systems (OSs) face unprecedented challenges posed by an evolving application landscape and increasingly heterogeneous hardware ecosystems. This shift toward increasingly dynamic and unpredictable operational contexts presents significant challenges for both OS developers and users. Against this backdrop, the fusion of Artificial Intelligence (AI) with Operating Systems emerges as a critical frontier for innovation. This survey delves into the intricate interplay between AI and OSs, illustrating how existing OS mechanisms combined with AI significantly elevate the performance, security, and efficiency of modern operating systems. We investigate a range of AI methodologies applied to optimize core OS functionalities and clarify the correlation to related studies. Our analysis touches on the existing hurdles and prospective avenues in this interdisciplinary domain, underscoring the imperative for robust and seamless integration of AI capabilities into OS architectures.
  Through an examination of illustrative case studies and cutting-edge developments, we offer a thorough review of the current status of AI-OS integration, accentuating its pivotal role in steering the evolution of advanced computing paradigms. We also envision the promising prospects of Intelligent Operating Systems, debating how groundbreaking OS designs will usher in novel possibilities and highlight the central role that AI will assume in propelling these next-generation systems forward. This forward-thinking outlook illuminates the profound influence of AI on the foundational elements of computing, heralding the advent of a new epoch characterized by intelligent, self-adapting, and highly adaptive software ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14567v2</guid>
      <category>cs.OS</category>
      <category>cs.AI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Zhang, Xinkui Zhao, Ziying Li, Jianwei Yin, Lufei Zhang, Zuoning Chen</dc:creator>
    </item>
    <item>
      <title>Contextualizing Security and Privacy of Software-Defined Vehicles: State of the Art and Industry Perspectives</title>
      <link>https://arxiv.org/abs/2411.10612</link>
      <description>arXiv:2411.10612v2 Announce Type: replace-cross 
Abstract: The growing reliance on software in vehicles has given rise to the concept of Software-Defined Vehicles (SDVs), fundamentally reshaping the vehicles and the automotive industry. This survey explores the cybersecurity and privacy challenges posed by SDVs, which increasingly integrate features like Over-the-Air (OTA) updates and Vehicle-to-Everything (V2X) communication. While these advancements enhance vehicle capabilities and flexibility, they also come with a flip side: increased exposure to security risks including API vulnerabilities, third-party software risks, and supply-chain threats. The transition to SDVs also raises significant privacy concerns, with vehicles collecting vast amounts of sensitive data, such as location and driver behavior, that could be exploited using inference attacks. This work aims to provide a detailed overview of security threats, mitigation strategies, and privacy risks in SDVs, primarily through a literature review, enriched with insights from a targeted questionnaire with industry experts. Key topics include defining SDVs, comparing them to Connected Vehicles (CVs) and Autonomous Vehicles (AVs), discussing the security challenges associated with OTA updates and the impact of SDV features on data privacy. Our findings highlight the need for robust security frameworks, standardized communication protocols, and privacy-preserving techniques to address the issues of SDVs. This work ultimately emphasizes the importance of a multi-layered defense strategy,integrating both in-vehicle and cloud-based security solutions, to safeguard future SDVs and increase user trust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10612v2</guid>
      <category>cs.CR</category>
      <category>cs.OS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco De Vincenzi, Mert D. Pes\'e, Chiara Bodei, Ilaria Matteucci, Richard R. Brooks, Monowar Hasan, Andrea Saracino, Mohammad Hamad, Sebastian Steinhorst</dc:creator>
    </item>
  </channel>
</rss>
