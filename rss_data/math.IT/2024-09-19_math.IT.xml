<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Sep 2024 01:45:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fluid Antenna-enabled Integrated Sensing, Communication, and Computing Systems</title>
      <link>https://arxiv.org/abs/2409.11622</link>
      <description>arXiv:2409.11622v1 Announce Type: new 
Abstract: The current integrated sensing, communication, and computing (ISCC) systems face significant challenges in both efficiency and resource utilization. To tackle these issues, we propose a novel fluid antenna (FA)-enabled ISCC system, specifically designed for vehicular networks. We develop detailed models for the communication and sensing processes to support this architecture. An integrated latency optimization problem is formulated to jointly optimize computing resources, receive combining matrices, and antenna positions. To tackle this complex problem, we decompose it into three sub-problems and analyze each separately. A mixed optimization algorithm is then designed to address the overall problem comprehensively. Numerical results demonstrate the rapid convergence of the proposed algorithm. Compared with baseline schemes, the FA-enabled vehicle ISCC system significantly improves resource utilization and reduces latency for communication, sensing, and computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11622v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiping Zuo, Jiajia Guo, Weicong Chen, Weibei Fan, Biyun Sheng, Fu Xiao, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Synchronizable hybrid subsystem codes</title>
      <link>https://arxiv.org/abs/2409.11312</link>
      <description>arXiv:2409.11312v1 Announce Type: cross 
Abstract: Quantum synchronizable codes are quantum error correcting codes that can correct not only Pauli errors but also errors in block synchronization. The code can be constructed from two classical cyclic codes $\mathcal{C}$, $\mathcal{D}$ satisfying $\mathcal{C}^{\perp} \subset \mathcal{C} \subset \mathcal{D}$ through the Calderbank-Shor-Steane (CSS) code construction. In this work, we establish connections between quantum synchronizable codes, subsystem codes, and hybrid codes constructed from the same pair of classical cyclic codes. We also propose a method to construct a synchronizable hybrid subsystem code which can correct both Pauli and synchronization errors, is resilient to gauge errors by virtue of the subsystem structure, and can transmit both classical and quantum information, all at the same time. The trade-offs between the number of synchronization errors that the code can correct, the number of gauge qubits, and the number of logical classical bits of the code are also established. In addition, we propose general methods to construct hybrid and hybrid subsystem codes of CSS type from classical codes, which cover relevant codes from our main construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11312v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theerapat Tansuwannont, Andrew Nemec</dc:creator>
    </item>
    <item>
      <title>On the second-order zero differential properties of several classes of power functions over finite fields</title>
      <link>https://arxiv.org/abs/2409.11693</link>
      <description>arXiv:2409.11693v2 Announce Type: cross 
Abstract: Feistel Boomerang Connectivity Table (FBCT) is an important cryptanalytic technique on analysing the resistance of the Feistel network-based ciphers to power attacks such as differential and boomerang attacks. Moreover, the coefficients of FBCT are closely related to the second-order zero differential spectra of the function $F(x)$ over the finite fields with even characteristic and the Feistel boomerang uniformity is the second-order zero differential uniformity of $F(x)$. In this paper, by computing the number of solutions of specific equations over finite fields, we determine explicitly the second-order zero differential spectra of power functions $x^{2^m+3}$ and $x^{2^m+5}$ with $m&gt;2$ being a positive integer over finite field with even characteristic, and $x^{p^k+1}$ with integer $k\geq1$ over finite field with odd characteristic $p$. It is worth noting that $x^{2^m+3}$ is a permutation over $\mathbb{F}_{2^n}$ and only when $m$ is odd, $x^{2^m+5}$ is a permutation over $\mathbb{F}_{2^n}$, where integer $n=2m$. As a byproduct, we find $F(x)=x^4$ is a PN and second-order zero differentially $0$-uniform function over $\mathbb{F}_{3^n}$ with odd $n$. The computation of these entries and the cardinalities in each table aimed to facilitate the analysis of differential and boomerang cryptanalysis of S-boxes when studying distinguishers and trails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11693v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan Zhou, Xiaoni Du, Xingbin Qiao, Wenping Yuan</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Constructing Minimum-Weight Codewords in Some Extended Binary BCH Codes</title>
      <link>https://arxiv.org/abs/2305.17764</link>
      <description>arXiv:2305.17764v2 Announce Type: replace 
Abstract: We present $O(m^3)$ algorithms for specifying the support of minimum-weight words of extended binary BCH codes of length $n=2^m$ and designed distance $d(m,s,i):=2^{m-1-s}-2^{m-1-i-s}$ for some values of $m,i,s$, where $m$ may grow to infinity. The support is specified as the sum of two sets: a set of $2^{2i-1}-2^{i-1}$ elements, and a subspace of dimension $m-2i-s$, specified by a basis.
  In some detail, for designed distance $6\cdot 2^j$, we have a deterministic algorithm for even $m\geq 4$, and a probabilistic algorithm with success probability $1-O(2^{-m})$ for odd $m&gt;4$. For designed distance $28\cdot 2^j$, we have a probabilistic algorithm with success probability $\geq 1/3-O(2^{-m/2})$ for even $m\geq 6$. Finally, for designed distance $120\cdot 2^j$, we have a deterministic algorithm for $m\geq 8$ divisible by $4$. We also present a construction via Gold functions when $2i|m$.
  Our construction builds on results of Kasami and Lin (IEEE T-IT, 1972), who proved that for extended binary BCH codes of designed distance $d(m,s,i)$, the minimum distance equals the designed distance. Their proof makes use of a non-constructive result of Berlekamp (Inform. Contrl., 1970), and a constructive ``down-conversion theorem'' that converts some words in BCH codes to lower-weight words in BCH codes of lower designed distance. Our main contribution is in replacing the non-constructive argument of Berlekamp by a low-complexity algorithm.
  In one aspect, we extends the results of Grigorescu and Kaufman (IEEE T-IT, 2012), who presented explicit minimum-weight words for designed distance $6$ (and hence also for designed distance $6\cdot 2^j$, by a well-known ``up-conversion theorem''), as we cover more cases of the minimum distance. However, the minimum-weight words we construct are not affine generators for designed distance $&gt;6$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17764v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Berman, Yaron Shany, Itzhak Tamo</dc:creator>
    </item>
    <item>
      <title>Practical Radar Sensing Using Two Stage Neural Network for Denoising OTFS Signals</title>
      <link>https://arxiv.org/abs/2310.00897</link>
      <description>arXiv:2310.00897v2 Announce Type: replace 
Abstract: Our objective is to derive the range and velocity of multiple targets from the delay-Doppler domain for radar sensing using orthogonal time frequency space (OTFS) signaling. Noise contamination affects the performance of OTFS signals in real-world environments, making radar sensing challenging. This work introduces a two-stage approach to tackle this issue. In the first stage, we use a generative adversarial network to denoise the corrupted OTFS samples, significantly improving the data quality. Following this, the denoised signals are passed to a convolutional neural network model to predict the values of the velocities and ranges of multiple targets. The proposed two-stage approach can predict the range and velocity of multiple targets, even in very low signal-to-noise ratio scenarios, with high accuracy and outperforms existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00897v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ashok S Kumar, Sheetal Kalyani</dc:creator>
    </item>
    <item>
      <title>Using Waste Factor to Optimize Energy Efficiency in Multiple-Input Single-Output (MISO) and Multiple-Input Multiple-Output (MIMO) Systems</title>
      <link>https://arxiv.org/abs/2405.01352</link>
      <description>arXiv:2405.01352v2 Announce Type: replace 
Abstract: This paper introduces Waste Factor (W) and Waste Figure (WF) to assess power efficiency in any multiple-input multiple-output (MIMO) or single-input multiple-output (SIMO) or multiple-input single-output (MISO) cascaded communication system. This paper builds upon the new theory of Waste Factor, which systematically models added wasted power in any cascade for parallel systems such as MISO, SIMO, and MIMO systems, which are prevalent in current wireless networks. Here, we also show the advantage of W compared to conventional metrics for quantifying and analyzing energy efficiency. This work explores the utility of W in assessing energy efficiency in communication channels, within Radio Access Networks (RANs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01352v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingjun Ying, Dipankar Shakya, Theodore S. Rappaport</dc:creator>
    </item>
    <item>
      <title>Improved Channel Coding Performance Through Cost Variability</title>
      <link>https://arxiv.org/abs/2407.05260</link>
      <description>arXiv:2407.05260v2 Announce Type: replace 
Abstract: Channel coding for discrete memoryless channels (DMCs) with mean and variance cost constraints has been recently introduced. We show that there is an improvement in coding performance due to cost variability, both with and without feedback. We demonstrate this improvement over the traditional almost-sure cost constraint (also called the peak-power constraint) that prohibits any cost variation above a fixed threshold. Our result simultaneously shows that feedback does not improve the second-order coding rate of simple-dispersion DMCs under the peak-power constraint. This finding parallels similar results for unconstrained simple-dispersion DMCs, additive white Gaussian noise (AWGN) channels and parallel Gaussian channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05260v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adeel Mahmood, Aaron B. Wagner</dc:creator>
    </item>
    <item>
      <title>On the Statistical Complexity of Sample Amplification</title>
      <link>https://arxiv.org/abs/2201.04315</link>
      <description>arXiv:2201.04315v2 Announce Type: replace-cross 
Abstract: The ``sample amplification'' problem formalizes the following question: Given $n$ i.i.d. samples drawn from an unknown distribution $P$, when is it possible to produce a larger set of $n+m$ samples which cannot be distinguished from $n+m$ i.i.d. samples drawn from $P$? In this work, we provide a firm statistical foundation for this problem by deriving generally applicable amplification procedures, lower bound techniques and connections to existing statistical notions. Our techniques apply to a large class of distributions including the exponential family, and establish a rigorous connection between sample amplification and distribution learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.04315v2</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Axelrod, Shivam Garg, Yanjun Han, Vatsal Sharan, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Adversarial attacks on neural networks through canonical Riemannian foliations</title>
      <link>https://arxiv.org/abs/2203.00922</link>
      <description>arXiv:2203.00922v3 Announce Type: replace-cross 
Abstract: Deep learning models are known to be vulnerable to adversarial attacks. Adversarial learning is therefore becoming a crucial task. We propose a new vision on neural network robustness using Riemannian geometry and foliation theory. The idea is illustrated by creating a new adversarial attack that takes into account the curvature of the data space. This new adversarial attack, called the two-step spectral attack is a piece-wise linear approximation of a geodesic in the data space. The data space is treated as a (degenerate) Riemannian manifold equipped with the pullback of the Fisher Information Metric (FIM) of the neural network. In most cases, this metric is only semi-definite and its kernel becomes a central object to study. A canonical foliation is derived from this kernel. The curvature of transverse leaves gives the appropriate correction to get a two-step approximation of the geodesic and hence a new efficient adversarial attack. The method is first illustrated on a 2D toy example in order to visualize the neural network foliation and the corresponding attacks. Next, we report numerical results on the MNIST and CIFAR10 datasets with the proposed technique and state of the art attacks presented in Zhao et al. (2019) (OSSA) and Croce et al. (2020) (AutoAttack). The result show that the proposed attack is more efficient at all levels of available budget for the attack (norm of the attack), confirming that the curvature of the transverse neural network FIM foliation plays an important role in the robustness of neural networks. The main objective and interest of this study is to provide a mathematical understanding of the geometrical issues at play in the data space when constructing efficient attacks on neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.00922v3</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.IT</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eliot Tron, Nicolas Couellan, St\'ephane Puechmorel</dc:creator>
    </item>
    <item>
      <title>Computationally efficient reductions between some statistical models</title>
      <link>https://arxiv.org/abs/2402.07717</link>
      <description>arXiv:2402.07717v2 Announce Type: replace-cross 
Abstract: We study the problem of approximately transforming a sample from a source statistical model to a sample from a target statistical model without knowing the parameters of the source model, and construct several computationally efficient such reductions between canonical statistical experiments. In particular, we provide computationally efficient procedures that approximately reduce uniform, Erlang, and Laplace location models to general target families. We illustrate our methodology by establishing nonasymptotic reductions between some canonical high-dimensional problems, spanning mixtures of experts, phase retrieval, and signal denoising. Notably, the reductions are structure-preserving and can accommodate missing data. We also point to a possible application in transforming one differentially private mechanism to another.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07717v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengqi Lou, Guy Bresler, Ashwin Pananjady</dc:creator>
    </item>
  </channel>
</rss>
