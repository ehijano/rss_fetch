<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 01:52:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Analogy making as the basis of statistical inference</title>
      <link>https://arxiv.org/abs/2504.16186</link>
      <description>arXiv:2504.16186v1 Announce Type: new 
Abstract: Standard statistical theory has arguably proved to be unsuitable as a basis for constructing a satisfactory completely general framework for performing statistical inference. For example, frequentist theory has never come close to providing such a general inferential framework, which is not only attributable to the question surrounding the soundness of this theory, but also to its focus on attempting to address the problem of how to perform statistical inference only in certain special cases. Also, theories of inference that are grounded in the idea of deducing sample-based inferences about populations of interest from a given set of universally acceptable axioms, e.g. many theories that aim to justify Bayesian inference and theories of imprecise probability, suffer from the difficulty of finding such axioms that are weak enough to be widely acceptable, but strong enough to lead to methods of inference that can be regarded as being efficient. These observations justify the need to look for an alternative means by which statistical inference may be performed, and in particular, to explore the one that is offered by analogy making. What is presented here goes down this path. To be clear, this is done in a way that does not simply endorse the common use of analogy making as a supplementary means of understanding how statistical methods work, but formally develops analogy making as the foundation of a general framework for performing statistical inference. In the latter part of the paper, the use of this framework is illustrated by applying some of the most important analogies contained within it to a relatively simple but arguably still unresolved problem of statistical inference, which naturally leads to an original way being put forward of addressing issues that relate to Bartlett's and Lindley's paradoxes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16186v1</guid>
      <category>stat.OT</category>
      <category>stat.ME</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Russell J. Bowater</dc:creator>
    </item>
  </channel>
</rss>
