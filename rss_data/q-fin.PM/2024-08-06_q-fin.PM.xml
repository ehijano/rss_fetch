<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.PM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.PM</link>
    <description>q-fin.PM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.PM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2024 01:34:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Investment strategies based on forecasts are (almost) useless</title>
      <link>https://arxiv.org/abs/2408.01772</link>
      <description>arXiv:2408.01772v1 Announce Type: new 
Abstract: Several studies on portfolio construction reveal that sensible strategies essentially yield the same results as their nonsensical inverted counterparts; moreover, random portfolios managed by Malkiel's dart-throwing monkey would outperform the cap-weighted benchmark index. Forecasting the future development of stock returns is an important aspect of portfolio assessment. Similar to the ostensible arbitrariness of portfolio selection methods, it is shown that there is no substantial difference between the performances of ``best'' and ``trivial'' forecasts - even under euphemistic model assumptions on the underlying price dynamics. A certain significance of a predictor is found only in the following special case: the best linear unbiased forecast is used, the planning horizon is small, and a critical relation is not satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01772v1</guid>
      <category>q-fin.PM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Weba</dc:creator>
    </item>
    <item>
      <title>AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models with Neural Networks</title>
      <link>https://arxiv.org/abs/2407.19858</link>
      <description>arXiv:2407.19858v2 Announce Type: replace 
Abstract: In quantitative finance, machine learning methods are essential for alpha generation. This study introduces a new approach that combines Hidden Markov Models (HMM) and neural networks, integrated with Black-Litterman portfolio optimization. During the COVID period (2019-2022), this dual-model approach achieved a 97% return with a Sharpe ratio of 0.992. It incorporates two risk models to enhance risk management, showing efficiency during volatile periods. The methodology was implemented on the QuantConnect platform, which was chosen for its robust framework and experimental reproducibility. The system, which predicts future price movements, includes a three-year warm-up to ensure proper algorithm function. It targets highly liquid, large-cap energy stocks to ensure stable and predictable performance while also considering broker payments. The dual-model alpha system utilizes log returns to select the optimal state based on the historical performance. It combines state predictions with neural network outputs, which are based on historical data, to generate trading signals. This study examined the architecture of the trading system, data pre-processing, training, and performance. The full code and backtesting data are available under the MIT license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19858v2</guid>
      <category>q-fin.PM</category>
      <category>cs.LG</category>
      <category>q-fin.GN</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiago Monteiro</dc:creator>
    </item>
    <item>
      <title>Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow</title>
      <link>https://arxiv.org/abs/2407.18103</link>
      <description>arXiv:2407.18103v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) and their fine-tuning techniques have demonstrated superior performance in various language understanding and generation tasks. This paper explores fine-tuning LLMs for stock return forecasting with financial newsflow. In quantitative investing, return forecasting is fundamental for subsequent tasks like stock picking, portfolio optimization, etc. We formulate the model to include text representation and forecasting modules. We propose to compare the encoder-only and decoder-only LLMs, considering they generate text representations in distinct ways. The impact of these different representations on forecasting performance remains an open question. Meanwhile, we compare two simple methods of integrating LLMs' token-level representations into the forecasting module. The experiments on real news and investment universes reveal that: (1) aggregated representations from LLMs' token-level embeddings generally produce return predictions that enhance the performance of long-only and long-short portfolios; (2) in the relatively large investment universe, the decoder LLMs-based prediction model leads to stronger portfolios, whereas in the small universes, there are no consistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama), Mistral performs more robustly across different universes; (3) return predictions derived from LLMs' text representations are a strong signal for portfolio construction, outperforming conventional sentiment scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18103v2</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian Guo, Emmanuel Hauptmann</dc:creator>
    </item>
  </channel>
</rss>
