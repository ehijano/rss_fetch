<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MS</link>
    <description>cs.MS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Apr 2025 01:48:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>auto-fpt: Automating Free Probability Theory Calculations for Machine Learning Theory</title>
      <link>https://arxiv.org/abs/2504.10754</link>
      <description>arXiv:2504.10754v1 Announce Type: cross 
Abstract: A large part of modern machine learning theory often involves computing the high-dimensional expected trace of a rational expression of large rectangular random matrices. To symbolically compute such quantities using free probability theory, we introduce auto-fpt, a lightweight Python and SymPy-based tool that can automatically produce a reduced system of fixed-point equations which can be solved for the quantities of interest, and effectively constitutes a theory. We overview the algorithmic ideas underlying auto-fpt and its applications to various interesting problems, such as the high-dimensional error of linearized feed-forward neural networks, recovering well-known results. We hope that auto-fpt streamlines the majority of calculations involved in high-dimensional analysis, while helping the machine learning community reproduce known and uncover new phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10754v1</guid>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Subramonian, Elvis Dohmatob</dc:creator>
    </item>
    <item>
      <title>Low-Rank SPIKE Framework for Solving Large Sparse Linear Systems with Applications</title>
      <link>https://arxiv.org/abs/2504.11167</link>
      <description>arXiv:2504.11167v1 Announce Type: cross 
Abstract: The SPIKE family of linear system solvers provides parallelism using a block tridiagonal partitioning. Typically SPIKE-based solvers are applied to banded systems, resulting in structured off-diagonal blocks with non-zeros elements restricted to relatively small submatrices comprising the band of the original matrix. In this work, a low-rank SVD based approximation of the off-diagonal blocks is investigated. This produces a representation which more effectively handles matrices with large, sparse bands. A set of flexible distributed solvers, the LR-SPIKE variants, are implemented. There are applicable to a wide range of applications -- from use as a "black-box" preconditioner which straightforwardly improves upon the classic Block Jacobi preconditioner, to use as a specialized "approximate direct solver." An investigation of the effectiveness of the new preconditioners for a selection of SuiteSparse matrices is performed, particularly focusing on matrices derived from 3D finite element simulations. In addition, the SPIKE approximate linear system solvers are also paired with the FEAST eigenvalue solver, where they are shown to be particularly effective due to the former's rapid convergence, and the latter's acceptance of loose linear system solver convergence, resulting in a combination which requires very few solver iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11167v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Braegan S. Spring, Eric Polizzi, Ahmed H. Sameh</dc:creator>
    </item>
    <item>
      <title>Performant Automatic BLAS Offloading on Unified Memory Architecture with OpenMP First-Touch Style Data Movement</title>
      <link>https://arxiv.org/abs/2501.00279</link>
      <description>arXiv:2501.00279v3 Announce Type: replace-cross 
Abstract: BLAS is a fundamental building block of advanced linear algebra libraries and many modern scientific computing applications. GPUs are known for their strong arithmetic computing capabilities and are highly suited for BLAS operations. However, porting code to GPUs often requires significant effort, especially for large, complex codes or legacy codes, even for BLAS-heavy applications. While various tools exist to automatically offload BLAS to GPUs, they are often impractical due to the high costs associated with mandatory data transfers. The advent of unified memory architectures in recent GPU designs, such as the NVIDIA Grace-Hopper, allows cache-coherent memory access across all types of memory for both CPU and GPU, potentially eliminating the bottlenecks faced in conventional architectures. This breakthrough paves the way for innovative application developments and porting strategies. Building on our preliminary work demonstrating the potential of automatic *gemm offload, this paper extends the framework to all level-3 BLAS operations and introduces SCILIB-Accel, a novel tool for automatic BLAS offload. SCILIB-Accel leverages the memory coherency in Grace-Hopper and introduces a Device First-Use data movement policy inspired by the OpenMP First-Touch approach in multi-socket CPU programming, minimizing CPU-GPU data transfers for typical scientific computing codes. Additionally, utilizing dynamic binary instrumentation, the tool intercepts BLAS symbols directly from a CPU binary, requiring no code modifications or recompilation. SCILIB-Accel has been evaluated using multiple quantum physics codes on up to a few hundred GPU nodes, yielding promising speedups. Notably, for the LSMS method in the MuST suite, a 3x speedup was achieved on Grace-Hopper compared to Grace-Grace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00279v3</guid>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <category>cs.SE</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junjie Li</dc:creator>
    </item>
  </channel>
</rss>
