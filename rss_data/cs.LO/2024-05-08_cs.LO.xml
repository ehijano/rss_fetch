<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 May 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Axiomatization of approximate exclusion</title>
      <link>https://arxiv.org/abs/2405.04998</link>
      <description>arXiv:2405.04998v1 Announce Type: new 
Abstract: We define and axiomatize approximate exclusion atoms in the team semantic setting. A team is a set of assignments, which can be seen as a mathematical model of a uni-relational database, and we say that an approximate exclusion atom is satisfied in a team if the corresponding usual exclusion atom is satisfied in a large enough subteam. We consider the implication problem for approximate exclusion atoms and show that it is axiomatizable for consequences with a degree of approximation that is not too large. We prove the completeness theorem for usual exclusion atoms, which is currently missing from the literature, and generalize it to approximate exclusion atoms. We also provide a polynomial time algorithm for the implication problems. The results also apply to exclusion dependencies in database theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04998v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matilda H\"aggblom</dc:creator>
    </item>
    <item>
      <title>The Existential Theory of the Reals with Summation Operators</title>
      <link>https://arxiv.org/abs/2405.04697</link>
      <description>arXiv:2405.04697v1 Announce Type: cross 
Abstract: To characterize the computational complexity of satisfiability problems for probabilistic and causal reasoning within the Pearl's Causal Hierarchy, arXiv:2305.09508 [cs.AI] introduce a new natural class, named succ-$\exists$R. This class can be viewed as a succinct variant of the well-studied class $\exists$R based on the Existential Theory of the Reals (ETR). Analogously to $\exists$R, succ-$\exists$R is an intermediate class between NEXP and EXPSPACE, the exponential versions of NP and PSPACE. The main contributions of this work are threefold. Firstly, we characterize the class succ-$\exists$R in terms of nondeterministic real RAM machines and develop structural complexity theoretic results for real RAMs, including translation and hierarchy theorems. Notably, we demonstrate the separation of $\exists$R and succ-$\exists$R. Secondly, we examine the complexity of model checking and satisfiability of fragments of existential second-order logic and probabilistic independence logic. We show succ-$\exists$R- completeness of several of these problems, for which the best-known complexity lower and upper bounds were previously NEXP-hardness and EXPSPACE, respectively. Thirdly, while succ-$\exists$R is characterized in terms of ordinary (non-succinct) ETR instances enriched by exponential sums and a mechanism to index exponentially many variables, in this paper, we prove that when only exponential sums are added, the corresponding class $\exists$R^{\Sigma} is contained in PSPACE. We conjecture that this inclusion is strict, as this class is equivalent to adding a VNP-oracle to a polynomial time nondeterministic real RAM. Conversely, the addition of exponential products to ETR, yields PSPACE. Additionally, we study the satisfiability problem for probabilistic reasoning, with the additional requirement of a small model and prove that this problem is complete for $\exists$R^{\Sigma}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04697v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Bl\"aser, Julian D\"orfler, Maciej Liskiewicz, Benito van der Zander</dc:creator>
    </item>
    <item>
      <title>Logical Negation Augmenting and Debiasing for Prompt-based Methods</title>
      <link>https://arxiv.org/abs/2405.04872</link>
      <description>arXiv:2405.04872v1 Announce Type: cross 
Abstract: Prompt-based methods have gained increasing attention on NLP and shown validity on many downstream tasks. Many works have focused on mining these methods' potential for knowledge extraction, but few explore their ability to make logical reasoning. In this work, we focus on the effectiveness of the prompt-based methods on first-order logical reasoning and find that the bottleneck lies in logical negation. Based on our analysis, logical negation tends to result in spurious correlations to negative answers, while propositions without logical negation correlate to positive answers. To solve the problem, we propose a simple but effective method, Negation Augmenting and Negation Debiasing (NAND), which introduces negative propositions to prompt-based methods without updating parameters. Specifically, these negative propositions can counteract spurious correlations by providing "not" for all instances so that models cannot make decisions only by whether expressions contain a logical negation. Experiments on three datasets show that NAND not only solves the problem of calibrating logical negation but also significantly enhances prompt-based methods of logical reasoning without model retraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04872v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitian Li, Jidong Tian, Hao He, Yaohui Jin</dc:creator>
    </item>
    <item>
      <title>Reasonable Space for the $\lambda$-Calculus, Logarithmically</title>
      <link>https://arxiv.org/abs/2203.00362</link>
      <description>arXiv:2203.00362v4 Announce Type: replace 
Abstract: Can the $\lambda$-calculus be considered a reasonable computational model? Can we use it for measuring the time $\textit{and}$ space consumption of algorithms? While the literature contains positive answers about time, much less is known about space. This paper presents a new reasonable space cost model for the $\lambda$-calculus, based on a variant over the Krivine abstract machine. For the first time, this cost model is able to accommodate logarithmic space. Moreover, we study the time behavior of our machine and show how to transport our results to the call-by-value $\lambda$-calculus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.00362v4</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Beniamino Accattoli, Ugo Dal Lago, Gabriele Vanoni</dc:creator>
    </item>
    <item>
      <title>On Tools for Completeness of Kleene Algebra with Hypotheses</title>
      <link>https://arxiv.org/abs/2210.13020</link>
      <description>arXiv:2210.13020v4 Announce Type: replace 
Abstract: In the literature on Kleene algebra, a number of variants have been proposed which impose additional structure specified by a theory, such as Kleene algebra with tests (KAT) and the recent Kleene algebra with observations (KAO), or make specific assumptions about certain constants, as for instance in NetKAT. Many of these variants fit within the unifying perspective offered by Kleene algebra with hypotheses, which comes with a canonical language model constructed from a given set of hypotheses. For the case of KAT, this model corresponds to the familiar interpretation of expressions as languages of guarded strings. A relevant question therefore is whether Kleene algebra together with a given set of hypotheses is complete with respect to its canonical language model. In this paper, we revisit, combine and extend existing results on this question to obtain tools for proving completeness in a modular way. We showcase these tools by giving new and modular proofs of completeness for KAT, KAO and NetKAT, and we prove completeness for new variants of KAT: KAT extended with a constant for the full relation, KAT extended with a converse operation, and a version of KAT where the collection of tests only forms a distributive lattice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.13020v4</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Pous, Jurriaan Rot, Jana Wagemaker</dc:creator>
    </item>
    <item>
      <title>Lattice-preserving $\mathcal{ALC}$ ontology embeddings</title>
      <link>https://arxiv.org/abs/2305.07163</link>
      <description>arXiv:2305.07163v2 Announce Type: replace 
Abstract: Generating vector representations (embeddings) of OWL ontologies is a growing task due to its applications in predicting missing facts and knowledge-enhanced learning in fields such as bioinformatics. The underlying semantics of OWL ontologies is expressed using Description Logics (DLs). Initial approaches to generate embeddings relied on constructing a graph out of ontologies, neglecting the semantics of the logic therein. Recent semantic-preserving embedding methods often target lightweight DL languages like $\mathcal{EL}^{++}$, ignoring more expressive information in ontologies. Although some approaches aim to embed more descriptive DLs like $\mathcal{ALC}$, those methods require the existence of individuals, while many real-world ontologies are devoid of them. We propose an ontology embedding method for the $\mathcal{ALC}$ DL language that considers the lattice structure of concept descriptions. We use connections between DL and Category Theory to materialize the lattice structure and embed it using an order-preserving embedding method. We show that our method outperforms state-of-the-art methods in several knowledge base completion tasks. We make our code and data available at https://github.com/bio-ontology-research-group/catE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07163v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Zhapa-Camacho, Robert Hoehndorf</dc:creator>
    </item>
    <item>
      <title>Proving Confluence in the Confluence Framework with CONFident</title>
      <link>https://arxiv.org/abs/2306.16330</link>
      <description>arXiv:2306.16330v2 Announce Type: replace 
Abstract: This article describes the *Confluence Framework*, a novel framework for proving and disproving confluence using a divide-and-conquer modular strategy, and its implementation in CONFident. Using this approach, we are able to automatically prove and disprove confluence of *Generalized Term Rewriting Systems*, where (i) only selected arguments of function symbols can be rewritten and (ii) a rather general class of conditional rules can be used. This includes, as particular cases, several variants of rewrite systems such as (context-sensitive) *term rewriting systems*, *string rewriting systems*, and (context-sensitive) *conditional term rewriting systems*. The divide-and-conquer modular strategy allows us to combine in a proof tree different techniques for proving confluence, including modular decompositions, checking joinability of (conditional) critical and variable pairs, transformations, etc., and auxiliary tasks required by them, e.g., joinability of terms, joinability of conditional pairs, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16330v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ra\'ul Guti\'errez, Salvador Lucas, Miguel V\'itores</dc:creator>
    </item>
    <item>
      <title>Generalized Weighted Type Graphs for Termination of Graph Transformation Systems</title>
      <link>https://arxiv.org/abs/2307.07601</link>
      <description>arXiv:2307.07601v2 Announce Type: replace 
Abstract: We refine the weighted type graph technique for proving termination of double pushout (DPO) graph transformation systems. We increase the power of the approach for graphs, we generalize the technique to other categories, and we allow for variations of DPO that occur in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07601v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\"org Endrullis, Roy Overbeek</dc:creator>
    </item>
    <item>
      <title>Many-valued coalgebraic logic over semi-primal varieties</title>
      <link>https://arxiv.org/abs/2308.14581</link>
      <description>arXiv:2308.14581v4 Announce Type: replace 
Abstract: We study many-valued coalgebraic logics with semi-primal algebras of truth-degrees. We provide a systematic way to lift endofunctors defined on the variety of Boolean algebras to endofunctors on the variety generated by a semi-primal algebra. We show that this can be extended to a technique to lift classical coalgebraic logics to many-valued ones, and that (one-step) completeness and expressivity are preserved under this lifting. For specific classes of endofunctors, we also describe how to obtain an axiomatization of the lifted many-valued logic directly from an axiomatization of the original classical one. In particular, we apply all of these techniques to classical modal logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14581v4</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Kurz, Wolfgang Poiger, Bruno Teheux</dc:creator>
    </item>
    <item>
      <title>A Completeness Theorem for Probabilistic Regular Expressions</title>
      <link>https://arxiv.org/abs/2310.08779</link>
      <description>arXiv:2310.08779v2 Announce Type: replace 
Abstract: We introduce Probabilistic Regular Expressions (PRE), a probabilistic analogue of regular expressions denoting probabilistic languages in which every word is assigned a probability of being generated. We present and prove the completeness of an inference system for reasoning about probabilistic language equivalence of PRE based on Salomaa's axiomatisation of Kleene Algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08779v2</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wojciech R\'o\.zowski, Alexandra Silva</dc:creator>
    </item>
    <item>
      <title>Two-dimensional Kripke Semantics I: Presheaves</title>
      <link>https://arxiv.org/abs/2405.04157</link>
      <description>arXiv:2405.04157v2 Announce Type: replace 
Abstract: The study of modal logic has witnessed tremendous development following the introduction of Kripke semantics. However, recent developments in programming languages and type theory have led to a second way of studying modalities, namely through their categorical semantics. We show how the two correspond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04157v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.FSCD.2024.11</arxiv:DOI>
      <arxiv:journal_reference>LIPIcs, Volume 299, FSCD 2024, article 11</arxiv:journal_reference>
      <dc:creator>G. A. Kavvos</dc:creator>
    </item>
  </channel>
</rss>
