<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Parametric Disjunctive Cuts for Sequences of Mixed Integer Linear Optimization Problems</title>
      <link>https://arxiv.org/abs/2511.15873</link>
      <description>arXiv:2511.15873v1 Announce Type: new 
Abstract: Many applications require solving sequences of related mixed-integer linear programs. We introduce a class of parametric disjunctive inequalities (PDIs), obtained by reusing the disjunctive proofs of optimality from prior solves to construct cuts valid for perturbed instances. We describe several methods of generating such cuts that navigate the tradeoff between computational expense and strength. We provide sufficient conditions under which PDIs support the disjunctive hull and a tightening step that guarantees support when needed. On perturbed instances from MIPLIB 2017, augmenting branch-and-cut with PDIs substantially improves performance, reducing total solve times on the majority of challenging cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15873v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shannon Kelley, Aleksandr M. Kazachkov, Ted Ralphs</dc:creator>
    </item>
    <item>
      <title>Single-loop variance reduction methods in Bregman setups for finite-sum structured variational inequalities</title>
      <link>https://arxiv.org/abs/2511.16007</link>
      <description>arXiv:2511.16007v1 Announce Type: new 
Abstract: In this paper, we address variational inequalities (VI) with a finite sum structure by proposing a novel single-loop variance-reduced algorithm that incorporates the Bregman distance. Under the monotone setting, we establish the almost sure convergence of the proposed algorithm and prove that it achieves the optimal complexity of $\mathcal{O}\left(\frac{\sqrt{M}}{\varepsilon }\right)$ for finding an $\varepsilon$-gap. Furthermore, under the non-monotone setting, we derive a complexity of $\mathcal{O}\left(\frac{1}{\varepsilon^2 }\right)$ of the algorithm. Our proposed method yields complexity results that either match or improve the state-of-the-art complexity bounds reported in existing literature. Notably, this work is the first to rigorously establish the linear convergence rate of the algorithm for solving finite-sum variational inequalities in Bregman setups. Finally, we report two numerical experiments to validate the effectiveness and practical performance of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16007v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wang Zhong-bao, Zhang Zhong-cheng</dc:creator>
    </item>
    <item>
      <title>Data informativity for stabilization of discrete-time infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2511.16008</link>
      <description>arXiv:2511.16008v1 Announce Type: new 
Abstract: This paper develops a data-driven framework for stabilization of discrete-time infinite-dimensional systems. We investigate informativity for stabilization, defined as the existence of a feedback gain that stabilizes all systems compatible with the available input-state data. Assuming that infinite-length data are Bessel sequences, we first establish a sufficient condition for data informativity in the noise-free case. We next show that this sufficient condition is also necessary under a mild data assumption when the input space is one-dimensional. Furthermore, if the state sequence forms a frame, then the sufficient condition can be extended to the case of noisy data. Finally, when the unstable part of the true system is known to be finite-dimensional, we derive a necessary and sufficient condition for data informativity of finite-length data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16008v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masashi Wakaiki</dc:creator>
    </item>
    <item>
      <title>A novel way of computing the shape derivative for a class of non-smooth PDEs and its impact on deriving necessary conditions for locally optimal shapes</title>
      <link>https://arxiv.org/abs/2511.16127</link>
      <description>arXiv:2511.16127v1 Announce Type: new 
Abstract: We derive necessary conditions for locally optimal shapes of a design problem governed by a non-smooth PDE. The main particularity of the state system is the lack of differentiability of the nonlinearity. We work in the framework of the functional variational approach (FVA), which has the capacity to transfer geometric optimization problems into optimal control problems, the set of admissible shapes being parametrized by a large class of continuous mappings. In the FVA setting, we introduce a sensitivity analysis technique that is novel even for smooth PDEs. We emphasize that we do not resort to extensions on the hold-all domain or any kind of approximation of the original PDE. The computation of the directional derivative of the state w.r.t. functional variations results in a new way of computing the shape derivative. The presented approach allows us to handle in the objective pointwise observation and derivatives of the state on an observation set as well as distributed observation terms. In addition, we introduce the concept of locally optimal shapes and we put into evidence its connection to locally minimizers of the corresponding control problem. With directional differentiability results for the control-to-state map at our disposal, we can then state necessary conditions for locally optimal shapes in general non-smooth settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16127v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DG</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Livia Betz</dc:creator>
    </item>
    <item>
      <title>Physics-informed Gaussian Processes as Linear Model Predictive Controller with Constraint Satisfaction</title>
      <link>https://arxiv.org/abs/2511.16195</link>
      <description>arXiv:2511.16195v1 Announce Type: new 
Abstract: Model Predictive Control evolved as the state of the art paradigm for safety critical control tasks. Control-as-Inference approaches thereof model the constrained optimization problem as a probabilistic inference problem. The constraints have to be implemented into the inference model. A recently introduced physics-informed Gaussian Process method uses Control-as-Inference with a Gaussian likelihood for state constraint modeling, but lacks guarantees of open-loop constraint satisfaction. We mitigate the lack of guarantees via an additional sampling step using Hamiltonian Monte Carlo sampling in order to obtain safe rollouts of the open-loop dynamics which are then used to obtain an approximation of the truncated normal distribution which has full probability mass in the safe area. We provide formal guarantees of constraint satisfaction while maintaining the ODE structure of the Gaussian Process on a discretized grid. Moreover, we show that we are able to perform optimization of a quadratic cost function by closed form Gaussian Process computations only and introduce the Mat\'ern kernel into the inference model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16195v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\"orn Tebbe, Andreas Besginow, Markus Lange-Hegermann</dc:creator>
    </item>
    <item>
      <title>Weak optimal transport with moment constraints: constraintqualification, dual attainment and entropic regularization</title>
      <link>https://arxiv.org/abs/2511.16211</link>
      <description>arXiv:2511.16211v1 Announce Type: new 
Abstract: We consider weak optimal problems (possibly entropically penalized) incorporating both soft and hard (including the case of the martingale condition) moment constraints. Even in the special case of the martingale optimal transport problem, existence of Lagrange multipliers corresponding to the martingale constraint is notoriously hard (and may fail unless some specific additional assumptions are made). We identify a condition of qualification of the hard moment constraints (which in the martingale case is implied by well-known conditions in the literature) under which general dual attainment results are established. We also analyze the convergence of entropically regularized schemes combined with penalization of the moment constraint and illustrate our theoretical findings by numerically solving in dimension one, the Brenier-Strassen problem of Gozlan and Juillet and a family of problems which interpolates between monotone transport and left-curtain martingale coupling of Beiglb\"{o}ck and Juillet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16211v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Carlier, Hugo Malamut, Maxime Sylvestre</dc:creator>
    </item>
    <item>
      <title>A case study in ensemble optimal control for Bayesian input design</title>
      <link>https://arxiv.org/abs/2511.16251</link>
      <description>arXiv:2511.16251v1 Announce Type: new 
Abstract: We discuss the problem of input design for uncertainty reduction in a parameter estimation procedure. Assuming a linear continuous-time control system with noisy measurements, we formulate an objective of variance reduction in a Bayesian Gaussian setting as an optimal control problem and analyze it from a geometric control perspective. The resulting cost functional depends on the unknown parameter, we compare the optimal control approach with a non-standard alternative inspired by ensemble control, where the cost is averaged over the prior distribution after computation, rather than before. This requires the statement of a generalized Pontryagin's maximum principle adapted to Gaussian distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16251v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovic Sacchelli, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>Regularized Multiobjective Optimization with Directionally Lipschitzian Data</title>
      <link>https://arxiv.org/abs/2511.16336</link>
      <description>arXiv:2511.16336v1 Announce Type: new 
Abstract: The paper is devoted to the study of regularized versions of multiobjective optimization problems described by directionally Lipschitzian functions. Such regularizations appear in proximal-type algorithms of multiobjective optimization, various models of machine learning, medical physics, etc. We investigate and illustrate several useful properties of directionally Lipschitzian functions, which distinguish them from locally Lipschitzian ones. By using advanced tools of variational analysis and generalized differentiation revolving around the limiting/Mordukhovich subdifferential, we derive necessary conditions for Pareto optimality in regularized multiobjective problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16336v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. C. Bento, J. X. Cruz Neto, J. O. Lopes, B. S. Mordukhovich, P. R. Silva Filho</dc:creator>
    </item>
    <item>
      <title>iFCTN: Folding-Free Fully-Connected Tensor Network Decomposition for Tensor Completion</title>
      <link>https://arxiv.org/abs/2511.16358</link>
      <description>arXiv:2511.16358v1 Announce Type: new 
Abstract: The fully-connected tensor network (FCTN) decomposition has recently exhibited strong modeling capabilities by connecting every pair of tensor factors, thereby capturing rich cross-mode correlations and maintaining invariance under mode transpositions. However, this advantage comes with an inherent limitation: updating the factors typically requires reconstructing auxiliary sub-networks, which entails extensive and cumbersome (un)folding. In this study, we propose intra-block FCTN (iFCTN) decomposition, a novel (un)folding-free variant of FCTN decomposition that streamlines computation. We parameterize each FCTN factor through Khatri-Rao products, which significantly reduces the complexity of reconstructing intermediate sub-networks and yields subproblems with well-structured coefficient matrices. Furthermore, we deploy the proposed iFCTN decomposition on the representative task of tensor completion and design an efficient proximal alternating minimization algorithm while retaining convergence guarantees. Extensive experiments demonstrate that iFCTN outperforms or matches state-of-the-art methods with comparable computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16358v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Gan, Chunfeng Cui</dc:creator>
    </item>
    <item>
      <title>On the Convex Interpolation for Linear Operators</title>
      <link>https://arxiv.org/abs/2511.16360</link>
      <description>arXiv:2511.16360v1 Announce Type: new 
Abstract: The worst-case performance of an optimization method on a problem class can be analyzed using a finite description of the problem class, known as interpolation conditions. In this work, we study interpolation conditions for linear operators given scalar products between discrete inputs and outputs. First, we show that if only convex constraints on the scalar products of inputs and outputs are allowed,it is only possible to characterize classes of linear operators or symmetric linear operator whose all singular values or eigenvalues belong to some subset of R. Then, we propose new interpolation conditions for linear operators with minimal and maximal singular values and linear operators whose eigenvalues or singular values belong to unions of subsets. Finally, we illustrate the new interpolation conditions through the analysis of the Gradient and Chambolle-Pock methods. It allows to obtain new numerical worst-case guarantees on these methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16360v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nizar Bousselmi, Zhicheng Deng, Jie Lu, Francois Glineur, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>A Fast Relax-and-Round Approach to Unit Commitment for Data Center Own Generation</title>
      <link>https://arxiv.org/abs/2511.16420</link>
      <description>arXiv:2511.16420v1 Announce Type: new 
Abstract: The rapid growth of data centers increasingly requires data center operators to "bring own generation" to complement the available utility power plants to supply all or part of data center load. This practice sharply increases the number of generators on the bulk power system and shifts operational focus toward fuel costs rather than traditional startup and runtime constraints. Conventional mixed-integer unit commitment formulations are not well suited for systems with thousands of flexible, fast-cycling units. We propose a unit commitment formulation that relaxes binary commitment decisions by allowing generators to be fractionally on, enabling the use of algorithms for continuous solvers. We then use a rounding approach to get a feasible unit commitment. For a 276-unit system, solution time decreases from 10 hours to less than a second, with minor accuracy degradation. Our approach scales with no issues to tens of thousands of generators, which allows solving problems on the scale of the major North America interconnections. The bulk of computation is parallel and GPU compatible, enabling further acceleration in future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16420v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaked Regev, Eve Tsybina, Slaven Peles</dc:creator>
    </item>
    <item>
      <title>A convex approach for Markov chain estimation from aggregate data via inverse optimal transport</title>
      <link>https://arxiv.org/abs/2511.16458</link>
      <description>arXiv:2511.16458v1 Announce Type: new 
Abstract: We address the problem of identifying the dynamical law governing the evolution of a population of indistinguishable particles, when only aggregate distributions at successive times are observed. Assuming a Markovian evolution on a discrete state space, the task reduces to estimating the underlying transition probability matrix from distributional data. We formulate this inverse problem within the framework of entropic optimal transport, as a joint optimization over the transition matrix and the transport plans connecting successive distributions. This formulation results in a convex optimization problem, and we propose an efficient iterative algorithm based on the entropic proximal method. We illustrate the accuracy and convergence of the method in two numerical setups, considering estimation from independent snapshots and estimation from a time series of aggregate observations, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16458v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Mascherpa, Axel Ringh, Amirhossein Taghvaei, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Scenario-based Regularization: A Tractable Framework for Distributionally Robust Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2511.16500</link>
      <description>arXiv:2511.16500v1 Announce Type: new 
Abstract: We propose a flexible scenario-based regularized Sample Average Approximation (SBR-SAA) framework for stochastic optimization. This work is motivated by challenges in standard Wasserstein Distributionally Robust Optimization (WDRO), where out-of-sample performance, particularly tail risk, is sensitive to the choice of the p-norm, and formulations can be computationally intractable. Our method is inspired by the asymptotic expansion of the WDRO objective and introduces a regularizer that penalizes the (sub)gradient norm of the objective at a selected set of scenarios. This framework serves a dual purpose: (i) it provides a computationally tractable alternative to WDRO by using a representative subset of the data, and (ii) it can provide targeted robustness by incorporating user-defined adverse scenarios. We establish the theoretical properties of this framework by proving its equivalence to a decision-dependent WDRO problem, from which we derive finite sample guarantees and asymptotic consistency. We demonstrate the method's efficacy in two applications: (1) a multi-product newsvendor problem, where SBR-SAA serves as a tractable alternative to NP-hard WDRO, and (2) a mean-risk portfolio optimization problem, where it successfully uses historical crisis data to improve out-of-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16500v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Fonseca, Mauricio Junca</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Newton methods with effective subspaces for polyhedral regularization</title>
      <link>https://arxiv.org/abs/2511.16514</link>
      <description>arXiv:2511.16514v1 Announce Type: new 
Abstract: We propose several new nonsmooth Newton methods for solving convex composite opti- mization problems with polyhedral regularizers, while avoiding the computation of compli- cated second-order information on these functions. Under the tilt-stability condition at the optimal solution, these methods achieve the quadratic convergence rates expected of New- ton schemes. Numerical experiments on Lasso, generalized Lasso, OSCAR-regularized least- square problems, and an image super-resolution task illustrate both the broad applicability and the accelerated convergence profile of the proposed algorithms, in comparison with first-order and several recently developed nonsmooth Newton schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16514v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tran T. A. Nghia, Nghia V. Vo, Khoa V. H. Vu</dc:creator>
    </item>
    <item>
      <title>Failure of uniform laws of large numbers for subdifferentials and beyond</title>
      <link>https://arxiv.org/abs/2511.16568</link>
      <description>arXiv:2511.16568v1 Announce Type: new 
Abstract: We provide counterexamples showing that uniform laws of large numbers do not hold for subdifferentials under natural assumptions. Our results apply to random Lipschitz functions and random convex functions with a finite number of smooth pieces. Consequently, they resolve the questions posed by Shapiro and Xu [J. Math. Anal. Appl., 325(2), 2007] in the negative and highlight the obstacles nonsmoothness poses to uniform results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16568v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lai Tian, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Stabilization of nonautonomous linear parabolic equations with inputs subject to time-delay</title>
      <link>https://arxiv.org/abs/2511.16616</link>
      <description>arXiv:2511.16616v1 Announce Type: new 
Abstract: The stabilization of nonautonomous parabolic equations is achieved by feedback inputs tuning a finite number of actuators, where it is assumed that the input is subject to a time delay. To overcome destabilizing effects of the time delay, the input is based on a prediction of the state at a future time. This prediction is computed depending on a state-estimate at the current time, which in turn is provided by a Luenberger observer. The observer is designed using the output of measurements performed by a finite number of sensors. The asymptotic behavior of the resulting coupled system is investigated. Numerical simulations are presented validating the theoretical findings, including tests showing the response against sensor measurement errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16616v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karl Kunisch, S\'ergio S. Rodrigues</dc:creator>
    </item>
    <item>
      <title>ECPv2: Fast, Efficient, and Scalable Global Optimization of Lipschitz Functions</title>
      <link>https://arxiv.org/abs/2511.16575</link>
      <description>arXiv:2511.16575v1 Announce Type: cross 
Abstract: We propose ECPv2, a scalable and theoretically grounded algorithm for global optimization of Lipschitz-continuous functions with unknown Lipschitz constants. Building on the Every Call is Precious (ECP) framework, which ensures that each accepted function evaluation is potentially informative, ECPv2 addresses key limitations of ECP, including high computational cost and overly conservative early behavior. ECPv2 introduces three innovations: (i) an adaptive lower bound to avoid vacuous acceptance regions, (ii) a Worst-m memory mechanism that restricts comparisons to a fixed-size subset of past evaluations, and (iii) a fixed random projection to accelerate distance computations in high dimensions. We theoretically show that ECPv2 retains ECP's no-regret guarantees with optimal finite-time bounds and expands the acceptance region with high probability. We further empirically validate these findings through extensive experiments and ablation studies. Using principled hyperparameter settings, we evaluate ECPv2 across a wide range of high-dimensional, non-convex optimization problems. Across benchmarks, ECPv2 consistently matches or outperforms state-of-the-art optimizers, while significantly reducing wall-clock time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16575v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fares Fourati, Mohamed-Slim Alouini, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence Analysis of Differentially Private Stochastic Gradient Methods</title>
      <link>https://arxiv.org/abs/2511.16587</link>
      <description>arXiv:2511.16587v1 Announce Type: cross 
Abstract: Differentially private stochastic gradient descent (DP-SGD) has become the standard algorithm for training machine learning models with rigorous privacy guarantees. Despite its widespread use, the theoretical understanding of its long-run behavior remains limited: existing analyses typically establish convergence in expectation or with high probability, but do not address the almost sure convergence of single trajectories. In this work, we prove that DP-SGD converges almost surely under standard smoothness assumptions, both in nonconvex and strongly convex settings, provided the step sizes satisfy some standard decaying conditions. Our analysis extends to momentum variants such as the stochastic heavy ball (DP-SHB) and Nesterov's accelerated gradient (DP-NAG), where we show that careful energy constructions yield similar guarantees. These results provide stronger theoretical foundations for differentially private optimization and suggest that, despite privacy-induced distortions, the algorithm remains pathwise stable in both convex and nonconvex regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16587v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amartya Mukherjee, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Decentralized Bilevel Optimization: A Perspective from Transient Iteration Complexity</title>
      <link>https://arxiv.org/abs/2402.03167</link>
      <description>arXiv:2402.03167v4 Announce Type: replace 
Abstract: Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, most decentralized SBO algorithms focus solely on asymptotic convergence rates, overlooking transient iteration complexity-the number of iterations required before asymptotic rates dominate, which results in limited understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. To address this issue, this paper introduces D-SOBA, a Decentralized Stochastic One-loop Bilevel Algorithm framework. D-SOBA comprises two variants: D-SOBA-SO, which incorporates second-order Hessian and Jacobian matrices, and D-SOBA-FO, which relies entirely on first-order gradients. We provide a comprehensive non-asymptotic convergence analysis and establish the transient iteration complexity of D-SOBA. This provides the first theoretical understanding of how network topology, data heterogeneity, and nested bilevel structures influence decentralized SBO. Extensive experimental results demonstrate the efficiency and theoretical advantages of D-SOBA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03167v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boao Kong, Shuchen Zhu, Songtao Lu, Xinmeng Huang, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of the transformed gradient projection algorithms on compact matrix manifolds</title>
      <link>https://arxiv.org/abs/2404.19392</link>
      <description>arXiv:2404.19392v3 Announce Type: replace 
Abstract: In this paper, we study the optimization problem on a compact matrix manifold. While existing feasible algorithms can be broadly categorized into retraction-based and projection-based methods, compared to the more comprehensive and in-depth algorithmic and convergence research framework for retraction-based line-search (RetrLS) algorithms using only tangent vectors, the theoretical understanding and algorithmic design of projection-based line-search (ProjLS) algorithms remain limited, especially when general search directions and stepsizes are involved. To bridge this gap, we propose a unified algorithmic framework called the Transformed Gradient Projection (TGP) algorithm. The key idea is to construct the search direction as a transformed Riemannian (or Euclidean) gradient augmented by an additional normal component, allowing the framework to encompass and generalize numerous existing algorithms. Then, we conduct a thorough exploration of the convergence properties of the TGP algorithms under various stepsizes, including the Armijo, Zhang-Hager type nonmonotone Armijo, and fixed stepsizes. To achieve this, we extensively analyze the geometric properties of the projection onto compact matrix manifolds, which may be of independent interest. Building upon these insights, we establish the weak convergence, iteration complexity, and global convergence of TGP algorithms under three distinct stepsizes. In cases where the compact matrix manifold is the Stiefel or Grassmann manifold, our convergence results either encompass or surpass those found in the literature. Finally, through a series of numerical experiments and theoretical analysis, we observe that different choices of scaling matrices and normal components in the search direction of TGP algorithms can lead to significantly different performance in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19392v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Ding, Jianze Li, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Structured eigenvalue backward errors of Rosenbrock systems and related $\mu$-value problems</title>
      <link>https://arxiv.org/abs/2405.11974</link>
      <description>arXiv:2405.11974v2 Announce Type: replace 
Abstract: In this paper, we compute the structured eigenvalue backward error of a Rosenbrock system matrix $S(z)=\left[\begin{array}{cc} A-zI &amp; B \\ C &amp; P(z) \end{array}\right]$ for a given scalar $\lambda\in \mathbb C$.
  We have developed simplified formulas for the structured eigenvalue backward error of the Rosenbrock system matrix, considering both full and partial block perturbations. These formulas involve computing
  structured $\mu$-values of a rectangular matrix under rectangular-block-diagonal perturbations.
  For the reformulated $\mu$-value problem, we provide an explicit expression using partial isometric matrices and also obtain a computable upper bound, which is equal to the $\mu$-value when the pertrubation matrix has no more than three blocks at the diagonal.
  The results are illustrated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11974v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshul Prajapati, Punit Sharma</dc:creator>
    </item>
    <item>
      <title>Modelling Global Trade with Optimal Transport</title>
      <link>https://arxiv.org/abs/2409.06554</link>
      <description>arXiv:2409.06554v3 Announce Type: replace 
Abstract: Global trade is shaped by a complex mix of factors beyond supply and demand, including tangible variables like transport costs and tariffs, as well as less quantifiable influences such as political and economic relations. Traditionally, economists model trade using gravity models, which rely on explicit covariates that might struggle to capture these subtler drivers of trade. In this work, we employ optimal transport and a deep neural network to learn a time-dependent cost function from data, without imposing a specific functional form. This approach consistently outperforms traditional gravity models in accuracy and has similar performance to three-way gravity models, while providing natural uncertainty quantification. Applying our framework to global food and agricultural trade, we show that the Global South suffered disproportionately from the war in Ukraine's impact on wheat markets. We also analyse the effects of free-trade agreements and trade disputes with China, as well as Brexit's impact on British trade with Europe, uncovering hidden patterns that trade volumes alone cannot reveal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06554v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Gaskin, Guven Demirel, Marie-Therese Wolfram, Andrew Duncan</dc:creator>
    </item>
    <item>
      <title>Finite convergence and minimizer extraction in moment relaxations with correlative sparsity</title>
      <link>https://arxiv.org/abs/2502.01410</link>
      <description>arXiv:2502.01410v2 Announce Type: replace 
Abstract: We identify a new sufficient condition for the finite convergence of moment relaxations of polynomial optimization problems with correlative sparsity. This condition, which follows from a solution to a correlatively sparse version of the classical truncated moment problem, requires that certain moment matrices admit a flat extension and that the variable cliques underpinning the relaxation satisfy a "running intersection" property. We also describe an algorithm that, when these conditions are met, extracts at least as many minimizers for the original polynomial optimization problem as the largest rank of the moment matrices in its relaxation. Our results, along with the necessity of the running intersection property, are illustrated with examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01410v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Fantuzzi, Federico Fuentes</dc:creator>
    </item>
    <item>
      <title>Increasing competitiveness by imbalanced groups: The example of the 48-team FIFA World Cup</title>
      <link>https://arxiv.org/abs/2502.08565</link>
      <description>arXiv:2502.08565v3 Announce Type: replace 
Abstract: A match played in a sports tournament can be called stakeless if at least one team is indifferent to its outcome because it already has qualified or has been eliminated. Such a game threatens fairness since teams may not exert full effort without incentives. This paper suggests a novel classification for stakeless matches based on their expected outcome: they are more costly if the indifferent team is more likely to win by playing honestly. Our approach is illustrated with the 2026 FIFA World Cup, the first edition of the competition with 48 teams. We propose a novel format based on imbalanced groups, which substantially reduces the probability of stakeless matches played by the strongest teams according to Monte Carlo simulations. The new design also increases the uncertainty of match outcomes and requires fewer matches. Governing bodies in sports are encouraged to consider our innovative idea in order to enhance the competitiveness of their tournaments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08565v3</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2025.11.025</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research, 2025, forthcoming</arxiv:journal_reference>
      <dc:creator>L\'aszl\'o Csat\'o, Andr\'as Gyimesi</dc:creator>
    </item>
    <item>
      <title>Optimizing Server Locations in Spatial Queues: Parametric and Nonparametric Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2505.22249</link>
      <description>arXiv:2505.22249v2 Announce Type: replace 
Abstract: This paper presents a new model for solving the optimal server location problem in a spatial hypercube queueing model. Unlike deterministic location models, our approach accounts for server availability, varying utilization levels, and dependencies across servers. We prove that the problem is NP-hard and establish lower and upper bounds, as well as asymptotic results, by relating it to special cases of the classical $p$-Median problem. To address the computational challenge, we propose two Bayesian optimization approaches: (i) a parametric approach based on a sparse Bayesian linear model with second-order interactions, and (ii) a nonparametric approach using a Gaussian process surrogate with the $p$-Median objective as the prior mean function. We prove that both methods achieve sublinear regret and converge to the optimal solution. Numerical experiments and a case study using real-world data from the St. Paul, Minnesota, emergency response system show that our approaches consistently identify optimal solutions and outperform all baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22249v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Hua, Arthur J. Swersey, Wenqian Xing, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic gradient with least-squares control variates</title>
      <link>https://arxiv.org/abs/2507.20981</link>
      <description>arXiv:2507.20981v2 Announce Type: replace 
Abstract: The stochastic gradient descent (SGD) method is a widely used approach for solving stochastic optimization problems, but its convergence is typically slow. Existing variance reduction techniques, such as SAGA, improve convergence by leveraging stored gradient information; however, they are restricted to settings where the objective functional is a finite sum, and their performance degrades when the number of terms in the sum is large. In this work, we propose a novel approach which is well suited when the objective is given by an expectation over random variables with a continuous probability distribution. Our method constructs a control variate by fitting a linear model to past gradient evaluations using weighted discrete least-squares, effectively reducing variance while preserving computational efficiency. We establish theoretical sublinear convergence guarantees for strongly convex objectives and demonstrate the method's effectiveness through numerical experiments on random PDE-constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20981v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Nobile, Matteo Raviola, Nathan Schaeffer</dc:creator>
    </item>
    <item>
      <title>Polyconvex double well functions</title>
      <link>https://arxiv.org/abs/2508.14541</link>
      <description>arXiv:2508.14541v2 Announce Type: replace 
Abstract: We investigate polyconvexity of the double well function $f(X)\,:= |X-X\_1|^2|X-X\_2|^2$ for given matrices $X\_1, X\_2 \in \R^{n \times n}$. Such functions are fundamental in the modeling of phase transitions in materials, but their non-convex nature presents challenges for the analysis of variational problems. Polyconvexity of $f$ is related to the singular values of the matrix difference $X\_1 - X\_2$. We prove that $f$ is polyconvex if and only if the square of the largest singular value does not exceed the sum of the squares of the other singular values. This condition allows the function to be decomposed into the sum of a strictly convex part and a null Lagrangean. As a direct application of this result, we prove an existence and uniqueness theorem for the corresponding Dirichlet minimization problem of the integral functional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14541v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didier Henrion (LAAS-POP), Martin Kru\v{z}\'ik (UTIA / CAS)</dc:creator>
    </item>
    <item>
      <title>Trust-region Filter Algorithms utilising Hessian Information for Grey-Box Optimisation</title>
      <link>https://arxiv.org/abs/2509.01651</link>
      <description>arXiv:2509.01651v2 Announce Type: replace 
Abstract: Optimising industrial processes often involves grey-box models that couple algebraic glass-box equations with black-box components lacking analytic derivatives. Such hybrid systems challenge derivative-based solvers. The classical trust-region filter (TRF) algorithm provides a robust framework but requires extensive parameter tuning and numerous black-box evaluations. This work introduces four Hessian-informed TRF variants (A1-A4) that use projected positive definite Hessians for automatic step scaling and minimal tuning, combined with both low-fidelity (linear, quadratic) and high-fidelity (Taylor series, Gaussian process) surrogates for local black-box approximation. Tested on 25 grey-box benchmarks and five engineering case studies (Himmelblau, liquid-liquid extraction, pressure vessel design, alkylation, and spring design), the new variants achieved up to an order-of-magnitude reduction in iterations and black-box evaluations, with reduced sensitivity to tuning parameters relative to the classical TRF algorithm. High-fidelity surrogates solved 92-100 % problems, compared to 72-84 % for the low-fidelity surrogates. Developed TRF methods also outperformed classical derivative-free optimisation solvers. The results show that new variants offer robust and scalable alternatives for grey-box process systems optimisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01651v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gul Hameed, Tao Chen, Antonio del Rio Chanona, Lorenz T. Biegler, Michael Short</dc:creator>
    </item>
    <item>
      <title>Degradation-Aware Model Predictive Control for Battery Swapping Stations under Energy Arbitrage</title>
      <link>https://arxiv.org/abs/2510.07902</link>
      <description>arXiv:2510.07902v2 Announce Type: replace 
Abstract: Battery swapping stations (BSS) offer a fast and scalable alternative to conventional electric vehicle (EV) charging, gaining growing policy support worldwide. However, existing BSS control strategies typically rely on heuristics or low-fidelity degradation models, limiting profitability and service level. This paper proposes BSS-MPC: a real-time, degradation-aware Model Predictive Control (MPC) framework for BSS operations to trade off economic incentives from energy market arbitrage and long-term battery degradation effects. BSS-MPC integrates a high-fidelity, physics informed battery aging model that accurately predicts the degradation level and the remaining capacity of battery packs. The resulting multiscale optimization-jointly considering energy arbitrage, swapping logistics, and battery health-is formulated as a mixed-integer optimal control problem and solved with tailored algorithms. Simulation results show that BSS-MPC outperforms rule-based and low-fidelity baselines, achieving lower energy cost, reduced capacity fade, and strict satisfaction of EV swapping demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07902v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruochen Li (Department of Systems Engineering, City University of Hong Kong, Kowloon, Hong Kong, China), Zhichao Chen (Department of Systems Engineering, City University of Hong Kong, Kowloon, Hong Kong, China), Zhaoting Zhang (Department of Systems Engineering, City University of Hong Kong, Kowloon, Hong Kong, China), Renjie Guo (Department of Decision Analytics and Operations, City University of Hong Kong, Kowloon, Hong Kong, China), Zhankun Sun (Department of Decision Analytics and Operations, City University of Hong Kong, Kowloon, Hong Kong, China), Jiwei Yao (Department of Chemical Engineering, University of Utah, Salt Lake City, UT, USA), Jiaze Ma (Department of Systems Engineering, City University of Hong Kong, Kowloon, Hong Kong, China)</dc:creator>
    </item>
    <item>
      <title>Verification of Sequential Convex Programming for Parametric Non-convex Optimization</title>
      <link>https://arxiv.org/abs/2511.10622</link>
      <description>arXiv:2511.10622v2 Announce Type: replace 
Abstract: We introduce a verification framework to exactly verify the worst-case performance of sequential convex programming (SCP) algorithms for parametric non-convex optimization. The verification problem is formulated as an optimization problem that maximizes a performance metric (e.g., the suboptimality after a given number of iterations) over parameters constrained to be in a parameter set and iterate sequences consistent with the SCP update rules. Our framework is general, extending the notion of SCP to include both conventional variants such as trust-region, convex-concave, and prox-linear methods, and algorithms that combine convex subproblems with rounding steps, as in relaxing and rounding schemes. Unlike existing analyses that may only provide local guarantees under limited conditions, our framework delivers global worst-case guarantees--quantifying how well an SCP algorithm performs across all problem instances in the specified family. Applications in control, signal processing, and operations research demonstrate that our framework provides, for the first time, global worst-case guarantees for SCP algorithms in the parametric setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10622v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajiv Sambharya, Nikolai Matni, George Pappas</dc:creator>
    </item>
    <item>
      <title>Linear-Space Extragradient Methods for Fast, Large-Scale Optimal Transport</title>
      <link>https://arxiv.org/abs/2511.11359</link>
      <description>arXiv:2511.11359v2 Announce Type: replace 
Abstract: Optimal transport (OT) and its entropy-regularized form (EOT) have become increasingly prominent computational problems, with applications in machine learning and statistics. Recent years have seen a commensurate surge in first-order methods aiming to improve the complexity of large-scale (E)OT. However, there has been a consistent tradeoff: attaining state-of-the-art rates requires $\mathcal{O}(n^2)$ storage to enable ergodic primal averaging. In this work, we demonstrate that recently proposed primal-dual extragradient methods (PDXG) can be implemented entirely in the dual with $\mathcal{O}(n)$ storage. Additionally, we prove that regularizing the reformulated OT problem is equivalent to EOT with extensions to entropy-regularized barycenter problems, further widening the applications of the proposed method. The proposed dual-only extragradient method (DXG) achieves $\mathcal{O}(n^2\varepsilon^{-1})$ complexity for $\varepsilon$-approximate OT with $\mathcal{O}(n)$ memory. Numerical experiments demonstrate that the dual extragradient method scales favorably in non/weakly-regularized regimes compared to existing algorithms, though future work is needed to improve performance in certain problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11359v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew X. Burns, Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>QUASAR: An Evolutionary Algorithm to Accelerate High-Dimensional Optimization</title>
      <link>https://arxiv.org/abs/2511.13843</link>
      <description>arXiv:2511.13843v2 Announce Type: replace 
Abstract: High-dimensional numerical optimization presents a persistent challenge. This paper introduces Quasi-Adaptive Search with Asymptotic Reinitialization (QUASAR), an evolutionary algorithm to accelerate convergence in complex, non-differentiable problems afflicted by the curse of dimensionality.
  Evaluated on the notoriously difficult CEC2017 benchmark suite of 29 functions, QUASAR achieved the lowest overall rank sum (150) using the Friedman test, significantly outperforming L-SHADE (229) and standard DE (305) in the dimension-variant trials. QUASAR also proves computationally efficient, with run times averaging $1.4 \text{x}$ faster than DE and $7.8 \text{x}$ faster than L-SHADE ($p \ll 0.001$) in the population-variant trials.
  Building upon Differential Evolution (DE), QUASAR introduces a highly stochastic architecture to dynamically balance exploration and exploitation. Inspired by the probabilistic behavior of quantum particles in a stellar core, the algorithm implements three primary components that augment standard DE mechanisms: 1) probabilistically selected mutation strategies and scaling factors; 2) rank-based crossover rates; 3) asymptotically decaying reinitialization that leverages a covariance matrix of the best solutions to introduce high-quality genetic diversity.
  QUASAR's performance establishes it as an effective, user-friendly optimizer for complex high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13843v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Soltes</dc:creator>
    </item>
    <item>
      <title>It\=o and It\=o-Wentzell chain rule for flows of conditional laws of continuous semimartingales: an easy approach</title>
      <link>https://arxiv.org/abs/2404.11010</link>
      <description>arXiv:2404.11010v3 Announce Type: replace-cross 
Abstract: We provide a general It\=o\,-Wentzell formula for a random field of maps on the Wasserstein space of probability measures, defined by continuous semimartingales, and evaluated along the flow of conditional distributions of another continuous semimartingale. Our method follows standard arguments of It\=o calculus, and thus bypasses the approximation by empirical measures commonly used in the existing literature. As an application, we derive the dynamic programming equation for a mean field stochastic control problem with common noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11010v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Assil Fadle, Mehdi Talbi, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic Approximations with Markovian Noise</title>
      <link>https://arxiv.org/abs/2409.19546</link>
      <description>arXiv:2409.19546v5 Announce Type: replace-cross 
Abstract: Stochastic approximation is a powerful class of algorithms with celebrated success. However, a large body of previous analysis focuses on stochastic approximations driven by contractive operators, which is not applicable in some important reinforcement learning settings like the average reward setting. This work instead investigates stochastic approximations with merely nonexpansive operators. In particular, we study nonexpansive stochastic approximations with Markovian noise, providing both asymptotic and finite sample analysis. Key to our analysis are novel bounds of noise terms resulting from the Poisson equation. As an application, we prove for the first time that classical tabular average reward temporal difference learning converges to a sample-path dependent fixed point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19546v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Blaser, Shangtong Zhang</dc:creator>
    </item>
    <item>
      <title>Optimizing Resource Distribution in a One-Dimensional Logistic Diffusion Model</title>
      <link>https://arxiv.org/abs/2511.15428</link>
      <description>arXiv:2511.15428v2 Announce Type: replace-cross 
Abstract: In this article, we study the optimization of resource distributions in a one-dimensional logistic diffusive model. The goal is to determine a distribution on a bounded one-dimensional domain that maximizes the total population at equilibrium. Previous works have shown that optimal resources are bang-bang, and in one dimension, a sufficiently large dispersal rate forces the optimal resource to be concentrated. For general dispersal rates, however, the analysis becomes more difficult because the equilibrium population may behave irregularly, and the optimal resource may be fragmented. To address this, we introduce a block decomposition that reduces fragmented resources to a collection of concentrated blocks. We then define an advantage function, which measures the gain in the equilibrium population obtained by allocating resources on a fixed interval and is used to analyze the contribution of each block to the total population. This function also allows us to reformulate the optimization problem as a convexity analysis of the advantage function. We prove the superlinearity of this function when the total resource is small enough, and this property leads to an explicit characterization of the optimal control with sufficiently small total resource.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15428v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyoung Heo, Yubin Lee</dc:creator>
    </item>
  </channel>
</rss>
