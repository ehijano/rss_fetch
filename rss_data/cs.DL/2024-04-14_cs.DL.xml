<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Apr 2024 04:02:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Toward FAIR Semantic Publishing of Research Dataset Metadata in the Open Research Knowledge Graph</title>
      <link>https://arxiv.org/abs/2404.08443</link>
      <description>arXiv:2404.08443v1 Announce Type: new 
Abstract: Search engines these days can serve datasets as search results. Datasets get picked up by search technologies based on structured descriptions on their official web pages, informed by metadata ontologies such as the Dataset content type of schema.org. Despite this promotion of the content type dataset as a first-class citizen of search results, a vast proportion of datasets, particularly research datasets, still need to be made discoverable and, therefore, largely remain unused. This is due to the sheer volume of datasets released every day and the inability of metadata to reflect a dataset's content and context accurately. This work seeks to improve this situation for a specific class of datasets, namely research datasets, which are the result of research endeavors and are accompanied by a scholarly publication. We propose the ORKG-Dataset content type, a specialized branch of the Open Research Knowledge Graoh (ORKG) platform, which provides descriptive information and a semantic model for research datasets, integrating them with their accompanying scholarly publications. This work aims to establish a standardized framework for recording and reporting research datasets within the ORKG-Dataset content type. This, in turn, increases research dataset transparency on the web for their improved discoverability and applied use. In this paper, we present a proposal -- the minimum FAIR, comparable, semantic description of research datasets in terms of salient properties of their supporting publication. We design a specific application of the ORKG-Dataset semantic model based on 40 diverse research datasets on scientific information extraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08443v1</guid>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>In Joint Proceedings of the Onto4FAIR 2023 Workshops: Collocated with FOIS 2023 and SEMANTICS 2023. pp.23-31. https://hal.science/hal-04312604</arxiv:journal_reference>
      <dc:creator>Raia Abu Ahmad, Jennifer D'Souza, Matth\"aus Zloch, Wolfgang Otto, Georg Rehm, Allard Oelen, Stefan Dietze, S\"oren Auer</dc:creator>
    </item>
    <item>
      <title>Augmenting Knowledge Graph Hierarchies Using Neural Transformers</title>
      <link>https://arxiv.org/abs/2404.08020</link>
      <description>arXiv:2404.08020v1 Announce Type: cross 
Abstract: Knowledge graphs are useful tools to organize, recommend and sort data. Hierarchies in knowledge graphs provide significant benefit in improving understanding and compartmentalization of the data within a knowledge graph. This work leverages large language models to generate and augment hierarchies in an existing knowledge graph. For small (&lt;100,000 node) domain-specific KGs, we find that a combination of few-shot prompting with one-shot generation works well, while larger KG may require cyclical generation. We present techniques for augmenting hierarchies, which led to coverage increase by 98% for intents and 99% for colors in our knowledge graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08020v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-56069-9_35</arxiv:DOI>
      <dc:creator>Sanat Sharma, Mayank Poddar, Jayant Kumar, Kosta Blank, Tracy King</dc:creator>
    </item>
    <item>
      <title>Learning representations of learning representations</title>
      <link>https://arxiv.org/abs/2404.08403</link>
      <description>arXiv:2404.08403v1 Announce Type: cross 
Abstract: The ICLR conference is unique among the top machine learning conferences in that all submitted papers are openly available. Here we present the ICLR dataset consisting of abstracts of all 24 thousand ICLR submissions from 2017-2024 with meta-data, decision scores, and custom keyword-based labels. We find that on this dataset, bag-of-words representation outperforms most dedicated sentence transformer models in terms of $k$NN classification accuracy, and the top performing language models barely outperform TF-IDF. We see this as a challenge for the NLP community. Furthermore, we use the ICLR dataset to study how the field of machine learning has changed over the last seven years, finding some improvement in gender balance. Using a 2D embedding of the abstracts' texts, we describe a shift in research topics from 2017 to 2024 and identify hedgehogs and foxes among the authors with the highest number of ICLR submissions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08403v1</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rita Gonz\'alez-M\'arquez, Dmitry Kobak</dc:creator>
    </item>
    <item>
      <title>Is ChatGPT Transforming Academics' Writing Style?</title>
      <link>https://arxiv.org/abs/2404.08627</link>
      <description>arXiv:2404.08627v1 Announce Type: cross 
Abstract: Based on one million arXiv papers submitted from May 2018 to January 2024, we assess the textual density of ChatGPT's writing style in their abstracts by means of a statistical analysis of word frequency changes. Our model is calibrated and validated on a mixture of real abstracts and ChatGPT-modified abstracts (simulated data) after a careful noise analysis. We find that ChatGPT is having an increasing impact on arXiv abstracts, especially in the field of computer science, where the fraction of ChatGPT-revised abstracts is estimated to be approximately 35%, if we take the output of one of the simplest prompts, "revise the following sentences", as a baseline. We conclude with an analysis of both positive and negative aspects of the penetration of ChatGPT into academics' writing style.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08627v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingmeng Geng, Roberto Trotta</dc:creator>
    </item>
    <item>
      <title>Accessibility in Information Retrieval</title>
      <link>https://arxiv.org/abs/2404.08628</link>
      <description>arXiv:2404.08628v1 Announce Type: cross 
Abstract: This paper introduces the concept of accessibility from the field of transportation planning and adopts it within the context of Information Retrieval (IR). An analogy is drawn between the fields, which motivates the development of document accessibility measures for IR systems. Considering the accessibility of documents within a collection given an IR System provides a different perspective on the analysis and evaluation of such systems which could be used to inform the design, tuning and management of current and future IR systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08628v1</guid>
      <category>cs.IR</category>
      <category>cs.DL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-540-78646-7_46</arxiv:DOI>
      <arxiv:journal_reference>European Conference in Information Retrieval (ECIR) 2008</arxiv:journal_reference>
      <dc:creator>Leif Azzopardi, Vishwa Vinay</dc:creator>
    </item>
    <item>
      <title>When Science Locks In, Can AI Help?</title>
      <link>https://arxiv.org/abs/2402.16839</link>
      <description>arXiv:2402.16839v3 Announce Type: replace 
Abstract: Over the past century, the purpose of scientific practices has undergone a profound transformation, from an intellectual pursuit to a problem-solving enterprise, leading to an increasing risk of path dependency in scientific endeavors. Our research, analyzing 41 million research articles from the past six decades, emphasizes the concern of science lock-in by identifying and measuring two types of innovations in science: complementary and substitutive. Over the past six decades, the fraction of complementary innovation has risen to become the majority, while the fraction of substitutive innovation has declined to become the minority, revealing two different mechanisms of innovation: recombination and substitution. Amidst the increasing knowledge burden for innovation, while current AIs may excel in idea recombination due to their strong memory capabilities, their potential to contribute to the substitution mechanism remains uncertain, as they lack the ability to forget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16839v3</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linzhuo Li, Yiling Lin, Lingfei Wu</dc:creator>
    </item>
  </channel>
</rss>
