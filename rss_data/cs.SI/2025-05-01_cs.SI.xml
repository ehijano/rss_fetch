<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 01:30:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mining and Intervention of Social Networks Information Cocoon Based on Multi-Layer Network Community Detection</title>
      <link>https://arxiv.org/abs/2504.21357</link>
      <description>arXiv:2504.21357v1 Announce Type: new 
Abstract: With the rapid development of information technology and the widespread utilization of recommendation algorithms, users are able to access information more conveniently, while the content they receive tends to be homogeneous. Homogeneous viewpoints and preferences tend to cluster users into sub-networks, leading to group polarization and increasing the likelihood of forming information cocoons. This paper aims to handle information cocoon phenomena in debates on social media. In order to investigate potential user connections, we construct a double-layer network that incorporates two dimensions: relational ties and feature-based similarity between users. Based on the structure of the multi-layer network, we promote two graph auto-encoder (GAE) based community detection algorithms, which can be applied to the partition and determination of information cocoons. This paper tests these two algorithms on Cora, Citeseer, and synthetic datasets, comparing them with existing multi-layer network unsupervised community detection algorithms. Numerical experiments illustrate that the algorithms proposed in this paper significantly improve prediction accuracy indicator NMI (normalized mutual information) and network topology indicator Q. Additionally, an influence-based intervention measure on which algorithms can operate is proposed. Through the Markov states transition model, we simulate the intervention effects, which illustrate that our community detection algorithms play a vital role in partitioning and determining information cocoons. Simultaneously, our intervention strategy alleviates the polarization of viewpoints and the formation of information cocoons with minimal intervention effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21357v1</guid>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yang Suwen, Shi Lei</dc:creator>
    </item>
    <item>
      <title>Applying Machine Learning for characterizing social networks Agent-based models</title>
      <link>https://arxiv.org/abs/2504.21609</link>
      <description>arXiv:2504.21609v1 Announce Type: new 
Abstract: Nowadays, social media networks are increasingly significant to our lives, the imperative to study social media networks becomes more and more essential. With billions of users across platforms and constant updates, the complexity of modeling social networks is immense. Agent-based modeling (ABM) is widely employed to study social networks community, allowing us to define individual behaviors and simulate system-level evolution. It can be a powerful tool to test how the algorithms affect users behavior. To fully leverage agent-based models,superior data processing and storage capabilities are essential. High Performance Computing (HPC) presents an optimal solution, adept at managing complex computations and analysis, particularly for voluminous or iteration-intensive tasks. We utilize Machine Learning (ML) methods to analyze social media users due to their ability to efficiently process vast amounts of data and derive insights that aid in understanding user behaviors, preferences, and trends. Therefore, our proposal involves ML to characterize user attributes and to develop a general user model for ABM simulation of in social networks on HPC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21609v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoyuan Li, Lidia Conde Matos, Eduardo C\'esar Galobardes, Anna Sikora</dc:creator>
    </item>
    <item>
      <title>Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models</title>
      <link>https://arxiv.org/abs/2504.21026</link>
      <description>arXiv:2504.21026v1 Announce Type: cross 
Abstract: With the growing presence of multilingual users on social media, detecting abusive language in code-mixed text has become increasingly challenging. Code-mixed communication, where users seamlessly switch between English and their native languages, poses difficulties for traditional abuse detection models, as offensive content may be context-dependent or obscured by linguistic blending. While abusive language detection has been extensively explored for high-resource languages like English and Hindi, low-resource languages such as Telugu and Nepali remain underrepresented, leaving gaps in effective moderation. In this study, we introduce a novel, manually annotated dataset of 2 thousand Telugu-English and 5 Nepali-English code-mixed comments, categorized as abusive and non-abusive, collected from various social media platforms. The dataset undergoes rigorous preprocessing before being evaluated across multiple Machine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). We experimented with models including Logistic Regression, Random Forest, Support Vector Machines (SVM), Neural Networks (NN), LSTM, CNN, and LLMs, optimizing their performance through hyperparameter tuning, and evaluate it using 10-fold cross-validation and statistical significance testing (t-test). Our findings provide key insights into the challenges of detecting abusive language in code-mixed settings and offer a comparative analysis of computational approaches. This study contributes to advancing NLP for low-resource languages by establishing benchmarks for abusive language detection in Telugu-English and Nepali-English code-mixed text. The dataset and insights can aid in the development of more robust moderation strategies for multilingual social media environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21026v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manish Pandey, Nageshwar Prasad Yadav, Mokshada Adduru, Sawan Rai</dc:creator>
    </item>
    <item>
      <title>Construct to Commitment: The Effect of Narratives on Economic Growth</title>
      <link>https://arxiv.org/abs/2504.21060</link>
      <description>arXiv:2504.21060v1 Announce Type: cross 
Abstract: We study how government-led narratives through mass media evolve from construct, a mechanism for framing expectations, into commitment, a sustainable pillar for growth. We propose the ``Narratives-Construct-Commitment (NCC)" framework outlining the mechanism and institutionalization of narratives, and formalize it as a dynamic Bayesian game. Using the Innovation-Driven Development Strategy (2016) as a case study, we identify the narrative shock from high-frequency financial data and trace its impact using local projection method. By shaping expectations, credible narratives institutionalize investment incentives, channel resources into R\&amp;D, and facilitate sustained improvements in total factor productivity (TFP). Our findings strive to provide insights into the New Quality Productive Forces initiative, highlighting the role of narratives in transforming vision into tangible economic growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21060v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyuan Jiang, Yi Man</dc:creator>
    </item>
    <item>
      <title>Detecting Manipulated Contents Using Knowledge-Grounded Inference</title>
      <link>https://arxiv.org/abs/2504.21165</link>
      <description>arXiv:2504.21165v1 Announce Type: cross 
Abstract: The detection of manipulated content, a prevalent form of fake news, has been widely studied in recent years. While existing solutions have been proven effective in fact-checking and analyzing fake news based on historical events, the reliance on either intrinsic knowledge obtained during training or manually curated context hinders them from tackling zero-day manipulated content, which can only be recognized with real-time contextual information. In this work, we propose Manicod, a tool designed for detecting zero-day manipulated content. Manicod first sources contextual information about the input claim from mainstream search engines, and subsequently vectorizes the context for the large language model (LLM) through retrieval-augmented generation (RAG). The LLM-based inference can produce a "truthful" or "manipulated" decision and offer a textual explanation for the decision. To validate the effectiveness of Manicod, we also propose a dataset comprising 4270 pieces of manipulated fake news derived from 2500 recent real-world news headlines. Manicod achieves an overall F1 score of 0.856 on this dataset and outperforms existing methods by up to 1.9x in F1 score on their benchmarks on fact-checking and claim verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21165v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai</dc:creator>
    </item>
    <item>
      <title>The Metric Dimension of Sparse Random Graphs</title>
      <link>https://arxiv.org/abs/2504.21244</link>
      <description>arXiv:2504.21244v1 Announce Type: cross 
Abstract: In 2013, Bollob\'as, Mitsche, and Pralat at gave upper and lower bounds for the likely metric dimension of random Erd\H{o}s-R\'enyi graphs $G(n,p)$ for a large range of expected degrees $d=pn$. However, their results only apply when $d \ge \log^5 n$, leaving open sparser random graphs with $d &lt; \log^5 n$. Here we provide upper and lower bounds on the likely metric dimension of $G(n,p)$ from just above the connectivity transition, i.e., where $d=pn=c \log n$ for some $c &gt; 1$, up to $d=\log^5 n$. Our lower bound technique is based on an entropic argument which is more general than the use of Suen's inequality by Bollob\'as, Mitsche, and Pralat, whereas our upper bound is similar to theirs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21244v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <category>math.PR</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josep D\'iaz, Harrison Hartle, Cristopher Moore</dc:creator>
    </item>
    <item>
      <title>Defense Against Shortest Path Attacks</title>
      <link>https://arxiv.org/abs/2305.19083</link>
      <description>arXiv:2305.19083v2 Announce Type: replace 
Abstract: Identifying shortest paths between nodes in a network is an important task in many applications. Recent work has shown that a malicious actor can manipulate a graph to make traffic between two nodes of interest follow their target path. In this paper, we develop a defense against such attacks by modifying the edge weights that users observe. The defender must balance inhibiting the attacker against any negative effects on benign users. Specifically, the defender's goals are: (a) recommend the shortest paths to users, (b) make the lengths of the shortest paths in the published graph close to those of the same paths in the true graph, and (c) minimize the probability of an attack. We formulate the defense as a Stackelberg game in which the defender is the leader and the attacker is the follower. We also consider a zero-sum version of the game in which the defender's goal is to minimize cost while achieving the minimum possible attack probability. We show that the defense problem is NP-hard and propose heuristic solutions for both the zero-sum and non-zero-sum settings. By relaxing some constraints of the original problem, we formulate a linear program for local optimization around a feasible point. We present defense results with both synthetic and real networks and show that our methods often reach the lower bound of the defender's cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19083v2</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin A. Miller, Zohair Shafi, Wheeler Ruml, Yevgeniy Vorobeychik, Tina Eliassi-Rad, Scott Alfeld</dc:creator>
    </item>
    <item>
      <title>BOPIM: Bayesian Optimization for influence maximization on temporal networks</title>
      <link>https://arxiv.org/abs/2308.04700</link>
      <description>arXiv:2308.04700v4 Announce Type: replace 
Abstract: The goal of influence maximization (IM) is to select a small set of seed nodes which maximizes the spread of influence on a network. In this work, we propose BOPIM, a Bayesian Optimization (BO) algorithm for IM on temporal networks. The IM task is well-suited for a BO solution due to its expensive and complicated objective function. There are at least two key challenges, however, that must be overcome, primarily due to the inputs coming from a cardinality-constrained, non-Euclidean, combinatorial space. The first is constructing the kernel function for the Gaussian Process regression. We propose two kernels, one based on the Hamming distance between seed sets and the other leveraging the Jaccard coefficient between node's neighbors. The second challenge is the acquisition function. For this, we use the Expected Improvement function, suitably adjusting for noise in the observations, and optimize it using a greedy algorithm to account for the cardinality constraint. In numerical experiments on real-world networks, we prove that BOPIM outperforms competing methods and yields comparable influence spreads to a gold-standard greedy algorithm while being as much as ten times faster. In addition, we find that the Hamming kernel performs favorably compared to the Jaccard kernel in nearly all settings, a somewhat surprising result as the former does not explicitly account for the graph structure. Finally, we demonstrate two ways that the proposed method can quantify uncertainty in optimal seed sets. To our knowledge, this is the first attempt to look at uncertainty in the seed sets for IM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04700v4</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Yanchenko</dc:creator>
    </item>
    <item>
      <title>HateSieve: A Contrastive Learning Framework for Detecting and Segmenting Hateful Content in Multimodal Memes</title>
      <link>https://arxiv.org/abs/2408.05794</link>
      <description>arXiv:2408.05794v2 Announce Type: replace-cross 
Abstract: Amidst the rise of Large Multimodal Models (LMMs) and their widespread application in generating and interpreting complex content, the risk of propagating biased and harmful memes remains significant. Current safety measures often fail to detect subtly integrated hateful content within ``Confounder Memes''. To address this, we introduce \textsc{HateSieve}, a new framework designed to enhance the detection and segmentation of hateful elements in memes. \textsc{HateSieve} features a novel Contrastive Meme Generator that creates semantically paired memes, a customized triplet dataset for contrastive learning, and an Image-Text Alignment module that produces context-aware embeddings for accurate meme segmentation. Empirical experiments on the Hateful Meme Dataset show that \textsc{HateSieve} not only surpasses existing LMMs in performance with fewer trainable parameters but also offers a robust mechanism for precisely identifying and isolating hateful content. \textcolor{red}{Caution: Contains academic discussions of hate speech; viewer discretion advised.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05794v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.MM</category>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Findings Assoc. Comput. Linguistics: NAACL 2025, 5201-5215 (2025)</arxiv:journal_reference>
      <dc:creator>Xuanyu Su, Yansong Li, Diana Inkpen, Nathalie Japkowicz</dc:creator>
    </item>
    <item>
      <title>How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation</title>
      <link>https://arxiv.org/abs/2504.19489</link>
      <description>arXiv:2504.19489v4 Announce Type: replace-cross 
Abstract: Recently, numerous community search methods for large graphs have been proposed, at the core of which is defining and measuring cohesion. This paper experimentally evaluates the effectiveness of these community search algorithms w.r.t. cohesiveness in the context of online social networks. Social communities are formed and developed under the influence of group cohesion theory, which has been extensively studied in social psychology. However, current generic methods typically measure cohesiveness using structural or attribute-based approaches and overlook domain-specific concepts such as group cohesion. We introduce five novel psychology-informed cohesiveness measures, based on the concept of group cohesion from social psychology, and propose a novel framework called CHASE for evaluating eight representative community search algorithms w.r.t. these measures on online social networks. Our analysis reveals that there is no clear correlation between structural and psychological cohesiveness, and no algorithm effectively identifies psychologically cohesive communities in online social networks. This study provides new insights that could guide the development of future community search methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19489v4</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3729997</arxiv:DOI>
      <dc:creator>Yining Zhao, Sourav S Bhowmick, Nastassja L. Fischer, SH Annabel Chen</dc:creator>
    </item>
  </channel>
</rss>
