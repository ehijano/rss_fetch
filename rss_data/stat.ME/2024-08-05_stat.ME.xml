<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 02:30:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Early Stopping Based on Repeated Significance</title>
      <link>https://arxiv.org/abs/2408.00908</link>
      <description>arXiv:2408.00908v1 Announce Type: new 
Abstract: For a bucket test with a single criterion for success and a fixed number of samples or testing period, requiring a $p$-value less than a specified value of $\alpha$ for the success criterion produces statistical confidence at level $1 - \alpha$. For multiple criteria, a Bonferroni correction that partitions $\alpha$ among the criteria produces statistical confidence, at the cost of requiring lower $p$-values for each criterion. The same concept can be applied to decisions about early stopping, but that can lead to strict requirements for $p$-values. We show how to address that challenge by requiring criteria to be successful at multiple decision points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00908v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Bax, Arundhyoti Sarkar, Alex Shtoff</dc:creator>
    </item>
    <item>
      <title>Aggregation Models with Optimal Weights for Distributed Gaussian Processes</title>
      <link>https://arxiv.org/abs/2408.00955</link>
      <description>arXiv:2408.00955v1 Announce Type: cross 
Abstract: Gaussian process (GP) models have received increasingly attentions in recent years due to their superb prediction accuracy and modeling flexibility. To address the computational burdens of GP models for large-scale datasets, distributed learning for GPs are often adopted. Current aggregation models for distributed GPs are not time-efficient when incorporating correlations between GP experts. In this work, we propose a novel approach for aggregated prediction in distributed GPs. The technique is suitable for both the exact and sparse variational GPs. The proposed method incorporates correlations among experts, leading to better prediction accuracy with manageable computational requirements. As demonstrated by empirical studies, the proposed approach results in more stable predictions in less time than state-of-the-art consistent aggregation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00955v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyuan Chen, Rui Tuo</dc:creator>
    </item>
    <item>
      <title>Reduced-Rank Estimation for Ill-Conditioned Stochastic Linear Model with High Signal-to-Noise Ratio</title>
      <link>https://arxiv.org/abs/2408.01117</link>
      <description>arXiv:2408.01117v1 Announce Type: cross 
Abstract: Reduced-rank approach has been used for decades in robust linear estimation of both deterministic and random vector of parameters in linear model y=Hx+\sqrt{epsilon}n. In practical settings, estimation is frequently performed under incomplete or inexact model knowledge, which in the stochastic case significantly increases mean-square-error (MSE) of an estimate obtained by the linear minimum mean-square-error (MMSE) estimator, which is MSE-optimal among linear estimators in the theoretical case of perfect model knowledge. However, the improved performance of reduced-rank estimators over MMSE estimator in estimation under incomplete or inexact model knowledge has been established to date only by means of numerical simulations and arguments indicating that the reduced-rank approach may provide improved performance over MMSE estimator in certain settings. In this paper we focus on the high signal-to-noise ratio (SNR) case, which has not been previously considered as a natural area of application of reduced-rank estimators. We first show explicit sufficient conditions under which familiar reduced-rank MMSE and truncated SVD estimators achieve lower MSE than MMSE estimator if singular values of array response matrix H are perturbed. We then extend these results to the case of a generic perturbation of array response matrix H, and demonstrate why MMSE estimator frequently attains higher MSE than reduced-rank MMSE and truncated SVD estimators if H is ill-conditioned. The main results of this paper are verified in numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01117v1</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jfranklin.2016.05.007</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Franklin Institute, 2016</arxiv:journal_reference>
      <dc:creator>Tomasz Piotrowski, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Probabilistic Inversion Modeling of Gas Emissions: A Gradient-Based MCMC Estimation of Gaussian Plume Parameters</title>
      <link>https://arxiv.org/abs/2408.01298</link>
      <description>arXiv:2408.01298v1 Announce Type: cross 
Abstract: In response to global concerns regarding air quality and the environmental impact of greenhouse gas emissions, detecting and quantifying sources of emissions has become critical. To understand this impact and target mitigations effectively, methods for accurate quantification of greenhouse gas emissions are required. In this paper, we focus on the inversion of concentration measurements to estimate source location and emission rate. In practice, such methods often rely on atmospheric stability class-based Gaussian plume dispersion models. However, incorrectly identifying the atmospheric stability class can lead to significant bias in estimates of source characteristics. We present a robust approach that reduces this bias by jointly estimating the horizontal and vertical dispersion parameters of the Gaussian plume model, together with source location and emission rate, atmospheric background concentration, and sensor measurement error variance. Uncertainty in parameter estimation is quantified through probabilistic inversion using gradient-based MCMC methods. A simulation study is performed to assess the inversion methodology. We then focus on inference for the published Chilbolton dataset which contains controlled methane releases and demonstrates the practical benefits of estimating dispersion parameters in source inversion problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01298v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Newman, Christopher Nemeth, Matthew Jones, Philip Jonathan</dc:creator>
    </item>
    <item>
      <title>Mean and Covariance Estimation for Discretely Observed High-Dimensional Functional Data: Rates of Convergence and Division of Observational Regimes</title>
      <link>https://arxiv.org/abs/2408.01326</link>
      <description>arXiv:2408.01326v2 Announce Type: cross 
Abstract: Estimation of the mean and covariance parameters for functional data is a critical task, with local linear smoothing being a popular choice. In recent years, many scientific domains are producing multivariate functional data for which $p$, the number of curves per subject, is often much larger than the sample size $n$. In this setting of high-dimensional functional data, much of developed methodology relies on preliminary estimates of the unknown mean functions and the auto- and cross-covariance functions. This paper investigates the convergence rates of local linear estimators in terms of the maximal error across components and pairs of components for mean and covariance functions, respectively, in both $L^2$ and uniform metrics. The local linear estimators utilize a generic weighting scheme that can adjust for differing numbers of discrete observations $N_{ij}$ across curves $j$ and subjects $i$, where the $N_{ij}$ vary with $n$. Particular attention is given to the equal weight per observation (OBS) and equal weight per subject (SUBJ) weighting schemes. The theoretical results utilize novel applications of concentration inequalities for functional data and demonstrate that, similar to univariate functional data, the order of the $N_{ij}$ relative to $p$ and $n$ divides high-dimensional functional data into three regimes (sparse, dense, and ultra-dense), with the high-dimensional parametric convergence rate of $\left\{\log(p)/n\right\}^{1/2}$ being attainable in the latter two.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01326v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Petersen</dc:creator>
    </item>
    <item>
      <title>Differentially Private Methods for Compositional Data</title>
      <link>https://arxiv.org/abs/2211.06337</link>
      <description>arXiv:2211.06337v3 Announce Type: replace 
Abstract: Confidential data, such as electronic health records, activity data from wearable devices, and geolocation data, are becoming increasingly prevalent. Differential privacy provides a framework to conduct statistical analyses while mitigating the risk of leaking private information. Compositional data, which consist of vectors with positive components that add up to a constant, have received little attention in the differential privacy literature. This article proposes differentially private approaches for analyzing compositional data using the Dirichlet distribution. We explore several methods, including Bayesian and bootstrap procedures. For the Bayesian methods, we consider posterior inference techniques based on Markov Chain Monte Carlo, Approximate Bayesian Computation, and asymptotic approximations. We conduct an extensive simulation study to compare these approaches and make evidence-based recommendations. Finally, we apply the methodology to a data set from the American Time Use Survey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06337v3</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Guo, Andr\'es F. Barrientos, V\'ictor Pe\~na</dc:creator>
    </item>
    <item>
      <title>A marginalized three-part interrupted time series regression model for proportional data</title>
      <link>https://arxiv.org/abs/2212.09996</link>
      <description>arXiv:2212.09996v2 Announce Type: replace 
Abstract: Interrupted time series (ITS) is often used to evaluate the effectiveness of a health policy intervention that accounts for the temporal dependence of outcomes. When the outcome of interest is a percentage or percentile, the data can be highly skewed, bounded in $[0, 1]$, and have many zeros or ones. A three-part Beta regression model is commonly used to separate zeros, ones, and positive values explicitly by three submodels. However, incorporating temporal dependence into the three-part Beta regression model is challenging. In this article, we propose a marginalized zero-one-inflated Beta time series model that captures the temporal dependence of outcomes through copula and allows investigators to examine covariate effects on the marginal mean. We investigate its practical performance using simulation studies and apply the model to a real ITS study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.09996v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shangyuan Ye, Maricela Cruz, Ziyou Wang, Yun Yu</dc:creator>
    </item>
    <item>
      <title>More power to you: Using machine learning to augment human coding for more efficient inference in text-based randomized trials</title>
      <link>https://arxiv.org/abs/2309.13666</link>
      <description>arXiv:2309.13666v2 Announce Type: replace 
Abstract: For randomized trials that use text as an outcome, traditional approaches for assessing treatment impact require that each document first be manually coded for constructs of interest by trained human raters. This process, the current standard, is both time-consuming and limiting: even the largest human coding efforts are typically constrained to measure only a small set of dimensions across a subsample of available texts. In this work, we present an inferential framework that can be used to increase the power of an impact assessment, given a fixed human-coding budget, by taking advantage of any "untapped" observations -- those documents not manually scored due to time or resource constraints -- as a supplementary resource. Our approach, a methodological combination of causal inference, survey sampling methods, and machine learning, has four steps: (1) select and code a sample of documents; (2) build a machine learning model to predict the human-coded outcomes from a set of automatically extracted text features; (3) generate machine-predicted scores for all documents and use these scores to estimate treatment impacts; and (4) adjust the final impact estimates using the residual differences between human-coded and machine-predicted outcomes. This final step ensures any biases in the modeling procedure do not propagate to biases in final estimated effects. Through an extensive simulation study and an application to a recent field trial in education, we show that our proposed approach can be used to reduce the scope of a human-coding effort while maintaining nominal power to detect a significant treatment impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13666v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reagan Mozer, Luke Miratrix</dc:creator>
    </item>
    <item>
      <title>Nonparametric Strategy Test</title>
      <link>https://arxiv.org/abs/2312.10695</link>
      <description>arXiv:2312.10695v4 Announce Type: replace 
Abstract: We present a nonparametric statistical test for determining whether an agent is following a given mixed strategy in a repeated strategic-form game given samples of the agent's play. This involves two components: determining whether the agent's frequencies of pure strategies are sufficiently close to the target frequencies, and determining whether the pure strategies selected are independent between different game iterations. Our integrated test involves applying a chi-squared goodness of fit test for the first component and a generalized Wald-Wolfowitz runs test for the second component. The results from both tests are combined using Bonferroni correction to produce a complete test for a given significance level $\alpha.$ We applied the test to publicly available data of human rock-paper-scissors play. The data consists of 50 iterations of play for 500 human players. We test with a null hypothesis that the players are following a uniform random strategy independently at each game iteration. Using a significance level of $\alpha = 0.05$, we conclude that 305 (61%) of the subjects are following the target strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10695v4</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Ganzfried</dc:creator>
    </item>
    <item>
      <title>Sequential decision rules for 2-arm clinical trials: a Bayesian perspective</title>
      <link>https://arxiv.org/abs/2312.15222</link>
      <description>arXiv:2312.15222v2 Announce Type: replace 
Abstract: Practical employment of Bayesian trial designs has been rare. Even if accepted in principle, the regulators have commonly required that such designs be calibrated according to an upper bound for the frequentist Type 1 error rate. This represents an internally inconsistent hybrid methodology, where important advantages from applying the Bayesian principles are lost. In particular, all pre-planned interim looks have an inflating multiplicity effect on Type 1 error rate. To present an alternative approach, we consider the prototype case of a 2-arm superiority trial with binary outcomes. The design is adaptive, using error tolerance criteria based on sequentially updated posterior probabilities, to conclude efficacy of the experimental treatment or futility of the trial. In the proposed approach, the regulators are assumed to have the main responsibility in defining criteria for the error control against false conclusions of efficacy, whereas the trial investigators will have a natural role in determining the criteria for concluding futility and thereby stopping the trial. It is suggested that the control of Type 1 error rate be replaced by the control of a criterion called regulators' False Discovery Probability (rFDP), the term corresponding directly to the probability interpretation of this criterion. Importantly, the sequential error control during the data analysis based on posterior probabilities will satisfy the rFDP criterion automatically, so that no separate computations are needed for such a purpose. The method contains the option of applying a decision rule for terminating the trial early if the predicted costs from continuing would exceed the corresponding gains. The proposed approach can lower the ultimately unnecessary barriers from the practical application of Bayesian trial designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15222v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elja Arjas, Dario Gasbarra</dc:creator>
    </item>
    <item>
      <title>Sparse signal recovery and source localization via covariance learning</title>
      <link>https://arxiv.org/abs/2401.13975</link>
      <description>arXiv:2401.13975v2 Announce Type: replace 
Abstract: In the Multiple Measurements Vector (MMV) model, measurement vectors are connected to unknown, jointly sparse signal vectors through a linear regression model employing a single known measurement matrix (or dictionary). Typically, the number of atoms (columns of the dictionary) is greater than the number measurements and the sparse signal recovery problem is generally ill-posed. In this paper, we treat the signals and measurement noise as independent Gaussian random vectors with unknown signal covariance matrix and noise variance, respectively, and characterize the solution of the likelihood equation in terms of fixed point equation, thereby enabling the recovery of the sparse signal support (sources with non-zero variances) via a block coordinate descent (BCD) algorithm that leverage the FP characterization of the likelihood equation. Additionally, a greedy pursuit method, analogous to popular simultaneous orthogonal matching pursuit (OMP), is introduced. Our numerical examples demonstrate effectiveness of the proposed covariance learning (CL) algorithms both in classic sparse signal recovery as well as in direction-of-arrival (DOA) estimation problems where they perform favourably compared to the state-of-the-art algorithms under a broad variety of settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13975v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Esa Ollila</dc:creator>
    </item>
    <item>
      <title>Doubly Robust Interval Estimation for Optimal Policy Evaluation in Online Learning</title>
      <link>https://arxiv.org/abs/2110.15501</link>
      <description>arXiv:2110.15501v4 Announce Type: replace-cross 
Abstract: Evaluating the performance of an ongoing policy plays a vital role in many areas such as medicine and economics, to provide crucial instructions on the early-stop of the online experiment and timely feedback from the environment. Policy evaluation in online learning thus attracts increasing attention by inferring the mean outcome of the optimal policy (i.e., the value) in real-time. Yet, such a problem is particularly challenging due to the dependent data generated in the online environment, the unknown optimal policy, and the complex exploration and exploitation trade-off in the adaptive experiment. In this paper, we aim to overcome these difficulties in policy evaluation for online learning. We explicitly derive the probability of exploration that quantifies the probability of exploring non-optimal actions under commonly used bandit algorithms. We use this probability to conduct valid inference on the online conditional mean estimator under each action and develop the doubly robust interval estimation (DREAM) method to infer the value under the estimated optimal policy in online learning. The proposed value estimator provides double protection for consistency and is asymptotically normal with a Wald-type confidence interval provided. Extensive simulation studies and real data applications are conducted to demonstrate the empirical validity of the proposed DREAM method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.15501v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Shen, Hengrui Cai, Rui Song</dc:creator>
    </item>
    <item>
      <title>Boosted generalized normal distributions: Integrating machine learning with operations knowledge</title>
      <link>https://arxiv.org/abs/2407.19092</link>
      <description>arXiv:2407.19092v2 Announce Type: replace-cross 
Abstract: Applications of machine learning (ML) techniques to operational settings often face two challenges: i) ML methods mostly provide point predictions whereas many operational problems require distributional information; and ii) They typically do not incorporate the extensive body of knowledge in the operations literature, particularly the theoretical and empirical findings that characterize specific distributions. We introduce a novel and rigorous methodology, the Boosted Generalized Normal Distribution ($b$GND), to address these challenges. The Generalized Normal Distribution (GND) encompasses a wide range of parametric distributions commonly encountered in operations, and $b$GND leverages gradient boosting with tree learners to flexibly estimate the parameters of the GND as functions of covariates. We establish $b$GND's statistical consistency, thereby extending this key property to special cases studied in the ML literature that lacked such guarantees. Using data from a large academic emergency department in the United States, we show that the distributional forecasting of patient wait and service times can be meaningfully improved by leveraging findings from the healthcare operations literature. Specifically, $b$GND performs 6% and 9% better than the distribution-agnostic ML benchmark used to forecast wait and service times respectively. Further analysis suggests that these improvements translate into a 9% increase in patient satisfaction and a 4% reduction in mortality for myocardial infarction patients. Our work underscores the importance of integrating ML with operations knowledge to enhance distributional forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19092v2</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ragip Gurlek, Francis de Vericourt, Donald K. K. Lee</dc:creator>
    </item>
  </channel>
</rss>
