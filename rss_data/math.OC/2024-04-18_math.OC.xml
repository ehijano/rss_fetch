<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Apr 2024 04:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Asymptotic Nash Equilibria of Finite-State Ergodic Markovian Mean Field Games</title>
      <link>https://arxiv.org/abs/2404.11695</link>
      <description>arXiv:2404.11695v1 Announce Type: new 
Abstract: Mean field games (MFGs) model equilibria in games with a continuum of weakly interacting players as limiting systems of symmetric $n$-player games. We consider the finite-state, infinite-horizon problem with ergodic cost. Assuming Markovian strategies, we first prove that any solution to the MFG system gives rise to a $(C/\sqrt{n})$-Nash equilibrium in the $n$-player game. We follow this result by proving the same is true for the strategy profile derived from the master equation. We conclude the main theoretical portion of the paper by establishing a large deviation principle for empirical measures associated with the asymptotic Nash equilibria. Then, we contrast the asymptotic Nash equilibria using an example. We solve the MFG system directly and numerically solve the ergodic master equation by adapting the deep Galerkin method of Sirignano and Spiliopoulos. We use these results to derive the strategies of the asymptotic Nash equilibria and compare them. Finally, we derive an explicit form for the rate functions in dimension two.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11695v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Cohen, Ethan Zell</dc:creator>
    </item>
    <item>
      <title>A Sequential Benders-based Mixed-Integer Quadratic Programming Algorithm</title>
      <link>https://arxiv.org/abs/2404.11786</link>
      <description>arXiv:2404.11786v1 Announce Type: new 
Abstract: For continuous decision spaces, nonlinear programs (NLPs) can be efficiently solved via sequential quadratic programming (SQP) and, more generally, sequential convex programming (SCP). These algorithms linearize only the nonlinear equality constraints and keep the outer convex structure of the problem intact. The aim of the presented sequential mixed-integer quadratic programming (MIQP) algorithm for mixed-integer nonlinear problems (MINLPs) is to extend the SQP/SCP methodology to MINLPs and leverage the availability of efficient MIQP solvers. The algorithm employs a three-step method in each iterate: First, the MINLP is linearized at a given iterate. Second, an MIQP with its feasible set restricted to a specific region around the current linearization point is formulated and solved. Third, the integer variables obtained from the MIQP solution are fixed, and only an NLP in the continuous variables is solved. The outcome of the third step is compared to previous iterates, and the best iterate so far is used as a linearization point in the next iterate. Crucially, the objective values and derivatives from all previous iterates are used to formulate the polyhedral region in the second step. The linear inequalities that define the region build on concepts from generalized Benders' decomposition for MINLPs. Although the presented MINLP algorithm is a heuristic method without any global optimality guarantee, it converges to the exact integer solution when applied to convex MINLP with a linear outer structure. The conducted numerical experiments demonstrate that the proposed algorithm is competitive with other open-source solvers for MINLP. Finally, we solve two mixed-integer optimal control problems (MIOCPs) transcribed into MINLPs via direct methods, showing that the presented algorithm can effectively deal with nonlinear equality constraints, a major hurdle for generic MINLP solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11786v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Ghezzi, Wim Van Roy, Sebastian Sager, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Constrained Stochastic Recursive Momentum Successive Convex Approximation</title>
      <link>https://arxiv.org/abs/2404.11790</link>
      <description>arXiv:2404.11790v1 Announce Type: new 
Abstract: We consider stochastic optimization problems with functional constraints. If the objective and constraint functions are not convex, the classical stochastic approximation algorithms such as the proximal stochastic gradient descent do not lead to efficient algorithms. In this work, we put forth an accelerated SCA algorithm that utilizes the recursive momentum-based acceleration which is widely used in the unconstrained setting. Remarkably, the proposed algorithm also achieves the optimal SFO complexity, at par with that achieved by state-of-the-art (unconstrained) stochastic optimization algorithms and match the SFO-complexity lower bound for minimization of general smooth functions. At each iteration, the proposed algorithm entails constructing convex surrogates of the objective and the constraint functions, and solving the resulting convex optimization problem. A recursive update rule is employed to track the gradient of the objective function, and contributes to achieving faster convergence and improved SFO complexity. A key ingredient of the proof is a new parameterized version of the standard Mangasarian-Fromowitz Constraints Qualification, that allows us to bound the dual variables and hence establish that the iterates approach an $\epsilon$-stationary point. We also detail a obstacle-avoiding trajectory optimization problem that can be solved using the proposed algorithm, and show that its performance is superior to that of the existing algorithms. The performance of the proposed algorithm is also compared against that of a specialized sparse classification algorithm on a binary classification problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11790v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Basil M. Idrees, Lavish Arora, Ketan Rajawat</dc:creator>
    </item>
    <item>
      <title>Derivative-Free Optimization via Adaptive Sampling Strategies</title>
      <link>https://arxiv.org/abs/2404.11893</link>
      <description>arXiv:2404.11893v1 Announce Type: new 
Abstract: In this paper, we present a novel derivative-free optimization framework for solving unconstrained stochastic optimization problems. Many problems in fields ranging from simulation optimization to reinforcement learning involve settings where only stochastic function values are obtained via an oracle with no available gradient information, necessitating the usage of derivative-free optimization methodologies. Our approach includes estimating gradients using stochastic function evaluations and integrating adaptive sampling techniques to control the accuracy in these stochastic approximations. We consider various gradient estimation techniques including standard finite difference, Gaussian smoothing, sphere smoothing, randomized coordinate finite difference, and randomized subspace finite difference methods. We provide theoretical convergence guarantees for our framework and analyze the worst-case iteration and sample complexities associated with each gradient estimation method. Finally, we demonstrate the empirical performance of the methods on logistic regression and nonlinear least squares problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11893v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raghu Bollapragada, Cem Karamanli, Stefan M. Wild</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Relative Investment Games in a Jump Diffusion Market with Deep Reinforcement Learning Algorithm</title>
      <link>https://arxiv.org/abs/2404.11967</link>
      <description>arXiv:2404.11967v1 Announce Type: new 
Abstract: This paper focuses on multi-agent stochastic differential games for jump-diffusion systems. On one hand, we study the multi-agent game for optimal investment in a jump-diffusion market. We derive constant Nash equilibria and provide sufficient conditions for their existence and uniqueness for exponential, power, and logarithmic utilities, respectively. On the other hand, we introduce a computational framework based on the actor-critic method in deep reinforcement learning to solve the stochastic control problem with jumps. We extend this algorithm to address the multi-agent game with jumps and utilize parallel computing to enhance computational efficiency. We present numerical examples of the Merton problem with jumps, linear quadratic regulators, and the optimal investment game under various settings to demonstrate the accuracy, efficiency, and robustness of the proposed method. In particular, neural network solutions numerically converge to the derived constant Nash equilibrium for the multi-agent game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11967v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liwei Lu, Ruimeng Hu, Xu Yang, Yi Zhu</dc:creator>
    </item>
    <item>
      <title>Recursive stochastic differential games with non-Lipschitzian generators and viscosity solutions of Hamilton-Jacobi-Bellman-Isaacs equation</title>
      <link>https://arxiv.org/abs/2404.12129</link>
      <description>arXiv:2404.12129v1 Announce Type: new 
Abstract: This investigation is dedicated to a two-player zero-sum stochastic differential game (SDG), where a cost function is characterized by a backward stochastic differential equation (BSDE) with a continuous and monotonic generator regarding the first unknown variable, which possesses immense applicability in financial engineering. A verification theorem by virtue of classical solution of derived Hamilton-Jacobi-Bellman-Isaacs (HJBI) equation is given. The dynamic programming principle (DPP) and unique weak (viscosity) solvability of HJBI equation are formulated through comparison theorem for BSDEs with monotonic generators and stability of viscosity solution. Some new regularity properties of value function are presented. Finally, we propose three concrete examples, which are concerned with resp., classical, and viscosity solution of HJBI equation, as well as a financial application where an investor with a non-Lipschitzian Epstein-Zin utility deals with market friction to maximize her utility preference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12129v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangchen Wang, Zhuangzhuang Xing</dc:creator>
    </item>
    <item>
      <title>Multi-material topology optimization of an electric machine considering demagnetization</title>
      <link>https://arxiv.org/abs/2404.12188</link>
      <description>arXiv:2404.12188v1 Announce Type: new 
Abstract: We consider the topology optimization problem of a 2d permanent magnet synchronous machine in magnetostatic operation with demagnetization. This amounts to a PDE-constrained multi-material design optimization problem with an additional pointwise state constraint. Using a generic framework we can incorporate this additional constraint and compute the corresponding topological derivative. We present and discuss optimization results obtained by a multi-material level set algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12188v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nepomuk Krenn, Peter Gangl</dc:creator>
    </item>
    <item>
      <title>Tracing Pareto-optimal points for multi-objective shape optimization applied to electric machines</title>
      <link>https://arxiv.org/abs/2404.12205</link>
      <description>arXiv:2404.12205v1 Announce Type: new 
Abstract: In the context of the optimization of rotating electric machines, many different objective functions are of interest and considering this during the optimization is of crucial importance. While evolutionary algorithms can provide a Pareto front straightforwardly and are widely used in this context, derivative-based optimization algorithms can be computationally more efficient. In this case, a Pareto front can be obtained by performing several optimization runs with different weights. In this work, we focus on a free-form shape optimization approach allowing for arbitrary motor geometries. In particular, we propose a way to efficiently obtain Pareto-optimal points by moving along to the Pareto front exploiting a homotopy method based on second order shape derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12205v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessio Cesarano, Peter Gangl</dc:creator>
    </item>
    <item>
      <title>Investigating Variance Definitions for Mirror Descent with Relative Smoothness</title>
      <link>https://arxiv.org/abs/2404.12213</link>
      <description>arXiv:2404.12213v1 Announce Type: new 
Abstract: Mirror Descent is a popular algorithm, that extends Gradients Descent (GD) beyond the Euclidean geometry. One of its benefits is to enable strong convergence guarantees through smooth-like analyses, even for objectives with exploding or vanishing curvature. This is achieved through the introduction of the notion of relative smoothness, which holds in many of the common use-cases of Mirror descent. While basic deterministic results extend well to the relative setting, most existing stochastic analyses require additional assumptions on the mirror, such as strong convexity (in the usual sense), to ensure bounded variance. In this work, we revisit Stochastic Mirror Descent (SMD) proofs in the (relatively-strongly-) convex and relatively-smooth setting, and introduce a new (less restrictive) definition of variance which can generally be bounded (globally) under mild regularity assumptions. We then investigate this notion in more details, and show that it naturally leads to strong convergence guarantees for stochastic mirror descent. Finally, we leverage this new analysis to obtain convergence guarantees for the Maximum Likelihood Estimator of a Gaussian with unknown mean and variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12213v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadrien Hendrikx</dc:creator>
    </item>
    <item>
      <title>Corrected Correlation Estimates for Meta-Analysis</title>
      <link>https://arxiv.org/abs/2404.11678</link>
      <description>arXiv:2404.11678v1 Announce Type: cross 
Abstract: Meta-analysis allows rigorous aggregation of estimates and uncertainty across multiple studies. When a given study reports multiple estimates, such as log odds ratios (ORs) or log relative risks (RRs) across exposure groups, accounting for within-study correlations improves accuracy and efficiency of meta-analytic results. Canonical approaches of Greenland-Longnecker and Hamling estimate pseudo cases and non-cases for exposure groups to obtain within-study correlations. However, currently available implementations for both methods fail on simple examples.
  We review both GL and Hamling methods through the lens of optimization. For ORs, we provide modifications of each approach that ensure convergence for any feasible inputs. For GL, this is achieved through a new connection to entropic minimization. For Hamling, a modification leads to a provably solvable equivalent set of equations given a specific initialization. For each, we provide implementations a guaranteed to work for any feasible input.
  For RRs, we show the new GL approach is always guaranteed to succeed, but any Hamling approach may fail: we give counter-examples where no solutions exist. We derive a sufficient condition on reported RRs that guarantees success when reported variances are all equal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11678v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Johnson-V\'azquez, Peng Zheng, Aleksandr Aravkin</dc:creator>
    </item>
    <item>
      <title>Perspectives on Contractivity in Control, Optimization, and Learning</title>
      <link>https://arxiv.org/abs/2404.11707</link>
      <description>arXiv:2404.11707v1 Announce Type: cross 
Abstract: Contraction theory is a mathematical framework for studying the convergence, robustness, and modularity properties of dynamical systems and algorithms. In this opinion paper, we provide five main opinions on the virtues of contraction theory. These opinions are (i) contraction theory is a unifying framework emerging from classical and modern works, (ii) contractivity is computationally-friendly, robust, and modular stability, (iii) numerous dynamical systems are contracting, (iv) contraction theory is relevant to modern applications, and (v) contraction theory can be vastly extended in numerous directions. We survey recent theoretical and applied research in each of these five directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11707v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Davydov, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>End-to-End Mesh Optimization of a Hybrid Deep Learning Black-Box PDE Solver</title>
      <link>https://arxiv.org/abs/2404.11766</link>
      <description>arXiv:2404.11766v1 Announce Type: cross 
Abstract: Deep learning has been widely applied to solve partial differential equations (PDEs) in computational fluid dynamics. Recent research proposed a PDE correction framework that leverages deep learning to correct the solution obtained by a PDE solver on a coarse mesh. However, end-to-end training of such a PDE correction model over both solver-dependent parameters such as mesh parameters and neural network parameters requires the PDE solver to support automatic differentiation through the iterative numerical process. Such a feature is not readily available in many existing solvers. In this study, we explore the feasibility of end-to-end training of a hybrid model with a black-box PDE solver and a deep learning model for fluid flow prediction. Specifically, we investigate a hybrid model that integrates a black-box PDE solver into a differentiable deep graph neural network. To train this model, we use a zeroth-order gradient estimator to differentiate the PDE solver via forward propagation. Although experiments show that the proposed approach based on zeroth-order gradient estimation underperforms the baseline that computes exact derivatives using automatic differentiation, our proposed method outperforms the baseline trained with a frozen input mesh to the solver. Moreover, with a simple warm-start on the neural network parameters, we show that models trained by these zeroth-order algorithms achieve an accelerated convergence and improved generalization performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11766v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaocong Ma, James Diffenderfer, Bhavya Kailkhura, Yi Zhou</dc:creator>
    </item>
    <item>
      <title>A Mean-Field Analysis of Neural Gradient Descent-Ascent: Applications to Functional Conditional Moment Equations</title>
      <link>https://arxiv.org/abs/2404.12312</link>
      <description>arXiv:2404.12312v1 Announce Type: cross 
Abstract: We study minimax optimization problems defined over infinite-dimensional function classes. In particular, we restrict the functions to the class of overparameterized two-layer neural networks and study (i) the convergence of the gradient descent-ascent algorithm and (ii) the representation learning of the neural network. As an initial step, we consider the minimax optimization problem stemming from estimating a functional equation defined by conditional expectations via adversarial estimation, where the objective function is quadratic in the functional space. For this problem, we establish convergence under the mean-field regime by considering the continuous-time and infinite-width limit of the optimization dynamics. Under this regime, gradient descent-ascent corresponds to a Wasserstein gradient flow over the space of probability measures defined over the space of neural network parameters. We prove that the Wasserstein gradient flow converges globally to a stationary point of the minimax objective at a $\mathcal{O}(T^{-1} + \alpha^{-1} ) $ sublinear rate, and additionally finds the solution to the functional equation when the regularizer of the minimax objective is strongly convex. Here $T$ denotes the time and $\alpha$ is a scaling parameter of the neural network. In terms of representation learning, our results show that the feature representation induced by the neural networks is allowed to deviate from the initial one by the magnitude of $\mathcal{O}(\alpha^{-1})$, measured in terms of the Wasserstein distance. Finally, we apply our general results to concrete examples including policy evaluation, nonparametric instrumental variable regression, and asset pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12312v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Zhu, Yufeng Zhang, Zhaoran Wang, Zhuoran Yang, Xiaohong Chen</dc:creator>
    </item>
    <item>
      <title>Decision making in stochastic extensive form I: Stochastic decision forests</title>
      <link>https://arxiv.org/abs/2404.12332</link>
      <description>arXiv:2404.12332v1 Announce Type: cross 
Abstract: A general theory of stochastic decision forests reconciling two concepts of information flow -- decision trees and refined partitions on the one hand, filtrations from probability theory on the other -- is constructed. The traditional "nature" agent is replaced with a one-shot lottery draw that determines a tree of a given decision forest, while each "personal" agent is equipped with an oracle providing updates on the draw's result and makes partition refining choices adapted to this information. This theory overcomes the incapacity of existing approaches to extensive form theory to capture continuous time stochastic processes like Brownian motion as outcomes of "nature" decision making in particular. Moreover, a class of stochastic decision forests based on paths of action indexed by time is constructed, covering a large fraction of models from the literature and constituting a first step towards an approximation theory for stochastic differential games in extensive form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12332v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Emanuel Rapsch</dc:creator>
    </item>
    <item>
      <title>Matching the Statistical Query Lower Bound for k-sparse Parity Problems with Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2404.12376</link>
      <description>arXiv:2404.12376v1 Announce Type: cross 
Abstract: The $k$-parity problem is a classical problem in computational complexity and algorithmic theory, serving as a key benchmark for understanding computational classes. In this paper, we solve the $k$-parity problem with stochastic gradient descent (SGD) on two-layer fully-connected neural networks. We demonstrate that SGD can efficiently solve the $k$-sparse parity problem on a $d$-dimensional hypercube ($k\le O(\sqrt{d})$) with a sample complexity of $\tilde{O}(d^{k-1})$ using $2^{\Theta(k)}$ neurons, thus matching the established $\Omega(d^{k})$ lower bounds of Statistical Query (SQ) models. Our theoretical analysis begins by constructing a good neural network capable of correctly solving the $k$-parity problem. We then demonstrate how a trained neural network with SGD can effectively approximate this good network, solving the $k$-parity problem with small statistical errors. Our theoretical results and findings are supported by empirical evidence, showcasing the efficiency and efficacy of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12376v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwen Kou, Zixiang Chen, Quanquan Gu, Sham M. Kakade</dc:creator>
    </item>
    <item>
      <title>A Highly Efficient Adaptive-Sieving-Based Algorithm for the High-Dimensional Rank Lasso Problem</title>
      <link>https://arxiv.org/abs/2207.12753</link>
      <description>arXiv:2207.12753v3 Announce Type: replace 
Abstract: The high-dimensional rank lasso (hdr lasso) model is an efficient approach to deal with high-dimensional data analysis. It was proposed as a tuning-free robust approach for the high-dimensional regression and was demonstrated to enjoy several statistical advantages over other approaches. The hdr lasso problem is essentially an $L_1$-regularized optimization problem whose loss function is Jaeckel's dispersion function with Wilcoxon scores. Due to the nondifferentiability of the above loss function, many classical algorithms for lasso-type problems are unable to solve this model. In this paper, inspired by the adaptive sieving strategy for the exclusive lasso problem [1], we propose an adaptive-sieving-based algorithm to solve the hdr lasso problem. The proposed algorithm makes full use of the sparsity of the solution. In each iteration, a subproblem with the same form as the original model is solved, but in a much smaller size. We apply the proximal point algorithm to solve the subproblem, which fully takes advantage of the two nonsmooth terms. Extensive numerical results demonstrate that the proposed algorithm (AS-PPA) is robust for different types of noises, which verifies the attractive statistical property as shown in [2]. Moreover, AS-PPA is also highly efficient, especially for the case of high-dimensional features, compared with other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.12753v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoning Bai, Qingna Li</dc:creator>
    </item>
    <item>
      <title>Learning Decision-Focused Uncertainty Sets in Robust Optimization</title>
      <link>https://arxiv.org/abs/2305.19225</link>
      <description>arXiv:2305.19225v2 Announce Type: replace 
Abstract: We propose a data-driven technique to automatically learn the uncertainty sets in robust optimization. Our method reshapes the uncertainty sets by minimizing the expected performance across a family of problems subject to guaranteeing constraint satisfaction. Our approach is very flexible and can learn a wide variety of uncertainty sets while preserving tractability. We solve the constrained learning problem using a stochastic augmented Lagrangian method that relies on differentiating the solutions of the robust optimization problems with respect to the parameters of the uncertainty set. Due to the nonsmooth and nonconvex nature of the augmented Lagrangian function, we apply the nonsmooth conservative implicit function theorem to establish convergence to a critical point, which is a feasible solution of the constrained problem under mild assumptions. Using empirical process theory, we show finite-sample probabilistic guarantees of constraint satisfaction for the resulting solutions. Numerical experiments show that our method outperforms traditional approaches in robust and distributionally robust optimization in terms of out-of-sample performance and constraint satisfaction guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19225v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irina Wang, Cole Becker, Bart Van Parys, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Achieving Social Optimum and Budget Balance via a Joint Electricity-Carbon Pricing Mechanism</title>
      <link>https://arxiv.org/abs/2308.08195</link>
      <description>arXiv:2308.08195v2 Announce Type: replace 
Abstract: Decarbonizing electric grids is a crucial global endeavor in the pursuit of carbon neutrality. Taking carbon emissions from generation into account when pricing electricity usage is an essential way to achieve this goal. However, such pricing is not trivial due to the requirements of an effective electricity market, such as maintaining budget balance, providing incentives to motivate participants to follow the dispatch schedule, and minimizing the impact on affected parties compared to when they were in the traditional electricity market. Although existing joint electricity-carbon pricing mechanisms have shown promising performance in reducing emissions in power networks, they can hardly meet all the requirements. This paper proposes a novel joint electricity-carbon pricing mechanism based on primal-dual optimality condition-enabled transformation. An algorithm for determining the critical market parameter is developed. The proposed pricing mechanism is proven to possess all the desired properties, including budget balance, individual rationality, dispatch-following incentive compatibility, and truthful-bidding incentive compatibility. These properties ensure the proposed mechanism can incentivize market participants to achieve carbon-aware social optimum in a self-organized and sustainable way. Numerical experiments show the advantages of the proposed pricing mechanism compared to the existing marginal-based and carbon emission flow-based pricing mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08195v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yue Chen, Changhong Zhao</dc:creator>
    </item>
    <item>
      <title>Infinite Horizon Average Cost Optimality Criteria for Mean-Field Control</title>
      <link>https://arxiv.org/abs/2309.11744</link>
      <description>arXiv:2309.11744v2 Announce Type: replace 
Abstract: We study mean-field control problems in discrete-time under the infinite horizon average cost optimality criteria. We focus on both the finite population and the infinite population setups. We show the existence of a solution to the average cost optimality equation (ACOE) and the existence of optimal stationary Markov policies for finite population problems under (i) a minorization condition that provides geometric ergodicity on the collective state process of the agents, and (ii) under standard Lipschitz continuity assumptions on the stage-wise cost and transition function of the agents when the Lipschitz constant of the transition function satisfies a certain bound. For the infinite population problem, we establish the existence of a solution to the ACOE, and the existence of optimal policies under the continuity assumptions on the cost and the transition functions. Finally, we relate the finite population and infinite population control problems: (i) we prove that the optimal value of the finite population problem converges to the optimal value of the infinite population problem as the number of agents grows to infinity; (ii) we show that the accumulation points of the finite population optimal solution corresponds to an optimal solution for the infinite population problem, and finally (iii), we show that one can use the solution of the infinite population problem for the finite population problem symmetrically across the agents to achieve near optimal performance when the population is sufficiently large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11744v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Ali D. Kara</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control Matching</title>
      <link>https://arxiv.org/abs/2312.02027</link>
      <description>arXiv:2312.02027v3 Announce Type: replace 
Abstract: Stochastic optimal control, which has the goal of driving the behavior of noisy systems, is broadly applicable in science, engineering and artificial intelligence. Our work introduces Stochastic Optimal Control Matching (SOCM), a novel Iterative Diffusion Optimization (IDO) technique for stochastic optimal control that stems from the same philosophy as the conditional score matching loss for diffusion models. That is, the control is learned via a least squares problem by trying to fit a matching vector field. The training loss, which is closely connected to the cross-entropy loss, is optimized with respect to both the control function and a family of reparameterization matrices which appear in the matching vector field. The optimization with respect to the reparameterization matrices aims at minimizing the variance of the matching vector field. Experimentally, our algorithm achieves lower error than all the existing IDO techniques for stochastic optimal control for three out of four control problems, in some cases by an order of magnitude. The key idea underlying SOCM is the path-wise reparameterization trick, a novel technique that may be of independent interest. Code at https://github.com/facebookresearch/SOC-matching</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02027v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Jiequn Han, Brandon Amos, Joan Bruna, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>Switching Frequency Limitation with Finite Control Set Model Predictive Control via Slack Variables</title>
      <link>https://arxiv.org/abs/2312.05916</link>
      <description>arXiv:2312.05916v2 Announce Type: replace 
Abstract: Past work proposed an extension to finite control set model predictive control to track both a current reference and a switching frequency reference, simultaneously. Such an objective can jeopardize the current tracking performance, and this can potentially be alleviated by instead limiting the switching frequency. To this end, we propose to limit the switching frequency in finite control set model predictive control. The switching frequency is captured with an infinite impulse response filter and bounded by an inequality constraint; its corresponding slack variable is penalized in the cost function. To solve the resulting problem efficiently, a sphere decoder with a computational speed-up is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05916v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca M. Hartmann, Orcun Karaca, Tinus Dorfling, Tobias Geyer</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Control for Safe Spacecraft Autonomy: Convex Programming Approach</title>
      <link>https://arxiv.org/abs/2403.04062</link>
      <description>arXiv:2403.04062v3 Announce Type: replace 
Abstract: This paper presents a robust path-planning framework for safe spacecraft autonomy under uncertainty and develops a computationally tractable formulation based on convex programming. We utilize chance-constrained control to formulate the problem. It provides a mathematical framework to solve for a sequence of control policies that minimizes a probabilistic cost under probabilistic constraints with a user-defined confidence level (e.g., safety with 99.9% confidence). The framework enables the planner to directly control state distributions under operational uncertainties while ensuring the vehicle safety. This paper rigorously formulates the safe autonomy problem, gathers and extends techniques in literature to accommodate key cost/constraint functions that often arise in spacecraft path planning, and develops a tractable solution method. The presented framework is demonstrated via two representative numerical examples: safe autonomous rendezvous and orbit maintenance in cislunar space, both under uncertainties due to navigation error from Kalman filter, execution error via Gates model, and imperfect force models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04062v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Managing Distributional Ambiguity in Stochastic Optimization through a Statistical Upper Bound Framework</title>
      <link>https://arxiv.org/abs/2403.08966</link>
      <description>arXiv:2403.08966v3 Announce Type: replace 
Abstract: Stochastic optimization is often hampered by distributional ambiguity, where critical probability distributions are poorly characterized or unknown. Addressing this challenge, we introduce a new framework that targets the minimization of a statistical upper bound for the expected value of uncertain objectives, facilitating more statistically robust decision-making. Central to our approach is the Average Percentile Upper Bound (APUB), a novel construct that simultaneously delivers a statistically rigorous upper bound for the population mean and a meaningful risk metric for the sample mean. The integration of APUB into stochastic optimization not only fortifies the process against distributional ambiguity but also reinforces key data-driven decision-making attributes, such as reliability, consistency, and comprehensibility. Notably, APUB-enriched optimization problems feature tractability, with particular advantages in two-stage stochastic optimization with random recourse. Empirical demonstrations on two-stage product mix and multi-product newsvendor benchmark problems reveal the benefit of the APUB optimization framework, in comparison with conventional techniques such as sample average approximation and distributionally robust optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08966v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixin Liu, Jian Hu</dc:creator>
    </item>
    <item>
      <title>Global Convergence of High-Order Regularization Methods with Sums-of-Squares Taylor Models</title>
      <link>https://arxiv.org/abs/2404.03035</link>
      <description>arXiv:2404.03035v2 Announce Type: replace 
Abstract: High-order tensor methods that employ Taylor-based local models (of degree $p\ge 3$) within adaptive regularization frameworks have been recently proposed for both convex and nonconvex optimization problems. They have been shown to have superior, and even optimal, worst-case global convergence rates and local rates compared to Newton's method. Finding rigorous and efficient techniques for minimizing the Taylor polynomial sub-problems remains a challenging aspect for these algorithms. Ahmadi et al. recently introduced a tensor method based on sum-of-squares (SoS) reformulations, so that each Taylor polynomial sub-problem in their approach can be tractably minimized using semidefinite programming (SDP); however, the global convergence and complexity of their method have not been addressed for general nonconvex problems. This paper introduces an algorithmic framework that combines the Sum of Squares (SoS) Taylor model with adaptive regularization techniques for nonconvex smooth optimization problems. Each iteration minimizes an SoS Taylor model, offering a polynomial cost per iteration. For general nonconvex functions, the worst-case evaluation complexity bound is $\mathcal{O}(\epsilon^{-2})$, while for strongly convex functions, an improved evaluation complexity bound of $\mathcal{O}(\epsilon^{-\frac{1}{p}})$ is established. To the best of our knowledge, this is the first global rate analysis for an adaptive regularization algorithm with a tractable high-order sub-problem in nonconvex smooth optimization, opening the way for further improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03035v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenqi Zhu, Coralia Cartis</dc:creator>
    </item>
    <item>
      <title>Simultaneous compensation of input delay and state/input quantization for linear systems via switched predictor feedback</title>
      <link>https://arxiv.org/abs/2404.11194</link>
      <description>arXiv:2404.11194v2 Announce Type: replace 
Abstract: We develop a switched predictor-feedback law, which achieves global asymptotic stabilization of linear systems with input delay and with the plant and actuator states available only in (almost) quantized form. The control design relies on a quantized version of the nominal predictor-feedback law for linear systems, in which quantized measurements of the plant and actuator states enter the predictor state formula. A switching strategy is constructed to dynamically adjust the tunable parameter of the quantizer (in a piecewise constant manner), in order to initially increase the range and subsequently decrease the error of the quantizers. The key element in the proof of global asymptotic stability in the supremum norm of the actuator state is derivation of solutions' estimates combining a backstepping transformation with small-gain and input-to-state stability arguments, for addressing the error due to quantization. We extend this result to the input quantization case and illustrate our theory with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11194v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florent Koudohode, Nikolaos Bekiaris-Liberis</dc:creator>
    </item>
    <item>
      <title>Convergence of Policy Gradient for Stochastic Linear-Quadratic Control Problem in Infinite Horizon</title>
      <link>https://arxiv.org/abs/2404.11382</link>
      <description>arXiv:2404.11382v2 Announce Type: replace 
Abstract: With the outstanding performance of policy gradient (PG) method in the reinforcement learning field, the convergence theory of it has aroused more and more interest recently. Meanwhile, the significant importance and abundant theoretical researches make the stochastic linear quadratic (SLQ) control problem a starting point for studying PG in model-based learning setting. In this paper, we study the PG method for the SLQ problem in infinite horizon and take a step towards providing rigorous guarantees for gradient methods. Although the cost functional of linear-quadratic problem is typically nonconvex, we still overcome the difficulty based on gradient domination condition and L-smoothness property, and prove exponential/linear convergence of gradient flow/descent algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11382v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinpei Zhang, Guangyan Jia</dc:creator>
    </item>
    <item>
      <title>Learning time-scales in two-layers neural networks</title>
      <link>https://arxiv.org/abs/2303.00055</link>
      <description>arXiv:2303.00055v3 Announce Type: replace-cross 
Abstract: Gradient-based learning in multi-layer neural networks displays a number of striking features. In particular, the decrease rate of empirical risk is non-monotone even after averaging over large batches. Long plateaus in which one observes barely any progress alternate with intervals of rapid decrease. These successive phases of learning often take place on very different time scales. Finally, models learnt in an early phase are typically `simpler' or `easier to learn' although in a way that is difficult to formalize.
  Although theoretical explanations of these phenomena have been put forward, each of them captures at best certain specific regimes. In this paper, we study the gradient flow dynamics of a wide two-layer neural network in high-dimension, when data are distributed according to a single-index model (i.e., the target function depends on a one-dimensional projection of the covariates). Based on a mixture of new rigorous results, non-rigorous mathematical derivations, and numerical simulations, we propose a scenario for the learning dynamics in this setting. In particular, the proposed evolution exhibits separation of timescales and intermittency. These behaviors arise naturally because the population gradient flow can be recast as a singularly perturbed dynamical system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00055v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rapha\"el Berthier, Andrea Montanari, Kangjie Zhou</dc:creator>
    </item>
    <item>
      <title>Towards optimal sensor placement for inverse problems in spaces of measures</title>
      <link>https://arxiv.org/abs/2308.01055</link>
      <description>arXiv:2308.01055v2 Announce Type: replace-cross 
Abstract: The objective of this work is to quantify the reconstruction error in sparse inverse problems with measures and stochastic noise, motivated by optimal sensor placement. To be useful in this context, the error quantities must be explicit in the sensor configuration and robust with respect to the source, yet relatively easy to compute in practice, compared to a direct evaluation of the error by a large number of samples. In particular, we consider the identification of a measure consisting of an unknown linear combination of point sources from a finite number of measurements contaminated by Gaussian noise. The statistical framework for recovery relies on two main ingredients: first, a convex but non-smooth variational Tikhonov point estimator over the space of Radon measures and, second, a suitable mean-squared error based on its Hellinger-Kantorovich distance to the ground truth. To quantify the error, we employ a non-degenerate source condition as well as careful linearization arguments to derive a computable upper bound. This leads to asymptotically sharp error estimates in expectation that are explicit in the sensor configuration. Thus they can be used to estimate the expected reconstruction error for a given sensor configuration and guide the placement of sensors in sparse inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01055v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6420/ad2cf8</arxiv:DOI>
      <arxiv:journal_reference>Inverse Probl. 40.5 (2024) 055007</arxiv:journal_reference>
      <dc:creator>Phuoc-Truong Huynh, Konstantin Pieper, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>Generalized Schr\"odinger Bridge Matching</title>
      <link>https://arxiv.org/abs/2310.02233</link>
      <description>arXiv:2310.02233v2 Announce Type: replace-cross 
Abstract: Modern distribution matching algorithms for training diffusion or flow models directly prescribe the time evolution of the marginal distributions between two boundary distributions. In this work, we consider a generalized distribution matching setup, where these marginals are only implicitly described as a solution to some task-specific objective function. The problem setup, known as the Generalized Schr\"odinger Bridge (GSB), appears prevalently in many scientific areas both within and without machine learning. We propose Generalized Schr\"odinger Bridge Matching (GSBM), a new matching algorithm inspired by recent advances, generalizing them beyond kinetic energy minimization and to account for task-specific state costs. We show that such a generalization can be cast as solving conditional stochastic optimal control, for which efficient variational approximations can be used, and further debiased with the aid of path integral theory. Compared to prior methods for solving GSB problems, our GSBM algorithm better preserves a feasible transport map between the boundary distributions throughout training, thereby enabling stable convergence and significantly improved scalability. We empirically validate our claims on an extensive suite of experimental setups, including crowd navigation, opinion depolarization, LiDAR manifolds, and image domain transfer. Our work brings new algorithmic opportunities for training diffusion models enhanced with task-specific optimality structures. Code available at https://github.com/facebookresearch/generalized-schrodinger-bridge-matching</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02233v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guan-Horng Liu, Yaron Lipman, Maximilian Nickel, Brian Karrer, Evangelos A. Theodorou, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise</title>
      <link>https://arxiv.org/abs/2310.18784</link>
      <description>arXiv:2310.18784v4 Announce Type: replace-cross 
Abstract: We study high-probability convergence guarantees of learning on streaming data in the presence of heavy-tailed noise. In the proposed scenario, the model is updated in an online fashion, as new information is observed, without storing any additional data. To combat the heavy-tailed noise, we consider a general framework of nonlinear stochastic gradient descent (SGD), providing several strong results. First, for non-convex costs and component-wise nonlinearities, we establish a convergence rate arbitrarily close to $\mathcal{O}\left(t^{-\frac{1}{4}}\right)$, whose exponent is independent of noise and problem parameters. Second, for strongly convex costs and a broader class of nonlinearities, we establish convergence of the last iterate to the optimum, with a rate $\mathcal{O}\left(t^{-\zeta} \right)$, where $\zeta \in (0,1)$ depends on problem parameters, noise and nonlinearity. As we show analytically and numerically, $\zeta$ can be used to inform the preferred choice of nonlinearity for given problem settings. Compared to state-of-the-art, who only consider clipping, require bounded noise moments of order $\eta \in (1,2]$, and establish convergence rates whose exponents go to zero as $\eta \rightarrow 1$, we provide high-probability guarantees for a much broader class of nonlinearities and symmetric density noise, with convergence rates whose exponents are bounded away from zero, even when the noise has finite first moment only. Moreover, in the case of strongly convex functions, we demonstrate analytically and numerically that clipping is not always the optimal nonlinearity, further underlining the value of our general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18784v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Pranay Sharma, Gauri Joshi, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Geometric Data-Driven Dimensionality Reduction in MPC with Guarantees</title>
      <link>https://arxiv.org/abs/2312.02734</link>
      <description>arXiv:2312.02734v2 Announce Type: replace-cross 
Abstract: We address the challenge of dimension reduction in the discrete-time optimal control problem which is solved repeatedly online within the framework of model predictive control. Our study demonstrates that a reduced-order approach, aimed at identifying a suboptimal solution within a low-dimensional subspace, retains the stability and recursive feasibility characteristics of the original problem. We present a necessary and sufficient condition for ensuring initial feasibility, which is seamlessly integrated into the subspace design process. Additionally, we employ techniques from optimization on Riemannian manifolds to develop a subspace that efficiently represents a collection of pre-specified high-dimensional data points, all while adhering to the initial admissibility constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02734v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roland Schurig, Andreas Himmel, Rolf Findeisen</dc:creator>
    </item>
    <item>
      <title>A necessary condition for non-monotonic dose response, with an application to a kinetic proofreading model -- Extended version</title>
      <link>https://arxiv.org/abs/2403.13862</link>
      <description>arXiv:2403.13862v2 Announce Type: replace-cross 
Abstract: Steady state non-monotonic ("biphasic") dose responses are often observed in experimental biology, which raises the control-theoretic question of identifying which possible mechanisms might underlie such behaviors. It is well known that the presence of an incoherent feedforward loop (IFFL) in a network may give rise to a non-monotonic response. It has been conjectured that this condition is also necessary, i.e. that a non-monotonic response implies the existence of an IFFL. In this paper, we show that this conjecture is false, and in the process prove a weaker version: that either an IFFL must exist or both a positive loop and a negative feedback loop must exist. Towards this aim, we give necessary and sufficient conditions for when minors of a symbolic matrix have mixed signs. Finally, we study in full generality when a model of immune T-cell activation could exhibit a steady state non-monotonic dose response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13862v2</guid>
      <category>q-bio.MN</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Polly Y. Yu, Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>Low Frequency Sampling in Model Predictive Path Integral Control</title>
      <link>https://arxiv.org/abs/2404.03094</link>
      <description>arXiv:2404.03094v2 Announce Type: replace-cross 
Abstract: Sampling-based model-predictive controllers have become a powerful optimization tool for planning and control problems in various challenging environments. In this paper, we show how the default choice of uncorrelated Gaussian distributions can be improved upon with the use of a colored noise distribution. Our choice of distribution allows for the emphasis on low frequency control signals, which can result in smoother and more exploratory samples. We use this frequency-based sampling distribution with Model Predictive Path Integral (MPPI) in both hardware and simulation experiments to show better or equal performance on systems with various speeds of input response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03094v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LRA.2024.3382530</arxiv:DOI>
      <arxiv:journal_reference>IEEE Robotics and Automation Letters, vol. 9, no. 5, pp.4543-4550, 2024</arxiv:journal_reference>
      <dc:creator>Bogdan Vlahov, Jason Gibson, David D. Fan, Patrick Spieler, Ali-akbar Agha-mohammadi, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Nonnegative tensor train for the multicomponent Smoluchowski equation</title>
      <link>https://arxiv.org/abs/2404.10898</link>
      <description>arXiv:2404.10898v2 Announce Type: replace-cross 
Abstract: We propose an efficient implementation of the numerical tensor-train (TT) based algorithm solving the multicomponent coagulation equation preserving the nonnegativeness of solution. Unnatural negative elements in the constructed approximation arise due to the errors of the low-rank decomposition and discretization scheme. In this work, we propose to apply the rank-one corrections in the TT-format proportional to the minimal negative element. Such an element can be found via application of the global optimization methods that can be fully implemented within efficient operations in the tensor train format. We incorporate this trick into the time-integration scheme for the multicomponent coagulation equation and also use it for post-processing of the stationary solution for the problem with the source of particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10898v2</guid>
      <category>math.NA</category>
      <category>cond-mat.soft</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey A. Matveev, Ilya Tretyak</dc:creator>
    </item>
    <item>
      <title>It\=o and It\=o-Wentzell chain rule for flows of conditional laws of continuous semimartingales: an easy approach</title>
      <link>https://arxiv.org/abs/2404.11010</link>
      <description>arXiv:2404.11010v2 Announce Type: replace-cross 
Abstract: We provide a general It\=o\,-Wentzell formula for a random field of maps on the Wasserstein space of probability measures, defined by continuous semimartingales, and evaluated along the flow of conditional distributions of another continuous semimartingale. Our method follows standard arguments of It\=o calculus, and thus bypasses the approximation by empirical measures commonly used in the existing literature. As an application, we derive the dynamic programming equation for a mean field stochastic control problem with common noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11010v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Assil Fadle, Nizar Touzi</dc:creator>
    </item>
  </channel>
</rss>
