<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Dec 2025 05:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Neuromodulation-inspired gated associative memory networks:extended memory retrieval and emergent multistability</title>
      <link>https://arxiv.org/abs/2512.13859</link>
      <description>arXiv:2512.13859v1 Announce Type: new 
Abstract: Classical autoassociative memory models have been central to understanding emergent computations in recurrent neural circuits across diverse biological contexts. However, they typically neglect neuromodulatory agents that are known to strongly shape memory capacity and stability. Here we introduce a minimal, biophysically motivated associative memory network where neuropeptide-like signals are modeled by a self-adaptive, activity-dependent gating mechanism. Using many-body simulations and dynamical mean-field theory, we show that such gating fundamentally reorganizes the attractor structure: the network bypasses the classical spin-glass transition, maintaining robust, high-overlap retrieval far beyond the standard critical capacity, without shrinking basins of attraction. Mechanistically, the gate stabilizes transient ghost remnants of stored patterns even far above the Hopfield limit, converting them into multistable attractors. These results demonstrate that neuromodulation-like gating alone can dramatically enhance associative memory capacity, eliminate the sharp Hopfield-style catastrophic breakdown, and reshape the memory landscape, providing a simple, general route to richer memory dynamics and computational capabilities in neuromodulated circuits and neuromorphic architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13859v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Goto, Hector Manuel Lopez Rios, Monika Scholz, Suriyanarayanan Vaikuntanathan</dc:creator>
    </item>
    <item>
      <title>Forecasting Excessive Anesthesia Depth Using EEG {\alpha}-Spindle Dynamics and Machine Learning</title>
      <link>https://arxiv.org/abs/2512.14160</link>
      <description>arXiv:2512.14160v1 Announce Type: new 
Abstract: Objectives. Accurately predicting transitions to anesthetic drugs overdosage is a critical challenge in general anesthesia as it requires the identification of EEG indicators relevant for anticipating the evolution of the depth of anesthesia. Methods. In this study, we introduce a real-time, data-driven framework based on alpha spindle dynamics extracted from frontal EEG recordings. Using Empirical Mode Decomposition, we segment transient alpha spindle events and extract statistical features such as amplitude, duration, frequency, and suppression intervals. We apply these features to train a Light Gradient Boosting Machine, LGBM, classifier on a clinical EEG dataset spanning induction, maintenance, and emergence phases of general anesthesia. Results. Our model accurately classifies anesthesia phases with over 80 percent accuracy and anticipates the onset of isoelectric suppression, a marker of anesthetic drugs overdosage, with 96 percent accuracy up to 90 seconds in advance. Conclusion. The spindle-based metrics provides a non-invasive, interpretable, and predictive approach. This real-time method can be used to forecast unintentional anesthetic drugs overdosage, enabling proactive anesthesia management based solely on EEG signals. Significance. This new method is the first to provide a way to prevent too deep anesthesia and its consequence for the well-being of patients after the recovery from anesthesia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14160v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christophe Sun, Pierre-Olivier Michel, Fran\c{c}ois David, Nathalie Rouach, Dan Longrois, David Holcman</dc:creator>
    </item>
    <item>
      <title>Temporal interference stimulation for deep brain neuromodulation in humans</title>
      <link>https://arxiv.org/abs/2512.14359</link>
      <description>arXiv:2512.14359v1 Announce Type: new 
Abstract: For decades, focal non-invasive neuromodulation of deep brain regions has not been possible because of the steep depth-focality trade-off of conventional non-invasive brain stimulation (NIBS) techniques, such as transcranial magnetic stimulation (TMS) or classical transcranial electric stimulation (tES). Deep brain stimulation has therefore largely relied on invasive approaches in clinical populations, requiring surgery. Transcranial Temporal Interference Stimulation (tTIS) has recently emerged as a promising method to overcome this challenge and allows for the first time focal non-invasive electrical deep brain stimulation. The method, which was first validated through computational modeling and rodent work, has now been successfully translated to humans to target deep brain regions such as the hippocampus or striatum. In this Perspective, we present current evidence for tTIS-based neuromodulation, underlying mechanisms and discuss future developments of this promising technology. More specifically, we highlight key opportunities and challenges for fundamental neuroscience as well as for the design of new interventions in neuropsychiatric disorders. We also discuss the status of understanding and challenges regarding the basic mechanisms of action of tTIS and possible lines of technological innovation to optimize stimulation, in particular in terms of intensity and focality. Overall, we suggest that following the first proof-of-concepts, an important multidisciplinary research effort is now required to further validate the use of tTIS in multiple applications, understand its underlying principles and optimize the technology in the view of a wider scientific and clinical deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14359v1</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pierre Vassiliadis, Elena Beanato, Maximilian J. Wessel, Friedhelm C. Hummel</dc:creator>
    </item>
    <item>
      <title>Graph AI generates neurological hypotheses validated in molecular, organoid, and clinical systems</title>
      <link>https://arxiv.org/abs/2512.13724</link>
      <description>arXiv:2512.13724v1 Announce Type: cross 
Abstract: Neurological diseases are the leading global cause of disability, yet most lack disease-modifying treatments. We present PROTON, a heterogeneous graph transformer that generates testable hypotheses across molecular, organoid, and clinical systems. To evaluate PROTON, we apply it to Parkinson's disease (PD), bipolar disorder (BD), and Alzheimer's disease (AD). In PD, PROTON linked genetic risk loci to genes essential for dopaminergic neuron survival and predicted pesticides toxic to patient-derived neurons, including the insecticide endosulfan, which ranked within the top 1.29% of predictions. In silico screens performed by PROTON reproduced six genome-wide $\alpha$-synuclein experiments, including a split-ubiquitin yeast two-hybrid system (normalized enrichment score [NES] = 2.30, FDR-adjusted $p &lt; 1 \times 10^{-4}$), an ascorbate peroxidase proximity labeling assay (NES = 2.16, FDR $&lt; 1 \times 10^{-4}$), and a high-depth targeted exome sequencing study in 496 synucleinopathy patients (NES = 2.13, FDR $&lt; 1 \times 10^{-4}$). In BD, PROTON predicted calcitriol as a candidate drug that reversed proteomic alterations observed in cortical organoids derived from BD patients. In AD, we evaluated PROTON predictions in health records from $n = 610,524$ patients at Mass General Brigham, confirming that five PROTON-predicted drugs were associated with reduced seven-year dementia risk (minimum hazard ratio = 0.63, 95% CI: 0.53-0.75, $p &lt; 1 \times 10^{-7}$). PROTON generated neurological hypotheses that were evaluated across molecular, organoid, and clinical systems, defining a path for AI-driven discovery in neurological disease.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13724v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayush Noori, Joaqu\'in Polonuer, Katharina Meyer, Bogdan Budnik, Shad Morton, Xinyuan Wang, Sumaiya Nazeen, Yingnan He, I\~naki Arango, Lucas Vittor, Matthew Woodworth, Richard C. Krolewski, Michelle M. Li, Ninning Liu, Tushar Kamath, Evan Macosko, Dylan Ritter, Jalwa Afroz, Alexander B. H. Henderson, Lorenz Studer, Samuel G. Rodriques, Andrew White, Noa Dagan, David A. Clifton, George M. Church, Sudeshna Das, Jenny M. Tam, Vikram Khurana, Marinka Zitnik</dc:creator>
    </item>
    <item>
      <title>Linguists should learn to love speech-based deep learning models</title>
      <link>https://arxiv.org/abs/2512.14506</link>
      <description>arXiv:2512.14506v1 Announce Type: cross 
Abstract: Futrell and Mahowald present a useful framework bridging technology-oriented deep learning systems and explanation-oriented linguistic theories. Unfortunately, the target article's focus on generative text-based LLMs fundamentally limits fruitful interactions with linguistics, as many interesting questions on human language fall outside what is captured by written text. We argue that audio-based deep learning models can and should play a crucial role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14506v1</guid>
      <category>cs.CL</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marianne de Heer Kloots, Paul Boersma, Willem Zuidema</dc:creator>
    </item>
    <item>
      <title>Arbor-TVB: A Novel Multi-Scale Co-Simulation Framework with a Case Study on Neural-Level Seizure Generation and Whole-Brain Propagation</title>
      <link>https://arxiv.org/abs/2505.16861</link>
      <description>arXiv:2505.16861v2 Announce Type: replace 
Abstract: Computational neuroscience has traditionally focused on isolated scales, limiting understanding of brain function across multiple levels. While microscopic models capture biophysical details of neurons, macroscopic models describe large-scale network dynamics. Integrating these scales, however, remains a significant challenge. In this study, we present a novel co-simulation framework that bridges these levels by integrating the neural simulator Arbor with The Virtual Brain (TVB) platform. Arbor enables detailed simulations from single-compartment neurons to populations of such cells, while TVB models whole-brain dynamics based on anatomical features and the mean neural activity of a brain region. By linking these simulators for the first time, we provide an example of how to model and investigate the onset of seizures in specific areas and their propagation to the whole brain. This framework employs an MPI intercommunicator for real-time bidirectional interaction, translating between discrete spikes from Arbor and continuous TVB activity. Its fully modular design enables independent model selection for each scale, requiring minimal effort to translate activity across simulators. The novel Arbor-TVB co-simulator allows replacement of TVB nodes with biologically realistic neuron populations, offering insights into seizure propagation and potential intervention strategies. The integration of Arbor and TVB marks a significant advancement in multi-scale modeling, providing a comprehensive computational framework for studying neural disorders and optimizing treatments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16861v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thorsten Hater, Juliette Courson, Han Lu, Sandra Diaz-Pier, Thanos Manos</dc:creator>
    </item>
    <item>
      <title>Developmental Symmetry-Loss: A Free-Energy Perspective on Brain-Inspired Invariance Learning</title>
      <link>https://arxiv.org/abs/2512.10984</link>
      <description>arXiv:2512.10984v2 Announce Type: replace 
Abstract: We propose Symmetry-Loss, a brain-inspired algorithmic principle that enforces invariance and equivariance through a differentiable constraint derived from environmental symmetries. The framework models learning as the iterative refinement of an effective symmetry group, paralleling developmental processes in which cortical representations align with the world's structure. By minimizing structural surprise, i.e. deviations from symmetry consistency, Symmetry-Loss operationalizes a Free-Energy--like objective for representation learning. This formulation bridges predictive-coding and group-theoretic perspectives, showing how efficient, stable, and compositional representations can emerge from symmetry-based self-organization. The result is a general computational mechanism linking developmental learning in the brain with principled representation learning in artificial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10984v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>nlin.AO</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arif D\"onmez</dc:creator>
    </item>
  </channel>
</rss>
