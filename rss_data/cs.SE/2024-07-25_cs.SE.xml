<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 01:39:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Architectural Tactics to Improve the Environmental Sustainability of Microservices: A Rapid Review</title>
      <link>https://arxiv.org/abs/2407.16706</link>
      <description>arXiv:2407.16706v1 Announce Type: new 
Abstract: Microservices are a popular architectural style adopted by the industry when it comes to deploying software that requires scalability, maintainability, and agile development. There is an increasing demand for improving the sustainability of microservice systems in the industry. This rapid review gathers 22 peer-reviewed studies and synthesizes architectural tactics that improve the environmental sustainability of microservices from them. We list 6 tactics that are presented in an actionable way and categorized according to their sustainability aspects and context. The sustainability aspects include energy efficiency, carbon efficiency, and resource efficiency, among which resource efficiency is the most researched one while energy efficiency and carbon efficiency are still in the early stage of study. The context categorization, including serverless platforms, decentralized networks, etc., helps to identify the tactics that we can use in a specific setting. Additionally, we present how the evidence of optimization after adopting these tactics is presented, like the measurement unit and statistical methods, and how experiments are generally set up so that this review is both instructive for our future study and our industrial practitioners' interest. We further study the insufficiencies of the current study and hope to provide insight for other researchers and the industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16706v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xingwen Xiao</dc:creator>
    </item>
    <item>
      <title>Benchmarks as Microscopes: A Call for Model Metrology</title>
      <link>https://arxiv.org/abs/2407.16711</link>
      <description>arXiv:2407.16711v1 Announce Type: new 
Abstract: Modern language models (LMs) pose a new challenge in capability assessment. Static benchmarks inevitably saturate without providing confidence in the deployment tolerances of LM-based systems, but developers nonetheless claim that their models have generalized traits such as reasoning or open-domain language understanding based on these flawed metrics. The science and practice of LMs requires a new approach to benchmarking which measures specific capabilities with dynamic assessments. To be confident in our metrics, we need a new discipline of model metrology -- one which focuses on how to generate benchmarks that predict performance under deployment. Motivated by our evaluation criteria, we outline how building a community of model metrology practitioners -- one focused on building tools and studying how to measure system capabilities -- is the best way to meet these needs to and add clarity to the AI discussion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16711v1</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Saxon, Ari Holtzman, Peter West, William Yang Wang, Naomi Saphra</dc:creator>
    </item>
    <item>
      <title>Container Morphisms for Composable Interactive Systems</title>
      <link>https://arxiv.org/abs/2407.16713</link>
      <description>arXiv:2407.16713v1 Announce Type: new 
Abstract: This paper provides a mathematical framework for client-server communication that results in a modular and type-safe architecture. It is informed and motivated by the software engineering practice of developing server backends with a database layer and a frontend, all of which communicate with a notion of request/response. I make use of dependent types to ensure the request/response relation matches and show how this idea fits in the broader context of containers and their morphisms. Using the category of containers and their monoidal products, I define monads on containers that mimic their functional programming counterparts, and using the Kleene star, I describe stateful protocols in the same system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16713v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'e Videla</dc:creator>
    </item>
    <item>
      <title>PyBench: Evaluating LLM Agent on various real-world coding tasks</title>
      <link>https://arxiv.org/abs/2407.16732</link>
      <description>arXiv:2407.16732v1 Announce Type: new 
Abstract: The LLM Agent, equipped with a code interpreter, is capable of automatically solving real-world coding tasks, such as data analysis and image editing.
  However, existing benchmarks primarily focus on either simplistic tasks, such as completing a few lines of code, or on extremely complex and specific tasks at the repository level, neither of which are representative of various daily coding tasks.
  To address this gap, we introduce \textbf{PyBench}, a benchmark encompassing five main categories of real-world tasks, covering more than 10 types of files. Given a high-level user query and related files, the LLM Agent needs to reason and execute Python code via a code interpreter for a few turns before making a formal response to fulfill the user's requirements. Successfully addressing tasks in PyBench demands a robust understanding of various Python packages, superior reasoning capabilities, and the ability to incorporate feedback from executed code. Our evaluations indicate that current open-source LLMs are struggling with these tasks. Hence, we conduct analysis and experiments on four kinds of datasets proving that comprehensive abilities are needed for PyBench. Our fine-tuned 8B size model: \textbf{PyLlama3} achieves an exciting performance on PyBench which surpasses many 33B and 70B size models. Our Benchmark, Training Dataset, and Model are available at: \href{https://github.com/Mercury7353/PyBench}{https://github.com/Mercury7353/PyBench}</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16732v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaolun Zhang, Yinxu Pan, Yudong Wang, Jie Cai, Zhi Zheng, Guoyang Zeng, Zhiyuan Liu</dc:creator>
    </item>
    <item>
      <title>OpenDevin: An Open Platform for AI Software Developers as Generalist Agents</title>
      <link>https://arxiv.org/abs/2407.16741</link>
      <description>arXiv:2407.16741v1 Announce Type: new 
Abstract: Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. In this paper, we introduce OpenDevin, a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to those of a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 15 challenging tasks, including software engineering (e.g., SWE-Bench) and web browsing (e.g., WebArena), among others. Released under the permissive MIT license, OpenDevin is a community project spanning academia and industry with more than 1.3K contributions from over 160 contributors and will improve going forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16741v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, Graham Neubig</dc:creator>
    </item>
    <item>
      <title>Path-optimal symbolic execution of heap-manipulating programs</title>
      <link>https://arxiv.org/abs/2407.16827</link>
      <description>arXiv:2407.16827v1 Announce Type: new 
Abstract: Symbolic execution is at the core of many techniques for program analysis and test generation. Traditional symbolic execution of programs with numeric inputs enjoys the property of forking as many analysis traces as the number of analyzed program paths, a property that in this paper we refer to as path optimality. On the contrary, current approaches for symbolic execution of heap-manipulating programs fail to satisfy this property, thereby incurring heavy path explosion effects that crucially penalize the efficiency of the analysis. This paper introduces POSE, path-optimal symbolic execution, a symbolic execution algorithm that originally accomplishes path optimality against heap-manipulating programs. We formalize the POSE algorithm for a tiny, but representative object-oriented programming language, and implement the formalization into a prototype symbolic executor to experiment the algorithm against a benchmark of sample programs that take data structures as inputs. Our experiments provide initial empirical evidence of the potential of POSE for improving on the state of the art of symbolic execution of heap-manipulating programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16827v1</guid>
      <category>cs.SE</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pietro Braione, Giovanni Denaro</dc:creator>
    </item>
    <item>
      <title>Fostering Microservice Maintainability Assurance through a Comprehensive Framework</title>
      <link>https://arxiv.org/abs/2407.16873</link>
      <description>arXiv:2407.16873v1 Announce Type: new 
Abstract: Cloud-native systems represent a significant leap in constructing scalable, large systems, employing microservice architecture as a key element in developing distributed systems through self-contained components. However, the decentralized nature of these systems, characterized by separate source codes and deployments, introduces challenges in assessing system qualities. Microservice-based systems, with their inherent complexity and the need for coordinated changes across multiple microservices, lack established best practices and guidelines, leading to difficulties in constructing and comprehending the holistic system view. This gap can result in performance degradation and increased maintenance costs, potentially requiring system refactoring. The main goal of this project is to offer maintainability assurance for microservice practitioners. It introduces an automated assessment framework tailored to microservice architecture, enhancing practitioners' understanding and analytical capabilities of the multiple system perspectives. The framework addresses various granularity levels, from artifacts to constructing holistic views of static and dynamic system characteristics. It integrates diverse perspectives, encompassing human-centric elements like architectural visualization and automated evaluations, including coupling detection, testing coverage measurement, and semantic clone identification. Validation studies involving practitioners demonstrate the framework's effectiveness in addressing diverse quality and maintainability issues, revealing insights not apparent when analyzing individual microservices in isolation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16873v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amr S. Abdelfattah</dc:creator>
    </item>
    <item>
      <title>Automatic Categorization of GitHub Actions with Transformers and Few-shot Learning</title>
      <link>https://arxiv.org/abs/2407.16946</link>
      <description>arXiv:2407.16946v1 Announce Type: new 
Abstract: In the GitHub ecosystem, workflows are used as an effective means to automate development tasks and to set up a Continuous Integration and Delivery (CI/CD pipeline). GitHub Actions (GHA) have been conceived to provide developers with a practical tool to create and maintain workflows, avoiding reinventing the wheel and cluttering the workflow with shell commands. Properly leveraging the power of GitHub Actions can facilitate the development processes, enhance collaboration, and significantly impact project outcomes. To expose actions to search engines, GitHub allows developers to assign them to one or more categories manually. These are used as an effective means to group actions sharing similar functionality. Nevertheless, while providing a practical way to execute workflows, many actions have unclear purposes, and sometimes they are not categorized. In this work, we bridge such a gap by conceptualizing Gavel, a practical solution to increasing the visibility of actions in GitHub. By leveraging the content of README.MD files for each action, we use Transformer--a deep learning algorithm--to assign suitable categories to the action. We conducted an empirical investigation and compared Gavel with a state-of-the-art baseline. The experimental results show that our proposed approach can assign categories to GitHub actions effectively, thus outperforming the state-of-the-art baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16946v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Phuong T. Nguyen, Juri Di Rocco, Claudio Di Sipio, Mudita Shakya, Davide Di Ruscio, Massimiliano Di Penta</dc:creator>
    </item>
    <item>
      <title>SelfPiCo: Self-Guided Partial Code Execution with LLMs</title>
      <link>https://arxiv.org/abs/2407.16974</link>
      <description>arXiv:2407.16974v1 Announce Type: new 
Abstract: Code executability plays a vital role in software debugging and testing (e.g., detecting runtime exceptions or assertion violations). However, code execution, especially partial or arbitrary code execution, is a non-trivial task due to missing definitions and complex third-party dependencies. To make partial code (such as code snippets posted on the web or code fragments deep inside complex software projects) executable, the existing study has proposed a machine learning model to predict the undefined element types and inject the pre-defined dummy values into execution. However, the performance of their tool is limited due to its simply designed dummy values and the inability to continue learning. In this paper, we design and implement a novel framework, named SelfPiCo (Self Guided Partial Code Executor), to dynamically guide partial code execution by incorporating the open-source LLM (i.e., Code Llama) within an interactive loop. Particularly, SelfPiCo leverages few-shot in-context learning and chain-of-thought reasoning to elicit human knowledge and logical reasoning based on fine-tuning the Code Llama model. SelfPiCo continuously learns from code execution results and refines its predictions step after step. Our evaluations demonstrate that SelfPiCo can execute 72.7% and 83.3% of all lines in the open-source code and Stack Overflow snippets, outperforming the most recent state-of-the-art Lexecutor by 37.9% and 33.5%, respectively. Moreover, SelfPiCo successfully detected 18 and 33 runtime type error issues by executing the partial code from eight GitHub software projects and 43 Stack Overflow posts, demonstrating the practical usage and potential application of our framework in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16974v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhipeng Xue, Zhipeng Gao, Shaohua Wang, Xing Hu, Xin Xia, Shanping Li</dc:creator>
    </item>
    <item>
      <title>Cultural influence on RE activities: An extended analysis of state of the art</title>
      <link>https://arxiv.org/abs/2407.17038</link>
      <description>arXiv:2407.17038v1 Announce Type: new 
Abstract: Designing mobile software that aligns with cultural contexts is crucial for optimizing human-computer interaction. Considering cultural influences is essential not only for the actual set of functional/non-functional requirements, but also for the whole Requirement Engineering (RE) process. Without a clear understanding of cultural influences on RE activities, it's hardly possible to elaborate a correct and complete set of requirements. This research explores the impact of national culture on RE-related activities based on recent studies. We conducted a Systematic Literature Review (SLR) of studies published in 2019-2023 and compared them to an older SLR covering 2000-2018. We identified 17 relevant studies, extracted 33 cultural influences impacting RE activities, and mapped them to the Hofstede model, widely used for cultural analysis in software development research. Our work highlights the critical role of national culture in RE activities, summarizes current research trends, and helps practitioners consider cultural influences for mobile app/software development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17038v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3640471.3680236</arxiv:DOI>
      <dc:creator>Chowdhury Shahriar Muzammel, Maria Spichkova, James Harland</dc:creator>
    </item>
    <item>
      <title>Automated Code-centric Software Vulnerability Assessment: How Far Are We? An Empirical Study in C/C++</title>
      <link>https://arxiv.org/abs/2407.17053</link>
      <description>arXiv:2407.17053v2 Announce Type: new 
Abstract: Background: The C and C++ languages hold significant importance in Software Engineering research because of their widespread use in practice. Numerous studies have utilized Machine Learning (ML) and Deep Learning (DL) techniques to detect software vulnerabilities (SVs) in the source code written in these languages. However, the application of these techniques in function-level SV assessment has been largely unexplored. SV assessment is increasingly crucial as it provides detailed information on the exploitability, impacts, and severity of security defects, thereby aiding in their prioritization and remediation. Aims: We conduct the first empirical study to investigate and compare the performance of ML and DL models, many of which have been used for SV detection, for function-level SV assessment in C/C++. Method: Using 9,993 vulnerable C/C++ functions, we evaluated the performance of six multi-class ML models and five multi-class DL models for the SV assessment at the function level based on the Common Vulnerability Scoring System (CVSS). We further explore multi-task learning, which can leverage common vulnerable code to predict all SV assessment outputs simultaneously in a single model, and compare the effectiveness and efficiency of this model type with those of the original multi-class models. Results: We show that ML has matching or even better performance compared to the multi-class DL models for function-level SV assessment with significantly less training time. Employing multi-task learning allows the DL models to perform significantly better, with an average of 8-22% increase in Matthews Correlation Coefficient (MCC). Conclusions: We distill the practices of using data-driven techniques for function-level SV assessment in C/C++, including the use of multi-task DL to balance efficiency and effectiveness. This can establish a strong foundation for future work in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17053v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anh The Nguyen, Triet Huynh Minh Le, M. Ali Babar</dc:creator>
    </item>
    <item>
      <title>PatchFinder: A Two-Phase Approach to Security Patch Tracing for Disclosed Vulnerabilities in Open-Source Software</title>
      <link>https://arxiv.org/abs/2407.17065</link>
      <description>arXiv:2407.17065v1 Announce Type: new 
Abstract: Open-source software (OSS) vulnerabilities are increasingly prevalent, emphasizing the importance of security patches. However, in widely used security platforms like NVD, a substantial number of CVE records still lack trace links to patches. Although rank-based approaches have been proposed for security patch tracing, they heavily rely on handcrafted features in a single-step framework, which limits their effectiveness. In this paper, we propose PatchFinder, a two-phase framework with end-to-end correlation learning for better-tracing security patches. In the **initial retrieval** phase, we employ a hybrid patch retriever to account for both lexical and semantic matching based on the code changes and the description of a CVE, to narrow down the search space by extracting those commits as candidates that are similar to the CVE descriptions. Afterwards, in the **re-ranking** phase, we design an end-to-end architecture under the supervised fine-tuning paradigm for learning the semantic correlations between CVE descriptions and commits. In this way, we can automatically rank the candidates based on their correlation scores while maintaining low computation overhead. We evaluated our system against 4,789 CVEs from 532 OSS projects. The results are highly promising: PatchFinder achieves a Recall@10 of 80.63% and a Mean Reciprocal Rank (MRR) of 0.7951. Moreover, the Manual Effort@10 required is curtailed to 2.77, marking a 1.94 times improvement over current leading methods. When applying PatchFinder in practice, we initially identified 533 patch commits and submitted them to the official, 482 of which have been confirmed by CVE Numbering Authorities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17065v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3650212.3680305</arxiv:DOI>
      <dc:creator>Kaixuan Li, Jian Zhang, Sen Chen, Han Liu, Yang Liu, Yixiang Chen</dc:creator>
    </item>
    <item>
      <title>Formalizing UML State Machines for Automated Verification -- A Survey</title>
      <link>https://arxiv.org/abs/2407.17215</link>
      <description>arXiv:2407.17215v1 Announce Type: new 
Abstract: The Unified Modeling Language (UML) is a standard for modeling dynamic systems. UML behavioral state machines are used for modeling the dynamic behavior of object-oriented designs. The UML specification, maintained by the Object Management Group (OMG), is documented in natural language (in contrast to formal language). The inherent ambiguity of natural languages may introduce inconsistencies in the resulting state machine model. Formalizing UML state machine specification aims at solving the ambiguity problem and at providing a uniform view to software designers and developers. Such a formalization also aims at providing a foundation for automatic verification of UML state machine models, which can help to find software design vulnerabilities at an early stage and reduce the development cost. We provide here a comprehensive survey of existing work from 1997 to 2021 related to formalizing UML state machine semantics for the purpose of conducting model checking at the design stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17215v1</guid>
      <category>cs.SE</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3579821</arxiv:DOI>
      <arxiv:journal_reference>ACM Computing Surveys, Volume 55, Issue 13s, Article No.: 277, Pages 1-47, 2023</arxiv:journal_reference>
      <dc:creator>\'Etienne Andr\'e, Shuang Liu, Yang Liu, Christine Choppy, Jun Sun, Jin Song Dong</dc:creator>
    </item>
    <item>
      <title>Ranking Plausible Patches by Historic Feature Frequencies</title>
      <link>https://arxiv.org/abs/2407.17240</link>
      <description>arXiv:2407.17240v1 Announce Type: new 
Abstract: Automated program repair (APR) techniques have achieved conspicuous progress, and are now capable of producing genuinely correct fixes in scenarios that were well beyond their capabilities only a few years ago. Nevertheless, even when an APR technique can find a correct fix for a bug, it still runs the risk of ranking the fix lower than other patches that are plausible (they pass all available tests) but incorrect. This can seriously hurt the technique's practical effectiveness, as the user will have to peruse a larger number of patches before finding the correct one.
  This paper presents PrevaRank, a technique that ranks plausible patches produced by any APR technique according to their feature similarity with historic programmer-written fixes for similar bugs. PrevaRank implements simple heuristics, which help make it scalable and applicable to any APR tool that produces plausible patches. In our experimental evaluation, after training PrevaRank on the fix history of 81 open-source Java projects, we used it to rank patches produced by 8 Java APR tools on 168 Defects4J bugs. PrevaRank consistently improved the ranking of correct fixes: for example, it ranked a correct fix within the top-3 positions in 27% more cases than the original tools did. Other experimental results indicate that PrevaRank works robustly with a variety of APR tools and bugs, with negligible overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17240v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shifat Sahariar Bhuiyan, Abhishek Tiwari, Yu Pei, Carlo A. Furia</dc:creator>
    </item>
    <item>
      <title>Component Matching as a Graph Matching Problem</title>
      <link>https://arxiv.org/abs/2407.17273</link>
      <description>arXiv:2407.17273v1 Announce Type: new 
Abstract: The development of an IT strategy and ensuring that it is the best possible one for business is a key problem many organizations face. This problem is that of linking business architecture to IT architecture in general and application architecture specifically. In our earlier work we proposed Category theory as the formal language to unify the business and IT worlds with the ability to represent the concepts and relations between the two in a unified way. We used rCOS as the underlying model for the specification of interfaces, contracts, and components. The concept of pseudo-category was then utilized to represent the business and application architecture specifications and the relationships contained within. Contracts are used for the specification of both IT and Business architecture components. The linkages between them is now established using the matching of the business component contracts with the application component contracts. Typically, the matching was based on manual process, in this paper we extend the work by considering automated component matching process. In this paper we provide implementation of the matching process using graph matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17273v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Suresh Kamath</dc:creator>
    </item>
    <item>
      <title>Integrating Sustainability Concerns into Agile Software Development Process</title>
      <link>https://arxiv.org/abs/2407.17426</link>
      <description>arXiv:2407.17426v1 Announce Type: new 
Abstract: Software has the potential to be a key driver in fostering sustainability. Despite this potential, it is not clear if and how the software industry integrates consideration of sustainability into its common software development processes. This research starts by investigating the current state of sustainability consideration within the software engineering industry through a survey. The results highlight a lack of progress in practically integrating sustainability considerations into software development activities. To address this gap, a case study with an industry partner is conducted to demonstrate how sustainability concerns and effects can be integrated into agile software development. The findings of this case study demonstrate practical approaches to integrating sustainability into software development practices. Reflecting on the findings from the survey and the case study, we note some insights on scaling up the adoption of sustainability consideration into the daily practice of agile software development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17426v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shola Oyedeji, Ruzanna Chitchyan, Mikhail Ola Adisa, Hatef Shamshiri</dc:creator>
    </item>
    <item>
      <title>Generative AI in Evidence-Based Software Engineering: A White Paper</title>
      <link>https://arxiv.org/abs/2407.17440</link>
      <description>arXiv:2407.17440v1 Announce Type: new 
Abstract: Context. In less than a year practitioners and researchers witnessed a rapid and wide implementation of Generative Artificial Intelligence. The daily availability of new models proposed by practitioners and researchers has enabled quick adoption. Textual GAIs capabilities enable researchers worldwide to explore new generative scenarios simplifying and hastening all timeconsuming text generation and analysis tasks.
  Motivation. The exponentially growing number of publications in our field with the increased accessibility to information due to digital libraries makes conducting systematic literature reviews and mapping studies an effort and timeinsensitive task Stemmed from this challenge we investigated and envisioned the role of GAIs in evidencebased software engineering.
  Future Directions. Based on our current investigation we will follow up the vision with the creation and empirical validation of a comprehensive suite of models to effectively support EBSE researchers</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17440v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mattel Esposito, Andrea Janes, Davide Taibi, Valentina Lenarduzzi</dc:creator>
    </item>
    <item>
      <title>SimCT: A Simple Consistency Test Protocol in LLMs Development Lifecycle</title>
      <link>https://arxiv.org/abs/2407.17150</link>
      <description>arXiv:2407.17150v1 Announce Type: cross 
Abstract: In this work, we report our efforts to advance the standard operation procedure of developing Large Language Models (LLMs) or LLMs-based systems or services in industry. We introduce the concept of Large Language Model Development Lifecycle (LDLC) and then highlight the importance of consistency test in ensuring the delivery quality. The principled solution of consistency test, however, is usually overlooked by industrial practitioners and not urgent in academia, and current practical solutions are insufficiently rigours and labor-intensive. We thus propose a simple yet effective consistency test protocol, named SimCT. SimCT is mainly to proactively check the consistency across different development stages of "bare metal" LLMs or associated services without accessing the model artifacts, in an attempt to expedite the delivery by reducing the back-and-forth alignment communications among multiple teams involved in different development stages.
  Specifically, SimCT encompasses response-wise and model-wise tests. We implement the protocol with LightGBM and Student's t-test for two components respectively, and perform extensive experiments to substantiate the effectiveness of SimCT and the involved components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17150v1</guid>
      <category>cs.CL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fufangchen Zhao, Guoqiang Jin, Rui Zhao, Jiangheng Huang, Fei Tan</dc:creator>
    </item>
    <item>
      <title>Can GitHub Issues Help in App Review Classifications?</title>
      <link>https://arxiv.org/abs/2308.14211</link>
      <description>arXiv:2308.14211v3 Announce Type: replace 
Abstract: App reviews reflect various user requirements that can aid in planning maintenance tasks. Recently, proposed approaches for automatically classifying user reviews rely on machine learning algorithms. A previous study demonstrated that models trained on existing labeled datasets exhibit poor performance when predicting new ones. Therefore, a comprehensive labeled dataset is essential to train a more precise model. In this paper, we propose a novel approach that assists in augmenting labeled datasets by utilizing information extracted from an additional source, GitHub issues, that contains valuable information about user requirements. First, we identify issues concerning review intentions (bug reports, feature requests, and others) by examining the issue labels. Then, we analyze issue bodies and define 19 language patterns for extracting targeted information. Finally, we augment the manually labeled review dataset with a subset of processed issues through the Within-App, Within-Context, and Between-App Analysis methods. We conducted several experiments to evaluate the proposed approach. Our results demonstrate that using labeled issues for data augmentation can improve the F1-score to 6.3 in bug reports and 7.2 in feature requests. Furthermore, we identify an effective range of 0.3 to 0.7 for the auxiliary volume, which provides better performance improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14211v3</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3678170</arxiv:DOI>
      <dc:creator>Yasaman Abedini, Abbas Heydarnoori</dc:creator>
    </item>
    <item>
      <title>Architecture and Applications of IoT Devices in Socially Relevant Fields</title>
      <link>https://arxiv.org/abs/2308.09195</link>
      <description>arXiv:2308.09195v2 Announce Type: replace-cross 
Abstract: Number of IoT enabled devices are being tried and introduced every year and there is a healthy competition among researched and businesses to capitalize the space created by IoT, as these devices have a great market potential. Depending on the type of task involved and sensitive nature of data that the device handles, various IoT architectures, communication protocols and components are chosen and their performance is evaluated. This paper reviews such IoT enabled devices based on their architecture, communication protocols and functions in few key socially relevant fields like health care, farming, firefighting, women/individual safety/call for help/harm alert, home surveillance and mapping as these fields involve majority of the general public. It can be seen, to one's amazement, that already significant number of devices are being reported on these fields and their performance is promising. This paper also outlines the challenges involved in each of these fields that require solutions to make these devices reliable</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09195v2</guid>
      <category>cs.NI</category>
      <category>cs.SE</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Anush Lakshman, S. Akash, J. Cynthia, R. Gautam, D. Ebenezer</dc:creator>
    </item>
  </channel>
</rss>
