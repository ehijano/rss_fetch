<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 02:39:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sorting by Strip Swaps is NP-Hard</title>
      <link>https://arxiv.org/abs/2511.00015</link>
      <description>arXiv:2511.00015v1 Announce Type: new 
Abstract: We show that \emph{Sorting by Strip Swaps} (SbSS) is NP-hard by a polynomial reduction of \emph{Block Sorting}. The key idea is a local gadget, a \emph{cage}, that replaces every decreasing adjacency $(a_i,a_{i+1})$ by a guarded triple $a_i,m_i,a_{i+1}$ enclosed by guards $L_i,U_i$, so the only decreasing adjacencies are the two inside the cage. Small \emph{hinge} gadgets couple adjacent cages that share an element and enforce that a strip swap that removes exactly two adjacencies corresponds bijectively to a block move that removes exactly one decreasing adjacency in the source permutation. This yields a clean equivalence between exact SbSS schedules and perfect block schedules, establishing NP-hardness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00015v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swapnoneel Roy, Asai Asaithambi, Debajyoti Mukhopadhyay</dc:creator>
    </item>
    <item>
      <title>Scheduling Problems with Constrained Rejections</title>
      <link>https://arxiv.org/abs/2511.00184</link>
      <description>arXiv:2511.00184v1 Announce Type: new 
Abstract: We study bicriteria versions of Makespan Minimization on Unrelated Machines and Santa Claus by allowing a constrained number of rejections. Given an instance of Makespan Minimization on Unrelated Machines where the optimal makespan for scheduling $n$ jobs on $m$ unrelated machines is $T$, (Feige and Vondr\'ak, 2006) gave an algorithm that schedules a $(1-1/e+10^{-180})$ fraction of jobs in time $T$. We show the ratio can be improved to $0.6533&gt;1-1/e+0.02$ if we allow makespan $3T/2$. To the best our knowledge, this is the first result examining the tradeoff between makespan and the fraction of scheduled jobs when the makespan is not $T$ or $2T$.
  For the Santa Claus problem (the Max-Min version of Makespan Minimization), the analogous bicriteria objective was studied by (Golovin, 2005), who gave an algorithm providing an allocation so a $(1-1/k)$ fraction of agents receive value at least $T/k$, for any $k \in \mathbb{Z}^+$ and $T$ being the optimal minimum value every agent can receive. We provide the first hardness result by showing there are constants $\delta,\varepsilon&gt;0$ such that it is NP-hard to find an allocation where a $(1-\delta)$ fraction of agents receive value at least $(1-\varepsilon) T$. To prove this hardness result, we introduce a bicriteria version of Set Packing, which may be of independent interest, and prove some algorithmic and hardness results for it. Overall, we believe these bicriteria scheduling problems warrant further study as they provide an interesting lens to understand how robust the difficulty of the original optimization goal might be.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00184v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sami Davies, Venkatesan Guruswami, Xuandi Ren</dc:creator>
    </item>
    <item>
      <title>Uncrossed Multiflows and Applications to Disjoint Paths</title>
      <link>https://arxiv.org/abs/2511.00254</link>
      <description>arXiv:2511.00254v1 Announce Type: new 
Abstract: A multiflow in a planar graph is uncrossed if the curves identified by its support paths do not cross in the plane. Such flows have played a role in previous routing algorithms, including Schrijver's Homotopy Method and unsplittable flows in directed planar single-source instances. Recently uncrossed flows have played a key role in approximation algorithms for maximum disjoint paths in fully-planar instances, where the combined supply plus demand graph is planar. In the fully-planar case, any fractional multiflow can be converted into one that is uncrossed, which is then exploited to find a good rounding of the fractional solution. We investigate finding an uncrossed multiflow as a standalone algorithmic problem in general planar instances (not necessarily fully-planar). We consider both a congestion model where the given demands must all be routed, and a maximization model where the goal is to pack as much flow in the supply graph as possible (not necessarily equitably).
  For the congestion model, we show that determining if an instance has an uncrossed (fractional) multiflow is NP-hard, but the problem of finding an integral uncrossed flow is polytime solvable if the demands span a bounded number of faces. For the maximization model, we present a strong (almost polynomial) inapproximability result. Regarding integrality gaps, for maximization we show that an uncrossed multiflow in a planar instance can always be rounded to an integral multiflow with a constant fraction of the original value. This holds in both the edge-capacitated and node-capacitated settings, and generalizes earlier bounds for fully-planar instances. In the congestion model, given an uncrossed fractional multiflow, we give a rounding procedure that produces an integral multiflow with edge congestion 2, which can be made unsplittable with an additional additive error of the maximum demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00254v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandra Chekuri, Guyslain Naves, Joseph Poremba, F. Bruce Shepherd</dc:creator>
    </item>
    <item>
      <title>An Approximation Algorithm for Monotone Submodular Cost Allocation</title>
      <link>https://arxiv.org/abs/2511.00470</link>
      <description>arXiv:2511.00470v1 Announce Type: new 
Abstract: In this paper, we consider the minimum submodular cost allocation (MSCA) problem. The input of MSCA is $k$ non-negative submodular functions $f_1,\ldots,f_k$ on the ground set $N$ given by evaluation oracles, and the goal is to partition $N$ into $k$ (possibly empty) sets $X_1,\ldots,X_k$ so that $\sum_{i=1}^k f_i(X_i)$ is minimized. In this paper, we focus on the case when $f_1,\ldots,f_k$ are monotone (denoted by Mono-MSCA). We provide a natural LP-relaxation for Mono-MSCA, which is equivalent to the convex program relaxation introduced by Chekuri and Ene. We show that the integrality gap of the LP-relaxation is at most $k/2$, which yields a $k/2$-approximation algorithm for Mono-MSCA. We also show that the integrality gap of the LP-relaxation is at least $k/2-\epsilon$ for any constant $\epsilon&gt;0$ when $k$ is fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00470v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryuhei Mizutani</dc:creator>
    </item>
    <item>
      <title>Fast Stochastic Greedy Algorithm for $k$-Submodular Cover Problem</title>
      <link>https://arxiv.org/abs/2511.00869</link>
      <description>arXiv:2511.00869v1 Announce Type: new 
Abstract: We study the $k$-Submodular Cover ($kSC$) problem, a natural generalization of the classical Submodular Cover problem that arises in artificial intelligence and combinatorial optimization tasks such as influence maximization, resource allocation, and sensor placement. Existing algorithms for $\kSC$ often provide weak approximation guarantees or incur prohibitively high query complexity. To overcome these limitations, we propose a \textit{Fast Stochastic Greedy} algorithm that achieves strong bicriteria approximation while substantially lowering query complexity compared to state-of-the-art methods. Our approach dramatically reduces the number of function evaluations, making it highly scalable and practical for large-scale real-world AI applications where efficiency is essential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00869v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hue T. Nguyen, Tan D. Tran, Nguyen Long Giang, Canh V. Pham</dc:creator>
    </item>
    <item>
      <title>Dynamic Diameter in High-Dimensions against Adaptive Adversary and Beyond</title>
      <link>https://arxiv.org/abs/2511.01065</link>
      <description>arXiv:2511.01065v1 Announce Type: new 
Abstract: In this paper, we study the fundamental problems of maintaining the diameter and a $k$-center clustering of a dynamic point set $P \subset \mathbb{R}^d$, where points may be inserted or deleted over time and the ambient dimension $d$ is not constant and may be high. Our focus is on designing algorithms that remain effective even in the presence of an adaptive adversary -- an adversary that, at any time $t$, knows the entire history of the algorithm's outputs as well as all the random bits used by the algorithm up to that point. We present a fully dynamic algorithm that maintains a $2$-approximate diameter with a worst-case update time of $\text{poly}(d, \log n)$, where $n$ is the length of the stream. Our result is achieved by identifying a robust representative of the dataset that requires infrequent updates, combined with a careful deamortization. To the best of our knowledge, this is the first efficient fully-dynamic algorithm for diameter in high dimensions that simultaneously achieves a 2-approximation guarantee and robustness against an adaptive adversary. We also give an improved dynamic $(4+\epsilon)$-approximation algorithm for the $k$-center problem, also resilient to an adaptive adversary. Our clustering algorithm achieves an amortized update time of $k^{2.5} d \cdot \text{poly}(\epsilon^{-1}, \log n)$, improving upon the amortized update time of $k^6 d \cdot \text{poly}(\epsilon^{-1}, \log n)$ by Biabani et al. [NeurIPS'24].</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01065v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiarash Banihashem, Jeff Giliberti, Samira Goudarzi, MohammadTaghi Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh</dc:creator>
    </item>
    <item>
      <title>Fault-Tolerant Approximate Distance Oracles with a Source Set</title>
      <link>https://arxiv.org/abs/2511.01239</link>
      <description>arXiv:2511.01239v1 Announce Type: new 
Abstract: Our input is an undirected weighted graph $G = (V,E)$ on $n$ vertices along with a source set $S\subseteq V$. The problem is to preprocess $G$ and build a compact data structure such that upon query $Qu(s,v,f)$ where $(s,v) \in S\times V$ and $f$ is any faulty edge, we can quickly find a good estimate (i.e., within a small multiplicative stretch) of the $s$-$v$ distance in $G-f$. We use a fault-tolerant $ST$-distance oracle from the work of Bil{\`{o}} et al. (STACS 2018) to construct an $S\times V$ approximate distance oracle or {\em sourcewise} approximate distance oracle of size $\widetilde{O}(|S|n + n^{3/2})$ with multiplicative stretch at most 5. We construct another fault-tolerant sourcewise approximate distance oracle of size $\widetilde{O}(|S|n + n^{4/3})$ with multiplicative stretch at most 13. Both the oracles have $O(1)$ query answering time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01239v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipan Dey, Telikepalli Kavitha</dc:creator>
    </item>
    <item>
      <title>Subtree Mode and Applications</title>
      <link>https://arxiv.org/abs/2511.01376</link>
      <description>arXiv:2511.01376v1 Announce Type: new 
Abstract: The mode of a collection of values (i.e., the most frequent value in the collection) is a key summary statistic. Finding the mode in a given range of an array of values is thus of great importance, and constructing a data structure to solve this problem is in fact the well-known Range Mode problem. In this work, we introduce the Subtree Mode (SM) problem, the analogous problem in a leaf-colored tree, where the task is to compute the most frequent color in the leaves of the subtree of a given node. SM is motivated by several applications in domains such as text analytics and biology, where the data are hierarchical and can thus be represented as a (leaf-colored) tree. Our central contribution is a time-optimal algorithm for SM that computes the answer for every node of an input $N$-node tree in $O(N)$ time. We further show how our solution can be adapted for node-colored trees, or for computing the $k$ most frequent colors, in the optimal $O(N)$ time, for any given $k=O(1)$. Moreover, we prove that a similarly fast solution for when the input is a sink-colored directed acyclic graph instead of a leaf-colored tree is highly unlikely. Our experiments on real datasets with trees of up to 7.3 billion nodes demonstrate that our algorithm is faster than baselines by at least one order of magnitude and much more space efficient. Last, we present case studies showing the effectiveness of our approach in pattern mining and sequence-to-database search applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01376v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jialong Zhou, Ben Bals, Matei Tinca, Ai Guan, Panagiotis Charalampopoulos, Grigorios Loukides, Solon P. Pissis</dc:creator>
    </item>
    <item>
      <title>Robust Streaming Against Low-Memory Adversaries</title>
      <link>https://arxiv.org/abs/2511.01769</link>
      <description>arXiv:2511.01769v1 Announce Type: new 
Abstract: Robust streaming, the study of streaming algorithms that provably work when the stream is generated by an adaptive adversary, has seen tremendous progress in recent years. However, fundamental barriers remain: the best known algorithm for turnstile $F_p$-estimation in the robust streaming setting is exponentially worse than in the oblivious setting, and closing this gap seems difficult. Arguably, one possible cause of this barrier is the adversarial model, which may be too strong: unlike the space-bounded streaming algorithm, the adversary can memorize the entire history of the interaction with the algorithm. Can we then close the exponential gap if we insist that the adversary itself is an adaptive but low-memory entity, roughly as powerful as (or even weaker than) the algorithm?
  In this work we present the first set of models and results aimed towards this question. We design efficient robust streaming algorithms against adversaries that are fully adaptive but have no long-term memory ("memoryless") or very little memory of the history of interaction. Roughly speaking, a memoryless adversary only sees, at any given round, the last output of the algorithm (and does not even know the current time) and can generate an unlimited number of independent coin tosses. A low-memory adversary is similar, but maintains an additional small buffer. While these adversaries may seem quite limited at first glance, we show that this adversarial model is strong enough to produce streams that have high flip number and density in the context of $F_2$-estimation, which rules out most of known robustification techniques. We then design a new simple approach, similar to the computation paths framework, to obtain efficient algorithms against memoryless and low-memory adversaries for a wide class of order-invariant problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01769v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omri Ben-Eliezer, Krzysztof Onak, Sandeep Silwal</dc:creator>
    </item>
    <item>
      <title>Unbounded-width CSPs are Untestable in a Sublinear Number of Queries</title>
      <link>https://arxiv.org/abs/2510.27012</link>
      <description>arXiv:2510.27012v1 Announce Type: cross 
Abstract: The bounded-degree query model, introduced by Goldreich and Ron (\textit{Algorithmica, 2002}), is a standard framework in graph property testing and sublinear-time algorithms. Many properties studied in this model, such as bipartiteness and 3-colorability of graphs, can be expressed as satisfiability of constraint satisfaction problems (CSPs). We prove that for the entire class of \emph{unbounded-width} CSPs, testing satisfiability requires $\Omega(n)$ queries in the bounded-degree model. This result unifies and generalizes several previous lower bounds. In particular, it applies to all CSPs that are known to be $\mathbf{NP}$-hard to solve, including $k$-colorability of $\ell$-uniform hypergraphs for any $k,\ell \ge 2$ with $(k,\ell) \neq (2,2)$.
  Our proof combines the techniques from Bogdanov, Obata, and Trevisan (\textit{FOCS, 2002}), who established the first $\Omega(n)$ query lower bound for CSP testing in the bounded-degree model, with known results from universal algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27012v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yumou Fei</dc:creator>
    </item>
    <item>
      <title>SpEx: A Spectral Approach to Explainable Clustering</title>
      <link>https://arxiv.org/abs/2511.00885</link>
      <description>arXiv:2511.00885v1 Announce Type: cross 
Abstract: Explainable clustering by axis-aligned decision trees was introduced by Moshkovitz et al. (2020) and has gained considerable interest. Prior work has focused on minimizing the price of explainability for specific clustering objectives, lacking a general method to fit an explanation tree to any given clustering, without restrictions. In this work, we propose a new and generic approach to explainable clustering, based on spectral graph partitioning. With it, we design an explainable clustering algorithm that can fit an explanation tree to any given non-explainable clustering, or directly to the dataset itself. Moreover, we show that prior algorithms can also be interpreted as graph partitioning, through a generalized framework due to Trevisan (2013) wherein cuts are optimized in two graphs simultaneously. Our experiments show the favorable performance of our method compared to baselines on a range of datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00885v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tal Argov, Tal Wagner</dc:creator>
    </item>
    <item>
      <title>Fast Answering Pattern-Constrained Reachability Queries with Two-Dimensional Reachability Index</title>
      <link>https://arxiv.org/abs/2511.01025</link>
      <description>arXiv:2511.01025v1 Announce Type: cross 
Abstract: Reachability queries ask whether there exists a path from the source vertex to the target vertex on a graph. Recently, several powerful reachability queries, such as Label-Constrained Reachability (LCR) queries and Regular Path Queries (RPQ), have been proposed for emerging complex edge-labeled digraphs. However, they cannot allow users to describe complex query requirements by composing query patterns. Here, we introduce composite patterns, a logical expression of patterns that can express complex constraints on the set of labels. Based on pattern, we propose pattern-constrained reachability queries (PCR queries). However, answering PCR queries is NP-hard. Thus, to improve the performance to answer PCR queries, we build a two-dimensional reachability (TDR for short) index which consists of a multi-way index (horizontal dimension) and a path index (vertical dimension). Because the number of combinations of both labels and vertices is exponential, it is very expensive to build full indices that contain all the reachability information. Thus, the reachable vertices of a vertex are decomposed into blocks, each of which is hashed into the horizontal dimension index and the vertical dimension index, respectively. The indices in the horizontal dimension and the vertical dimension serve as a global filter and a local filter, respectively, to prune the search space. Experimental results demonstrate that our index size and indexing time outperform the state-of-the-art label-constrained reachability indexing technique on 16 real datasets. TDR can efficiently answer pattern-constrained reachability queries, including label-constrained reachability queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01025v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huihui Yang, Pingpeng Yuan</dc:creator>
    </item>
    <item>
      <title>NP-membership for the boundary-boundary art-gallery problem</title>
      <link>https://arxiv.org/abs/2511.01562</link>
      <description>arXiv:2511.01562v1 Announce Type: cross 
Abstract: The boundary-boundary art-gallery problem asks, given a polygon $P$ representing an art-gallery, for a minimal set of guards that can see the entire boundary of $P$ (the wall of the art gallery), where the guards must be placed on the boundary. We show that this art-gallery variant is in NP. In order to prove this, we develop a constraint-propagation procedure for continuous constraint satisfaction problems where each constraint involves at most 2 variables.
  The X-Y variant of the art-gallery problem is the one where the guards must lie in X and need to see all of Y. Each of X and Y can be either the vertices of the polygon, the boundary of the polygon, or the entire polygon, giving 9 different variants. Previously, it was known that X-vertex and vertex-Y variants are all NP-complete and that the point-point, point-boundary, and boundary-point variants are $\exists \mathbb{R}$-complete [Abrahamsen, Adamaszek, and Miltzow, JACM 2021][Stade, SoCG 2025]. However, the boundary-boundary variant was only known to lie somewhere between NP and $\exists \mathbb{R}$.
  The X-vertex and vertex-Y variants can be straightforwardly reduced to discrete set-cover instances. In contrast, we give example to show that a solution to an instance of the boundary-boundary art-gallery problem sometimes requires placing guards at irrational coordinates, so it unlikely that the problem can be easily discretized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01562v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Stade</dc:creator>
    </item>
    <item>
      <title>Translating between the representations of an acyclic convex geometry of bounded degree</title>
      <link>https://arxiv.org/abs/2506.24052</link>
      <description>arXiv:2506.24052v2 Announce Type: replace 
Abstract: We consider the problem of translating between irreducible closed sets and implicational bases in closure systems. To date, the complexity status of this problem is widely open, and it is further known to generalize the notorious hypergraph dualization problem, even in the context of acyclic convex geometries, i.e., closure systems admitting an acyclic implicational base. This paper studies this later class with a focus on the degree, which corresponds to the maximal number of implications in which an element occurs. We show that the problem is tractable for bounded values of this parameter, even when relaxed to the notions of premise- and conclusion-degree. Our algorithms rely on structural properties of acyclic convex geometries and involve various techniques from algorithmic enumeration such as solution graph traversal, saturation techniques, and a sequential approach leveraging from acyclicity. They are shown to perform in incremental-polynomial time. Finally, we complete these results by showing that our running times cannot be improved to polynomial delay using the standard framework of flashlight search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24052v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar Defrain, Arthur Ohana, Simon Vilmin</dc:creator>
    </item>
    <item>
      <title>Graph-Based Approximate Nearest Neighbor Search Revisited: Theoretical Analysis and Optimization</title>
      <link>https://arxiv.org/abs/2509.15531</link>
      <description>arXiv:2509.15531v2 Announce Type: replace 
Abstract: Graph-based approaches to approximate nearest neighbor search (ANNS) have achieved remarkable success in enabling fast, high-recall retrieval on billion-scale vector datasets. Among them, the Sparse Neighborhood Graph (SNG) has emerged as a widely adopted graph structure due to its superior search performance. However, the theoretical understanding of SNG remains limited, leading to reliance on heuristic-based and often suboptimal truncation strategies. In this work, we aim to bridge the gap between theory and practice by providing formal guarantees for graph-based ANNS methods and proposing principled optimization strategies for the truncation parameter. By characterizing the index construction process through martingale-based analysis, we show that the degree of the index graph is $O(n^{2/3+\epsilon})$, where $\epsilon$ is an arbitrarily small constant. Furthermore, we prove that the expected search path length during query processing is $O(\log n)$. Based on these theoretical insights, we introduce a novel and principled method for selecting the truncation parameter $R$ in SNG. Experimental results demonstrate that our method achieves comparable or superior performance in terms of query latency and Recall@10 compared to commonly used binary search heuristics, while yielding 2x to 9x speedups in overall index construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15531v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinran Ma, Zhaoqi Zhou, Chuan Zhou, Qi Meng, Zaijiu Shang, Guoliang Li, Zhiming Ma</dc:creator>
    </item>
    <item>
      <title>Inclusive and Exclusive Vertex Splitting into Specific Graph Classes: NP Hardness and Algorithms</title>
      <link>https://arxiv.org/abs/2510.26938</link>
      <description>arXiv:2510.26938v2 Announce Type: replace 
Abstract: We study a family of graph modification problems called the F-Vertex Splitting problem. Given a graph G, the task is to determine whether G can be transformed into a graph G-prime belonging to a graph class F through a sequence of at most k vertex splits. We investigate this problem for several target graph classes, namely constellations, cycle graphs, linear forests, and bipartite graphs. We analyze both inclusive and exclusive variants of vertex splitting, as introduced by Abu-Khzam and collaborators (ISCO 2018). Our results show that the F-Vertex Splitting problem is polynomial-time solvable when F is a cycle graph or a linear forest, for both variants. In contrast, when F is a constellation or a bipartite graph, the problem is NP-complete for both variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26938v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad, Hitendra Kumar, S. Padmapriya, Praneet Kumar Patra, Harsh Sanklecha, Soumen Maity</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization with Adversarial Data Contamination</title>
      <link>https://arxiv.org/abs/2507.10718</link>
      <description>arXiv:2507.10718v2 Announce Type: replace-cross 
Abstract: Distributionally Robust Optimization (DRO) provides a framework for decision-making under distributional uncertainty, yet its effectiveness can be compromised by outliers in the training data. This paper introduces a principled approach to simultaneously address both challenges. We focus on optimizing Wasserstein-1 DRO objectives for generalized linear models with convex Lipschitz loss functions, where an $\epsilon$-fraction of the training data is adversarially corrupted. Our primary contribution lies in a novel modeling framework that integrates robustness against training data contamination with robustness against distributional shifts, alongside an efficient algorithm inspired by robust statistics to solve the resulting optimization problem. We prove that our method achieves an estimation error of $O(\sqrt{\epsilon})$ for the true DRO objective value using only the contaminated data under the bounded covariance assumption. This work establishes the first rigorous guarantees, supported by efficient computation, for learning under the dual challenges of data contamination and distributional shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10718v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuyao Li, Ilias Diakonikolas, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of s-Club Cluster Edge Deletion: When Is the Diameter Bound Necessary?</title>
      <link>https://arxiv.org/abs/2510.07065</link>
      <description>arXiv:2510.07065v4 Announce Type: replace-cross 
Abstract: We study the parameterized and kernelization complexity of the s-Club Cluster Edge Deletion problem, a distance-bounded generalization of Cluster Edge Deletion. Given a graph G = (V, E) and integers k and s, the goal is to delete at most k edges so that every connected component in the resulting graph has diameter at most s. This captures a broad class of distance-constrained graph modification problems that lie between clustering and connectivity control.
  We prove that for s = 2 the problem is NP-hard already on split graphs, closing the gap between the polynomially solvable cases s = 1 and s = 3. For this setting we give a cubic vertex kernel parameterized by k, the first polynomial kernel for 2-Club Cluster Edge Deletion on split graphs. On the structural side, we show that the problem is W[1]-hard when parameterized by pathwidth (and hence treewidth), implying that the diameter bound s is crucial for fixed-parameter tractability. In contrast, the problem is FPT when parameterized by treedepth, neighborhood diversity, or the cluster vertex deletion number.
  Finally, we design an FPT bicriteria approximation scheme that, for graphs excluding long induced cycles, runs in time f(k, 1/epsilon) * n^{O(1)} and outputs a solution of size at most k whose components have diameter at most (1 + epsilon) * s. We further present an exact FPT algorithm for interval graphs parameterized by k and a polynomial-time algorithm for unit interval graphs. We also introduce the directed variant s-Club Cluster Arc Deletion and show it is W[1]-hard when parameterized by k, even on DAGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07065v4</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad</dc:creator>
    </item>
  </channel>
</rss>
