<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Large Neighborhood and Hybrid Genetic Search for Inventory Routing Problems</title>
      <link>https://arxiv.org/abs/2506.03172</link>
      <description>arXiv:2506.03172v1 Announce Type: new 
Abstract: The inventory routing problem (IRP) focuses on jointly optimizing inventory and distribution operations from a supplier to retailers over multiple days. Compared to other problems from the vehicle routing family, the interrelations between inventory and routing decisions render IRP optimization more challenging and call for advanced solution techniques. A few studies have focused on developing large neighborhood search approaches for this class of problems, but this remains a research area with vast possibilities due to the challenges related to the integration of inventory and routing decisions. In this study, we advance this research area by developing a new large neighborhood search operator tailored for the IRP. Specifically, the operator optimally removes and reinserts all visits to a specific retailer while minimizing routing and inventory costs. We propose an efficient tailored dynamic programming algorithm that exploits preprocessing and acceleration strategies. The operator is used to build an effective local search routine, and included in a state-of-the-art routing algorithm, i.e., Hybrid Genetic Search (HGS). Through extensive computational experiments, we demonstrate that the resulting heuristic algorithm leads to solutions of unmatched quality up to this date, especially on large-scale benchmark instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03172v1</guid>
      <category>cs.NE</category>
      <category>stat.ME</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyi Zhao, Claudia Archetti, Tuan Anh Pham, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>SENMAP: Multi-objective data-flow mapping and synthesis for hybrid scalable neuromorphic systems</title>
      <link>https://arxiv.org/abs/2506.03450</link>
      <description>arXiv:2506.03450v1 Announce Type: new 
Abstract: This paper introduces SENMap, a mapping and synthesis tool for scalable, energy-efficient neuromorphic computing architecture frameworks. SENECA is a flexible architectural design optimized for executing edge AI SNN/ANN inference applications efficiently. To speed up the silicon tape-out and chip design for SENECA, an accurate emulator, SENSIM, was designed. While SENSIM supports direct mapping of SNNs on neuromorphic architectures, as the SNN and ANNs grow in size, achieving optimal mapping for objectives like energy, throughput, area, and accuracy becomes challenging. This paper introduces SENMap, flexible mapping software for efficiently mapping large SNN and ANN applications onto adaptable architectures. SENMap considers architectural, pretrained SNN and ANN realistic examples, and event rate-based parameters and is open-sourced along with SENSIM to aid flexible neuromorphic chip design before fabrication. Experimental results show SENMap enables 40 percent energy improvements for a baseline SENSIM operating in timestep asynchronous mode of operation. SENMap is designed in such a way that it facilitates mapping large spiking neural networks for future modifications as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03450v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prithvish V Nembhani, Oliver Rhodes, Guangzhi Tang, Alexandra F Dobrita, Yingfu Xu, Kanishkan Vadivel, Kevin Shidqi, Paul Detterer Mario Konijnenburg, Gert-Jan van Schaik, Manolis Sifalakis, Zaid Al-Ars, Amirreza Yousefzadeh</dc:creator>
    </item>
    <item>
      <title>IntLevPy: A Python library to classify and model intermittent and L\'evy processes</title>
      <link>https://arxiv.org/abs/2506.03729</link>
      <description>arXiv:2506.03729v1 Announce Type: new 
Abstract: IntLevPy provides a comprehensive description of the IntLevPy Package, a Python library designed for simulating and analyzing intermittent and L\'evy processes. The package includes functionalities for process simulation, including full parameter estimation and fitting optimization for both families of processes, moment calculation, and classification methods. The classification methodology utilizes adjusted-$R^2$ and a noble performance measure {\Gamma}, enabling the distinction between intermittent and L\'evy processes. IntLevPy integrates iterative parameter optimization with simulation-based validation. This paper provides an in-depth user guide covering IntLevPy software architecture, installation, validation workflows, and usage examples. In this way, IntLevPy facilitates systematic exploration of these two broad classes of stochastic processes, bridging theoretical models and practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03729v1</guid>
      <category>cs.NE</category>
      <category>cs.MS</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shailendra Bhandari, Pedro Lencastre, Sergiy Denysov, Yurii Bystryk, Pedro G. Lind</dc:creator>
    </item>
    <item>
      <title>Designing morphologies of soft medical devices using cooperative neuro coevolution</title>
      <link>https://arxiv.org/abs/2506.03847</link>
      <description>arXiv:2506.03847v1 Announce Type: new 
Abstract: Soft robots have proven to outperform traditional robots in applications related to propagation in geometrically constrained environments. Designing these robots and their controllers is an intricate task, since their building materials exhibit non-linear properties. Human designs may be biased; hence, alternative designing processes should be considered. We present a cooperative neuro coevolution approach to designing the morphologies of soft actuators and their controllers for applications in drug delivery apparatus. Morphologies and controllers are encoded as compositional pattern-producing networks evolved by Neuroevolution of Augmented Topologies (NEAT) and in cooperative coevolution methodology, taking into account different collaboration methods. Four collaboration methods are studied: n best individuals, n worst individuals, n best and worst individuals, and n random individuals. As a performance baseline, the results from the implementation of Age-Fitness Pareto Optimisation (AFPO) are considered. The metrics used are the maximum displacement in upward bending and the robustness of the devices in terms of applying to the same evolved morphology a diverse set of controllers. Results suggest that the cooperative neuro coevolution approach can produce more suitable morphologies for the intended devices than AFPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03847v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3712255.3726671</arxiv:DOI>
      <dc:creator>Hugo Alcaraz-Herrera, Michail-Antisthenis Tsompanas, Igor Balaz, Andrew Adamatzky</dc:creator>
    </item>
    <item>
      <title>Lightweight Convolutional Neural Networks for Retinal Disease Classification</title>
      <link>https://arxiv.org/abs/2506.03186</link>
      <description>arXiv:2506.03186v1 Announce Type: cross 
Abstract: Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH) significantly impact vision and affect millions worldwide. Early detection is crucial, as DR, a complication of diabetes, damages retinal blood vessels, potentially leading to blindness, while MH disrupts central vision, affecting tasks like reading and facial recognition. This paper employed two lightweight and efficient Convolution Neural Network architectures, MobileNet and NASNetMobile, for the classification of Normal, DR, and MH retinal images. The models were trained on the RFMiD dataset, consisting of 3,200 fundus images, after undergoing preprocessing steps such as resizing, normalization, and augmentation. To address data scarcity, this study leveraged transfer learning and data augmentation techniques, enhancing model generalization and performance. The experimental results demonstrate that MobileNetV2 achieved the highest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5% accuracy. These findings highlight the effectiveness of CNNs in retinal disease classification, providing a foundation for AI-assisted ophthalmic diagnosis and early intervention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03186v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duaa Kareem Qasim, Sabah Abdulazeez Jebur, Lafta Raheem Ali, Abdul Jalil M. Khalaf, Abir Jaafar Hussain</dc:creator>
    </item>
    <item>
      <title>Multiple-Frequencies Population-Based Training</title>
      <link>https://arxiv.org/abs/2506.03225</link>
      <description>arXiv:2506.03225v1 Announce Type: cross 
Abstract: Reinforcement Learning's high sensitivity to hyperparameters is a source of instability and inefficiency, creating significant challenges for practitioners. Hyperparameter Optimization (HPO) algorithms have been developed to address this issue, among them Population-Based Training (PBT) stands out for its ability to generate hyperparameters schedules instead of fixed configurations. PBT trains a population of agents, each with its own hyperparameters, frequently ranking them and replacing the worst performers with mutations of the best agents. These intermediate selection steps can cause PBT to focus on short-term improvements, leading it to get stuck in local optima and eventually fall behind vanilla Random Search over longer timescales. This paper studies how this greediness issue is connected to the choice of evolution frequency, the rate at which the selection is done. We propose Multiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm that addresses greediness by employing sub-populations, each evolving at distinct frequencies. MF-PBT introduces a migration process to transfer information between sub-populations, with an asymmetric design to balance short and long-term optimization. Extensive experiments on the Brax suite demonstrate that MF-PBT improves sample efficiency and long-term performance, even without actually tuning hyperparameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03225v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wa\"el Doulazmi, Auguste Lehuger, Marin Toromanoff, Valentin Charraut, Thibault Buhet, Fabien Moutarde</dc:creator>
    </item>
    <item>
      <title>Multi-Exit Kolmogorov-Arnold Networks: enhancing accuracy and parsimony</title>
      <link>https://arxiv.org/abs/2506.03302</link>
      <description>arXiv:2506.03302v1 Announce Type: cross 
Abstract: Kolmogorov-Arnold Networks (KANs) uniquely combine high accuracy with interpretability, making them valuable for scientific modeling. However, it is unclear a priori how deep a network needs to be for any given task, and deeper KANs can be difficult to optimize. Here we introduce multi-exit KANs, where each layer includes its own prediction branch, enabling the network to make accurate predictions at multiple depths simultaneously. This architecture provides deep supervision that improves training while discovering the right level of model complexity for each task. Multi-exit KANs consistently outperform standard, single-exit versions on synthetic functions, dynamical systems, and real-world datasets. Remarkably, the best predictions often come from earlier, simpler exits, revealing that these networks naturally identify smaller, more parsimonious and interpretable models without sacrificing accuracy. To automate this discovery, we develop a differentiable "learning to exit" algorithm that balances contributions from exits during training. Our approach offers scientists a practical way to achieve both high performance and interpretability, addressing a fundamental challenge in machine learning for scientific discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03302v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Bagrow, Josh Bongard</dc:creator>
    </item>
    <item>
      <title>A Class Inference Scheme With Dempster-Shafer Theory for Learning Fuzzy-Classifier Systems</title>
      <link>https://arxiv.org/abs/2506.03588</link>
      <description>arXiv:2506.03588v1 Announce Type: cross 
Abstract: The decision-making process significantly influences the predictions of machine learning models. This is especially important in rule-based systems such as Learning Fuzzy-Classifier Systems (LFCSs) where the selection and application of rules directly determine prediction accuracy and reliability. LFCSs combine evolutionary algorithms with supervised learning to optimize fuzzy classification rules, offering enhanced interpretability and robustness. Despite these advantages, research on improving decision-making mechanisms (i.e., class inference schemes) in LFCSs remains limited. Most LFCSs use voting-based or single-winner-based inference schemes. These schemes rely on classification performance on training data and may not perform well on unseen data, risking overfitting. To address these limitations, this article introduces a novel class inference scheme for LFCSs based on the Dempster-Shafer Theory of Evidence (DS theory). The proposed scheme handles uncertainty well. By using the DS theory, the scheme calculates belief masses (i.e., measures of belief) for each specific class and the ``I don't know'' state from each fuzzy rule and infers a class from these belief masses. Unlike the conventional schemes, the proposed scheme also considers the ``I don't know'' state that reflects uncertainty, thereby improving the transparency and reliability of LFCSs. Applied to a variant of LFCS (i.e., Fuzzy-UCS), the proposed scheme demonstrates statistically significant improvements in terms of test macro F1 scores across 30 real-world datasets compared to conventional voting-based and single-winner-based fuzzy inference schemes. It forms smoother decision boundaries, provides reliable confidence measures, and enhances the robustness and generalizability of LFCSs in real-world applications. Our implementation is available at https://github.com/YNU-NakataLab/jUCS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03588v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3717613</arxiv:DOI>
      <arxiv:journal_reference>ACM Transactions on Evolutionary Learning and Optimization (2025)</arxiv:journal_reference>
      <dc:creator>Hiroki Shiraishi, Hisao Ishibuchi, Masaya Nakata</dc:creator>
    </item>
    <item>
      <title>Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems</title>
      <link>https://arxiv.org/abs/2506.03602</link>
      <description>arXiv:2506.03602v1 Announce Type: cross 
Abstract: Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs), a family of rule-based machine learning systems that evolve interpretable models through evolutionary processes. However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS incorporates a generalization bias favoring crisp rules where feasible, enhancing model interpretability without compromising accuracy. Experimental results on real-world classification tasks show that our LCS achieves significantly superior test accuracy and produces more compact rule sets. Our implementation is available at https://github.com/YNU-NakataLab/Beta4-UCS. An extended abstract related to this work is available at https://doi.org/10.36227/techrxiv.174900805.59801248/v1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03602v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TEVC.2025.3550915</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Evolutionary Computation (2025)</arxiv:journal_reference>
      <dc:creator>Hiroki Shiraishi, Yohei Hayamizu, Tomonori Hashiyama, Keiki Takadama, Hisao Ishibuchi, Masaya Nakata</dc:creator>
    </item>
    <item>
      <title>Optimal Spiking Brain Compression: Improving One-Shot Post-Training Pruning and Quantization for Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2506.03996</link>
      <description>arXiv:2506.03996v1 Announce Type: cross 
Abstract: Spiking Neural Networks (SNNs) have emerged as a new generation of energy-efficient neural networks suitable for implementation on neuromorphic hardware. As neuromorphic hardware has limited memory and computing resources, weight pruning and quantization have recently been explored to improve SNNs' efficiency. State-of-the-art SNN pruning/quantization methods employ multiple compression and training iterations, increasing the cost for pre-trained or very large SNNs. In this paper, we propose a new one-shot post-training pruning/quantization framework, Optimal Spiking Brain Compression (OSBC), that adapts the Optimal Brain Compression (OBC) method of [Frantar, Singh, and Alistarh, 2023] for SNNs. Rather than minimizing the loss on neuron input current as OBC does, OSBC achieves more efficient and accurate SNN compression in one pass by minimizing the loss on spiking neuron membrane potential with a small sample dataset. Our experiments on neuromorphic datasets (N-MNIST, CIFAR10-DVS, DVS128-Gesture) demonstrate that OSBC can achieve 97% sparsity through pruning with 1.41%, 10.20%, and 1.74% accuracy loss, or 4-bit symmetric quantization with 0.17%, 1.54%, and 7.71% accuracy loss, respectively. Code will be available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03996v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lianfeng Shi, Ao Li, Benjamin Ward-Cherrier</dc:creator>
    </item>
    <item>
      <title>Dendritic Localized Learning: Toward Biologically Plausible Algorithm</title>
      <link>https://arxiv.org/abs/2501.09976</link>
      <description>arXiv:2501.09976v2 Announce Type: replace 
Abstract: Backpropagation is the foundational algorithm for training neural networks and a key driver of deep learning's success. However, its biological plausibility has been challenged due to three primary limitations: weight symmetry, reliance on global error signals, and the dual-phase nature of training, as highlighted by the existing literature. Although various alternative learning approaches have been proposed to address these issues, most either fail to satisfy all three criteria simultaneously or yield suboptimal results. Inspired by the dynamics and plasticity of pyramidal neurons, we propose Dendritic Localized Learning (DLL), a novel learning algorithm designed to overcome these challenges. Extensive empirical experiments demonstrate that DLL satisfies all three criteria of biological plausibility while achieving state-of-the-art performance among algorithms that meet these requirements. Furthermore, DLL exhibits strong generalization across a range of architectures, including MLPs, CNNs, and RNNs. These results, benchmarked against existing biologically plausible learning algorithms, offer valuable empirical insights for future research. We hope this study can inspire the development of new biologically plausible algorithms for training multilayer networks and advancing progress in both neuroscience and machine learning. Our code is available at https://github.com/Lvchangze/Dendritic-Localized-Learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09976v2</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changze Lv, Jingwen Xu, Yiyang Lu, Xiaohua Wang, Zhenghua Wang, Zhibo Xu, Di Yu, Xin Du, Xiaoqing Zheng, Xuanjing Huang</dc:creator>
    </item>
    <item>
      <title>Random-key genetic algorithms: Principles and applications</title>
      <link>https://arxiv.org/abs/2506.02120</link>
      <description>arXiv:2506.02120v2 Announce Type: replace 
Abstract: A random-key genetic algorithm is an evolutionary metaheuristic for discrete and global optimization. Each solution is encoded as a vector of N random keys, where a random key is a real number randomly generated in the continuous interval [0, 1). A decoder maps each vector of random keys to a solution of the optimization problem being solved and computes its cost. The benefit of this approach is that all genetic operators and transformations can be maintained within the unitary hypercube, regardless of the problem being addressed. This enhances the productivity and maintainability of the core framework. The algorithm starts with a population of P vectors of random keys. At each iteration, the vectors are partitioned into two sets: a smaller set of high-valued elite solutions and the remaining non-elite solutions. All elite elements are copied, without change, to the next population. A small number of random-key vectors (the mutants) is added to the population of the next iteration. The remaining elements of the population of the next iteration are generated by combining, with the parametrized uniform crossover of Spears and DeJong (1991), pairs of solutions. This chapter reviews random-key genetic algorithms and describes an effective variant called biased random-key genetic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02120v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariana A. Londe, Luciana S. Pessoa, Carlos E. Andrade, Jos\'e F. Gon\c{c}alves, Mauricio G. C. Resende</dc:creator>
    </item>
    <item>
      <title>An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures</title>
      <link>https://arxiv.org/abs/2501.07930</link>
      <description>arXiv:2501.07930v3 Announce Type: replace-cross 
Abstract: Orthogonal convolutional layers are valuable components in multiple areas of machine learning, such as adversarial robustness, normalizing flows, GANs, and Lipschitz-constrained models. Their ability to preserve norms and ensure stable gradient propagation makes them valuable for a large range of problems. Despite their promise, the deployment of orthogonal convolution in large-scale applications is a significant challenge due to computational overhead and limited support for modern features like strides, dilations, group convolutions, and transposed convolutions. In this paper, we introduce AOC (Adaptative Orthogonal Convolution), a scalable method that extends a previous method (BCOP), effectively overcoming existing limitations in the construction of orthogonal convolutions. This advancement unlocks the construction of architectures that were previously considered impractical. We demonstrate through our experiments that our method produces expressive models that become increasingly efficient as they scale. To foster further advancement, we provide an open-source python package implementing this method, called Orthogonium ( https://github.com/deel-ai/orthogonium ) .</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07930v3</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Learning, 2025, Vancouver, Canada</arxiv:journal_reference>
      <dc:creator>Thibaut Boissin (IRIT), Franck Mamalet (IRIT), Thomas Fel (IRIT), Agustin Martin Picard (IRIT), Thomas Massena (IRIT), Mathieu Serrurier (IRIT)</dc:creator>
    </item>
  </channel>
</rss>
