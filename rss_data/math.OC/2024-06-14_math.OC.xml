<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Jun 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The strong convergence of the trajectory of a Tikhonov regularized inertial primal-dual dynamical system with a slow damping</title>
      <link>https://arxiv.org/abs/2406.08836</link>
      <description>arXiv:2406.08836v1 Announce Type: new 
Abstract: We propose a Tikhonov regularized inertial primal-dual dynamical system with a slow damping $\frac{\alpha}{t^q}$, where the inertial term is introduced only for the primal variable, for the linearly constrained convex optimization problem in Hilbert spaces. Under a suitable assumption on the underlying parameters, by a Lyapunov analysis approach, we prove the strong convergence of the trajectory of the proposed system to the minimal norm primal-dual solution of the problem, along with convergence rate results for the primal-dual gap, the objective residual and the feasibility violation. In Section 4, , we perform some numerical experiments to illustrate the theoretical results. Finaly, we give a conclusion in Section 5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08836v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting-Ting Zhu, Rong Hu, Ya-Ping Fang</dc:creator>
    </item>
    <item>
      <title>Mirror and Preconditioned Gradient Descent in Wasserstein Space</title>
      <link>https://arxiv.org/abs/2406.08938</link>
      <description>arXiv:2406.08938v1 Announce Type: new 
Abstract: As the problem of minimizing functionals on the Wasserstein space encompasses many applications in machine learning, different optimization algorithms on $\mathbb{R}^d$ have received their counterpart analog on the Wasserstein space. We focus here on lifting two explicit algorithms: mirror descent and preconditioned gradient descent. These algorithms have been introduced to better capture the geometry of the function to minimize and are provably convergent under appropriate (namely relative) smoothness and convexity conditions. Adapting these notions to the Wasserstein space, we prove guarantees of convergence of some Wasserstein-gradient-based discrete-time schemes for new pairings of objective functionals and regularizers. The difficulty here is to carefully select along which curves the functionals should be smooth and convex. We illustrate the advantages of adapting the geometry induced by the regularizer on ill-conditioned optimization tasks, and showcase the improvement of choosing different discrepancies and geometries in a computational biology task of aligning single-cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08938v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Bonet, Th\'eo Uscidda, Adam David, Pierre-Cyril Aubin-Frankowski, Anna Korba</dc:creator>
    </item>
    <item>
      <title>S-SOS: Stochastic Sum-Of-Squares for Parametric Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2406.08954</link>
      <description>arXiv:2406.08954v1 Announce Type: new 
Abstract: Global polynomial optimization is an important tool across applied mathematics, with many applications in operations research, engineering, and physical sciences. In various settings, the polynomials depend on external parameters that may be random. We discuss a stochastic sum-of-squares (S-SOS) algorithm based on the sum-of squares hierarchy that constructs a series of semidefinite programs to jointly find strict lower bounds on the global minimum and extract candidates for parameterized global minimizers. We prove quantitative convergence of the hierarchy as the degree increases and use it to solve unconstrained and constrained polynomial optimization problems parameterized by random variables. By employing $n$-body priors from condensed matter physics to induce sparsity, we can use S-SOS to produce solutions and uncertainty intervals for sensor network localization problems containing up to 40 variables and semidefinite matrix sizes surpassing $800 \times 800$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08954v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard L. Zhu, Mathias Oster, Yuehaw Khoo</dc:creator>
    </item>
    <item>
      <title>Bilevel Optimization of the Kantorovich Problem and its Quadratic Regularization Part III: The Finite-Dimensional Case</title>
      <link>https://arxiv.org/abs/2406.08992</link>
      <description>arXiv:2406.08992v1 Announce Type: new 
Abstract: As the title suggests, this is the third paper in a series addressing bilevel optimization problems that are governed by the Kantorovich problem of optimal transport. These tasks can be reformulated as mathematical problems with complementarity constraints in the space of regular Borel measures. Due to the nonsmoothness that is introduced by the complementarity constraints, such problems are often regularized, for instance, using entropic regularization. In this series of papers, however, we apply a quadratic regularization to the Kantorovich problem. By doing so, we enhance its numerical properties while preserving the sparsity structure of the optimal transportation plan as much as possible. While the first two papers in this series focus on the well-posedness of the regularized bilevel problems and the approximation of solutions to the bilevel optimization problem in the infinite-dimensional case, in this paper, we reproduce these results for the finite-dimensional case and present findings that go well beyond the ones of the previous papers and pave the way for the numerical treatment of the bilevel problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08992v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Hillbrecht</dc:creator>
    </item>
    <item>
      <title>Asymptotic Stability and Strict Passivity of Port-Hamiltonian Descriptor Systems via State Feedback</title>
      <link>https://arxiv.org/abs/2406.08994</link>
      <description>arXiv:2406.08994v1 Announce Type: new 
Abstract: While port-Hamiltonian descriptor systems are known to be stable and passive, they may not be asymptotically stable or strictly passive. Necessary and sufficient conditions are presented when these properties as well as the regularity and the index one property can be achieved via state feedback while preserving the port-Hamiltonian structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08994v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delin Chu, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>Second Order Shape Optimization for an Interface Identification Problem constrained by Nonlocal Models</title>
      <link>https://arxiv.org/abs/2406.09118</link>
      <description>arXiv:2406.09118v1 Announce Type: new 
Abstract: Since shape optimization methods have been proven useful for identifying interfaces in models governed by partial differential equations, we show how shape optimization techniques can also be applied to an interface identification problem constrained by a nonlocal Dirichlet problem. Here, we focus on deriving the second shape derivative of the corresponding reduced functional and we further investigate a second order optimization algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09118v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matthias Schuster, Volker Schulz</dc:creator>
    </item>
    <item>
      <title>What is the long-run distribution of stochastic gradient descent? A large deviations analysis</title>
      <link>https://arxiv.org/abs/2406.09241</link>
      <description>arXiv:2406.09241v1 Announce Type: new 
Abstract: In this paper, we examine the long-run distribution of stochastic gradient descent (SGD) in general, non-convex problems. Specifically, we seek to understand which regions of the problem's state space are more likely to be visited by SGD, and by how much. Using an approach based on the theory of large deviations and randomly perturbed dynamical systems, we show that the long-run distribution of SGD resembles the Boltzmann-Gibbs distribution of equilibrium thermodynamics with temperature equal to the method's step-size and energy levels determined by the problem's objective and the statistics of the noise. In particular, we show that, in the long run, (a) the problem's critical region is visited exponentially more often than any non-critical region; (b) the iterates of SGD are exponentially concentrated around the problem's minimum energy state (which does not always coincide with the global minimum of the objective); (c) all other connected components of critical points are visited with frequency that is exponentially proportional to their energy level; and, finally (d) any component of local maximizers or saddle points is "dominated" by a component of local minimizers which is visited exponentially more often.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09241v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wa\"iss Azizian, Franck Iutzeler, J\'er\^ome Malick, Panayotis Mertikopoulos</dc:creator>
    </item>
    <item>
      <title>A geometry in the set of solutions to ill-posed linear problems with box constraints: Applications to probabilities on discrete sets</title>
      <link>https://arxiv.org/abs/2406.08513</link>
      <description>arXiv:2406.08513v1 Announce Type: cross 
Abstract: When there are no constraints upon the solutions of the equation $\mathbf{A}\mathbf{\xi}= \mathbf{y},$ where $\mathbf{A}$ is a $K\times N-$matrix, $\mathbf{\xi}\in\mathbb{R}^N$ and $\mathbf{y}\in\mathbb{R}^K$ a given vector, the description of the set of solutions as $\mathbf{y}$ varies in $\mathbb{R}^K$ is well known. But this is not so when the solutions are required to satisfy $\mathbf{\xi} \in \mathcal{K}\prod_{i\leq j\leq N} [a_j,b_j],$ for finite $a_j\leq b_j: 1\leq j\leq N.$ Here we provide a description of the set of solutions as a surface in the constraint set, parameterized by the Lagrange multipliers that come up in a related optimization problem in which $\mathbf{A}\mathbf{\xi} = \mathbf{y}$ appears as a constraint. It is the dependence of the Lagrange multipliers on the data vector $\mathbf{y}$ that determines how the solution changes as the datum changes. The geometry on the solutions is inherited from a Riemannian geometry on the set of constraints induced by the Hessian of an entropy of the Fermi-Dirac type which is the objective in the restatement of the optimization problem mentioned above. We prove that the set of solutions is contained in $\ker(\mathbf{A})^\perp$ in the metric defined as the Hessian of the entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08513v1</guid>
      <category>math.RA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Henryk Gzyl</dc:creator>
    </item>
    <item>
      <title>The Monge-Kantorovich problem on Wasserstein space</title>
      <link>https://arxiv.org/abs/2406.08585</link>
      <description>arXiv:2406.08585v1 Announce Type: cross 
Abstract: We consider the Monge-Kantorovich problem between two random measuress. More precisely, given probability measures $\mathbb{P}_1,\mathbb{P}_2\in\mathcal{P}(\mathcal{P}(M))$ on the space $\mathcal{P}(M)$ of probability measures on a smooth compact manifold, we study the optimal transport problem between $\mathbb{P}_1$ and $\mathbb{P}_2 $ where the cost function is given by the squared Wasserstein distance $W_2^2(\mu,\nu)$ between $\mu,\nu \in \mathcal{P}(M)$. Under appropriate assumptions on $\mathbb{P}_1$, we prove that there exists a unique optimal plan and that it takes the form of an optimal map. An extension of this result to cost functions of the form $h(W_2(\mu,\nu))$, for strictly convex and strictly increasing functions $h$, is also established. The proofs rely heavily on a recent result of Schiavo \cite{schiavo2020rademacher}, which establishes a version of Rademacher's theorem on Wasserstein space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08585v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedram Emami, Brendan Pass</dc:creator>
    </item>
    <item>
      <title>A Game Between Two Identical Dubins Cars: Evading a Conic Sensor in Minimum Time</title>
      <link>https://arxiv.org/abs/2406.08637</link>
      <description>arXiv:2406.08637v1 Announce Type: cross 
Abstract: A fundamental task in mobile robotics is keeping an intelligent agent under surveillance with an autonomous robot as it travels in the environment. This work studies a version of that problem involving one of the most popular vehicle platforms in robotics. In particular, we consider two identical Dubins cars moving on a plane without obstacles. One of them plays as the pursuer, and it is equipped with a limited field-of-view detection region modeled as a semi-infinite cone with its apex at the pursuer's position. The pursuer aims to maintain the other Dubins car, which plays as the evader, as much time as possible inside its detection region. On the contrary, the evader wants to escape as soon as possible. In this work, employing differential game theory, we find the time-optimal motion strategies near the game's end. The analysis of those trajectories reveals the existence of at least two singular surfaces: a Transition Surface and an Evader's Universal Surface. We also found that the barrier's standard construction produces a surface that partially lies outside the playing space and fails to define a closed region, implying that an additional procedure is required to determine all configurations where the evader escapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08637v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ubaldo Ruiz</dc:creator>
    </item>
    <item>
      <title>Large Stepsize Gradient Descent for Non-Homogeneous Two-Layer Networks: Margin Improvement and Fast Optimization</title>
      <link>https://arxiv.org/abs/2406.08654</link>
      <description>arXiv:2406.08654v1 Announce Type: cross 
Abstract: The typical training of neural networks using large stepsize gradient descent (GD) under the logistic loss often involves two distinct phases, where the empirical risk oscillates in the first phase but decreases monotonically in the second phase. We investigate this phenomenon in two-layer networks that satisfy a near-homogeneity condition. We show that the second phase begins once the empirical risk falls below a certain threshold, dependent on the stepsize. Additionally, we show that the normalized margin grows nearly monotonically in the second phase, demonstrating an implicit bias of GD in training non-homogeneous predictors. If the dataset is linearly separable and the derivative of the activation function is bounded away from zero, we show that the average empirical risk decreases, implying that the first phase must stop in finite steps. Finally, we demonstrate that by choosing a suitably large stepsize, GD that undergoes this phase transition is more efficient than GD that monotonically decreases the risk. Our analysis applies to networks of any width, beyond the well-known neural tangent kernel and mean-field regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08654v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Cai, Jingfeng Wu, Song Mei, Michael Lindsey, Peter L. Bartlett</dc:creator>
    </item>
    <item>
      <title>Orthogonalized Estimation of Difference of $Q$-functions</title>
      <link>https://arxiv.org/abs/2406.08697</link>
      <description>arXiv:2406.08697v1 Announce Type: cross 
Abstract: Offline reinforcement learning is important in many settings with available observational data but the inability to deploy new policies online due to safety, cost, and other concerns. Many recent advances in causal inference and machine learning target estimation of causal contrast functions such as CATE, which is sufficient for optimizing decisions and can adapt to potentially smoother structure. We develop a dynamic generalization of the R-learner (Nie and Wager 2021, Lewis and Syrgkanis 2021) for estimating and optimizing the difference of $Q^\pi$-functions, $Q^\pi(s,1)-Q^\pi(s,0)$ (which can be used to optimize multiple-valued actions). We leverage orthogonal estimation to improve convergence rates in the presence of slower nuisance estimation rates and prove consistency of policy optimization under a margin condition. The method can leverage black-box nuisance estimators of the $Q$-function and behavior policy to target estimation of a more structured $Q$-function contrast.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08697v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angela Zhou</dc:creator>
    </item>
    <item>
      <title>Equilibrium Selection for Multi-agent Reinforcement Learning: A Unified Framework</title>
      <link>https://arxiv.org/abs/2406.08844</link>
      <description>arXiv:2406.08844v1 Announce Type: cross 
Abstract: While there are numerous works in multi-agent reinforcement learning (MARL), most of them focus on designing algorithms and proving convergence to a Nash equilibrium (NE) or other equilibrium such as coarse correlated equilibrium. However, NEs can be non-unique and their performance varies drastically. Thus, it is important to design algorithms that converge to Nash equilibrium with better rewards or social welfare. In contrast, classical game theory literature has extensively studied equilibrium selection for multi-agent learning in normal-form games, demonstrating that decentralized learning algorithms can asymptotically converge to potential-maximizing or Pareto-optimal NEs. These insights motivate this paper to investigate equilibrium selection in the MARL setting. We focus on the stochastic game model, leveraging classical equilibrium selection results from normal-form games to propose a unified framework for equilibrium selection in stochastic games. The proposed framework is highly modular and can extend various learning rules and their corresponding equilibrium selection results from normal-form games to the stochastic game setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08844v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Jeff Shamma, Na Li</dc:creator>
    </item>
    <item>
      <title>A continuous model of transportation in the Heisenberg group</title>
      <link>https://arxiv.org/abs/2406.09380</link>
      <description>arXiv:2406.09380v1 Announce Type: cross 
Abstract: We adapt to the Heisenberg group a minimization problem with horizontal divergence-type constraint. We investigate its dual formulation and its connection with the congested optimal transport problem, for $1&lt;p&lt;+\infty$, and the Monge-Kantorovich problem, in the limit case $p=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09380v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Circelli, Albert Clop</dc:creator>
    </item>
    <item>
      <title>Lossless Convexification and Duality</title>
      <link>https://arxiv.org/abs/2108.01457</link>
      <description>arXiv:2108.01457v4 Announce Type: replace 
Abstract: The main goal of this paper is to investigate strong duality of non-convex semidefinite programming problems (SDPs). In the optimization community, it is well-known that a convex optimization problem satisfies strong duality if the Slater's condition holds. However, this result cannot be directly generalized to non-convex problems. In this paper, we prove that a class of non-convex SDPs with special structures satisfies strong duality under the Slater's condition. Such a class of SDPs arises in SDP-based control analysis and design approaches. Throughout the paper, several examples are given to support the proposed results. We expect that the proposed analysis can potentially deepen our understanding of non-convex SDPs arising in the control community, and promote their analysis based on KKT conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.01457v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donghwan Lee</dc:creator>
    </item>
    <item>
      <title>When sampling works in data-driven control: Informativity for stabilization in continuous time</title>
      <link>https://arxiv.org/abs/2301.10873</link>
      <description>arXiv:2301.10873v2 Announce Type: replace 
Abstract: This paper introduces a notion of data informativity for stabilization tailored to continuous-time signals and systems. We establish results comparable to those known for discrete-time systems with sampled data. We justify that additional assumptions on the properties of the noise signals are needed to understand when sampled versions of continuous-time signals are informative for stabilization, thereby introducing the notions of square Lipschitzness and total bounded variation. This allows us to connect the continuous and discrete domains, yielding sufficient conditions to synthesize a stabilizing controller for the true continuous-time system on the basis of sampled data. Simulations illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10873v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaap Eising, Jorge Cortes</dc:creator>
    </item>
    <item>
      <title>On the detection of the presence of malicious components in cyber-physical systems in the almost sure sense</title>
      <link>https://arxiv.org/abs/2306.12516</link>
      <description>arXiv:2306.12516v4 Announce Type: replace 
Abstract: This article studies a fundamental problem of security of cyber-physical systems (CPSs): that of detecting, almost surely, the presence of malicious components in the CPS. We assume that some of the actuators may be malicious while all sensors are honest. We introduce a novel idea of separability of state trajectories generated by CPSs in two situations: those under the nominal no-attack situation and those under the influence of an attacker. We establish its connection to security of CPSs in the context of detecting the presence of malicious actuators (if any) in them. As primary contributions we establish necessary and sufficient conditions for the aforementioned detection in CPSs modeled as Markov decision processes (MDPs). Moreover, we focus on the mechanism of perturbing the pre-determined control policies of the honest agents in CPSs modeled as stochastic linear systems, by injecting a certain class of random process called private excitation; sufficient conditions for detectability and non-detectability of the presence of malicious actuators assuming that the policies are randomized history dependent and randomized Markovian, are established. Several technical aspects of our results are discussed extensively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12516v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Souvik Das, Priyanka Dey, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>On Optimal Control at the Onset of a New Viral Outbreak</title>
      <link>https://arxiv.org/abs/2311.05738</link>
      <description>arXiv:2311.05738v2 Announce Type: replace 
Abstract: We propose a versatile model with a flexible choice of control for an early-pandemic outbreak prevention when vaccine/drug is not yet available. At that stage, control is often limited to non-medical interventions like social distancing and other behavioral changes. For the SIR optimal control problem, we show that the running cost of control satisfying mild, practically justified conditions generates an optimal strategy, $u(t)$, $t \in [0, T]$, that is sustainable up until some moment $\tau \in [0 ,T)$. However, for any $t \in [\tau, T]$, the function $u(t)$ will decline as $t$ approaches $T$, which may cause the number of newly infected people to increase. So, the window from $0$ to $\tau$ is the time for public health officials to prepare alternative mitigation measures, such as vaccines, testing, antiviral medications, and others. In addition to theoretical study, we develop a fast and stable computational method for solving the proposed optimal control problem. The efficiency of the new method is illustrated with numerical examples of optimal control trajectories for various cost functions and weights. Simulation results provide a comprehensive demonstration of the effects of control on the epidemic spread and mitigation expenses, which can serve as invaluable references for public health officials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05738v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandra Smirnova, Xiaojing Ye</dc:creator>
    </item>
    <item>
      <title>Distributions and controllability problems (I)</title>
      <link>https://arxiv.org/abs/2401.07555</link>
      <description>arXiv:2401.07555v2 Announce Type: replace 
Abstract: We consider a non-linear real analytic control system of first order $\dot q^i = f^i(t, q, w)$, with controls $w = (w^\alpha)$ in a connected open set $\mathcal{K} \subset \mathbb{R}^m$ and configurations $q = (q^i)$ in $\mathcal{Q} := \mathbb{R}^n$. The set of points in the extended space-time $\mathcal{M} = \mathbb{R} \times \mathcal{Q} \times \mathcal{K}$, which can be reached from a triple $x_o = (t_o , q_o, w_o) \in \mathcal{M}$ through a continuous graph completion $\gamma(s) = \big(t(s), q(t(s)), w(t(s))\big)$ of the graph of a solution $t \to (q(t), w(t))$, $t \in [t_o ,t_o + T]$, with piecewise real analytic controls, is called the {\it $\mathcal{M}$-attainable set of $x_o$ in time $T$}. We prove that if $y_o$ is an $\mathcal{M}$-attainable point of $x_o$, a large set of other nearby $\mathcal{M}$-attainable points of $x_o$ can be determined starting directly from $y_o$ and applying an appropriate ordered composition of flows of vector fields in a distinguished distribution $\mathcal{D}^{II} \subset T \mathcal{M}$, canonically associated with the control system. We then determine sufficient conditions for such neighbouring points to constitute an orbit of the pseudogroup of local diffeomorphisms generated by the vector fields in $\mathcal{D}^{II}$. If such conditions are satisfied and if the tangent spaces of these orbits have maximal rank projections onto $\mathcal{Q}$, the control system is locally accessible and has the small time local controllability property near the state points of equilibrium. These results lead to new proofs of classical local controllability criterions and yield new methods to establish the accessibility and the small time local controllability of non-linear control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07555v2</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristina Giannotti, Andrea Spiro, Marta Zoppello</dc:creator>
    </item>
    <item>
      <title>Distributions and controllability problems (II)</title>
      <link>https://arxiv.org/abs/2401.07560</link>
      <description>arXiv:2401.07560v2 Announce Type: replace 
Abstract: In [C. Giannotti, A. Spiro, M. Zoppello, {\it Distributions and controllability problems (I)}, preprint posted on ArXiv (2024)], we introduced a new approach to the real analytic non-linear control systems of the form $\dot q^i = f^i(t, q, w)$, with controls $w = (w^\alpha)$ running in a connected open set $\mathcal{K}$ of $ \mathbb{R}^m$ and states represented by points $q = (q^i)$ in a configuration space $\mathcal{Q} := \mathbb{R}^n$. The new approach consists of a differential-geometric study of (a) the oriented piecewise regular curves in the {\it extended space-time} $\mathcal{M} = \mathbb{R} \times \mathcal{Q} \times \mathcal{K}$, which are the (completed) graphs of the piecewise real analytic solutions $t \mapsto (q(t), w(t))$ of the control system, and (b) the local structure of the sets of points of $\mathcal{M}$ that are reachable from an initial point $x_o = (t_o, q_o, w_o) \in \mathcal{M}$ through such (completed) graphs. The main results of that paper are two new criterions which can be used to establish the small time local controllability near stable points of real analytic non-linear systems. The goal of this paper is to offer a friendly user's guide to those criterions, illustrating them by several examples. In particular, we analyse certain non-linear control systems, for which the new criterions show that they are small time locally controllable at their stable points, while, at the best of our knowledge, all other previous criterions are either inconclusive or not applicable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07560v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristina Giannotti, Andrea Spiro, Marta Zoppello</dc:creator>
    </item>
    <item>
      <title>Probabilistic ODE Solvers for Integration Error-Aware Numerical Optimal Control</title>
      <link>https://arxiv.org/abs/2401.17731</link>
      <description>arXiv:2401.17731v2 Announce Type: replace 
Abstract: Appropriate time discretization is crucial for real-time applications of numerical optimal control, such as nonlinear model predictive control. However, if the discretization error strongly depends on the applied control input, meeting accuracy and sampling time requirements simultaneously can be challenging using classical discretization methods. In particular, neither fixed-grid nor adaptive-grid discretizations may be suitable, when they suffer from large integration error or exceed the prescribed sampling time, respectively. In this work, we take a first step at closing this gap by utilizing probabilistic numerical integrators to approximate the solution of the initial value problem, as well as the computational uncertainty associated with it, inside the optimal control problem (OCP). By taking the viewpoint of probabilistic numerics and propagating the numerical uncertainty in the cost, the OCP is reformulated such that the optimal input reduces the computational uncertainty insofar as it is beneficial for the control objective. The proposed approach is illustrated using a numerical example, and potential benefits and limitations are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17731v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amon Lahr, Filip Tronarp, Nathanael Bosch, Jonathan Schmidt, Philipp Hennig, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Control sets on maximal compact subgroups</title>
      <link>https://arxiv.org/abs/2305.07674</link>
      <description>arXiv:2305.07674v2 Announce Type: replace-cross 
Abstract: In this paper we study the action of semigroups with nonempty interior of noncompact connected semisimple Lie groups, with finite center, on their maximal compact connected subgroups. As main results we describe the set of transitivity of a control set as fixed points of regular elements in the semigroup, and determine the number of control sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07674v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mauro Patr\~ao, La\'ercio dos Santos</dc:creator>
    </item>
    <item>
      <title>On the time consistent solution to optimal stopping problems with expectation constraint</title>
      <link>https://arxiv.org/abs/2311.05378</link>
      <description>arXiv:2311.05378v2 Announce Type: replace-cross 
Abstract: We study the (weak) equilibrium problem arising from the problem of optimally stopping a one-dimensional diffusion subject to an expectation constraint on the time until stopping. The weak equilibrium problem is realized with a set of randomized but purely state dependent stopping times as admissible strategies. We derive a verification theorem and necessary conditions for equilibria, which together basically characterize all equilibria. Furthermore, additional structural properties of equilibria are obtained to feed a possible guess-and-verify approach, which is then illustrated by an example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05378v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S\"oren Christensen, Maike Klein, Boy Schultz</dc:creator>
    </item>
    <item>
      <title>Harnessing Membership Function Dynamics for Stability Analysis of T-S Fuzzy Systems</title>
      <link>https://arxiv.org/abs/2401.02216</link>
      <description>arXiv:2401.02216v2 Announce Type: replace-cross 
Abstract: The main goal of this paper is to develop a new linear matrix inequality (LMI) condition for the asymptotic stability of continuous-time Takagi-Sugeno (T-S) fuzzy systems. A key advantage of this new condition is its independence from the bounds on the time-derivatives of the membership functions, a requirement present in the existing approaches. This is achieved by introducing a novel fuzzy Lyapunov function that incorporates an augmented state vector. Notably, this augmented state vector encompasses the membership functions, allowing the dynamics of these functions to be integrated into the proposed condition. This inclusion of additional information about the membership function serves to reduce the conservativeness of the suggested stability condition. To demonstrate the effectiveness of the proposed method, examples are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02216v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donghwan Lee, Do-Wan Kim</dc:creator>
    </item>
    <item>
      <title>Unichain and Aperiodicity are Sufficient for Asymptotic Optimality of Average-Reward Restless Bandits</title>
      <link>https://arxiv.org/abs/2402.05689</link>
      <description>arXiv:2402.05689v2 Announce Type: replace-cross 
Abstract: We consider the infinite-horizon, average-reward restless bandit problem in discrete time. We propose a new class of policies that are designed to drive a progressively larger subset of arms toward the optimal distribution. We show that our policies are asymptotically optimal with an $O(1/\sqrt{N})$ optimality gap for an $N$-armed problem, provided that the single-armed MDP is unichain and aperiodic under the optimal single-armed policy. Our approach departs from most existing work that focuses on index or priority policies, which rely on the Uniform Global Attractor Property (UGAP) to guarantee convergence to the optimum, or a recently developed simulation-based policy, which requires a Synchronization Assumption (SA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05689v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yige Hong, Qiaomin Xie, Yudong Chen, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Predictive Linear Online Tracking for Unknown Targets</title>
      <link>https://arxiv.org/abs/2402.10036</link>
      <description>arXiv:2402.10036v3 Announce Type: replace-cross 
Abstract: In this paper, we study the problem of online tracking in linear control systems, where the objective is to follow a moving target. Unlike classical tracking control, the target is unknown, non-stationary, and its state is revealed sequentially, thus, fitting the framework of online non-stochastic control. We consider the case of quadratic costs and propose a new algorithm, called predictive linear online tracking (PLOT). The algorithm uses recursive least squares with exponential forgetting to learn a time-varying dynamic model of the target. The learned model is used in the optimal policy under the framework of receding horizon control. We show the dynamic regret of PLOT scales with $\mathcal{O}(\sqrt{TV_T})$, where $V_T$ is the total variation of the target dynamics and $T$ is the time horizon. Unlike prior work, our theoretical results hold for non-stationary targets. We implement PLOT on a real quadrotor and provide open-source software, thus, showcasing one of the first successful applications of online control methods on real hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10036v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasios Tsiamis, Aren Karapetyan, Yueshan Li, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>To Cool or not to Cool? Temperature Network Meets Large Foundation Models via DRO</title>
      <link>https://arxiv.org/abs/2404.04575</link>
      <description>arXiv:2404.04575v2 Announce Type: replace-cross 
Abstract: The temperature parameter plays a profound role during training and/or inference with large foundation models (LFMs) such as large language models (LLMs) and CLIP models. Particularly, it adjusts the logits in the softmax function in LLMs, which is crucial for next token generation, and it scales the similarities in the contrastive loss for training CLIP models. A significant question remains: Is it viable to learn a neural network to predict a personalized temperature of any input data for enhancing LFMs"? In this paper, we present a principled framework for learning a small yet generalizable temperature prediction network (TempNet) to improve LFMs. Our solution is composed of a novel learning framework with a robust loss underpinned by constrained distributionally robust optimization (DRO), and a properly designed TempNet with theoretical inspiration. TempNet can be trained together with a large foundation model from scratch or learned separately given a pretrained foundation model. It is not only useful for predicting personalized temperature to promote the training of LFMs but also generalizable and transferable to new tasks. Our experiments on LLMs and CLIP models demonstrate that TempNet greatly improves the performance of existing solutions or models, e.g. Table 1. The code to reproduce the experimental results in this paper can be found at https://github.com/zhqiu/TempNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04575v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zi-Hao Qiu, Siqi Guo, Mao Xu, Tuo Zhao, Lijun Zhang, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Multi-objective Optimization under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2405.19440</link>
      <description>arXiv:2405.19440v2 Announce Type: replace-cross 
Abstract: Multi-objective optimization (MOO) is receiving more attention in various fields such as multi-task learning. Recent works provide some effective algorithms with theoretical analysis but they are limited by the standard $L$-smooth or bounded-gradient assumptions, which are typically unsatisfactory for neural networks, such as recurrent neural networks (RNNs) and transformers. In this paper, we study a more general and realistic class of $\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function of gradient norm. We develop two novel single-loop algorithms for $\ell$-smooth MOO problems, Generalized Smooth Multi-objective Gradient descent (GSMGrad) and its stochastic variant, Stochastic Generalized Smooth Multi-objective Gradient descent (SGSMGrad), which approximate the conflict-avoidant (CA) direction that maximizes the minimum improvement among objectives. We provide a comprehensive convergence analysis of both algorithms and show that they converge to an $\epsilon$-accurate Pareto stationary point with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between the updating direction and the CA direction) over all iterations, where totally $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are needed for deterministic and stochastic settings, respectively. Our algorithms can also guarantee a tighter $\epsilon$-level CA distance in each iteration using more samples. Moreover, we propose a practical variant of GSMGrad named GSMGrad-FA using only constant-level time and space, while achieving the same performance guarantee as GSMGrad. Our experiments validate our theory and demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19440v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Peiyao Xiao, Kaiyi Ji, Shaofeng Zou</dc:creator>
    </item>
    <item>
      <title>Local Methods with Adaptivity via Scaling</title>
      <link>https://arxiv.org/abs/2406.00846</link>
      <description>arXiv:2406.00846v2 Announce Type: replace-cross 
Abstract: The rapid development of machine learning and deep learning has introduced increasingly complex optimization challenges that must be addressed. Indeed, training modern, advanced models has become difficult to implement without leveraging multiple computing nodes in a distributed environment. Distributed optimization is also fundamental to emerging fields such as federated learning. Specifically, there is a need to organize the training process to minimize the time lost due to communication. A widely used and extensively researched technique to mitigate the communication bottleneck involves performing local training before communication. This approach is the focus of our paper. Concurrently, adaptive methods that incorporate scaling, notably led by Adam, have gained significant popularity in recent years. Therefore, this paper aims to merge the local training technique with the adaptive approach to develop efficient distributed learning methods. We consider the classical Local SGD method and enhance it with a scaling feature. A crucial aspect is that the scaling is described generically, allowing us to analyze various approaches, including Adam, RMSProp, and OASIS, in a unified manner. In addition to theoretical analysis, we validate the performance of our methods in practice by training a neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00846v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Savelii Chezhegov, Sergey Skorik, Nikolas Khachaturov, Danil Shalagin, Aram Avetisyan, Aleksandr Beznosikov, Martin Tak\'a\v{c}, Yaroslav Kholodov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Positive definiteness of fourth order three dimensional symmetric tensors</title>
      <link>https://arxiv.org/abs/2406.04010</link>
      <description>arXiv:2406.04010v2 Announce Type: replace-cross 
Abstract: For a 4th order 3-dimensional symmetric tensor with its entries $1$ or $-1$, we show the analytic sufficient and necessary conditions of its positive definiteness. By applying these conclusions, several strict inequalities is bulit for ternary quartic homogeneous polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04010v2</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yisheng Song</dc:creator>
    </item>
  </channel>
</rss>
