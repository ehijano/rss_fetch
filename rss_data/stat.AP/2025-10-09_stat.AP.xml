<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 04:01:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Modeling and forecasting of European Carbon Emission Allowance futures by ARIMA-TX-GARCH models with correlation threshold</title>
      <link>https://arxiv.org/abs/2510.07568</link>
      <description>arXiv:2510.07568v1 Announce Type: new 
Abstract: We propose an ARIMA-TX-GARCH model and use it to forecast European Carbon Emission Allowance futures prices, incorporating Brent crude oil futures prices as an exogenous variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07568v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaeho Lee, Eunju Hwang</dc:creator>
    </item>
    <item>
      <title>Large-scale spatial variable gene atlas for spatial transcriptomics</title>
      <link>https://arxiv.org/abs/2510.07653</link>
      <description>arXiv:2510.07653v1 Announce Type: new 
Abstract: Spatial variable genes (SVGs) reveal critical information about tissue architecture, cellular interactions, and disease microenvironments. As spatial transcriptomics (ST) technologies proliferate, accurately identifying SVGs across diverse platforms, tissue types, and disease contexts has become both a major opportunity and a significant computational challenge. Here, we present a comprehensive benchmarking study of 20 state-of-the-art SVG detection methods using human slides from STimage-1K4M, a large-scale resource of ST data comprising 662 slides from more than 18 tissue types. We evaluate each method across a range of biologically and technically meaningful criteria, including recovery of pathologist-annotated domain-specific markers, cross-slide reproducibility, scalability to high-resolution data, and robustness to technical variation. Our results reveal marked differences in performance depending on tissue type, spatial resolution, and study design. Beyond benchmarking, we construct the first cross-tissue atlas of SVGs, enabling comparative analysis of spatial gene programs across cancer and normal tissues. We observe similarities between pairs of tissues that reflect developmental and functional relationships, such as high overlap between thymus and lymph node, and uncover spatial gene programs associated with metastasis, immune infiltration, and tissue-of-origin identity in cancer. Together, our work defines a framework for evaluating and interpreting spatial gene expression and establishes a reference resource for the ST community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07653v1</guid>
      <category>stat.AP</category>
      <category>cs.DB</category>
      <category>q-bio.GN</category>
      <category>q-bio.TO</category>
      <category>stat.CO</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawen Chen, Jinwei Zhang, Dongshen Peng, Yutong Song, Aitong Ruan, Yun Li, Didong Li</dc:creator>
    </item>
    <item>
      <title>Evaluating multi-season occupancy models with autocorrelation fitted to heterogeneous datasets</title>
      <link>https://arxiv.org/abs/2510.08151</link>
      <description>arXiv:2510.08151v1 Announce Type: new 
Abstract: Predicting species distributions using occupancy models accounting for imperfect detection is now commonplace in ecology. Recently, modelling spatial and temporal autocorrelation was proposed to alleviate the lack of replication in occupancy data, which often prevents model identifiability. However, how such models perform in highly heterogeneous datasets where missing or single-visit data dominates remains an open question. Motivated by an heterogeneous fine-scale butterfly occupancy dataset, we evaluate the performance of a multi-season occupancy model with spatial and temporal random effects to a skewed (Poisson) distribution of the number of surveys per site, overlap of covariates between occupancy and detection submodels, and spatiotemporal clustering of observations. Results showed that the model is robust to heterogeneous data and covariate overlap. However, when spatiotemporal gaps were added, site occupancy was biased towards the average occupancy, itself overestimated. Random effects did not correct the influence of gaps, due to identifiability issues of variance and autocorrelation parameters. Occupancy analysis of two butterfly species further confirmed these results. Overall, multi-season occupancy models with autocorrelation are robust to heterogeneous data and covariate overlap, but still present identifiability issues and are challenged by severe data gaps, which compromise predictions even in data-rich areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08151v1</guid>
      <category>stat.AP</category>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'e Lu\'is Luza, Didier Alard, Fr\'ed\'eric Barraquand</dc:creator>
    </item>
    <item>
      <title>Two-Stage Trigonometric Regression for Modeling Circadian Rhythms</title>
      <link>https://arxiv.org/abs/2510.08309</link>
      <description>arXiv:2510.08309v1 Announce Type: new 
Abstract: Gene expression levels, hormone secretion, and internal body temperature each oscillate over an approximately 24-hour cycle, or display circadian rhythms. Many circadian biology studies have investigated how these rhythms vary across cohorts, uncovering associations between atypical rhythms and diseases such as cancer, metabolic syndrome, and sleep disorders. A challenge in analyzing circadian biology data is that the oscillation peak and trough times for a phenomenon differ across individuals. If these individual-level differences are not accounted for in trigonometric regression, which is prevalent in circadian biology studies, then estimates of the population-level amplitude parameters can suffer from attenuation bias. This attenuation bias could lead to inaccurate study conclusions. To address attenuation bias, we propose a refined two-stage (RTS) method for trigonometric regression given longitudinal data obtained from each individual participating in a study. In the first stage, the parameters of individual-level models are estimated. In the second stage, transformations of these individual-level estimates are aggregated to produce population-level parameter estimates for inference. Simulation studies show that our RTS method mitigates bias in parameter estimation, obtains greater statistical power, and maintains appropriate type I error control when compared to the standard two-stage (STS) method, which ignores individual-level differences in peak and trough times. The only exception for parameter estimation and statistical power occurs when the oscillation amplitudes are weak relative to random variability in the data and the sample size is small. Illustrations with cortisol level data and heart rate data show that our RTS method obtains larger population-level amplitude parameter estimates and smaller $p$-values for multiple hypothesis tests when compared to the STS method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08309v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael T. Gorczyca, Jenna D. Li, Charissa M. Newkirk, Arjun S. Srivatsa, Hugo F. M. Milan</dc:creator>
    </item>
    <item>
      <title>Monthly Rural-Urban Scaling of Road Accidents in England, Wales and Scotland (2019-2023)</title>
      <link>https://arxiv.org/abs/2510.07351</link>
      <description>arXiv:2510.07351v1 Announce Type: cross 
Abstract: Road traffic accidents remain a major public health challenge worldwide, with urbanisation and population density identified as key factors influencing risk. This study analyses monthly accident data from 2009 to 2023 across 632 parliamentary constituencies in England, Wales, and Scotland, using an area-normalised approach based on population density. Segmented power law models consistently identified breakpoints separating sublinear rural from superlinear urban scaling behaviours. Seasonal variation in scaling exponents was pronounced in rural regions but less evident in urban ones. Fourier-based cross-spectral analysis of yearly cycles revealed systematic phase shifts: rural exponents lagged pre-exponential factors by 4.5 months, while urban exponents were 2.7 months out of phase, producing a 5.3 month shift between rural and urban exponents. These findings highlight the importance of pre-exponentials-defined as the expected density of accidents at unit population density-as comparable descaled metrics, revealing both long-term national declines and recurring seasonal peaks. Notably, the phase offsets suggest structurally distinct causes of rural and urban accident risk, with urban regions exhibiting increasing acceleration in accident scaling, potentially linked to growth in vehicle numbers, size, and weight. Residuals, modelled with the Type I Generalised Logistic Distribution (GLD), captured skewness and heterogeneity more effectively than normal assumptions. Geospatial mapping highlighted persistent urban hotspots alongside rural and coastal constituencies with systematically lower accident densities than predicted. Together, these findings advance understanding of how density and urbanisation shape accident risk and provide evidence to support more targeted road safety interventions and policy planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07351v1</guid>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Isabel Copsey, Quentin Hanley, Jack Sutton</dc:creator>
    </item>
    <item>
      <title>Zero-Inflated Bayesian Multi-Study Infinite Non-Negative Matrix Factorization</title>
      <link>https://arxiv.org/abs/2510.07518</link>
      <description>arXiv:2510.07518v1 Announce Type: cross 
Abstract: Understanding the association between dietary patterns and health outcomes, such as the cancer risk, is crucial to inform public health guidelines and shaping future dietary interventions. However, dietary intake data present several statistical challenges: they are high-dimensional, often sparse with excess zeros, and exhibit heterogeneity driven by individual-level covariates. Non-Negative Matrix Factorization (NMF), commonly used to estimate patterns in high-dimensional count data, typically relies on Poisson assumptions and lacks the flexibility to fully address these complexities. Additionally, integrating data across multiple studies, such as case-control studies on cancer risk, requires models that can share information across sources while preserving study-specific structure.
  In this paper, we introduce a novel Bayesian NMF model that (i) jointly models multi-study count data to enable cross-study information sharing, (ii) incorporate a mixture component to account for zero inflation, and (iii) leverage flexible Bayesian non-parametric priors for characterizing the heterogeneity in pattern scores induced by the individual covariates. This structure allows for clustering of individuals based on dietary profiles, enabling downstream association analyses with health outcomes. Through extensive simulation studies, we demonstrate that our model significantly improves estimation accuracy compared to existing Bayesian NMF methods.
  We further illustrate its utility through an application to multiple case-control studies on diet and upper aero-digestive tract cancers, identifying nutritionally meaningful dietary patterns. An R package implementing our approach is available at https://github.com/blhansen/ZIMultiStudyNMF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07518v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Blake Hansen, Dafne Zorzetto, Valeria Edefonti, Roberta De Vito</dc:creator>
    </item>
    <item>
      <title>A Honest Cross-Validation Estimator for Prediction Performance</title>
      <link>https://arxiv.org/abs/2510.07649</link>
      <description>arXiv:2510.07649v1 Announce Type: cross 
Abstract: Cross-validation is a standard tool for obtaining a honest assessment of the performance of a prediction model. The commonly used version repeatedly splits data, trains the prediction model on the training set, evaluates the model performance on the test set, and averages the model performance across different data splits. A well-known criticism is that such cross-validation procedure does not directly estimate the performance of the particular model recommended for future use. In this paper, we propose a new method to estimate the performance of a model trained on a specific (random) training set. A naive estimator can be obtained by applying the model to a disjoint testing set. Surprisingly, cross-validation estimators computed from other random splits can be used to improve this naive estimator within a random-effects model framework. We develop two estimators -- a hierarchical Bayesian estimator and an empirical Bayes estimator -- that perform similarly to or better than both the conventional cross-validation estimator and the naive single-split estimator. Simulations and a real-data example demonstrate the superior performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07649v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Pan, Vincent Z. Yu, Viswanath Devanarayan, Lu Tian</dc:creator>
    </item>
    <item>
      <title>A weighted-likelihood framework for class imbalance in Bayesian prediction models</title>
      <link>https://arxiv.org/abs/2504.17013</link>
      <description>arXiv:2504.17013v2 Announce Type: replace 
Abstract: Class imbalance is a pervasive problem in predictive toxicology, where the number of non-toxic compounds often exceeds the number of toxic ones. Models trained on such data often perform well on the majority class but poorly on the minority class, which is most relevant for safety assessment. We propose a simple and general Bayesian framework that addresses class imbalance by modifying the likelihood function. Each observation's likelihood is raised to a power inversely proportional to its class proportion, with the weights normalized to preserve the overall information content. This weighted-likelihood (or power-likelihood) approach embeds cost-sensitive learning directly into Bayesian updating. The method is demonstrated using simulated binary data and an ordered logistic model for drug-induced liver injury (DILI). Weighting alters parameter estimates and decision boundaries, improving balanced accuracy and sensitivity for the minority (toxic) class. The approach can be implemented with minimal changes in standard probabilistic programming languages such as Stan, PyMC, and Turing.jl. This framework provides an easily extensible foundation for developing Bayesian prediction models that better reflect the asymmetric costs of safety-critical decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17013v2</guid>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Stanley E. Lazic</dc:creator>
    </item>
    <item>
      <title>Efficient Inference in First Passage Time Models</title>
      <link>https://arxiv.org/abs/2503.18381</link>
      <description>arXiv:2503.18381v2 Announce Type: replace-cross 
Abstract: First passage time models describe the time it takes for a random process to exit a region of interest and are widely used across various scientific fields. Fast and accurate numerical methods for computing the likelihood function in these models are essential for efficient statistical inference of model parameters. Specifically, in computational cognitive neuroscience, generalized drift diffusion models (GDDMs) are an important class of first passage time models that describe the latent psychological processes underlying simple decision-making scenarios. GDDMs model the joint distribution over choices and response times as the first hitting time of a one-dimensional stochastic differential equation (SDE) to possibly time-varying upper and lower boundaries. They are widely applied to extract parameters associated with distinct cognitive and neural mechanisms. However, current likelihood computation methods struggle in common application scenarios in which drift rates dynamically vary within trials as a function of exogenous covariates (e.g., brain activity in specific regions or visual fixations). In this work, we propose a fast and flexible algorithm for computing the likelihood function of GDDMs based on a large class of SDEs satisfying the Cherkasov condition. Our method divides each trial into discrete stages, employs fast analytical results to compute stage-wise densities, and integrates these to compute the overall trial-wise likelihood. Numerical examples demonstrate that our method not only yields accurate likelihood evaluations for efficient statistical inference, but also considerably outperforms existing approaches in terms of speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18381v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 10 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sicheng Liu, Alexander Fengler, Michael J. Frank, Matthew T. Harrison</dc:creator>
    </item>
  </channel>
</rss>
