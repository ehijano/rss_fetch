<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2025 03:03:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries</title>
      <link>https://arxiv.org/abs/2512.21499</link>
      <description>arXiv:2512.21499v1 Announce Type: new 
Abstract: We revisit the task of releasing marginal queries under differential privacy with additive (correlated) Gaussian noise. We first give a construction for answering arbitrary workloads of weighted marginal queries, over arbitrary domains. Our technique is based on releasing queries in the Fourier basis with independent noise with carefully calibrated variances, and reconstructing the marginal query answers using the inverse Fourier transform. We show that our algorithm, which is a factorization mechanism, is exactly optimal among all factorization mechanisms, both for minimizing the sum of weighted noise variances, and for minimizing the maximum noise variance. Unlike algorithms based on optimizing over all factorization mechanisms via semidefinite programming, our mechanism runs in time polynomial in the dataset and the output size. This construction recovers results of Xiao et al. [Neurips 2023] with a simpler algorithm and optimality proof, and a better running time.
  We then extend our approach to a generalization of marginals which we refer to as product queries. We show that our algorithm is still exactly optimal for this more general class of queries. Finally, we show how to embed extended marginal queries, which allow using a threshold predicate on numerical attributes, into product queries. We show that our mechanism is almost optimal among all factorization mechanisms for extended marginals, in the sense that it achieves the optimal (maximum or average) noise variance up to lower order terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21499v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic Spectral Sparsification for Directed Hypergraphs</title>
      <link>https://arxiv.org/abs/2512.21671</link>
      <description>arXiv:2512.21671v1 Announce Type: new 
Abstract: There has been a surge of interest in spectral hypergraph sparsification, a natural generalization of spectral sparsification for graphs. In this paper, we present a simple fully dynamic algorithm for maintaining spectral hypergraph sparsifiers of \textit{directed} hypergraphs. Our algorithm achieves a near-optimal size of $O(n^2 / \varepsilon ^2 \log ^7 m)$ and amortized update time of $O(r^2 \log ^3 m)$, where $n$ is the number of vertices, and $m$ and $r$ respectively upper bound the number of hyperedges and the rank of the hypergraph at any time.
  We also extend our approach to the parallel batch-dynamic setting, where a batch of any $k$ hyperedge insertions or deletions can be processed with $O(kr^2 \log ^3 m)$ amortized work and $O(\log ^2 m)$ depth. This constitutes the first spectral-based sparsification algorithm in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21671v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Forster, Gramoz Goranci, Ali Momeni</dc:creator>
    </item>
    <item>
      <title>A 58-Addition, Rank-23 Scheme for General 3x3 Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2512.21980</link>
      <description>arXiv:2512.21980v1 Announce Type: new 
Abstract: This paper presents a new state-of-the-art algorithm for exact $3\times3$ matrix multiplication over general non-commutative rings, achieving a rank-23 scheme with only 58 scalar additions. This improves the previous best additive complexity of 60 additions without a change of basis. The result was discovered through an automated search combining ternary-restricted flip-graph exploration with greedy intersection reduction for common subexpression elimination. The resulting scheme uses only coefficients from $\{-1, 0, 1\}$, ensuring both efficiency and portability across arbitrary fields. The total scalar operation count is reduced from 83 to 81.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21980v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. I. Perminov</dc:creator>
    </item>
    <item>
      <title>BLEST: Blazingly Efficient BFS using Tensor Cores</title>
      <link>https://arxiv.org/abs/2512.21967</link>
      <description>arXiv:2512.21967v1 Announce Type: cross 
Abstract: Breadth-First Search (BFS) is a fundamental graph kernel that underpins a wide range of applications. While modern GPUs provide specialised Matrix-Multiply-Accumulate (MMA) units, e.g., Tensor Cores (TC), with extremely high throughput, they target dense operations, making it non-trivial to exploit them for irregular, unstructured graph computations. In particular, fully utilising them for a BFS requires an efficient mapping of the edge operations onto TCs while avoiding redundancy, load imbalance, and synchronisation. We present BLEST, a TC-accelerated framework that reformulates the pull-based BFS pipeline around a bitmap-oriented structure and a carefully engineered execution layout. BLEST introduces Binarised Virtual Slice Sets (BVSS) to enforce warp-level load balancing and to eliminate frontier-oblivious work assignment. To improve both memory efficiency and update locality across diverse graphs, we apply two complementary graph reordering strategies: a compression-oriented ordering for social-like graphs and a bandwidth-reducing ordering for non-social graphs. At the compute level, we develop a batched SpMSpV multiplication pattern that uses the bitwise TC tiles to handle dot products without wasting output entries, thereby reducing the number of required MMA calls. Finally, BLEST combines kernel fusion with a lazy vertex update scheme to reduce host-side synchronisation, mitigate atomic overheads, and improve cache locality. Experiments show that BLEST delivers, on average, $3.58\times$, $4.64\times$ and $4.9\times$ speedup over BerryBees, Gunrock, and GSWITCH, respectively, across a broad set of real-world graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21967v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deniz Elbek, Kamer Kaya</dc:creator>
    </item>
    <item>
      <title>Matroid Intersection under Minimum Rank Oracle</title>
      <link>https://arxiv.org/abs/2407.03229</link>
      <description>arXiv:2407.03229v2 Announce Type: replace 
Abstract: In this paper, we consider the tractability of the matroid intersection problem under the minimum rank oracle. In this model, we are given an oracle that takes as its input a set of elements and returns as its output the minimum of the ranks of the given set in the two matroids. For the unweighted matroid intersection problem, we show how to construct a necessary part of the exchangeability graph, which enables us to emulate the standard augmenting path algorithm. For the weighted problem, the tractability is open in general. Nevertheless, we describe several special cases where tractability can be achieved, and we discuss potential approaches and the challenges encountered.
  On the positive side, we present a solution for the case where no circuit of one matroid is contained within a circuit of the other. Additionally, we propose a fixed-parameter tractable algorithm, parameterized by the maximum size of a circuit of one matroid. We also show that a lexicographically maximal common independent set can be found by the same approach, which leads to a nontrivial approximation ratio for finding a maximum-weight common independent set. On the negative side, we prove that the approach employed for the tractable cases above involves an NP-hard problem in the general case. We also show that if we consider the generalization to polymatroid intersection, even the unweighted problem is hard under the minimum rank oracle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03229v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mih\'aly B\'ar\'asz, Krist\'of B\'erczi, Tam\'as Kir\'aly, Taihei Oki, Yutaro Yamaguchi, Yu Yokoi</dc:creator>
    </item>
    <item>
      <title>Multi-Pass Streaming Lower Bounds for Uniformity Testing</title>
      <link>https://arxiv.org/abs/2511.03960</link>
      <description>arXiv:2511.03960v2 Announce Type: replace 
Abstract: We prove multi-pass streaming lower bounds for uniformity testing over a domain of size $2m$. The tester receives a stream of $n$ i.i.d. samples and must distinguish (i) the uniform distribution on $[2m]$ from (ii) a Paninski-style planted distribution in which, for each pair $(2i-1,2i)$, the probabilities are biased left or right by $\epsilon/2m$. We show that any $\ell$-pass streaming algorithm using space $s$ and achieving constant advantage must satisfy the tradeoff $sn\ell=\tilde{\Omega}(m/\epsilon^2)$. This extends the one-pass lower bound of Diakonikolas, Gouleakis, Kane, and Rao (2019) to multiple passes.
  Our proof has two components. First, we develop a hybrid argument, inspired by Dinur (2020), that reduces streaming to two-player communication problems. This reduction relies on a new perspective on hardness: we identify the source of hardness as uncertainty in the bias directions, rather than the collision locations. Second, we prove a strong lower bound for a basic two-player communication task, in which Alice and Bob must decide whether two random sign vectors $Y^a,Y^b\in\{\pm 1\}^m$ are independent or identical, yet they cannot observe the signs directly--only noisy local views of each coordinate. Our techniques may be of independent use for other streaming problems with stochastic inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03960v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Li, Xin Lyu</dc:creator>
    </item>
    <item>
      <title>Merging RLBWTs adaptively</title>
      <link>https://arxiv.org/abs/2511.16953</link>
      <description>arXiv:2511.16953v3 Announce Type: replace 
Abstract: We show how we can merge two run-length compressed Burrows-Wheeler Transforms (RLBWTs) into a run-length compressed extended Burrows-Wheeler Transform (eBWT) in $O (r)$ space and $O ((r + L) \log (m + n))$ time, where $m$ and $n$ are the lengths of the uncompressed strings, $r$ is the number of runs in the final eBWT and $L$ is the sum of the longest common prefix (LCP) values at the beginnings of those runs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16953v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Precomputed Dominant Resource Fairness</title>
      <link>https://arxiv.org/abs/2507.08846</link>
      <description>arXiv:2507.08846v4 Announce Type: replace-cross 
Abstract: Although resource allocation is a well studied problem in computer science, until the prevalence of distributed systems, such as computing clouds and data centres, the question had been addressed predominantly for single resource type scenarios. At the beginning of the last decade, with the introuction of Dominant Resource Fairness, the studies of the resource allocation problem has finally extended to the multiple resource type scenarios. Dominant Resource Fairness is a solution, addressing the problem of fair allocation of multiple resource types, among users with heterogeneous demands. Based on Max-min Fairness, which is a well established algorithm in the literature for allocating resources in the single resource type scenarios, Dominant Resource Fairness generalises the scheme to the multiple resource case. It has a number of desirable properties that makes it preferable over alternatives, such as Sharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness, and as such, it is widely adopted in distributed systems. In the present study, we revisit the original study, and analyse the structure of the algorithm in closer view, to come up with an alternative algorithm, which approximates the Dominant Resource Fairness allocation in fewer steps. We name the new algorithm Precomputed Dominant Resource Fairness, after its main working principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08846v4</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serdar Metin</dc:creator>
    </item>
    <item>
      <title>ESCHER: Efficient and Scalable Hypergraph Evolution Representation with Application to Triad Counting</title>
      <link>https://arxiv.org/abs/2512.21009</link>
      <description>arXiv:2512.21009v2 Announce Type: replace-cross 
Abstract: Higher-order interactions beyond pairwise relationships in large complex networks are often modeled as hypergraphs. Analyzing hypergraph properties such as triad counts is essential, as hypergraphs can reveal intricate group interaction patterns that conventional graphs fail to capture. In real-world scenarios, these networks are often large and dynamic, introducing significant computational challenges. Due to the absence of specialized software packages and data structures, the analysis of large dynamic hypergraphs remains largely unexplored. Motivated by this gap, we propose ESCHER, a GPU-centric parallel data structure for Efficient and Scalable Hypergraph Evolution Representation, designed to manage large scale hypergraph dynamics efficiently. We also design a hypergraph triad-count update framework that minimizes redundant computation while fully leveraging the capabilities of ESCHER for dynamic operations. We validate the efficacy of our approach across multiple categories of hypergraph triad counting, including hyperedge-based, incident-vertex-based, and temporal triads. Empirical results on both large real-world and synthetic datasets demonstrate that our proposed method outperforms existing state-of-the-art methods, achieving speedups of up to 104.5x, 473.7x, and 112.5x for hyperedge-based, incident-vertex-based, and temporal triad types, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21009v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 29 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. M. Shovan, Arindam Khanda, Sanjukta Bhowmick, Sajal K. Das</dc:creator>
    </item>
  </channel>
</rss>
