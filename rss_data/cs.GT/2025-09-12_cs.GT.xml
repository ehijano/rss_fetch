<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Sep 2025 04:00:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic Paradigm for Defense and Dominance</title>
      <link>https://arxiv.org/abs/2509.08976</link>
      <description>arXiv:2509.08976v1 Announce Type: new 
Abstract: Cyber warfare has become a central element of modern conflict, especially within multi-domain operations. As both a distinct and critical domain, cyber warfare requires integrating defensive and offensive technologies into coherent strategies. While prior research has emphasized isolated tactics or fragmented technologies, a holistic understanding is essential for effective resource deployment and risk mitigation. Game theory offers a unifying framework for this purpose. It not only models attacker-defender interactions but also provides quantitative tools for equilibrium analysis, risk assessment, and strategic reasoning. Integrated with modern AI techniques, game-theoretic models enable the design and optimization of strategies across multiple levels of cyber warfare, from policy and strategy to operations, tactics, and technical implementations. These models capture the paradoxical logic of conflict, where more resources do not always translate into greater advantage, and where nonlinear dynamics govern outcomes. To illustrate the approach, this chapter examines RedCyber, a synthetic cyber conflict, demonstrating how game-theoretic methods capture the interdependencies of cyber operations. The chapter concludes with directions for future research on resilience, cros-echelon planning, and the evolving role of AI in cyber warfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08976v1</guid>
      <category>cs.GT</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-Ting Yang, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Persuasion Gains and Losses from Peer Communication</title>
      <link>https://arxiv.org/abs/2509.09099</link>
      <description>arXiv:2509.09099v1 Announce Type: new 
Abstract: We study a Bayesian persuasion setting in which a sender wants to persuade a critical mass of receivers by revealing partial information about the state to them. The homogeneous binary-action receivers are located on a communication network, and each observes the private messages sent to them and their immediate neighbors. We examine how the sender's expected utility varies with increased communication among receivers. We show that for general families of networks, extending the network can strictly benefit the sender. Thus, the sender's gain from persuasion is not monotonic in network density. Moreover, many network extensions can achieve the upper bound on the sender's expected utility among all networks, which corresponds to the payoff in an empty network. This is the case in networks reflecting a clear informational hierarchy (e.g., in global corporations), as well as in decentralized networks in which information originates from multiple sources (e.g., influencers in social media). Finally, we show that a slight modification to the structure of some of these networks precludes the possibility of such beneficial extensions. Overall, our results caution against presuming that more communication necessarily leads to better collective outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09099v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toygar T. Kerman, Anastas P. Tenev, Konstantin Zabarnyi</dc:creator>
    </item>
    <item>
      <title>Mechanism Design with Outliers and Predictions</title>
      <link>https://arxiv.org/abs/2509.09561</link>
      <description>arXiv:2509.09561v1 Announce Type: new 
Abstract: We initiate the study of mechanism design with outliers, where the designer can discard $z$ agents from the social cost objective. This setting is particularly relevant when some agents exhibit extreme or atypical preferences. As a natural case study, we consider facility location on the line: $n$ strategic agents report their preferred locations, and a mechanism places a facility to minimize a social cost function. In our setting, the $z$ agents farthest from the chosen facility are excluded from the social cost. While it may seem intuitive that discarding outliers improves efficiency, our results reveal that the opposite can hold.
  We derive tight bounds for deterministic strategyproof mechanisms under the two most-studied objectives: utilitarian and egalitarian social cost. Our results offer a comprehensive view of the impact of outliers. We first show that when $z \ge n/2$, no strategyproof mechanism can achieve a bounded approximation for either objective. For egalitarian cost, selecting the $(z + 1)$-th order statistic is strategyproof and 2-approximate. In fact, we show that this is best possible by providing a matching lower bound. Notably, this lower bound of 2 persists even when the mechanism has access to a prediction of the optimal location, in stark contrast to the setting without outliers. For utilitarian cost, we show that strategyproof mechanisms cannot effectively exploit outliers, leading to the counterintuitive outcome that approximation guarantees worsen as the number of outliers increases. However, in this case, access to a prediction allows us to design a strategyproof mechanism achieving the best possible trade-off between consistency and robustness. Finally, we also establish lower bounds for randomized mechanisms that are truthful in expectation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09561v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argyrios Deligkas, Eduard Eiben, Sophie Klumper, Guido Sch\"afer, Artem Tsikiridis</dc:creator>
    </item>
    <item>
      <title>Maximizing social welfare among EF1 allocations at the presence of two types of agents</title>
      <link>https://arxiv.org/abs/2509.09641</link>
      <description>arXiv:2509.09641v1 Announce Type: new 
Abstract: We study the fair allocation of indivisible items to $n$ agents to maximize the utilitarian social welfare, where the fairness criterion is envy-free up to one item and there are only two different utility functions shared by the agents. We present a $2$-approximation algorithm when the two utility functions are normalized, improving the previous best ratio of $16 \sqrt{n}$ shown for general normalized utility functions; thus this constant ratio approximation algorithm confirms the APX-completeness in this special case previously shown APX-hard. When there are only three agents, i.e., $n = 3$, the previous best ratio is $3$ shown for general utility functions, and we present an improved and tight $\frac 53$-approximation algorithm when the two utility functions are normalized, and a best possible and tight $2$-approximation algorithm when the two utility functions are unnormalized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09641v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaxuan Ma, Yong Chen, Guangting Chen, Mingyang Gong, Guohui Lin, An Zhang</dc:creator>
    </item>
    <item>
      <title>Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games</title>
      <link>https://arxiv.org/abs/2509.09071</link>
      <description>arXiv:2509.09071v1 Announce Type: cross 
Abstract: Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09071v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Crystal Qian, Kehang Zhu, John Horton, Benjamin S. Manning, Vivian Tsai, James Wexler, Nithum Thain</dc:creator>
    </item>
    <item>
      <title>Discrepancy Beyond Additive Functions with Applications to Fair Division</title>
      <link>https://arxiv.org/abs/2509.09252</link>
      <description>arXiv:2509.09252v1 Announce Type: cross 
Abstract: We consider a setting where we have a ground set $M$ together with real-valued set functions $f_1, \dots, f_n$, and the goal is to partition $M$ into two sets $S_1,S_2$ such that $|f_i(S_1) - f_i(S_2)|$ is small for every $i$. Many results in discrepancy theory can be stated in this form with the functions $f_i$ being additive. In this work, we initiate the study of the unstructured case where $f_i$ is not assumed to be additive. We show that even without the additivity assumption, the upper bound remains at most $O(\sqrt{n \log n})$.
  Our result has implications on the fair allocation of indivisible goods. In particular, we show that a consensus halving up to $O(\sqrt{n \log n})$ goods always exists for $n$ agents with monotone utilities. Previously, only an $O(n)$ bound was known for this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09252v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandros Hollender, Pasin Manurangsi, Raghu Meka, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>Completeness of coalition logics with seriality, independence of agents, or determinism</title>
      <link>https://arxiv.org/abs/2409.14635</link>
      <description>arXiv:2409.14635v2 Announce Type: replace 
Abstract: Coalition Logic is a central logic in logical research on strategic reasoning. In a recent paper, Li and Ju argued that generally, models of Coalition Logic, concurrent game models, have three too strong assumptions: seriality, independence of agents, and determinism. They presented a Minimal Coalition Logic based on general concurrent game models, which do not have the three assumptions. However, when constructing coalition logics about strategic reasoning in special kinds of situations, we may want to keep some of the assumptions. Thus, studying coalition logics with some of these assumptions makes good sense. In this paper, we show the completeness of these coalition logics in a uniform way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14635v2</guid>
      <category>cs.GT</category>
      <category>math.LO</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinfeng Li, Fengkui Ju</dc:creator>
    </item>
    <item>
      <title>Efficiently Computing Equilibria in Budget-Aggregation Games</title>
      <link>https://arxiv.org/abs/2509.08767</link>
      <description>arXiv:2509.08767v2 Announce Type: replace 
Abstract: Budget aggregation deals with the social choice problem of distributing an exogenously given budget among a set of public projects, given agents' preferences. Taking a game-theoretic perspective, we initialize the study of budget-aggregation games where each agent has virtual decision power over some fraction of the budget. This paper investigates the structure and shows efficient computability of Nash equilibria in this setting for various preference models. In particular, we show that Nash equilibria for Leontief utilities can be found in polynomial time, solving an open problem from Brandt et al. [2023].</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08767v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Becker, Alexander Fries, Matthias Greger, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Optimal Single-Choice Prophet Inequalities from Samples</title>
      <link>https://arxiv.org/abs/1911.07945</link>
      <description>arXiv:1911.07945v2 Announce Type: replace-cross 
Abstract: We study the single-choice Prophet Inequality problem when the gambler is given access to samples. We show that the optimal competitive ratio of $1/2$ can be achieved with a single sample from each distribution. When the distributions are identical, we show that for any constant $\varepsilon &gt; 0$, $O(n)$ samples from the distribution suffice to achieve the optimal competitive ratio ($\approx 0.745$) within $(1+\varepsilon)$, resolving an open problem of Correa, D\"utting, Fischer, and Schewior.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.07945v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviad Rubinstein, Jack Z. Wang, S. Matthew Weinberg</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion by Large Language Models</title>
      <link>https://arxiv.org/abs/2404.00806</link>
      <description>arXiv:2404.00806v4 Announce Type: replace-cross 
Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs). We find that LLM-based pricing agents quickly and autonomously reach supracompetitive prices and profits in oligopoly settings and that variation in seemingly innocuous phrases in LLM instructions ("prompts") may substantially influence the degree of supracompetitive pricing. Off-path analysis using novel techniques uncovers price-war concerns as contributing to these phenomena. Our results extend to auction settings. Our findings uncover unique challenges to any future regulation of LLM-based pricing agents, and AI-based pricing agents more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00806v4</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer</dc:creator>
    </item>
    <item>
      <title>DeepVoting: Learning and Fine-Tuning Voting Rules with Canonical Embeddings</title>
      <link>https://arxiv.org/abs/2408.13630</link>
      <description>arXiv:2408.13630v2 Announce Type: replace-cross 
Abstract: Aggregating agent preferences into a collective decision is an important step in many problems (e.g., hiring, elections, peer review) and across areas of computer science (e.g., reinforcement learning, recommender systems). As Social Choice Theory has shown, the problem of designing aggregation rules with specific sets of properties (axioms) can be difficult, or provably impossible in some cases. Instead of designing algorithms by hand, one can learn aggregation rules, particularly voting rules, from data. However, prior work in this area has required extremely large models or been limited by the choice of preference representation, i.e., embedding. We recast the problem of designing voting rules with desirable properties into one of learning probabilistic functions that output distributions over a set of candidates. Specifically, we use neural networks to learn probabilistic social choice functions. Using standard embeddings from the social choice literature we show that preference profile encoding has significant impact on the efficiency and ability of neural networks to learn rules, allowing us to learn rules faster and with smaller networks than previous work. Moreover, we show that our learned rules can be fine-tuned using axiomatic properties to create novel voting rules and make them resistant to specific types of "attack". Namely, we fine-tune rules to resist a probabilistic version of the No Show Paradox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13630v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leonardo Matone, Ben Abramowitz, Ben Armstrong, Avinash Balakrishnan, Nicholas Mattei</dc:creator>
    </item>
  </channel>
</rss>
