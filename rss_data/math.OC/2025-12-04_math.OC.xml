<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Dec 2025 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Game-Theoretic Learning-Based Mitigation of Insider Threats</title>
      <link>https://arxiv.org/abs/2512.03222</link>
      <description>arXiv:2512.03222v1 Announce Type: new 
Abstract: An insider is defined as a team member who covertly deviates from the team's optimal collaborative control strategy in pursuit of a private objective, while maintaining an outward appearance of cooperation. Such insider threats can severely undermine cooperative systems: subtle deviations may degrade collective performance, jeopardize mission success, and compromise operational safety. This paper presents a comprehensive framework for identifying and mitigating insider threats in cooperative control settings. We introduce an insider-aware, game-theoretic formulation in which the insider's hidden intention is parameterized, allowing the threat identification task to be reformulated as a parameter estimation problem. To address this challenge, we employ an online indirect dual adaptive control approach that simultaneously infers the insider's control strategy and counteracts its negative influence. By injecting properly designed probing signals, the resulting mitigation policy asymptotically recovers the nominal optimal control law - one that would be achieved under full knowledge of the insider's objective. Simulation results validate the effectiveness of the proposed identification-mitigation framework and illustrate its capability to preserve team performance even in the presence of covert adversarial behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03222v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gehui Xu, Kaiwen Chen, Thomas Parisini, Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>Theoretical and numerical comparison of seven single-level reformulations for bilevel programs</title>
      <link>https://arxiv.org/abs/2512.03376</link>
      <description>arXiv:2512.03376v1 Announce Type: new 
Abstract: This paper considers a bilevel program. To solve this bilevel program, it is generally necessary to transform it into some single-level optimization problem. One approach is to replace the lower-level program by its KKT conditions to transform the bilevel program as a mathematical program with complementarity constraints (MPCC). Another approach is to apply the lower-level Wolfe/Mond-Weir/extended Mond-Weir duality to transform the bilevel program into some duality-based single-level reformulations, called WDP, MDP, and eMDP respectively in the literature. In this paper, inspired by a conjecture from a recent publication that the tighter feasible region of a reformulation, the better its numerical performance, we present three new duality-based single-level reformulations, called TWDP/TMDP/eTMDP, with tighter feasible regions. Our main goal is to compare all above-mentioned reformulations by designing some direct and relaxation algorithms with projection and implementing these algorithms on 450 test examples generated randomly. Our numerical experiments show that, whether overall comparison or pairwise comparison, at least in our tests, the WDP/MDP/TWDP/TMDP reformulations were always better than the MPCC reformulation, while the eMDP/eTMDP reformulations were always the worst ones among six duality-based reformulations, which indicates that the above conjecture is incorrect. In particular, for the relaxation algorithms, the WDP/MDP/TWDP/TMDP reformulations performed 3-5 times better than the MPCC reformulation, while the eMDP/eTMDP reformulations performed 2 times better than the MPCC reformulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03376v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu-Wei Li, Gui-Hua Lin, Xide Zhu</dc:creator>
    </item>
    <item>
      <title>Suboptimal Shrinking Horizon MPC with a Lower Hessian Condition Number from Adjustable Terminal Cost</title>
      <link>https://arxiv.org/abs/2512.03410</link>
      <description>arXiv:2512.03410v1 Announce Type: new 
Abstract: A strategy for reducing the number of iterations and computational burden in shrinking horizon Model Predictive Control (SH-MPC) when steering into a prescribed terminal set despite unmeasured disturbances is proposed. This strategy exploits dynamic adjustment of the terminal cost weight and horizon length while ensuring that the terminal set is reached within a desired number of steps. A lower Hessian condition number which facilitates the computational reduction is proved under assumptions, and an example of spacecraft nutation damping using the proposed approach is reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03410v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven van Leeuwen, Ilya Kolmanovsky</dc:creator>
    </item>
    <item>
      <title>Mean-Square Stability of Continuous-Time Stochastic Model Predictive Control</title>
      <link>https://arxiv.org/abs/2512.03516</link>
      <description>arXiv:2512.03516v1 Announce Type: new 
Abstract: We propose a stochastic model predictive control (SMPC) framework for a broad class of unconstrained controlled stochastic differential equations (SDEs) and establish its mean-square exponential stability in the infinite-horizon limit. At each prediction step of the MPC iteration, the nonlinear controlled SDE is approximated by its linearization at the origin, with the sampled state of the nonlinear system as initial condition, yielding a finite-horizon stochastic linear-quadratic (SLQ) optimal control problem. The resulting optimal control is then applied to the original nonlinear stochastic dynamics until the next sampling instant. This construction leads to a delayed SMPC scheme whose closed-loop behavior is governed by a coupled time-delay SDE system, a setting that has not been analyzed before. We prove global mean-square exponential stability for linear and mildly nonlinear SDEs by exploiting the exponential convergence of the Riccati equation to the algebraic Riccati equation (ARE). For strongly nonlinear SDEs, we establish local mean-square exponential stability by combining exponential Riccati convergence with stopping-time techniques and Gr\"onwall-type estimates. It is observed that, to ensure the desired local stability properties, the nonlinearities of the SDE are allowed to have polynomial growth but not exponential growth, distinguishing SMPC from its deterministic counterpart.
  These results provide the first rigorous mean-square stability guarantees for SMPC of SDE systems with delayed state information, thereby advancing the theoretical foundations of stochastic predictive control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03516v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi L\"u, Bowen Ma, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Market share maximizing strategies of CAV fleet operators may cause chaos in our cities</title>
      <link>https://arxiv.org/abs/2512.03524</link>
      <description>arXiv:2512.03524v1 Announce Type: new 
Abstract: We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03524v1</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grzegorz Jamr\'oz, Rafa{\l} Kucharski, David Watling</dc:creator>
    </item>
    <item>
      <title>Leader-Follower Mean Field LQG Games with Multiplicative Noise</title>
      <link>https://arxiv.org/abs/2512.03535</link>
      <description>arXiv:2512.03535v1 Announce Type: new 
Abstract: This paper studies open-loop and feedback solutions to leader-follower mean field linear-quadratic-Gaussian games with multiplicative noise by the direct approach. The leader-follower game involves a leader and many followers, where the state and control weight matrices in their costs are not limited to be positive definite. From variational analysis with mean field approximations, we obtain a set of open-loop controls in terms of solutions to mean field forward-backward stochastic differential equations. By applying the matrix maximum principle, a set of decentralized feedback strategies is constructed. Distinct from traditional works, a cross term has appeared in derivation due to the presence of mean field terms. For open-loop and feedback solutions, the corresponding optimal costs of all players are explicitly given in terms of the solutions to two Riccati equations, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03535v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bing-Chang Wang, Huanshui Zhang, Ji-Feng Zhang</dc:creator>
    </item>
    <item>
      <title>Learning-Based Hierarchical Approach for Fast Mixed-Integer Optimization</title>
      <link>https://arxiv.org/abs/2512.03547</link>
      <description>arXiv:2512.03547v1 Announce Type: new 
Abstract: We propose a hierarchical architecture for efficiently computing high-quality solutions to structured mixed-integer programs (MIPs). To reduce computational effort, our approach decouples the original problem into a higher level problem and a lower level problem, both of smaller size. We solve both problems sequentially, where decisions of the higher level problem become parameters of the constraints of the lower level problem. We formulate this learning task as a convex optimization problem using decision-focused learning techniques and solve it by differentiating through the higher and the lower level problems in our architecture. To ensure robustness, we derive out-of-sample performance guarantees using conformal prediction. Numerical experiments in facility location, knapsack problems, and vehicle routing problems demonstrate that our approach significantly reduces computation time while maintaining feasibility and high solution quality compared to state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03547v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Clarke, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Parameters Optimization in Trajectory Planning Using Diffrentiable Convex Programing</title>
      <link>https://arxiv.org/abs/2512.03557</link>
      <description>arXiv:2512.03557v1 Announce Type: new 
Abstract: Sequential convex programming has been established as an effective framework for solving nonconvex trajectory planning problems. However, its performance is highly sensitive to problem parameters, including trajectory variables, algorithmic hyperparameters, and physical vehicle parameters. This paper introduces a differentiable sequential convex programming framework that integrates differentiable convex optimization with sequential convex programming to enable end-to-end parameter optimization. By deriving first-order sensitivity relations of second-order cone programming solutions with respect to problem data, exact gradients of trajectory performance metrics with respect to arbitrary parameters are obtained and propagated through iterations. The effectiveness of the proposed framework is validated through three representative applications: optimal terminal-time prediction for powered landing, trust-region penalty optimization in subproblems, and surface-to-mass ratio optimization for hypersonic gliding vehicles. Simulation results show that the proposed framework enables reliable gradient-based parameter learning and significantly improves numerical performance, convergence behavior, and design efficiency. These results indicate that differentiable sequential convex programming framework provides a powerful and general tool for vehicle design, mission optimization, and hyperparameter selection in aerospace trajectory planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03557v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziqi Xu, Lin Cheng, Shengping Gong</dc:creator>
    </item>
    <item>
      <title>A hybrid large neighborhood search algorithm for the integrated dial-a-ride problem using electric vehicles</title>
      <link>https://arxiv.org/abs/2512.03562</link>
      <description>arXiv:2512.03562v1 Announce Type: new 
Abstract: Integrating demand-responsive mobility services with transit systems is recognized as a practical and effective strategy to mitigate their impact on traffic congestion and the environment. This study develops an efficient hybrid metaheuristic to solve the integrated dial-a-ride problem by utilizing electric vehicles to minimize operational costs and customer travel time. Customer transfer inconvenience is restricted by a maximum intermodal transfer time to synchronize demand-responsive buses' arrival and transit departures. The proposed metaheuristic addresses the challenges of integrating demand-responsive vehicle routing and charging operations with fixed-route transit systems with capacitated charging stations and partial recharge. We benchmarked our algorithm against a state-of-the-art mixed-integer programming solver on instances with 10-50 customers and two transit lines. Our approach achieves solutions that are, on average, 23.8% better in solution quality within around 2 minutes, outperforming those obtained by the solver using an 8-hour computational time limit. We evaluate the impact of various system parameters to bridge the gap between theory and practice. The results suggest that, from the operator's perspective, while the integrated dial-a-ride service reduces vehicle kilometers traveled, the used fleet size may not necessarily be reduced when ensuring high-quality service for passengers. Moreover, operating the integrated systems is more beneficial in areas with dense transit networks, compared with increases in transit frequency. The findings provide valuable insights for developing integrated dial-a-ride services in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03562v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.tre.2025.104562</arxiv:DOI>
      <dc:creator>Yumeng Fang, Tai-Yu Ma</dc:creator>
    </item>
    <item>
      <title>A Gradient Method for Risk Averse Control of a PDE-SDE Interconnected System</title>
      <link>https://arxiv.org/abs/2512.03626</link>
      <description>arXiv:2512.03626v1 Announce Type: new 
Abstract: In this paper, we design a risk-averse controller for an interconnected system composed of a linear Stochastic Differential Equation (SDE) actuated through a linear parabolic heat equation. These dynamics arise in various applications, such as coupled heat transfer systems and chemical reaction processes that are subject to disturbances. While existing optimal control methods for these systems focus on minimizing average performance, this risk-neutral perspective may allow rare but highly undesirable system behaviors. To account for such events, we instead minimize the cost within a coherent risk measure. Our approach reformulates the coupled dynamics as a stochastic PDE, approximates it by a finite-dimensional SDE system, and applies a gradient-based method to compute a riskaverse feedback controller. Numerical simulations show that the proposed controller substantially reduces the tail of the cost distribution, improving reliability with only a minor reduction in average performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03626v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Velho (L2S), Jean Auriol (L2S), Riccardo Bonalli (L2S)</dc:creator>
    </item>
    <item>
      <title>A Lyapunov-based MPC for Distributed Multi Agent Systems with Time Delays and Packet Dropouts using Hidden Markov Models</title>
      <link>https://arxiv.org/abs/2512.03708</link>
      <description>arXiv:2512.03708v1 Announce Type: new 
Abstract: We propose a SCHMM LMPC framework, integrating Semi Continuous Hidden Markov Models with Lyapunov based Model Predictive Control, for distributed optimal control of multi agent systems under network imperfections. The SCHMM captures the stochastic network behavior in real time, while LMPC ensures consensus and optimality via Linear Matrix Inequalities LMIs. The developed optimal control problem simultaneously minimizes three elements. First, the control effort is reduced to avoid aggressive inputs and second, the network induced error caused by time delays and packet dropouts. Third, the topology-induced error, as the distributed graph restricts agents access to global information. This error is inherent to the communication graph and cannot be addressed through offline learning. To overcome this, the study also introduces the incremental Expectation Maximization EM algorithm, enabling online learning of the SCHMM. This adaptation allows the framework to mitigate both network and topology errors while maintaining optimality through MPC. Simulations validate the effectiveness of the proposed SCHMM LMPC, demonstrating adaptability in multi agent systems with diverse topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03708v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Loaie Solyman, Aamir Ahmad, Ayman El-Badawy</dc:creator>
    </item>
    <item>
      <title>Variational Analysis in the Wasserstein Hierarchy</title>
      <link>https://arxiv.org/abs/2512.03726</link>
      <description>arXiv:2512.03726v1 Announce Type: new 
Abstract: Let $M$ be a complete connected Riemannian manifold. For $n \geq 0$, we endow the Wasserstein space $P^{(n)}_2(M) = P_2(\ldots P_2(M)\ldots)$, equipped with the Wasserstein distance $W_2$, with a variational structure that generalizes the standard variational structure on $P_2(M)$ provided by optimal transport theory. Our approach makes use of tools from category theory to lift the geometric structure of the manifold $M$ to the spaces $P^{(n)}_2(M)$, in order to establish in a principled way a rigorous theoretical framework for variational analysis on the space $P^{(n)}_2(M)$. In particular, we obtain a precise characterization of the constant speed geodesics of the space $P^{(n)}_2(M)$ in terms of optimal velocity plans. Moreover, we introduce a notion of gradient for functionals defined on $P^{(n)}_2(M)$, which allows us to study the differentiability and the convexity of various types of such functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03726v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christophe Vauthier</dc:creator>
    </item>
    <item>
      <title>Strategic Selection of Remanufacturing Business Models: A Consumer Perception Perspective</title>
      <link>https://arxiv.org/abs/2512.03732</link>
      <description>arXiv:2512.03732v1 Announce Type: new 
Abstract: As a key circular economy strategy, remanufacturing allows original equipment manufacturers (OEMs) to reduce waste by restoring used products to ``as-new'' conditions. This paper investigates an OEM's optimal remanufacturing business model by incorporating consumer perceptions into price and production quantity decisions. We analyze three alternative models: no remanufacturing, OEM in-house remanufacturing, and third-party remanufacturer (TPR) authorized remanufacturing. We extend the authorization with a two-part tariff contract and consider a stochastic market size. Through a numerical approach, we optimize price and quantity decisions based on consumer perceptions and develop a hierarchical decision roadmap to guide model selection. Our findings show that when consumer's perceived value of remanufactured products is high, OEM in-house remanufacturing is most profitable and reduces environmental impacts, but generally leads to a market dominated by remanufactured products. In contrast, when consumer's perceived value of remanufactured products is moderate and TPR remanufacturing significantly increases the perceived value of new products, the TPR-authorized remanufacturing is most profitable. It typically boosts total market sales, but accordingly increases environmental impacts. In addition, sensitivity analysis indicates that two-part authorization contracts are more advanced in meeting stringent environmental requirements than one-part contracts. Incorporating market size stochasticity enhances system profitability while keeping environmental impacts within a limited scope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03732v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongxin Hu, Christina Imdahl, Zumbul Atan</dc:creator>
    </item>
    <item>
      <title>Penalty-Free SDDP: Feasibility Cuts for Robust Multi-Stage Stochastic Optimization in Energy Planning</title>
      <link>https://arxiv.org/abs/2512.03739</link>
      <description>arXiv:2512.03739v1 Announce Type: new 
Abstract: Multi-stage decision problems under uncertainty can be efficiently solved with the Stochastic Dual Dynamic Programming (SDDP) algorithm. However, traditional implementations require all stage problems to be feasible. Feasibility is usually enforced by adding slack variables and penalizing them in the objective function, a process that depends on case-specific calibration and often distorts the economic interpretation of results. This paper proposes the Penalty-Free SDDP, an extension that introduces a Future Feasibility Function alongside the traditional Future Cost Function. The new recursion handles infeasibilities automatically, distinguishing between temporary and truly infeasible cases, and propagates feasibility information across stages through dedicated feasibility cuts. The approach was validated in a large-scale deterministic case inspired by the Brazilian hydrothermal system, achieving equivalent feasibility to the benchmark solution while eliminating miscalibrated artificial penalties. Results confirm its robustness and practicality as a foundation for future stochastic, multi-stage applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03739v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilherme Freitas, Luiz Carlos da Costa Junior, Tiago Andrade, Alexandre Street</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Counterfactual Tuning for Compressor Pressure Control</title>
      <link>https://arxiv.org/abs/2512.03747</link>
      <description>arXiv:2512.03747v1 Announce Type: new 
Abstract: In controlled industrial environments, ensuring safety and performance during controller tuning is a challenging and critical task. In particular, control loops in compressor-plenum-throttle systems cannot tolerate costly interruptions, and aggressive excitation may lead to unsafe operating regimes. Given the wide availability of historical data, this paper introduces a counterfactual explainability approach for sample-efficient retuning of compressor control loops. The proposed data-driven algorithm determines, without an explicit plant model or previous control law, the smallest controller adjustment required to achieve predefined performance specifications while guaranteeing stability. The effectiveness of the method is demonstrated through an extensive Monte Carlo simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03747v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Margarita A. Guerrero, Rodrigo A. Gonz\'alez, Cristian R. Rojas</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models</title>
      <link>https://arxiv.org/abs/2512.03915</link>
      <description>arXiv:2512.03915v1 Announce Type: new 
Abstract: In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03915v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>X. Y. Han, Yuan Zhong</dc:creator>
    </item>
    <item>
      <title>Discontinuous Strongly Quasiconvex Functions</title>
      <link>https://arxiv.org/abs/2512.03934</link>
      <description>arXiv:2512.03934v1 Announce Type: new 
Abstract: A fundamental open question asking whether all real-valued strongly quasiconvex functions defined on $\mathbb R^n$ are necessarily continuous, akin to their convex counterparts, is answered in detail in this paper. Among other things, we show that such functions can have infinitely many points of discontinuity. The failure of lower semicontinuity together with the lack of upper semicontinuity at infinitely many points of certain real-valued strongly quasiconvex functions are also shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03934v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen Thi Van Hang, Felipe Lara, Nguyen Dong Yen</dc:creator>
    </item>
    <item>
      <title>Data-Dependent Complexity of First-Order Methods for Binary Classification</title>
      <link>https://arxiv.org/abs/2512.03947</link>
      <description>arXiv:2512.03947v1 Announce Type: new 
Abstract: Large-scale problems in data science are often modeled with optimization, and the optimization model is usually solved with first-order methods that may converge at a sublinear rate. Therefore, it is of interest to terminate the optimization algorithm as soon as the underlying data science task is accomplished. We consider FISTA for solving two binary classification problems: the ellipsoid separation problem (ESP), and the soft-margin support-vector machine (SVM). For the ESP, we cast the dual second-order cone program into a form amenable to FISTA and show that the FISTA residual converges to the infimal displacement vector of the primal-dual hybrid gradient (PDHG) algorithm, that directly encodes a separating hyperplane. We further derive a data-dependent iteration upper bound scaling as $\mathcal{O}(1/\delta_{\mathcal{A}}^2)$, where $\delta_{\mathcal{A}}$ is the minimal perturbation that destroys separability. For the SVM, we propose a strongly-concave perturbed dual that admits efficient FISTA updates under a linear time projection scheme, and with our parameter choices, the objective has small condition number, enabling rapid convergence. We prove that, under a reasonable data model, early-stopped iterates identify well-classified points and yield a hyperplane that exactly separates them, where the accuracy required of the dual iterate is governed by geometric properties of the data. In particular, the proposed early-stopping criteria diminish the need for hard-to-select tolerance-based stopping conditions. Our numerical experiments on ESP instances derived from MNIST data and on soft-margin SVM benchmarks indicate competitive runtimes and substantial speedups from stopping early.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03947v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Hough, Stephen A. Vavasis</dc:creator>
    </item>
    <item>
      <title>Accelerating shape optimization by deep neural networks with on-the-fly determined architecture</title>
      <link>https://arxiv.org/abs/2512.03555</link>
      <description>arXiv:2512.03555v1 Announce Type: cross 
Abstract: In component shape optimization, the component properties are often evaluated by computationally expensive simulations. Such optimization becomes unfeasible when it is focused on a global search requiring thousands of simulations to be evaluated. Here, we present a viable global shape optimization methodology based on multi-objective evolutionary algorithms accelerated by deep neural networks (DNNs). Our methodology alternates between evaluating simulations and utilizing the generated data to train DNNs with various architectures. When a suitable DNN architecture is identified, the DNN replaces the simulation in the rest of the global search. Our methodology was tested on five ZDT benchmark functions, showing itself at the level of and sometimes more flexible than other state-of-the-art acceleration approaches. Then, it was applied to a real-life optimization problem, namely the shape optimization of a single-phase ejector. Compared with a non-accelerated methodology, ours was able to save weeks of CPU time in solving this problem. To experimentally confirm the performance of the optimized ejector shapes, four of them were 3D printed and tested on the lab scale confirming the predicted performance. This suggests that our methodology could be used for acceleration of other real-life shape optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03555v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucie Kub\'i\v{c}kov\'a, On\v{r}ej Gebousk\'y, Jan Haidl, Martin Isoz</dc:creator>
    </item>
    <item>
      <title>A dynamic competitive equilibrium model of irreversible capacity investment with stochastic demand and heterogeneous producers</title>
      <link>https://arxiv.org/abs/2512.03646</link>
      <description>arXiv:2512.03646v1 Announce Type: cross 
Abstract: We formulate a continuous-time competitive equilibrium model of irreversible capacity investment in which a continuum of heterogeneous producers supplies a single non-durable good subject to exogenous stochastic demand. Each producer optimally adjusts both output and capacity over time in response to endogenous price signals, while investment decisions are irreversible. Market clearing holds continuously, with prices evolving endogenously to balance aggregate supply and demand through a constant-elasticity demand function driven by a stochastic base component. The model admits a mean-field interpretation, as each producer's decisions both influence and are influenced by the aggregate behaviour of all others. We show that the equilibrium price process can be expressed as a nonlinear functional of the exogenous base demand, leading to a three-dimensional singular stochastic control problem for each producer. We derive an explicit solution to the associated Hamilton-Jacobi-Bellman equation, including a closed-form characterisation of the free-boundary surface separating investment and waiting regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03646v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Constantinos Kardaras, Alexandros Pavlis, Mihail Zervos</dc:creator>
    </item>
    <item>
      <title>Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics</title>
      <link>https://arxiv.org/abs/2512.03807</link>
      <description>arXiv:2512.03807v1 Announce Type: cross 
Abstract: Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03807v1</guid>
      <category>cs.IR</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christos Kolomvakis, Thomas Bobille, Arnaud Vandaele, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>An Information Theory of Finite Abstractions and their Fundamental Scalability Limits</title>
      <link>https://arxiv.org/abs/2512.03977</link>
      <description>arXiv:2512.03977v1 Announce Type: cross 
Abstract: Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03977v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Delimpaltadakis, Gabriel Gleizer</dc:creator>
    </item>
    <item>
      <title>Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics</title>
      <link>https://arxiv.org/abs/2512.04006</link>
      <description>arXiv:2512.04006v1 Announce Type: cross 
Abstract: Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04006v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connall Garrod, Jonathan P. Keating, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Convergence for Discrete Parameter Updates</title>
      <link>https://arxiv.org/abs/2512.04051</link>
      <description>arXiv:2512.04051v1 Announce Type: cross 
Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04051v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Paul Wilson, Fabio Zanasi, George Constantinides</dc:creator>
    </item>
    <item>
      <title>A New Lineserach for Accelerated Composite Minimization</title>
      <link>https://arxiv.org/abs/2405.03414</link>
      <description>arXiv:2405.03414v2 Announce Type: replace 
Abstract: The choice of the stepsize in first-order convex optimization is typically based on the smoothness constant and plays a crucial role in the performance of algorithms. Recently, there has been a resurgent interest in introducing adaptive stepsizes that do not explicitly depend on smooth constant. In this paper, we propose a novel linesearch stepsize rule based on function evaluations (i.e., zero-order information) that enjoys provable convergence guarantees for both accelerated and non-accelerated gradient descent. We further discuss the similarities and differences between the proposed stepsize regimes and the existing stepsize rules (including Polyak and Armijo). We numerically benchmark the performance of our proposed algorithms against state-of-the-art methods across three major problems classes of (1) smooth minimization (logistic regression, quadratic programs, log-sum-exponential, and smooth max-cut relaxation) (2) composite minimization ($\ell_1$-regularized least-squares, $\ell_1$-constrained least-squares, and $\ell_1$-regularized logistic regression), and (3) non-convex minimization (cubic minimization). These classes include a wide range of operations research and management applications such as portfolio optimization, discrete choice models, sparse classification and feature selections, high-order optimization and trust-region subproblems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03414v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reza Rahimi Baghbadorani, Sergio Grammatico, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>On the Characteristics of the Conjugate Function Enabling Effective Dual Decomposition Methods</title>
      <link>https://arxiv.org/abs/2405.08933</link>
      <description>arXiv:2405.08933v3 Announce Type: replace 
Abstract: We investigate a novel characteristic of the conjugate function associated to a generic convex optimization problem, which can subsequently be leveraged for efficient dual decomposition methods. In particular, under mild assumptions, we show that there is a specific region in the domain of the conjugate function such that for any point in the region, there is always a ray originating from that point along which the gradients of the conjugate remain constant. We refer to this characteristic as a fixed gradient over rays (FGOR). We further show that this characteristic is inherited by the corresponding dual function. Then we provide a thorough exposition of the application of the FGOR characteristic to dual subgradient methods. More importantly, we leverage FGOR to devise a simple stepsize rule that can be prepended with state-of-the-art stepsize methods enabling them to be more efficient. Furthermore, we investigate how the FGOR characteristic is used when solving the global consensus problem, a prevalent formulation in diverse application domains. We show that FGOR can be exploited not only to expedite the convergence of the dual decomposition methods but also to reduce the communication overhead. FGOR is extended to nonconvex formulations, and its advantages in stochastic optimization are demonstrated. Numerical experiments using quadratic objectives and a regularized least squares regression with real datasets are conducted. The results show that FGOR can significantly improve the performance of existing stepsize methods and outperform the state-of-the-art splitting methods on average in terms of both convergence behavior and communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08933v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hansi Abeynanda, Chathuranga Weeraddana, Carlo Fischione</dc:creator>
    </item>
    <item>
      <title>Dynamical System Approach for Optimal Control Problems with Equilibrium Constraints Using Gap-Constraint-Based Reformulation</title>
      <link>https://arxiv.org/abs/2412.01326</link>
      <description>arXiv:2412.01326v2 Announce Type: replace 
Abstract: This study focuses on using direct methods (first-discretize-then-optimize) to solve optimal control problems for a class of nonsmooth dynamical systems governed by differential variational inequalities (DVI), called optimal control problems with equilibrium constraints (OCPEC). In the discretization step, we propose a class of novel approaches to smooth the DVI. The generated smoothing approximations of DVI, referred to as gap-constraint-based reformulations, have computational advantages owing to their concise and semismoothly differentiable constraint system. In the optimization step, we propose an efficient dynamical system approach to solve the discretized OCPEC, where a sequence of its smoothing approximations is solved approximately. This system approach involves a semismooth Newton flow, thereby achieving fast local exponential convergence. We confirm the effectiveness of our method using a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01326v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangyu Lin, Toshiyuki Ohtsuka</dc:creator>
    </item>
    <item>
      <title>SPLD polynomial optimization and bounded degree SOS hierarchies</title>
      <link>https://arxiv.org/abs/2502.11343</link>
      <description>arXiv:2502.11343v3 Announce Type: replace 
Abstract: In this paper, we introduce a new class of structured polynomials, called separable plus lower degree (SPLD) polynomials. The formal definition of an SPLD polynomial, which extends the concept of SPQ polynomials (Ahmadi et al. in Math Oper Res 48:1316--1343, 2023), is provided. A type of bounded degree SOS hierarchy, referred to as BSOS-SPLD, is proposed to efficiently solve optimization problems involving SPLD polynomials. Numerical experiments on several benchmark problems indicate that the proposed method yields better performance than the standard bounded degree SOS hierarchy (Lasserre et al. in EURO J Comput Optim 5:87--117, 2017). An exact SOS relaxation for a class of convex SPLD polynomial optimization problems is proposed. Finally, we present an application of SPLD polynomials to convex polynomial regression problems arising in statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11343v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liguo Jiao, Jae Hyoung Lee, Nguyen Bui Nguyen Thao</dc:creator>
    </item>
    <item>
      <title>Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?</title>
      <link>https://arxiv.org/abs/2503.20772</link>
      <description>arXiv:2503.20772v3 Announce Type: replace 
Abstract: Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability - ranging from ordinal level comparability to full cardinal comparability - together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20772v3</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilia Shilov, Ezzat Elokda, Sophie Hall, Heinrich H. Nax, Saverio Bolognani</dc:creator>
    </item>
    <item>
      <title>Deriving the Gradients of Some Popular Optimal Transport Algorithms</title>
      <link>https://arxiv.org/abs/2504.08722</link>
      <description>arXiv:2504.08722v3 Announce Type: replace 
Abstract: In this note, I review entropy-regularized Monge-Kantorovich problem in Optimal Transport, and derive the gradients of several popular algorithms popular in Computational Optimal Transport, including the Sinkhorn algorithms, Wasserstein Barycenter algorithms, and the Wasserstein Dictionary Learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08722v3</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fangzhou Xie</dc:creator>
    </item>
    <item>
      <title>Learning to Solve Constrained Bilevel Control Co-Design Problems</title>
      <link>https://arxiv.org/abs/2507.09050</link>
      <description>arXiv:2507.09050v2 Announce Type: replace 
Abstract: Learning to Optimize (L2O) is a subfield of machine learning (ML) in which ML models are trained to solve parametric optimization problems. The general goal is to learn a fast approximator of solutions to constrained optimization problems, as a function of their defining parameters. Prior L2O methods focus almost entirely on single-level programs, in contrast to the bilevel programs, whose constraints are themselves expressed in terms of optimization subproblems. Bilevel programs have numerous important use cases but are notoriously difficult to solve, particularly under stringent time demands. This paper proposes a framework for learning to solve a broad class of challenging bilevel optimization problems, by leveraging modern techniques for differentiation through optimization problems. The framework is illustrated on an array of synthetic bilevel programs, as well as challenging control system co-design problems, showing how neural networks can be trained as efficient approximators of parametric bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09050v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Kotary, Himanshu Sharma, Ethan King, Draguna Vrabie, Ferdinando Fioretto, Jan Drgona</dc:creator>
    </item>
    <item>
      <title>Revisiting the Geometrically Decaying Step Size: Linear Convergence for Smooth or Non-Smooth Functions</title>
      <link>https://arxiv.org/abs/2508.13569</link>
      <description>arXiv:2508.13569v3 Announce Type: replace 
Abstract: We revisit the geometrically decaying step size given a positive inverse condition number, under which a locally Lipschitz function shows linear convergence. The positivity does not require the function to satisfy convexity, weak convexity, quasar convexity, or sharpness, but instead amounts to a property strictly weaker than the assumptions used in existing works (e.g., weak convexity + sharpness). We propose a clean and simple subgradient descent algorithm that requires minimal knowledge of problem constants, applicable to either smooth or non-smooth functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13569v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim</dc:creator>
    </item>
    <item>
      <title>G-BSDEs with non-Lipschitz coefficients and the corresponding stochastic recursive optimal control problem</title>
      <link>https://arxiv.org/abs/2508.17731</link>
      <description>arXiv:2508.17731v2 Announce Type: replace 
Abstract: In this paper, we study the existence and uniqueness of solutions to a class of non-Lipschitz G-BSDEs and the corresponding stochastic recursive optimal control problem. More precisely, we suppose that the generator of G-BSDE is uniformly continuous and monotonic with respect to the first unknown variable. Using the comparison theorem for G-BSDE and the stability of viscosity solutions, we establish the dynamic programming principle and the connection between the value function and the viscosity solution of the associated Hamilton-Jacobi-Bellman equation.We provide an example of continuous time Epstein-Zin utility to demonstrate the application of our study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17731v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei He, Qiangjun Tang</dc:creator>
    </item>
    <item>
      <title>Computing Optimal Trajectories for Optimal Transport in Nonuniform Environments</title>
      <link>https://arxiv.org/abs/2510.17170</link>
      <description>arXiv:2510.17170v2 Announce Type: replace 
Abstract: In this work, we solve a discrete optimal transport problem in a nonuniform environment. To solve the optimal transport problem, we build the cost matrix and then use classical solvers for discrete optimal transport. The challenge is to form the cost matrix, which requires finding the optimal path between two points, and for this task we formulate and solve the associated Euler-Lagrange equations. A main contribution of ours is to provide verifiable sufficient conditions of optimality of the solution of the Euler-Lagrange equation and to propose new algorithms to to check optimality a-posteriori, thus validating the (exact) computation of the cost matrix. We illustrate our results and performance of the algorithms on several numerical examples in 2 and 3 dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17170v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Dieci, Daniyar Omarov</dc:creator>
    </item>
    <item>
      <title>Asset-liability management with Epstein-Zin utility under stochastic interest rate and unknown market price of risk</title>
      <link>https://arxiv.org/abs/2511.02158</link>
      <description>arXiv:2511.02158v2 Announce Type: replace 
Abstract: This paper solves a consumption-investment choice problem with Epstein-Zin recursive utility under partial information--unobservable market price of risk. The main novelty is the introduction of a terminal liability constraint, a feature directly motivated by practical portfolio management and insurance applications but absent from the recursive utility literature. Such constraint gives rise to a coupled forward-backward stochastic differential equation (FBSDE) whose well-posedness has not been addressed in earlier work. We provide an explicit solution to this FBSDE system--contrasting with the typical existence and uniqueness results with no closed-form expressions in the literature. Under mild additional assumptions, we also establish the Malliavin differentiability of the solution allowing the optimal investment strategy to be expressed as a conditional expectation of random variables that can be efficiently simulated. These results allows us to obtain the explicit expressions of the optimal controls and the value function. Finally, we quantify the utility loss from ignoring learning about the market price of risk, highlighting the economic significance of partial information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02158v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wilfried Kuissi-Kamdem</dc:creator>
    </item>
    <item>
      <title>Mathematical Analysis and Modeling of Ebola Virus Dynamics via Optimal Control and Neural Network Paradigms</title>
      <link>https://arxiv.org/abs/2511.06303</link>
      <description>arXiv:2511.06303v2 Announce Type: replace 
Abstract: Ebola virus disease is a severe hemorrhagic fever with rapid transmission through infected fluids and surfaces. We develop a fractional-order model using Caputo derivatives to capture memory effects in disease dynamics. An eight-compartment structure distinguishes symptomatic, asymptomatic, and post-mortem transmission pathways. We prove global well-posedness, derive the basic reproduction number $\mathcal{R}_0$, and establish stability theorems. Sensitivity analysis shows $\mathcal{R}_0$ is most sensitive to transmission rate, incubation period, and deceased infectivity. Treatment-safe burial synergy achieves 86.5\% morbidity-mortality control, with safe burial being most effective. Our disease-informed neural network achieves near-perfect predictive accuracy ($R^2$: 0.991-0.999, 99.1-99.9\% accuracy), closely matching real epidemic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06303v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noor Muhammad (School of Mathematics, Sichuan University, Chengdu, China), Md. Nur Alam (Department of Mathematics, Pabna University of Science &amp; Technology, Pabna-6600, Bangladesh), Zhang Shiqing (School of Mathematics, Sichuan University, Chengdu, China)</dc:creator>
    </item>
    <item>
      <title>Global Regularity Estimates for Optimal Transport via Entropic Regularisation</title>
      <link>https://arxiv.org/abs/2501.11382</link>
      <description>arXiv:2501.11382v5 Announce Type: replace-cross 
Abstract: We develop a general approach to prove global regularity estimates for quadratic optimal transport using the entropic regularisation of the problem and the Prekopa-Leindler inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11382v5</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathael Gozlan (MAP5 - UMR 8145), Maxime Sylvestre (CEREMADE, MOKAPLAN)</dc:creator>
    </item>
    <item>
      <title>Target search optimization by threshold resetting</title>
      <link>https://arxiv.org/abs/2504.13501</link>
      <description>arXiv:2504.13501v2 Announce Type: replace-cross 
Abstract: We introduce a new class of first passage time optimization driven by threshold resetting, inspired by many natural processes where crossing a critical limit triggers failure, degradation or transition. In here, search agents are collectively reset when a threshold is reached, creating event-driven, system-coupled simultaneous resets that induce long-range interactions. We develop a unified framework to compute search times for these correlated stochastic processes, with ballistic- and diffusive- searchers as key examples uncovering diverse optimization behaviors. A cost function, akin to breakdown penalties, reveals that optimal resetting can forestall larger losses. This formalism generalizes to broader stochastic systems with multiple degrees of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13501v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.ST</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/752c-wqly</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 135, 227101 (2025)</arxiv:journal_reference>
      <dc:creator>Arup Biswas, Satya N Majumdar, Arnab Pal</dc:creator>
    </item>
    <item>
      <title>Sharpness of Minima in Deep Matrix Factorization: Exact Expressions</title>
      <link>https://arxiv.org/abs/2509.25783</link>
      <description>arXiv:2509.25783v4 Announce Type: replace-cross 
Abstract: Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss, which measures the sharpness of the landscape. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in general overparameterized deep matrix factorization (i.e., deep linear neural network training) problems, resolving an open question posed by Mulayoff &amp; Michaeli (2020). This expression uncovers a fundamental property of the loss landscape of depth-2 matrix factorization problems: a minimum is flat if and only if it is spectral-norm balanced, which implies that flat minima are not necessarily Frobenius-norm balanced. Furthermore, to complement our theory, we empirically investigate an escape phenomenon observed during gradient-based training near a minimum that crucially relies on our exact expression of the sharpness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25783v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anil Kamber, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior</title>
      <link>https://arxiv.org/abs/2510.22501</link>
      <description>arXiv:2510.22501v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce the SDIR (Susceptible-Delayable-Infected-Recovered) model, an extension of the classical SIR epidemic framework, to provide a more explicit characterization of user behavior in online social networks. The newly merged state D (delayable) represents users who have received the information but delayed its spreading and may eventually choose not to share it at all. Based on the mean-field approximation method, we derive the dynamical equations of the model and investigate its convergence and stability conditions. Under these conditions, we further propose an approximation algorithm for the edge-deletion problem, aiming to minimize the influence of information diffusion by identifying approximate solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22501v2</guid>
      <category>cs.SI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tran Van Khanh, Do Xuan Cho, Hoang Phi Dung</dc:creator>
    </item>
    <item>
      <title>Direction-of-Arrival and Noise Covariance Matrix joint estimation for beamforming</title>
      <link>https://arxiv.org/abs/2511.10639</link>
      <description>arXiv:2511.10639v2 Announce Type: replace-cross 
Abstract: We propose a joint estimation method for the Direction-of-Arrival (DoA) and the Noise Covariance Matrix (NCM) tailored for beamforming applications. Building upon an existing NCM framework, our approach simplifies the estimation procedure by deriving an quasi-linear solution, instead of the traditional exhaustive search. Additionally, we introduce a novel DoA estimation technique that operates across all frequency bins, improving robustness in reverberant environments. Simulation results demonstrate that our method outperforms classical techniques, such as MUSIC, in mid- to high-angle scenarios, achieving lower angular errors and superior signal enhancement through beamforming. The proposed framework was also fared against other techniques for signal enhancement, having better noise rejection and interference canceling capabilities. These improvements are validated using both theoretical and empirical performance metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10639v2</guid>
      <category>eess.AS</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vitor Gelsleichter Probst Curtarelli, Stephan Paul, Anderson Wedderhoff Spengler</dc:creator>
    </item>
    <item>
      <title>No-Regret Gaussian Process Optimization of Time-Varying Functions</title>
      <link>https://arxiv.org/abs/2512.00517</link>
      <description>arXiv:2512.00517v2 Announce Type: replace-cross 
Abstract: Sequential optimization of black-box functions from noisy evaluations has been widely studied, with Gaussian Process bandit algorithms such as GP-UCB guaranteeing no-regret in stationary settings. However, for time-varying objectives, it is known that no-regret is unattainable under pure bandit feedback unless strong and often unrealistic assumptions are imposed.
  In this article, we propose a novel method to optimize time-varying rewards in the frequentist setting, where the objective has bounded RKHS norm. Time variations are captured through uncertainty injection (UI), which enables heteroscedastic GP regression that adapts past observations to the current time step. As no-regret is unattainable in general in the strict bandit setting, we relax the latter allowing additional queries on previously observed points. Building on sparse inference and the effect of UI on regret, we propose W-SparQ-GP-UCB, an online algorithm that achieves no-regret with only a vanishing number of additional queries per iteration. To assess the theoretical limits of this approach, we establish a lower bound on the number of additional queries required for no-regret, proving the efficiency of our method. Finally, we provide a comprehensive analysis linking the degree of time-variation of the function to achievable regret rates, together with upper and lower bounds on the number of additional queries needed in each regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00517v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eliabelle Mauduit, Elo\"ise Berthier, Andrea Simonetto</dc:creator>
    </item>
  </channel>
</rss>
