<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Feb 2026 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Model checking with temporal graphs and their derivative</title>
      <link>https://arxiv.org/abs/2602.12446</link>
      <description>arXiv:2602.12446v1 Announce Type: new 
Abstract: Temporal graphs are graphs where the presence or properties of their vertices and edges change over time. When time is discrete, a temporal graph can be defined as a sequence of static graphs over a discrete time span, called lifetime, or as a single graph where each edge is associated with a specific set of time instants where the edge is alive. For static graphs, Courcelle's Theorem asserts that any graph problem expressible in monadic second-order logic can be solved in linear time on graphs of bounded tree-width. We propose the first adaptation of Courcelle's Theorem for monadic second-order logic on temporal graphs that does not explicitly rely on the lifetime as a parameter. We then introduce the notion of derivative over a sliding time window of a chosen size, and define the tree-width and twin-width of the temporal graph's derivative. We exemplify its usefulness with meta theorems with respect to a temporal variant of first-order logic. The resulting logic expresses a wide range of temporal graph problems including a version of temporal cliques, an important notion when querying time series databases for community structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12446v1</guid>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binh-Minh Bui-Xuan, Florent Krasnopol, Bruno Monasson, Nathalie Sznajder</dc:creator>
    </item>
    <item>
      <title>Additively Competitive Secretaries</title>
      <link>https://arxiv.org/abs/2602.12632</link>
      <description>arXiv:2602.12632v1 Announce Type: new 
Abstract: In the secretary problem, a set of secretary candidates arrive in a uniformly random order and reveal their values one by one. A company, who can only hire one candidate and hopes to maximize the expected value of its hire, needs to make irrevocable online decisions about whether to hire the current candidate. The classical framework of evaluating a policy is to compute its worst-case competitive ratio against the optimal solution in hindsight, and there the best policy -- the ``$1/e$ law'' -- has a competitive ratio of $1/e$.
  We propose an alternative evaluation framework through the lens of regret -- the worst-case additive difference between the optimal hindsight solution and the expected performance of the policy, assuming that each value is normalized between $0$ and $1$. The $1/e$ law for the classical framework has a regret of $1 - 1/e \approx 0.632$; by contrast, we show that the class of ``pricing curves'' algorithms can guarantee a regret of at most $1/4 = 0.25$ (which is tight within the class), and the class of ``best-only pricing curves'' algorithms can guarantee a regret of at most $0.190$ (with a lower bound of $0.171$). In addition, we show that in general, no policy can give a regret guarantee better than $0.152$. Finally, we discuss other objectives in our regret-minimization framework, such as selecting the top-$k$ candidates for $k &gt; 1$, or maximizing revenue during the selection process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12632v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Mahdian, Jieming Mao, Enze Sun, Kangning Wang, Yifan Wang</dc:creator>
    </item>
    <item>
      <title>Lower Bounds on Flow Sparsifiers with Steiner Nodes</title>
      <link>https://arxiv.org/abs/2602.12645</link>
      <description>arXiv:2602.12645v1 Announce Type: new 
Abstract: Given a large graph $G$ with a set of its $k$ vertices called terminals, a \emph{quality-$q$ flow sparsifier} is a small graph $G'$ that contains the terminals and preserves all multicommodity flows between them up to some multiplicative factor $q\ge 1$, called the \emph{quality}. Constructing flow sparsifiers with good quality and small size ($|V(G')|$) has been a central problem in graph compression. The most common approach of constructing flow sparsifiers is contraction: first compute a partition of the vertices in $V(G)$, and then contract each part into a supernode to obtain $G'$. When $G'$ is only allowed to contain all terminals, the best quality is shown to be $O(\log k/\log\log k)$ and $\Omega(\sqrt{\log k/\log\log k})$. In this paper, we show that allowing a few Steiner nodes does not help much in improving the quality. Specifically, there exist $k$-terminal graphs such that, even if we allow $k\cdot 2^{(\log k)^{\Omega(1)}}$ Steiner nodes in its contraction-based flow sparsifier, the quality is still $\Omega\big((\log k)^{0.3}\big)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12645v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Chen, Zihan Tan, Mingyang Yang</dc:creator>
    </item>
    <item>
      <title>Efficient Streaming Algorithms for Two-Dimensional Congruence Testing and Geometric Hashing</title>
      <link>https://arxiv.org/abs/2602.12667</link>
      <description>arXiv:2602.12667v1 Announce Type: new 
Abstract: The geometric congruence problem is a fundamental building block in many computer vision and image recognition tasks. This problem considers the decision task of whether two point sets are congruent under translation and rotation. A related and more general problem, geometric hashing, considers the task of compactly encoding multiple point sets for efficient congruence queries. Despite its wide applications, both problems have received little prior attention in space-aware settings.
  In this work, we study the two-dimensional congruence testing and geometric hashing problem in the streaming model, where data arrive as a stream and the primary goal is to minimize the space usage. To meaningfully analyze space complexity, we address the underaddressed issue of input precision by working in the finite-precision rational setting: the input point coordinates are rational numbers of the form $p/q$ with $|p|, |q| \le U$.
  Our result considers a stronger variant of congruence testing called congruence identification, for which we obtain a 3-pass randomized streaming algorithm using $O(\log n(\log U+\log n))$ space. Using the congruence identification algorithm as a building block, we give a 6-pass $O(m\log n (\log n + \log U + \log m))$-space randomized streaming algorithm that outputs a hash function of length $O(\log n+\log U+\log m)$.
  Our key technical tool for achieving space efficiency is the use of complex moments. While complex moment methods are widely employed as heuristics in object recognition, their effectiveness is often limited by vanishing moment issues (Flusser and Suk [IEEE Trans. Image Process 2006]). We show that, in the rational setting, it suffices to track only $O(\log n)$ complex moments to ensure a non-vanishing moment, thus providing a sound theoretical guarantee for recovering a valid rotation in positive instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12667v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yen-Cheng Chang, Tsun Ming Cheung, Meng-Tsung Tsai, Ting-An Wu</dc:creator>
    </item>
    <item>
      <title>Independence-Number Parameterized Space Complexity for Directed Connectivity Certificate</title>
      <link>https://arxiv.org/abs/2602.12668</link>
      <description>arXiv:2602.12668v1 Announce Type: new 
Abstract: We study the space complexity of computing a sparse subgraph of a directed graph that certifies connectivity in the streaming and distributed models. Formally, for a directed graph $G=(V,A)$ and $k\in \mathbb{N}$, a $k$-node strong connectivity certificate is a subgraph $H=(V,A')\subseteq G$ such that for every pair of distinct nodes $s,t\in V$, the number of pairwise internally node-disjoint paths from $s$ to $t$ in $H$ is at least $k$ or the corresponding number in $G$. In light of the inherent hardness of directed connectivity problems, several prior work focused on restricted graph classes, showing that several problems that are hard in general become efficiently solvable when the input graph is a tournament (i.e., a directed complete graph) (Chakrabarti et al. [SODA 2020]; Baweja, Jia, and Woddruff [ITCS 2022]), or close to a tournament in edit distance (Ghosh and Kuchlous [ESA 2024]). Extending this line of work, our main result shows, at a qualitative level, that the streaming complexity of strong connectivity certificates and related problems is parameterized by independence number, demonstrating a continuum of hardness for directed graph connectivity problems. Quantitatively, for an $n$-node graph with independence number $\alpha$, we give $p$-pass randomized algorithms that compute a $k$-node strong connectivity certificate of size $O(\alpha n)$ using $\tilde{O}(k^{1-1/p}\alpha n^{1+1/p})$ space in the insertion-only model. For the lower bound, we show that even when $k=1$, any $p$-pass streaming algorithm for a 1-node strong connectivity certificate in the insertion-only model requires $\Omega(\alpha n/p)$ space. To derive these lower bounds, we introduce the gadget-embedding tournament framework to construct direct-sum-type hard instances with a prescribed independence number, which is applicable to lower-bounding a wide range of directed graph problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12668v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ho-Lin Chen, Tsun Ming Cheung, Peng-Ting Lin, Meng-Tsung Tsai</dc:creator>
    </item>
    <item>
      <title>Online Flow Time Minimization with Gradually Revealed Jobs</title>
      <link>https://arxiv.org/abs/2602.12716</link>
      <description>arXiv:2602.12716v1 Announce Type: new 
Abstract: We consider the problem of online preemptive scheduling on a single machine to minimize the total flow time. In clairvoyant scheduling, where job processing times are revealed upon arrival, the Shortest Remaining Processing Time (SRPT) algorithm is optimal. In practice, however, exact processing times are often unknown. At the opposite extreme, non-clairvoyant scheduling, in which processing times are revealed only upon completion, suffers from strong lower bounds on the competitive ratio. This motivates the study of intermediate information models. We introduce a new model in which processing times are revealed gradually during execution. Each job consists of a sequence of operations, and the processing time of an operation becomes known only after the preceding one completes. This models many scheduling scenarios that arise in computing systems.
  Our main result is a deterministic $O(m^2)$-competitive algorithm, where $m$ is the maximum number of operations per job. More specifically, we prove a refined competitive ratio in $O(m_1 \cdot m_2)$, where $m_1$ and $m_2$ are instance-dependent parameters describing the operation size structure. Our algorithm and analysis build on recent advancements in robust flow time minimization (SODA '26), where jobs arrive with estimated sizes. However, in our setting we have no bounded estimate on a job's processing time. Thus, we design a highly adaptive algorithm that gradually explores a job's operations while working on them, and groups them into virtual chunks whose size can be well-estimated. This is a crucial ingredient of our result and requires a much more careful analysis compared to the robust setting. We also provide lower bounds showing that our bounds are essentially best possible. For the special case of scheduling with uniform obligatory tests, we show that SRPT at the operation level is $2$-competitive, which is best possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12716v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Lindermayr, Guido Sch\"afer, Jens Schl\"oter, Leen Stougie</dc:creator>
    </item>
    <item>
      <title>Optimal Path Partitions in Subcubic and Almost-subcubic Graphs</title>
      <link>https://arxiv.org/abs/2602.12925</link>
      <description>arXiv:2602.12925v1 Announce Type: new 
Abstract: We consider the problem of partitioning the edges of a graph into as few paths as possible. This is a~subject of the classic conjecture of Gallai and a recurring topic in combinatorics. Regarding the complexity of partitioning a graph optimally, Peroch\'e [Discret. Appl. Math., 1984] proved that it is NP-hard already on graphs of maximum degree four, even when we only ask if two paths suffice.
  We show that the problem is solvable in polynomial time on subcubic graphs and then we present an efficient algorithm for ``almost-subcubic'' graphs. Precisely, we prove that the problem is fixed-parameter tractable when parameterized by the edge-deletion distance to a subcubic graph. To this end, we reduce the task to model checking in first-order logic extended by disjoint-paths predicates ($\mathsf{FO}\text{+}\mathsf{DP}$) and then we employ the recent tractability result by Schirrmacher, Siebertz, Stamoulis, Thilikos, and Vigny [LICS 2024].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12925v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom\'a\v{s} Masa\v{r}\'ik, Micha{\l} W{\l}odarczyk, Mehmet Akif Y{\i}ld{\i}z</dc:creator>
    </item>
    <item>
      <title>Linear Regression with Unknown Truncation Beyond Gaussian Features</title>
      <link>https://arxiv.org/abs/2602.12534</link>
      <description>arXiv:2602.12534v1 Announce Type: cross 
Abstract: In truncated linear regression, samples $(x,y)$ are shown only when the outcome $y$ falls inside a certain survival set $S^\star$ and the goal is to estimate the unknown $d$-dimensional regressor $w^\star$. This problem has a long history of study in Statistics and Machine Learning going back to the works of (Galton, 1897; Tobin, 1958) and more recently in, e.g., (Daskalakis et al., 2019; 2021; Lee et al., 2023; 2024). Despite this long history, however, most prior works are limited to the special case where $S^\star$ is precisely known. The more practically relevant case, where $S^\star$ is unknown and must be learned from data, remains open: indeed, here the only available algorithms require strong assumptions on the distribution of the feature vectors (e.g., Gaussianity) and, even then, have a $d^{\mathrm{poly} (1/\varepsilon)}$ run time for achieving $\varepsilon$ accuracy.
  In this work, we give the first algorithm for truncated linear regression with unknown survival set that runs in $\mathrm{poly} (d/\varepsilon)$ time, by only requiring that the feature vectors are sub-Gaussian. Our algorithm relies on a novel subroutine for efficiently learning unions of a bounded number of intervals using access to positive examples (without any negative examples) under a certain smoothness condition. This learning guarantee adds to the line of works on positive-only PAC learning and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12534v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandros Kouridakis, Anay Mehrotra, Alkis Kalavasis, Constantine Caramanis</dc:creator>
    </item>
    <item>
      <title>The Complexity of Homomorphism Reconstruction Revisited</title>
      <link>https://arxiv.org/abs/2602.12780</link>
      <description>arXiv:2602.12780v1 Announce Type: cross 
Abstract: We revisit the algorithmic problem of reconstructing a graph from homomorphism counts that has first been studied in (B\"oker et al., STACS 2024): given graphs $F_1,\ldots,F_k$ and counts $m_1,\ldots,m_k$, decide if there is a graph $G$ such that the number of homomorphisms from $F_i$ to $G$ is $m_i$, for all $i$. We prove that the problem is NEXP-hard if the counts $m_i$ are specified in binary and $\Sigma_2^p$-complete if they are in unary.
  Furthermore, as a positive result, we show that the unary version can be solved in polynomial time if the constraint graphs are stars of bounded size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12780v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Gervens, Martin Grohe, Louis H\"artel, Philipp Silva da Fonseca</dc:creator>
    </item>
    <item>
      <title>Limits of Kernelization and Parametrization for Phylogenetic Diversity with Dependencies</title>
      <link>https://arxiv.org/abs/2602.12959</link>
      <description>arXiv:2602.12959v1 Announce Type: cross 
Abstract: In the Maximize Phylogenetic Diversity problem, we are given a phylogenetic tree that represents the genetic proximity of species, and we are asked to select a subset of species of maximum phylogenetic diversity to be preserved through conservation efforts, subject to budgetary constraints that allow only k species to be saved. This neglects that it is futile to preserve a predatory species if we do not also preserve at least a subset of the prey it feeds on. Thus, in the Optimizing PD with Dependencies ($\epsilon$-PDD) problem, we are additionally given a food web that represents the predator-prey relationships between species. The goal is to save a set of k species of maximum phylogenetic diversity such that for every saved species, at least one of its prey is also saved. This problem is NP-hard even when the phylogenetic tree is a star. The $\alpha$-PDD problem alters PDD by requiring that at least some fraction $\alpha$ of the prey of every saved species are also saved. In this paper, we study the parameterized complexity of $\alpha$-PDD. We prove that the problem is W[1]-hard and in XP when parameterized by the solution size k, the diversity threshold D, or their complements. When parameterized by the vertex cover number of the food web, $\alpha$-PDD is fixed-parameter tractable (FPT). A key measure of the computational difficulty of a problem that is FPT is the size of the smallest kernel that can be obtained. We prove that, when parameterized by the distance to clique, 1-PDD admits a linear kernel. Our main contribution is to prove that $\alpha$-PDD does not admit a polynomial kernel when parameterized by the vertex cover number plus the diversity threshold D, even if the phylogenetic tree is a star. This implies the non-existence of a polynomial kernel for $\alpha$-PDD also when parameterized by a range of structural parameters of the food web, such as its dist[...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12959v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels Holtgrefe, Jannik Schestag, Norbert Zeh</dc:creator>
    </item>
    <item>
      <title>Out-of-Order Membership to Regular Languages</title>
      <link>https://arxiv.org/abs/2602.13100</link>
      <description>arXiv:2602.13100v1 Announce Type: cross 
Abstract: We introduce the task of out-of-order membership to a formal language L, where the letters of a word w are revealed one by one in an adversarial order. The length |w| is known in advance, but the content of w is streamed as pairs (i, w[i]), received exactly once for each position i, in arbitrary order. We study efficient algorithms for this task when L is regular, seeking tight complexity bounds as a function of |w| for a fixed target language. Most of our results apply to an algebraically defined variant dubbed out-of-order evaluation: this problem is defined for a fixed finite monoid or semigroup S, and our goal is to compute the ordered product of the streamed elements of w.
  We show that, for any fixed regular language or finite semigroup, both problems can be solved in constant time per streamed symbol and in linear space. However, the precise space complexity strongly depends on the algebraic structure of the target language or evaluation semigroup. Our main contributions are therefore to show (deterministic) space complexity characterizations, which we do for out-of-order evaluation of monoids and semigroups.
  For monoids, we establish a trichotomy: the space complexity is either {\Theta}(1), {\Theta}(log n), or {\Theta}(n), where n = |w|. More specifically, the problem admits a constant-space solution for commutative monoids, while all non-commutative monoids require {\Omega}(log n) space. We further identify a class of monoids admitting an O(log n)-space algorithm, and show that all remaining monoids require {\Omega}(n) space.
  For general semigroups, the situation is more intricate. We characterize a class of semigroups admitting constant-space algorithms for out-of-order evaluation, and show that semigroups outside this class require at least {\Omega}(log n) space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13100v1</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Amarilli, Sebastien Labbe, Charles Paperman</dc:creator>
    </item>
    <item>
      <title>Which Algorithms Can Graph Neural Networks Learn?</title>
      <link>https://arxiv.org/abs/2602.13106</link>
      <description>arXiv:2602.13106v1 Announce Type: cross 
Abstract: In recent years, there has been growing interest in understanding neural architectures' ability to learn to execute discrete algorithms, a line of work often referred to as neural algorithmic reasoning. The goal is to integrate algorithmic reasoning capabilities into larger neural pipelines. Many such architectures are based on (message-passing) graph neural networks (MPNNs), owing to their permutation equivariance and ability to deal with sparsity and variable-sized inputs. However, existing work is either largely empirical and lacks formal guarantees or it focuses solely on expressivity, leaving open the question of when and how such architectures generalize beyond a finite training set. In this work, we propose a general theoretical framework that characterizes the sufficient conditions under which MPNNs can learn an algorithm from a training set of small instances and provably approximate its behavior on inputs of arbitrary size. Our framework applies to a broad class of algorithms, including single-source shortest paths, minimum spanning trees, and general dynamic programming problems, such as the $0$-$1$ knapsack problem. In addition, we establish impossibility results for a wide range of algorithmic tasks, showing that standard MPNNs cannot learn them, and we derive more expressive MPNN-like architectures that overcome these limitations. Finally, we refine our analysis for the Bellman-Ford algorithm, yielding a substantially smaller required training set and significantly extending the recent work of Nerem et al. [2025] by allowing for a differentiable regularization loss. Empirical results largely support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13106v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Solveig Wittig, Antonis Vasileiou, Robert R. Nerem, Timo Stoll, Floris Geerts, Yusu Wang, Christopher Morris</dc:creator>
    </item>
    <item>
      <title>Learning to Approximate Uniform Facility Location via Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2602.13155</link>
      <description>arXiv:2602.13155v1 Announce Type: cross 
Abstract: There has been a growing interest in using neural networks, especially message-passing neural networks (MPNNs), to solve hard combinatorial optimization problems heuristically. However, existing learning-based approaches for hard combinatorial optimization tasks often rely on supervised training data, reinforcement learning, or gradient estimators, leading to significant computational overhead, unstable training, or a lack of provable performance guarantees. In contrast, classical approximation algorithms offer such performance guarantees under worst-case inputs but are non-differentiable and unable to adaptively exploit structural regularities in natural input distributions. We address this dichotomy with the fundamental example of Uniform Facility Location (UniFL), a variant of the combinatorial facility location problem with applications in clustering, data summarization, logistics, and supply chain design. We develop a fully differentiable MPNN model that embeds approximation-algorithmic principles while avoiding the need for solver supervision or discrete relaxations. Our approach admits provable approximation and size generalization guarantees to much larger instances than seen during training. Empirically, we show that our approach outperforms standard non-learned approximation algorithms in terms of solution quality, closing the gap with computationally intensive integer linear programming approaches. Overall, this work provides a step toward bridging learning-based methods and approximation algorithms for discrete optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13155v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chendi Qian, Christopher Morris, Stefanie Jegelka, Christian Sohler</dc:creator>
    </item>
    <item>
      <title>Improved Regret Guarantees for Online Mirror Descent using a Portfolio of Mirror Maps</title>
      <link>https://arxiv.org/abs/2602.13177</link>
      <description>arXiv:2602.13177v1 Announce Type: cross 
Abstract: OMD and its variants give a flexible framework for OCO where the performance depends crucially on the choice of the mirror map. While the geometries underlying OPGD and OEG, both special cases of OMD, are well understood, it remains a challenging open question on how to construct an optimal mirror map for any given constrained set and a general family of loss functions, e.g., sparse losses. Motivated by parameterizing a near-optimal set of mirror maps, we consider a simpler question: is it even possible to obtain polynomial gains in regret by using mirror maps for geometries that interpolate between $L_1$ and $L_2$, which may not be possible by restricting to only OEG ($L_1$) or OPGD ($L_2$).
  Our main result answers this question positively. We show that mirror maps based on block norms adapt better to the sparsity of loss functions, compared to previous $L_p$ (for $p \in [1, 2]$) interpolations. In particular, we construct a family of online convex optimization instances in $\mathbb{R}^d$, where block norm-based mirror maps achieve a provable polynomial (in $d$) improvement in regret over OEG and OPGD for sparse loss functions. We then turn to the setting in which the sparsity level of the loss functions is unknown. In this case, the choice of geometry itself becomes an online decision problem. We first show that naively switching between OEG and OPGD can incur linear regret, highlighting the intrinsic difficulty of geometry selection. To overcome this issue, we propose a meta-algorithm based on multiplicative weights that dynamically selects among a family of uniform block norms. We show that this approach effectively tunes OMD to the sparsity of the losses, yielding adaptive regret guarantees. Overall, our results demonstrate that online mirror-map selection can significantly enhance the ability of OMD to exploit sparsity in online convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13177v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swati Gupta, Jai Moondra, Mohit Singh</dc:creator>
    </item>
    <item>
      <title>Exactly simulating stochastic chemical reaction networks in sub-constant time per reaction</title>
      <link>https://arxiv.org/abs/2508.04079</link>
      <description>arXiv:2508.04079v2 Announce Type: replace 
Abstract: The model of chemical reaction networks is among the oldest and most widely studied and used in natural science. The model describes reactions among abstract chemical species, for instance $A + B \to C$, which indicates that if a molecule of type $A$ interacts with a molecule of type $B$ (the reactants), they may stick together to form a molecule of type $C$ (the product). The standard algorithm for simulating (discrete, stochastic) chemical reaction networks is the Gillespie algorithm [JPC 1977], which stochastically simulates one reaction at a time, so to simulate $\ell$ consecutive reactions, it requires total running time $\Omega(\ell)$.
  We give the first chemical reaction network stochastic simulation algorithm that can simulate $\ell$ reactions, provably preserving the exact stochastic dynamics (sampling from precisely the same distribution as the Gillespie algorithm), yet using time provably sublinear in $\ell$. Under reasonable assumptions, our algorithm can simulate $\ell$ reactions among $n$ total molecules in time $O(\ell/\sqrt n)$ when $\ell \ge n^{5/4}$, and in time $O(\ell/n^{2/5})$ when $n \le \ell \le n^{5/4}$. Our work adapts an algorithm of Berenbrink, Hammer, Kaaser, Meyer, Penschuck, and Tran [ESA 2020] for simulating the distributed computing model known as population protocols, extending it (in a very nontrivial way) to the more general chemical reaction network setting.
  We provide an implementation of our algorithm as a Python package, with the core logic implemented in Rust, with remarkably fast performance in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04079v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Petrack, David Doty</dc:creator>
    </item>
    <item>
      <title>On Hardness and Approximation of Broadcasting in Structured Graphs</title>
      <link>https://arxiv.org/abs/2510.20026</link>
      <description>arXiv:2510.20026v2 Announce Type: replace 
Abstract: We study the Telephone Broadcasting problem in graphs with restricted structure. Given a designated source in an undirected graph, the goal is to disseminate a message to all vertices in the minimum number of rounds, where in each round every informed vertex may inform at most one neighbor. For general graphs, the problem is NP-hard. Recent work shows that the problem remains NP-hard even on restricted graph classes such as graphs of treewidth 2 [Tale 2025], cactus graphs of pathwidth 2 [Aminian et~al. 2025] and graphs at distance 1 to a path forest [Egami et~al. 2025].
  In this work, we investigate the problem in several graph families. We first prove NP-hardness for cycle-star graphs, graphs formed by k cycles sharing a single vertex, as well as melon graphs, graphs formed by k paths with shared endpoints. Despite multiple efforts to understand the problem in these simple graph families, the computational complexity of the problem remained unsettled. Our hardness results answer open questions by Bhabak and Harutyunyan [2015] and Harutyunyan and Hovhannisyan [2023] concerning the problem's complexity in cycle-star and melon graphs, respectively.
  On the positive side, we present EPTASs for cycle-star and melon graphs, improving over the best existing approximation factors of 2 for both graph families. Moreover, we identify a structural frontier for tractability by showing that the problem is solvable in polynomial time on graphs of bounded cutwidth, a class that generalizes other families such as graphs of bounded bandwidth. This result subsumes existing tractability results for graph families such as necklace graphs.
  Finally, for split graphs, a fundamental class of highly structured graphs, we obtain a polynomial-time algorithm with approximation factor 1.76. This improves on the previously known factor 2 bound; the same approach also applies to the multi-source setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20026v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Bringolf, Hovhannes A. Harutyunyan, Shahin Kamali, Seyed-Mohammad Seyed-Javadi</dc:creator>
    </item>
    <item>
      <title>Implementation and Brief Experimental Analysis of the Duan et al. (2025) Algorithm for Single-Source Shortest Paths</title>
      <link>https://arxiv.org/abs/2511.03007</link>
      <description>arXiv:2511.03007v3 Announce Type: replace 
Abstract: We present an implementation and experimental analysis of the deterministic algorithm proposed by Duan et al. (2025) for the Single-Source Shortest Path (SSSP) problem, which achieves the best-known asymptotic upper bound of $O(m \log^{2/3} n)$. We provide a worst-case C++ implementation of this algorithm utilizing $O(n \log^{1/3} n)$ space, as well as a variant that reduces memory usage to $O(n)$ while maintaining the same time complexity in expectation. We compare these implementations against Dijkstra's algorithm on sparse random graphs, grids, and U.S. road networks with up to 10 million vertices. Our results show that while the implementations adhere to their theoretical complexity bounds, large constant factors hinder their practical utility; Dijkstra's algorithm remains 3 to 4 times faster in all tested scenarios. Furthermore, we estimate that the number of vertices would need to vastly exceed $10^{67}$ for the worst-case implementation to outperform Dijkstra's. These findings suggest that a substantial reduction in constant factors is required before this theoretical breakthrough can displace established methods in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03007v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Castro, Thailsson Clementino, Rosiane de Freitas</dc:creator>
    </item>
    <item>
      <title>Adaptive Power Iteration Method for Differentially Private PCA</title>
      <link>https://arxiv.org/abs/2602.11454</link>
      <description>arXiv:2602.11454v2 Announce Type: replace 
Abstract: We study $(\epsilon,\delta)$-differentially private algorithms for the problem of approximately computing the top singular vector of a matrix $A\in\mathbb{R}^{n\times d}$ where each row of $A$ is a datapoint in $\mathbb{R}^{d}$. In our privacy model, neighboring inputs differ by one single row/datapoint. We study the private variant of the power iteration method, which is widely adopted in practice. Our algorithm is based on a filtering technique which adapts to the coherence parameter of the input matrix. This technique provides a utility that goes beyond the worst-case guarantees for matrices with low coherence parameter. Our work departs from and complements the work by Hardt-Roth (STOC 2013) which designed a private power iteration method for the privacy model where neighboring inputs differ in one single entry by at most 1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11454v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ta Duy Nguyen, Alina Ene, Huy Le Nguyen</dc:creator>
    </item>
    <item>
      <title>Extending Ghouila-Houri's Characterization of Comparability Graphs to Temporal Graphs</title>
      <link>https://arxiv.org/abs/2510.06849</link>
      <description>arXiv:2510.06849v2 Announce Type: replace-cross 
Abstract: An orientation of a given static graph is called transitive if for any three vertices $a,b,c$, the presence of arcs $(a,b)$ and $(b,c)$ forces the presence of the arc $(a,c)$. If only the presence of an arc between $a$ and $c$ is required, but its orientation is unconstrained, the orientation is called quasi-transitive. A fundamental result presented by Ghouila-Houri guarantees that any static graph admitting a quasi-transitive orientation also admits a transitive orientation. In a seminal work, Mertzios et al. introduced the notion of temporal transitivity in order to model information flows in simple temporal networks. We revisit the model introduced by Mertzios et al. and propose an analogous to Ghouila-Houri's characterization for the temporal scenario. We present a structure theorem that will allow us to express by a 2-SAT formula all the constraints imposed by temporal transitive orientations. The latter produces an efficient recognition algorithm for graphs admitting such orientations. Additionally, we extend the temporal transitivity model to temporal graphs having multiple time-labels associated to their edges and claim that the previous results hold in the multilabel setting. Finally, we propose a characterization of temporal comparability graphs via forbidden temporal ordered patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06849v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Charbit, Michel Habib, Amalia Sorondo</dc:creator>
    </item>
  </channel>
</rss>
