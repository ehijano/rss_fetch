<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Feb 2025 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Emergence of Self-Awareness in Artificial Systems: A Minimalist Three-Layer Approach to Artificial Consciousness</title>
      <link>https://arxiv.org/abs/2502.06810</link>
      <description>arXiv:2502.06810v1 Announce Type: new 
Abstract: This paper proposes a minimalist three-layer model for artificial consciousness, focusing on the emergence of self-awareness. The model comprises a Cognitive Integration Layer, a Pattern Prediction Layer, and an Instinctive Response Layer, interacting with Access-Oriented and Pattern-Integrated Memory systems. Unlike brain-replication approaches, we aim to achieve minimal self-awareness through essential elements only. Self-awareness emerges from layer interactions and dynamic self-modeling, without initial explicit self-programming. We detail each component's structure, function, and implementation strategies, addressing technical feasibility. This research offers new perspectives on consciousness emergence in artificial systems, with potential implications for human consciousness understanding and adaptable AI development. We conclude by discussing ethical considerations and future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06810v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurando Iida</dc:creator>
    </item>
    <item>
      <title>A Relativistic Theory of Consciousness (shorten version)</title>
      <link>https://arxiv.org/abs/2502.07247</link>
      <description>arXiv:2502.07247v1 Announce Type: new 
Abstract: This paper is a shorten version of the full paper that was published in the journal Frontiers of Psychology in May 2022. In recent decades, the scientific study of consciousness has significantly increased our understanding of this elusive phenomenon. Yet, despite critical development in our understanding of the functional side of consciousness, we still lack a fundamental theory regarding its phenomenal aspect. The phenomenal aspect of consciousness is the first-person answer to what it is like question, and it has thus far proved recalcitrant to direct scientific investigation. The question of how the brain, or any cognitive system, can create conscious experience out of neural representations poses a great conundrum to science. Naturalistic dualists argue that it is composed of a primitive, private, nonreductive element of reality. Illusionists, on the other hand, argue that it is merely a cognitive illusion. We contend that both the dualist and illusionist positions are flawed because they tacitly assume consciousness to be an absolute property that does not depend on the observer. We developed a conceptual and a mathematical argument for a relativistic theory of consciousness in which a system either has or does not have phenomenal consciousness with respect to some observer. According to the theory, Phenomenal consciousness is neither private nor delusional, just relativistic. In the frame of reference of the cognitive system, it will be observable (first-person perspective) and in other frame of reference it will not (third-person perspective). These two cognitive frames of reference are both correct, just as in the case of an observer that claims to be at rest while another will claim that the observer has constant velocity. Neither observer position can be privileged, as they both describe the same underlying reality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07247v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.3389/fpsyg.2021.704270</arxiv:DOI>
      <arxiv:journal_reference>A Relativistic theory of consciousness." Frontiers in Psychology 12 (2022): 704270</arxiv:journal_reference>
      <dc:creator>Nir Lahav, Zachariah A. Neemeh</dc:creator>
    </item>
    <item>
      <title>Understanding and controlling the geometry of memory organization in RNNs</title>
      <link>https://arxiv.org/abs/2502.07256</link>
      <description>arXiv:2502.07256v1 Announce Type: new 
Abstract: Training recurrent neural networks (RNNs) is a high-dimensional process that requires updating numerous parameters. Therefore, it is often difficult to pinpoint the underlying learning mechanisms. To address this challenge, we propose to gain mechanistic insights into the phenomenon of \emph{abrupt learning} by studying RNNs trained to perform diverse short-term memory tasks. In these tasks, RNN training begins with an initial search phase. Following a long period of plateau in accuracy, the values of the loss function suddenly drop, indicating abrupt learning. Analyzing the neural computation performed by these RNNs reveals geometric restructuring (GR) in their phase spaces prior to the drop. To promote these GR events, we introduce a temporal consistency regularization that accelerates (bioplausible) training, facilitates attractor formation, and enables efficient learning in strongly connected networks. Our findings offer testable predictions for neuroscientists and emphasize the need for goal-agnostic secondary mechanisms to facilitate learning in biological and artificial networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07256v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Udith Haputhanthri, Liam Storan, Yiqi Jiang, Tarun Raheja, Adam Shai, Orhun Akengin, Nina Miolane, Mark J. Schnitzer, Fatih Dinc, Hidenori Tanaka</dc:creator>
    </item>
    <item>
      <title>From Thought to Action: How a Hierarchy of Neural Dynamics Supports Language Production</title>
      <link>https://arxiv.org/abs/2502.07429</link>
      <description>arXiv:2502.07429v1 Announce Type: new 
Abstract: Humans effortlessly communicate their thoughts through intricate sequences of motor actions. Yet, the neural processes that coordinate language production remain largely unknown, in part because speech artifacts limit the use of neuroimaging. To elucidate the unfolding of language production in the brain, we investigate with magnetoencephalography (MEG) and electroencephalography (EEG) the neurophysiological activity of 35 skilled typists, while they typed sentences on a keyboard. This approach confirms the hierarchical predictions of linguistic theories: the neural activity preceding the production of each word is marked by the sequential rise and fall of context-, word-, syllable-, and letter-level representations. Remarkably, each of these neural representations is maintained over long time periods within each level of the language hierarchy. This phenomenon results in a superposition of successive representations that is supported by a hierarchy of dynamic neural codes. Overall, these findings provide a precise computational breakdown of the neural dynamics that coordinate the production of language in the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07429v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Mingfang (Lucy),  Zhang, Jarod L\'evy, St\'ephane d'Ascoli, J\'er\'emy Rapin, F. -Xavier Alario, Pierre Bourdillon, Svetlana Pinet, Jean-R\'emi King</dc:creator>
    </item>
    <item>
      <title>Human foraging strategies flexibly adapt to resource distribution and time constraints</title>
      <link>https://arxiv.org/abs/2408.01350</link>
      <description>arXiv:2408.01350v2 Announce Type: replace 
Abstract: Foraging is a crucial activity, yet the extent to which humans employ flexible versus rigid strategies remains unclear. This study investigates how individuals adapt their foraging strategies in response to resource distribution and foraging time constraints. For this, we designed a video-game-like foraging task that requires participants to navigate a four-areas environment to collect coins from treasure boxes within a limited time. This task engages multiple cognitive abilities, such as navigation, learning, and memorization of treasure box locations. Findings indicate that participants adjust their foraging strategies -- encompassing both stay-or-leave decisions, such as the number of boxes opened in initial areas and behavioral aspects, such as the time to navigate from box to box -- depending on both resource distribution and foraging time. Additionally, they improved their performance over time as an effect of both enhanced navigation skills and adaptation of foraging strategies. Finally, participants' performance was initially distant from the reward-maximizing performance of optimal agents due to the learning process humans undergo; however, it approximated the optimal agent's performance towards the end of the task, without fully reaching it. These results highlight the flexibility of human foraging behavior and underscore the importance of employing optimality models and ecologically rich scenarios to study foraging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01350v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Valeria Simonelli, Davide Nuzzi, Gian Luca Lancia, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>A state-space framework for causal detection of hippocampal ripple-replay events</title>
      <link>https://arxiv.org/abs/2502.05394</link>
      <description>arXiv:2502.05394v2 Announce Type: replace 
Abstract: Hippocampal ripple-replay events are typically identified using a two-step process that at each time point uses past and future data to determine whether an event is occurring. This prevents researchers from identifying these events in real time for closed-loop experiments. It also prevents the identification of periods of nonlocal representation that are not accompanied by large changes in the spectral content of the local field potentials (LFPs). In this work, we present a new state-space model framework that is able to detect concurrent changes in the rhythmic structure of LFPs with nonlocal activity in place cells to identify ripple-replay events in a causal manner. The model combines latent factors related to neural oscillations, represented space, and switches between coding properties to explain simultaneously the spiking activity from multiple units and the rhythmic content of LFPs recorded from multiple sources. The model is temporally causal, meaning that estimates of the switching state can be made at each instant using only past information from the spike and LFP signals, or can be combined with future data to refine those estimates. We applied this model framework to simulated and real hippocampal data to demonstrate its performance in identifying ripple-replay events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05394v2</guid>
      <category>q-bio.NC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sirui Zeng, Uri T. Eden</dc:creator>
    </item>
    <item>
      <title>A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes</title>
      <link>https://arxiv.org/abs/2408.01322</link>
      <description>arXiv:2408.01322v3 Announce Type: replace-cross 
Abstract: The objects we perceive guide our eye movements when observing real-world dynamic scenes. Yet, gaze shifts and selective attention are critical for perceiving details and refining object boundaries. Object segmentation and gaze behavior are, however, typically treated as two independent processes. Here, we present a computational model that simulates these processes in an interconnected manner and allows for hypothesis-driven investigations of distinct attentional mechanisms. Drawing on an information processing pattern from robotics, we use a Bayesian filter to recursively segment the scene, which also provides an uncertainty estimate for the object boundaries that we use to guide active scene exploration. We demonstrate that this model closely resembles observers' free viewing behavior on a dataset of dynamic real-world scenes, measured by scanpath statistics, including foveation duration and saccade amplitude distributions used for parameter fitting and higher-level statistics not used for fitting. These include how object detections, inspections, and returns are balanced and a delay of returning saccades without an explicit implementation of such temporal inhibition of return. Extensive simulations and ablation studies show that uncertainty promotes balanced exploration and that semantic object cues are crucial to forming the perceptual units used in object-based attention. Moreover, we show how our model's modular design allows for extensions, such as incorporating saccadic momentum or pre-saccadic attention, to further align its output with human scanpaths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01322v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1167/jov.25.2.6</arxiv:DOI>
      <arxiv:journal_reference>Journal of Vision 2025;25(2):6</arxiv:journal_reference>
      <dc:creator>Vito Mengers, Nicolas Roth, Oliver Brock, Klaus Obermayer, Martin Rolfs</dc:creator>
    </item>
    <item>
      <title>ScholaWrite: A Dataset of End-to-End Scholarly Writing Process</title>
      <link>https://arxiv.org/abs/2502.02904</link>
      <description>arXiv:2502.02904v2 Announce Type: replace-cross 
Abstract: Writing is a cognitively demanding task involving continuous decision-making, heavy use of working memory, and frequent switching between multiple activities. Scholarly writing is particularly complex as it requires authors to coordinate many pieces of multiform knowledge. To fully understand writers' cognitive thought process, one should fully decode the end-to-end writing data (from individual ideas to final manuscript) and understand their complex cognitive mechanisms in scholarly writing. We introduce ScholaWrite dataset, the first-of-its-kind keystroke logs of an end-to-end scholarly writing process for complete manuscripts, with thorough annotations of cognitive writing intentions behind each keystroke. Our dataset includes LaTeX-based keystroke data from five preprints with nearly 62K total text changes and annotations across 4 months of paper writing. ScholaWrite shows promising usability and applications (e.g., iterative self-writing) for the future development of AI writing assistants for academic research, which necessitate complex methods beyond LLM prompting. Our experiments clearly demonstrated the importance of collection of end-to-end writing data, rather than the final manuscript, for the development of future writing assistants to support the cognitive thinking process of scientists. Our de-identified dataset, demo, and code repository are available on our project page.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02904v2</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linghe Wang, Minhwa Lee, Ross Volkov, Luan Tuyen Chau, Dongyeop Kang</dc:creator>
    </item>
  </channel>
</rss>
