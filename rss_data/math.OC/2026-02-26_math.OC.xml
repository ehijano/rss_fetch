<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 02:41:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimal extraction with an impact on diffusion-jump pricing</title>
      <link>https://arxiv.org/abs/2602.21274</link>
      <description>arXiv:2602.21274v1 Announce Type: new 
Abstract: We study an optimal extraction problem where the agent's actions in the spot market exert an additive proportional negative impact on the commodity price. The commodity price dynamics, prior to any activity by the agent, are evolved by a drifted Brownian motion with jumps. The agent's primary aim is to identify an optimal extraction strategy that maximizes their expected net profits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21274v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johanna Garz\'on, Jhonatan S. Mora Rodr\'iguez, Harold A. Moreno-Franco</dc:creator>
    </item>
    <item>
      <title>An accelerated rearrangement method for two-phase composite optimization</title>
      <link>https://arxiv.org/abs/2602.21352</link>
      <description>arXiv:2602.21352v1 Announce Type: new 
Abstract: We propose and analyze an Accelerated Rearrangement Method (ARM) for solving a class of nonconvex optimization problems involving two-phase composites. These problems include maximizing the (work) energy of a membrane governed by the Poisson equation and minimizing the principal eigenvalue of a weighted Dirichlet-Laplacian, both subject to material distribution constraints. Building on the classical rearrangement method, we introduce momentum-like acceleration by extrapolating the Fr\'echet derivative, leading to a provably convergent algorithm. We also introduce a restarted variant that guarantees monotonic improvement of the objective. In one dimension, we derive asymptotic convergence rates for ARM and prove that they improve upon the classical rearrangement method. Numerical experiments in both two and three dimensions confirm the accelerated convergence and demonstrate practical efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21352v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chiu-Yen Kao, Seyyed Abbas Mohammadi, Braxton Osting</dc:creator>
    </item>
    <item>
      <title>Fenchel-Young Estimators of Perturbed Utility Models</title>
      <link>https://arxiv.org/abs/2602.21376</link>
      <description>arXiv:2602.21376v1 Announce Type: new 
Abstract: The Perturbed Utility Model framework offers a powerful generalization of discrete choice analysis, unifying models like Multinomial Logit and Sparsemax through convex optimization. However, standard Maximum Likelihood Estimation (MLE) faces severe theoretical and numerical challenges when applied to this broader class, particularly regarding non-convexity and instability in sparse regimes. To resolve these issues, this paper introduces a unified estimation framework based on the Fenchel-Young loss. By leveraging the intrinsic convex conjugate structure of PUMs, we demonstrate that the Fenchel-Young estimator guarantees global convexity and bounded gradients, providing a mathematically natural alternative to MLE. Addressing the critical challenge of data scarcity, we further extend this framework via Wasserstein Distributionally Robust Optimization. We first derive an exact finite-dimensional reformulation of the infinite-dimensional primal problem, establishing its theoretical convexity. However, recognizing that the resulting worst-case constraints involve computationally intractable inner maximizations, we subsequently construct a tractable safe approximation by exploiting the global Lipschitz continuity of the Fenchel-Young loss. Through this tractable formulation, we uncover a rigorous geometric unification: two canonical regularization techniques, standard L2-regularization and the margin-enforcing Hinge loss, emerge mathematically as specific limiting cases of our distributionally robust estimator. Extensive experiments on synthetic data and the Swissmetro benchmark validate that the proposed framework significantly outperforms traditional methods, recovering stable preferences even under severe data limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21376v1</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Lin, Yafeng Yin, Tianming Liu</dc:creator>
    </item>
    <item>
      <title>Narrowing the Gap: SOS Ranks of $4 \times 3$ Biquadratic Forms and a Lower Bound of $8$</title>
      <link>https://arxiv.org/abs/2602.21570</link>
      <description>arXiv:2602.21570v1 Announce Type: new 
Abstract: We investigate the maximum sum-of-squares (SOS) rank of biquadratic forms in the critical case of $4 \times 3$ variables, where the general bounds are currently $7 \leq \mathrm{BSR}(4,3) \leq 11$. By analyzing two important structured subclasses, we obtain exact determinations and improved upper bounds that significantly narrow this gap.
  For simple biquadratic forms those containing only distinct terms of the type $x_i^2 y_j^2$ we prove that the maximum achievable SOS rank is exactly 7, a value attained by a form corresponding to a $C_4$-free bipartite graph with the maximum number of edges. This settles the question for simple forms.
  For $y$-deficient biquadratic forms a class introduced here that permits cross terms among two of the three $y$-variables while the third appears only in pure square terms we prove an upper bound of $9$ by combining Calder\"{o}n's theorem on $m\times 2$ forms with the known value $\mathrm{BSR}(4,2) = 5$.
  Our main result is a constructive proof that $\mathrm{BSR}(4,3) \geq 8$. We present an explicit non-simple, non-deficient $4\times 3$ biquadratic form and prove it requires exactly eight squares, thereby improving the general lower bound. This shows that any form achieving a rank higher than $8$ must possess a more complex algebraic structure, and it reduces the search space for determining the true value of $\mathrm{BSR}(4,3)$. Connections to Zarankiewicz numbers, extremal graph theory, and classical results on sums of squares are highlighted throughout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21570v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Xu, Chunfeng Cui, Liqun Qi</dc:creator>
    </item>
    <item>
      <title>Sum-Rate Maximization via Convex Optimization Using Subgradient Projections Onto Nonlinear Spectral Radius Constraint Sets</title>
      <link>https://arxiv.org/abs/2602.21592</link>
      <description>arXiv:2602.21592v1 Announce Type: new 
Abstract: We solve the (weighted) sum-rate maximization problem over the set of achievable rates characterized by a nonlinear spectral radius function. This set has been recently shown to be convex in some practically relevant settings in modern wireless networks, including cell-less networks. However, even under convexity, sum-rate maximization is challenging because the nonlinear spectral radius characterization of the achievable rate region is difficult to handle directly. We overcome this difficulty by exploiting subgradient projections onto the level sets of suitably reformulated spectral radius functions. Notably, the derived subgradient projection algorithm provably converges to the global optimum of the sum-rate maximization problem under the convexity condition. The efficacy of the proposed algorithm is illustrated in simulations for cell-less networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21592v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroki Kuroda, Renato Luis Garrido Cavalcante</dc:creator>
    </item>
    <item>
      <title>Survey on Neural Routing Solvers</title>
      <link>https://arxiv.org/abs/2602.21761</link>
      <description>arXiv:2602.21761v1 Announce Type: new 
Abstract: Neural routing solvers (NRSs) that leverage deep learning to tackle vehicle routing problems have demonstrated notable potential for practical applications. By learning implicit heuristic rules from data, NRSs replace the handcrafted counterparts in classic heuristic frameworks, thereby reducing reliance on costly manual design and trial-and-error adjustments. This survey makes two main contributions: (1) The heuristic nature of NRSs is highlighted, and existing NRSs are reviewed from the perspective of heuristics. A hierarchical taxonomy based on heuristic principles is further introduced. (2) A generalization-focused evaluation pipeline is proposed to address limitations of the conventional pipeline. Comparative benchmarking of representative NRSs across both pipelines uncovers a series of previously unreported gaps in current research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21761v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunpeng Ba, Xi Lin, Changliang Zhou, Ruihao Zheng, Zhenkun Wang, Xinyan Liang, Zhichao Lu, Jianyong Sun, Yuhua Qian, Qingfu Zhang</dc:creator>
    </item>
    <item>
      <title>Non-Extreme Individual Minima for Improved Pareto Front Sampling Efficiency and Decision-Making</title>
      <link>https://arxiv.org/abs/2602.21883</link>
      <description>arXiv:2602.21883v1 Announce Type: new 
Abstract: In multi-objective optimization, the set of optimal trade-offs -- the Pareto front -- often contains regions that are extremely steep or flat. The Pareto optimal points in these regions are typically of limited interest for decision-making, as the marginal rate of substitution is extreme: a marginal improvement in one objective necessitates a significant deterioration in at least one other objective. These unfavorable trade-offs frequently occur near the individual minima, where single objectives attain their minimum values without considering the remaining criteria.
  To address this, we propose the concept of \emph{non-extreme individual minima} that relies on the notion of $L$-practical proper efficiency. These points can serve as a less sensitive replacement for \emph{standard} individual minima in subsequent related methods. Specifically, they allow for a more practical restriction of the Pareto front sampling within a refined utopia-nadir hyperbox, provide a meaningful basis for image space normalization, and can enhance decision-making techniques, such as knee-point methods, by focusing on regions with acceptable trade-offs.
  We provide a computationally efficient algorithm to determine these non-extreme individual minima by solving at most $2n_J$ standard weighted-sum scalarizations, where $n_J$ is the number of objectives. To ensure robustness across varying objective scales, the method incorporates an integrated image space normalization strategy. Numerical examples, specifically a convex academic case and a non-convex real-world application, demonstrate that the method successfully excludes practically irrelevant regions in the image space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21883v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Herrmann-Wicklmayr, Kathrin Fla{\ss}kamp</dc:creator>
    </item>
    <item>
      <title>Comparison of Linear Systems Across Time Domains: Continuous-time vs. Discrete-time</title>
      <link>https://arxiv.org/abs/2602.21924</link>
      <description>arXiv:2602.21924v1 Announce Type: new 
Abstract: We develop a formal framework for the behavioral comparison of linear systems across different time domains. We accomplish this by introducing the notion of system interpolation, which determines whether the input-state trajectories of a continuous-time system can be realized as piecewise polynomial interpolations of the input-state trajectories of a discrete-time system. In this context, a piecewise polynomial interpolation of a discrete-time signal is characterized as a continuous-time function that coincides with the discrete-time signal at given sampling instants and can be realized as a polynomial of a prescribed degree over intervals between these instants. By representing piecewise polynomial functions as linear combinations of shifted Legendre polynomials, we characterize system interpolation as a subspace inclusion that is completely in terms of system parameters. This therefore allows for a computationally efficient comparison of the input-state behavior of a continuous-time system with that of a discrete-time one. We then exploit this characterization to discretize a given continuous-time system into a discrete-time one. Lastly, given a control specification, we exploit system interpolation to synthesize controllers that ensure satisfaction at each given sampling instant, while they measure the extent of (possible) violation over intervals between these instants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21924v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Armin Pirastehzad, Bart Besselink</dc:creator>
    </item>
    <item>
      <title>Target controllability for a minimum time problem in a trait-structured chemostat model</title>
      <link>https://arxiv.org/abs/2602.21999</link>
      <description>arXiv:2602.21999v1 Announce Type: new 
Abstract: In this paper, we consider a minimum time control problem governed by a trait-structured chemostat model including mutation and one limiting substrate. Our first main result proves the well-posedness of the control-to-state mapping. We subsequently analyze the class of auxostat-type controls, feedback laws designed to regulate substrate concentration, and prove that the corresponding solutions converge to a stationary state of the system. These convergence results are used to show the reachability of a target set corresponding to the selection of a population with a low weighted averaged half-saturation constant. Finally, we show the existence of an optimal control for the minimum time problem associated with reaching the target set. These theoretical findings are completed by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21999v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudia Alvarez-Latuz, Terence Bayen, Jerome Coville</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control with Side Information and Bayesian Learning</title>
      <link>https://arxiv.org/abs/2602.22047</link>
      <description>arXiv:2602.22047v1 Announce Type: new 
Abstract: We study infinite-horizon stochastic optimal control problems with observable side information: a Markov chain that modulates an unknown context-conditional randomness distribution. Since this distribution is unknown, we propose a Bayesian reformulation based on a parametric density model and posterior predictive dynamics, which yields a Bayesian Bellman equation. We prove posterior consistency under Markov samples and, under correct specification and identifiability, uniform convergence of the Bayesian value function. Finally, we establish Bernstein--von Mises-type asymptotic normality for the data-driven contextual optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22047v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Milz, Alexander Shapiro, Enlu Zhou</dc:creator>
    </item>
    <item>
      <title>A Polyhedral Study on Unit Commitment with a Single Type of Binary Variables</title>
      <link>https://arxiv.org/abs/2602.22058</link>
      <description>arXiv:2602.22058v1 Announce Type: new 
Abstract: Efficient power production scheduling is a crucial concern for power system operators aiming to minimize operational costs. Previous mixed-integer linear programming formulations for unit commitment (UC) problems have primarily used two or three types of binary variables. The investigation of strong formulations with a single type of binary variables has been limited, as it is believed to be challenging to derive strong valid inequalities using fewer binary variables, and the reduction of the number of binary variables is often accompanied by a compromise in tightness. To address these issues, this paper considers a formulation for unit commitment using a single type of binary variables and develops strong valid inequality families to enhance the tightness of the formulation. Conditions under which these strong valid inequalities serve as facet-defining inequalities for the single-generator UC polytope are provided. For those large-size valid inequality families, the existence of efficient separation algorithms for determining the most violated inequalities is also discussed. The effectiveness of the proposed single-binary formulation and strong valid inequalities is demonstrated through computational experiments on network-constrained UC problems. The results indicate that the strong valid inequalities presented in this paper are effective in solving UC problems and can also be applied to UC formulations that contain more than one type of binary variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22058v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Tian, Kai Pan, Chung-Lun Li</dc:creator>
    </item>
    <item>
      <title>Applying a Random-Key Optimizer on Mixed Integer Programs</title>
      <link>https://arxiv.org/abs/2602.22173</link>
      <description>arXiv:2602.22173v1 Announce Type: new 
Abstract: Mixed-Integer Programs (MIPs) are NP-hard optimization models that arise in a broad range of decision-making applications, including finance, logistics, energy systems, and network design. Although modern commercial solvers have achieved remarkable progress and perform effectively on many small- and medium-sized instances, their performance often degrades when confronted with large-cale or highly constrained formulations. This paper explores the use of the Random-Key Optimizer (RKO) framework as a flexible, metaheuristic alternative for computing high-quality solutions to MIPs through the design of problem-specific decoders. The proposed approach separates the search process from feasibility enforcement by operating in a continuous random-key space while mapping candidate solutions to feasible integer solutions via efficient decoding procedures. We evaluate the methodology on two representative and structurally distinct benchmark problems: the mean-variance Markowitz portfolio optimization problem with buy-in and cardinality constraints, and the Time-Dependent Traveling Salesman Problem. For each formulation, tailored decoders are developed to reduce the effective search space, promote feasibility, and accelerate convergence. Computational experiments demonstrate that RKO consistently produces competitive, and in several cases superior, solutions compared to a state-of-the-art commercial MIP solver, both in terms of solution quality and computational time. These results highlight the potential of RKO as a scalable and versatile heuristic framework for tackling challenging large-scale MIPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22173v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio A. Chaves, Mauricio G. C. Resende, Carise E. Schmidt, J. Kyle Brubaker, Helmut G. Katzgraber</dc:creator>
    </item>
    <item>
      <title>Exploiting Low-Rank Structure in Max-K-Cut Problems</title>
      <link>https://arxiv.org/abs/2602.20376</link>
      <description>arXiv:2602.20376v1 Announce Type: cross 
Abstract: We approach the Max-3-Cut problem through the lens of maximizing complex-valued quadratic forms and demonstrate that low-rank structure in the objective matrix can be exploited, leading to alternative algorithms to classical semidefinite programming (SDP) relaxations and heuristic techniques. We propose an algorithm for maximizing these quadratic forms over a domain of size $K$ that enumerates and evaluates a set of $O\left(n^{2r-1}\right)$ candidate solutions, where $n$ is the dimension of the matrix and $r$ represents the rank of an approximation of the objective. We prove that this candidate set is guaranteed to include the exact maximizer when $K=3$ (corresponding to Max-3-Cut) and the objective is low-rank, and provide approximation guarantees when the objective is a perturbation of a low-rank matrix. This construction results in a family of novel, inherently parallelizable and theoretically-motivated algorithms for Max-3-Cut. Extensive experimental results demonstrate that our approach achieves performance comparable to existing algorithms across a wide range of graphs, while being highly scalable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20376v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ria Stevens, Fangshuo Liao, Barbara Su, Jianqiang Li, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>A General Equilibrium Theory of Orchestrated AI Agent Systems</title>
      <link>https://arxiv.org/abs/2602.21255</link>
      <description>arXiv:2602.21255v1 Announce Type: cross 
Abstract: We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent is modeled as a firm whose production set Y a $\subset$ H = L 2 ([0, T ], R R ) represents the feasible metric trajectories determined by its frozen model weights. The orchestrator is the consumer, choosing a routing policy over the agent DAG to maximize system welfare subject to a budget constraint evaluated at functional prices p $\in$ H A . These prices-elements of the Hilbert dual of the commodity space-assign a shadow value to each metric of each agent at each instant. We prove, via Brouwer's theorem applied to a finitedimensional approximation V K $\subset$ H, that every such economy admits at least one general equilibrium (p * , y * , $\pi$ * ). A functional Walras' law  holds as a theorem: the value of functional excess demand is zero for all prices, as a consequence of the consumer's budget constraint-not by construction. We further establish Pareto optimality (First Welfare Theorem), decentralizability of Pareto optima (Second Welfare Theorem), and uniqueness with geometric convergence under a contraction condition (Banach). The orchestration dynamics constitute a Walrasian t{\^a}tonnement that converges globally under the contraction condition, unlike classical t{\^a}tonnement (Scarf, 1960). The framework admits a DSGE interpretation with SLO parameters as policy rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21255v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Philippe Garnier (Br.AI.K)</dc:creator>
    </item>
    <item>
      <title>Dynamic Symmetric Point Tracking: Tackling Non-ideal Reference in Analog In-memory Training</title>
      <link>https://arxiv.org/abs/2602.21321</link>
      <description>arXiv:2602.21321v1 Announce Type: cross 
Abstract: Analog in-memory computing (AIMC) performs computation directly within resistive crossbar arrays, offering an energy-efficient platform to scale large vision and language models. However, non-ideal analog device properties make the training on AIMC devices challenging. In particular, its update asymmetry can induce a systematic drift of weight updates towards a device-specific symmetric point (SP), which typically does not align with the optimum of the training objective. To mitigate this bias, most existing works assume the SP is known and pre-calibrate it to zero before training by setting the reference point as the SP. Nevertheless, calibrating AIMC devices requires costly pulse updates, and residual calibration error can directly degrade training accuracy. In this work, we present the first theoretical characterization of the pulse complexity of SP calibration and the resulting estimation error. We further propose a dynamic SP estimation method that tracks the SP during model training, and establishes its convergence guarantees. In addition, we develop an enhanced variant based on chopping and filtering techniques from digital signal processing. Numerical experiments demonstrate both the efficiency and effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21321v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Xiao, Jindan Li, Zhaoxian Wu, Tayfun Gokmen, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Provably Safe Generative Sampling with Constricting Barrier Functions</title>
      <link>https://arxiv.org/abs/2602.21429</link>
      <description>arXiv:2602.21429v1 Announce Type: cross 
Abstract: Flow-based generative models, such as diffusion models and flow matching models, have achieved remarkable success in learning complex data distributions. However, a critical gap remains for their deployment in safety-critical domains: the lack of formal guarantees that generated samples will satisfy hard constraints. We address this by proposing a safety filtering framework that acts as an online shield for any pre-trained generative model. Our key insight is to cooperate with the generative process rather than override it. We define a constricting safety tube that is relaxed at the initial noise distribution and progressively tightens to the target safe set at the final data distribution, mirroring the coarse-to-fine structure of the generative process itself. By characterizing this tube via Control Barrier Functions (CBFs), we synthesize a feedback control input through a convex Quadratic Program (QP) at each sampling step. As the tube is loosest when noise is high and intervention is cheapest in terms of control energy, most constraint enforcement occurs when it least disrupts the model's learned structure. We prove that this mechanism guarantees safe sampling while minimizing the distributional shift from the original model at each sampling step, as quantified by the KL divergence. Our framework applies to any pre-trained flow-based generative scheme requiring no retraining or architectural modifications. We validate the approach across constrained image generation, physically-consistent trajectory sampling, and safe robotic manipulation policies, achieving 100% constraint satisfaction while preserving semantic fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21429v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darshan Gadginmath, Ahmed Allibhoy, Fabio Pasqualetti</dc:creator>
    </item>
    <item>
      <title>Simple vs. Optimal Congestion Pricing</title>
      <link>https://arxiv.org/abs/2602.21495</link>
      <description>arXiv:2602.21495v1 Announce Type: cross 
Abstract: Congestion pricing has emerged as an effective tool for mitigating traffic congestion, yet implementing welfare or revenue-optimal dynamic tolls is often impractical. Most real-world congestion pricing deployments, including New York City's recent program, rely on significantly simpler, often static, tolls. This discrepancy motivates the question of how much revenue and welfare loss there is when real-world traffic systems use static rather than optimal dynamic pricing.
  We address this question by analyzing the performance gap between static (simple) and dynamic (optimal) congestion pricing schemes in two canonical frameworks: Vickrey's bottleneck model with a public transit outside option and its city-scale extension based on the Macroscopic Fundamental Diagram (MFD). In both models, we first characterize the revenue-optimal static and dynamic tolling policies, which have received limited attention in prior work. In the worst-case, revenue-optimal static tolls achieve at least half of the dynamic optimal revenue and at most twice the minimum achievable system cost across a wide range of practically relevant parameter regimes, with stronger and more general guarantees in the bottleneck model than in the MFD model. We further corroborate our theoretical guarantees with numerical results based on real-world datasets from the San Francisco Bay Area and New York City, which demonstrate that static tolls achieve roughly 80-90% of the dynamic optimal revenue while incurring at most a 8-20% higher total system cost than the minimum achievable system cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21495v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh Jalota, Sharon Di, Adam N. Elmachtoub</dc:creator>
    </item>
    <item>
      <title>Learning spatially adaptive sparsity level maps for arbitrary convolutional dictionaries</title>
      <link>https://arxiv.org/abs/2602.21707</link>
      <description>arXiv:2602.21707v1 Announce Type: cross 
Abstract: State-of-the-art learned reconstruction methods often rely on black-box modules that, despite their strong performance, raise questions about their interpretability and robustness. Here, we build on a recently proposed image reconstruction method, which is based on embedding data-driven information into a model-based convolutional dictionary regularization via neural network-inferred spatially adaptive sparsity level maps. By means of improved network design and dedicated training strategies, we extend the method to achieve filter-permutation invariance as well as the possibility to change the convolutional dictionary at inference time. We apply our method to low-field MRI and compare it to several other recent deep learning-based methods, also on in vivo data, in which the benefit for the use of a different dictionary is showcased. We further assess the method's robustness when tested on in- and out-of-distribution data. When tested on the latter, the proposed method suffers less from the data distribution shift compared to the other learned methods, which we attribute to its reduced reliance on training data due to its underlying model-based reconstruction component.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21707v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Schulz, David Schote, Christoph Kolbitsch, Kostas Papafitsoros, Andreas Kofler</dc:creator>
    </item>
    <item>
      <title>Learning-Based Geometric Leader-Follower Control for Cooperative Rigid-Payload Transport with Aerial Manipulators</title>
      <link>https://arxiv.org/abs/2602.21768</link>
      <description>arXiv:2602.21768v1 Announce Type: cross 
Abstract: This paper presents a learning-based tracking control framework for cooperative transport of a rigid payload by multiple aerial manipulators under rigid grasp constraints. A unified geometric model is developed, yielding a coupled agent--payload differential--algebraic system that explicitly captures contact wrenches, payload dynamics, and internal force redundancy. A leader--follower architecture is adopted in which a designated leader generates a desired payload wrench based on geometric tracking errors, while the remaining agents realize this wrench through constraint-consistent force allocation.
  Unknown disturbances and modeling uncertainties are compensated using Gaussian Process (GP) regression. High-probability bounds on the learning error are explicitly incorporated into the control design, combining GP feedforward compensation with geometric feedback. Lyapunov analysis establishes uniform ultimate boundedness of the payload tracking errors with high probability, with an ultimate bound that scales with the GP predictive uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21768v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omayra Yago Nieto, Leonardo Colombo</dc:creator>
    </item>
    <item>
      <title>Selecting representative community partitions under modularity degeneracy: the STAR method</title>
      <link>https://arxiv.org/abs/2602.21838</link>
      <description>arXiv:2602.21838v1 Announce Type: cross 
Abstract: Community detection based on modularity maximization is one of the most widely used approaches for uncovering mesoscale structures in complex networks. However, it is well known that the modularity function exhibits a highly degenerate optimization landscape: a large number of structurally distinct partitions attain close modularity values. This degeneracy raises issues of instability, reproducibility, and interpretability of the detected communities. We propose a simple and user-friendly post-processing method to address this problem by selecting a representative partition among the set of high-modularity solutions. The proposed approach is model-agnostic and can be applied a posteriori to the output of any modularity-based community detection algorithm. Rather than seeking the optimal partition in terms of modularity, our method aims to identify a solution that best represents the structural features shared across degenerate partitions. We compare our approach with consensus clustering methods, which pursue a similar objective, and show that the resulting partitions are highly consistent, while being obtained through a substantially simpler procedure that does not require additional optimization steps or external software packages. Moreover, unlike standard consensus clustering techniques, the proposed method can be applied to networks with both positive and negative edge weights, making it suitable for a wide range of applications involving signed networks and correlation-based systems, such as social, financial, and neuroscience networks. Overall, the method provides a practical and robust tool for handling degeneracy in modularity-based community detection, combining simplicity with broad applicability across different types of networks and real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21838v1</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Grassetti, Rossana Mastrandrea</dc:creator>
    </item>
    <item>
      <title>Concentration for random Euclidean combinatorial optimization</title>
      <link>https://arxiv.org/abs/2602.21851</link>
      <description>arXiv:2602.21851v1 Announce Type: cross 
Abstract: We prove concentration bounds for random Euclidean combinatorial optimization problems with $p$--costs. For bipartite matching and for the (mono- and bi-partite) traveling salesperson problem in dimension $d\ge 3$, we obtain concentration at the natural energy scale $n^{1-p/d}$ for $1\le p&lt;d^2/2$. Our method combines a Poincar\'e inequality with a robust geometric mechanism providing uniform bounds on the edges of optimizers. We also formulate a conjectural $p\!\to\!q$ transfer principle for the $p$--optimal matching which, if true, would extend the concentration range to all $p\ge 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21851v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo D'Achille, Francesco Mattesini, Dario Trevisan</dc:creator>
    </item>
    <item>
      <title>Robust Kaczmarz methods for nearly singular linear systems</title>
      <link>https://arxiv.org/abs/2602.21916</link>
      <description>arXiv:2602.21916v1 Announce Type: cross 
Abstract: The Kaczmarz method is an efficient iterative algorithm for large-scale linear systems. However, its linear convergence rate suffers from ill-conditioned problems and is highly sensitive to the smallest nonzero singular value. In this work, we aim to extend the classical Kaczmarz to nearly singular linear systems that are row rank-deficient. We introduce a new concept of nearly singular property by treating the row space as an unstable subspace in the Grassman manifold. We then define a related important space called the approximate kernel, based on which a robust kernel-augmented Kaczmarz (KaK) is introduced via the subspace correction framework and analyzed by the well-known Xu--Zikatanov identity. To get an implementable version, we further introduce the approximate dual kernel and transform KaK into an equivalent kernel-augmented coordinate descent. Furthermore, we develop an accelerated variant and establish the improved rate of convergence matching the optimal complexity of first-order methods. Compared with existing methods, ours achieve uniform convergence rates for nearly singular linear systems, and the robustness has been confirmed by some numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21916v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunying Ke, Hao Luo</dc:creator>
    </item>
    <item>
      <title>Aggressiveness-Aware Learning-based Control of Quadrotor UAVs with Safety Guarantees</title>
      <link>https://arxiv.org/abs/2602.21936</link>
      <description>arXiv:2602.21936v1 Announce Type: cross 
Abstract: This paper presents an aggressiveness-aware control framework for quadrotor UAVs that integrates learning-based oracles to mitigate the effects of unknown disturbances. Starting from a nominal tracking controller on $\mathrm{SE}(3)$, unmodeled generalized forces and moments are estimated using a learning-based oracle and compensated in the control inputs. An aggressiveness-aware gain scheduling mechanism adapts the feedback gains based on probabilistic model-error bounds, enabling reduced feedback-induced aggressiveness while guaranteeing a prescribed practical exponential tracking performance. The proposed approach makes explicit the trade-off between model accuracy, robustness, and control aggressiveness, and provides a principled way to exploit learning for safer and less aggressive quadrotor maneuvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21936v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Colombo, Thomas Beckers, Juan Giribet</dc:creator>
    </item>
    <item>
      <title>Neural solver for Wasserstein Geodesics and optimal transport dynamics</title>
      <link>https://arxiv.org/abs/2602.22003</link>
      <description>arXiv:2602.22003v1 Announce Type: cross 
Abstract: In recent years, the machine learning community has increasingly embraced the optimal transport (OT) framework for modeling distributional relationships. In this work, we introduce a sample-based neural solver for computing the Wasserstein geodesic between a source and target distribution, along with the associated velocity field. Building on the dynamical formulation of the optimal transport (OT) problem, we recast the constrained optimization as a minimax problem, using deep neural networks to approximate the relevant functions. This approach not only provides the Wasserstein geodesic but also recovers the OT map, enabling direct sampling from the target distribution. By estimating the OT map, we obtain velocity estimates along particle trajectories, which in turn allow us to learn the full velocity field. The framework is flexible and readily extends to general cost functions, including the commonly used quadratic cost. We demonstrate the effectiveness of our method through experiments on both synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22003v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hailiang Liu, Yan-Han Chen</dc:creator>
    </item>
    <item>
      <title>Robust Permutation Flowshops Under Budgeted Uncertainty</title>
      <link>https://arxiv.org/abs/2602.22110</link>
      <description>arXiv:2602.22110v1 Announce Type: cross 
Abstract: We consider the robust permutation flowshop problem under the budgeted uncertainty model, where at most a given number of job processing times may deviate on each machine. We show that solutions for this problem can be determined by solving polynomially many instances of the corresponding nominal problem. As a direct consequence, our result implies that this robust flowshop problem can be solved in polynomial time for two machines, and can be approximated in polynomial time for any fixed number of machines. The reduction that is our main result follows from an analysis similar to Bertsimas and Sim (2003) except that dualization is applied to the terms of a min-max objective rather than to a linear objective function. Our result may be surprising considering that heuristic and exact integer programming based methods have been developed in the literature for solving the two-machine flowshop problem. We conclude by showing a logarithmic factor improvement in the overall running time implied by a naive reduction to nominal problems in the case of two machines and three machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22110v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noam Goldberg, Danny Hermelin, Dvir Shabtay</dc:creator>
    </item>
    <item>
      <title>Frictionless Hamiltonian Descent and Coordinate Hamiltonian Descent for Strongly Convex Quadratic Problems</title>
      <link>https://arxiv.org/abs/2402.13988</link>
      <description>arXiv:2402.13988v4 Announce Type: replace 
Abstract: We propose an optimization algorithm called Frictionless Hamiltonian Descent, which is a direct counterpart of classical Hamiltonian Monte Carlo in sampling. We analyze Frictionless Hamiltonian Descent for strongly convex quadratic functions and show that the method has a non-trivial accelerated rate as that of Heavy Ball flow. We also propose Frictionless Coordinate Hamiltonian Descent and its parallelizable variant, which turns out to encapsulate the classical Gauss-Seidel method, Successive Over-relaxation, Jacobi method, and more, for solving a linear system of equations. The result not only offers a new perspective on these existing algorithms but also leads to a broader class of update schemes that guarantee the convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13988v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun-Kun Wang</dc:creator>
    </item>
    <item>
      <title>Proximal Comixture Minimization Models for Image Recovery and Data Analysis</title>
      <link>https://arxiv.org/abs/2403.09610</link>
      <description>arXiv:2403.09610v2 Announce Type: replace 
Abstract: In minimization models for image recovery and data analysis problems, loss functions and linear operators are typically aggregated as an average of composite terms. Each term in the aggregate models a desired property of the ideal solution arising from the \emph{a priori} knowledge and the observed data. We propose an alternative minimization model based on proximal comixtures, an operation which combines functions and linear operators in such a way that the proximity operator of the resulting function is computable explicitly in terms of the individual proximity and linear operators. The mathematical properties of this operation are analyzed and comparisons between proximal comixtures and standard composite averages are made. Numerical illustrations of the benefits of minimization models based on proximal comixtures are provided in the context of image recovery and machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09610v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>On the Convexification of Spectral Sets Induced by Non-Invariant Sets</title>
      <link>https://arxiv.org/abs/2405.14143</link>
      <description>arXiv:2405.14143v3 Announce Type: replace 
Abstract: Given a finite-dimensional FTvN system $(\mathbb{V},\mathbb{W},\lambda)$, we study the convexification of the spectral set $\lambda^{-1}(\mathcal{C})$ induced by a set $\mathcal{C} \subseteq \mathbb{W}$. While the case of invariant $\mathcal{C}$ has been relatively well-studied, the results for non-invariant $\mathcal{C}$ are largely lacking in the literature. We fill this void by developing simple and geometric characterizations of the convex hull and closed convex hull of $\lambda^{-1}(\mathcal{C})$ when $\mathcal{C}$ has no invariance property. We further specialize our results to the case of invariant $\mathcal{C}$, and obtain new convexifications of $\lambda^{-1}(\mathcal{C})$ in this case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14143v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renbo Zhao</dc:creator>
    </item>
    <item>
      <title>Learning to Pursue AC Optimal Power Flow Solutions with Feasibility Guarantees</title>
      <link>https://arxiv.org/abs/2505.22399</link>
      <description>arXiv:2505.22399v2 Announce Type: replace 
Abstract: This paper focuses on an AC optimal power flow (OPF) problem for distribution feeders equipped with controllable distributed energy resources (DERs). We consider a solution method that is based on a continuous approximation of the projected gradient flow - referred to as the safe gradient flow - that incorporates voltage and current information obtained either through real-time measurements or power flow computations. These two setups enable both online and offline implementations. The safe gradient flow involves the solution of convex quadratic programs (QPs). To enhance computational efficiency, we propose a novel framework that employs a neural network approximation of the optimal solution map of the QP. The resulting method has two key features: (a) it ensures that the DERs' setpoints are practically feasible, even for an online implementation or when an offline algorithm has an early termination; (b) it ensures convergence to a neighborhood of a strict local optimizer of the AC OPF. The proposed method is tested on a 93-node distribution system with realistic loads and renewable generation. The test shows that our method successfully regulates voltages within limits during periods with high renewable generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22399v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damola Ajeyemi, Yiting Chen, Antonin Colot, Jorge Cortes, Emiliano Dall'Anese</dc:creator>
    </item>
    <item>
      <title>A DC-Reformulation for Gradient-$L^0$-Constrained Problems</title>
      <link>https://arxiv.org/abs/2506.11917</link>
      <description>arXiv:2506.11917v2 Announce Type: replace 
Abstract: Cardinality constraints in optimization are commonly of $L^0$-type, and they lead to sparsely supported optimizers. An efficient way of dealing with these constraints algorithmically, when the objective functional is convex, is reformulating the constraint using the difference of suitable $L^1$- and largest-$K$-norms and subsequently solving a sequence of penalized subproblems in the difference-of-convex (DC) class. We extend this DC-reformulation approach to problems with $L^0$-type cardinality constraints on the support of the gradients, i.e., problems where sparsity of the gradient and thus piecewise constant solutions are the target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11917v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bastian Dittrich, Evelyn Herberg, Roland Herzog, Georg M\"uller</dc:creator>
    </item>
    <item>
      <title>Dual-Regularized Riccati Recursions for Interior-Point Optimal Control</title>
      <link>https://arxiv.org/abs/2509.16370</link>
      <description>arXiv:2509.16370v5 Announce Type: replace 
Abstract: We derive closed-form extensions of Riccati's recursions (both sequential and parallel) for solving dual-regularized LQR problems. We show how these methods can be used to solve general constrained, non-convex, discrete-time optimal control problems via a regularized interior point method, while guaranteeing that each primal step is a descent direction of an Augmented Barrier-Lagrangian merit function. We provide MIT-licensed implementations of our methods in C++ and JAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16370v5</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Sousa-Pinto, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Relating Checkpoint Update Probabilities to Momentum Parameters in Single-Loop Variance Reduction Methods</title>
      <link>https://arxiv.org/abs/2601.02899</link>
      <description>arXiv:2601.02899v2 Announce Type: replace 
Abstract: We propose a single-loop variance-reduced acceleration framework, which relates checkpoint update probabilities to momentum parameters, for solving the composite general convex problem where the smooth part has the finite-sum structure. Under the proposed framework, the growth rate of the momentum parameter is further altered, creating a novel continuous trade-off between acceleration and variance reduction, controlled by the key parameter $\alpha\in [0,1]$. A series of novel complexity is obtained, and some complexity of distinct known methods are rediscovered under the unified framework. When the mini-batch size is restricted due to the massive scale of the problem or the computational resource shortage, near-optimal complexity can still be achieved by choosing suitable $\alpha$ for any prefixed target accuracy. Analysis shows that although the considered gradient oracle is exact, acceleration comes with implicit price of heavier variance reduction, hence the obtained optimal $\alpha$ not necessarily corresponds to the largest allowable acceleration strength. Without prefixing the target accuracy, the proposed method achieves the near-optimal complexity $\tilde{\mathcal{O}}(n+\sqrt{n}/\sqrt{\epsilon})$ to obtain an $\epsilon$-accurate solution under standard assumptions ($n$ is the number of components of the finite-sum), significantly improves upon previous best complexity $\mathcal{O}(n+n/\sqrt{\epsilon})$ of single-loop variance reduction methods, which does not exceed the complexity of the deterministic method FISTA. Numerical experiments demonstrate the efficiency of the proposed method and validate other theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02899v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hai Liu, Tiande Guo, Congying Han</dc:creator>
    </item>
    <item>
      <title>Integrated Optimization of Scheduling and Flexible Charging in Mixed Electric-Diesel Urban Transit Bus Systems</title>
      <link>https://arxiv.org/abs/2601.11751</link>
      <description>arXiv:2601.11751v2 Announce Type: replace 
Abstract: The transition of transit fleets to alternative powertrains offers a potential pathway to reducing the cost of mobility. However, the limited range and long charging durations of battery electric buses (BEBs) introduce significant operational complexities, necessitating innovative scheduling and charging strategies. This study proposes an integrated mixed-integer linear programming model to optimize vehicle scheduling and charging strategies for mixed fleets of BEBs and diesel buses. Unlike existing models, which often assume a fixed BEB fleet size or restrict charging to a single charger type, our approach simultaneously determines the optimal fleet composition, scheduling, and flexible partial charging strategy incorporating both slow and fast chargers at garages and terminal stations. The model minimizes combined fleet purchase and operational costs. A queuing strategy is introduced, departing from traditional first-come, first-served methods by dynamically allocating waiting and charging times based on operational priorities and resource availability, improving overall scheduling efficiency. To overcome computational complexities arising from numerous variables, a column generation framework is developed, facilitating scalable solutions for large-scale transit networks. Numerical experiments using real-world transit data from the Chicago Transit Authority and the Pace suburban bus systems demonstrate the model's effectiveness. Results indicate that while a full transition to alternative powertrains results in a modest cost increase, optimal mixed-fleet configurations can actually reduce total system costs. Furthermore, sensitivity analyses reveal that restricting charging to garages significantly increases fleet size and operational costs, underscoring the potential of distributed opportunistic charging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11751v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sadjad Bazarnovi, Taner Cokyasar, Omer Verbas, Abolfazl Kouros Mohammadian</dc:creator>
    </item>
    <item>
      <title>Implicit Decision Diagrams</title>
      <link>https://arxiv.org/abs/2602.20793</link>
      <description>arXiv:2602.20793v3 Announce Type: replace 
Abstract: Decision Diagrams (DDs) have emerged as a powerful tool for discrete optimization, with rapidly growing adoption. DDs are directed acyclic layered graphs; restricted DDs are a generalized greedy heuristic for finding feasible solutions, and relaxed DDs compute combinatorial relaxed bounds. There is substantial theory that leverages DD-based bounding, yet the complexity of constructing the DDs themselves has received little attention. Standard restricted DD construction requires $O(w \log(w))$ per layer; standard relaxed DD construction requires $O(w^2)$, where $w$ is the width of the DD. Increasing $w$ improves bound quality at the cost of more time and memory.
  We introduce implicit Decision Diagrams, storing arcs implicitly rather than explicitly, and reducing per-layer complexity to $O(w)$ for restricted and relaxed DDs. We prove this is optimal: any framework treating state-update and merge operations as black boxes cannot do better.
  Optimal complexity shifts the challenge from algorithmic overhead to low-level engineering. We show how implicit DDs can drive a MIP solver, and release ImplicitDDs, an open-source Julia solver exploiting the implementation refinements our theory enables. Experiments demonstrate the solver outperforms Gurobi on Subset Sum.
  Code (https://github.com/IsaacRudich/ImplicitDDs.jl)</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20793v3</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaac Rudich, Louis-Martin Rousseau</dc:creator>
    </item>
    <item>
      <title>Random-Restart Best-Response Dynamics for Large-Scale Integer Programming Games and Their Applications</title>
      <link>https://arxiv.org/abs/2409.04078</link>
      <description>arXiv:2409.04078v3 Announce Type: replace-cross 
Abstract: This paper presents scalable algorithms for computing pure Nash equilibria (PNEs) in large-scale integer programming games (IPGs), where existing exact methods typically handle only small numbers of players. Motivated by a county-level aquatic invasive species (AIS) prevention problem with 84 decision makers, we develop and analyze random-restart best-response dynamics (RR-BRD), a randomized search framework for PNEs. For IPGs with finite action sets, we model RR-BRD as a Markov chain on the best-response state graph and show that, whenever a PNE exists and the restart law has positive probability of reaching a PNE within the round cap, RR-BRD finds a PNE almost surely. We also propose a Monte Carlo sampling-and-simulation procedure to estimate success behavior under a fixed round cap, which informs our instance-dependent performance characterization. We then embed RR-BRD as a randomized local-search subroutine within the zero-regret (ZR) framework, yielding BRD-incorporated zero-regret (BZR). Using solver callbacks, RR-BRD searches for and supplies PNEs, while ZR separates and adds equilibrium inequalities to tighten the formulation. We introduce edge-weighted budgeted maximum coverage (EBMC) games to model AIS prevention and establish PNE existence results for both selfish and locally altruistic utilities. Computational experiments on synthetic EBMC and knapsack problem game instances show that RR-BRD and BZR scale equilibrium computation up to $n \le 30$ players. We further solve a real-world EBMC game derived from the Minnesota AIS dataset with $n = 84$ county players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04078v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunwoo Lee, Robert Hildebrand, Wenbo Cai, \.I. Esra B\"uy\"uktahtak{\i}n</dc:creator>
    </item>
    <item>
      <title>Topology optimization of type-II superconductors with superconductor-dielectric/vacuum interfaces based on Ginzburg-Landau theory under Weyl gauge</title>
      <link>https://arxiv.org/abs/2602.14261</link>
      <description>arXiv:2602.14261v3 Announce Type: replace-cross 
Abstract: Geometrical design is a crucial and challenging strategy for improving the performance of type-II superconductors, because the proper placement of intended defects in the current path contribute to flux pinning, a reduction in dissipation, and an increase in achievable current density. Topology optimization is currently one of the most powerful approaches used to determine consistent structural geometries. Therefore, a topology optimization approach is presented to inversely design structural geometries of low- and high-temperature type-II superconductors with superconductor-dielectric/vacuum interfaces. In the presented approach, the magnetic response of type-II superconductors is modeled using the Ginzburg-Landau theory, where the temporal evolution of the order parameter and vector potential is described by the time-dependent Ginzburg-Landau equations under the Weyl gauge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14261v3</guid>
      <category>cond-mat.supr-con</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yongbo Deng, Jan G. Korvink</dc:creator>
    </item>
    <item>
      <title>OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents</title>
      <link>https://arxiv.org/abs/2602.19439</link>
      <description>arXiv:2602.19439v2 Announce Type: replace-cross 
Abstract: Supply chain optimization models frequently become infeasible because of modeling errors. Diagnosis and repair require scarce OR expertise: analysts must interpret solver diagnostics, trace root causes across echelons, and fix formulations without sacrificing operational soundness. Whether AI agents can perform this task remains untested. We decompose this task into two phases: a domain-agnostic feasibility phase that iteratively repairs any LP using IIS-guided diagnosis, and a domain-specific validation phase that enforces five rationality checks grounded in inventory theory. We test 22 API models from seven families on 976 multi-echelon supply chain problems and train two 8B-parameter models with self-taught reasoning and solver-verified rewards. The trained models reach 81.7% Rational Recovery Rate (RRR) -- the fraction of problems resolved to both feasibility and operational rationality -- versus 42.2% for the best API model and 21.3% on average. The gap concentrates in Phase 1 repair, where API models average 27.6% recovery rate versus 97.2% for trained models. Two gaps separate current AI from reliable model repair: solver interaction, as API models restore only 27.6% of infeasible formulations; and operational rationale, as roughly one in four feasible repairs violate supply chain theory. Each gap requires a different intervention -- targeted training closes the solver interaction gap, while explicit specification as solver-verifiable checks closes the rationality gap. For organizations adopting AI in operational planning, formalizing what 'rational' means in their context is the higher-return investment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19439v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruicheng Ao, David Simchi-Levi, Xinshang Wang</dc:creator>
    </item>
  </channel>
</rss>
