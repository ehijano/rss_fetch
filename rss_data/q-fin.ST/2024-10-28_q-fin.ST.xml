<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.ST</link>
    <description>q-fin.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 04:01:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fitting the seven-parameter Generalized Tempered Stable distribution to the financial data</title>
      <link>https://arxiv.org/abs/2410.19751</link>
      <description>arXiv:2410.19751v1 Announce Type: new 
Abstract: The paper proposes and implements a methodology to fit a seven-parameter Generalized Tempered Stable (GTS) distribution to financial data. The nonexistence of the mathematical expression of the GTS probability density function makes the maximum likelihood estimation (MLE) inadequate for providing parameter estimations. Based on the function characteristic and the fractional Fourier transform (FRFT), We provide a comprehensive approach to circumvent the problem and yield a good parameter estimation of the GTS probability. The methodology was applied to fit two heavily tailed data (Bitcoin and Ethereum returns) and two peaked data (S&amp;P 500 and SPY ETF returns). For each index, the estimation results show that the six parameter estimations are statistically significant except for the local parameter ($\mu$). The goodness of fit was assessed through Kolmogorov-Smirnov, Anderson-Darling, and Pearson's chi-squared statistics. While the two-parameter geometric Brownian motion (GBM) hypothesis is always rejected, the Generalized Tempered Sable (GTS) distribution fits significantly with a very high P_value; and outperforms the Kobol, CGMY, and Bilateral Gamma distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19751v1</guid>
      <category>q-fin.ST</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. H Nzokem</dc:creator>
    </item>
    <item>
      <title>MCI-GRU: Stock Prediction Model Based on Multi-Head Cross-Attention and Improved GRU</title>
      <link>https://arxiv.org/abs/2410.20679</link>
      <description>arXiv:2410.20679v1 Announce Type: new 
Abstract: As financial markets grow increasingly complex in the big data era, accurate stock prediction has become more critical. Traditional time series models, such as GRUs, have been widely used but often struggle to capture the intricate nonlinear dynamics of markets, particularly in the flexible selection and effective utilization of key historical information. Recently, methods like Graph Neural Networks and Reinforcement Learning have shown promise in stock prediction but require high data quality and quantity, and they tend to exhibit instability when dealing with data sparsity and noise. Moreover, the training and inference processes for these models are typically complex and computationally expensive, limiting their broad deployment in practical applications. Existing approaches also generally struggle to capture unobservable latent market states effectively, such as market sentiment and expectations, microstructural factors, and participant behavior patterns, leading to an inadequate understanding of market dynamics and subsequently impact prediction accuracy. To address these challenges, this paper proposes a stock prediction model, MCI-GRU, based on a multi-head cross-attention mechanism and an improved GRU. First, we enhance the GRU model by replacing the reset gate with an attention mechanism, thereby increasing the model's flexibility in selecting and utilizing historical information. Second, we design a multi-head cross-attention mechanism for learning unobservable latent market state representations, which are further enriched through interactions with both temporal features and cross-sectional features. Finally, extensive experiments on four main stock markets show that the proposed method outperforms SOTA techniques across multiple metrics. Additionally, its successful application in real-world fund management operations confirms its effectiveness and practicality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20679v1</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Zhu, Yuante Li, Yifan Hu, Sheng Xiang, Qinyuan Liu, Dawei Cheng, Yuqi Liang</dc:creator>
    </item>
    <item>
      <title>NeuralBeta: Estimating Beta Using Deep Learning</title>
      <link>https://arxiv.org/abs/2408.01387</link>
      <description>arXiv:2408.01387v2 Announce Type: replace 
Abstract: Traditional approaches to estimating beta in finance often involve rigid assumptions and fail to adequately capture beta dynamics, limiting their effectiveness in use cases like hedging. To address these limitations, we have developed a novel method using neural networks called NeuralBeta, which is capable of handling both univariate and multivariate scenarios and tracking the dynamic behavior of beta. To address the issue of interpretability, we introduce a new output layer inspired by regularized weighted linear regression, which provides transparency into the model's decision-making process. We conducted extensive experiments on both synthetic and market data, demonstrating NeuralBeta's superior performance compared to benchmark methods across various scenarios, especially instances where beta is highly time-varying, e.g., during regime shifts in the market. This model not only represents an advancement in the field of beta estimation, but also shows potential for applications in other financial contexts that assume linear relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01387v2</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxin Liu, Jimin Lin, Achintya Gopal</dc:creator>
    </item>
    <item>
      <title>Macroscopic properties of equity markets: stylized facts and portfolio performance</title>
      <link>https://arxiv.org/abs/2409.10859</link>
      <description>arXiv:2409.10859v2 Announce Type: replace 
Abstract: Macroscopic properties of equity markets affect the performance of active equity strategies but many are not adequately captured by conventional models of financial mathematics and econometrics. Using the CRSP Database of the US equity market, we study empirically several macroscopic properties defined in terms of market capitalizations and returns, and highlight a list of stylized facts and open questions motivated in part by stochastic portfolio theory. Additionally, we present a systematic backtest of the diversity-weighted portfolio under various configurations and study its performance in relation to macroscopic quantities. All of our results can be replicated using codes made available on our GitHub repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10859v2</guid>
      <category>q-fin.ST</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven Campbell, Qien Song, Ting-Kam Leonard Wong</dc:creator>
    </item>
    <item>
      <title>Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions: Uncovering Causal Relationships</title>
      <link>https://arxiv.org/abs/2306.08157</link>
      <description>arXiv:2306.08157v3 Announce Type: replace-cross 
Abstract: Cryptocurrencies have gained popularity across various sectors, especially in finance and investment. Despite their growing popularity, cryptocurrencies can be a high-risk investment due to their price volatility. The inherent volatility in cryptocurrency prices, coupled with the effects of external global economic factors, makes predicting their price movements challenging. To address this challenge, we propose a dynamic Bayesian network (DBN)-based approach to uncover potential causal relationships among various features including social media data, traditional financial market factors, and technical indicators. Six popular cryptocurrencies, Bitcoin, Binance Coin, Ethereum, Litecoin, Ripple, and Tether are studied in this work. The proposed model's performance is compared to five baseline models of auto-regressive integrated moving average, support vector regression, long short-term memory, random forests, and support vector machines. The results show that while DBN performance varies across cryptocurrencies, with some cryptocurrencies exhibiting higher predictive accuracy than others, the DBN significantly outperforms the baseline models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08157v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rasoul Amirzadeh, Dhananjay Thiruvady, Asef Nazari, Mong Shan Ee</dc:creator>
    </item>
  </channel>
</rss>
