<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Sep 2024 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Robust Approach to Gaussian Processes Implementation</title>
      <link>https://arxiv.org/abs/2409.11577</link>
      <description>arXiv:2409.11577v1 Announce Type: new 
Abstract: Gaussian Process (GP) regression is a flexible modeling technique used to predict outputs and to capture uncertainty in the predictions. However, the GP regression process becomes computationally intensive when the training spatial dataset has a large number of observations. To address this challenge, we introduce a scalable GP algorithm, termed MuyGPs, which incorporates nearest neighbor and leave-one-out cross-validation during training. This approach enables the evaluation of large spatial datasets with state-of-the-art accuracy and speed in certain spatial problems. Despite these advantages, conventional quadratic loss functions used in the MuyGPs optimization such as Root Mean Squared Error(RMSE), are highly influenced by outliers. We explore the behavior of MuyGPs in cases involving outlying observations, and subsequently, develop a robust approach to handle and mitigate their impact. Specifically, we introduce a novel leave-one-out loss function based on the pseudo-Huber function (LOOPH) that effectively accounts for outliers in large spatial datasets within the MuyGPs framework. Our simulation study shows that the "LOOPH" loss method maintains accuracy despite outlying observations, establishing MuyGPs as a powerful tool for mitigating unusual observation impacts in the large data regime. In the analysis of U.S. ozone data, MuyGPs provides accurate predictions and uncertainty quantification, demonstrating its utility in managing data anomalies. Through these efforts, we advance the understanding of GP regression in spatial contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11577v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juliette Mukangango, Amanda Muyskens, Benjamin W. Priest</dc:creator>
    </item>
    <item>
      <title>Model-Embedded Gaussian Process Regression for Parameter Estimation in Dynamical System</title>
      <link>https://arxiv.org/abs/2409.11745</link>
      <description>arXiv:2409.11745v1 Announce Type: new 
Abstract: Identifying dynamical system (DS) is a vital task in science and engineering. Traditional methods require numerous calls to the DS solver, rendering likelihood-based or least-squares inference frameworks impractical. For efficient parameter inference, two state-of-the-art techniques are the kernel method for modeling and the "one-step framework" for jointly inferring unknown parameters and hyperparameters. The kernel method is a quick and straightforward technique, but it cannot estimate solutions and their derivatives, which must strictly adhere to physical laws. We propose a model-embedded "one-step" Bayesian framework for joint inference of unknown parameters and hyperparameters by maximizing the marginal likelihood. This approach models the solution and its derivatives using Gaussian process regression (GPR), taking into account smoothness and continuity properties, and treats differential equations as constraints that can be naturally integrated into the Bayesian framework in the linear case. Additionally, we prove the convergence of the model-embedded Gaussian process regression (ME-GPR) for theoretical development. Motivated by Taylor expansion, we introduce a piecewise first-order linearization strategy to handle nonlinear dynamic systems. We derive estimates and confidence intervals, demonstrating that they exhibit low bias and good coverage properties for both simulated models and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11745v1</guid>
      <category>stat.CO</category>
      <category>math.DS</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Zhou, Jinglai Li, Xiang Zhou, Hongqiao Wang</dc:creator>
    </item>
    <item>
      <title>Effects of the entropy source on Monte Carlo simulations</title>
      <link>https://arxiv.org/abs/2409.11539</link>
      <description>arXiv:2409.11539v1 Announce Type: cross 
Abstract: In this paper we show how different sources of random numbers influence the outcomes of Monte Carlo simulations. We compare industry-standard pseudo-random number generators (PRNGs) to a quantum random number generator (QRNG) and show, using examples of Monte Carlo simulations with exact solutions, that the QRNG yields statistically significantly better approximations than the PRNGs. Our results demonstrate that higher accuracy can be achieved in the commonly known Monte Carlo method for approximating $\pi$. For Buffon's needle experiment, we further quantify a potential reduction in approximation errors by up to $1.89\times$ for optimal parameter choices when using a QRNG and a reduction of the sample size by $\sim 8\times$ for sub-optimal parameter choices. We attribute the observed higher accuracy to the underlying differences in the random sampling, where a uniformity analysis reveals a tendency of the QRNG to sample the solution space more homogeneously. Additionally, we compare the results obtained with the QRNG and PRNG in solving the non-linear stochastic Schr\"odinger equation, benchmarked against the analytical solution. We observe higher accuracy of the approximations of the QRNG and demonstrate that equivalent results can be achieved at 1/3 to 1/10-th of the costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11539v1</guid>
      <category>physics.comp-ph</category>
      <category>stat.CO</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Lebedev, Annika M\"oslein, Olha I. Yaman, Del Rajan, Philip Intallura</dc:creator>
    </item>
    <item>
      <title>Fitting Multilevel Factor Models</title>
      <link>https://arxiv.org/abs/2409.12067</link>
      <description>arXiv:2409.12067v1 Announce Type: cross 
Abstract: We examine a special case of the multilevel factor model, with covariance given by multilevel low rank (MLR) matrix~\cite{parshakova2023factor}. We develop a novel, fast implementation of the expectation-maximization (EM) algorithm, tailored for multilevel factor models, to maximize the likelihood of the observed data. This method accommodates any hierarchical structure and maintains linear time and storage complexities per iteration. This is achieved through a new efficient technique for computing the inverse of the positive definite MLR matrix. We show that the inverse of an invertible PSD MLR matrix is also an MLR matrix with the same sparsity in factors, and we use the recursive Sherman-Morrison-Woodbury matrix identity to obtain the factors of the inverse. Additionally, we present an algorithm that computes the Cholesky factorization of an expanded matrix with linear time and space complexities, yielding the covariance matrix as its Schur complement. This paper is accompanied by an open-source package that implements the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12067v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>stat.CO</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tetiana Parshakova, Trevor Hastie, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Solving the Poisson equation using coupled Markov chains</title>
      <link>https://arxiv.org/abs/2206.05691</link>
      <description>arXiv:2206.05691v3 Announce Type: replace 
Abstract: This article shows how coupled Markov chains that meet exactly after a random number of iterations can be used to generate unbiased estimators of the solutions of the Poisson equation. We establish connections to recently-proposed unbiased estimators of Markov chain equilibrium expectations. We further employ the proposed estimators of solutions of the Poisson equation to construct unbiased estimators of the asymptotic variance of Markov chain ergodic averages, involving a random but finite computing time. The proposed estimators are studied under realistic assumptions on the meeting times of the coupled chains and on the existence of moments of test functions under the target distribution. We provide experiments in toy examples as well as more realistic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05691v3</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Randal Douc, Pierre E. Jacob, Anthony Lee, Dootika Vats</dc:creator>
    </item>
    <item>
      <title>Nonlinear Causality in Brain Networks: With Application to Motor Imagery vs Execution</title>
      <link>https://arxiv.org/abs/2409.10374</link>
      <description>arXiv:2409.10374v2 Announce Type: replace-cross 
Abstract: One fundamental challenge of data-driven analysis in neuroscience is modeling causal interactions and exploring the connectivity between nodes in a brain network. Various statistical methods, using different perspectives and data modalities, have been developed to understand the causal structures in brain dynamics. This study introduces a novel statistical approach, TAR4C, to dissect causal interactions in multichannel EEG recordings. TAR4C uses the threshold autoregressive (TAR) model to describe causal interactions between nodes in a brain network from two perspectives. The first tests whether one node controls the dynamics of another. The controlling node, named the threshold variable, implies its causative role since it operates as a switching mechanism governing the instantaneous transitions between autoregressive structures. This concept is known as threshold non-linearity. Once verified between a node pair, the next step in TAR modeling is assessing the causal node's predictive ability on the other's activity, representing causal interactions in autoregressive terms, a concept underlying Granger (G) causality. TAR4C can discover non-linear, time-dependent causal interactions while maintaining the G-causality framework. The approach's efficacy is demonstrated through EEG data from a motor execution/imagery experiment. By comparing causal interactions during motor execution and imagery, TAR4C reveals key similarities and differences in brain connectivity across subjects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10374v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sipan Aslan, Hernando Ombao</dc:creator>
    </item>
  </channel>
</rss>
