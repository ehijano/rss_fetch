<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Aug 2025 01:36:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Integrative Prognostic Modeling of Breast Cancer Survival with Gene Expression and Clinical Data</title>
      <link>https://arxiv.org/abs/2508.16740</link>
      <description>arXiv:2508.16740v1 Announce Type: new 
Abstract: Background: Accurate survival prediction in breast cancer is essential for patient stratification and personalized therapy. Integrating gene expression data with clinical factors may enhance prognostic performance and support precision medicine. Objective: To develop an integrative survival prediction model combining clinical variables and gene expression signatures, and to assess their contributions using penalized Cox regression and machine learning. Methods: We analyzed 1,867 patients from the METABRIC cohort with clinical annotations and microarray-based gene expression profiles. The top 5,000 most variable genes were retained. Elastic Net-penalized Cox regression identified 75 predictors (70 genes and 5 clinical variables: tumor size, stage, surgery type, age at diagnosis, and Nottingham Prognostic Index). Model performance was evaluated with Harrell's concordance index (C-index) and 36-month time-dependent AUC. Random Survival Forests (RSF) trained on the top 20 genes assessed nonlinear effects and validated variable importance. PCA and heatmaps visualized gene expression patterns across risk groups. Results: The integrative Cox model achieved a C-index of 0.922 and a 36-month AUC of 0.94, outperforming clinical-only models (C=0.64). RSF confirmed the prognostic value of top genes (e.g., OR2T27, TBATA, LINC01165, SLC10A4), yielding a 36-month AUC of 0.88. Conclusions: Combining gene expression signatures with clinical variables substantially improves survival prediction in breast cancer and provides a framework for individualized prognostic assessment and clinical decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16740v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Amevor, Emmanuel Kubuafor, Dennis Baidoo, Junaidu Salifu, Koshali Muthunama Gonnage, Onyedikachi Joshua Okeke</dc:creator>
    </item>
    <item>
      <title>Lie-RMSD: A Gradient-Based Framework for Protein Structural Alignment using Lie Algebra</title>
      <link>https://arxiv.org/abs/2508.17010</link>
      <description>arXiv:2508.17010v1 Announce Type: new 
Abstract: The comparison of protein structures is a fundamental task in computational biology, crucial for understanding protein function, evolution, and for drug design. While analytical methods like the Kabsch algorithm provide an exact, closed-form solution for minimizing the Root Mean Square Deviation (RMSD) between two sets of corresponding atoms, their application is limited to this specific metric. The rise of deep learning and automatic differentiation frameworks offers a new, more flexible paradigm for such optimization problems. We present Lie-RMSD, a novel, fully differentiable framework for protein structural alignment. Our method represents the rigid-body transformation (rotation and translation) as a 6-dimensional vector in the Lie algebra se(3) of the special Euclidean group SE(3). This representation allows the RMSD to be formulated as a loss function that can be directly minimized by modern gradient-based optimizers. We benchmarked our framework by aligning two allosteric conformations of Adenylate Kinase (PDB IDs: 4AKE and 1AKE). We demonstrate that a suite of standard optimizers (SGD, Adam, AdamW, and Sophia) can robustly converge to the global minimum, achieving precision effectively identical to the analytical Kabsch algorithm. This work validates the accuracy of the Lie algebra-based gradient descent approach and establishes a robust foundation for its extension to more sophisticated and biologically relevant scoring functions where no analytical solutions exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17010v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Hu, Zanxia Cao, Yingchao Liu</dc:creator>
    </item>
    <item>
      <title>Neural Proteomics Fields for Super-resolved Spatial Proteomics Prediction</title>
      <link>https://arxiv.org/abs/2508.17389</link>
      <description>arXiv:2508.17389v1 Announce Type: new 
Abstract: Spatial proteomics maps protein distributions in tissues, providing transformative insights for life sciences. However, current sequencing-based technologies suffer from low spatial resolution, and substantial inter-tissue variability in protein expression further compromises the performance of existing molecular data prediction methods. In this work, we introduce the novel task of spatial super-resolution for sequencing-based spatial proteomics (seq-SP) and, to the best of our knowledge, propose the first deep learning model for this task--Neural Proteomics Fields (NPF). NPF formulates seq-SP as a protein reconstruction problem in continuous space by training a dedicated network for each tissue. The model comprises a Spatial Modeling Module, which learns tissue-specific protein spatial distributions, and a Morphology Modeling Module, which extracts tissue-specific morphological features. Furthermore, to facilitate rigorous evaluation, we establish an open-source benchmark dataset, Pseudo-Visium SP, for this task. Experimental results demonstrate that NPF achieves state-of-the-art performance with fewer learnable parameters, underscoring its potential for advancing spatial proteomics research. Our code and dataset are publicly available at https://github.com/Bokai-Zhao/NPF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17389v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bokai Zhao, Weiyang Shi, Hanqing Chao, Zijiang Yang, Yiyang Zhang, Ming Song, Tianzi Jiang</dc:creator>
    </item>
    <item>
      <title>Comprehensively stratifying MCIs into distinct risk subtypes based on brain imaging genetics fusion learning</title>
      <link>https://arxiv.org/abs/2508.18058</link>
      <description>arXiv:2508.18058v1 Announce Type: new 
Abstract: Mild cognitive impairment (MCI) is the prodromal stage of Alzheimer's disease (AD) and thus enrolling MCI subjects to undergo clinical trials is worthwhile. However, MCI groups usually show significant diversity and heterogeneity in the pathology and symptom, which pose great challenge to accurately select appropriate subjects. This study aimed to stratify MCI subjects into distinct subgroups with substantial difference in the risk of transitioning to AD by fusing multimodal brain imaging genetic data. The integrated imaging genetics method comprised three modules, i.e., the whole-genome-oriented risk genetic information extraction module (RGE), the genetic-to-brain mapping module (RG2PG), and the genetic-guided pseudo-brain fusion module (CMPF). We used data from AD Neuroimaging Initiative (ADNI) and identified two MCI subtypes, called low-risk MCI (lsMCI) and high-risk MCI (hsMCI). We also validated that the two subgroups showed distinct patterns of in terms of multiple biomarkers including genetics, demographics, fluid biomarkers, brain imaging features, clinical symptoms and cognitive functioning at baseline, as well as their longitudinal developmental trajectories. Furthermore, we also identified potential biomarkers that may implicate the risk of MCIs, providing critical insights for patient stratification at early stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18058v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muheng Shang, Jin Zhang, Junwei Han, Lei Du</dc:creator>
    </item>
    <item>
      <title>Predicting brain tumour enhancement from non-contrast MR imaging with artificial intelligence</title>
      <link>https://arxiv.org/abs/2508.16650</link>
      <description>arXiv:2508.16650v1 Announce Type: cross 
Abstract: Brain tumour imaging assessment typically requires both pre- and post-contrast MRI, but gadolinium administration is not always desirable, such as in frequent follow-up, renal impairment, allergy, or paediatric patients. We aimed to develop and validate a deep learning model capable of predicting brain tumour contrast enhancement from non-contrast MRI sequences alone. We assembled 11089 brain MRI studies from 10 international datasets spanning adult and paediatric populations with various neuro-oncological states, including glioma, meningioma, metastases, and post-resection appearances. Deep learning models (nnU-Net, SegResNet, SwinUNETR) were trained to predict and segment enhancing tumour using only non-contrast T1-, T2-, and T2/FLAIR-weighted images. Performance was evaluated on 1109 held-out test patients using patient-level detection metrics and voxel-level segmentation accuracy. Model predictions were compared against 11 expert radiologists who each reviewed 100 randomly selected patients. The best-performing nnU-Net achieved 83% balanced accuracy, 91.5% sensitivity, and 74.4% specificity in detecting enhancing tumour. Enhancement volume predictions strongly correlated with ground truth (R2 0.859). The model outperformed expert radiologists, who achieved 69.8% accuracy, 75.9% sensitivity, and 64.7% specificity. 76.8% of test patients had Dice over 0.3 (acceptable detection), 67.5% had Dice over 0.5 (good detection), and 50.2% had Dice over 0.7 (excellent detection). Deep learning can identify contrast-enhancing brain tumours from non-contrast MRI with clinically relevant performance. These models show promise as screening tools and may reduce gadolinium dependence in neuro-oncology imaging. Future work should evaluate clinical utility alongside radiology experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16650v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev</dc:creator>
    </item>
    <item>
      <title>A predictive modular approach to constraint satisfaction under uncertainty - with application to glycosylation in continuous monoclonal antibody biosimilar production</title>
      <link>https://arxiv.org/abs/2508.16803</link>
      <description>arXiv:2508.16803v1 Announce Type: cross 
Abstract: The paper proposes a modular-based approach to constraint handling in process optimization and control. This is partly motivated by the recent interest in learning-based methods, e.g., within bioproduction, for which constraint handling under uncertainty is a challenge. The proposed constraint handler, called predictive filter, is combined with an adaptive constraint margin and a constraint violation cost monitor to minimize the cost of violating soft constraints due to model uncertainty and disturbances. The module can be combined with any controller and is based on minimally modifying the controller output, in a least squares sense, such that constraints are satisfied within the considered horizon. The proposed method is computationally efficient and suitable for real-time applications. The effectiveness of the method is illustrated through a realistic simulation case study of glycosylation constraint satisfaction in continuous monoclonal antibody biosimilar production using Chinese hamster ovary cells, for which the metabolic network model consists of 23 extracellular metabolites and 126 reactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16803v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Wang, Xiao Chen, Hubert Schwarz, V\'eronique Chotteau, Elling W. Jacobsen</dc:creator>
    </item>
    <item>
      <title>Addressing Annotation Scarcity in Hyperspectral Brain Image Segmentation with Unsupervised Domain Adaptation</title>
      <link>https://arxiv.org/abs/2508.16934</link>
      <description>arXiv:2508.16934v1 Announce Type: cross 
Abstract: This work presents a novel deep learning framework for segmenting cerebral vasculature in hyperspectral brain images. We address the critical challenge of severe label scarcity, which impedes conventional supervised training. Our approach utilizes a novel unsupervised domain adaptation methodology, using a small, expert-annotated ground truth alongside unlabeled data. Quantitative and qualitative evaluations confirm that our method significantly outperforms existing state-of-the-art approaches, demonstrating the efficacy of domain adaptation for label-scarce biomedical imaging tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16934v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim Mach, Daniel Rueckert, Alex Berger, Laurin Lux, Ivan Ezhov</dc:creator>
    </item>
    <item>
      <title>Boltzina: Efficient and Accurate Virtual Screening via Docking-Guided Binding Prediction with Boltz-2</title>
      <link>https://arxiv.org/abs/2508.17555</link>
      <description>arXiv:2508.17555v1 Announce Type: cross 
Abstract: In structure-based drug discovery, virtual screening using conventional molecular docking methods can be performed rapidly but suffers from limitations in prediction accuracy. Recently, Boltz-2 was proposed, achieving extremely high accuracy in binding affinity prediction, but requiring approximately 20 seconds per compound per GPU, making it difficult to apply to large-scale screening of hundreds of thousands to millions of compounds. This study proposes Boltzina, a novel framework that leverages Boltz-2's high accuracy while significantly improving computational efficiency. Boltzina achieves both accuracy and speed by omitting the rate-limiting structure prediction from Boltz-2's architecture and directly predicting affinity from AutoDock Vina docking poses. We evaluate on eight assays from the MF-PCBA dataset and show that while Boltzina performs below Boltz-2, it provides significantly higher screening performance compared to AutoDock Vina and GNINA. Additionally, Boltzina achieved up to 11.8$\times$ faster through reduced recycling iterations and batch processing. Furthermore, we investigated multi-pose selection strategies and two-stage screening combining Boltzina and Boltz-2, presenting optimization methods for accuracy and efficiency according to application requirements. This study represents the first attempt to apply Boltz-2's high-accuracy predictions to practical-scale screening, offering a pipeline that combines both accuracy and efficiency in computational biology. The Boltzina is available on github; https://github.com/ohuelab/boltzina.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17555v1</guid>
      <category>q-bio.BM</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kairi Furui, Masahito Ohue</dc:creator>
    </item>
    <item>
      <title>Benchmarking Class Activation Map Methods for Explainable Brain Hemorrhage Classification on Hemorica Dataset</title>
      <link>https://arxiv.org/abs/2508.17699</link>
      <description>arXiv:2508.17699v1 Announce Type: cross 
Abstract: Explainable Artificial Intelligence (XAI) has become an essential component of medical imaging research, aiming to increase transparency and clinical trust in deep learning models. This study investigates brain hemorrhage diagnosis with a focus on explainability through Class Activation Mapping (CAM) techniques. A pipeline was developed to extract pixellevel segmentation and detection annotations from classification models using nine state-of-the-art CAM algorithms, applied across multiple network stages, and quantitatively evaluated on the Hemorica dataset, which uniquely provides both slice-level labels and high-quality segmentation masks. Metrics including Dice, IoU, and pixel-wise overlap were employed to benchmark CAM variants. Results show that the strongest localization performance occurred at stage 5 of EfficientNetV2S, with HiResCAM yielding the highest bounding-box alignment and AblationCAM achieving the best pixel-level Dice (0.57) and IoU (0.40), representing strong accuracy given that models were trained solely for classification without segmentation supervision. To the best of current knowledge, this is among the f irst works to quantitatively compare CAM methods for brain hemorrhage detection, establishing a reproducible benchmark and underscoring the potential of XAI-driven pipelines for clinically meaningful AI-assisted diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17699v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Z. Rafati, M. Hoseyni, J. Khoramdel, A. Nikoofard</dc:creator>
    </item>
    <item>
      <title>Arnold: a generalist muscle transformer policy</title>
      <link>https://arxiv.org/abs/2508.18066</link>
      <description>arXiv:2508.18066v1 Announce Type: cross 
Abstract: Controlling high-dimensional and nonlinear musculoskeletal models of the human body is a foundational scientific challenge. Recent machine learning breakthroughs have heralded policies that master individual skills like reaching, object manipulation and locomotion in musculoskeletal systems with many degrees of freedom. However, these agents are merely "specialists", achieving high performance for a single skill. In this work, we develop Arnold, a generalist policy that masters multiple tasks and embodiments. Arnold combines behavior cloning and fine-tuning with PPO to achieve expert or super-expert performance in 14 challenging control tasks from dexterous object manipulation to locomotion. A key innovation is Arnold's sensorimotor vocabulary, a compositional representation of the semantics of heterogeneous sensory modalities, objectives, and actuators. Arnold leverages this vocabulary via a transformer architecture to deal with the variable observation and action spaces of each task. This framework supports efficient multi-task, multi-embodiment learning and facilitates rapid adaptation to novel tasks. Finally, we analyze Arnold to provide insights into biological motor control, corroborating recent findings on the limited transferability of muscle synergies across tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18066v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Silvio Chiappa, Boshi An, Merkourios Simos, Chengkun Li, Alexander Mathis</dc:creator>
    </item>
    <item>
      <title>Optimizing the Design of an Artificial Pancreas to Improve Diabetes Management</title>
      <link>https://arxiv.org/abs/2402.07949</link>
      <description>arXiv:2402.07949v2 Announce Type: replace 
Abstract: Diabetes, a chronic condition that impairs how the body turns food into energy, i.e. blood glucose, affects 38 million people in the US alone. The standard treatment is to supplement carbohydrate intake with an artificial pancreas, i.e. a continuous insulin pump (basal shots), as well as occasional insulin injections (bolus shots). The goal of the treatment is to keep blood glucose at the center of an acceptable range, as measured through a continuous glucose meter. A secondary goal is to minimize injections, which are unpleasant and difficult for some patients to implement. In this study, neuroevolution was used to discover an optimal strategy for the treatment. Based on a dataset of 30 days of treatment and measurements of a single patient, a random forest was first trained to predict future glucose levels. A neural network was then evolved to prescribe carbohydrates, basal pumping levels, and bolus injections. Evolution discovered a Pareto front that reduced deviation from the target and number of injections compared to the original data, thus improving patients' quality of life. To make the system easier to adopt, a language interface was developed with a large language model. Thus, these technologies not only improve patient care but also adoption in a broader population.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07949v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the IJCAI workshop on Advanced Neural Systems for Next-Generation Biomedical Intelligence, 2025</arxiv:journal_reference>
      <dc:creator>Ashok Khanna, Olivier Francon, Risto Miikkulainen</dc:creator>
    </item>
    <item>
      <title>High-Throughput Low-Cost Segmentation of Brightfield Microscopy Live Cell Images</title>
      <link>https://arxiv.org/abs/2508.14106</link>
      <description>arXiv:2508.14106v2 Announce Type: replace 
Abstract: Live cell culture is crucial in biomedical studies for analyzing cell properties and dynamics in vitro. This study focuses on segmenting unstained live cells imaged with bright-field microscopy. While many segmentation approaches exist for microscopic images, none consistently address the challenges of bright-field live-cell imaging with high throughput, where temporal phenotype changes, low contrast, noise, and motion-induced blur from cellular movement remain major obstacles. We developed a low-cost CNN-based pipeline incorporating comparative analysis of frozen encoders within a unified U-Net architecture enhanced with attention mechanisms, instance-aware systems, adaptive loss functions, hard instance retraining, dynamic learning rates, progressive mechanisms to mitigate overfitting, and an ensemble technique. The model was validated on a public dataset featuring diverse live cell variants, showing consistent competitiveness with state-of-the-art methods, achieving 93% test accuracy and an average F1-score of 89% (std. 0.07) on low-contrast, noisy, and blurry images. Notably, the model was trained primarily on bright-field images with limited exposure to phase- contrast microscopy (&lt;20%), yet it generalized effectively to the phase-contrast LIVECell dataset, demonstrating modality, robustness and strong performance. This highlights its potential for real- world laboratory deployment across imaging conditions. The model requires minimal compute power and is adaptable using basic deep learning setups such as Google Colab, making it practical for training on other cell variants. Our pipeline outperforms existing methods in robustness and precision for bright-field microscopy segmentation. The code and dataset are available for reproducibility 1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14106v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surajit Das, Gourav Roy, Pavel Zun</dc:creator>
    </item>
    <item>
      <title>Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting</title>
      <link>https://arxiv.org/abs/2508.12260</link>
      <description>arXiv:2508.12260v2 Announce Type: replace-cross 
Abstract: Infectious disease forecasting in novel outbreaks or low resource settings has been limited by the need for disease-specific data, bespoke training, and expert tuning. We introduce Mantis, a foundation model trained entirely on mechanistic simulations, which enables out-of-the-box forecasting across diseases, regions, and outcomes, even in settings with limited historical data. Mantis is built on over 400 million simulated days of outbreak dynamics spanning diverse pathogens, transmission modes, interventions, and surveillance artifacts. Despite requiring no real-world data during training, Mantis outperformed 39 expert-tuned models we tested across six diseases, including all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel epidemiological regimes, including diseases with held-out transmission mechanisms, demonstrating that it captures fundamental contagion dynamics. Critically, Mantis is mechanistically interpretable, enabling public health decision-makers to identify the latent drivers behind its predictions. Finally, Mantis delivers accurate forecasts at 8-week horizons, more than doubling the actionable range of most models, enabling proactive public health planning. Together, these capabilities position Mantis as a foundation for next-generation disease forecasting systems: general, interpretable, and deployable where traditional models fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12260v2</guid>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carson Dudley, Reiden Magdaleno, Christopher Harding, Ananya Sharma, Emily Martin, Marisa Eisenberg</dc:creator>
    </item>
  </channel>
</rss>
