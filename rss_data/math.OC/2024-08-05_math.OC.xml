<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 02:30:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning with Linear Function Approximations in Mean-Field Control</title>
      <link>https://arxiv.org/abs/2408.00991</link>
      <description>arXiv:2408.00991v1 Announce Type: new 
Abstract: The paper focuses on mean-field type multi-agent control problems where the dynamics and cost structures are symmetric and homogeneous, and are affected by the distribution of the agents. A standard solution method for these problems is to consider the infinite population limit as an approximation and use symmetric solutions of the limit problem to achieve near optimality. The control policies, and in particular the dynamics, depend on the population distribution in the finite population setting, or the marginal distribution of the state variable of a representative agent for the infinite population setting. Hence, learning and planning for these control problems generally require estimating the reaction of the system to all possible state distributions of the agents. To overcome this issue, we consider linear function approximation for the control problem and provide several coordinated and independent learning methods. We rigorously establish error upper bounds for the performance of learned solutions. The performance gap stems from (i) the mismatch due to estimating the true model with a linear one, and (ii) using the infinite population solution in the finite population problem as an approximate control. The provided upper bounds quantify the impact of these error sources on the overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00991v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Ali D. Kara</dc:creator>
    </item>
    <item>
      <title>Analysis of Microhubs for Three-Sided Meal Delivery Services</title>
      <link>https://arxiv.org/abs/2408.01047</link>
      <description>arXiv:2408.01047v1 Announce Type: new 
Abstract: The rise of online meal delivery has led to a surge in delivery traffic to urban neighborhoods, resulting in issues such as increased traffic congestion, illegal parking, noise, and air pollution. This paper introduces and analyzes a novel meal delivery strategy that incorporates a microhub. In this approach, the service area is segmented into smaller sub-areas, with deliverers assigned to operate exclusively within these sub-areas. The microhub functions as a transfer depot, enabling the batching and transfer of orders toward different sub-areas. To evaluate this system's performance, two critical metrics -- customer waiting time and vehicle miles traveled -- are estimated through the continuous approximation approach. Comprehensive numerical experiments are conducted to validate the accuracy of our approximations. The derived analytical approximation is then integrated into an optimal design problem to determine the optimal number of sub-areas and the optimal batch size of packages within each sub-area. The numerical results suggest that the meal delivery system with a microhub outperforms the traditional pickup and delivery mode in both metrics, under either high demand or low supply conditions. The higher efficiency of the microhub design is attributed to the strategy of sub-regional batching, facilitated by the use of the microhub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01047v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linxuan Shi, Zhengtian Xu</dc:creator>
    </item>
    <item>
      <title>Reduced-Rank Estimation for Ill-Conditioned Stochastic Linear Model with High Signal-to-Noise Ratio</title>
      <link>https://arxiv.org/abs/2408.01117</link>
      <description>arXiv:2408.01117v1 Announce Type: new 
Abstract: Reduced-rank approach has been used for decades in robust linear estimation of both deterministic and random vector of parameters in linear model y=Hx+\sqrt{epsilon}n. In practical settings, estimation is frequently performed under incomplete or inexact model knowledge, which in the stochastic case significantly increases mean-square-error (MSE) of an estimate obtained by the linear minimum mean-square-error (MMSE) estimator, which is MSE-optimal among linear estimators in the theoretical case of perfect model knowledge. However, the improved performance of reduced-rank estimators over MMSE estimator in estimation under incomplete or inexact model knowledge has been established to date only by means of numerical simulations and arguments indicating that the reduced-rank approach may provide improved performance over MMSE estimator in certain settings. In this paper we focus on the high signal-to-noise ratio (SNR) case, which has not been previously considered as a natural area of application of reduced-rank estimators. We first show explicit sufficient conditions under which familiar reduced-rank MMSE and truncated SVD estimators achieve lower MSE than MMSE estimator if singular values of array response matrix H are perturbed. We then extend these results to the case of a generic perturbation of array response matrix H, and demonstrate why MMSE estimator frequently attains higher MSE than reduced-rank MMSE and truncated SVD estimators if H is ill-conditioned. The main results of this paper are verified in numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01117v1</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jfranklin.2016.05.007</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Franklin Institute, 2016</arxiv:journal_reference>
      <dc:creator>Tomasz Piotrowski, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Common Noise by Random Measures: Mean-Field Equilibria for Competitive Investment and Hedging</title>
      <link>https://arxiv.org/abs/2408.01175</link>
      <description>arXiv:2408.01175v1 Announce Type: new 
Abstract: We study mean-field games where common noise dynamics are described by integer-valued random measures, for instance Poisson random measures, in addition to Brownian motions. In such a framework, we describe Nash equilibria for mean-field portfolio games of both optimal investment and hedging under relative performance concerns with respect to exponential (CARA) utility preferences. Agents have independent individual risk aversions, competition weights and initial capital endowments, whereas their liabilities are described by contingent claims which can depend on both common and idiosyncratic risk factors. Liabilities may incorporate, e.g., compound Poisson-like jump risks and can only be hedged partially by trading in a common but incomplete financial market, in which prices of risky assets evolve as It\^{o}-processes. Mean-field equilibria are fully characterized by solutions to suitable McKean-Vlasov forward-backward SDEs with jumps, for whose we prove existence and uniqueness of solutions, without restricting competition weights to be small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01175v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dirk Becherer, Stefanie Hesse</dc:creator>
    </item>
    <item>
      <title>A Short-Term Planning Framework for the Operation of Tanker-Based Water Distribution Systems in Urban Areas</title>
      <link>https://arxiv.org/abs/2408.01184</link>
      <description>arXiv:2408.01184v1 Announce Type: new 
Abstract: Tanker-based distribution systems have been prevalent in developing countries to supply clean and pure water in different regions. To efficiently operate such tanker service systems, a large fleet of tanker trucks are required to transport water among several water sources, water treatment plants and consumers spanning across the regions. This requires tighter coordination between water suppliers, treatment plant operations, and user groups to use available water resources in a sustainable manner, along with the assurance of water quality and timely delivery. This paper proposes a novel formulation to assist decision-making for optimizing tanker-based water distribution systems and treatment operations, with an overall objective of minimizing the total operating cost such that all of the constraints related to the water demand, supply operations, and environmental and social aspects are honored while supplying water to a maximum number of users. The problem is formulated and solved as a mixed integer linear programming (MILP) optimization framework and captures all of the nuances related to (i) water availability limitations and quality constraints from different sources, (ii) maintaining water quality as it transports via tankers, (iii) water demands for various end-use purposes, and (iv) transportation across a water supply chain. The proposed novel framework is applied to a realistic urban model to find the optimal tanker delivery schedule, ensuring appropriate treatment and timely delivery of water. The results of the case study conducted on a representative-scale problem also elucidate several aspects of treatment plant operation and consumer demand fulfillment for the efficient planning and management of tanker-based water distribution systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01184v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1021/acs.iecr.0c00303</arxiv:DOI>
      <dc:creator>Abhilasha Maheshwari, Shamik Misra, Ravindra Gudi, Senthilmurugan Subbiah</dc:creator>
    </item>
    <item>
      <title>Occasionally Observed Piecewise-deterministic Markov Processes</title>
      <link>https://arxiv.org/abs/2408.01335</link>
      <description>arXiv:2408.01335v1 Announce Type: new 
Abstract: Piecewise-deterministic Markov processes (PDMPs) are often used to model abrupt changes in the global environment or capabilities of a controlled system. This is typically done by considering a set of "operating modes" (each with its own system dynamics and performance metrics) and assuming that the mode can switch stochastically while the system state evolves. Such models have a broad range of applications in engineering, economics, manufacturing, robotics, and biological sciences. Here, we introduce and analyze an "occasionally observed" version of mode-switching PDMPs. We show how such systems can be controlled optimally if the planner is not alerted to mode-switches as they occur but may instead have access to infrequent mode observations. We first develop a general framework for handling this through dynamic programming on a higher-dimensional mode-belief space. While quite general, this method is rarely practical due to the curse of dimensionality. We then discuss assumptions that allow for solving the same problem much more efficiently, with the computational costs growing linearly (rather than exponentially) with the number of modes. We use this approach to derive Hamilton-Jacobi-Bellman PDEs and quasi-variational inequalities encoding the optimal behavior for a variety of planning horizons (fixed, infinite, indefinite, random) and mode-observation schemes (at fixed times or on-demand). We discuss the computational challenges associated with each version and illustrate the resulting methods on test problems from surveillance-evading path planning. We also include an example based on robotic navigation: a Mars rover that minimizes the expected time to target while accounting for the possibility of unobserved/incremental damages and dynamics-altering breakdowns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01335v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marissa Gee, Alexander Vladimirsky</dc:creator>
    </item>
    <item>
      <title>A value-focused thinking approach to measure community resilience</title>
      <link>https://arxiv.org/abs/2408.00901</link>
      <description>arXiv:2408.00901v1 Announce Type: cross 
Abstract: Community resilience refers to the ability to prepare for, absorb, recover from, and adapt to disruptive events, but specific definitions and measures for resilience can vary widely from researcher to researcher or from discipline to discipline. Community resilience is often measured using a set of indicators based on census, socioeconomic, and community organizational data, but these metrics and measures for community resilience provide little guidance for policymakers to determine how best to increase the community resilience. This article proposes to measure community resilience based on value focused thinking. We propose an objectives hierarchy that begins with a community decision makers' fundamental objective for resilience. Six high level objectives for community resilience, including social resilience, economic resilience, infrastructure resilience, environmental resilience, availability of resources, and functionality of critical services, are broken down into measurable attributes that focus on specific outcomes that a decision maker would like to achieve if a disruption occurs. This new way of assessing resilience is applied to measure the resilience of an illustrative community to an improvised explosive device, a cyberattack, a tornado, a flood, and a winter storm. Keywords: Community Resilience, Resiliency, Risk Analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00901v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohit Suresh, Parastoo Akbari, Cameron A MacKenzie</dc:creator>
    </item>
    <item>
      <title>Characterization of the Dynamical Properties of Safety Filters for Linear Planar Systems</title>
      <link>https://arxiv.org/abs/2408.00958</link>
      <description>arXiv:2408.00958v1 Announce Type: cross 
Abstract: This paper studies the dynamical properties of closed-loop systems obtained from control barrier function-based safety filters. We provide a sufficient and necessary condition for the existence of undesirable equilibria and show that the Jacobian matrix of the closed-loop system evaluated at an undesirable equilibrium always has a nonpositive eigenvalue. In the special case of linear planar systems and ellipsoidal obstacles, we give a complete characterization of the dynamical properties of the corresponding closed-loop system. We show that for underactuated systems, the safety filter always introduces a single undesired equilibrium, which is a saddle point. We prove that all trajectories outside the global stable manifold of such equilibrium converge to the origin. In the fully actuated case, we discuss how the choice of nominal controller affects the stability properties of the closed-loop system. Various simulations illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00958v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiting Chen, Pol Mestres, Emiliano Dall'Anese, Jorge Cortes</dc:creator>
    </item>
    <item>
      <title>Numerical approximations of McKean Anticipative Backward Stochastic Differential Equations arising in Initial Margin requirements</title>
      <link>https://arxiv.org/abs/2408.01185</link>
      <description>arXiv:2408.01185v1 Announce Type: cross 
Abstract: We introduce a new class of anticipative backward stochastic differential equations with a dependence of McKean type on the law of the solution, that we name MKABSDE. We provide existence and uniqueness results in a general framework with relatively general regularity assumptions on the coefficients. We show how such stochastic equations arise within the modern paradigm of derivative pricing where a central counterparty (CCP) requires the members to deposit variation and initial margins to cover their exposure. In the case when the initial margin is proportional to the Conditional Value-at-Risk (CVaR) of the contract price, we apply our general result to define the price as a solution of a MKABSDE. We provide several linear and non-linear simpler approximations, which we solve using different numerical (deterministic and Monte-Carlo) methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01185v1</guid>
      <category>q-fin.PR</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1051/proc/201965001</arxiv:DOI>
      <arxiv:journal_reference>Agarwal, A. et. al., Numerical approximations of McKean anticipative backward stochastic differential equations arising in initial margin requirements, ESAIM: ProcS, 2019, 65, 1-26</arxiv:journal_reference>
      <dc:creator>A. Agarwal, S. De Marco, E. Gobet, J. G. Lopez-Salas, F. Noubiagain, A. Zhou</dc:creator>
    </item>
    <item>
      <title>Certified Robust Invariant Polytope Training in Neural Controlled ODEs</title>
      <link>https://arxiv.org/abs/2408.01273</link>
      <description>arXiv:2408.01273v1 Announce Type: cross 
Abstract: We consider a nonlinear control system modeled as an ordinary differential equation subject to disturbance, with a state feedback controller parameterized as a feedforward neural network. We propose a framework for training controllers with certified robust forward invariant polytopes, where any trajectory initialized inside the polytope remains within the polytope, regardless of the disturbance. First, we parameterize a family of lifted control systems in a higher dimensional space, where the original neural controlled system evolves on an invariant subspace of each lifted system. We use interval analysis and neural network verifiers to further construct a family of lifted embedding systems, carefully capturing the knowledge of this invariant subspace. If the vector field of any lifted embedding system satisfies a sign constraint at a single point, then a certain convex polytope of the original system is robustly forward invariant. Treating the neural network controller and the lifted system parameters as variables, we propose an algorithm to train controllers with certified forward invariant polytopes in the closed-loop control system. Through two examples, we demonstrate how the simplicity of the sign constraint allows our approach to scale with system dimension to over $50$ states, and outperform state-of-the-art Lyapunov-based sampling approaches in runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01273v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>A Converse Robust-Safety Theorem for Differential Inclusions</title>
      <link>https://arxiv.org/abs/2208.11364</link>
      <description>arXiv:2208.11364v3 Announce Type: replace 
Abstract: This paper establishes the equivalence between robust safety and the existence of a barrier function certificate for differential inclusions. More precisely, for a robustly-safe differential inclusion, a barrier function is constructed as the time-to-impact function with respect to a specifically-constructed reachable set. Using techniques from set-valued and nonsmooth analysis, we show that such a function, although being possibly discontinuous, certifies robust safety by verifying a condition involving the system's solutions. Furthermore, we refine this construction, using smoothing techniques from the literature of converse Lyapunov theory, to provide a smooth barrier certificate that certifies robust safety by verifying a condition involving only the barrier function and the system's dynamics. In comparison with existing converse robust-safety theorems, our results are more general as they allow the safety region to be unbounded, the dynamics to be a general continuous set-valued map, and the solutions to be non-unique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.11364v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Maghenem, Masoumeh Ghanbarpour</dc:creator>
    </item>
    <item>
      <title>Linear System Analysis and Optimal Control of Natural Gas Dynamics in Pipeline Networks</title>
      <link>https://arxiv.org/abs/2305.06658</link>
      <description>arXiv:2305.06658v3 Announce Type: replace 
Abstract: We examine nonlinear and adaptive linear control systems that model compressor-actuated dynamics of natural gas flow in pipeline networks. A model-predictive controller (MPC) is developed for feedback control of compressor actions in which the internal optimization over the local time horizon is constrained by the dynamics of either the nonlinear system or the adaptive linear system. Stability of the local linear system is established and a rigorous bound on the error between the solutions of the nonlinear and linear systems is derived and used to devise situations when the linear MPC may be used instead of the nonlinear MPC without a significant difference between their respective predictions. We use several test networks to compare the performances of various controllers that involve nonlinear and adaptive linear models as well as moving-horizon and single-interval optimization. Our results demonstrate that the proposed moving-horizon MPC is well-equipped to adapt in local time to changes in system parameters and has the ability to reduce total computational costs by orders of magnitude relative to conventional transient optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.06658v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Sachin Shivakumar, Dieter Armbruster, Rodrigo B. Platte, Anatoly Zlotnik</dc:creator>
    </item>
    <item>
      <title>A mathematical model of the visual MacKay effect</title>
      <link>https://arxiv.org/abs/2311.07338</link>
      <description>arXiv:2311.07338v5 Announce Type: replace 
Abstract: This paper investigates the intricate connection between visual perception and the mathematical modeling of neural activity in the primary visual cortex (V1). The focus is on modeling the visual MacKay effect [D. M. MacKay, Nature, 180 (1957), pp. 849--850]. While bifurcation theory has been a prominent mathematical approach for addressing issues in neuroscience, especially in describing spontaneous pattern formations in V1 due to parameter changes, it faces challenges in scenarios with localized sensory inputs. This is evident, for instance, in MacKay's psychophysical experiments, where the redundancy of visual stimuli information results in irregular shapes, making bifurcation theory and multiscale analysis less effective. To address this, we follow a mathematical viewpoint based on the input-output controllability of an Amari-type neural fields model. In this framework, we consider sensory input as a control function, a cortical representation via the retino-cortical map of the visual stimulus that captures its distinct features. This includes highly localized information in the center of MacKay's funnel pattern "MacKay rays". From a control theory point of view, the Amari-type equation's exact controllability property is discussed for linear and nonlinear response functions. For the visual MacKay effect modeling, we adjust the parameter representing intra-neuron connectivity to ensure that cortical activity exponentially stabilizes to the stationary state in the absence of sensory input. Then, we perform quantitative and qualitative studies to demonstrate that they capture all the essential features of the induced after-image reported by MacKay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07338v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Dario Prandi, Yacine Chitour</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification of Set-Membership Estimation in Control and Perception: Revisiting the Minimum Enclosing Ellipsoid</title>
      <link>https://arxiv.org/abs/2311.15962</link>
      <description>arXiv:2311.15962v4 Announce Type: replace 
Abstract: Set-membership estimation (SME) outputs a set estimator that guarantees to cover the groundtruth. Such sets are, however, defined by (many) abstract (and potentially nonconvex) constraints and therefore difficult to manipulate. We present tractable algorithms to compute simple and tight overapproximations of SME in the form of minimum enclosing ellipsoids (MEE). We first introduce the hierarchy of enclosing ellipsoids proposed by Nie and Demmel (2005), based on sums-of-squares relaxations, that asymptotically converge to the MEE of a basic semialgebraic set. This framework, however, struggles in modern control and perception problems due to computational challenges. We contribute three computational enhancements to make this framework practical, namely constraints pruning, generalized relaxed Chebyshev center, and handling non-Euclidean geometry. We showcase numerical examples on system identification and object pose estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15962v4</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukai Tang, Jean-Bernard Lasserre, Heng Yang</dc:creator>
    </item>
    <item>
      <title>On the Nonsmooth Geometry and Neural Approximation of the Optimal Value Function of Infinite-Horizon Pendulum Swing-up</title>
      <link>https://arxiv.org/abs/2312.17467</link>
      <description>arXiv:2312.17467v3 Announce Type: replace 
Abstract: We revisit the inverted pendulum problem with the goal of understanding and computing the true optimal value function. We start with an observation that the true optimal value function must be nonsmooth ($i.e.$, not globally $C^1$) due to the symmetry of the problem. We then give a result that can certify the optimality of a candidate $\textit{piece-wise}$ $C^1$ value function. Further, for a candidate value function obtained via numerical approximation, we provide a bound of suboptimality based on its Hamilton-Jacobi-Bellman (HJB) equation residuals. Inspired by Holzhuter (2004), we then design an algorithm that solves backward the Pontryagin's minimum principle (PMP) ODE from terminal conditions provided by the locally optimal LQR value function. This numerical procedure leads to a piece-wise $C^1$ value function whose nonsmooth region contains periodic $\textit{spiral lines}$ and smooth regions attain HJB residuals about $10^{-4}$, hence certified to be the optimal value function up to minor numerical inaccuracies. This optimal value function checks the power of optimality: (i) it sits above a polynomial lower bound; (ii) its induced controller globally swings up and stabilizes the pendulum, and (iii) attains lower trajectory cost than baseline methods such as energy shaping, model predictive control (MPC), and proximal policy optimization (with MPC attaining almost the same cost). We conclude by distilling the optimal value function into a simple neural network. Our code is avilable in https://github.com/ComputationalRobotics/InvertedPendulumOptimalValue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17467v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Han, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Towards Model-Free LQR Control over Rate-Limited Channels</title>
      <link>https://arxiv.org/abs/2401.01258</link>
      <description>arXiv:2401.01258v2 Announce Type: replace 
Abstract: Given the success of model-free methods for control design in many problem settings, it is natural to ask how things will change if realistic communication channels are utilized for the transmission of gradients or policies. While the resulting problem has analogies with the formulations studied under the rubric of networked control systems, the rich literature in that area has typically assumed that the model of the system is known. As a step towards bridging the fields of model-free control design and networked control systems, we ask: \textit{Is it possible to solve basic control problems - such as the linear quadratic regulator (LQR) problem - in a model-free manner over a rate-limited channel?} Toward answering this question, we study a setting where a worker agent transmits quantized policy gradients (of the LQR cost) to a server over a noiseless channel with a finite bit-rate. We propose a new algorithm titled Adaptively Quantized Gradient Descent (\texttt{AQGD}), and prove that above a certain finite threshold bit-rate, \texttt{AQGD} guarantees exponentially fast convergence to the globally optimal policy, with \textit{no deterioration of the exponent relative to the unquantized setting}. More generally, our approach reveals the benefits of adaptive quantization in preserving fast linear convergence rates, and, as such, may be of independent interest to the literature on compressed optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01258v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aritra Mitra, Lintao Ye, Vijay Gupta</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Traveling Purchaser Problems</title>
      <link>https://arxiv.org/abs/2404.02476</link>
      <description>arXiv:2404.02476v3 Announce Type: replace 
Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently construct the route using the policy network, and once the route is determined, the associated purchasing plan can be easily derived through linear programming, while, leveraging DRL, we can train the policy network to optimize the global solution objective. Furthermore, by introducing a meta-learning strategy, the policy network can be trained stably on large-sized TPP instances, and generalize well across instances of varying sizes and distributions, even to much larger instances that are never seen during training. Experiments on various synthetic TPP instances and the TPPLIB benchmark demonstrate that our DRL-based approach can significantly outperform well-established TPP heuristics, reducing the optimality gap by 40%-90%, and also showing an advantage in runtime, especially on large-sized instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02476v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haofeng Yuan, Rongping Zhu, Wanlu Yang, Shiji Song, Keyou You, Yuli Zhang, C. L. Philip Chen</dc:creator>
    </item>
    <item>
      <title>Globally-Constrained Decentralized Optimization with Variable Coupling</title>
      <link>https://arxiv.org/abs/2407.10770</link>
      <description>arXiv:2407.10770v2 Announce Type: replace 
Abstract: Many realistic decision-making problems in networked scenarios, such as formation control and collaborative task offloading, often involve complicatedly entangled local decisions, which, however, have not been sufficiently investigated yet. Motivated by this, we study a class of decentralized optimization problems with a variable coupling structure that is new to the literature. Specifically, we consider a network of nodes collaborating to minimize a global objective subject to a collection of global inequality and equality constraints, which are formed by the local objective and constraint functions of the nodes. On top of that, we allow such local functions of each node to depend on not only its own decision variable but the decisions of its neighbors as well. To address this problem, we propose a decentralized projected primal-dual algorithm. It first incorporates a virtual-queue technique with a primal-dual-primal scheme, and then linearizes the non-separable objective and constraint functions to enable decentralized implementation. Under mild conditions, we derive $O(1/k)$ convergence rates for both objective error and constraint violations. Finally, two numerical experiments corroborate our theoretical results and illustrate the competitive performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10770v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dandan Wang, Xuyang Wu, Zichong Ou, Jie Lu</dc:creator>
    </item>
    <item>
      <title>Weighed l1 on the simplex: Compressive sensing meets locality</title>
      <link>https://arxiv.org/abs/2104.13894</link>
      <description>arXiv:2104.13894v2 Announce Type: replace-cross 
Abstract: Sparse manifold learning algorithms combine techniques in manifold learning and sparse optimization to learn features that could be utilized for downstream tasks. The standard setting of compressive sensing can not be immediately applied to this setup. Due to the intrinsic geometric structure of data, dictionary atoms might be redundant and do not satisfy the restricted isometry property or coherence condition. In addition, manifold learning emphasizes learning local geometry which is not reflected in a standard $\ell_1$ minimization problem. We propose weighted $\ell_0$ and weighted $\ell_1$ metrics that encourage representation via neighborhood atoms suited for dictionary based manifold learning. Assuming that the data is generated from Delaunay triangulation, we show the equivalence of weighted $\ell_0$ and weighted $\ell_1$. We discuss an optimization program that learns the dictionaries and sparse coefficients and demonstrate the utility of our regularization on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.13894v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abiy Tasissa, Pranay Tankala, Demba Ba</dc:creator>
    </item>
    <item>
      <title>DASA: Delay-Adaptive Multi-Agent Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2403.17247</link>
      <description>arXiv:2403.17247v3 Announce Type: replace-cross 
Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tau_{mix}$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, including multi-agent and distributed temporal difference (TD) learning, Q-learning and stochastic optimization with correlated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17247v3</guid>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicol\`o Dal Fabbro, Arman Adibi, H. Vincent Poor, Sanjeev R. Kulkarni, Aritra Mitra, George J. Pappas</dc:creator>
    </item>
    <item>
      <title>On Exponential Convergence of Random Variables</title>
      <link>https://arxiv.org/abs/2406.03644</link>
      <description>arXiv:2406.03644v3 Announce Type: replace-cross 
Abstract: Given the discrete-time sequence of nonnegative random variables, general dependencies between the exponential convergence of the expectations, exponential convergence of the trajectories and the logarithmic growth of the corresponding expected hitting times are analysed. The applications are presented: the general results are applied to the areas of optimization, stochastic control and estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03644v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4064/am2540-7-2024</arxiv:DOI>
      <arxiv:journal_reference>Applicationes Mathematicae 51 (2024), 1-11</arxiv:journal_reference>
      <dc:creator>Dawid Tar{\l}owski</dc:creator>
    </item>
    <item>
      <title>cDVAE: Multimodal Generative Conditional Diffusion Guided by Variational Autoencoder Latent Embedding for Virtual 6D Phase Space Diagnostics</title>
      <link>https://arxiv.org/abs/2407.20218</link>
      <description>arXiv:2407.20218v5 Announce Type: replace-cross 
Abstract: Imaging the 6D phase space of a beam in a particle accelerator in a single shot is currently impossible. Single shot beam measurements only exist for certain 2D beam projections and these methods are destructive. A virtual diagnostic that can generate an accurate prediction of a beam's 6D phase space would be incredibly useful for precisely controlling the beam. In this work, a generative conditional diffusion-based approach to creating a virtual diagnostic of all 15 unique 2D projections of a beam's 6D phase space is developed. The diffusion process is guided by a combination of scalar parameters and images that are converted to low-dimensional latent vector representation by a variational autoencoder (VAE). We demonstrate that conditional diffusion guided by VAE (cDVAE) can accurately reconstruct all 15 of the unique 2D projections of a charge particle beam's 6 phase space for the HiRES compact accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20218v5</guid>
      <category>physics.acc-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Scheinker</dc:creator>
    </item>
    <item>
      <title>Infrequent Resolving Algorithm for Online Linear Programming</title>
      <link>https://arxiv.org/abs/2408.00465</link>
      <description>arXiv:2408.00465v2 Announce Type: replace-cross 
Abstract: Online linear programming (OLP) has gained significant attention from both researchers and practitioners due to its extensive applications, such as online auction, network revenue management and advertising. Existing OLP algorithms fall into two categories: LP-based algorithms and LP-free algorithms. The former one typically guarantees better performance, even offering a constant regret, but requires solving a large number of LPs, which could be computationally expensive. In contrast, LP-free algorithm only requires first-order computations but induces a worse performance, lacking a constant regret bound. In this work, we bridge the gap between these two extremes by proposing an algorithm that achieves a constant regret while solving LPs only $O(\log\log T)$ times over the time horizon $T$. Moreover, when we are allowed to solve LPs only $M$ times, we propose an algorithm that can guarantee an $O\left(T^{(1/2+\epsilon)^{M-1}}\right)$ regret. Furthermore, when the arrival probabilities are known at the beginning, our algorithm can guarantee a constant regret by solving LPs $O(\log\log T)$ times, and an $O\left(T^{(1/2+\epsilon)^{M}}\right)$ regret by solving LPs only $M$ times. Numerical experiments are conducted to demonstrate the efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00465v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guokai Li, Zizhuo Wang, Jingwei Zhang</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning applied to Insurance Portfolio Pursuit</title>
      <link>https://arxiv.org/abs/2408.00713</link>
      <description>arXiv:2408.00713v2 Announce Type: replace-cross 
Abstract: When faced with a new customer, many factors contribute to an insurance firm's decision of what offer to make to that customer. In addition to the expected cost of providing the insurance, the firm must consider the other offers likely to be made to the customer, and how sensitive the customer is to differences in price. Moreover, firms often target a specific portfolio of customers that could depend on, e.g., age, location, and occupation. Given such a target portfolio, firms may choose to modulate an individual customer's offer based on whether the firm desires the customer within their portfolio. We term the problem of modulating offers to achieve a desired target portfolio the portfolio pursuit problem. Having formulated the portfolio pursuit problem as a sequential decision making problem, we devise a novel reinforcement learning algorithm for its solution. We test our method on a complex synthetic market environment, and demonstrate that it outperforms a baseline method which mimics current industry approaches to portfolio pursuit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00713v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Edward James Young, Alistair Rogers, Elliott Tong, James Jordon</dc:creator>
    </item>
  </channel>
</rss>
