<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Apr 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Regularization in Space-Time Topology Optimization for Multi-Axis Additive Manufacturing</title>
      <link>https://arxiv.org/abs/2404.13059</link>
      <description>arXiv:2404.13059v1 Announce Type: new 
Abstract: In additive manufacturing, the fabrication sequence has a large influence on the quality of manufactured components. While planning of the fabrication sequence is typically performed after the component has been designed, recent developments have demonstrated the possibility and benefits of simultaneous optimization of both the structural layout and the corresponding fabrication sequence. The simultaneous optimization approach, called space-time topology optimization, introduces a pseudo-time field to encode the manufacturing process order, alongside a pseudo-density field representing the structural layout. To comply with manufacturing principles, the pseudo-time field needs to be monotonic, i.e., free of local minima. However, explicitly formulated constraints are not always effective, particularly for complex structural layouts.
  In this paper, we introduce a novel method to regularize the pseudo-time field in space-time topology optimization. We conceptualize the monotonic additive manufacturing process as a virtual heat conduction process starting from the surface upon which a component is constructed layer by layer. The virtual temperature field, which shall not be confused with the actual temperature field during manufacturing, serves as an analogy for encoding the fabrication sequence. In this new formulation, we use local virtual heat conductivity coefficients as optimization variables to steer the temperature field and, consequently, the fabrication sequence. The virtual temperature field is inherently free of local minima due to the physics it resembles. We numerically validate the effectiveness of this regularization in space-time topology optimization under process-dependent loads, including gravity and thermomechanical loads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13059v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.GR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiming Wang, Kai Wu, Fred van Keulen, Jun Wu</dc:creator>
    </item>
    <item>
      <title>Quantum Assisted Stochastic Economic Dispatch for Renewables Rich Power Systems</title>
      <link>https://arxiv.org/abs/2404.13073</link>
      <description>arXiv:2404.13073v1 Announce Type: new 
Abstract: Considering widely dispersed uncertain renewable energy sources (RESs), scenario-based stochastic optimization is an effective method for the economic dispatch of renewables-rich power systems. However, on classic computers, to simulate RES uncertainties with high accuracy, the massive scenario generation is very time-consuming, and the pertinent optimization problem is high-dimensional NP-hard mixed-integer programming. To this end, we design a quantum-assisted scheme to accelerate the stochastic optimization for power system economic dispatch without losing accuracy. We first propose the unified quantum amplitude estimation to characterize RES uncertainties, thereby generating massive scenarios by a few qubits to reduce state variables. Then, strong Benders cuts corresponding to some specific scenarios are selected to control the solution scale of Benders master problem in the iterative process, all of which are implemented by customized quantum approximation optimization algorithms. Finally, we perform numerical experiments on the modified IEEE 6-bus system to test the designed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13073v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xutao Han, Zhiyi Li, Yue Xu</dc:creator>
    </item>
    <item>
      <title>Optimal Acceleration for Minimax and Fixed-Point Problems is Not Unique</title>
      <link>https://arxiv.org/abs/2404.13228</link>
      <description>arXiv:2404.13228v1 Announce Type: new 
Abstract: Recently, accelerated algorithms using the anchoring mechanism for minimax optimization and fixed-point problems have been proposed, and matching complexity lower bounds establish their optimality. In this work, we present the surprising observation that the optimal acceleration mechanism in minimax optimization and fixed-point problems is not unique. Our new algorithms achieve exactly the same worst-case convergence rates as existing anchor-based methods while using materially different acceleration mechanisms. Specifically, these new algorithms are dual to the prior anchor-based accelerated methods in the sense of H-duality. This finding opens a new avenue of research on accelerated algorithms since we now have a family of methods that empirically exhibit varied characteristics while having the same optimal worst-case guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13228v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>TaeHo Yoon, Jaeyeon Kim, Jaewook J. Suh, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Optimal Control of a Sub-diffusion Model using Dirichlet-Neumann and Neumann-Neumann Waveform Relaxation Algorithms</title>
      <link>https://arxiv.org/abs/2404.13283</link>
      <description>arXiv:2404.13283v1 Announce Type: new 
Abstract: This paper explores the convergence behavior of two waveform relaxation algorithms, namely the Dirichlet-Neumann and Neumann-Neumann Waveform Relaxation algorithms, for an optimal control problem with a sub-diffusion partial differential equation (PDE) constraint. The algorithms are tested on regular 1D domains with multiple subdomains, and the analysis focuses on how different constant values of the generalized diffusion coefficient affect the convergence of these algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13283v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Soura Sana, Bankim C. Mandal</dc:creator>
    </item>
    <item>
      <title>Sequential subspace methods on Stiefel manifold optimization problems</title>
      <link>https://arxiv.org/abs/2404.13301</link>
      <description>arXiv:2404.13301v1 Announce Type: new 
Abstract: We study the minimization of a quadratic over Stiefel manifolds (the set of all orthogonal $r$-frames in \IR^n), which has applications in high-dimensional semi-supervised classification tasks. To reduce the computational complexity, sequential subspace methods(SSM) are employed to convert the high-dimensional minimization problems to low-dimensional ones. In this paper, we are interested in attaining an optimal solution of good quality, i.e., a ``qualified" critical point. Qualified critical points are those critical points, at which the associated multiplier matrix meets some upper bound condition. These critical points enjoy the global optimality in special quadratic problems. For a general quadratic,
  SSM computes a sequence of ``qualified critical points" in its low-dimensional ``surrogate regularized models". The convergence to a qualified critical point is ensured, whenever each SSM subspace is constructed by the following vectors: (i) a set of orthogonal unit vectors associated with the current iterate, (ii) a set of vectors corresponding to the gradient of the objective, and (iii) a set of eigenvectors associated with the smallest $r$ eigenvalues of the system matrix. In addition, when Newton direction vectors are included in subspaces, the convergence of SSM can be accelerated significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13301v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengwen Chen, Chung-Kuan Cheng, Chester Holtz</dc:creator>
    </item>
    <item>
      <title>On the stability of Lipschitz continuous control problems and its application to reinforcement learning</title>
      <link>https://arxiv.org/abs/2404.13316</link>
      <description>arXiv:2404.13316v1 Announce Type: new 
Abstract: We address the crucial yet underexplored stability properties of the Hamilton--Jacobi--Bellman (HJB) equation in model-free reinforcement learning contexts, specifically for Lipschitz continuous optimal control problems. We bridge the gap between Lipschitz continuous optimal control problems and classical optimal control problems in the viscosity solutions framework, offering new insights into the stability of the value function of Lipschitz continuous optimal control problems. By introducing structural assumptions on the dynamics and reward functions, we further study the rate of convergence of value functions. Moreover, we introduce a generalized framework for Lipschitz continuous control problems that incorporates the original problem and leverage it to propose a new HJB-based reinforcement learning algorithm. The stability properties and performance of the proposed method are tested with well-known benchmark examples in comparison with existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13316v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Namkyeong Cho, Yeoneung Kim</dc:creator>
    </item>
    <item>
      <title>Accelerated Methods with Compression for Horizontal and Vertical Federated Learning</title>
      <link>https://arxiv.org/abs/2404.13328</link>
      <description>arXiv:2404.13328v1 Announce Type: new 
Abstract: Distributed optimization algorithms have emerged as a superior approaches for solving machine learning problems. To accommodate the diverse ways in which data can be stored across devices, these methods must be adaptable to a wide range of situations. As a result, two orthogonal regimes of distributed algorithms are distinguished: horizontal and vertical. During parallel training, communication between nodes can become a critical bottleneck, particularly for high-dimensional and over-parameterized models. Therefore, it is crucial to enhance current methods with strategies that minimize the amount of data transmitted during training while still achieving a model of similar quality. This paper introduces two accelerated algorithms with various compressors, working in the regime of horizontal and vertical data division. By utilizing a momentum and variance reduction technique from the Katyusha algorithm, we were able to achieve acceleration and demonstrate one of the best asymptotics for the horizontal case. Additionally, we provide one of the first theoretical convergence guarantees for the vertical regime. Our experiments involved several compressor operators, including RandK and PermK, and we were able to demonstrate superior practical performance compared to other popular approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13328v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Stanko, Timur Karimullin, Aleksandr Beznosikov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>On Risk-Sensitive Decision Making Under Uncertainty</title>
      <link>https://arxiv.org/abs/2404.13371</link>
      <description>arXiv:2404.13371v1 Announce Type: new 
Abstract: This paper studies a risk-sensitive decision-making problem under uncertainty. It considers a decision-making process that unfolds over a fixed number of stages, in which a decision-maker chooses among multiple alternatives, some of which are deterministic and others are stochastic. The decision-maker's cumulative value is updated at each stage, reflecting the outcomes of the chosen alternatives. After formulating this as a stochastic control problem, we delineate the necessary optimality conditions for it. Two illustrative examples from optimal betting and inventory management are provided to support our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13371v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-fin.CP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chung-Han Hsieh, Yi-Shan Wong</dc:creator>
    </item>
    <item>
      <title>An investigation of stochastic trust-region based algorithms for finite-sum minimization</title>
      <link>https://arxiv.org/abs/2404.13382</link>
      <description>arXiv:2404.13382v1 Announce Type: new 
Abstract: This work elaborates on the TRust-region-ish (TRish) algorithm, a stochastic optimization method for finite-sum minimization problems proposed by Curtis et al. in [Curtis2019, Curtis2022]. A theoretical analysis that complements the results in the literature is presented, and the issue of tuning the involved hyper-parameters is investigated. Our study also focuses on a practical version of the method, which computes the stochastic gradient by means of the inner product test and the orthogonality test proposed by Bollapragada et al. in [Bollapragada2018]. It is shown experimentally that this implementation improves the performance of TRish and reduces its sensitivity to the choice of the hyper-parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13382v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Benedetta Morini, Simone Rebegoldi</dc:creator>
    </item>
    <item>
      <title>Distribution Network Restoration: Resource Scheduling Considering Coupled Transportation-Power Networks</title>
      <link>https://arxiv.org/abs/2404.13422</link>
      <description>arXiv:2404.13422v1 Announce Type: new 
Abstract: Optimal decision-making is key to efficient allocation and scheduling of repair resources (e.g., crews) to service affected nodes of large power grid networks. Traditional manual restoration methods are inadequate for modern smart grids sprawling across vast territories, compounded by the unpredictable nature of damage and disruptions in power and transportation networks. This paper develops a method that focuses on the restoration and repair efforts within power systems. We expand upon the methodology proposed in the literature and incorporate a real-world transportation network to enhance the realism and practicality of repair schedules. Our approach carefully devises a reduced network that combines vulnerable components from the distribution network with the real transportation network. Key contributions include dynamically addressing a coupled resource allocation and capacitated vehicle routing problem over a new reduced network model, constructed by integrating the power grid with the transportation network. This is performed using network heuristics and graph theory to prioritize securing critical grid segments. A case study is presented for the 8500 bus system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13422v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harshal D. Kaushik, Roshni Anna Jacob, Souma Chowdhury, Jie Zhang</dc:creator>
    </item>
    <item>
      <title>Planning of Truck Platooning for Road-Network Capacitated Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2404.13512</link>
      <description>arXiv:2404.13512v1 Announce Type: new 
Abstract: Truck platooning, a linking technology of trucks on the highway, has gained enormous attention in recent years due to its benefits in energy and operation cost savings. However, most existing studies on truck platooning limit their focus on scenarios in which each truck can serve only one customer demand and is thus with a specified origin-destination pair, so only routing and time schedules are considered. Nevertheless, in real-world logistics, each truck may need to serve multiple customers located at different places, and the operator has to determine not only the routing and time schedules of each truck but also the set of customers allocated to each truck and their sequence to visit. This is well known as a capacitated vehicle routing problem with time windows (CVRPTW), and considering the application of truck platooning in such a problem entails new modeling frameworks and tailored solution algorithms. In light of this, this study makes the first attempt to optimize the truck platooning plan for a road-network CVRPTW to minimize the total operation cost, including vehicles' fixed dispatch cost and energy cost, while fulfilling all delivery demands within their time window constraints. Specifically, the operation plan will dictate the number of trucks to be dispatched, the set of customers, and the routing and time schedules for each truck. In addition, the modeling framework is constructed based on a road network instead of a traditional customer node graph to better resemble and facilitate the platooning operation. A 3-stage algorithm embedded with a "route-then-schedule" scheme, dynamic programming, and modified insertion heuristic, is developed to solve the proposed model in a timely manner. Numerical experiments are conducted to validate the modeling framework, demonstrate the performance of the proposed solution algorithm, and quantify the benefit of truck platooning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13512v1</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilang Hao, Zhibin Chen, Xiaotong Sun, Lu Tong</dc:creator>
    </item>
    <item>
      <title>Towards Parameter-free Distributed Optimization: a Port-Hamiltonian Approach</title>
      <link>https://arxiv.org/abs/2404.13529</link>
      <description>arXiv:2404.13529v1 Announce Type: new 
Abstract: This paper introduces a novel distributed optimization technique for networked systems, which removes the dependency on specific parameter choices, notably the learning rate. Traditional parameter selection strategies in distributed optimization often lead to conservative performance, characterized by slow convergence or even divergence if parameters are not properly chosen. In this work, we propose a systems theory tool based on the port-Hamiltonian formalism to design algorithms for consensus optimization programs. Moreover, we propose the Mixed Implicit Discretization (MID), which transforms the continuous-time port-Hamiltonian system into a discrete time one, maintaining the same convergence properties regardless of the step size parameter. The consensus optimization algorithm enhances the convergence speed without worrying about the relationship between parameters and stability. Numerical experiments demonstrate the method's superior performance in convergence speed, outperforming other methods, especially in scenarios where conventional methods fail due to step size parameter limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13529v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Aldana-L\'opez, Alessandro Macchelli, Giuseppe Notarstefano, Rosario Arag\"u\'es, Carlos Sag\"u\'es</dc:creator>
    </item>
    <item>
      <title>Stratified Monge-Kantorovich optimal transport problems</title>
      <link>https://arxiv.org/abs/2404.13616</link>
      <description>arXiv:2404.13616v1 Announce Type: new 
Abstract: In this paper, we investigate Monge-Kantorovich problems for which the absolute continuity of marginals is relaxed. For $X,Y\subseteq\mathbb{R}^{n+1}$ let $(X,\mathcal{B}_X,\mu)$ and $(Y,\mathcal{B}_Y,\nu)$ be two Borel probability spaces, $c:X\times Y\to\mathbb{R}$ be a cost function, and consider the problem \begin{align*}\tag{MKP}\label{MKPEQ} \inf\left\{\int_{X\times Y} c(x,y)\,d\lambda\ :\ \lambda \in\Pi(\mu,\nu) \right\}. \end{align*} Inspired by the seminal paper \cite{GANGBOMCCANN2} with applications in shape recognition problem, we first consider \eqref{MKPEQ} for the cost $c(x,y)=h(x-y)$ with $h$ strictly convex defined on the multi-layers target space \begin{align*} X=\overline{X}\times\{\overline{x}\},\quad\text{and}\quad Y=\bigcup_{k=1}^K \left(\overline{Y}_{k}\times \{\overline{y}_k\}\right), \end{align*} where $\overline{X}, \overline{Y}_{k}\subseteq \mathbb{R}^{n}$ for $k\in \{1,\ldots,K\},$ $\overline{x}\in \mathbb{R}$, and $\{\overline{y}_1,..., \overline{y}_K\}\subseteq \mathbb{R}$. Here, we assume that $\mu|_\overline{X}\ll\mathcal{L}^n$ (the Lebesgue measure on $\mathbb{R}^n$), but $\mu$ is singular w.r.t. $\mathcal{L}^{n+1}$. When $K=1$, this translates to the standard \eqref{MKPEQ} for which the unique solution is concentrated on a map. We show that for $K\geq 2,$ the solution is still unique but it concentrates on the graph of several maps. Next, we study \eqref{MKPEQ} for a closed subset $X\subseteq \mathbb{R}^{n+1}$ and its $n$-dimensional submanifold $X_0$ with the first marginal of the form \begin{align*} \int_X f(x)\,d\mu(x)=\int_X f(x)\alpha(x)\,d\mathcal{L}^{n+1}(x)+\int_{X_0} f(x_0)\,d S(x_0),\ \ \forall f\in C_b(X). \end{align*} Here, $S$ is a measure on $X_0$ such that $S\ll \mathcal{L}^{n}$ on each coordinate chart of $X_0$. This can be seen as a two-layers problem as the measure $\mu$ charges both $n$- and $n+1$-dimensional subsets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13616v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Ali Ahmadpoor, Abbas Moameni</dc:creator>
    </item>
    <item>
      <title>Optimal Interventions in Coupled-Activity Network Games: Application to Sustainable Forestry</title>
      <link>https://arxiv.org/abs/2404.13662</link>
      <description>arXiv:2404.13662v1 Announce Type: new 
Abstract: We consider the problem of promoting sustainability in production forests wherein a given number of strategic entities are authorized to own or manage concession regions. These entities harvest agricultural commodities and sell them in a market. We study optimal price-shaping in a coupled-activity network game model in which the concession owners (agents) engage in two activities: (a) the sustainable activity of producing a commodity that does not interfere with protected forest resources, and (b) the unsustainable activity of infringing into protected regions to expand their agricultural footprint. We characterize two types of policies in a budget-constrained setting: one that maximally suppresses the aggregate unsustainable activity and another that maximizes social welfare while constraining the aggregate unsustainable activity to remain below a predefined tolerance. Our analysis provides novel insights on the agents' equilibrium effort across the two activities and their influence on others due to intra- and cross-activity network effects. We also identify a measure of node centrality that resembles the Bonacich-Katz centrality and helps us determine pricing incentives that lead to welfare improvement while reducing the aggregate unsustainable activity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13662v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Parasnis, Saurabh Amin</dc:creator>
    </item>
    <item>
      <title>Rate Analysis of Coupled Distributed Stochastic Approximation for Misspecified Optimization</title>
      <link>https://arxiv.org/abs/2404.13669</link>
      <description>arXiv:2404.13669v1 Announce Type: new 
Abstract: We consider an $n$ agents distributed optimization problem with imperfect information characterized in a parametric sense, where the unknown parameter can be solved by a distinct distributed parameter learning problem. Though each agent only has access to its local parameter learning and computational problem, they mean to collaboratively minimize the average of their local cost functions. To address the special optimization problem, we propose a coupled distributed stochastic approximation algorithm, in which every agent updates the current beliefs of its unknown parameter and decision variable by stochastic approximation method; and then averages the beliefs and decision variables of its neighbors over network in consensus protocol. Our interest lies in the convergence analysis of this algorithm. We quantitatively characterize the factors that affect the algorithm performance, and prove that the mean-squared error of the decision variable is bounded by $\mathcal{O}(\frac{1}{nk})+\mathcal{O}\left(\frac{1}{\sqrt{n}(1-\rho_w)}\right)\frac{1}{k^{1.5}}+\mathcal{O}\big(\frac{1}{(1-\rho_w)^2} \big)\frac{1}{k^2}$, where $k$ is the iteration count and $(1-\rho_w)$ is the spectral gap of the network weighted adjacency matrix. It reveals that the network connectivity characterized by $(1-\rho_w)$ only influences the high order of convergence rate, while the domain rate still acts the same as the centralized algorithm. In addition, we analyze that the transient iteration needed for reaching its dominant rate $\mathcal{O}(\frac{1}{nk})$ is $\mathcal{O}(\frac{n}{(1-\rho_w)^2})$. Numerical experiments are carried out to demonstrate the theoretical results by taking different CPUs as agents, which is more applicable to real-world distributed scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13669v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaqun Yang, Jinlong Lei</dc:creator>
    </item>
    <item>
      <title>$\mathsf{QuITO}$ $\textsf{v.2}$: Trajectory Optimization with Uniform Error Guarantees under Path Constraints</title>
      <link>https://arxiv.org/abs/2404.13681</link>
      <description>arXiv:2404.13681v1 Announce Type: new 
Abstract: This article introduces a new transcription, change point localization, and mesh refinement scheme for direct optimization-based solutions and for uniform approximation of optimal control trajectories associated with a class of nonlinear constrained optimal control problems (OCPs). The base transcription algorithm for which we establish the refinement algorithm is a $\textit{direct multiple shooting technique}$ -- $\mathsf{QuITO}$ $\textsf{v.2}$ (Quasi-Interpolation based Trajectory Optimization). The mesh refinement technique consists of two steps -- localization of certain irregular regions in an optimal control trajectory via wavelets, followed by a targeted $h$-refinement approach around such regions of irregularity. Theoretical approximation guarantees on uniform grids are presented for optimal controls with certain regularity properties along with guarantees of localization of change points by wavelet transform. Numerical illustrations are provided for control profiles involving discontinuities to show the effectiveness of the localization and refinement strategy. We also announce and make freely available a new software package developed based on $\mathsf{QuITO}$ $\textsf{v.2}$ along with its functionalities to make the article complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13681v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Ganguly, Rihan Aaron D'Silva, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Variable-Stepsize Implicit Peer Triplets in ODE Constrained Optimal Control</title>
      <link>https://arxiv.org/abs/2404.13716</link>
      <description>arXiv:2404.13716v1 Announce Type: new 
Abstract: This paper is concerned with the theory, construction and application of implicit Peer two-step methods that are super-convergent for variable stepsizes, i.e., preserve their classical order achieved for uniform stepsizes when applied to ODE constrained optimal control problems in a first-discretize-then-optimize setting. We upgrade our former implicit two-step Peer triplets constructed in [Algorithms, 15:310, 2022] to get ready for dynamical systems with varying time scales without loosing efficiency. Peer triplets consist of a standard Peer method for interior time steps supplemented by matching methods for the starting and end steps. A decisive advantage of Peer methods is their absence of order reduction since they use stages of the same high stage order. The consistency analysis of variable-stepsize implicit Peer methods results in additional order conditions and severe new difficulties for uniform zero-stability, which intensifies the demands on the Peer triplet. Further, we discuss the construction of 4-stage methods with order pairs (4,3) and (3,3) for state and adjoint variables in detail and provide four Peer triplets of practical interest. We rigorously prove convergence of order $s-1$ for $s$-stage Peer methods applied on grids with bounded or smoothly changing stepsize ratios. Numerical tests show the expected order of convergence for the new variable-stepsize Peer triplets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13716v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens Lang, Bernhard A. Schmitt</dc:creator>
    </item>
    <item>
      <title>Data-Driven Performance Guarantees for Classical and Learned Optimizers</title>
      <link>https://arxiv.org/abs/2404.13831</link>
      <description>arXiv:2404.13831v1 Announce Type: new 
Abstract: We introduce a data-driven approach to analyze the performance of continuous optimization algorithms using generalization guarantees from statistical learning theory. We study classical and learned optimizers to solve families of parametric optimization problems. We build generalization guarantees for classical optimizers, using a sample convergence bound, and for learned optimizers, using the Probably Approximately Correct (PAC)-Bayes framework. To train learned optimizers, we use a gradient-based algorithm to directly minimize the PAC-Bayes upper bound. Numerical experiments in signal processing, control, and meta-learning showcase the ability of our framework to provide strong generalization guarantees for both classical and learned optimizers given a fixed budget of iterations. For classical optimizers, our bounds are much tighter than those that worst-case guarantees provide. For learned optimizers, our bounds outperform the empirical outcomes observed in their non-learned counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13831v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajiv Sambharya, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Characterization of Maximizers in A Non-Convex Geometric Optimization Problem With Application to Optical Wireless Power Transfer Systems</title>
      <link>https://arxiv.org/abs/2404.13832</link>
      <description>arXiv:2404.13832v1 Announce Type: new 
Abstract: This research studies a non-convex geometric optimization problem arising from the field of optical wireless power transfer. In the considered optimization problem, the cost function is a sum of negatively and fractionally powered distances from given points arbitrarily located in a plane to another point belonging to a different plane. Therefore, it is a strongly nonlinear and non-convex programming, hence posing a challenge on the characterization of its optimizer set, especially its set of global optimizers. To tackle this challenge, the bifurcation theory is employed to investigate the continuation and bifurcation structures of the Hessian matrix of the cost function. As such, two main results are derived. First, there is a critical distance between the two considered planes such that beyond which a unique global optimizer exists. Second, the exact number of maximizers is locally derived by the number of bifurcation branches determined via one-dimensional isotropic subgroups of a Lie group acting on $\mathbb{R}^2$, when the inter-plane distance is smaller than the above-mentioned critical distance. Consequently, numerical simulations and computations of bifurcation points are carried out for various configurations of the given points, whose results confirm the derived theoretical outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13832v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dinh Hoa Nguyen, Kaname Matsue</dc:creator>
    </item>
    <item>
      <title>Linear Convergence Results for Inertial Type Projection Algorithm for Quasi-Variational Inequalities</title>
      <link>https://arxiv.org/abs/2404.13912</link>
      <description>arXiv:2404.13912v1 Announce Type: new 
Abstract: Many recently proposed gradient projection algorithms with inertial extrapolation step for solving quasi-variational inequalities in Hilbert spaces are proven to be strongly convergent with no linear rate given when the cost operator is strongly monotone and Lipschitz continuous. In this paper, our aim is to design an inertial type gradient projection algorithm for quasi-variational inequalities and obtain its linear rate of convergence. Therefore, our results fill in the gap for linear convergence results for inertial type gradient projection algorithms for quasi variational inequalities in Hilbert spaces. We perform numerical implementations of our proposed algorithm and give numerical comparisons with other related inertial type gradient projection algorithms for quasi variational inequalities in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13912v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonghong Yao, Lateef O. Jolaoso, Yekini Shehu</dc:creator>
    </item>
    <item>
      <title>Angle-Aware Coverage with Camera Rotational Motion Control</title>
      <link>https://arxiv.org/abs/2404.13915</link>
      <description>arXiv:2404.13915v1 Announce Type: new 
Abstract: This paper presents a novel control strategy for drone networks to improve the quality of 3D structures reconstructed from aerial images by drones. Unlike the existing coverage control strategies for this purpose, our proposed approach simultaneously controls both the camera orientation and drone translational motion, enabling more comprehensive perspectives and enhancing the map's overall quality. Subsequently, we present a novel problem formulation, including a new performance function to evaluate the drone positions and camera orientations. We then design a QP-based controller with a control barrier-like function for a constraint on the decay rate of the objective function. The present problem formulation poses a new challenge, requiring significantly greater computational efforts than the case involving only translational motion control. We approach this issue technologically, namely by introducing JAX, utilizing just-in-time (JIT) compilation and Graphical Processing Unit (GPU) acceleration. We finally conduct extensive verifications through simulation in ROS (Robot Operating System) and show the real-time feasibility of the controller and the superiority of the present controller to the conventional method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13915v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyuan Lu, Muhammad Hanif, Takumi Shimizu, Takeshi Hatanaka</dc:creator>
    </item>
    <item>
      <title>Neural Control Systems</title>
      <link>https://arxiv.org/abs/2404.13967</link>
      <description>arXiv:2404.13967v1 Announce Type: new 
Abstract: We propose a function-learning methodology with a control-theoretical foundation. We parametrise the approximating function as the solution to a control system on a reproducing-kernel Hilbert space, and propose several methods to find the set of controls which bring the initial function as close as possible to the target function. At first, we derive the expression for the gradient of the cost function with respect to the controls that parametrise the difference equations. This allows us to find the optimal controls by means of gradient descent. In addition, we show how to compute derivatives of the approximating functions with respect to the controls and describe two optimisation methods relying on linear approximations of the approximating functions. We show how the assumptions we make lead to results which are coherent with Pontryagin's maximum principle. We test the optimisation methods on two toy examples and on two higher-dimensional real-world problems, showing that the approaches succeed in learning from real data and are versatile enough to tackle learning tasks of different nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13967v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Colusso, Damir Filipovi\'c</dc:creator>
    </item>
    <item>
      <title>Achieving binary topology optimization solutions via automatic projection parameter increase</title>
      <link>https://arxiv.org/abs/2404.14111</link>
      <description>arXiv:2404.14111v1 Announce Type: new 
Abstract: A method is created to automatically increase the threshold projection parameter in three-field density-based topology optimization to achieve a near binary design. The parameter increase each iteration is based on an exponential growth function, where the growth rate is dynamically changed during optimization by linking it to the change in objective function. This results in a method that does not need to be tuned for specific problems, or optimizers, and the same set of hyper-parameters can be used for a wide range of problems. The effectiveness of the method is demonstrated on several 2D benchmark problems, including linear buckling and geometrically nonlinear problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14111v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Peter Donald Dunning</dc:creator>
    </item>
    <item>
      <title>Hierarchical NMPC for Obstacle Avoidance on Skid-steer Loaders</title>
      <link>https://arxiv.org/abs/2404.14257</link>
      <description>arXiv:2404.14257v1 Announce Type: new 
Abstract: This paper introduces a novel NMPC formulation for real-time obstacle avoidance on heavy equipment by modeling both vehicle and obstacles as convex superellipsoids. The combination of this approach with the separating hyperplane theorem and Optimization Engine (OpEn) allows to achieve efficient obstacle avoidance in autonomous heavy equipment and robotics. We demonstrate the efficacy of the approach through simulated and experimental results, showcasing a skid-steer loader's capability to navigate in obstructed environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14257v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruairi Moran, Sheila Bagley, David Pasley, Seth Kasmann, Rob Martin, Scott Pfursich, Shane Trimble, James Dianics, Pantelis Sopasakis</dc:creator>
    </item>
    <item>
      <title>A General Continuous-Time Formulation of Stochastic ADMM and Its Variants</title>
      <link>https://arxiv.org/abs/2404.14358</link>
      <description>arXiv:2404.14358v1 Announce Type: new 
Abstract: Stochastic versions of the alternating direction method of multiplier (ADMM) and its variants play a key role in many modern large-scale machine learning problems. In this work, we introduce a unified algorithmic framework called generalized stochastic ADMM and investigate their continuous-time analysis. The generalized framework widely includes many stochastic ADMM variants such as standard, linearized and gradient-based ADMM. Our continuous-time analysis provides us with new insights into stochastic ADMM and variants, and we rigorously prove that under some proper scaling, the trajectory of stochastic ADMM weakly converges to the solution of a stochastic differential equation with small noise. Our analysis also provides a theoretical explanation of why the relaxation parameter should be chosen between 0 and 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14358v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Junchi Li</dc:creator>
    </item>
    <item>
      <title>A New Optimization Model for Multiple-Control Toffoli Quantum Circuit Design</title>
      <link>https://arxiv.org/abs/2404.14384</link>
      <description>arXiv:2404.14384v1 Announce Type: new 
Abstract: As quantum technology is advancing, the efficient design of quantum circuits has become an important area of research. This paper provides an introduction to the MCT quantum circuit design problem for reversible Boolean functions without assuming a prior background in quantum computing. While this is a well-studied problem, optimization models that minimize the true objective have only been explored recently. This paper introduces a new optimization model and symmetry-breaking constraints that improve solving time by up to two orders of magnitude compared to earlier work when a Constraint Programming solver is used. Experiments with up to seven qubits and using up to 15 quantum gates result in several new best-known circuits for well-known benchmarks. Finally, an extensive comparison with other approaches shows that optimization models may require more time but can provide superior circuits with optimality guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14384v1</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihye Jung, Kevin Dalmeijer, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Denoising Sphere-Valued Data by Relaxed Total Variation Regularization</title>
      <link>https://arxiv.org/abs/2404.13181</link>
      <description>arXiv:2404.13181v1 Announce Type: cross 
Abstract: Circle- and sphere-valued data play a significant role in inverse problems like magnetic resonance phase imaging and radar interferometry, in the analysis of directional information, and in color restoration tasks. In this paper, we aim to restore $(d-1)$-sphere-valued signals exploiting the classical anisotropic total variation on the surrounding $d$-dimensional Euclidean space. For this, we propose a novel variational formulation, whose data fidelity is based on inner products instead of the usually employed squared norms. Convexifying the resulting non-convex problem and using ADMM, we derive an efficient and fast numerical denoiser. In the special case of binary (0-sphere-valued) signals, the relaxation is provable tight, i.e. the relaxed solution can be used to construct a solution of the original non-convex problem. Moreover, the tightness can be numerically observed for barcode and QR code denoising as well as in higher dimensional experiments like the color restoration using hue and chromaticity and the recovery of SO(3)-valued signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13181v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Beinert, Jonas Bresch</dc:creator>
    </item>
    <item>
      <title>Online Planning of Power Flows for Power Systems Against Bushfires Using Spatial Context</title>
      <link>https://arxiv.org/abs/2404.13391</link>
      <description>arXiv:2404.13391v1 Announce Type: cross 
Abstract: The 2019-20 Australia bushfire incurred numerous economic losses and significantly affected the operations of power systems. A power station or transmission line can be significantly affected due to bushfires, leading to an increase in operational costs. We study a fundamental but challenging problem of planning the optimal power flow (OPF) for power systems subject to bushfires. Considering the stochastic nature of bushfire spread, we develop a model to capture such dynamics based on Moore's neighborhood model. Under a periodic inspection scheme that reveals the in-situ bushfire status, we propose an online optimization modeling framework that sequentially plans the power flows in the electricity network. Our framework assumes that the spread of bushfires is non-stationary over time, and the spread and containment probabilities are unknown. To meet these challenges, we develop a contextual online learning algorithm that treats the in-situ geographical information of the bushfire as a 'spatial context'. The online learning algorithm learns the unknown probabilities sequentially based on the observed data and then makes the OPF decision accordingly. The sequential OPF decisions aim to minimize the regret function, which is defined as the cumulative loss against the clairvoyant strategy that knows the true model parameters. We provide a theoretical guarantee of our algorithm by deriving a bound on the regret function, which outperforms the regret bound achieved by other benchmark algorithms. Our model assumptions are verified by the real bushfire data from NSW, Australia, and we apply our model to two power systems to illustrate its applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13391v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianyu Xu, Qiuzhuang Sun, Yang Yang, Huadong Mo, Daoyi Dong</dc:creator>
    </item>
    <item>
      <title>Beamforming Design for Integrated Sensing and Communications Using Uplink-Downlink Duality</title>
      <link>https://arxiv.org/abs/2404.13392</link>
      <description>arXiv:2404.13392v1 Announce Type: cross 
Abstract: This paper presents a novel optimization framework for beamforming design in integrated sensing and communication systems where a base station seeks to minimize the Bayesian Cram\'er-Rao bound of a sensing problem while satisfying quality of service constraints for the communication users. Prior approaches formulate the design problem as a semidefinite program for which acquiring a beamforming solution is computationally expensive. In this work, we show that the computational burden can be considerably alleviated. To achieve this, we transform the design problem to a tractable form that not only provides a new understanding of Cram\'er-Rao bound optimization, but also allows for an uplink-downlink duality relation to be developed. Such a duality result gives rise to an efficient algorithm that enables the beamforming design problem to be solved at a much lower complexity as compared to the-state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13392v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kareem M. Attiah, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Towards General Conceptual Model Editing via Adversarial Representation Engineering</title>
      <link>https://arxiv.org/abs/2404.13752</link>
      <description>arXiv:2404.13752v1 Announce Type: cross 
Abstract: Recent research has introduced Representation Engineering (RepE) as a promising approach for understanding complex inner workings of large-scale models like Large Language Models (LLMs). However, finding practical and efficient methods to apply these representations for general and flexible model editing remains an open problem. Inspired by the Generative Adversarial Network (GAN) framework, we introduce a novel approach called Adversarial Representation Engineering (ARE). This method leverages RepE by using a representation sensor to guide the editing of LLMs, offering a unified and interpretable framework for conceptual model editing without degrading baseline performance. Our experiments on multiple conceptual editing confirm ARE's effectiveness. Code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13752v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihao Zhang, Zeming Wei, Jun Sun, Meng Sun</dc:creator>
    </item>
    <item>
      <title>Carleman estimates for higher order partial differential operators and its applications</title>
      <link>https://arxiv.org/abs/2404.14008</link>
      <description>arXiv:2404.14008v1 Announce Type: cross 
Abstract: In this paper, we obtain a Carleman estimate for the higher order partial differential operator. In the process of establishing this estimate, we developed a new method, which is called the back-propagation method (the BPM, for short). This method can also be used to build up Carleman estimates for some other partial differential operators, and might provide assistance with corresponding numerical analyses. As an application of the above-mentioned Carleman estimate, we proved the conditional stability of a Cauchy problem for a time fractional diffusion equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14008v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Fu, Yuan Gao</dc:creator>
    </item>
    <item>
      <title>Distributed Nonconvex Optimization: Gradient-free Iterations and $\epsilon$-Globally Optimal Solution</title>
      <link>https://arxiv.org/abs/2008.00252</link>
      <description>arXiv:2008.00252v5 Announce Type: replace 
Abstract: Distributed optimization utilizes local computation and communication to realize a global aim of optimizing the sum of local objective functions. This article addresses a class of constrained distributed nonconvex optimization problems involving univariate objectives, aiming to achieve global optimization without requiring local evaluations of gradients at every iteration. We propose a novel algorithm named CPCA, exploiting the notion of combining Chebyshev polynomial approximation, average consensus, and polynomial optimization. The proposed algorithm is i) able to obtain $\epsilon$-globally optimal solutions for any arbitrarily small given accuracy $\epsilon$, ii) efficient in both zeroth-order queries (i.e., evaluations of function values) and inter-agent communication, and iii) distributed terminable when the specified precision requirement is met. The key insight is to use polynomial approximations to substitute for general local objectives, distribute these approximations via average consensus, and solve an easier approximate version of the original problem. Due to the nice analytic properties of polynomials, this approximation not only facilitates efficient global optimization, but also allows the design of gradient-free iterations to reduce cumulative costs of queries and achieve geometric convergence for solving nonconvex problems. We provide a comprehensive analysis of the accuracy and complexities of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.00252v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhiyu He, Jianping He, Cailian Chen, Xinping Guan</dc:creator>
    </item>
    <item>
      <title>Codifferentials and Quasidifferentials of the Expectation of Nonsmooth Random Integrands and Two-Stage Stochastic Programming</title>
      <link>https://arxiv.org/abs/2102.06677</link>
      <description>arXiv:2102.06677v4 Announce Type: replace 
Abstract: This work is devoted to an analysis of exact penalty functions and optimality conditions for nonsmooth two-stage stochastic programming problems. To this end, we first study the co-/quasi-differentiability of the expectation of nonsmooth random integrands and obtain explicit formulae for its co- and quasidifferential under some natural assumptions on the integrand. Then we analyse exact penalty functions for a variational reformulation of two-stage stochastic programming problems and obtain sufficient conditions for the global exactness of these functions with two different penalty terms. In the end of the paper, we combine our results on the co-/quasi-differentiability of the expectation of nonsmooth random integrands and exact penalty functions to derive optimality conditions for nonsmooth two-stage stochastic programming problems in terms of codifferentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.06677v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-00832-0_5</arxiv:DOI>
      <arxiv:journal_reference>High-Dimensional Optimization and Probability. Nikeghbali, A., Pardalos, P.M., Raigorodskii, A.M., Rassias, M.T. (eds). Springer, Cham. pp. 185-218 (2022)</arxiv:journal_reference>
      <dc:creator>M. V. Dolgopolik</dc:creator>
    </item>
    <item>
      <title>Optimal Gradient Tracking for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2110.05282</link>
      <description>arXiv:2110.05282v4 Announce Type: replace 
Abstract: In this paper, we focus on solving the decentralized optimization problem of minimizing the sum of $n$ objective functions over a multi-agent network. The agents are embedded in an undirected graph where they can only send/receive information directly to/from their immediate neighbors. Assuming smooth and strongly convex objective functions, we propose an Optimal Gradient Tracking (OGT) method that achieves the optimal gradient computation complexity $O\left(\sqrt{\kappa}\log\frac{1}{\epsilon}\right)$ and the optimal communication complexity $O\left(\sqrt{\frac{\kappa}{\theta}}\log\frac{1}{\epsilon}\right)$ simultaneously, where $\kappa$ and $\frac{1}{\theta}$ denote the condition numbers related to the objective functions and the communication graph, respectively. To our knowledge, OGT is the first single-loop decentralized gradient-type method that is optimal in both gradient computation and communication complexities. The development of OGT involves two building blocks which are also of independent interest. The first one is another new decentralized gradient tracking method termed "Snapshot" Gradient Tracking (SS-GT), which achieves the gradient computation and communication complexities of $O\left(\sqrt{\kappa}\log\frac{1}{\epsilon}\right)$ and $O\left(\frac{\sqrt{\kappa}}{\theta}\log\frac{1}{\epsilon}\right)$, respectively. SS-GT can be potentially extended to more general settings compared to OGT. The second one is a technique termed Loopless Chebyshev Acceleration (LCA) which can be implemented "looplessly" but achieve similar effect with adding multiple inner loops of Chebyshev acceleration in the algorithms. In addition to SS-GT, this LCA technique can accelerate many other gradient tracking based methods with respect to the graph condition number $\frac{1}{\theta}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.05282v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoqing Song, Lei Shi, Shi Pu, Ming Yan</dc:creator>
    </item>
    <item>
      <title>Exactness and Effective Degree Bound of Lasserre's Relaxation for Polynomial Optimization over Finite Variety</title>
      <link>https://arxiv.org/abs/2110.13766</link>
      <description>arXiv:2110.13766v5 Announce Type: replace 
Abstract: We consider the effective degree bound problem for Lasserre's hierarchy of sum of squares (SOS) relaxations for polynomial optimization with $n$ variables. Under the assumption that the first $n$ equality constraint defining polynomials $g_1,\ldots,g_n$ have no nontrivial common complex zero locus at infinity, and a nonsingularity condition, we establish an effective degree bound for the exactness of Lasserre's hierarchy. Our assumption holds on a Zariski open set in the space of polynomials of fixed degrees, which is much weaker than the grid condition under which the same effective degree bound was previously known. As a direct application we obtain the first explicit degree bound for gradient type SOS relaxation under a generic condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.13766v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Hua, Zheng Qu</dc:creator>
    </item>
    <item>
      <title>Coordinated Vehicle Platooning with Fixed Routes: Efficient Time Discretization, Strengthened Formulation and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2205.11043</link>
      <description>arXiv:2205.11043v2 Announce Type: replace 
Abstract: We consider the coordinated vehicle platooning problem over a road network with time constraints while the routes of vehicles are given. The problem is to coordinate the departure time of each vehicle to enable platoon formation hence maximizing the total fuel saving. All problem instances can be divided into two categories: the tree instances and the cycle-containing instances based on the graph formed by the routes of all vehicles in the system using a preprocessing algorithm. For tree instances, relative time windows can be defined for all vehicles to which an efficient time discretization can be applied. This property leads to a tight mixed-integer linear program reformulation as compared to the continuous-time formulation involving big-M coefficients proposed in our previous work. This formulation approach has been extended to cycle-containing instances, and the validness of the extension is characterized by the pattern of lattice groups. As an independent interest, two approximation algorithms have been derived with provable competitive ratios under certain regularity conditions for tree instances, which is for the first time on this discrete optimization problem. It is demonstrated by systematic numerical experiments that the reformulation outperforms the continuous-time formulation, and the effectiveness of the approximation algorithms is tested in additional numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.11043v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fengqiao Luo</dc:creator>
    </item>
    <item>
      <title>Convergence Analyses of Davis-Yin Splitting via Scaled Relative Graphs</title>
      <link>https://arxiv.org/abs/2207.04015</link>
      <description>arXiv:2207.04015v3 Announce Type: replace 
Abstract: Davis-Yin splitting (DYS) has found a wide range of applications in optimization, but its linear rates of convergence have not been studied extensively. The scaled relative graph (SRG) simplifies the convergence analysis of operator splitting methods by mapping the action of the operator onto the complex plane, but the prior SRG theory did not fully apply to the DYS operator. In this work, we formalize an SRG theory for the DYS operator and use it to obtain tighter contraction factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.04015v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongmin Lee, Soheun Yi, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Multilevel Geometric Optimization for Regularised Constrained Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2207.04934</link>
      <description>arXiv:2207.04934v3 Announce Type: replace 
Abstract: We present a geometric multilevel optimization approach that smoothly incorporates box constraints. Given a box constrained optimization problem, we consider a hierarchy of models with varying discretization levels. Finer models are accurate but expensive to compute, while coarser models are less accurate but cheaper to compute. When working at the fine level, multilevel optimisation computes the search direction based on a coarser model which speeds up updates at the fine level. Moreover, exploiting geometry induced by the hierarchy the feasibility of the updates is preserved. In particular, our approach extends classical components of multigrid methods like restriction and prolongation to the Riemannian structure of our constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.04934v3</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>math.DG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Pure and Applied Functional Analysis, Vol. 8 (2023), No. 3, pp. 855-880</arxiv:journal_reference>
      <dc:creator>Sebastian M\"uller, Stefania Petra, Matthias Zisler</dc:creator>
    </item>
    <item>
      <title>A fast continuous time approach for non-smooth convex optimization with time scaling and Tikhonov regularization</title>
      <link>https://arxiv.org/abs/2207.12023</link>
      <description>arXiv:2207.12023v2 Announce Type: replace 
Abstract: In a Hilbert setting we aim to study a second order in time differential equation, combining viscous and Hessian-driven damping, containing a time scaling parameter function and a Tikhonov regularization term. The dynamical system is related to the problem of minimization of a nonsmooth convex function. In the formulation of the problem as well as in our analysis we use the Moreau envelope of the objective function and its gradient and heavily rely on their properties. We show that there is a setting where the newly introduced system preserves and even improves the well-known fast convergence properties of the function and Moreau envelope along the trajectories and also of the gradient of Moreau envelope due to the presence of time scaling. Moreover, in a different setting we prove strong convergence of the trajectories to the element of the minimal norm from the set of all minimizers of the objective. The manuscript concludes with various numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.12023v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Ern\"o Csetnek, Mikhail A. Karapetyants</dc:creator>
    </item>
    <item>
      <title>Sharpness and non-sharpness of occupation measure bounds for integral variational problems</title>
      <link>https://arxiv.org/abs/2207.13570</link>
      <description>arXiv:2207.13570v3 Announce Type: replace 
Abstract: We analyze two recently proposed methods to establish a priori lower bounds on the minimum of general integral variational problems. The methods, which involve either `occupation measures' or a `pointwise dual relaxation' procedure, are shown to produce the same lower bound under a coercivity hypothesis ensuring their strong duality. We then show by a minimax argument that the methods actually evaluate the minimum for classes of one-dimensional, scalar-valued, or convex multidimensional problems. For generic problems, however, these methods should fail to capture the minimum and produce non-sharp lower bounds. We demonstrate this using two examples, the first of which is one-dimensional and scalar-valued with a non-convex constraint, and the second of which is multidimensional and non-convex in a different way. The latter example emphasizes the existence in multiple dimensions of nonlinear constraints on gradient fields that are ignored by occupation measures, but are built into the finer theory of gradient Young measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.13570v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Fantuzzi, Ian Tobasco</dc:creator>
    </item>
    <item>
      <title>Scalable Computation of Energy Functions for Nonlinear Balanced Truncation</title>
      <link>https://arxiv.org/abs/2209.07645</link>
      <description>arXiv:2209.07645v3 Announce Type: replace 
Abstract: Nonlinear balanced truncation is a model order reduction technique that reduces the dimension of nonlinear systems in a manner that accounts for either open- or closed-loop observability and controllability aspects of the system. A computational challenges that has so far prevented its deployment on large-scale systems is that the energy functions required for characterization of controllability and observability are solutions of various high-dimensional Hamilton-Jacobi-(Bellman) equations, which are computationally intractable in high dimensions. This work proposes a unifying and scalable approach to this challenge by considering a Taylor-series-based approximation to solve a class of parametrized Hamilton-Jacobi-Bellman equations that are at the core of nonlinear balancing. The value of a formulation parameter provides either open-loop balancing or a variety of closed-loop balancing options. To solve for the coefficients of Taylor-series approximations to the energy functions, the presented method derives a linear tensor system and heavily utilizes it to numerically solve structured linear systems with billions of unknowns. The strength and scalability of the algorithm is demonstrated on two semi-discretized partial differential equations, namely the Burgers and the Kuramoto-Sivashinsky equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07645v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris Kramer, Serkan Gugercin, Jeff Borggaard, Linus Balicki</dc:creator>
    </item>
    <item>
      <title>A Theory of the NEPv Approach for Optimization On the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2305.00091</link>
      <description>arXiv:2305.00091v2 Announce Type: replace 
Abstract: The NEPv approach has been increasingly used lately for optimization on the Stiefel manifold arising from machine learning. General speaking, the approach first turns the first order optimality condition, also known as the KKT condition, into a nonlinear eigenvalue problem with eigenvector dependency (NEPv) or a nonlinear polar decomposition with orthogonal factor dependency (NPDo) and then solve the nonlinear problem via some variations of the self-consistent-field (SCF) iteration. The difficulty, however, lies in designing a proper SCF iteration so that a maximizer is found at the end. Currently, each use of the approach is very much individualized, especially in its convergence analysis to show that the approach does work or otherwise. In this paper, a unifying framework is established. The framework is built upon some basic assumptions. If the basic assumptions are satisfied, globally convergence is guaranteed to a stationary point and during the SCF iterative process that leads to the stationary point, the objective function increases monotonically. Also a notion of atomic functions is proposed, which include commonly used matrix traces of linear and quadratic forms as special ones. It is shown that the basic assumptions are satisfied by atomic functions and by convex compositions of atomic functions. Together they provide a large collection of objectives for which the NEPv/NPDo approach is guaranteed to work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00091v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ren-Cang Li</dc:creator>
    </item>
    <item>
      <title>Efficient vectors in priority setting methodology</title>
      <link>https://arxiv.org/abs/2305.04886</link>
      <description>arXiv:2305.04886v2 Announce Type: replace 
Abstract: The Analytic Hierarchy Process (AHP) is a much discussed method in ranking business alternatives based on empirical and judgemental information. We focus here upon the key component of deducing efficient vectors for a reciprocal matrix of pair-wise comparisons. It is not yet known how to produce all efficient vectors. It has been shown that the entry-wise geometric mean of all columns is efficient for any reciprocal matrix. Here, by combining some new basic observations with some known theory, we 1) give a method for inductively generating large collections of efficient vectors, and 2) show that the entry-wise geometric mean of any collection of distinct columns of a reciprocal matrix is efficient. We study numerically, using different measures, the performance of these geometric means in approximating the reciprocal matrix by a consistent matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04886v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susana Furtado, Charles Johnson</dc:creator>
    </item>
    <item>
      <title>Uniqueness of optimal plans for multi-marginal mass transport problems via a reduction argument</title>
      <link>https://arxiv.org/abs/2305.08650</link>
      <description>arXiv:2305.08650v3 Announce Type: replace 
Abstract: For a family of probability spaces $\{(X_k,\mathcal{B}_{X_k},\mu_k)\}_{k=1}^N$ and a cost function $c: X_1\times\cdots\times X_N\to \mathbb{R}$ we consider the Monge-Kantorovich problem \begin{align*}\tag{MK}\label{MONKANT} \inf_{\lambda\in\Pi(\mu_1,\ldots,\mu_N)}\int_{\prod_{k=1}^N X_k}c\,d\lambda. \end{align*} Then for each ordered subset $\mathcal{P}=\{i_1,\ldots,i_p\}\subsetneq\{1,...,N\}$ with $p\geq 2$ we create a new cost function $c_\mathcal{P}$ corresponding to the original cost function $c$ defined on $\prod_{k=1}^p X_{i_k}$. This new cost function $c_\mathcal{P}$ enjoys many of the features of the original cost $c$ while it has the property that any optimal plan $\lambda$ of \eqref{MONKANT} restricted to $\prod_{k=1}^p X_{i_k}$ is also an optimal plan to the problem \begin{align*}\tag{RMK}\label{REDMONKANT} \inf_{\tau\in\Pi(\mu_{i_1},\ldots\mu_{i_p})}\int_{\prod_{k=1}^p X_{i_k}}c_{\mathcal{P}}\,d\tau. \end{align*} Our main contribution in this paper is to show that, for appropriate choices of index set $\mathcal{P}$, one can recover the optimal plans of \eqref{MONKANT} from \eqref{REDMONKANT}. In particular, we study situations in which the problem \eqref{MONKANT} admits a unique solution depending on the uniqueness of the solution for the lower marginal problems of the form \eqref{REDMONKANT}. This allows us to prove many uniqueness results for multi-marginal problems when the unique optimal plan is not necessarily induced by a map. To this end, we extensively benefit from disintegration theorems and the $c$-extremality notions. Moreover, by employing this argument, besides recovering many standard results on the subject including the pioneering work of Gangbo-\'Swi\c ech, several new applications will be demonstrated to evince the applicability of this argument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08650v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Ali Ahmadpoor, Abbas Moameni</dc:creator>
    </item>
    <item>
      <title>Det-CGD: Compressed Gradient Descent with Matrix Stepsizes for Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2305.12568</link>
      <description>arXiv:2305.12568v2 Announce Type: replace 
Abstract: This paper introduces a new method for minimizing matrix-smooth non-convex objectives through the use of novel Compressed Gradient Descent (CGD) algorithms enhanced with a matrix-valued stepsize. The proposed algorithms are theoretically analyzed first in the single-node and subsequently in the distributed settings. Our theoretical results reveal that the matrix stepsize in CGD can capture the objective's structure and lead to faster convergence compared to a scalar stepsize. As a byproduct of our general results, we emphasize the importance of selecting the compression mechanism and the matrix stepsize in a layer-wise manner, taking advantage of model structure. Moreover, we provide theoretical guarantees for free compression, by designing specific layer-wise compressors for the non-convex matrix smooth objectives. Our findings are supported with empirical evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12568v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Avetik Karagulyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Two-timescale Extragradient for Finding Local Minimax Points</title>
      <link>https://arxiv.org/abs/2305.16242</link>
      <description>arXiv:2305.16242v2 Announce Type: replace 
Abstract: Minimax problems are notoriously challenging to optimize. However, we present that the two-timescale extragradient method can be a viable solution. By utilizing dynamical systems theory, we show that it converges to points that satisfy the second-order necessary condition of local minimax points, under mild conditions that the two-timescale gradient descent ascent fails to work. This work provably improves upon all previous results on finding local minimax points, by eliminating a crucial assumption that the Hessian with respect to the maximization variable is nondegenerate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16242v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiseok Chae, Kyuwon Kim, Donghwan Kim</dc:creator>
    </item>
    <item>
      <title>Route planning of mobile sensing fleets for repeatable visits</title>
      <link>https://arxiv.org/abs/2307.02397</link>
      <description>arXiv:2307.02397v2 Announce Type: replace 
Abstract: Vehicle-based mobile sensing is an emerging data collection paradigm that leverages vehicle mobilities to scan a city at low costs. Certain urban sensing scenarios require dedicated vehicles for highly targeted monitoring, such as volatile organic compounds (VOCs, a type of air pollutant) sensing, road surface monitoring, and accident site investigation. A hallmark of these scenarios is that the points of interest (POIs) need to be repeatedly visited by a set of agents, whose routes should provide sufficient sensing coverage with coordinated overlap at certain important POIs. For these applications, this paper presents the open team orienteering problem with repeatable visits (OTOP-RV). The adaptive large neighborhood search (ALNS) algorithm is tailored to solve the OTOP-RV considering specific features of the problem. Test results on randomly generated datasets show that: (1) For small cases, the ALNS matches Gurobi in terms of optimality but with shorter computational times; (2) For large cases, the ALNS significantly outperforms the greedy algorithm (by 9.7% to 25.4%), and a heuristic based on sequential orienteering problems (by 6%). Finally, a real-world case study of VOCs sensing is presented, which highlights the unique applicability of the OTOP-RV to such specific sensing tasks, as well as the effectiveness of the proposed algorithms in optimizing the sensing utilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02397v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Ji, Ke Han, Qian Ge</dc:creator>
    </item>
    <item>
      <title>Tikhonov regularized second-order plus first-order primal-dual dynamical systems with asymptotically vanishing damping for linear equality constrained convex optimization problems</title>
      <link>https://arxiv.org/abs/2307.03612</link>
      <description>arXiv:2307.03612v2 Announce Type: replace 
Abstract: In this paper, in the setting of Hilbert spaces, we consider a Tikhonov regularized second-order plus first-order primal-dual dynamical system with asymptotically vanishing damping for a linear equality constrained convex optimization problem. The convergence properties of the proposed dynamical system depend heavily upon the choice of the Tikhonov regularization parameter. When the Tikhonov regularization parameter decreases rapidly to zero, we establish the fast convergence rates of the primal-dual gap, the objective function error, the feasibility measure, and the gradient norm of the objective function along the trajectory generated by the system. When the Tikhonov regularization parameter tends slowly to zero, we prove that the primal trajectory of the Tikhonov regularized dynamical system converges strongly to the minimal norm solution of the linear equality constrained convex optimization problem. Numerical experiments are performed to illustrate the efficiency of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03612v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Ting Zhu, Rong Hu, Ya Ping Fang</dc:creator>
    </item>
    <item>
      <title>Relaxation and asymptotic expansion of controlled stiff differential equations</title>
      <link>https://arxiv.org/abs/2309.08280</link>
      <description>arXiv:2309.08280v2 Announce Type: replace 
Abstract: The control of relaxation-type systems of ordinary differential equations is investigated using the Hamilton-Jacobi-Bellman equation. First, we recast the model as a singularly perturbed dynamics which we embed in a family of controlled systems. Then we study this dynamics together with the value function of the associated optimal control problem. We provide an asymptotic expansion in the relaxation parameter of the value function. We also show that its solution converges toward the solution of a Hamilton-Jacobi-Bellman equation for a reduced control problem. Such systems are motivated by semi-discretisation of kinetic and hyperbolic partial differential equations. Several examples are presented including Jin-Xin relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08280v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Herty, Hicham Kouhkouh</dc:creator>
    </item>
    <item>
      <title>Process flowsheet optimization with surrogate and implicit formulations of a Gibbs reactor</title>
      <link>https://arxiv.org/abs/2310.09307</link>
      <description>arXiv:2310.09307v2 Announce Type: replace 
Abstract: Alternative formulations for the optimization of chemical process flowsheets are presented that leverage surrogate models and implicit functions to replace and remove, respectively, the algebraic equations that describe a difficult-to-converge Gibbs reactor unit operation. Convergence reliability, solve time, and solution quality of an optimization problem are compared among full-space, ALAMO surrogate, neural network surrogate, and implicit function formulations. Both surrogate and implicit formulations lead to better convergence reliability, with low sensitivity to process parameters. The surrogate formulations are faster at the cost of minor solution error, while the implicit formulation provides exact solutions with similar solve time. In a parameter sweep on an autothermal reformer flowsheet optimization problem, the full space formulation solves 33 out of 64 instances, while the implicit function formulation solves 52 out of 64 instances, the ALAMO polynomial formulation solves 64 out of 64 instances, and the neural network formulation solves 48 out of 64 instances. This work demonstrates the trade-off between accuracy and solve time that exists in current methods for improving convergence reliability of chemical process flowsheet optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09307v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio I. Bugosen, Carl D. Laird, Robert B. Parker</dc:creator>
    </item>
    <item>
      <title>Log-Sum Regularized Kaczmarz Algorithms for High-Order Tensor Recovery</title>
      <link>https://arxiv.org/abs/2311.00783</link>
      <description>arXiv:2311.00783v2 Announce Type: replace 
Abstract: Sparse and low rank tensor recovery has emerged as a significant area of research with applications in many fields such as computer vision. However, minimizing the $\ell_0$-norm of a vector or the rank of a matrix is NP-hard. Instead, their convex relaxed versions are typically adopted in practice due to the computational efficiency, e.g., log-sum penalty. In this work, we propose novel log-sum regularized Kaczmarz algorithms for recovering high-order tensors with either sparse or low-rank structures. We present block variants along with convergence analysis of the proposed algorithms. Numerical experiments on synthetic and real-world data sets demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00783v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katherine Henneberger, Jing Qin</dc:creator>
    </item>
    <item>
      <title>Eigenstructure perturbations for a class of Hamiltonian matrices and solutions of related Riccati inequalities</title>
      <link>https://arxiv.org/abs/2311.14202</link>
      <description>arXiv:2311.14202v2 Announce Type: replace 
Abstract: The characterization of the solution set for a class of algebraic Riccati inequalities is studied. This class arises in the passivity analysis of linear time invariant control systems. Eigenvalue perturbation theory for the Hamiltonian matrix associated with the Riccati inequality is used to analyze the extremal points of the solution set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14202v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volker Mehrmann, Hongguo Xu</dc:creator>
    </item>
    <item>
      <title>Multichannel Frequency Estimation with Constant Amplitude via Convex Structured Low-Rank Approximation</title>
      <link>https://arxiv.org/abs/2401.01161</link>
      <description>arXiv:2401.01161v2 Announce Type: replace 
Abstract: We study the problem of estimating the frequencies of several complex sinusoids with constant amplitude (CA) (also called constant modulus) from multichannel signals of their superposition. To exploit the CA property for frequency estimation in the framework of atomic norm minimization (ANM), we introduce multiple positive-semidefinite block matrices composed of Hankel and Toeplitz submatrices and formulate the ANM problem as a convex structured low-rank approximation (SLRA) problem. The proposed SLRA is a semidefinite programming and has substantial differences from existing such formulations without using the CA property. The proposed approach is termed as SLRA-based ANM for CA frequency estimation (SACA). We provide theoretical guarantees and extensive simulations that validate the advantages of SACA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01161v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xunmeng Wu, Zai Yang, Zongben Xu</dc:creator>
    </item>
    <item>
      <title>Computing the Edge Expansion of a Graph using SDP</title>
      <link>https://arxiv.org/abs/2403.04657</link>
      <description>arXiv:2403.04657v3 Announce Type: replace 
Abstract: Computing the edge expansion of a graph is a famously hard combinatorial problem for which there have been many approximation studies. We present two versions of an exact algorithm using semidefinite programming (SDP) to compute this constant for any graph. The SDP relaxation is used to first reduce the search space considerably. One version applies then an SDP-based branch-and-bound algorithm, along with heuristic search. The other version transforms the problem into an instance of a max-cut problem and solves this using a state-of-the-art solver. Numerical results demonstrate that we clearly outperform mixed-integer quadratic solvers as well as another SDP-based algorithm from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04657v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 8th International Symposium on Combinatorial Optimization, ISCO 2024. LNCS volume</arxiv:journal_reference>
      <dc:creator>Akshay Gupte, Melanie Siebenhofer, Angelika Wiegele</dc:creator>
    </item>
    <item>
      <title>Pole Placement and Feedback Stabilization for Discrete Linear Ensemble Systems</title>
      <link>https://arxiv.org/abs/2403.19017</link>
      <description>arXiv:2403.19017v2 Announce Type: replace 
Abstract: We consider discrete ensembles of linear, scalar control systems with single-inputs. Assuming that all the individual systems are unstable, we investigate whether there exist linear feedback control laws that can asymptotically stabilize the ensemble system. We provide necessary/sufficient conditions for feasibility of pole placement in the left half plane and for feedback stabilizability of the ensemble systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19017v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xudong Chen</dc:creator>
    </item>
    <item>
      <title>Decay of Operator Semigroups, Infinite-time Admissibility, and Related Resolvent Estimates</title>
      <link>https://arxiv.org/abs/2212.00315</link>
      <description>arXiv:2212.00315v2 Announce Type: replace-cross 
Abstract: We study decay rates for bounded $C_0$-semigroups from the perspective of $L^p$-infinite-time admissibility and related resolvent estimates. In the Hilbert space setting, polynomial decay of semigroup orbits is characterized by the resolvent behavior in the open right half-plane. A similar characterization based on $L^p$-infinite-time admissibility is provided for multiplication semigroups on $L^q$-spaces with $1 \leq q \leq p &lt; \infty$. For polynomially stable $C_0$-semigroups on Hilbert spaces, we also give a sufficient condition for $L^2$-infinite-time admissibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00315v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masashi Wakaiki</dc:creator>
    </item>
    <item>
      <title>Linear Optimal Partial Transport Embedding</title>
      <link>https://arxiv.org/abs/2302.03232</link>
      <description>arXiv:2302.03232v4 Announce Type: replace-cross 
Abstract: Optimal transport (OT) has gained popularity due to its various applications in fields such as machine learning, statistics, and signal processing. However, the balanced mass requirement limits its performance in practical problems. To address these limitations, variants of the OT problem, including unbalanced OT, Optimal partial transport (OPT), and Hellinger Kantorovich (HK), have been proposed. In this paper, we propose the Linear optimal partial transport (LOPT) embedding, which extends the (local) linearization technique on OT and HK to the OPT problem. The proposed embedding allows for faster computation of OPT distance between pairs of positive measures. Besides our theoretical contributions, we demonstrate the LOPT embedding technique in point-cloud interpolation and PCA analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03232v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yikun Bai, Ivan Medri, Rocio Diaz Martin, Rana Muhammad Shahroz Khan, Soheil Kolouri</dc:creator>
    </item>
    <item>
      <title>A Graph-Prediction-Based Approach for Debiasing Underreported Data</title>
      <link>https://arxiv.org/abs/2307.07898</link>
      <description>arXiv:2307.07898v3 Announce Type: replace-cross 
Abstract: We present a novel Graph-based debiasing Algorithm for Underreported Data (GRAUD) aiming at an efficient joint estimation of event counts and discovery probabilities across spatial or graphical structures. This innovative method provides a solution to problems seen in fields such as policing data and COVID-$19$ data analysis. Our approach avoids the need for strong priors typically associated with Bayesian frameworks. By leveraging the graph structures on unknown variables $n$ and $p$, our method debiases the under-report data and estimates the discovery probability at the same time. We validate the effectiveness of our method through simulation experiments and illustrate its practicality in one real-world application: police 911 calls-to-service data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07898v3</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanyang Jiang, Yao Xie</dc:creator>
    </item>
    <item>
      <title>On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates</title>
      <link>https://arxiv.org/abs/2311.13584</link>
      <description>arXiv:2311.13584v3 Announce Type: replace-cross 
Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.
  Beyond the motivating example and in order to allow for the use of a diverse range of stochastic optimizers, we present our results using an $L^2$-accurate score estimation assumption, which crucially is formed under an expectation with respect to the stochastic optimizer and our novel auxiliary process that uses only known information. This approach yields the best known convergence rate for our sampling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13584v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bruno, Ying Zhang, Dong-Young Lim, \"Omer Deniz Akyildiz, Sotirios Sabanis</dc:creator>
    </item>
    <item>
      <title>On the Trajectories of SGD Without Replacement</title>
      <link>https://arxiv.org/abs/2312.16143</link>
      <description>arXiv:2312.16143v2 Announce Type: replace-cross 
Abstract: This article examines the implicit regularization effect of Stochastic Gradient Descent (SGD). We consider the case of SGD without replacement, the variant typically used to optimize large-scale neural networks. We analyze this algorithm in a more realistic regime than typically considered in theoretical works on SGD, as, e.g., we allow the product of the learning rate and Hessian to be $O(1)$ and we do not specify any model architecture, learning task, or loss (objective) function. Our core theoretical result is that optimizing with SGD without replacement is locally equivalent to making an additional step on a novel regularizer. This implies that the expected trajectories of SGD without replacement can be decoupled in (i) following SGD with replacement (in which batches are sampled i.i.d.) along the directions of high curvature, and (ii) regularizing the trace of the noise covariance along the flat ones. As a consequence, SGD without replacement travels flat areas and may escape saddles significantly faster than SGD with replacement. On several vision tasks, the novel regularizer penalizes a weighted trace of the Fisher Matrix, thus encouraging sparsity in the spectrum of the Hessian of the loss in line with empirical observations from prior work. We also propose an explanation for why SGD does not train at the edge of stability (as opposed to GD).</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16143v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierfrancesco Beneventano</dc:creator>
    </item>
    <item>
      <title>Tractable Optimal Experimental Design using Transport Maps</title>
      <link>https://arxiv.org/abs/2401.07971</link>
      <description>arXiv:2401.07971v2 Announce Type: replace-cross 
Abstract: We present a flexible method for computing Bayesian optimal experimental designs (BOEDs) for inverse problems with intractable posteriors. The approach is applicable to a wide range of BOED problems and can accommodate various optimality criteria, prior distributions and noise models. The key to our approach is the construction of a transport-map-based surrogate to the joint probability law of the design, observational and inference random variables. This order-preserving transport map is constructed using tensor trains and can be used to efficiently sample from (and evaluate approximate densities of) conditional distributions that are required in the evaluation of many commonly-used optimality criteria. The algorithm is also extended to sequential data acquisition problems, where experiments can be performed in sequence to update the state of knowledge about the unknown parameters. The sequential BOED problem is made computationally feasible by preconditioning the approximation of the joint density at the current stage using transport maps constructed at previous stages. The flexibility of our approach in finding optimal designs is illustrated with some numerical examples inspired by disease modeling and the reconstruction of subsurface structures in aquifers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07971v2</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Karina Koval, Roland Herzog, Robert Scheichl</dc:creator>
    </item>
    <item>
      <title>Soft-constrained Schrodinger Bridge: a Stochastic Control Approach</title>
      <link>https://arxiv.org/abs/2403.01717</link>
      <description>arXiv:2403.01717v2 Announce Type: replace-cross 
Abstract: Schr\"{o}dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process whose terminal distribution coincides with a pre-specified target distribution. We propose to generalize this problem by allowing the terminal distribution to differ from the target but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\"{o}dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of the target and some other distribution. This result is further extended to a time series setting. One application is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its use via a numerical example for the MNIST data set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01717v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jhanvi Garg, Xianyang Zhang, Quan Zhou</dc:creator>
    </item>
    <item>
      <title>Boundary controllability for a fourth order degenerate parabolic equation with a singular potential</title>
      <link>https://arxiv.org/abs/2403.08745</link>
      <description>arXiv:2403.08745v2 Announce Type: replace-cross 
Abstract: In this paper, we prove the null controllability of a one-dimensional fourth-order degenerate parabolic equation with a singular potential. Here, we analyze cases where boundary control conditions are applied at the left endpoint. We utilize a spectral decomposition involving Bessel functions and their zeros in a convenient weighted Sobolev space for a degenerate parabolic operator with specific boundary conditions. We establish the well-posedness of the system using semigroup operator theory. Subsequently, we employ the moment method by Fattorini and Russell to obtain an upper estimate of the cost of controllability. Additionally, we derive a lower estimate of the cost of controllability using a representation theorem for analytic functions of exponential type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08745v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leandro Galo-Mendoza</dc:creator>
    </item>
    <item>
      <title>Multi-task Magnetic Resonance Imaging Reconstruction using Meta-learning</title>
      <link>https://arxiv.org/abs/2403.19966</link>
      <description>arXiv:2403.19966v2 Announce Type: replace-cross 
Abstract: Using single-task deep learning methods to reconstruct Magnetic Resonance Imaging (MRI) data acquired with different imaging sequences is inherently challenging. The trained deep learning model typically lacks generalizability, and the dissimilarity among image datasets with different types of contrast leads to suboptimal learning performance. This paper proposes a meta-learning approach to efficiently learn image features from multiple MR image datasets. Our algorithm can perform multi-task learning to simultaneously reconstruct MR images acquired using different imaging sequences with different image contrasts. The experiment results demonstrate the ability of our new meta-learning reconstruction method to successfully reconstruct highly-undersampled k-space data from multiple MRI datasets simultaneously, outperforming other compelling reconstruction methods previously developed for single-task learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19966v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wanyu Bian, Albert Jang, Fang Liu</dc:creator>
    </item>
  </channel>
</rss>
