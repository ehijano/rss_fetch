<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Jul 2024 02:45:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Probabilistic Verification in Mechanism Design</title>
      <link>https://arxiv.org/abs/1908.05556</link>
      <description>arXiv:1908.05556v4 Announce Type: replace 
Abstract: We introduce a model of probabilistic verification in mechanism design. The principal elicits a message from the agent and then selects a test to give the agent. The agent's true type determines the probability with which he can pass each test. We characterize whether each type has an associated test that best screens out all other types. If this condition holds, then the testing technology can be represented in a tractable reduced form. We use this reduced form to solve for profit-maximizing mechanisms with verification. As the verification technology varies, the solution continuously interpolates between the no-verification solution and full surplus extraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:1908.05556v4</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ian Ball, Deniz Kattwinkel</dc:creator>
    </item>
    <item>
      <title>Interventions Against Machine-Assisted Statistical Discrimination</title>
      <link>https://arxiv.org/abs/2310.04585</link>
      <description>arXiv:2310.04585v3 Announce Type: replace 
Abstract: I study statistical discrimination driven by verifiable beliefs, such as those generated by machine learning, rather than by humans. When beliefs are verifiable, interventions against statistical discrimination can move beyond simple, belief-free designs like affirmative action, to more sophisticated ones, that constrain decision makers based on what they are thinking. Such mind reading interventions can perform well where affirmative action does not, even when the minds being read are biased. My theory of belief-contingent intervention design sheds light on influential methods of regulating machine learning, and yields novel interventions robust to covariate shift and incorrect, biased beliefs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04585v3</guid>
      <category>econ.TH</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>John Y. Zhu</dc:creator>
    </item>
    <item>
      <title>The Machiavellian frontier of stable mechanisms</title>
      <link>https://arxiv.org/abs/2405.12804</link>
      <description>arXiv:2405.12804v2 Announce Type: replace 
Abstract: The impossibility theorem in Roth (1982) states that no stable mechanism satisfies strategy-proofness. This paper explores the Machiavellian frontier of stable mechanisms by weakening strategy-proofness. For a fixed mechanism $\varphi$ and a true preference profile $\succ$, a $(\varphi,\succ)$-boost mispresentation of agent i is a preference of i that is obtained by (i) raising the ranking of the truth-telling assignment $\varphi_i(\succ)$, and (ii) keeping rankings unchanged above the new position of this truth-telling assignment. We require a matching mechanism $\varphi$ neither punish nor reward any such misrepresentation, and define such axiom as $\varphi$-boost-invariance. This is strictly weaker than requiring strategy-proofness. We show that no stable mechanism $\varphi$ satisfies $\varphi$-boost-invariance. Our negative result strengthens the Roth Impossibility Theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12804v2</guid>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiufu Chen, Yuanmei Li, Xiaopeng Yin, Luosai Zhang, Siyi Zhou</dc:creator>
    </item>
    <item>
      <title>Embracing the Enemy</title>
      <link>https://arxiv.org/abs/2406.09734</link>
      <description>arXiv:2406.09734v3 Announce Type: replace 
Abstract: We study repeated interactions between two power-hungry agents, the ``friend''and the ``enemy,'' and a power-broker, the principal. All three care about the leading agent's policy choice. The principal cannot fully control leadership allocation, but has some influence and aligns more with the friend. After an initial cordon sanitaire breaks, the principal embraces the enemy, sometimes promising persistent support: she grants the enemy power in exchange for moderation, which benefits the friend who reciprocates. The closer the principal is to the friend, the more she desires to embrace the enemy, but the harder it is to uphold such promises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09734v3</guid>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Schneider, \'Alvaro Delgado-Vega</dc:creator>
    </item>
  </channel>
</rss>
