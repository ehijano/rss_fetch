<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Dec 2025 02:41:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Drift estimation for a partially observed mixed fractional Ornstein--Uhlenbeck process</title>
      <link>https://arxiv.org/abs/2512.15362</link>
      <description>arXiv:2512.15362v1 Announce Type: new 
Abstract: We consider estimation of the drift parameter $\vartheta&gt;0$ in a \emph{partially observed} Ornstein--Uhlenbeck type model driven by a mixed fractional Brownian noise. Our framework extends the partially observed model of \cite{BrousteKleptsyna2010} to the \emph{mixed} case. We construct the canonical innovation representation, derive the associated Kalman filter and Riccati equations, and analyse the asymptotic behaviour of the filtering error covariance.
  Within the Ibragimov--Khasminskii LAN framework we prove that the MLE of $\vartheta$, based on continuous observation of the partially observed system on $[0,T]$, is consistent and asymptotically normal with rate $\sqrt{T}$ and the Fisher Information is the same as in \cite{BrousteKleptsyna2010} or the standard Brownian motion case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15362v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunhao Cai</dc:creator>
    </item>
    <item>
      <title>Sparse Principal Component Analysis with Energy Profile Dependent Sample Complexity</title>
      <link>https://arxiv.org/abs/2512.15191</link>
      <description>arXiv:2512.15191v1 Announce Type: cross 
Abstract: We study sparse principal component analysis in the high-dimensional, sample-limited regime, aiming to recover a leading component supported on a few coordinates. Despite extensive progress, most methods and analyses are tailored to the flat-spike case, offering little guidance when spike energy is unevenly distributed across the support. Motivated by this, we propose Spectral Energy Pursuit (SEP), an effective iterative scheme that repeatedly screens and reselects coordinates, with a sample complexity that adapts to the energy profile. We develop our framework around a structure function \(s(p)\) that quantifies how spike energy accumulates over its top \(p\) entries. We establish that SEP succeeds with a sample size of order \(\max_{1\le p\le k} p\,s^2(p)\,\log n\), which matches the classical \(k^2\log n\) sample complexity for flat spikes and improves toward the \(k\log n\) regime as the profile becomes more concentrated. As a lightweight post-processing, a single truncated power iteration is proven to enable the final estimator to attain a uniform statistical error bound. Empirical simulations across flat, power-law, and exponential signals validate that SEP adapts to profile structure without tuning and outperforms existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15191v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengchu Xu, Jian Wang, Yonina C. Eldar</dc:creator>
    </item>
    <item>
      <title>Interpretable Multivariate Conformal Prediction with Fast Transductive Standardization</title>
      <link>https://arxiv.org/abs/2512.15383</link>
      <description>arXiv:2512.15383v1 Announce Type: cross 
Abstract: We propose a conformal prediction method for constructing tight simultaneous prediction intervals for multiple, potentially related, numerical outputs given a single input. This method can be combined with any multi-target regression model and guarantees finite-sample coverage. It is computationally efficient and yields informative prediction intervals even with limited data. The core idea is a novel \emph{coordinate-wise} standardization procedure that makes residuals across output dimensions directly comparable, estimating suitable scaling parameters using the calibration data themselves. This does not require modeling of cross-output dependence nor auxiliary sample splitting. Implementing this idea requires overcoming technical challenges associated with transductive or full conformal prediction. Experiments on simulated and real data demonstrate this method can produce tighter prediction intervals than existing baselines while maintaining valid simultaneous coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15383v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunjie Fan, Matteo Sesia</dc:creator>
    </item>
    <item>
      <title>Statistics of Min-max Normalized Eigenvalues in Random Matrices</title>
      <link>https://arxiv.org/abs/2512.15427</link>
      <description>arXiv:2512.15427v1 Announce Type: cross 
Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15427v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.stat-mech</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyakka Nakada, Shu Tanaka</dc:creator>
    </item>
    <item>
      <title>Inference for Forecasting Accuracy: Pooled versus Individual Estimators in High-dimensional Panel Data</title>
      <link>https://arxiv.org/abs/2512.15592</link>
      <description>arXiv:2512.15592v1 Announce Type: cross 
Abstract: Panels with large time $(T)$ and cross-sectional $(N)$ dimensions are a key data structure in social sciences and other fields. A central question in panel data analysis is whether to pool data across individuals or to estimate separate models. Pooled estimators typically have lower variance but may suffer from bias, creating a fundamental trade-off for optimal estimation. We develop a new inference method to compare the forecasting performance of pooled and individual estimators. Specifically, we propose a confidence interval for the difference between their forecasting errors and establish its asymptotic validity. Our theory allows for complex temporal and cross-sectional dependence in the model errors and covers scenarios where $N$ can be much larger than $T$-including the independent case under the classical condition $N/T^2 \to 0$. The finite-sample properties of the proposed method are examined in an extensive simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15592v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim Kutta, Martin Schumann, Holger Dette</dc:creator>
    </item>
    <item>
      <title>A Central Limit Theorem for the permutation importance measure</title>
      <link>https://arxiv.org/abs/2412.13020</link>
      <description>arXiv:2412.13020v2 Announce Type: replace 
Abstract: Random Forests have become a widely used tool in machine learning since their introduction in 2001, known for their strong performance in classification and regression tasks. One key feature of Random Forests is the Random Forest Permutation Importance Measure (RFPIM), an internal, non-parametric measure of variable importance. While widely used, theoretical work on RFPIM is sparse, and most research has focused on empirical findings. However, recent progress has been made, such as establishing consistency of the RFPIM, although a mathematical analysis of its asymptotic distribution is still missing. In this paper, we provide a formal proof of a Central Limit Theorem for RFPIM using U-Statistics theory. Our approach deviates from the conventional Random Forest model by assuming a random number of trees and imposing conditions on the regression functions and error terms, which must be bounded and additive, respectively. Our result aims at improving the theoretical understanding of RFPIM rather than conducting comprehensive hypothesis testing. However, our contributions provide a solid foundation and demonstrate the potential for future work to extend to practical applications which we also highlight with a small simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13020v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nico F\"oge, Lena Schmid, Marc Ditzhaus, Markus Pauly</dc:creator>
    </item>
    <item>
      <title>Empirical Orlicz norms</title>
      <link>https://arxiv.org/abs/2510.25408</link>
      <description>arXiv:2510.25408v2 Announce Type: replace 
Abstract: The empirical Orlicz norm based on a random sample is defined as a natural estimator of the Orlicz norm of a univariate probability distribution. A law of large numbers is derived under minimal assumptions. The latter extends readily to a linear and a nonparametric regression model. Secondly, sufficient conditions for a central limit theorem with a standard rate of convergence are supplied. The conditions for the CLT exclude certain canonical examples, such as the empirical sub-Gaussian norm of normally distributed random variables. For the latter, we discover a nonstandard rate of $n^{1/4} \log(n)^{3/8}$, with a heavy-tailed, stable limit distribution. It is shown that in general, the empirical Orlicz norm does not admit any uniform rate of convergence for the class of distributions with bounded Orlicz norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25408v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Mies</dc:creator>
    </item>
    <item>
      <title>Solving a Research Problem in Mathematical Statistics with AI Assistance</title>
      <link>https://arxiv.org/abs/2511.18828</link>
      <description>arXiv:2511.18828v3 Announce Type: replace 
Abstract: Over the last few months, AI models including large language models have improved greatly. There are now several documented examples where they have helped professional mathematical scientists prove new results, sometimes even helping resolve known open problems. In this short note, we add another example to the list, by documenting how we were able to solve a previously unsolved research problem in robust mathematical statistics with crucial help from GPT-5. Our problem concerns robust density estimation, where the observations are perturbed by Wasserstein-bounded contaminations. In a previous preprint (Chao and Dobriban, 2023, arxiv:2308.01853v2), we have obtained upper and lower bounds on the minimax optimal estimation error; which were, however, not sharp.
  Starting in October 2025, making significant use of GPT-5 Pro, we were able to derive the minimax optimal error rate (reported in version 3 of the above arxiv preprint). GPT-5 provided crucial help along the way, including by suggesting calculations that we did not think of, and techniques that were not familiar to us, such as the dynamic Benamou-Brenier formulation, for key steps in the analysis. Working with GPT-5 took a few weeks of effort, and we estimate that it could have taken several months to get the same results otherwise. At the same time, there are still areas where working with GPT-5 was challenging: it sometimes provided incorrect references, and glossed over details that sometimes took days of work to fill in. We outline our workflow and steps taken to mitigate issues. Overall, our work can serve as additional documentation for a new age of human-AI collaborative work in mathematical science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18828v3</guid>
      <category>math.ST</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edgar Dobriban</dc:creator>
    </item>
    <item>
      <title>Robust Tensor Principal Component Analysis: Exact Recovery via Deterministic Model</title>
      <link>https://arxiv.org/abs/2008.02211</link>
      <description>arXiv:2008.02211v2 Announce Type: replace-cross 
Abstract: Tensor, also known as multi-dimensional array, arises from many applications in signal processing, manufacturing processes, healthcare, among others. As one of the most popular methods in tensor literature, Robust tensor principal component analysis (RTPCA) is a very effective tool to extract the low rank and sparse components in tensors. In this paper, a new method to analyze RTPCA is proposed based on the recently developed tensor-tensor product and tensor singular value decomposition (t-SVD). Specifically, it aims to solve a convex optimization problem whose objective function is a weighted combination of the tensor nuclear norm and the l1-norm. In most of literature of RTPCA, the exact recovery is built on the tensor incoherence conditions and the assumption of a uniform model on the sparse support. Unlike this conventional way, in this paper, without any assumption of randomness, the exact recovery can be achieved in a completely deterministic fashion by characterizing the tensor rank-sparsity incoherence, which is an uncertainty principle between the low-rank tensor spaces and the pattern of sparse tensor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.02211v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Shen (James), Yutong Zhang (James),  Zhenyu (James),  Kong</dc:creator>
    </item>
    <item>
      <title>Universal parameterized family of distributions of runs</title>
      <link>https://arxiv.org/abs/2302.14356</link>
      <description>arXiv:2302.14356v4 Announce Type: replace-cross 
Abstract: We present explicit formulae for parameterized families of probabilities of the number of nonoverlapping words and increasing nonoverlapping words in independent and identically distributed (i.i.d.) finite valued random variables, respectively. Then we provide an explicit formula for a parameterized family of probabilities of the number of runs, which
  generalizes \(\mu\)-overlapping probabilities for \(\mu\geq 0\) in i.i.d.~binary valued random variables. We also demonstrate exact probabilities of the number of runs whose size are exactly given numbers (Mood 1940). The number of arithmetic operations required to compute our formula for generalized probabilities of runs is linear order of sample size for fixed number of parameters and range. To analyse these number of arithmetic operations for unbounded number of parameters, we show an asymptotic formula for the number of integer partitions that are less than or equal to given number as a special case of Meinardus's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14356v4</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hayato Takahashi</dc:creator>
    </item>
    <item>
      <title>Testing for equivalence of pre-trends in Difference-in-Differences estimation</title>
      <link>https://arxiv.org/abs/2310.15796</link>
      <description>arXiv:2310.15796v2 Announce Type: replace-cross 
Abstract: The plausibility of the ``parallel trends assumption'' in Difference-in-Differences estimation is usually assessed by a test of the null hypothesis that the difference between the average outcomes of both groups is constant over time before the treatment. However, failure to reject the null hypothesis does not imply the absence of differences in time trends between both groups. We provide equivalence tests that allow researchers to find evidence in favor of the parallel trends assumption and thus increase the credibility of their treatment effect estimates. While we motivate our tests in the standard two-way fixed effects model, we discuss simple extensions to settings in which treatment adoption is staggered over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15796v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/07350015.2024.2308121</arxiv:DOI>
      <arxiv:journal_reference>Journal of Business &amp; Economic Statistics, 42(4), 1289-1301 (2024)</arxiv:journal_reference>
      <dc:creator>Holger Dette (Ruhr University Bochum), Martin Schumann (Maastricht University)</dc:creator>
    </item>
    <item>
      <title>Convergence of Noise-Free Sampling Algorithms with Regularized Wasserstein Proximals</title>
      <link>https://arxiv.org/abs/2409.01567</link>
      <description>arXiv:2409.01567v2 Announce Type: replace-cross 
Abstract: In this work, we investigate the convergence properties of the backward regularized Wasserstein proximal (BRWP) method for sampling a target distribution. The BRWP approach can be shown as a semi-implicit time discretization for a probability flow ODE with the score function whose density satisfies the Fokker-Planck equation of the overdamped Langevin dynamics. Specifically, the evolution of the density, hence the score function, is approximated via a kernel representation derived from the regularized Wasserstein proximal operator. By applying the dual formulation and a localized Taylor series to obtain the asymptotic expansion of this kernel formula, we establish guaranteed convergence in terms of the Kullback-Leibler divergence for the BRWP method towards a strongly log-concave target distribution. Our analysis also identifies the optimal and maximum step sizes for convergence. Furthermore, we demonstrate that the deterministic and semi-implicit BRWP scheme outperforms many classical Langevin Monte Carlo methods, such as the Unadjusted Langevin Algorithm (ULA), by offering faster convergence and reduced bias. Numerical experiments further validate the convergence analysis of the BRWP method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01567v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuqun Han, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Stopping Rules for Stochastic Gradient Descent via Anytime-Valid Confidence Sequences</title>
      <link>https://arxiv.org/abs/2512.13123</link>
      <description>arXiv:2512.13123v2 Announce Type: replace-cross 
Abstract: We study stopping rules for stochastic gradient descent (SGD) for convex optimization from the perspective of anytime-valid confidence sequences. Classical analyses of SGD provide convergence guarantees in expectation or at a fixed horizon, but offer no statistically valid way to assess, at an arbitrary time, how close the current iterate is to the optimum. We develop an anytime-valid, data-dependent upper confidence sequence for the weighted average suboptimality of projected SGD, constructed via nonnegative supermartingales and requiring no smoothness or strong convexity. This confidence sequence yields a simple stopping rule that is provably $\varepsilon$-optimal with probability at least $1-\alpha$ and is almost surely finite under standard stochastic approximation stepsizes. To the best of our knowledge, these are the first rigorous, time-uniform performance guarantees and finite-time $\varepsilon$-optimality certificates for projected SGD with general convex objectives, based solely on observable trajectory quantities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13123v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liviu Aolaritei, Michael I. Jordan</dc:creator>
    </item>
  </channel>
</rss>
