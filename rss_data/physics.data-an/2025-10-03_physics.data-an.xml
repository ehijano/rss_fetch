<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Mathematical Framework for Quantifying Nonlinear Uncertainty Propagation in Eddy Identification Criteria</title>
      <link>https://arxiv.org/abs/2510.01209</link>
      <description>arXiv:2510.01209v1 Announce Type: cross 
Abstract: Ocean eddies are swirling mesoscale features that play a fundamental role in oceanic transport and mixing. Eddy identification relies on diagnostic criteria that are inherently nonlinear functions of the flow variables. However, estimating the ocean flow field is subject to uncertainty due to its turbulent nature and the use of sparse and noisy observations. This uncertainty interacts with nonlinear diagnostics, complicating its quantification and limiting the accuracy of eddy identification. In this paper, an analytically tractable mathematical and computational framework for studying eddy identification is developed. It aims to address how uncertainty interacts with the nonlinearity in the eddy diagnostics and how the uncertainty in the eddy diagnostics is reduced when additional information from observations is incorporated. The framework employs a simple stochastic model for the flow field that mimics turbulent dynamics, allowing closed-form solutions for assessing uncertainty in eddy statistics. It also leverages a nonlinear, yet analytically tractable, data assimilation scheme to incorporate observations, facilitating the study of uncertainty reduction in eddy identification, which is quantified rigorously using information theory. Applied to the Okubo-Weiss (OW) parameter, a widely used eddy diagnostic criterion, the framework leads to three key results. First, closed formulae reveal inhomogeneous spatial patterns in the OW uncertainty despite homogeneous flow field uncertainty. Second, it shows a close link between local minima of the OW expectation (eddy centers) and local maxima of its uncertainty. Third, it reveals a practical information barrier: the reduction in uncertainty in diagnostics asymptotically saturates, limiting the benefit of additional observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01209v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charlotte Moser, Nan Chen, Stephen Wiggins</dc:creator>
    </item>
    <item>
      <title>Quantum-inspired Benchmark for Estimating Intrinsic Dimension</title>
      <link>https://arxiv.org/abs/2510.01335</link>
      <description>arXiv:2510.01335v1 Announce Type: cross 
Abstract: Machine learning models can generalize well on real-world datasets. According to the manifold hypothesis, this is possible because datasets lie on a latent manifold with small intrinsic dimension (ID). There exist many methods for ID estimation (IDE), but their estimates vary substantially. This warrants benchmarking IDE methods on manifolds that are more complex than those in existing benchmarks. We propose a Quantum-Inspired Intrinsic-dimension Estimation (QuIIEst) benchmark consisting of infinite families of topologically non-trivial manifolds with known ID. Our benchmark stems from a quantum-optical method of embedding arbitrary homogeneous spaces while allowing for curvature modification and additive noise. The IDE methods tested were generally less accurate on QuIIEst manifolds than on existing benchmarks under identical resource allocation. We also observe minimal performance degradation with increasingly non-uniform curvature, underscoring the benchmark's inherent difficulty. As a result of independent interest, we perform IDE on the fractal Hofstadter's butterfly and identify which methods are capable of extracting the effective dimension of a space that is not a manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01335v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>math.MG</category>
      <category>physics.data-an</category>
      <category>quant-ph</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aritra Das, Joseph T. Iosue, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>Securing generative artificial intelligence with parallel magnetic tunnel junction true randomness</title>
      <link>https://arxiv.org/abs/2510.01598</link>
      <description>arXiv:2510.01598v1 Announce Type: cross 
Abstract: Deterministic pseudo random number generators (PRNGs) used in generative artificial intelligence (GAI) models produce predictable patterns vulnerable to exploitation by attackers. Conventional defences against the vulnerabilities often come with significant energy and latency overhead. Here, we embed hardware-generated true random bits from spin-transfer torque magnetic tunnel junctions (STT-MTJs) to address the challenges. A highly parallel, FPGA-assisted prototype computing system delivers megabit-per-second true random numbers, passing NIST randomness tests after in-situ operations with minimal overhead. Integrating the hardware random bits into a generative adversarial network (GAN) trained on CIFAR-10 reduces insecure outputs by up to 18.6 times compared to the low-quality random number generators (RNG) baseline. With nanosecond switching speed, high energy efficiency, and established scalability, our STT-MTJ-based system holds the potential to scale beyond 106 parallel cells, achieving gigabit-per-second throughput suitable for large language model sampling. This advancement highlights spintronic RNGs as practical security components for next-generation GAI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01598v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youwei Bao, Shuhan Yang, Hyunsoo Yang</dc:creator>
    </item>
    <item>
      <title>GFSR-Net: Guided Focus via Segment-Wise Relevance Network for Interpretable Deep Learning in Medical Imaging</title>
      <link>https://arxiv.org/abs/2510.01919</link>
      <description>arXiv:2510.01919v1 Announce Type: cross 
Abstract: Deep learning has achieved remarkable success in medical image analysis, however its adoption in clinical practice is limited by a lack of interpretability. These models often make correct predictions without explaining their reasoning. They may also rely on image regions unrelated to the disease or visual cues, such as annotations, that are not present in real-world conditions. This can reduce trust and increase the risk of misleading diagnoses. We introduce the Guided Focus via Segment-Wise Relevance Network (GFSR-Net), an approach designed to improve interpretability and reliability in medical imaging. GFSR-Net uses a small number of human annotations to approximate where a person would focus within an image intuitively, without requiring precise boundaries or exhaustive markings, making the process fast and practical. During training, the model learns to align its focus with these areas, progressively emphasizing features that carry diagnostic meaning. This guidance works across different types of natural and medical images, including chest X-rays, retinal scans, and dermatological images. Our experiments demonstrate that GFSR achieves comparable or superior accuracy while producing saliency maps that better reflect human expectations. This reduces the reliance on irrelevant patterns and increases confidence in automated diagnostic tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01919v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jhonatan Contreras, Thomas Bocklitz</dc:creator>
    </item>
    <item>
      <title>Wasserstein normalized autoencoder for anomaly detection</title>
      <link>https://arxiv.org/abs/2510.02168</link>
      <description>arXiv:2510.02168v1 Announce Type: cross 
Abstract: A novel anomaly detection algorithm is presented. The Wasserstein normalized autoencoder (WNAE) is a normalized probabilistic model that minimizes the Wasserstein distance between the learned probability distribution -- a Boltzmann distribution where the energy is the reconstruction error of the autoencoder -- and the distribution of the training data. This algorithm has been developed and applied to the identification of semivisible jets -- conical sprays of visible standard model particles and invisible dark matter states -- with the CMS experiment at the CERN LHC. Trained on jets of particles from simulated standard model processes, the WNAE is shown to learn the probability distribution of the input data in a fully unsupervised fashion, such that it effectively identifies new physics jets as anomalies. The model consistently demonstrates stable, convergent training and achieves strong classification performance across a wide range of signals, improving upon standard normalized autoencoders, while remaining agnostic to the signal. The WNAE directly tackles the problem of outlier reconstruction, a common failure mode of autoencoders in anomaly detection tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02168v1</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> CMS Collaboration</dc:creator>
    </item>
    <item>
      <title>Unbinned Inference with Correlated Events</title>
      <link>https://arxiv.org/abs/2504.14072</link>
      <description>arXiv:2504.14072v2 Announce Type: replace 
Abstract: Modern machine learning has enabled parameter inference from event-level data without the need to first summarize all events with a histogram. All of these unbinned inference methods make use of the fact that the events are statistically independent so that the log likelihood is a sum over events. However, this assumption is not valid for unbinned inference on unfolded data, where the deconvolution process induces a correlation between events. We explore the impact of event correlations on downstream inference tasks in the context of the OmniFold unbinned unfolding method. We find that uncertainties may be significantly underestimated when event correlations are excluded from uncertainty quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14072v2</guid>
      <category>physics.data-an</category>
      <category>hep-ex</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Eur. Phys. J. C. 85 (2025) 1089</arxiv:journal_reference>
      <dc:creator>Krish Desai, Owen Long, Benjamin Nachman</dc:creator>
    </item>
    <item>
      <title>Multi-Scale Node Embeddings for Graph Modeling and Generation</title>
      <link>https://arxiv.org/abs/2412.04354</link>
      <description>arXiv:2412.04354v2 Announce Type: replace-cross 
Abstract: Lying at the interface between Network Science and Machine Learning, node embedding algorithms take a graph as input and encode its structure onto output vectors that represent nodes in an abstract geometric space, enabling various vector-based downstream tasks such as network modelling, data compression, link prediction, and community detection. Two apparently unrelated limitations affect these algorithms. On one hand, it is not clear what the basic operation defining vector spaces, i.e. the vector sum, corresponds to in terms of the original nodes in the network. On the other hand, while the same input network can be represented at multiple levels of resolution by coarse-graining the constituent nodes into arbitrary block-nodes, the relationship between node embeddings obtained at different hierarchical levels is not understood. Here, building on recent results in network renormalization theory, we address these two limitations at once and define a multiscale node embedding method that, upon arbitrary coarse-grainings, ensures statistical consistency of the embedding vector of a block-node with the sum of the embedding vectors of its constituent nodes. We illustrate the power of this approach on two economic networks that can be naturally represented at multiple resolution levels: namely, the international trade between (sets of) countries and the input-output flows among (sets of) industries in the Netherlands. We confirm the statistical consistency between networks retrieved from coarse-grained node vectors and networks retrieved from sums of fine-grained node vectors, a result that cannot be achieved by alternative methods. Several key network properties, including a large number of triangles, are successfully replicated already from embeddings of very low dimensionality, allowing for the generation of faithful replicas of the original networks at arbitrary resolution levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04354v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>physics.data-an</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Milocco, Fabian Jansen, Diego Garlaschelli</dc:creator>
    </item>
    <item>
      <title>Hyperbolic embedding of multilayer networks</title>
      <link>https://arxiv.org/abs/2505.20378</link>
      <description>arXiv:2505.20378v3 Announce Type: replace-cross 
Abstract: Multilayer networks offer a powerful framework for modeling complex systems across diverse domains, effectively capturing multiple types of connections and interdependent subsystems commonly found in real world scenarios. To analyze these networks, embedding techniques that project nodes into a lower-dimensional geometric space are essential. This paper introduces a novel hyperbolic embedding framework that advances the state of the art in multilayer network analysis. Our method, which supports heterogeneous node sets across networks and inter-layer connections, generates layer-specific hyperbolic embeddings, enabling detailed intra-layer analysis and inter-layer comparisons, while simultaneously preserving the global multilayer structure within hyperbolic space, a capability that sets it apart from existing approaches, which typically rely on independent embedding of layers. Through experiments on synthetic multilayer stochastic block models, we demonstrate that our approach effectively preserves community structure, even when layers consist of different node sets. When applied to real brain networks, the method successfully clusters disease-related brain regions from different patients, outperforming layer-independent approaches and highlighting its relevance for comparative analysis. Overall, this work provides a robust tool for multilayer network analysis, enhancing interpretability and offering new insights into the structure and function of complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20378v3</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Guillemaud, Vera Dinkelacker, Mario Chavez</dc:creator>
    </item>
    <item>
      <title>The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)</title>
      <link>https://arxiv.org/abs/2509.02661</link>
      <description>arXiv:2509.02661v2 Announce Type: replace-cross 
Abstract: This community paper developed out of the NSF Workshop on the Future of Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS), which was held in March 2025 with the goal of understanding how the MPS domains (Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics) can best capitalize on, and contribute to, the future of AI. We present here a summary and snapshot of the MPS community's perspective, as of Spring/Summer 2025, in a rapidly developing field. The link between AI and MPS is becoming increasingly inextricable; now is a crucial moment to strengthen the link between AI and Science by pursuing a strategy that proactively and thoughtfully leverages the potential of AI for scientific discovery and optimizes opportunities to impact the development of AI by applying concepts from fundamental science. To achieve this, we propose activities and strategic priorities that: (1) enable AI+MPS research in both directions; (2) build up an interdisciplinary community of AI+MPS researchers; and (3) foster education and workforce development in AI for MPS researchers and students. We conclude with a summary of suggested priorities for funding agencies, educational institutions, and individual researchers to help position the MPS community to be a leader in, and take full advantage of, the transformative potential of AI+MPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02661v2</guid>
      <category>cs.AI</category>
      <category>astro-ph.IM</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Ferguson, Marisa LaFleur, Lars Ruthotto, Jesse Thaler, Yuan-Sen Ting, Pratyush Tiwary, Soledad Villar, E. Paulo Alves, Jeremy Avigad, Simon Billinge, Camille Bilodeau, Keith Brown, Emmanuel Candes, Arghya Chattopadhyay, Bingqing Cheng, Jonathan Clausen, Connor Coley, Andrew Connolly, Fred Daum, Sijia Dong, Chrisy Xiyu Du, Cora Dvorkin, Cristiano Fanelli, Eric B. Ford, Luis Manuel Frutos, Nicol\'as Garc\'ia Trillos, Cecilia Garraffo, Robert Ghrist, Rafael Gomez-Bombarelli, Gianluca Guadagni, Sreelekha Guggilam, Sergei Gukov, Juan B. Guti\'errez, Salman Habib, Johannes Hachmann, Boris Hanin, Philip Harris, Murray Holland, Elizabeth Holm, Hsin-Yuan Huang, Shih-Chieh Hsu, Nick Jackson, Olexandr Isayev, Heng Ji, Aggelos Katsaggelos, Jeremy Kepner, Yannis Kevrekidis, Michelle Kuchera, J. Nathan Kutz, Branislava Lalic, Ann Lee, Matt LeBlanc, Josiah Lim, Rebecca Lindsey, Yongmin Liu, Peter Y. Lu, Sudhir Malik, Vuk Mandic, Vidya Manian, Emeka P. Mazi, Pankaj Mehta, Peter Melchior, Brice M\'enard, Jennifer Ngadiuba, Stella Offner, Elsa Olivetti, Shyue Ping Ong, Christopher Rackauckas, Philippe Rigollet, Chad Risko, Philip Romero, Grant Rotskoff, Brett Savoie, Uros Seljak, David Shih, Gary Shiu, Dima Shlyakhtenko, Eva Silverstein, Taylor Sparks, Thomas Strohmer, Christopher Stubbs, Stephen Thomas, Suriyanarayanan Vaikuntanathan, Rene Vidal, Francisco Villaescusa-Navarro, Gregory Voth, Benjamin Wandelt, Rachel Ward, Melanie Weber, Risa Wechsler, Stephen Whitelam, Olaf Wiest, Mike Williams, Zhuoran Yang, Yaroslava G. Yingling, Bin Yu, Shuwen Yue, Ann Zabludoff, Huimin Zhao, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Unveiling Entanglement's Metrological Power: Empirical Modeling of Optimal States in Quantum Metrics</title>
      <link>https://arxiv.org/abs/2509.15954</link>
      <description>arXiv:2509.15954v2 Announce Type: replace-cross 
Abstract: Using extensive numerical analysis of 20,000 randomly generated two-qubit states, we provide a quantitative analysis of the connection between entanglement measures and Maximized Quantum Fisher Information (MQFI). Our systematic study shows strong empirical relationships between the metrological capacity of quantum states and three different entanglement measures: concurrence, negativity, and relative entropy of entanglement. We show that optimization over local unitary transformations produces substantially more predictable relationships than fixed-generator quantum Fisher information approaches using sophisticated statistical analysis, such as bootstrap resampling, systematic data binning, and multiple model comparisons. With exponential fits reaching $R^2 &gt; 0.99$ and polynomial models reaching $R^2 = 0.999$, we offer thorough empirical support for saturation behavior in quantum metrological advantage. With immediate applications to realworld quantum sensing protocols, our findings directly empirically validate important predictions from quantum resource theory and set fundamental bounds for quantum sensor optimization and resource allocation. These intricate relationships are quantitatively described by the polynomial and exponential fit equations, which offer crucial real-world direction for the design of quantum sensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15954v2</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volkan Erol</dc:creator>
    </item>
  </channel>
</rss>
