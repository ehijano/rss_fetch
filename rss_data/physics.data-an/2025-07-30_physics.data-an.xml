<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Jul 2025 01:24:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards a Large Physics Benchmark</title>
      <link>https://arxiv.org/abs/2507.21695</link>
      <description>arXiv:2507.21695v1 Announce Type: new 
Abstract: We introduce a benchmark framework developed by and for the scientific community to evaluate, monitor and steer large language model development in fundamental physics. Building on philosophical concepts of scientific understanding and creativity, we develop a scoring system in which each question is scored by an expert for its correctness, difficulty, and surprise. The questions are of three forms: (i) multiple-choice questions for conceptual understanding, (ii) analytical problems requiring mathematical derivation, and (iii) openended tasks requiring complex problem solving. Our current dataset contains diverse set of examples, including a machine learning challenge to classify high-energy physics events, such as the four top quark signal. To ensure continued relevance, we propose a living benchmark, where physicists contribute questions, for instance alongside new publications. We invite contributions via: http://www.physicsbenchmarks.org/. We hope that this benchmark will enable a targeted AI development that can make a meaningful contribution to fundamental physics research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21695v1</guid>
      <category>physics.data-an</category>
      <category>cs.AI</category>
      <category>hep-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.hist-ph</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kristian G. Barman, Sascha Caron, Faegheh Hasibi, Eugene Shalugin, Yoris Marcet, Johannes Otte, Henk W. de Regt, Merijn Moody</dc:creator>
    </item>
    <item>
      <title>Energy Time Ptychography for one-dimensional phase retrieval</title>
      <link>https://arxiv.org/abs/2506.00492</link>
      <description>arXiv:2506.00492v2 Announce Type: replace-cross 
Abstract: Phase retrieval is at the heart of adaptive optics and modern high-resolution imaging. Without phase information, optical systems are limited to intensity-only measurements, hindering full reconstruction of object structures and wavefront dynamics essential for advanced applications. Here, we address a one-dimensional phase problem linking energy and time, which arises in X-ray scattering from ultrasharp nuclear resonances. We leverage the M\"ossbauer effect, where nuclei scatter radiation without energy loss to the lattice, and are sensitive to their magneto-chemical environments. Rather than using traditional spectroscopy with radioactive gamma-ray sources, we measure nuclear forward scattering of synchrotron X-ray pulses in the time domain, providing superior sensitivity and faster data acquisition. Extracting spectral information from a single measurement is challenging due to the missing phase information, typically requiring extensive modeling. Instead, we use multiple energetically overlapping measurements to retrieve both the transmission spectrum and the phase of the scattering response, similar to ptychographic phase retrieval in imaging. Our robust approach can overcome the bandwidth limitations of gamma-ray sources, opening new research directions with modern X-ray sources and M\"ossbauer isotopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00492v2</guid>
      <category>physics.optics</category>
      <category>physics.atom-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankita Negi, Leon Merten Lohse, Sven Velten, Ilya Sergeev, Olaf Leupold, Sakshath Sadashivaiah, Dimitrios Bessas, Aleksandr Chumakhov, Christina Brandt, Lars Bocklage, Guido Meier, Ralf R\"ohlsberger</dc:creator>
    </item>
    <item>
      <title>End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning</title>
      <link>https://arxiv.org/abs/2507.01918</link>
      <description>arXiv:2507.01918v2 Announce Type: replace-cross 
Abstract: We develop a rotation-invariant neural network that provides the global minimum-variance portfolio by jointly learning how to lag-transform historical returns and how to regularise both the eigenvalues and the marginal volatilities of large equity covariance matrices. This explicit mathematical mapping offers clear interpretability of each module's role, so the model cannot be regarded as a pure black-box. The architecture mirrors the analytical form of the global minimum-variance solution yet remains agnostic to dimension, so a single model can be calibrated on panels of a few hundred stocks and applied, without retraining, to one thousand US equities-a cross-sectional jump that demonstrates robust out-of-sample generalisation. The loss function is the future realized minimum portfolio variance and is optimized end-to-end on real daily returns. In out-of-sample tests from January 2000 to December 2024 the estimator delivers systematically lower realised volatility, smaller maximum drawdowns, and higher Sharpe ratios than the best analytical competitors, including state-of-the-art non-linear shrinkage. Furthermore, although the model is trained end-to-end to produce an unconstrained (long-short) minimum-variance portfolio, we show that its learned covariance representation can be used in general optimizers under long-only constraints with virtually no loss in its performance advantage over competing estimators. These gains persist when the strategy is executed under a highly realistic implementation framework that models market orders at the auctions, empirical slippage, exchange fees, and financing charges for leverage, and they remain stable during episodes of acute market stress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01918v2</guid>
      <category>q-fin.PM</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bongiorno, Efstratios Manolakis, Rosario Nunzio Mantegna</dc:creator>
    </item>
    <item>
      <title>LensingFlow: An Automated Workflow for Gravitational Wave Lensing Analyses</title>
      <link>https://arxiv.org/abs/2507.20256</link>
      <description>arXiv:2507.20256v2 Announce Type: replace-cross 
Abstract: In this work, we present LensingFlow. This is an implementation of an automated workflow to search for evidence of gravitational lensing in a large series of gravitational wave events. This workflow conducts searches for evidence in all generally considered lensing regimes. The implementation of this workflow is built atop the Asimov automation framework and CBCFlow metadata management software and the resulting product therefore encompasses both the automated running and status checking of jobs in the workflow as well as the automated production and storage of relevant metadata from these jobs to allow for later reproduction. This workflow encompasses a number of existing lensing pipelines and has been designed to accommodate any additional future pipelines to provide both a current and future basis on which to conduct large scale lensing analyses of gravitational wave signal catalogues. The workflow also implements a prioritisation management system for jobs submitted to the schedulers in common usage in computing clusters ensuring both the completion of the workflow across the entire catalogue of events as well as the priority completion of the most significant candidates. As a first proof-of-concept demonstration, we deploy LensingFlow on a mock data challenge comprising 10 signals in which signatures of each lensing regime are represented. LensingFlow successfully ran and identified the candidates from this data through its automated checks of results from consituent analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20256v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mick Wright, Justin Janquart, Paolo Cremonese, Juno C. L. Chan, Alvin K. Y. Li, Otto A. Hannuksela, Rico K. L. Lo, Jose M. Ezquiaga, Daniel Williams, Michael Williams, Gregory Ashton, Rhiannon Udall, Anupreeta More, Laura Uronen, Ankur Barsode, Eungwang Seo, David Keitel, Srashti Goyal, Jef Heynen, Anna Liu, Prasia Pankunni</dc:creator>
    </item>
  </channel>
</rss>
