<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Dec 2024 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cohort profile: the Northwest China Real-world and Population-based Cohort</title>
      <link>https://arxiv.org/abs/2411.18628</link>
      <description>arXiv:2411.18628v1 Announce Type: new 
Abstract: The Northwest China Real-World and Population-based cohort is an ongoing prospective cohort with more than 25 million population, covering almost all residents across approximately 1.66 million square kilometers in northwest China; The cohort integrates data from various sources, including health profiles, examination records, electronic health records, mortality records, statistical yearbooks, and environmental datasets, covering comprehensive health-related factors such as demographics, lifestyle factors, family medical history, living conditions, enrollment in national public health services, physical examinations, blood assay tests, diagnostic assessments, disease outcomes, and cause-specific mortality. This real-world dataset can evaluate clinical treatment effectiveness and prognosis, assess impact of health policy, and investigate the health effects of multiple risk factors . From January 2019 to December 2023, the cohort has included 13,634,481 participants, accumulating 47,050,707 person-years of follow-up, with 13,598,407 medical diagnosis records and 881,114 recorded deaths. Cohort data are available upon request. De-identified and anonymized data are stored on local servers and accessed through a data-sharing platform, enabling users to utilize the data without direct access to the raw information. A description of the proposed research can be sent to Yining Yang &amp; Qian Di.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18628v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Huang, Yanjun Li, Bo Yin, Yaoguo Wang, Yujuan Yuan, Yanying Guo, Kuiying Gu, Yining Yang, Qian Di</dc:creator>
    </item>
    <item>
      <title>The Method of Critical AI Studies, A Propaedeutic</title>
      <link>https://arxiv.org/abs/2411.18833</link>
      <description>arXiv:2411.18833v1 Announce Type: new 
Abstract: We outline some common methodological issues in the field of critical AI studies, including a tendency to overestimate the explanatory power of individual samples (the benchmark casuistry), a dependency on theoretical frameworks derived from earlier conceptualizations of computation (the black box casuistry), and a preoccupation with a cause-and-effect model of algorithmic harm (the stack casuistry). In the face of these issues, we call for, and point towards, a future set of methodologies that might take into account existing strengths in the humanistic close analysis of cultural objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18833v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Offert, Ranjodh Singh Dhaliwal</dc:creator>
    </item>
    <item>
      <title>Capstone Experiences in Developing Augmented Reality Tables for Community Organizations</title>
      <link>https://arxiv.org/abs/2411.18862</link>
      <description>arXiv:2411.18862v1 Announce Type: new 
Abstract: This paper examines two senior capstone experiences developed as augmented reality tables over the past two years. Both projects were public facing efforts that required working implementations. The first project was deployed at an astronomy center and focused on interactions between land use and ecological aspects of Hawaii Island while the second project focused more on historical sites on the same island. Both projects leveraged brownfield development and existing code bases to allow for student success in spite of the impacts of the COVID19 pandemic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18862v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Keith Edwards, Michael R. Peterson, Francis Cristobal</dc:creator>
    </item>
    <item>
      <title>Examining Multimodal Gender and Content Bias in ChatGPT-4o</title>
      <link>https://arxiv.org/abs/2411.19140</link>
      <description>arXiv:2411.19140v1 Announce Type: new 
Abstract: This study investigates ChatGPT-4o's multimodal content generation, highlighting significant disparities in its treatment of sexual content and nudity versus violent and drug-related themes. Detailed analysis reveals that ChatGPT-4o consistently censors sexual content and nudity, while showing leniency towards violence and drug use. Moreover, a pronounced gender bias emerges, with female-specific content facing stricter regulation compared to male-specific content. This disparity likely stems from media scrutiny and public backlash over past AI controversies, prompting tech companies to impose stringent guidelines on sensitive issues to protect their reputations. Our findings emphasize the urgent need for AI systems to uphold genuine ethical standards and accountability, transcending mere political correctness. This research contributes to the understanding of biases in AI-driven language and multimodal models, calling for more balanced and ethical content moderation practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19140v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>stat.OT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Balestri</dc:creator>
    </item>
    <item>
      <title>On the Ethical Considerations of Generative Agents</title>
      <link>https://arxiv.org/abs/2411.19211</link>
      <description>arXiv:2411.19211v1 Announce Type: new 
Abstract: The Generative Agents framework recently developed by Park et al. has enabled numerous new technical solutions and problem-solving approaches. Academic and industrial interest in generative agents has been explosive as a result of the effectiveness of generative agents toward emulating human behaviour. However, it is necessary to consider the ethical challenges and concerns posed by this technique and its usage. In this position paper, we discuss the extant literature that evaluate the ethical considerations regarding generative agents and similar generative tools, and identify additional concerns of significant importance. We also suggest guidelines and necessary future research on how to mitigate some of the ethical issues and systemic risks associated with generative agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19211v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N'yoma Diamond, Soumya Banerjee</dc:creator>
    </item>
    <item>
      <title>Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance</title>
      <link>https://arxiv.org/abs/2411.19356</link>
      <description>arXiv:2411.19356v1 Announce Type: new 
Abstract: Understanding public perception of artificial intelligence (AI) and the tradeoffs between potential risks and benefits is crucial, as these perceptions might shape policy decisions, influence innovation trajectories for successful market strategies, and determine individual and societal acceptance of AI technologies. Using a representative sample of 1100 participants from Germany, this study examines mental models of AI. Participants quantitatively evaluated 71 statements about AI's future capabilities (e.g., autonomous driving, medical care, art, politics, warfare, and societal divides), assessing the expected likelihood of occurrence, perceived risks, benefits, and overall value. We present rankings of these projections alongside visual mappings illustrating public risk-benefit tradeoffs. While many scenarios were deemed likely, participants often associated them with high risks, limited benefits, and low overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in value assessment can be explained by perceived risks ($\beta=-.504$) and perceived benefits ($\beta=+.710$), with no significant relation to expected likelihood. Demographics and personality traits influenced perceptions of risks, benefits, and overall evaluations, underscoring the importance of increasing AI literacy and tailoring public information to diverse user needs. These findings provide actionable insights for researchers, developers, and policymakers by highlighting critical public concerns and individual factors essential to align AI development with individual values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19356v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle</dc:creator>
    </item>
    <item>
      <title>Descriptions of women are longer than that of men: An analysis of gender portrayal prompts in Stable Diffusion</title>
      <link>https://arxiv.org/abs/2411.18994</link>
      <description>arXiv:2411.18994v1 Announce Type: cross 
Abstract: Generative AI for image creation emerges as a staple in the toolkit of digital artists, visual designers, and the general public. Social media users have many tools to shape their visual representation: image editing tools, filters, face masks, face swaps, avatars, and AI-generated images. The importance of the right profile image can not be understated: It is crucial for creating the right first impression, sustains trust, and enables communication. Conventionally correct representation of individuals, groups, and collectives may help foster inclusivity, understanding, and respect in society, ensuring that diverse perspectives are acknowledged and valued. While previous research revealed the biases in large image datasets such as ImageNet and inherited biases in the AI systems trained on it, within this work, we look at the prejudices and stereotypes as they emerge from textual prompts used for generating images on Discord using the StableDiffusion model. We analyze over 1.8 million prompts depicting men and women and use statistical methods to uncover how prompts describing men and women are constructed and what words constitute the portrayals of respective genders. We show that the median male description length is systematically shorter than the median female description length, while our findings also suggest a shared practice of prompting regarding the word length distribution. The topic analysis suggests the existence of classic stereotypes in which men are described using dominant qualities such as "strong" and "rugged". In contrast, women are represented with concepts related to body and submission: "beautiful", "pretty", etc. These results highlight the importance of the original intent of the prompting and suggest that cultural practices on platforms such as Discord should be considered when designing interfaces that promote exploration and fair representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18994v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Asadchy, Maximilian Schich</dc:creator>
    </item>
    <item>
      <title>Tracking Progress Towards Sustainable Development Goal 6 Using Satellite Imagery</title>
      <link>https://arxiv.org/abs/2411.19093</link>
      <description>arXiv:2411.19093v1 Announce Type: cross 
Abstract: Clean water and sanitation are essential for health, well-being, and sustainable development, yet significant global disparities remain. Although the United Nations' Sustainable Development Goal 6 has clear targets for universal access to clean water and sanitation, data coverage and openness remain obstacles for tracking progress in many countries. Nontraditional data sources are needed to fill this gap. This study incorporated Afrobarometer survey data, satellite imagery (Landsat 8 and Sentinel-2), and deep learning techniques (Meta's DINO model) to develop a modelling framework for evaluating access to piped water and sewage systems across diverse African regions. The modelling framework demonstrated high accuracy, achieving over 96% and 97% accuracy in identifying areas with piped water access and sewage system access respectively using satellite imagery. It can serve as a screening tool for policymakers and stakeholders to potentially identify regions for more targeted and prioritized efforts to improve water and sanitation infrastructure. When coupled with spatial population data, the modelling framework can also estimate and track the national-level percentages of the population with access to piped water and sewage systems. In the future, this approach could potentially be extended to evaluate other SDGs, particularly those related to critical infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19093v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Othmane Echchabi, Nizar Talty, Josh Manto, Aya Lahlou, Ka Leung Lam</dc:creator>
    </item>
    <item>
      <title>On the Unknowable Limits to Prediction</title>
      <link>https://arxiv.org/abs/2411.19223</link>
      <description>arXiv:2411.19223v1 Announce Type: cross 
Abstract: This short Correspondence critiques the classic dichotomization of prediction error into reducible and irreducible components, noting that certain types of error can be eliminated at differential speeds. We propose an improved analytical framework that better distinguishes epistemic from aleatoric uncertainty, emphasizing that predictability depends on information sets and cautioning against premature claims of unpredictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19223v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.ME</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiani Yan, Charles Rahal</dc:creator>
    </item>
    <item>
      <title>Habit Coach: Customising RAG-based chatbots to support behavior change</title>
      <link>https://arxiv.org/abs/2411.19229</link>
      <description>arXiv:2411.19229v1 Announce Type: cross 
Abstract: This paper presents the iterative development of Habit Coach, a GPT-based chatbot designed to support users in habit change through personalized interaction. Employing a user-centered design approach, we developed the chatbot using a Retrieval-Augmented Generation (RAG) system, which enables behavior personalization without retraining the underlying language model (GPT-4). The system leverages document retrieval and specialized prompts to tailor interactions, drawing from Cognitive Behavioral Therapy (CBT) and narrative therapy techniques. A key challenge in the development process was the difficulty of translating declarative knowledge into effective interaction behaviors. In the initial phase, the chatbot was provided with declarative knowledge about CBT via reference textbooks and high-level conversational goals. However, this approach resulted in imprecise and inefficient behavior, as the GPT model struggled to convert static information into dynamic and contextually appropriate interactions. This highlighted the limitations of relying solely on declarative knowledge to guide chatbot behavior, particularly in nuanced, therapeutic conversations. Over four iterations, we addressed this issue by gradually transitioning towards procedural knowledge, refining the chatbot's interaction strategies, and improving its overall effectiveness. In the final evaluation, 5 participants engaged with the chatbot over five consecutive days, receiving individualized CBT interventions. The Self-Report Habit Index (SRHI) was used to measure habit strength before and after the intervention, revealing a reduction in habit strength post-intervention. These results underscore the importance of procedural knowledge in driving effective, personalized behavior change support in RAG-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19229v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arian Fooroogh Mand Arabi, Cansu Koyuturk, Michael O'Mahony, Raffaella Calati, Dimitri Ognibene</dc:creator>
    </item>
    <item>
      <title>Unimib Assistant: designing a student-friendly RAG-based chatbot for all their needs</title>
      <link>https://arxiv.org/abs/2411.19554</link>
      <description>arXiv:2411.19554v1 Announce Type: cross 
Abstract: Natural language processing skills of Large Language Models (LLMs) are unprecedented, having wide diffusion and application in different tasks. This pilot study focuses on specializing ChatGPT behavior through a Retrieval-Augmented Generation (RAG) system using the OpenAI custom GPTs feature. The purpose of our chatbot, called Unimib Assistant, is to provide information and solutions to the specific needs of University of Milano-Bicocca (Unimib) students through a question-answering approach. We provided the system with a prompt highlighting its specific purpose and behavior, as well as university-related documents and links obtained from an initial need-finding phase, interviewing six students. After a preliminary customization phase, a qualitative usability test was conducted with six other students to identify the strengths and weaknesses of the chatbot, with the goal of improving it in a subsequent redesign phase. While the chatbot was appreciated for its user-friendly experience, perceived general reliability, well-structured responses, and conversational tone, several significant technical and functional limitations emerged. In particular, the satisfaction and overall experience of the users was impaired by the system's inability to always provide fully accurate information. Moreover, it would often neglect to report relevant information even if present in the materials uploaded and prompt given. Furthermore, it sometimes generated unclickable links, undermining its trustworthiness, since providing the source of information was an important aspect for our users. Further in-depth studies and feedback from other users as well as implementation iterations are planned to refine our Unimib Assistant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19554v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Antico, Stefano Giordano, Cansu Koyuturk, Dimitri Ognibene</dc:creator>
    </item>
    <item>
      <title>FairDD: Fair Dataset Distillation via Synchronized Matching</title>
      <link>https://arxiv.org/abs/2411.19623</link>
      <description>arXiv:2411.19623v1 Announce Type: cross 
Abstract: Condensing large datasets into smaller synthetic counterparts has demonstrated its promise for image classification. However, previous research has overlooked a crucial concern in image recognition: ensuring that models trained on condensed datasets are unbiased towards protected attributes (PA), such as gender and race. Our investigation reveals that dataset distillation (DD) fails to alleviate the unfairness towards minority groups within original datasets. Moreover, this bias typically worsens in the condensed datasets due to their smaller size. To bridge the research gap, we propose a novel fair dataset distillation (FDD) framework, namely FairDD, which can be seamlessly applied to diverse matching-based DD approaches, requiring no modifications to their original architectures. The key innovation of FairDD lies in synchronously matching synthetic datasets to PA-wise groups of original datasets, rather than indiscriminate alignment to the whole distributions in vanilla DDs, dominated by majority groups. This synchronized matching allows synthetic datasets to avoid collapsing into majority groups and bootstrap their balanced generation to all PA groups. Consequently, FairDD could effectively regularize vanilla DDs to favor biased generation toward minority groups while maintaining the accuracy of target attributes. Theoretical analyses and extensive experimental evaluations demonstrate that FairDD significantly improves fairness compared to vanilla DD methods, without sacrificing classification accuracy. Its consistent superiority across diverse DDs, spanning Distribution and Gradient Matching, establishes it as a versatile FDD approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19623v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qihang Zhou, Shenhao Fang, Shibo He, Wenchao Meng, Jiming Chen</dc:creator>
    </item>
    <item>
      <title>Build An Influential Bot In Social Media Simulations With Large Language Models</title>
      <link>https://arxiv.org/abs/2411.19635</link>
      <description>arXiv:2411.19635v1 Announce Type: cross 
Abstract: Understanding the dynamics of public opinion evolution on online social platforms is critical for analyzing influence mechanisms. Traditional approaches to influencer analysis are typically divided into qualitative assessments of personal attributes and quantitative evaluations of influence power. In this study, we introduce a novel simulated environment that combines Agent-Based Modeling (ABM) with Large Language Models (LLMs), enabling agents to generate posts, form opinions, and update follower networks. This simulation allows for more detailed observations of how opinion leaders emerge. Additionally, we present an innovative application of Reinforcement Learning (RL) to replicate the process of opinion leader formation. Our findings reveal that limiting the action space and incorporating self-observation are key factors for achieving stable opinion leader generation. The learning curves demonstrate the model's capacity to identify optimal strategies and adapt to complex, unpredictable dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19635v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bailu Jin, Weisi Guo</dc:creator>
    </item>
    <item>
      <title>Gated-Attention Feature-Fusion Based Framework for Poverty Prediction</title>
      <link>https://arxiv.org/abs/2411.19690</link>
      <description>arXiv:2411.19690v1 Announce Type: cross 
Abstract: This research paper addresses the significant challenge of accurately estimating poverty levels using deep learning, particularly in developing regions where traditional methods like household surveys are often costly, infrequent, and quickly become outdated. To address these issues, we propose a state-of-the-art Convolutional Neural Network (CNN) architecture, extending the ResNet50 model by incorporating a Gated-Attention Feature-Fusion Module (GAFM). Our architecture is designed to improve the model's ability to capture and combine both global and local features from satellite images, leading to more accurate poverty estimates. The model achieves a 75% R2 score, significantly outperforming existing leading methods in poverty mapping. This improvement is due to the model's capacity to focus on and refine the most relevant features, filtering out unnecessary data, which makes it a powerful tool for remote sensing and poverty estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19690v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Umer Ramzan, Wahab Khaddim, Muhammad Ehsan Rana, Usman Ali, Manohar Ali, Fiaz ul Hassan, Fatima Mehmood</dc:creator>
    </item>
    <item>
      <title>Examining quality of DGNSS derived positioning in data in urban city -- A case study of an urban city in India</title>
      <link>https://arxiv.org/abs/2411.19794</link>
      <description>arXiv:2411.19794v1 Announce Type: cross 
Abstract: GNSS observations are carried out in static mode/ Differential global navigation satellite system (DGNSS) and dynamic mode / Real time Kinematics (RTK) mainly. RTK mode of observation is useful in case of navigation whereas in order to determine very precise positioning, static / DGNSS/ DGPS mode is recommended. In this study, we have examined the quality of DGNSS survey of an urban city in India over ~300 Ground Control Points. Survey is carried out in DGNSS mode with dual frequency mode. All the observations were recorded using GPS, GLONASS , Galileo and Beidu with GDOP values in the range of 1.4 to 2.5. Beidu was used in broadcast ephemeris mode whereas for other constellations, precise orbit ephemeris were obtained from International GNSS service (IGS) site as per the observation day and month. Further, all the data was post processed in the SW suite and positional and vertical accuracies of millimeter to few centimeter level were obtained. This paper describes the approach of Ground Control Point (GCP) identification, surveying, methodology, use of CORS network and data post-processing in order to achieve such a precise accuracies in the urban city.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19794v1</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jai G Singla</dc:creator>
    </item>
    <item>
      <title>Musical composition and 2D cellular automata based on music intervals</title>
      <link>https://arxiv.org/abs/2411.19844</link>
      <description>arXiv:2411.19844v1 Announce Type: cross 
Abstract: This study is a theoretical approach for exploring the applicability of a 2D cellular automaton based on melodic and harmonic intervals in random arrays of musical notes. The aim of this study was to explore alternatives uses for a cellular automaton in the musical context for better understanding the musical creativity. We used the complex systems and humanities approaches as a framework for capturing the essence of creating music based on rules of music theory. Findings suggested that such rules matter for generating large-scale patterns of organized notes. Therefore, our formulation provides a novel approach for understanding and replicating aspects of the musical creativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19844v1</guid>
      <category>cs.SD</category>
      <category>cs.CY</category>
      <category>eess.AS</category>
      <category>stat.AP</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Lugo, Martha G. Alatriste-Contreras</dc:creator>
    </item>
    <item>
      <title>Misinformation Dissemination: Effects of Network Density in Segregated Communities</title>
      <link>https://arxiv.org/abs/2411.19866</link>
      <description>arXiv:2411.19866v1 Announce Type: cross 
Abstract: Understanding the relationship between network features and misinformation propagation is crucial for mitigating the spread of false information. Here, we investigate how network density and segregation affect the dissemination of misinformation using a susceptible-infectious-recovered framework. We find that a higher density consistently increases the proportion of misinformation believers. In segregated networks, our results reveal that minorities affect the majority: denser minority groups increase the number of believers in the majority, demonstrating how the structure of a segregated minority can influence misinformation dynamics within the majority group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19866v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soroush Karimi, Marcos Oliveira, Diogo Pacheco</dc:creator>
    </item>
    <item>
      <title>Monitoring Human Dependence On AI Systems With Reliance Drills</title>
      <link>https://arxiv.org/abs/2409.14055</link>
      <description>arXiv:2409.14055v5 Announce Type: replace 
Abstract: AI systems are assisting humans with increasingly diverse intellectual tasks but are still prone to mistakes. Humans are over-reliant on this assistance if they trust AI-generated advice, even though they would make a better decision on their own. To identify such instances of over-reliance, this paper proposes the reliance drill: an exercise that tests whether a human can recognise mistakes in AI-generated advice. Our paper examines the reasons why an organisation might choose to implement reliance drills and the doubts they may have about doing so. As an example, we consider the benefits and risks that could arise when using these drills to detect over-reliance on AI in healthcare professionals. We conclude by arguing that reliance drills should become a standard risk management practice for ensuring humans remain appropriately involved in the oversight of AI-assisted decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14055v5</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rosco Hunter, Richard Moulange, Jamie Bernardi, Merlin Stein</dc:creator>
    </item>
    <item>
      <title>The Hermeneutic Turn of AI: Are Machines Capable of Interpreting?</title>
      <link>https://arxiv.org/abs/2411.12517</link>
      <description>arXiv:2411.12517v2 Announce Type: replace 
Abstract: This article aims to demonstrate how the approach to computing is being disrupted by deep learning (artificial neural networks), not only in terms of techniques but also in our interactions with machines. It also addresses the philosophical tradition of hermeneutics (Don Ihde, Wilhelm Dilthey) to highlight a parallel with this movement and to demystify the idea of human-like AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12517v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>The Conversation, June 3, 2024</arxiv:journal_reference>
      <dc:creator>Remy Demichelis</dc:creator>
    </item>
    <item>
      <title>Rational Silence and False Polarization: How Viewpoint Organizations and Recommender Systems Distort the Expression of Public Opinion</title>
      <link>https://arxiv.org/abs/2403.06264</link>
      <description>arXiv:2403.06264v2 Announce Type: replace-cross 
Abstract: AI-based social media platforms has already transformed the nature of economic and social interaction. AI enables the massive scale and highly personalized nature of online information sharing that we now take for granted. Extensive attention has been devoted to the polarization that social media platforms appear to facilitate. However, a key implication of the transformation we are experiencing due to these AI-powered platforms has received much less attention: how platforms impact what observers of online discourse come to believe about community views. These observers include policymakers and legislators, who look to social media to gauge the prospects for policy and legislative change, as well as developers of AI models trained on large-scale internet data, whose outputs may similarly reflect a distorted view of public opinion. In this paper, we present a nested game-theoretic model to show how observed online opinion is produced by the interaction of the decisions made by users about whether and with what rhetorical intensity to share their opinions on a platform, the efforts of organizations (such as traditional media and advocacy organizations) that seek to encourage or discourage opinion-sharing online, and the operation of AI-powered recommender systems controlled by social media platforms. We show that signals from ideological organizations encourage an increase in rhetorical intensity, leading to the 'rational silence' of moderate users. This, in turn, creates a polarized impression of where average opinions lie. We also show that this observed polarization can also be amplified by recommender systems that encourage the formation of communities online that end up seeing a skewed sample of opinion. We also identify practical strategies platforms can implement, such as reducing exposure to signals from ideological organizations and a tailored approach to content moderation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06264v2</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atrisha Sarkar, Gillian K. Hadfield</dc:creator>
    </item>
    <item>
      <title>Representative Social Choice: From Learning Theory to AI Alignment</title>
      <link>https://arxiv.org/abs/2410.23953</link>
      <description>arXiv:2410.23953v2 Announce Type: replace-cross 
Abstract: Social choice theory is the study of preference aggregation across a population, used both in mechanism design for human agents and in the democratic alignment of language models. In this study, we propose the representative social choice framework for the modeling of democratic representation in collective decisions, where the number of issues and individuals are too large for mechanisms to consider all preferences directly. These scenarios are widespread in real-world decision-making processes, such as jury trials, indirect elections, legislation processes, corporate governance, and, more recently, language model alignment. In representative social choice, the population is represented by a finite sample of individual-issue pairs based on which social choice decisions are made. We show that many of the deepest questions in representative social choice can be naturally formulated as statistical learning problems, and prove the generalization properties of social choice mechanisms using the theory of machine learning. We further formulate axioms for representative social choice, and prove Arrow-like impossibility theorems with new combinatorial tools of analysis. Our framework introduces the representative approach to social choice, opening up research directions at the intersection of social choice, learning theory, and AI alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23953v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Qiu</dc:creator>
    </item>
    <item>
      <title>Multiscale spatiotemporal heterogeneity analysis of bike-sharing system's self-loop phenomenon: Evidence from Shanghai</title>
      <link>https://arxiv.org/abs/2411.17555</link>
      <description>arXiv:2411.17555v2 Announce Type: replace-cross 
Abstract: Bike-sharing is an environmentally friendly shared mobility mode, but its self-loop phenomenon, where bikes are returned to the same station after several time usage, significantly impacts equity in accessing its services. Therefore, this study conducts a multiscale analysis with a spatial autoregressive model and double machine learning framework to assess socioeconomic features and geospatial location's impact on the self-loop phenomenon at metro stations and street scales. The results reveal that bike-sharing self-loop intensity exhibits significant spatial lag effect at street scale and is positively associated with residential land use. Marginal treatment effects of residential land use is higher on streets with middle-aged residents, high fixed employment, and low car ownership. The multimodal public transit condition reveals significant positive marginal treatment effects at both scales. To enhance bike-sharing cooperation, we advocate augmenting bicycle availability in areas with high metro usage and low bus coverage, alongside implementing adaptable redistribution strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17555v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yichen Wang, Qing Yu, Yancun Song</dc:creator>
    </item>
  </channel>
</rss>
