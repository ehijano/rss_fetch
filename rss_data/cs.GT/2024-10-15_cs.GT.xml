<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2024 02:04:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimizing Hard-to-Place Kidney Allocation: A Machine Learning Approach to Center Ranking</title>
      <link>https://arxiv.org/abs/2410.09116</link>
      <description>arXiv:2410.09116v1 Announce Type: new 
Abstract: Kidney transplantation is the preferred treatment for end-stage renal disease, yet the scarcity of donors and inefficiencies in allocation systems create major bottlenecks, resulting in prolonged wait times and alarming mortality rates. Despite their severe scarcity, timely and effective interventions to prevent non-utilization of life-saving organs remain inadequate. Expedited out-of-sequence placement of hard-to-place kidneys to centers with the highest likelihood of utilizing them has been recommended in the literature as an effective strategy to improve placement success. Nevertheless, current attempts towards this practice is non-standardized and heavily rely on the subjective judgment of the decision-makers. This paper proposes a novel data-driven, machine learning-based ranking system for allocating hard-to-place kidneys to centers with a higher likelihood of accepting and successfully transplanting them. Using the national deceased donor kidney offer and transplant datasets, we construct a unique dataset with donor-, center-, and patient-specific features. We propose a data-driven out-of-sequence placement policy that utilizes machine learning models to predict the acceptance probability of a given kidney by a set of transplant centers, ranking them accordingly based on their likelihood of acceptance. Our experiments demonstrate that the proposed policy can reduce the average number of centers considered before placement by fourfold for all kidneys and tenfold for hard-to-place kidneys. This significant reduction indicates that our method can improve the utilization of hard-to-place kidneys and accelerate their acceptance, ultimately reducing patient mortality and the risk of graft failure. Further, we utilize machine learning interpretability tools to provide insights into factors influencing the kidney allocation decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09116v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sean Berry, Berk Gorgulu, Sait Tunc, Mucahit Cevik, Matthew J Ellis</dc:creator>
    </item>
    <item>
      <title>The Condorcet Dimension of Metric Spaces</title>
      <link>https://arxiv.org/abs/2410.09201</link>
      <description>arXiv:2410.09201v1 Announce Type: new 
Abstract: A Condorcet winning set is a set of candidates such that no other candidate is preferred by at least half the voters over all members of the set. The Condorcet dimension, which is the minimum cardinality of a Condorcet winning set, is known to be at most logarithmic in the number of candidates. We study the case of elections where voters and candidates are located in a $2$-dimensional space with preferences based upon proximity voting. Our main result is that the Condorcet dimension is at most $3$, under both the Manhattan norm and the infinity norm, natural measures in electoral systems. We also prove that any set of voter preferences can be embedded into a metric space of sufficiently high dimension for any $p$-norm, including the Manhattan and infinity norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09201v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandra Lassota, Adrian Vetta, Bernhard von Stengel</dc:creator>
    </item>
    <item>
      <title>Candidate Monotonicity and Proportionality for Lotteries and Non-Resolute Rules</title>
      <link>https://arxiv.org/abs/2410.10095</link>
      <description>arXiv:2410.10095v1 Announce Type: new 
Abstract: We study the problem of designing multiwinner voting rules that are candidate monotone and proportional. We show that the set of committees satisfying the proportionality axiom of proportionality for solid coalitions is candidate monotone. We further show that Phragm\'en's Ordered Rule can be turned into a candidate monotone probabilistic rule which randomizes over committees satisfying proportionality for solid coalitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10095v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannik Peters</dc:creator>
    </item>
    <item>
      <title>Sealed-bid Auctions on Blockchain with Timed Commitment Outsourcing</title>
      <link>https://arxiv.org/abs/2410.10607</link>
      <description>arXiv:2410.10607v1 Announce Type: new 
Abstract: Sealed-bid auctions play a crucial role in blockchain ecosystems. Previous works introduced viable blockchain sealed-bid auction protocols, leveraging timed commitments for bid encryption. However, a crucial challenge remains unresolved in these works: Who should bear the cost of decrypting these timed commitments?
  This work introduces a timed commitment outsourcing market as a solution to the aforementioned challenge. We first introduce an aggregation scheme for timed commitments, which combines all bidders' timed commitments into one while ensuring security and correctness and allowing a varying number of bidders. Next, we remodel the utility of auctioneers and timed commitment solvers, developing a new timed commitment competition mechanism and combining it with the sealed-bid auction to form a two-sided market. The protocol includes bid commitment collection, timed commitment solving, and payment. Through game-theoretical analysis, we prove that our protocol satisfies Dominant Strategy Incentive Compatibility (DSIC) for bidders, Bayesian Incentive Compatibility (BIC) for solvers, and achieves optimal revenue for the auctioneer among a large class of mechanisms. Finally, we prove that no mechanism can achieve positive expected revenue for the auctioneer while satisfying DSIC and Individual Rationality (IR) for both bidders and solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10607v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jichen Li, Yuanchen Tang, Jing Chen, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>A Generalization of von Neumann's Reduction from the Assignment Problem to Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2410.10767</link>
      <description>arXiv:2410.10767v1 Announce Type: new 
Abstract: The equivalence between von Neumann's Minimax Theorem for zero-sum games and the LP Duality Theorem connects cornerstone problems of the two fields of game theory and optimization, respectively, and has been the subject of intense scrutiny for seven decades. Yet, as observed in this paper, the proof of the difficult direction of this equivalence is unsatisfactory: It does not assign distinct roles to the two players of the game, as is natural from the definition of a zero-sum game.
  In retrospect, a partial resolution to this predicament was provided in another brilliant paper of von Neumann (1953), which reduced the assignment problem to zero-sum games. However, the underlying LP is highly specialized; all entries of its objective function vector are strictly positive and all entries of the constraint matrix and right hand side vector are equal to one.
  We generalize von Neumann's result along two directions, each allowing negative entries in certain parts of the LP. Our reductions make explicit the roles of the two players of the reduced game, namely their maximin strategies are to play optimal solutions to the primal and dual LPs. Furthermore, unlike previous reductions, the value of the reduced game reveals the value of the given LP. Our generalizations encompass several basic economic scenarios.
  We end by discussing evidence that von Neumann possessed an understanding of the notion of polynomial-time solvability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10767v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilan Adler, Martin Bullinger, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>On the Approximability of the Yolk in the Spatial Model of Voting</title>
      <link>https://arxiv.org/abs/2410.10788</link>
      <description>arXiv:2410.10788v1 Announce Type: new 
Abstract: In the spatial model of voting, the yolk and LP (linear programming) yolk are important solution concepts for predicting outcomes for a committee of voters. McKelvey and Tovey showed that the LP yolk provides a lower bound approximation for the size of the yolk and there has been considerable debate on whether the LP yolk is a good approximation of the yolk. In this paper, we show that for an odd number of voters in a two-dimensional space that the yolk radius is at most twice the size of the LP yolk radius. However, we also show that (1) even in this setting, the LP yolk center can be arbitrarily far away from the yolk center (relative to the radius of the yolk) and (2) for all other settings (an even number of voters or in dimension $k\geq 3$) that the LP yolk can be arbitrarily small relative to the yolk. Thus, in general, the LP yolk can be an arbitrarily poor approximation of the yolk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10788v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ran Hu, James P. Bailey</dc:creator>
    </item>
    <item>
      <title>Analyzing Wage Theft in Day Labor Markets via Principal Agent Models</title>
      <link>https://arxiv.org/abs/2410.09305</link>
      <description>arXiv:2410.09305v1 Announce Type: cross 
Abstract: In day labor markets, workers are particularly vulnerable to wage theft. This paper introduces a principal-agent model to analyze the conditions required to mitigate wage theft through fines and establishes the necessary and sufficient conditions to reduce theft. We find that the fines necessary to eliminate theft are significantly larger than those imposed by current labor laws, making wage theft likely to persist under penalty-based methods alone. Through numerical analysis, we show how wage theft disproportionately affects workers with lower reservation utilities and observe that workers with similar reservation utilities experience comparable impacts, regardless of their skill levels. To address the limitations of penalty-based approaches, we extend the model to a dynamic game incorporating worker awareness. We prove that wage theft can be fully eliminated if workers accurately predict theft using historical data and employers follow optimal fixed wage strategy. Additionally, sharing wage theft information becomes an effective long-term solution when employers use any given fixed wage strategies, emphasizing the importance of raising worker awareness through various channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09305v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James P. Bailey, Bahar Cavdar, Yanling Chang</dc:creator>
    </item>
    <item>
      <title>A Game-Theoretic Perspective for Efficient Modern Random Access</title>
      <link>https://arxiv.org/abs/2410.09588</link>
      <description>arXiv:2410.09588v1 Announce Type: cross 
Abstract: Modern random access mechanisms combine packet repetitions with multi-user detection mechanisms at the receiver to maximize the throughput and reliability in massive Internet of Things (IoT) scenarios. However, optimizing the access policy, which selects the number of repetitions, is a complicated problem, and failing to do so can lead to an inefficient use of resources and, potentially, to an increased congestion. In this paper, we follow a game-theoretic approach for optimizing the access policies of selfish users in modern random access mechanisms. Our goal is to find adequate values for the rewards given after a success to achieve a Nash equilibrium (NE) that optimizes the throughput of the system while considering the cost of transmission. Our results show that a mixed strategy, where repetitions are selected according to the irregular repetition slotted ALOHA (IRSA) protocol, attains a NE that maximizes the throughput in the special case with two users. In this scenario, our method increases the throughput by 30% when compared to framed ALOHA. Furthermore, we present three methods to attain a NE with near-optimal throughput for general modern random access scenarios, which exceed the throughput of framed ALOHA by up to 34%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09588v1</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>math.IT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Peter Juhl Hansen, Jeppe Roden M\"unster, Rasmus Erik Villadsen, Simon Bock Segaard, S{\o}ren Pilegaard Rasmussen, Christophe Biscio, Israel Leyva-Mayorga</dc:creator>
    </item>
    <item>
      <title>TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs</title>
      <link>https://arxiv.org/abs/2410.10479</link>
      <description>arXiv:2410.10479v1 Announce Type: cross 
Abstract: The rapid advancement of large language models (LLMs) has accelerated their application in reasoning, with strategic reasoning drawing increasing attention. To evaluate LLMs' strategic reasoning capabilities, game theory, with its concise structure, has become a preferred approach. However, current research focuses on a limited selection of games, resulting in low coverage. Classic game scenarios risk data leakage, and existing benchmarks often lack extensibility, making them inadequate for evaluating state-of-the-art models. To address these challenges, we propose TMGBench, a benchmark with comprehensive game type coverage, novel scenarios, and flexible organization. Specifically, we incorporate all 144 game types summarized by the Robinson-Goforth topology of 2x2 games, constructed as classic games. We also employ synthetic data generation to create diverse, higher-quality scenarios through topic guidance and human inspection, referred to as story-based games. Lastly, we provide a sustainable framework for increasingly powerful LLMs by treating these games as atomic units and organizing them into more complex forms via sequential, parallel, and nested structures. Our comprehensive evaluation of mainstream LLMs covers tests on rational reasoning, robustness, Theory-of-Mind (ToM), and reasoning in complex forms. Results reveal flaws in accuracy, consistency, and varying mastery of ToM. Additionally, o1-mini, OpenAI's latest reasoning model, achieved accuracy rates of 66.6%, 60.0%, and 70.0% on sequential, parallel, and nested games, highlighting TMGBench's challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10479v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haochuan Wang, Xiachong Feng, Lei Li, Zhanyue Qin, Dianbo Sui, Lingpeng Kong</dc:creator>
    </item>
    <item>
      <title>Optimal Scoring Rule Design under Partial Knowledge</title>
      <link>https://arxiv.org/abs/2107.07420</link>
      <description>arXiv:2107.07420v3 Announce Type: replace 
Abstract: This paper studies the design of optimal proper scoring rules when the principal has partial knowledge of an agent's signal distribution. Recent work characterizes the proper scoring rules that maximize the increase of an agent's payoff when the agent chooses to access a costly signal to refine a posterior belief from her prior prediction, under the assumption that the agent's signal distribution is fully known to the principal. In our setting, the principal only knows about a set of distributions where the agent's signal distribution belongs. We formulate the scoring rule design problem as a max-min optimization that maximizes the worst-case increase in payoff across the set of distributions.
  We propose an efficient algorithm to compute an optimal scoring rule when the set of distributions is finite, and devise a fully polynomial-time approximation scheme that accommodates various infinite sets of distributions. We further remark that widely used scoring rules, such as the quadratic and log rules, as well as previously identified optimal scoring rules under full knowledge, can be far from optimal in our partial knowledge settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.07420v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiling Chen, Fang-Yi Yu</dc:creator>
    </item>
    <item>
      <title>Beyond the worst case: Distortion in impartial culture electorates</title>
      <link>https://arxiv.org/abs/2307.07350</link>
      <description>arXiv:2307.07350v4 Announce Type: replace 
Abstract: {\em Distortion} is a well-established notion for quantifying the loss of social welfare that may occur in voting. As voting rules take as input only ordinal information, they are essentially forced to neglect the exact values the agents have for the alternatives. Thus, in worst-case electorates, voting rules may return low social welfare alternatives and have high distortion. Accompanying voting rules with a small number of cardinal queries per agent may reduce distortion considerably.
  To explore distortion beyond worst-case conditions, we use a simple stochastic model according to which the values the agents have for the alternatives are drawn independently from a common probability distribution. This gives rise to so-called {\em impartial culture electorates}. We refine the definition of distortion so that it is suitable for this stochastic setting and show that, rather surprisingly, all voting rules have high distortion {\em on average}. On the positive side, for the fundamental case where the agents have random {\em binary} values for the alternatives, we present a mechanism that achieves approximately optimal average distortion by making a {\em single} cardinal query per agent. This enables us to obtain slightly suboptimal average distortion bounds for general distributions using a simple randomized mechanism that makes one query per agent. We complement these results by presenting new tradeoffs between the distortion and the number of queries per agent in the traditional worst-case setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07350v4</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Karl Fehrs</dc:creator>
    </item>
    <item>
      <title>Active Inverse Learning in Stackelberg Trajectory Games</title>
      <link>https://arxiv.org/abs/2308.08017</link>
      <description>arXiv:2308.08017v3 Announce Type: replace 
Abstract: Game-theoretic inverse learning is the problem of inferring a player's objectives from their actions. We formulate an inverse learning problem in a Stackelberg game between a leader and a follower, where each player's action is the trajectory of a dynamical system. We propose an active inverse learning method for the leader to infer which hypothesis among a finite set of candidates best describes the follower's objective function. Instead of using passively observed trajectories like existing methods, we actively maximize the differences in the follower's trajectories under different hypotheses by optimizing the leader's control inputs. Compared with uniformly random inputs, the optimized inputs accelerate the convergence of the estimated probability of different hypotheses conditioned on the follower's trajectory. We demonstrate the proposed method in a receding-horizon repeated trajectory game and simulate the results using virtual TurtleBots in Gazebo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08017v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Ward, Yue Yu, Jacob Levy, Negar Mehr, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>When Should a Leader Act Suboptimally? The Role of Inferability in Repeated Stackelberg Games</title>
      <link>https://arxiv.org/abs/2310.00468</link>
      <description>arXiv:2310.00468v2 Announce Type: replace 
Abstract: When interacting with other decision-making agents in non-adversarial scenarios, it is critical for an autonomous agent to have inferable behavior: The agent's actions must convey their intention and strategy. We model the inferability problem using Stackelberg games with observations where a leader and a follower repeatedly interact. During the interactions, the leader uses a fixed mixed strategy. The follower does not know the leader's strategy and dynamically reacts to the statistically inferred strategy based on the leader's previous actions. In the inference setting, the leader may have a lower performance compared to the setting where the follower has full information on the leader's strategy. We refer to the performance gap between these settings as the inferability gap. For a variety of game settings, we show that the inferability gap is upper-bounded by a function of the number of interactions and the stochasticity level of the leader's strategy, encouraging the use of inferable strategies with lower stochasticity levels. We also analyze bimatrix Stackelberg games and identify a set of games where the leader's near-optimal strategy may suffer from a large inferability gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00468v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa O. Karabag, Sophia Smith, Negar Mehr, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Regret Minimization in Stackelberg Games with Side Information</title>
      <link>https://arxiv.org/abs/2402.08576</link>
      <description>arXiv:2402.08576v4 Announce Type: replace 
Abstract: Algorithms for playing in Stackelberg games have been deployed in real-world domains including airport security, anti-poaching efforts, and cyber-crime prevention. However, these algorithms often fail to take into consideration the additional information available to each player (e.g. traffic patterns, weather conditions, network congestion), which may significantly affect both players' optimal strategies. We formalize such settings as Stackelberg games with side information, in which both players observe an external context before playing. The leader commits to a (context-dependent) strategy, and the follower best-responds to both the leader's strategy and the context. We focus on the online setting in which a sequence of followers arrive over time, and the context may change from round-to-round. In sharp contrast to the non-contextual version, we show that it is impossible for the leader to achieve no-regret in the full adversarial setting. Motivated by this result, we show that no-regret learning is possible in two natural relaxations: the setting in which the sequence of followers is chosen stochastically and the sequence of contexts is adversarial, and the setting in which contexts are stochastic and follower types are adversarial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08576v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keegan Harris, Zhiwei Steven Wu, Maria-Florina Balcan</dc:creator>
    </item>
    <item>
      <title>$Proo\varphi$: A ZKP Market Mechanism</title>
      <link>https://arxiv.org/abs/2404.06495</link>
      <description>arXiv:2404.06495v3 Announce Type: replace 
Abstract: Zero-knowledge proofs (ZKPs) are computationally demanding to generate. Their importance for applications like ZK-Rollups has prompted some to outsource ZKP generation to a market of specialized provers. However, existing market designs either do not fit the ZKP setting or lack formal description and analysis.
  In this work, we propose a formal ZKP market model that captures the interactions between users submitting ZKP tasks and provers competing to generate proofs. Building on this model, we introduce $Proo\varphi$, an auction-based ZKP market mechanism. We prove that $Proo\varphi$ is incentive compatible for users and provers, and budget balanced. We augment $Proo\varphi$ with system-level designs to address the practical challenges of our setting, such as Sybil attacks, misreporting of prover capacity, and collusion. We analyze our system-level designs and show how they can mitigate the various security concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06495v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhao Wang, Lulu Zhou, Aviv Yaish, Fan Zhang, Ben Fisch, Benjamin Livshits</dc:creator>
    </item>
    <item>
      <title>Expectation in Stochastic Games with Prefix-independent Objectives</title>
      <link>https://arxiv.org/abs/2405.18048</link>
      <description>arXiv:2405.18048v2 Announce Type: replace 
Abstract: Stochastic two-player games model systems with an environment that is both adversarial and stochastic. In this paper, we study the expected value of quantitative prefix-independent objectives in stochastic games. We show a generic reduction from the expectation problem to linearly many instances of almost-sure satisfaction of threshold Boolean objectives. The result follows from partitioning the vertices of the game into so-called value classes where each class consists of vertices of the same value. Our procedure further entails that the memory required by both players to play optimally for the expectation problem is no more than the memory required by the players to play optimally for the almost-sure satisfaction problem for a corresponding threshold Boolean objective.
  We show the applicability of the framework to compute the expected window mean-payoff measure in stochastic games. The window mean-payoff measure strengthens the classical mean-payoff measure by computing the mean-payoff over a window of bounded length that slides along an infinite path. Two variants have been considered: in one variant, the maximum window length is fixed and given, while in the other, it is not fixed but is required to be bounded. For both variants, we show that the decision problem to check if the expected value is at least a given threshold is in UP $\cap$ coUP. The result follows from guessing the expected values of the vertices, partitioning them into value classes, and proving that a unique short certificate for the expected values exists. It also follows that the memory required by the players to play optimally is no more than that in non-stochastic two-player games with the corresponding window objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18048v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Doyen, Pranshu Gaba, Shibashis Guha</dc:creator>
    </item>
    <item>
      <title>Large Language Models Playing Mixed Strategy Nash Equilibrium Games</title>
      <link>https://arxiv.org/abs/2406.10574</link>
      <description>arXiv:2406.10574v2 Announce Type: replace 
Abstract: Generative artificial intelligence (Generative AI), and in particular Large Language Models (LLMs) have gained significant popularity among researchers and industrial communities, paving the way for integrating LLMs in different domains, such as robotics, telecom, and healthcare. In this paper, we study the intersection of game theory and generative artificial intelligence, focusing on the capabilities of LLMs to find the Nash equilibrium in games with a mixed strategy Nash equilibrium and no pure strategy Nash equilibrium (that we denote mixed strategy Nash equilibrium games). The study reveals a significant enhancement in the performance of LLMs when they are equipped with the possibility to run code and are provided with a specific prompt to incentivize them to do so. However, our research also highlights the limitations of LLMs when the randomization strategy of the game is not easy to deduce. It is evident that while LLMs exhibit remarkable proficiency in well-known standard games, their performance dwindles when faced with slight modifications of the same games. This paper aims to contribute to the growing body of knowledge on the intersection of game theory and generative artificial intelligence while providing valuable insights into LLMs strengths and weaknesses. It also underscores the need for further research to overcome the limitations of LLMs, particularly in dealing with even slightly more complex scenarios, to harness their full potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10574v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alonso Silva</dc:creator>
    </item>
    <item>
      <title>Information Design with Unknown Prior</title>
      <link>https://arxiv.org/abs/2410.05533</link>
      <description>arXiv:2410.05533v2 Announce Type: replace 
Abstract: Classical information design models (e.g., Bayesian persuasion and cheap talk) require players to have perfect knowledge of the prior distribution of the state of the world. Our paper studies repeated persuasion problems in which the information designer does not know the prior. The information designer learns to design signaling schemes from repeated interactions with the receiver. We design learning algorithms for the information designer to achieve no regret compared to using the optimal signaling scheme with known prior, under two models of the receiver's decision-making. (1) The first model assumes that the receiver knows the prior and can perform posterior update and best respond to signals. In this model, we design a learning algorithm for the information designer with $O(\log T)$ regret in the general case, and another algorithm with $\Theta(\log \log T)$ regret in the case where the receiver has only two actions. (2) The second model assumes that the receiver does not know the prior and employs a no-regret learning algorithm to take actions. We show that the information designer can achieve regret $O(\sqrt{\mathrm{rReg}(T) T})$, where $\mathrm{rReg}(T)=o(T)$ is an upper bound on the receiver's learning regret. Our work thus provides a learning foundation for the problem of information design with unknown prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05533v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Ce Li</dc:creator>
    </item>
  </channel>
</rss>
