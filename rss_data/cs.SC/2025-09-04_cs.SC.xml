<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 04:02:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving Polynomial Systems with Gr\"obner Bases: An Introduction to F4 and FGLM</title>
      <link>https://arxiv.org/abs/2509.03346</link>
      <description>arXiv:2509.03346v1 Announce Type: new 
Abstract: These notes originate from a reading course held by the authors in the spring of 2024 at the Universit\`a di Genova. They provide a hands-on introduction to the F4 and FGLM algorithms. In addition to the notes, we present two implementations of the algorithms: FGLM in CoCoALib and F4 in Sage. These implementations closely follow the structure of the algorithms as described here and are intended to help readers experiment with them in practice, thereby gaining a deeper understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03346v1</guid>
      <category>cs.SC</category>
      <category>math.AC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anna Maria Bigatti, Alessio Caminata, Tor Kristian Ellingsen, Evelina Lanteri, Andrea Sanguineti, Irene Villa</dc:creator>
    </item>
    <item>
      <title>Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained Large Language Models</title>
      <link>https://arxiv.org/abs/2509.03036</link>
      <description>arXiv:2509.03036v1 Announce Type: cross 
Abstract: Symbolic regression (SR) has emerged as a powerful tool for automated scientific discovery, enabling the derivation of governing equations from experimental data. A growing body of work illustrates the promise of integrating domain knowledge into the SR to improve the discovered equation's generality and usefulness. Physics-informed SR (PiSR) addresses this by incorporating domain knowledge, but current methods often require specialized formulations and manual feature engineering, limiting their adaptability only to domain experts. In this study, we leverage pre-trained Large Language Models (LLMs) to facilitate knowledge integration in PiSR. By harnessing the contextual understanding of LLMs trained on vast scientific literature, we aim to automate the incorporation of domain knowledge, reducing the need for manual intervention and making the process more accessible to a broader range of scientific problems. Namely, the LLM is integrated into the SR's loss function, adding a term of the LLM's evaluation of the SR's produced equation. We extensively evaluate our method using three SR algorithms (DEAP, gplearn, and PySR) and three pre-trained LLMs (Falcon, Mistral, and LLama 2) across three physical dynamics (dropping ball, simple harmonic motion, and electromagnetic wave). The results demonstrate that LLM integration consistently improves the reconstruction of physical dynamics from data, enhancing the robustness of SR models to noise and complexity. We further explore the impact of prompt engineering, finding that more informative prompts significantly improve performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03036v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.SC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bilge Taskin, Wenxiong Xie, Teddy Lazebnik</dc:creator>
    </item>
    <item>
      <title>Semi-Centennial REDUCE</title>
      <link>https://arxiv.org/abs/2505.01103</link>
      <description>arXiv:2505.01103v3 Announce Type: replace 
Abstract: We present a version of the REDUCE computer algebra system as it was in the early 1970s. We show how this historical version of REDUCE may be built and run in very modest present-day environments and outline some of its capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01103v3</guid>
      <category>cs.SC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur C. Norman, Stephen M. Watt</dc:creator>
    </item>
  </channel>
</rss>
