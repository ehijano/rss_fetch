<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 14 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Denoised IPW-Lasso for Heterogeneous Treatment Effect Estimation in Randomized Experiments</title>
      <link>https://arxiv.org/abs/2510.10527</link>
      <description>arXiv:2510.10527v1 Announce Type: new 
Abstract: This paper proposes a new method for estimating conditional average treatment effects (CATE) in randomized experiments. We adopt inverse probability weighting (IPW) for identification; however, IPW-transformed outcomes are known to be noisy, even when true propensity scores are used. To address this issue, we introduce a noise reduction procedure and estimate a linear CATE model using Lasso, achieving both accuracy and interpretability. We theoretically show that denoising reduces the prediction error of the Lasso. The method is particularly effective when treatment effects are small relative to the variability of outcomes, which is often the case in empirical applications. Applications to the Get-Out-the-Vote dataset and Criteo Uplift Modeling dataset demonstrate that our method outperforms fully nonparametric machine learning methods in identifying individuals with higher treatment effects. Moreover, our method uncovers informative heterogeneity patterns that are consistent with previous empirical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10527v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingqian Guan, Komei Fujita, Naoya Sueishi, Shota Yasui</dc:creator>
    </item>
    <item>
      <title>Identifying treatment effects on categorical outcomes in IV models</title>
      <link>https://arxiv.org/abs/2510.10946</link>
      <description>arXiv:2510.10946v1 Announce Type: new 
Abstract: This paper provides a nonparametric framework for causal inference with categorical outcomes under binary treatment and binary instrument settings. We decompose the observed joint probability of outcomes and treatment into marginal probabilities of potential outcomes and treatment, and association parameters that capture selection bias due to unobserved heterogeneity. Under a novel identifying assumption, association similarity, which requires the dependence between unobserved factors and potential outcomes to be invariant across treatment states, we achieve point identification of the full distribution of potential outcomes. Recognizing that this assumption may be strong in some contexts, we propose two weaker alternatives: monotonic association, which restricts the direction of selection heterogeneity, and bounded association, which constrains its magnitude. These relaxed assumptions deliver sharp partial identification bounds that nest point identification as a special case and facilitate transparent sensitivity analysis. We illustrate the framework in an empirical application, estimating the causal effect of private health insurance on health outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10946v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Onil Boussim</dc:creator>
    </item>
    <item>
      <title>Macroeconomic Forecasting and Machine Learning</title>
      <link>https://arxiv.org/abs/2510.11008</link>
      <description>arXiv:2510.11008v1 Announce Type: new 
Abstract: We forecast the full conditional distribution of macroeconomic outcomes by systematically integrating three key principles: using high-dimensional data with appropriate regularization, adopting rigorous out-of-sample validation procedures, and incorporating nonlinearities. By exploiting the rich information embedded in a large set of macroeconomic and financial predictors, we produce accurate predictions of the entire profile of macroeconomic risk in real time. Our findings show that regularization via shrinkage is essential to control model complexity, while introducing nonlinearities yields limited improvements in predictive accuracy. Out-of-sample validation plays a critical role in selecting model architecture and preventing overfitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11008v1</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ta-Chung Chi (Kevin), Ting-Han Fan (Kevin), Raffaele M. Ghigliazza (Kevin), Domenico Giannone (Kevin),  Zixuan (Kevin),  Wang</dc:creator>
    </item>
    <item>
      <title>Spatial and Temporal Boundaries in Difference-in-Differences: A Framework from Navier-Stokes Equation</title>
      <link>https://arxiv.org/abs/2510.11013</link>
      <description>arXiv:2510.11013v1 Announce Type: new 
Abstract: This paper develops a unified framework for identifying spatial and temporal boundaries of treatment effects in difference-in-differences designs. Starting from fundamental fluid dynamics equations (Navier-Stokes), we derive conditions under which treatment effects decay exponentially in space and time, enabling researchers to calculate explicit boundaries beyond which effects become undetectable. The framework encompasses both linear (pure diffusion) and nonlinear (advection-diffusion with chemical reactions) regimes, with testable scope conditions based on dimensionless numbers from physics (P\'eclet and Reynolds numbers). We demonstrate the framework's diagnostic capability using air pollution from coal-fired power plants. Analyzing 791 ground-based PM$_{2.5}$ monitors and 189,564 satellite-based NO$_2$ grid cells in the Western United States over 2019-2021, we find striking regional heterogeneity: within 100 km of coal plants, both pollutants show positive spatial decay (PM$_{2.5}$: $\kappa_s = 0.00200$, $d^* = 1,153$ km; NO$_2$: $\kappa_s = 0.00112$, $d^* = 2,062$ km), validating the framework. Beyond 100 km, negative decay parameters correctly signal that urban sources dominate and diffusion assumptions fail. Ground-level PM$_{2.5}$ decays approximately twice as fast as satellite column NO$_2$, consistent with atmospheric transport physics. The framework successfully diagnoses its own validity in four of eight analyzed regions, providing researchers with physics-based tools to assess whether their spatial difference-in-differences setting satisfies diffusion assumptions before applying the estimator. Our results demonstrate that rigorous boundary detection requires both theoretical derivation from first principles and empirical validation of underlying physical assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11013v1</guid>
      <category>econ.EM</category>
      <category>econ.GN</category>
      <category>math.ST</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Superstars or Super-Villains? Productivity Spillovers and Firm Dynamics in Indonesia</title>
      <link>https://arxiv.org/abs/2510.11139</link>
      <description>arXiv:2510.11139v1 Announce Type: new 
Abstract: Do industrial "superstars" help others up or crowd them out? We examine the relationship between the spillovers of superstar firms (those with the top market share in their industry) and the productivity dynamics in Indonesia. Employing data on Indonesian manufacturing firms from 2001 to 2015, we find that superstar exposures in the market raise both the productivity level and the growth of non-superstar firms through horizontal (within a sector-province) and vertical (across sectors) channels. When we distinguish by ownership, foreign superstars consistently encourage productivity except through the horizontal channel. In contrast, domestic superstars generate positive spillovers through both horizontal and vertical linkages, indicating that foreign firms do not solely drive positive externalities. Furthermore, despite overall productivity growth being positive in 2001-2015, the source of negative growth is mainly driven by within-group reallocation, evidence of misallocation among surviving firms, notably by domestic superstars. Although Indonesian superstar firms are more efficient in their operations, their relatively modest growth rates suggest a potential stagnation, which can be plausibly attributed to limited innovation activity or a slow pace of adopting new technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11139v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Zeqi Yasin</dc:creator>
    </item>
    <item>
      <title>Compositional difference-in-differences for categorical outcomes</title>
      <link>https://arxiv.org/abs/2510.11659</link>
      <description>arXiv:2510.11659v1 Announce Type: new 
Abstract: In difference-in-differences (DiD) settings with categorical outcomes, treatment effects often operate on both total quantities (e.g., voter turnout) and category shares (e.g., vote distribution across parties). In this context, linear DiD models can be problematic: they suffer from scale dependence, may produce negative counterfactual quantities, and are inconsistent with discrete choice theory. We propose compositional DiD (CoDiD), a new method that identifies counterfactual categorical quantities, and thus total levels and shares, under a parallel growths assumption. The assumption states that, absent treatment, each category's size grows or shrinks at the same proportional rate in treated and control groups. In a random utility framework, we show that this implies parallel evolution of relative preferences between any pair of categories. Analytically, we show that it also means the shares are reallocated in the same way in both groups in the absence of treatment. Finally, geometrically, it corresponds to parallel trajectories (or movements) of probability mass functions of the two groups in the probability simplex under Aitchison geometry. We extend CoDiD to i) derive bounds under relaxed assumptions, ii) handle staggered adoption, and iii) propose a synthetic DiD analog. We illustrate the method's empirical relevance through two applications: first, we examine how early voting reforms affect voter choice in U.S. presidential elections; second, we analyze how the Regional Greenhouse Gas Initiative (RGGI) affected the composition of electricity generation across sources such as coal, natural gas, nuclear, and renewables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11659v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Onil Boussim</dc:creator>
    </item>
    <item>
      <title>A mathematical model for pricing perishable goods for quick-commerce applications</title>
      <link>https://arxiv.org/abs/2510.11360</link>
      <description>arXiv:2510.11360v1 Announce Type: cross 
Abstract: Quick commerce (q-commerce) is one of the fastest growing sectors in India. It provides informal employment to approximately 4,50,000 workers, and it is estimated to become a USD 200 Billion industry by 2026. A significant portion of this industry deals with perishable goods. (e.g. milk, dosa batter etc.) These are food items which are consumed relatively fresh by the consumers and therefore their order volume is high and repetitive even when the average basket size is relatively small. The fundamental challenge for the retailer is that, increasing selling price would hamper sales and would lead to unsold inventory. On the other hand setting a price less, would lead to forgoing of potential revenue. This paper attempts to propose a mathematical model which formalizes this dilemma. The problem statement is not only important for improving the unit economics of the perennially loss making quick commerce firms, but also would lead to a trickle-down effect in improving the conditions of the gig workers as observed in [4]. The sections below describe the mathematical formulation. The results from the simulation would be published in a follow-up study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11360v1</guid>
      <category>cs.CE</category>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milon Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Estimating Continuous Treatment Effects in Panel Data using Machine Learning with a Climate Application</title>
      <link>https://arxiv.org/abs/2207.08789</link>
      <description>arXiv:2207.08789v3 Announce Type: replace 
Abstract: Economists often estimate continuous treatment effects in panel data using linear two-way fixed effects models (TWFE). When the treatment-outcome relationship is nonlinear, TWFE is misspecifed and potentially biased for the average partial derivative (APD). We develop an automatic double/de-biased machine learning (ADML) estimator that is consistent for the population APD while allowing additive unit fixed effects, nonlinearities, and high dimensional heterogeneity. We prove asymptotic normality and add two refinements - optimization based de-biasing and analytic derivatives - that reduce bias and remove numerical approximation error. Simulations show that the proposed method outperforms high order polynomial OLS and standard ML estimators. Our estimator leads to significantly larger (by 50%), but equally precise, estimates of the effect of extreme heat on corn yield compared to standard linear models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.08789v3</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sylvia Klosin, Max Vilgalys</dc:creator>
    </item>
    <item>
      <title>Quantifying the Internal Validity of Weighted Estimands</title>
      <link>https://arxiv.org/abs/2404.14603</link>
      <description>arXiv:2404.14603v4 Announce Type: replace 
Abstract: In this paper we study a class of weighted estimands, which we define as parameters that can be expressed as weighted averages of the underlying heterogeneous treatment effects. The popular ordinary least squares (OLS), two-stage least squares (2SLS), and two-way fixed effects (TWFE) estimands are all special cases within our framework. Our focus is on answering two questions concerning weighted estimands. First, under what conditions can they be interpreted as the average treatment effect for some (possibly latent) subpopulation? Second, when these conditions are satisfied, what is the upper bound on the size of that subpopulation, either in absolute terms or relative to a target population of interest? We argue that this upper bound provides a valuable diagnostic for empirical research. When a given weighted estimand corresponds to the average treatment effect for a small subset of the population of interest, we say its internal validity is low. Our paper develops practical tools to quantify the internal validity of weighted estimands. We also apply these tools to revisit a prominent study of the effects of unilateral divorce laws on female suicide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14603v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Poirier, Tymon S{\l}oczy\'nski</dc:creator>
    </item>
    <item>
      <title>Difference-in-differences with as few as two cross-sectional units -- A new perspective to the democracy-growth debate</title>
      <link>https://arxiv.org/abs/2408.13047</link>
      <description>arXiv:2408.13047v4 Announce Type: replace 
Abstract: Pooled panel analyses often mask heterogeneity in unit-specific treatment effects. This challenge, for example, crops up in studies of the impact of democracy on economic growth, where findings vary substantially due to differences in country composition. To address this challenge, this paper introduces a Difference-in-Differences (DiD) estimator that leverages temporal variation in the data to estimate unit-specific average treatment effects on the treated (ATT) with as few as two cross-sectional units. Under weak identification and temporal dependence conditions, the proposed DiD estimator is shown to be asymptotically normal. The method is further complemented with an identification test that, unlike pre-trends tests, is more powerful and can detect violations of parallel trends in post-treatment periods. Empirical results using the DiD estimator suggest Benin's economy would have been 6.3% smaller on average over the 1993-2018 period had she not democratised.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13047v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gilles Koumou, Emmanuel Selorm Tsyawo</dc:creator>
    </item>
    <item>
      <title>Inference on effect size after multiple hypothesis testing</title>
      <link>https://arxiv.org/abs/2503.22369</link>
      <description>arXiv:2503.22369v2 Announce Type: replace 
Abstract: Significant treatment effects are often emphasized when interpreting and summarizing empirical findings in studies that estimate multiple, possibly many, treatment effects. Under this kind of selective reporting, conventional treatment effect estimates may be biased and their corresponding confidence intervals may undercover the true effect sizes. We propose new estimators and confidence intervals that provide valid inferences on the effect sizes of the significant effects after multiple hypothesis testing. Our methods are based on the principle of selective conditional inference and complement a wide range of tests, including step-up tests and bootstrap-based step-down tests. Our approach is scalable, allowing us to study an application with over 370 estimated effects. We justify our procedure for asymptotically normal treatment effect estimators. We provide two empirical examples that demonstrate bias correction and confidence interval adjustments for significant effects. The magnitude and direction of the bias correction depend on the correlation structure of the estimated effects and whether the interpretation of the significant effects depends on the (in)significance of other effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22369v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andreas Dzemski, Ryo Okui, Wenjie Wang</dc:creator>
    </item>
    <item>
      <title>Partial Identification of Mean Achievement in ILSA Studies with Multi-Stage Stratified Sample Design and Student Non-Participation</title>
      <link>https://arxiv.org/abs/2504.01209</link>
      <description>arXiv:2504.01209v2 Announce Type: replace 
Abstract: International large-scale assessment (ILSA) studies collect information across education systems with the objective of learning about the population-wide distribution of student achievement in the assessment. In this article, we study one of the most fundamental threats that these studies face when justifying the conclusions reached about these distributions: the identification problem that arises from student non-participation during data collection. Recognizing that ILSA studies have traditionally employed a narrow range of strategies to address non-participation, we examine this problem using tools developed within the framework of partial identification of probability distributions. We tailor this framework to the problem of non-participation when data are collected using a multi-stage stratified random sample design, as in most ILSA studies. We demonstrate this approach with application to the International Computer and Information Literacy Study in 2018. We show how to use the framework to assess mean achievement under reasonable and credible sets of assumptions about the non-participating population. We also provide examples of how these results may be reported by agencies that administer ILSA studies. By doing so, we bring to the field of ILSA an alternative strategy for identification, estimation, and reporting of population parameters of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01209v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Cortes, Jeff Dominitz, Maximiliano Romero</dc:creator>
    </item>
    <item>
      <title>Dimension Reduction for Conditional Density Estimation with Applications to High-Dimensional Causal Inference</title>
      <link>https://arxiv.org/abs/2507.22312</link>
      <description>arXiv:2507.22312v2 Announce Type: replace 
Abstract: We propose a novel and computationally efficient approach for nonparametric conditional density estimation in high-dimensional settings that achieves dimension reduction without imposing restrictive distributional or functional form assumptions. To uncover the underlying sparsity structure of the data, we develop an innovative conditional dependence measure and a modified cross-validation procedure that enables data-driven variable selection, thereby circumventing the need for subjective threshold selection. We demonstrate the practical utility of our dimension-reduced conditional density estimation by applying it to doubly robust estimators for average treatment effects. Notably, our proposed procedure is able to select relevant variables for nonparametric propensity score estimation and also inherently reduce the dimensionality of outcome regressions through a refined ignorability condition. We evaluate the finite-sample properties of our approach through comprehensive simulation studies and an empirical study on the effects of 401(k) eligibility on savings using SIPP data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22312v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianhua Mei, Fu Ouyang, Thomas T. Yang</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Spatial and Temporal Treatment Effect Boundaries: Theory and Identification</title>
      <link>https://arxiv.org/abs/2510.00754</link>
      <description>arXiv:2510.00754v2 Announce Type: replace 
Abstract: This paper develops a unified theoretical framework for detecting and estimating boundaries in treatment effects across both spatial and temporal dimensions. We formalize the concept of treatment effect boundaries as structural parameters characterizing regime transitions where causal effects cease to operate. Building on reaction-diffusion models of information propagation, we establish conditions under which spatial and temporal boundaries share common dynamics governed by diffusion parameters (delta, lambda), yielding the testable prediction d^*/tau^* = 3.32 lambda sqrt{delta} for standard detection thresholds. We derive formal identification results under staggered treatment adoption and develop a three-stage estimation procedure implementable with standard panel data. Monte Carlo simulations demonstrate excellent finite-sample performance, with boundary estimates achieving RMSE below 10% in realistic configurations. We apply the framework to two empirical settings: EU broadband diffusion (2006-2021) and US wildfire economic impacts (2017-2022). The broadband application reveals a scope limitation -- our framework assumes depreciation dynamics and fails when effects exhibit increasing returns through network externalities. The wildfire application provides strong validation: estimated boundaries satisfy d^* = 198 km and tau^* = 2.7 years, with the empirical ratio (72.5) exactly matching the theoretical prediction 3.32 lambda sqrt{delta} = 72.5. The framework provides practical tools for detecting when localized treatments become systemic and identifying critical thresholds for policy intervention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00754v2</guid>
      <category>econ.EM</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Blackwell without Priors</title>
      <link>https://arxiv.org/abs/2510.08709</link>
      <description>arXiv:2510.08709v2 Announce Type: replace-cross 
Abstract: This paper proposes a fully prior-free model of experimentation in which the decision maker observes the entire distribution of signals generated by a known experiment under an unknown distribution of the state of the world. One experiment is robustly more informative than another if the decision maker's maxmin expected utility after observing the output of the former is always at least her maxmin expected utility after observing the latter. We show that this ranking holds if and only if the less informative experiment is a linear transformation of the more informative experiment; equivalently, the null space of the more informative experiment is a subset of the null space of the less informative experiment. Our criterion is implied by Blackwell's order but does not imply it, and we show by example that our ranking admits strictly more comparable pairs of experiments than the classical ranking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08709v2</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxwell Rosenthal</dc:creator>
    </item>
  </channel>
</rss>
