<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Oct 2024 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Packing-Inspired Algorithms for Periodic Scheduling Problems with Harmonic Periods</title>
      <link>https://arxiv.org/abs/2410.14756</link>
      <description>arXiv:2410.14756v1 Announce Type: new 
Abstract: We tackle the problem of non-preemptive periodic scheduling with a harmonic set of periods. Problems of this kind arise within domains of periodic manufacturing and maintenance, and also during the design of industrial, automotive, and avionics communication protocols, where efficient scheduling of messages is crucial for the performance of a time-triggered network. We consider the decision variant of the periodic scheduling problem on a single highly-utilized machine. We first prove a bijection between periodic scheduling and a particular (so-called height-divisible) 2D packing of rectangles. We formulate the problem using Constraint Programming and compare it with equivalent state-of-the-art Integer Linear Programming formulation, showing the former's superiority on difficult instances. Furthermore, we develop a packing-inspired first fit heuristic, which we compare with methods described in the literature. We justify our proposed methods on synthetically generated problem instances inspired by the communication of messages on one channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14756v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Josef Grus, Claire Hanen, Zden\v{e}k Hanz\'alek</dc:creator>
    </item>
    <item>
      <title>Efficient Matroid Intersection via a Batch-Update Auction Algorithm</title>
      <link>https://arxiv.org/abs/2410.14901</link>
      <description>arXiv:2410.14901v1 Announce Type: new 
Abstract: Given two matroids $\mathcal{M}_1$ and $\mathcal{M}_2$ over the same $n$-element ground set, the matroid intersection problem is to find a largest common independent set, whose size we denote by $r$. We present a simple and generic auction algorithm that reduces $(1-\varepsilon)$-approximate matroid intersection to roughly $1/\varepsilon^2$ rounds of the easier problem of finding a maximum-weight basis of a single matroid. Plugging in known primitives for this subproblem, we obtain both simpler and improved algorithms in two models of computation, including:
  * The first near-linear time/independence-query $(1-\varepsilon)$-approximation algorithm for matroid intersection. Our randomized algorithm uses $\tilde{O}(n/\varepsilon + r/\varepsilon^5)$ independence queries, improving upon the previous $\tilde{O}(n/\varepsilon + r\sqrt{r}/{\varepsilon^3})$ bound of Quanrud (2024).
  * The first sublinear exact parallel algorithms for weighted matroid intersection, using $O(n^{2/3})$ rounds of rank queries or $O(n^{5/6})$ rounds of independence queries. For the unweighted case, our results improve upon the previous $O(n^{3/4})$-round rank-query and $O(n^{7/8})$-round independence-query algorithms of Blikstad (2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14901v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joakim Blikstad, Ta-Wei Tu</dc:creator>
    </item>
    <item>
      <title>The Constrained Layer Tree Problem and Applications to Solar Farm Cabling</title>
      <link>https://arxiv.org/abs/2410.15031</link>
      <description>arXiv:2410.15031v1 Announce Type: new 
Abstract: Motivated by the cabling of solar farms, we study the problem Constrained Layer Tree. At its core, it asks whether there exists a tree that connects a set of sources (the leaves) to one sink (the root) such that certain capacity constraints at the inner nodes are satisfied. Our main algorithmic contribution is a dynamic program with various optimizations for Constrained Layer Tree. It outperforms the previously used MILP by multiple orders of magnitude. Moreover, our experiments show that the somewhat abstract problem Constrained Layer Tree is actually the core of the cabling problem in solar farms, i.e., the feasible solution produced by our dynamic program can be used to bootstrap an MILP that can then find good solutions for the original cabling problem efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15031v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Bl\"asius, Max G\"ottlicher, Sascha Gritzbach, Wendy Yi</dc:creator>
    </item>
    <item>
      <title>A Simplified Parameterized Algorithm for Directed Feedback Vertex Set</title>
      <link>https://arxiv.org/abs/2410.15411</link>
      <description>arXiv:2410.15411v1 Announce Type: new 
Abstract: The Directed Feedback Vertex Set problem (DFVS) asks whether it is possible to remove at most $k$ vertices from a directed graph to make it acyclic. Whether DFVS is fixed-parameter tractable was a long-standing open problem in parameterized complexity until it was solved by Chen et al. in 2008 (STOC 2008). Now the running-time bound of this problem is improved to $\mathcal O(k!4^kk^5(n+m))$ (Lokshtanov et al, SODA 2018), where $n$ and $m$ are the numbers of vertices and arcs in the graph. In this paper, we simplify one crucial step in all previous parameterized algorithms for DFVS, which is to solve the compression version of the problem, and refine the running-time bound for DFVS to $\mathcal O(k!2^{o(k)}(n+m))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15411v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziliang Xiong, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Timetable Nodes for Public Transport Network</title>
      <link>https://arxiv.org/abs/2410.15715</link>
      <description>arXiv:2410.15715v1 Announce Type: new 
Abstract: Faster pathfinding in time-dependent transport networks is an important and challenging problem in navigation systems. There are two main types of transport networks: road networks for car driving and public transport route network. The solutions that work well in road networks, such as Time-dependent Contraction Hierarchies and other graph-based approaches, do not usually apply in transport networks. In transport networks, non-graph solutions such as CSA and RAPTOR show the best results compared to graph-based techniques. In our work, we propose a method that advances graph-based approaches by using different optimization techniques from computational geometry to speed up the search process in transport networks. We apply a new pre-computation step, which we call timetable nodes (TTN). Our inspiration comes from an iterative search problem in computational geometry. We implement two versions of the TTN: one uses a Combined Search Tree (TTN-CST), and the second uses Fractional Cascading (TTN-FC). Both of these approaches decrease the asymptotic complexity of reaching new nodes from $O(k\times \log|C|)$ to $O(k + \log(k) + \log(|C|))$, where $k$ is the number of outgoing edges from a node and $|C|$ is the size of the timetable information (total outgoing edges). Our solution suits any other time-dependent networks and can be integrated into other pathfinding algorithms. Our experiments indicate that this pre-computation significantly enhances the performance on high-density graphs. This study showcases how leveraging computational geometry can enhance pathfinding in transport networks, enabling faster pathfinding in scenarios involving large numbers of outgoing edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15715v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrii Rohovyi, Peter J. Stuckey, Toby Walsh</dc:creator>
    </item>
    <item>
      <title>A Simpler Approach for Monotone Parametric Minimum Cut: Finding the Breakpoints in Order</title>
      <link>https://arxiv.org/abs/2410.15920</link>
      <description>arXiv:2410.15920v1 Announce Type: new 
Abstract: We present parametric breadth-first search (PBFS), a new algorithm for solving the parametric minimum cut problem in a network with source-sink-monotone capacities. The objective is to find the set of breakpoints, i.e., the points at which the minimum cut changes. It is well known that this problem can be solved in the same asymptotic runtime as the static minimum cut problem. However, existing algorithms that achieve this runtime bound involve fairly complicated steps that are inefficient in practice. PBFS uses a simpler approach that discovers the breakpoints in ascending order, which allows it to achieve the desired runtime bound while still performing well in practice. We evaluate our algorithm on benchmark instances from polygon aggregation and computer vision. Polygon aggregation was recently proposed as an application for parametric minimum cut, but the monotonicity property has not been exploited fully. PBFS outperforms the state of the art on most benchmark instances, usually by a factor of 2-3. It is particularly strong on instances with many breakpoints, which is the case for polygon aggregation. Compared to the existing min-cut-based approach for polygon aggregation, PBFS scales much better with the instance size. On large instances with millions of vertices, it is able to compute all breakpoints in a matter of seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15920v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arne Beines, Michael Kaibel, Philip Mayer, Petra Mutzel, Jonas Sauer</dc:creator>
    </item>
    <item>
      <title>Relating Left and Right Extensions of Maximal Repeats</title>
      <link>https://arxiv.org/abs/2410.15958</link>
      <description>arXiv:2410.15958v1 Announce Type: new 
Abstract: The compact directed acyclic word graph (CDAWG) of a string $T$ is an index occupying $O(\mathsf{e})$ space, where $\mathsf{e}$ is the number of right extensions of maximal repeats in $T$. For highly repetitive datasets, the measure $\mathsf{e}$ typically is small compared to the length $n$ of $T$ and, thus, the CDAWG serves as a compressed index. Unlike other compressibility measures (as LZ77, string attractors, BWT runs, etc.), $\mathsf{e}$ is very unstable with respect to reversals: the CDAWG of the reversed string $\overset{{}_{\leftarrow}}{T} = T[n] \cdots T[2] T[1]$ has size $O(\overset{{}_{\leftarrow}}{\mathsf{e}})$, where $\overset{{}_{\leftarrow}}{\mathsf{e}}$ is the number of left extensions of maximal repeats in $T$, and there are strings $T$ with $\frac{\overset{{}_{\leftarrow}}{\mathsf{e}}}{\mathsf{e}} \in \Omega(\sqrt{n})$. In this note, we prove that this lower bound is tight: $\frac{\overset{{}_{\leftarrow}}{\mathsf{e}}}{\mathsf{e}} \in O(\sqrt{n})$. Furthermore, given the alphabet size $\sigma$, we establish the alphabet-dependent bound $\frac{\overset{{}_{\leftarrow}}{\mathsf{e}}}{\mathsf{e}} \le \min\{\frac{2n}{\sigma}, \sigma\}$ and we show that it is asymptotically tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15958v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunsuke Inenaga, Dmitry Kosolobov</dc:creator>
    </item>
    <item>
      <title>Streaming and Communication Complexity of Load-Balancing via Matching Contractors</title>
      <link>https://arxiv.org/abs/2410.16094</link>
      <description>arXiv:2410.16094v1 Announce Type: new 
Abstract: In the load-balancing problem, we have an $n$-vertex bipartite graph $G=(L, R, E)$ between a set of clients and servers. The goal is to find an assignment of all clients to the servers, while minimizing the maximum load on each server, where load of a server is the number of clients assigned to it. We study load-balancing in the one-way communication model: the edges of the input graph are partitioned between Alice and Bob, and Alice needs to send a message to Bob for him to output the solution.
  We show that settling the one-way communication complexity of load-balancing is equivalent to a natural sparsification problem for load-balancing. We then prove a dual interpretation of this sparsifier, showing that the minimum density of a sparsifier is effectively the same as the maximum density one can achieve for an extremal graph family that is new to this paper, called Matching-Contractors; these graphs are intimately connected to the well-known Ruzsa-Szemeredi graphs and generalize them in certain aspects. Our chain of equivalences thus shows that the one-way communication complexity of load-balancing can be reduced to a purely graph theoretic question: what is the maximum density of a Matching-Contractor on $n$ vertices?
  Finally, we present a novel combinatorial construction of some-what dense Matching-Contractors, which implies a strong one-way communication lower bound for load-balancing: any one-way protocol (even randomized) with $\tilde{O}(n)$ communication cannot achieve a better than $n^{\frac14-o(1)}$-approximation. Previously, no non-trivial lower bounds were known for protocols with even $O(n\log{n})$ bits of communication. Our result also implies the first non-trivial lower bounds for semi-streaming load-balancing in the edge-arrival model, ruling out $n^{\frac14-o(1)}$-approximation in a single-pass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16094v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Aaron Bernstein, Zachary Langley, Lap Chi Lau, Robert Wang</dc:creator>
    </item>
    <item>
      <title>Fair Division in a Variable Setting</title>
      <link>https://arxiv.org/abs/2410.14421</link>
      <description>arXiv:2410.14421v1 Announce Type: cross 
Abstract: We study the classic problem of fairly dividing a set of indivisible items among a set of agents and consider the popular fairness notion of envy-freeness up to one item (EF1). While in reality, the set of agents and items may vary, previous works have studied static settings, where no change can occur in the system. We initiate and develop a formal model to understand fair division under the variable input setting: here, there is an EF1 allocation that gets disrupted because of the loss/deletion of an item, or the arrival of a new agent, resulting in a near-EF1 allocation. The objective is to perform a sequence of transfers of items between agents to regain EF1 fairness by traversing only via near-EF1 allocations. We refer to this as the EF1-Restoration problem.
  In this work, we present algorithms for the above problem when agents have identical monotone valuations, and items are either all goods or all chores. Both of these algorithms achieve an optimal number of transfers (at most $m/n$, where $m$ and $n$ are the number of items and agents respectively) for identical additive valuations. Next, we consider a valuation class with graphical structure, introduced by Christodoulou et al. (EC'23), where each item is valued by at most two agents, and hence can be seen as an edge between these two agents in a graph. Here, we consider EF1 orientations on (multi)graphs - allocations in which each item is allocated to an agent who values it. While considering EF1 orientations on multi-graphs with additive binary valuations, we present an optimal algorithm for the EF1-Restoration problem. Finally, for monotone binary valuations, we show that the problem of deciding whether EF1-Restoration is possible is PSPACE-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14421v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish Chandramouleeswaran, Prajakta Nimbhorkar, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Slipstream: Ebb-and-Flow Consensus on a DAG with Fast Confirmation for UTXO Transactions</title>
      <link>https://arxiv.org/abs/2410.14876</link>
      <description>arXiv:2410.14876v1 Announce Type: cross 
Abstract: This paper introduces Slipstream, a Byzantine Fault Tolerance (BFT) protocol where nodes concurrently propose blocks to be added to a Directed Acyclic Graph (DAG) and aim to agree on block ordering. Slipstream offers two types of block orderings: an optimistic ordering, which is live and secure in a sleepy model under up to 50% Byzantine nodes, and a final ordering, which is a prefix of the optimistic ordering and ensures safety and liveness in an eventual lock-step synchronous model under up to 33% Byzantine nodes. Additionally, Slipstream integrates a payment system that allows for fast UTXO transaction confirmation independently of block ordering. Transactions are confirmed in three rounds during synchrony, and unconfirmed double spends are resolved in a novel way using the DAG structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14876v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Polyanskii, Sebastian Muller, Mayank Raikwar</dc:creator>
    </item>
    <item>
      <title>Finite matrix multiplication algorithms from infinite groups</title>
      <link>https://arxiv.org/abs/2410.14905</link>
      <description>arXiv:2410.14905v1 Announce Type: cross 
Abstract: The Cohn-Umans (FOCS '03) group-theoretic framework for matrix multiplication produces fast matrix multiplication algorithms from three subsets of a finite group $G$ satisfying a simple combinatorial condition (the Triple Product Property). The complexity of such an algorithm then depends on the representation theory of $G$. In this paper we extend the group-theoretic framework to the setting of infinite groups. In particular, this allows us to obtain constructions in Lie groups, with favorable parameters, that are provably impossible in finite groups of Lie type (Blasiak, Cohn, Grochow, Pratt, and Umans, ITCS '23). Previously the Lie group setting was investigated purely as an analogue of the finite group case; a key contribution in this paper is a fully developed framework for obtaining bona fide matrix multiplication algorithms directly from Lie group constructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14905v1</guid>
      <category>math.GR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonah Blasiak, Henry Cohn, Joshua A. Grochow, Kevin Pratt, Chris Umans</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Algorithms for the Bahncard Problem</title>
      <link>https://arxiv.org/abs/2410.15257</link>
      <description>arXiv:2410.15257v1 Announce Type: cross 
Abstract: In this paper, we study learning-augmented algorithms for the Bahncard problem. The Bahncard problem is a generalization of the ski-rental problem, where a traveler needs to irrevocably and repeatedly decide between a cheap short-term solution and an expensive long-term one with an unknown future. Even though the problem is canonical, only a primal-dual-based learning-augmented algorithm was explicitly designed for it. We develop a new learning-augmented algorithm, named PFSUM, that incorporates both history and short-term future to improve online decision making. We derive the competitive ratio of PFSUM as a function of the prediction error and conduct extensive experiments to show that PFSUM outperforms the primal-dual-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15257v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hailiang Zhao, Xueyan Tang, Peng Chen, Shuiguang Deng</dc:creator>
    </item>
    <item>
      <title>Improved Explicit Near-Optimal Codes in the High-Noise Regimes</title>
      <link>https://arxiv.org/abs/2410.15506</link>
      <description>arXiv:2410.15506v1 Announce Type: cross 
Abstract: We study uniquely decodable codes and list decodable codes in the high-noise regime, specifically codes that are uniquely decodable from $\frac{1-\varepsilon}{2}$ fraction of errors and list decodable from $1-\varepsilon$ fraction of errors. We present several improved explicit constructions that achieve near-optimal rates, as well as efficient or even linear-time decoding algorithms. Our contributions are as follows.
  1. Explicit Near-Optimal Linear Time Uniquely Decodable Codes: We construct a family of explicit $\mathbb{F}_2$-linear codes with rate $\Omega(\varepsilon)$ and alphabet size $2^{\mathrm{poly} \log(1/\varepsilon)}$, that are capable of correcting $e$ errors and $s$ erasures whenever $2e + s &lt; (1 - \varepsilon)n$ in linear-time.
  2. Explicit Near-Optimal List Decodable Codes: We construct a family of explicit list decodable codes with rate $\Omega(\varepsilon)$ and alphabet size $2^{\mathrm{poly} \log(1/\varepsilon)}$, that are capable of list decoding from $1-\varepsilon$ fraction of errors with a list size $L = \exp\exp\exp(\log^{\ast}n)$ in polynomial time.
  3. List Decodable Code with Near-Optimal List Size: We construct a family of explicit list decodable codes with an optimal list size of $O(1/\varepsilon)$, albeit with a suboptimal rate of $O(\varepsilon^2)$, capable of list decoding from $1-\varepsilon$ fraction of errors in polynomial time. Furthermore, we introduce a new combinatorial object called multi-set disperser, and use it to give a family of list decodable codes with near-optimal rate $\frac{\varepsilon}{\log^2(1/\varepsilon)}$ and list size $\frac{\log^2(1/\varepsilon)}{\varepsilon}$, that can be constructed in probabilistic polynomial time and decoded in deterministic polynomial time.
  We also introduce new decoding algorithms that may prove valuable for other graph-based codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15506v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Songtao Mao</dc:creator>
    </item>
    <item>
      <title>Perpetual maintenance of machines with different urgency requirements</title>
      <link>https://arxiv.org/abs/2202.01567</link>
      <description>arXiv:2202.01567v3 Announce Type: replace 
Abstract: A garden $G$ is populated by $n\ge 1$ bamboos $b_1, b_2, ..., b_n$ with the respective daily growth rates $h_1 \ge h_2 \ge \dots \ge h_n$. It is assumed that the initial heights of bamboos are zero. The robotic gardener maintaining the garden regularly attends bamboos and trims them to height zero according to some schedule. The Bamboo Garden Trimming Problem (BGT) is to design a perpetual schedule of cuts to maintain the elevation of the bamboo garden as low as possible. The bamboo garden is a metaphor for a collection of machines which have to be serviced, with different frequencies, by a robot which can service only one machine at a time. The objective is to design a perpetual schedule of servicing which minimizes the maximum (weighted) waiting time for servicing.
  We consider two variants of BGT. In discrete BGT the robot trims only one bamboo at the end of each day. In continuous BGT the bamboos can be cut at any time, however, the robot needs time to move from one bamboo to the next.
  For discrete BGT, we show tighter approximation algorithms for the case when the growth rates are balanced and for the general case. The former algorithm settles one of the conjectures about the Pinwheel problem. The general approximation algorithm improves on the previous best approximation ratio. For continuous BGT, we propose approximation algorithms which achieve approximation ratios $O(\log \lceil h_1/h_n\rceil)$ and $O(\log n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.01567v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leszek G\k{a}sieniec, Tomasz Jurdzi\'nski, Ralf Klasing, Christos Levcopoulos, Andrzej Lingas, Jie Min, Tomasz Radzik</dc:creator>
    </item>
    <item>
      <title>Online Paging with Heterogeneous Cache Slots</title>
      <link>https://arxiv.org/abs/2206.05579</link>
      <description>arXiv:2206.05579v4 Announce Type: replace 
Abstract: It is natural to generalize the online $k$-Server problem by allowing each request to specify not only a point $p$, but also a subset $S$ of servers that may serve it. For uniform metrics, the problem is equivalent to a generalization of Paging in which each request specifies not only a page $p$, but also a subset $S$ of cache slots, and is satisfied by having a copy of $p$ in some slot in $S$. We call this problem Slot-Heterogenous Paging.
  We parameterize the problem by specifying a family $\mathcal S \subseteq 2^{[k]}$ of requestable slot sets, and we establish bounds on the competitive ratio as a function of the cache size $k$ and family $\mathcal S$:
  - If all request sets are allowed ($\mathcal S=2^{[k]}\setminus\{\emptyset\}$), the optimal deterministic and randomized competitive ratios are exponentially worse than for standard \Paging ($\mathcal S=\{[k]\}$).
  - As a function of $|\mathcal S|$ and $k$, the optimal deterministic ratio is polynomial: at most $O(k^2|\mathcal S|)$ and at least $\Omega(\sqrt{|\mathcal S|})$.
  - For any laminar family $\mathcal S$ of height $h$, the optimal ratios are $O(hk)$ (deterministic) and $O(h^2\log k)$ (randomized).
  - The special case of laminar $\mathcal S$ that we call All-or-One Paging extends standard Paging by allowing each request to specify a specific slot to put the requested page in. The optimal deterministic ratio for weighted All-or-One Paging is $\Theta(k)$. Offline All-or-One Paging is NP-hard.
  Some results for the laminar case are shown via a reduction to the generalization of Paging in which each request specifies a set $\mathcal P of pages, and is satisfied by fetching any page from $\mathcal P into the cache. The optimal ratios for the latter problem (with laminar family of height $h$) are at most $hk$ (deterministic) and $h\,H_k$ (randomized).</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05579v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00453-024-01270-z</arxiv:DOI>
      <arxiv:journal_reference>Algorithmica (2004)</arxiv:journal_reference>
      <dc:creator>Marek Chrobak, Samuel Haney, Mehraneh Liaee, Debmalya Panigrahi, Rajmohan Rajaraman, Ravi Sundaram, Neal E. Young</dc:creator>
    </item>
    <item>
      <title>Vital Edges for (s,t)-mincut: Efficient Algorithms, Compact Structures, and Optimal Sensitivity Oracle</title>
      <link>https://arxiv.org/abs/2310.12096</link>
      <description>arXiv:2310.12096v4 Announce Type: replace 
Abstract: Let G be a directed weighted graph (DiGraph) on n vertices and m edges with source s and sink t. An edge in G is vital if its removal reduces the capacity of (s,t)-mincut. Since the seminal work of Ford and Fulkerson, a long line of work has been done on computing the most vital edge and all vital edges of G. Unfortunately, after 60 years, the existing results are for undirected or unweighted graphs. We present the following result for DiGraph, which solves an open problem stated by Ausiello et al.
  1. There is an algorithm that computes all vital edges as well as the most vital edge of G using O(n) maxflow computations.
  Vital edges play a crucial role in the design of Sensitivity Oracle (SO) for (s,t)-mincut. For directed graphs, the only existing SO is for unweighted graphs by Picard and Queyranne. We present the first and optimal SO for DiGraph.
  2. (a) There is an O(n) space SO that can report in O(1) time the capacity of (s,t)-mincut and (b) an O($n^2$) space SO that can report an (s,t)-mincut in O(n) time after failure/insertion of an edge.
  For unweighted graphs, Picard and Queyranne designed an O(m) space DAG that stores and characterizes all mincuts for all vital edges. Conversely, there is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge belongs to the set. We generalize these results for DiGraph.
  3. (a) There is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge is present in the set. (b) We design two compact structures for storing and characterizing all mincuts for all vital edges, (i) O(m) space DAG for partial characterization and (ii) O(mn) space structure for complete characterization.
  To arrive at our results, we develop new techniques, especially a generalization of maxflow-mincut theorem by Ford and Fulkerson, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12096v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Surender Baswana, Koustav Bhanja</dc:creator>
    </item>
    <item>
      <title>Approximating Unrelated Machine Weighted Completion Time Using Iterative Rounding and Computer Assisted Proofs</title>
      <link>https://arxiv.org/abs/2404.04773</link>
      <description>arXiv:2404.04773v2 Announce Type: replace 
Abstract: We revisit the unrelated machine scheduling problem with the weighted completion time objective. It is known that independent rounding achieves a 1.5 approximation for the problem, and many prior algorithms improve upon this ratio by leveraging strong negative correlation schemes. On each machine $i$, these schemes introduce strong negative correlation between events that some pairs of jobs are assigned to $i$, while maintaining non-positive correlation for all pairs.
  Our algorithm deviates from this methodology by relaxing the pairwise non-positive correlation requirement. On each machine $i$, we identify many groups of jobs. For a job $j$ and a group $B$ not containing $j$, we only enforce non-positive correlation between $j$ and the group as a whole, allowing $j$ to be positively-correlated with individual jobs in $B$. This relaxation suffices to maintain the 1.5-approximation, while enabling us to obtain a much stronger negative correlation within groups using an iterative rounding procedure: at most one job from each group is scheduled on $i$.
  We prove that the algorithm achieves a $(1.36 + \epsilon)$-approximation, improving upon the previous best approximation ratio of $1.4$ due to Harris. While the improvement may not be substantial, the significance of our contribution lies in the relaxed non-positive correlation condition and the iterative rounding framework. Due to the simplicity of our algorithm, we are able to derive a closed form for the weighted completion time our algorithm achieves with a clean analysis. Unfortunately, we could not provide a good analytical analysis for the quantity; instead, we rely on a computer assisted proof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04773v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shi Li</dc:creator>
    </item>
    <item>
      <title>Unweighted Layered Graph Traversal: Passing a Crown via Entropy Maximization</title>
      <link>https://arxiv.org/abs/2404.16176</link>
      <description>arXiv:2404.16176v2 Announce Type: replace 
Abstract: Introduced by Papadimitriou and Yannakakis in 1989, layered graph traversal is a central problem in online algorithms and mobile computing that has been studied for several decades, and which now is essentially resolved in its original formulation. In this paper, we demonstrate that what appears to be an innocuous modification of the problem actually leads to a drastic (exponential) reduction of the competitive ratio. Specifically, we present an algorithm that is $O(\log^2 w)$-competitive for traversing unweighted layered graphs of width $w$. Our algorithm chooses the agent's position simply according to the probability distribution over the current layer that maximizes the sum of entropies of the induced distributions in the preceding layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16176v2</guid>
      <category>cs.DS</category>
      <category>math.MG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingjian Bai, Christian Coester, Romain Cosson</dc:creator>
    </item>
    <item>
      <title>More Asymmetry Yields Faster Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2404.16349</link>
      <description>arXiv:2404.16349v2 Announce Type: replace 
Abstract: We present a new improvement on the laser method for designing fast matrix multiplication algorithms. The new method further develops the recent advances by [Duan, Wu, Zhou FOCS 2023] and [Vassilevska Williams, Xu, Xu, Zhou SODA 2024]. Surprisingly the new improvement is achieved by incorporating more asymmetry in the analysis, circumventing a fundamental tool of prior work that requires two of the three dimensions to be treated identically. The method yields a new bound on the square matrix multiplication exponent $$\omega&lt;2.371339,$$ improved from the previous bound of $\omega&lt;2.371552$. We also improve the bounds of the exponents for multiplying rectangular matrices of various shapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16349v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josh Alman, Ran Duan, Virginia Vassilevska Williams, Yinzhan Xu, Zixuan Xu, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Engineering Optimal Parallel Task Scheduling</title>
      <link>https://arxiv.org/abs/2405.15371</link>
      <description>arXiv:2405.15371v2 Announce Type: replace 
Abstract: The NP-hard scheduling problem P||C_max encompasses a set of tasks with known execution time which must be mapped to a set of identical machines such that the overall completion time is minimized. In this work, we improve existing techniques for optimal P||C_max scheduling with a combination of new theoretical insights and careful practical engineering. Most importantly, we derive techniques to prune vast portions of the search space of branch-and-bound (BnB) approaches. We also propose improved upper and lower bounding techniques which can be combined with any approach to P||C_max. Moreover, we present new benchmarks for P||C_max, based on diverse application data, which can shed light on aspects which prior synthetic instances fail to capture. In an extensive evaluation, we observe that our pruning techniques reduce the number of explored nodes by 90$\times$ and running times by 12$\times$. Compared to a state-of-the-art ILP-based approach, our approach is preferable for short running time limits and for instances with large makespans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15371v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Akram, Nikolai Maas, Peter Sanders, Dominik Schreiber</dc:creator>
    </item>
    <item>
      <title>Massively Parallel Ruling Set Made Deterministic</title>
      <link>https://arxiv.org/abs/2406.12727</link>
      <description>arXiv:2406.12727v2 Announce Type: replace 
Abstract: We study the deterministic complexity of the $2$-Ruling Set problem in the model of Massively Parallel Computation (MPC) with linear and strongly sublinear local memory.
  Linear MPC: We present a constant-round deterministic algorithm for the $2$-Ruling Set problem that matches the randomized round complexity recently settled by Cambus, Kuhn, Pai, and Uitto [DISC'23], and improves upon the deterministic $O(\log \log n)$-round algorithm by Pai and Pemmaraju [PODC'22]. Our main ingredient is a simpler analysis of CKPU's algorithm based solely on bounded independence, which makes its efficient derandomization possible.
  Sublinear MPC: We present a deterministic algorithm that computes a $2$-Ruling Set in $\tilde O(\sqrt{\log n})$ rounds deterministically. Notably, this is the first deterministic ruling set algorithm with sublogarithmic round complexity, improving on the $O(\log \Delta + \log \log^* n)$-round complexity that stems from the deterministic MIS algorithm of Czumaj, Davies, and Parter [TALG'21]. Our result is based on a simple and fast randomness-efficient construction that achieves the same sparsification as that of the randomized $\tilde O(\sqrt{\log n})$-round LOCAL algorithm by Kothapalli and Pemmaraju [FSTTCS'12].</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12727v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeff Giliberti, Zahra Parsaeian</dc:creator>
    </item>
    <item>
      <title>Improved Bounds for Fully Dynamic Matching via Ordered Ruzsa-Szemeredi Graphs</title>
      <link>https://arxiv.org/abs/2406.13573</link>
      <description>arXiv:2406.13573v2 Announce Type: replace 
Abstract: In a very recent breakthrough, Behnezhad and Ghafari [FOCS'24] developed a novel fully dynamic randomized algorithm for maintaining a $(1-\epsilon)$-approximation of maximum matching with amortized update time potentially much better than the trivial $O(n)$ update time. The runtime of the BG algorithm is parameterized via the following graph theoretical concept:
  * For any $n$, define $ORS(n)$ -- standing for Ordered RS Graph -- to be the largest number of edge-disjoint matchings $M_1,\ldots,M_t$ of size $\Theta(n)$ in an $n$-vertex graph such that for every $i \in [t]$, $M_i$ is an induced matching in the subgraph $M_{i} \cup M_{i+1} \cup \ldots \cup M_t$.
  Then, for any fixed $\epsilon &gt; 0$, the BG algorithm runs in \[
  O\left( \sqrt{n^{1+O(\epsilon)} \cdot ORS(n)} \right) \] amortized update time with high probability, even against an adaptive adversary. $ORS(n)$ is a close variant of a more well-known quantity regarding RS graphs (which require every matching to be induced regardless of the ordering). It is currently only known that $n^{o(1)} \leqslant ORS(n) \leqslant n^{1-o(1)}$, and closing this gap appears to be a notoriously challenging problem.
  In this work, we further strengthen the result of Behnezhad and Ghafari and push it to limit to obtain a randomized algorithm with amortized update time of \[
  n^{o(1)} \cdot ORS(n) \] with high probability, even against an adaptive adversary. In the limit, i.e., if current lower bounds for $ORS(n) = n^{o(1)}$ are almost optimal, our algorithm achieves an $n^{o(1)}$ update time for $(1-\epsilon)$-approximation of maximum matching, almost fully resolving this fundamental question. In its current stage also, this fully reduces the algorithmic problem of designing dynamic matching algorithms to a purely combinatorial problem of upper bounding $ORS(n)$ with no algorithmic considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13573v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Sanjeev Khanna, Peter Kiss</dc:creator>
    </item>
    <item>
      <title>A Statistical View of Column Subset Selection</title>
      <link>https://arxiv.org/abs/2307.12892</link>
      <description>arXiv:2307.12892v2 Announce Type: replace-cross 
Abstract: We consider the problem of selecting a small subset of representative variables from a large dataset. In the computer science literature, this dimensionality reduction problem is typically formalized as Column Subset Selection (CSS). Meanwhile, the typical statistical formalization is to find an information-maximizing set of Principal Variables. This paper shows that these two approaches are equivalent, and moreover, both can be viewed as maximum likelihood estimation within a certain semi-parametric model. Within this model, we establish suitable conditions under which the CSS estimate is consistent in high dimensions, specifically in the proportional asymptotic regime where the number of variables over the sample size converges to a constant. Using these connections, we show how to efficiently (1) perform CSS using only summary statistics from the original dataset; (2) perform CSS in the presence of missing and/or censored data; and (3) select the subset size for CSS in a hypothesis testing framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12892v2</guid>
      <category>stat.ME</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anav Sood, Trevor Hastie</dc:creator>
    </item>
    <item>
      <title>Exponential quantum advantages for practical non-Hermitian eigenproblems</title>
      <link>https://arxiv.org/abs/2401.12091</link>
      <description>arXiv:2401.12091v2 Announce Type: replace-cross 
Abstract: While non-Hermitian physics has attracted considerable attention, current studies are limited to small or classically solvable systems. Quantum computing, as a powerful eigensolver, have predominantly been applied to Hermitian domain, leaving their potential for studying non-Hermitian problems largely unexplored. We extend the power of quantum computing to general non-Hermitian eigenproblems. Our approach works for finding eigenvalues without extra constrains, or eigenvalues closest to specified points or lines, thus extending results for ground energy and energy gap problems for Hermitian matrices. Our algorithms have broad applications, and as examples, we consider two central problems in non-Hermitian physics. Firstly, our approach is the first to offer an efficient quantum solution to the witness of spontaneous $PT$-symmetry breaking, and provide provable, exponential quantum advantage. Secondly, our approach enables the estimation of Liouvillian gap, which is crucial for characterizing relaxation times. Our general approach can also find applications in many other areas, such as the study of Markovian stochastic processes. These results underscore the significance of our quantum algorithms for addressing practical eigenproblems across various disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12091v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Ming Zhang, Yukun Zhang, Wenhao He, Xiao Yuan</dc:creator>
    </item>
  </channel>
</rss>
