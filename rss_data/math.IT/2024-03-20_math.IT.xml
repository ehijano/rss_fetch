<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Mar 2024 04:01:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 21 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-objective Optimization for Data Collection in UAV-assisted Agricultural IoT</title>
      <link>https://arxiv.org/abs/2403.12985</link>
      <description>arXiv:2403.12985v1 Announce Type: new 
Abstract: The ground fixed base stations (BSs) are often deployed inflexibly, and have high overheads, as well as are susceptible to the damage from natural disasters, making it impractical for them to continuously collect data from sensor devices. To improve the network coverage and performance of wireless communication, unmanned aerial vehicles (UAVs) have been introduced in diverse wireless networks, therefore in this work we consider employing a UAV as an aerial BS to acquire data of agricultural Internet of Things (IoT) devices. To this end, we first formulate a UAV-assisted data collection multi-objective optimization problem (UDCMOP) to efficiently collect the data from agricultural sensing devices. Specifically, we aim to collaboratively optimize the hovering positions of UAV, visit sequence of UAV, speed of UAV, in addition to the transmit power of devices, to simultaneously achieve the maximization of minimum transmit rate of devices, the minimization of total energy consumption of devices, and the minimization of total energy consumption of UAV. Second, the proposed UDCMOP is a non-convex mixed integer nonlinear optimization problem, which indicates that it includes continuous and discrete solutions, making it intractable to be solved. Therefore, we solve it by proposing an improved multi-objective artificial hummingbird algorithm (IMOAHA) with several specific improvement factors, that are the hybrid initialization operator, Cauchy mutation foraging operator, in addition to the discrete mutation operator. Finally, simulations are carried out to testify that the proposed IMOAHA can effectively improve the system performance comparing to other benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12985v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingling Liu, Aimin Wang, Geng Sun, Jiahui Li, Hongyang Pan, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Local Approximation of Secrecy Capacity</title>
      <link>https://arxiv.org/abs/2403.13345</link>
      <description>arXiv:2403.13345v1 Announce Type: new 
Abstract: This paper uses Euclidean Information Theory (EIT) to analyze the wiretap channel. We investigate a scenario of efficiently transmitting a small amount of information subject to compression rate and secrecy constraints. We transform the information-theoretic problem into a linear algebra problem and obtain the perturbed probability distributions such that secrecy is achievable. Local approximations are being used in order to obtain an estimate of the secrecy capacity by solving a generalized eigenvalue problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13345v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emmanouil M. Athanasakos, Nicholas Kalouptsidis, Hariprasad Manjunath</dc:creator>
    </item>
    <item>
      <title>Construction of Minimal Binary Linear Codes of dimension $n+3$</title>
      <link>https://arxiv.org/abs/2403.13350</link>
      <description>arXiv:2403.13350v1 Announce Type: new 
Abstract: In this paper, we will give the generic construction of a binary linear code of dimension $n+3$ and derive the necessary and sufficient conditions for the constructed code to be minimal. Using generic construction, a new family of minimal binary linear code will be constructed from a special class of Boolean functions violating the Ashikhmin-Barg condition. We also obtain the weight distribution of the constructed minimal binary linear code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13350v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wajid M. Shaikh, Rupali S. Jain, B. Surendranath Reddy, Bhagyashri S. Patil</dc:creator>
    </item>
    <item>
      <title>Massive MIMO CSI Feedback using Channel Prediction: How to Avoid Machine Learning at UE?</title>
      <link>https://arxiv.org/abs/2403.13363</link>
      <description>arXiv:2403.13363v1 Announce Type: new 
Abstract: In the literature, machine learning (ML) has been implemented at the base station (BS) and user equipment (UE) to improve the precision of downlink channel state information (CSI). However, ML implementation at the UE can be infeasible for various reasons, such as UE power consumption. Motivated by this issue, we propose a CSI learning mechanism at BS, called CSILaBS, to avoid ML at UE. To this end, by exploiting channel predictor (CP) at BS, a light-weight predictor function (PF) is considered for feedback evaluation at the UE. CSILaBS reduces over-the-air feedback overhead, improves CSI quality, and lowers the computation cost of UE. Besides, in a multiuser environment, we propose various mechanisms to select the feedback by exploiting PF while aiming to improve CSI accuracy. We also address various ML-based CPs, such as NeuralProphet (NP), an ML-inspired statistical algorithm. Furthermore, inspired to use a statistical model and ML together, we propose a novel hybrid framework composed of a recurrent neural network and NP, which yields better prediction accuracy than individual models. The performance of CSILaBS is evaluated through an empirical dataset recorded at Nokia Bell-Labs. The outcomes show that ML elimination at UE can retain performance gains, for example, precoding quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13363v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3376633</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Wireless Communications, 2024</arxiv:journal_reference>
      <dc:creator>Muhammad Karam Shehzad, Luca Rose, Mohamad Assaad</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Enabled Interference Network: Joint Antenna Position and Beamforming Design</title>
      <link>https://arxiv.org/abs/2403.13573</link>
      <description>arXiv:2403.13573v1 Announce Type: new 
Abstract: This paper investigates the utility of movable antenna (MA) assistance for the multiple-input single-output (MISO) interference channel. We exploit an additional design degree of freedom provided by MA to enhance the desired signal and suppress interference so as to reduce the total transmit power of interference network. To this end, we jointly optimize the MA positions and transmit beamforming, subject to the signal-to-interference-plus-noise ratio constraints of users. To address the non-convex optimization problem, we propose an efficient iterative algorithm to alternately optimize the MA positions via successive convex approximation method and the transmit beamforming via second-order cone program approach. Numerical results demonstrate that the proposed MA-enabled MISO interference network outperforms its conventional counterpart without MA, which significantly enhances the capability of inter-cell frequency reuse and reduces the complexity of transmitter design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13573v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Honghao Wang, Qingqing Wu, Wen Chen</dc:creator>
    </item>
    <item>
      <title>MIMO Channel as a Neural Function: Implicit Neural Representations for Extreme CSI Compression in Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2403.13615</link>
      <description>arXiv:2403.13615v1 Announce Type: new 
Abstract: Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology. Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process. Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations. Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains. Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm. Modulations are then applied to a shared base network to generate the elements of the CSI matrix. Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios. Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13615v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haotian Wu, Maojun Zhang, Yulin Shao, Krystian Mikolajczyk, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>A Multi-Task Oriented Semantic Communication Framework for Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2403.12997</link>
      <description>arXiv:2403.12997v1 Announce Type: cross 
Abstract: Task-oriented semantic communication is an emerging technology that transmits only the relevant semantics of a message instead of the whole message to achieve a specific task. It reduces latency, compresses the data, and is more robust in low SNR scenarios. This work presents a multi-task-oriented semantic communication framework for connected and autonomous vehicles (CAVs). We propose a convolutional autoencoder (CAE) that performs the semantic encoding of the road traffic signs. These encoded images are then transmitted from one CAV to another CAV through satellite in challenging weather conditions where visibility is impaired. In addition, we propose task-oriented semantic decoders for image reconstruction and classification tasks. Simulation results show that the proposed framework outperforms the conventional schemes, such as QAM-16, regarding the reconstructed image's similarity and the classification's accuracy. In addition, it can save up to 89 % of the bandwidth by sending fewer bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12997v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eslam Eldeeb, Mohammad Shehab, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>Syntropy in complex systems: A complement to Shannon's Entropy</title>
      <link>https://arxiv.org/abs/2403.13022</link>
      <description>arXiv:2403.13022v1 Announce Type: cross 
Abstract: This study introduces the syntropy function ($S_N$) and expectancy function ($E_N$), derived from the novel function $\phi$, to provide a refined perspective on complexity, extending beyond conventional entropy analysis. $S_N$ is designed to detect localized coherent events, whereas $E_N$ encapsulates expected system behaviors, offering a comprehensive framework for understanding system dynamics. The manuscript explores essential theorems and properties, underscoring their theoretical and practical implications. Future research will further elucidate their roles, particularly in biological signals and dynamic systems, suggesting a deep interplay between order and chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13022v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Santiago Mendez-Moreno</dc:creator>
    </item>
    <item>
      <title>Towards Better Statistical Understanding of Watermarking LLMs</title>
      <link>https://arxiv.org/abs/2403.13027</link>
      <description>arXiv:2403.13027v1 Announce Type: cross 
Abstract: In this paper, we study the problem of watermarking large language models (LLMs). We consider the trade-off between model distortion and detection ability and formulate it as a constrained optimization problem based on the green-red algorithm of Kirchenbauer et al. (2023a). We show that the optimal solution to the optimization problem enjoys a nice analytical property which provides a better understanding and inspires the algorithm design for the watermarking process. We develop an online dual gradient ascent watermarking algorithm in light of this optimization formulation and prove its asymptotic Pareto optimality between model distortion and detection ability. Such a result guarantees an averaged increased green list probability and henceforth detection ability explicitly (in contrast to previous results). Moreover, we provide a systematic discussion on the choice of the model distortion metrics for the watermarking problem. We justify our choice of KL divergence and present issues with the existing criteria of ``distortion-free'' and perplexity. Finally, we empirically evaluate our algorithms on extensive datasets against benchmark algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13027v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongze Cai, Shang Liu, Hanzhao Wang, Huaiyang Zhong, Xiaocheng Li</dc:creator>
    </item>
    <item>
      <title>Extremality of stabilizer states</title>
      <link>https://arxiv.org/abs/2403.13632</link>
      <description>arXiv:2403.13632v1 Announce Type: cross 
Abstract: We investigate the extremality of stabilizer states to reveal their exceptional role in the space of all $n$-qubit/qudit states. We establish uncertainty principles for the characteristic function and the Wigner function of states, respectively. We find that only stabilizer states achieve saturation in these principles. Furthermore, we prove a general theorem that stabilizer states are extremal for convex information measures invariant under local unitaries. We explore this extremality in the context of various quantum information and correlation measures, including entanglement entropy, conditional entropy and other entanglement measures. Additionally, leveraging the recent discovery that stabilizer states are the limit states under quantum convolution, we establish the monotonicity of the entanglement entropy and conditional entropy under quantum convolution. These results highlight the remarkable information-theoretic properties of stabilizer states. Their extremality provides valuable insights into their ability to capture information content and correlations, paving the way for further exploration of their potential in quantum information processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13632v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaifeng Bu</dc:creator>
    </item>
    <item>
      <title>Near-Field Beam Training: Joint Angle and Range Estimation with DFT Codebook</title>
      <link>https://arxiv.org/abs/2309.11872</link>
      <description>arXiv:2309.11872v3 Announce Type: replace 
Abstract: Prior works on near-field beam training have mostly assumed dedicated polar-domain codebook and on-grid range estimation, which, however, may suffer long training overhead and degraded estimation accuracy. To address these issues, we propose in this paper new and efficient beam training schemes with off-grid range estimation by using conventional discrete Fourier transform (DFT) codebook. Specifically, we first analyze the received beam pattern at the user when far-field beamforming vectors are used for beam scanning, and show an interesting result that this beam pattern contains useful user angle and range information. Then, we propose two efficient schemes to jointly estimate the user angle and range with the DFT codebook. The first scheme estimates the user angle based on a defined angular support and resolves the user range by leveraging an approximated angular support width, while the second scheme estimates the user range by minimizing a power ratio mean square error (MSE) to improve the range estimation accuracy. Finally, numerical simulations show that our proposed schemes greatly reduce the near-field beam training overhead and improve the range estimation accuracy as compared to various benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11872v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xun Wu, Changsheng You, Jiapeng Li, Yunpu Zhang</dc:creator>
    </item>
    <item>
      <title>Multispreads</title>
      <link>https://arxiv.org/abs/2312.07883</link>
      <description>arXiv:2312.07883v3 Announce Type: replace 
Abstract: Additive one-weight codes over a finite field of non-prime order are equivalent to special subspace coverings of the points of projective space, which we call multispreads. The current paper is devoted to the characterization of the parameters of multispreads, which is equivalent to the characterization of the parameters of additive one-weight codes. We characterize these parameters for the case of the prime-square order of the field and make a partial characterization for the prime-cube case and the case of the fourth degree of a prime (including a complete characterization for orders 8, 27, and 16).</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07883v3</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denis S. Krotov, Ivan Yu. Mogilnykh</dc:creator>
    </item>
    <item>
      <title>Assembly Theory is an approximation to algorithmic complexity based on LZ compression that does not explain selection or evolution</title>
      <link>https://arxiv.org/abs/2403.06629</link>
      <description>arXiv:2403.06629v4 Announce Type: replace 
Abstract: We demonstrate that Assembly Theory, pathway complexity, the assembly index, and the assembly number are subsumed and constitute a weak version of algorithmic (Kolmogorov-Solomonoff-Chaitin) complexity reliant on an approximation method based upon statistical compression, their results obtained due to the use of methods strictly equivalent to the LZ family of compression algorithms used in compressing algorithms such as ZIP, GZIP, or JPEG. Such popular algorithms have been shown to empirically reproduce the results of AT that were reported before in successful application to separating organic from non-organic molecules and in the context of the study of selection and evolution. We prove the connections and full equivalence of Assembly Theory to Shannon Entropy and statistical compression, and AT's disconnection as a statistical approach from causality. We demonstrate that formulating a traditional statistically compressed description of molecules, or the theory underlying it, does not imply an explanation or quantification of biases in generative (physical or biological) processes, including those brought about by selection and evolution, when lacking in logical consistency and empirical evidence. We argue that in their basic arguments, the authors of AT conflate how objects may assemble with causal directionality, and conclude that Assembly Theory does not explain selection or evolution beyond known and previously established connections, some of which are reviewed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06629v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe S. Abrah\~ao, Santiago Hern\'andez-Orozco, Narsis A. Kiani, Jesper Tegn\'er, Hector Zenil</dc:creator>
    </item>
    <item>
      <title>Quantum-inspired identification of complex cellular automata</title>
      <link>https://arxiv.org/abs/2103.14053</link>
      <description>arXiv:2103.14053v2 Announce Type: replace-cross 
Abstract: Elementary cellular automata (ECA) present iconic examples of complex systems. Though described only by one-dimensional strings of binary cells evolving according to nearest-neighbour update rules, certain ECA rules manifest complex dynamics capable of universal computation. Yet, the classification of precisely which rules exhibit complex behaviour remains a significant challenge. Here we approach this question using tools from quantum stochastic modelling, where quantum statistical memory -- the memory required to model a stochastic process using a class of quantum machines -- can be used to quantify the structure of a stochastic process. By viewing ECA rules as transformations of stochastic patterns, we ask: Does an ECA generate structure as quantified by the quantum statistical memory, and if so, how quickly? We illustrate how the growth of this measure over time correctly distinguishes simple ECA from complex counterparts. Moreover, it provides a more refined means for quantitatively identifying complex ECAs -- providing a spectrum on which we can rank the complexity of ECA by the rate in which they generate structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.14053v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>nlin.CG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1140/epjp/s13360-023-04160-5</arxiv:DOI>
      <arxiv:journal_reference>Eur. Phys. J. Plus 138 (6) 540 (2023)</arxiv:journal_reference>
      <dc:creator>Matthew Ho, Andri Pradana, Thomas J. Elliott, Lock Yue Chew, Mile Gu</dc:creator>
    </item>
    <item>
      <title>PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2210.17159</link>
      <description>arXiv:2210.17159v2 Announce Type: replace-cross 
Abstract: Aside from graph neural networks (GNNs) attracting significant attention as a powerful framework revolutionizing graph representation learning, there has been an increasing demand for explaining GNN models. Although various explanation methods for GNNs have been developed, most studies have focused on instance-level explanations, which produce explanations tailored to a given graph instance. In our study, we propose Prototype-bAsed GNN-Explainer (PAGE), a novel model-level GNN explanation method that explains what the underlying GNN model has learned for graph classification by discovering human-interpretable prototype graphs. Our method produces explanations for a given class, thus being capable of offering more concise and comprehensive explanations than those of instance-level explanations. First, PAGE selects embeddings of class-discriminative input graphs on the graph-level embedding space after clustering them. Then, PAGE discovers a common subgraph pattern by iteratively searching for high matching node tuples using node-level embeddings via a prototype scoring function, thereby yielding a prototype graph as our explanation. Using six graph classification datasets, we demonstrate that PAGE qualitatively and quantitatively outperforms the state-of-the-art model-level explanation method. We also carry out systematic experimental studies by demonstrating the relationship between PAGE and instance-level explanation methods, the robustness of PAGE to input data scarce environments, and the computational efficiency of the proposed prototype scoring function in PAGE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17159v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong-Min Shin, Sun-Woo Kim, Won-Yong Shin</dc:creator>
    </item>
    <item>
      <title>Machine-learning optimized measurements of chaotic dynamical systems via the information bottleneck</title>
      <link>https://arxiv.org/abs/2311.04896</link>
      <description>arXiv:2311.04896v2 Announce Type: replace-cross 
Abstract: Deterministic chaos permits a precise notion of a "perfect measurement" as one that, when obtained repeatedly, captures all of the information created by the system's evolution with minimal redundancy. Finding an optimal measurement is challenging, and has generally required intimate knowledge of the dynamics in the few cases where it has been done. We establish an equivalence between a perfect measurement and a variant of the information bottleneck. As a consequence, we can employ machine learning to optimize measurement processes that efficiently extract information from trajectory data. We obtain approximately optimal measurements for multiple chaotic maps and lay the necessary groundwork for efficient information extraction from general time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04896v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kieran A. Murphy, Dani S. Bassett</dc:creator>
    </item>
    <item>
      <title>Span-Based Optimal Sample Complexity for Average Reward MDPs</title>
      <link>https://arxiv.org/abs/2311.13469</link>
      <description>arXiv:2311.13469v2 Announce Type: replace-cross 
Abstract: We study the sample complexity of learning an $\varepsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. We establish the complexity bound $\widetilde{O}\left(SA\frac{H}{\varepsilon^2} \right)$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$ and $\varepsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters.
  Our result is based on reducing the average-reward MDP to a discounted MDP. To establish the optimality of this reduction, we develop improved bounds for $\gamma$-discounted MDPs, showing that $\widetilde{O}\left(SA\frac{H}{(1-\gamma)^2\varepsilon^2} \right)$ samples suffice to learn a $\varepsilon$-optimal policy in weakly communicating MDPs under the regime that $\gamma \geq 1 - \frac{1}{H}$, circumventing the well-known lower bound of $\widetilde{\Omega}\left(SA\frac{1}{(1-\gamma)^3\varepsilon^2} \right)$ for general $\gamma$-discounted MDPs. Our analysis develops upper bounds on certain instance-dependent variance parameters in terms of the span parameter. These bounds are tighter than those based on the mixing time or diameter of the MDP and may be of broader use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13469v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>S$\Omega$I: Score-based O-INFORMATION Estimation</title>
      <link>https://arxiv.org/abs/2402.05667</link>
      <description>arXiv:2402.05667v2 Announce Type: replace-cross 
Abstract: The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables. Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions. Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables. One of the most prominent and versatile measures based on this concept is O-information, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems. However, its practical application is limited to simplified cases. In this work, we introduce S$\Omega$I, which allows for the first time to compute O-information without restrictive assumptions about the system. Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of S$\Omega$I in the context of a real-world use case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05667v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustapha Bounoua, Giulio Franzese, Pietro Michiardi</dc:creator>
    </item>
  </channel>
</rss>
