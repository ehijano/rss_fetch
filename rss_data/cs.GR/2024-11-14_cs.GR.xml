<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GR</link>
    <description>cs.GR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 05:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ScribGen: Generating Scribble Art Through Metaheuristics</title>
      <link>https://arxiv.org/abs/2411.08673</link>
      <description>arXiv:2411.08673v1 Announce Type: new 
Abstract: Art has long been a medium for individuals to engage with the world. Scribble art, a form of abstract visual expression, features spontaneous, gestural strokes made with pens or brushes. These dynamic and expressive compositions, created quickly and impulsively, reveal intricate patterns and hidden meanings upon closer inspection. While scribble art is often associated with spontaneous expression and experimentation, it can also be planned and intentional. Some artists use scribble techniques as a starting point for their creative process, exploring the possibilities of line, shape, and texture before refining their work into more polished compositions. From ancient cave paintings to modern abstract sketches and doodles, scribble art has evolved with civilizations, reflecting diverse artistic movements and cultural influences. This evolution highlights its universal appeal, transcending language and cultural barriers and connecting people through the shared experience of creating art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08673v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3680530.3695448</arxiv:DOI>
      <dc:creator>Soumyaratna Debnath, Ashish Tiwari, Shanmuganathan Raman</dc:creator>
    </item>
    <item>
      <title>On integer sequences for rendering limit sets of Kleinian groups</title>
      <link>https://arxiv.org/abs/2411.08818</link>
      <description>arXiv:2411.08818v1 Announce Type: new 
Abstract: We present a technique for rendering limit sets for kleinian groups, based upon the base transformation of integers and which aims at saving memory resources and being faster than the traditional dictionary based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08818v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Rosa</dc:creator>
    </item>
    <item>
      <title>Audience Reach of Scientific Data Visualizations in Planetarium-Screened Films</title>
      <link>https://arxiv.org/abs/2411.08045</link>
      <description>arXiv:2411.08045v1 Announce Type: cross 
Abstract: Quantifying the global reach of planetarium dome shows presents significant challenges due to the lack of standardized viewership tracking mechanisms across diverse planetarium venues. We present an analysis of the global impact of dome shows, presenting data regarding four documentary films from a single visualization lab. Specifically, we designed and administered a viewership survey of four long-running shows that contained cinematic scientific visualizations. Reported survey data shows that between 1.2 - 2.6 million people have viewed these four films across the 68 responding planetariums (mean: 1.9 million). When we include estimates and extrapolate for the 315 planetariums that licensed these shows, we arrive at an estimate of 16.5 - 24.1 million people having seen these films (mean: 20.3 million).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08045v1</guid>
      <category>physics.pop-ph</category>
      <category>astro-ph.IM</category>
      <category>cs.CY</category>
      <category>cs.GR</category>
      <category>cs.HC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kalina Borkiewicz, Eric Jensen, Yiwen Miao, Stuart Levy, J. P. Naiman, Jeff Carpenter, Katherine E. Isaacs</dc:creator>
    </item>
    <item>
      <title>GaussianObject: High-Quality 3D Object Reconstruction from Four Views with Gaussian Splatting</title>
      <link>https://arxiv.org/abs/2402.10259</link>
      <description>arXiv:2402.10259v4 Announce Type: replace-cross 
Abstract: Reconstructing and rendering 3D objects from highly sparse views is of critical importance for promoting applications of 3D vision techniques and improving user experience. However, images from sparse views only contain very limited 3D information, leading to two significant challenges: 1) Difficulty in building multi-view consistency as images for matching are too few; 2) Partially omitted or highly compressed object information as view coverage is insufficient. To tackle these challenges, we propose GaussianObject, a framework to represent and render the 3D object with Gaussian splatting that achieves high rendering quality with only 4 input images. We first introduce techniques of visual hull and floater elimination, which explicitly inject structure priors into the initial optimization process to help build multi-view consistency, yielding a coarse 3D Gaussian representation. Then we construct a Gaussian repair model based on diffusion models to supplement the omitted object information, where Gaussians are further refined. We design a self-generating strategy to obtain image pairs for training the repair model. We further design a COLMAP-free variant, where pre-given accurate camera poses are not required, which achieves competitive quality and facilitates wider applications. GaussianObject is evaluated on several challenging datasets, including MipNeRF360, OmniObject3D, OpenIllumination, and our-collected unposed images, achieving superior performance from only four views and significantly outperforming previous SOTA methods. Our demo is available at https://gaussianobject.github.io/, and the code has been released at https://github.com/GaussianObject/GaussianObject.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10259v4</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Yang, Sikuang Li, Jiemin Fang, Ruofan Liang, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian</dc:creator>
    </item>
    <item>
      <title>Projecting Gaussian Ellipsoids While Avoiding Affine Projection Approximation</title>
      <link>https://arxiv.org/abs/2411.07579</link>
      <description>arXiv:2411.07579v2 Announce Type: replace-cross 
Abstract: Recently, 3D Gaussian Splatting has dominated novel-view synthesis with its real-time rendering speed and state-of-the-art rendering quality. However, during the rendering process, the use of the Jacobian of the affine approximation of the projection transformation leads to inevitable errors, resulting in blurriness, artifacts and a lack of scene consistency in the final rendered images. To address this issue, we introduce an ellipsoid-based projection method to calculate the projection of Gaussian ellipsoid on the image plane, witch is the primitive of 3D Gaussian Splatting. As our proposed ellipsoid-based projection method cannot handle Gaussian ellipsoids with camera origins inside them or parts lying below $z=0$ plane in the camera space, we designed a pre-filtering strategy. Experiments over multiple widely adopted benchmark datasets show that using our ellipsoid-based projection method can enhance the rendering quality of 3D Gaussian Splatting and its extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07579v2</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Qi, Tao Cai, Xiyue Han</dc:creator>
    </item>
  </channel>
</rss>
