<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>AllReduce Scheduling with Hierarchical Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.21013</link>
      <description>arXiv:2503.21013v1 Announce Type: new 
Abstract: AllReduce is a technique in distributed computing which saw use in many critical applications of deep learning. Existing methods of AllReduce scheduling oftentimes lack flexibility due to being topology-specific or relying on extensive handcrafted designs that require domain-specific knowledge. In this work, we aim to alleviate this inflexibility by proposing a deep-reinforcement-learning (DRL)-based pipeline that can generate AllReduce scheduling for various network topologies without topology-specific design features. The flow scheduling module of this pipeline consists of two hierarchically-structured DRL policies that work cooperatively to find optimal scheduling. We showcase the performance of our method compared to the baseline methods on three topologies: BCube, DCell, and Jellyfish. Finally, we contributed a Python-based simulation environment simulating AllReduce scheduling on these network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21013v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Wei, Mickel Liu, Wenfei Wu</dc:creator>
    </item>
    <item>
      <title>Declarative Traffic Engineering for Low-Latency and Reliable Networking</title>
      <link>https://arxiv.org/abs/2503.21289</link>
      <description>arXiv:2503.21289v1 Announce Type: new 
Abstract: Cloud-Edge applications like industrial control systems and connected vehicles demand stringent end-to-end latency guarantees. Among existing data plane candidate solutions for bounded latency networking, the guaranteed Latency-Based Forwarding (gLBF) approach ensures punctual delivery of traffic flows by managing per-hop delays to meet specific latency targets, while not requiring that per-flow states are maintained at each hop. However, as a forwarding plane mechanism, gLBF does not define the control mechanisms for determining feasible forwarding paths and per-hop latency budgets for packets to fulfil end-to-end latency objectives. In this work, we propose such a control mechanism implemented in Prolog that complies with gLBF specifications, called declarative gLBF (dgLBF). The declarative nature of Prolog allows our prototype to be concise (~120 lines of code) and easy to extend. We show how the core dgLBF implementation is extended to add reliability mechanisms, path protection, and fate-sharing avoidance to enhance fault tolerance and robustness. Finally, we evaluate the system's performance through simulative experiments under different network topologies and with increasing traffic load to simulate saturated network conditions, scaling up to 6000 flows. Our results show a quasi-linear degradation in placement times and system resilience under heavy traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21289v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacopo Massa, Stefano Forti, Federica Paganelli, Patrizio Dazzi, Antonio Brogi, Alexander Clemm, Toerless Eckert</dc:creator>
    </item>
    <item>
      <title>Optimizing Resource Allocation and Scheduling towards FRMCS and GSM-R networks coexistence in Railway Systems</title>
      <link>https://arxiv.org/abs/2503.21300</link>
      <description>arXiv:2503.21300v1 Announce Type: new 
Abstract: The actual railway communication system used in Europe for high-speed trains (HST) is called the GSM-R system, which is a communication system based on 2G infrastructure. This system is meant to be replaced by a new system based on 5G NR infrastructure called the Future Railway Mobile Communication System (FRMCS) by 2030. For the next years, both systems will probably coexist in the same frequency band since the migration from GSM-R to FRMCS is planned to be done progressively until the GSM-R system is completely shut down, mainly due to safety and budget constraints. In this paper, we study the resource allocation for the FRMCS system sharing the same frequency band as the already deployed GSM-R system. We formulate the resource allocation problem as an integer linear problem (ILP), known to be NP-hard.To solve it in a reasonable time, we propose a scheduling algorithm, called Intelligent Traffic Scheduling Preemptor (ITSP), that allocates resources for the different FRMCS traffic types considered (critical traffic and performance traffic) in the same frequency band with the GSM-R system. Our algorithm is channel quality Indicator (CQI) aware and uses the preemption mechanism in 5G NR standards to optimize the resource allocation for the FRMCS system without impacting the actual GSM-R resource allocation in the context of the white space concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21300v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Global Information Infrastructure Symposium, GIIS'25, IEEE Xplore, 2025</arxiv:journal_reference>
      <dc:creator>Mohamed Aziz Aboud (LIGM, ETS), Nawel Zangar (LIGM), Rami Langar (LIGM), Marion Berbineau (COSYS-LEOST), Jerome Madec</dc:creator>
    </item>
    <item>
      <title>A Deep Reinforcement Learning-based Approach for Adaptive Handover Protocols</title>
      <link>https://arxiv.org/abs/2503.21601</link>
      <description>arXiv:2503.21601v1 Announce Type: new 
Abstract: The use of higher frequencies in mobile communication systems leads to smaller cell sizes, resulting in the deployment of more base stations and an increase in handovers to support user mobility. This can lead to frequent radio link failures and reduced data rates. In this work, we propose a handover optimization method using proximal policy optimization (PPO) to develop an adaptive handover protocol. Our PPO-based agent, implemented in the base stations, is highly adaptive to varying user equipment speeds and outperforms the 3GPP-standardized 5G NR handover procedure in terms of average data rate and radio link failure rate. Additionally, our simulation environment is carefully designed to ensure high accuracy, realistic user movements, and fair benchmarking against the 3GPP handover method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21601v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Voigt, Peter Jiacheng Gu, Peter Rost</dc:creator>
    </item>
    <item>
      <title>RIS-Measurements for Codebook Design</title>
      <link>https://arxiv.org/abs/2503.21623</link>
      <description>arXiv:2503.21623v1 Announce Type: new 
Abstract: Reconfigurable Intelligent Surfaces (RIS) have gained significant attention for some time. Thanks to the possibility of individual steering of each reflecting element of the boards, they are envisaged to impact the propagation environment significantly. In this work, we concentrate on the practical verification of this concept. We present the results of detailed measurements of the reflection characteristics of the RIS boards, which have been conducted intentionally in the real environment. Various potential impacting factors have been considered (impact of azimuth and elevation angle, polarization, number of RIS boards, and distance). Achieved measurement results constituted the basis for conceptual analysis on the practical possibility of creating a codebook (consisting of RIS patterns - codewords) for some applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21623v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/WiMob61911.2024.10770406</arxiv:DOI>
      <dc:creator>Pawe{\l} Hatka, Marcel Garczyk, Pawe{\l} P{\l}aczkiewicz, Dawid Brz\k{a}ka{\l}a, Krzysztof Cicho\'n, Adrian Kliks</dc:creator>
    </item>
    <item>
      <title>Static and Repeated Cooperative Games for the Optimization of the AoI in IoT Networks</title>
      <link>https://arxiv.org/abs/2503.21633</link>
      <description>arXiv:2503.21633v1 Announce Type: new 
Abstract: Wireless sensing and the internet of things (IoT) are nowadays pervasive in 5G and beyond networks, and they are expected to play a crucial role in 6G. However, a centralized optimization of a distributed system is not always possible and cost-efficient. In this paper, we analyze a setting in which two sensors collaboratively update a common server seeking to minimize the age of information (AoI) of the latest sample of a common physical process. We consider a distributed and uncoordinated setting where each sensor lacks information about whether the other decides to update the server. This strategic setting is modeled through game theory (GT) and two games are defined: i) a static game of complete information with an incentive mechanism for cooperation, and ii) a repeated game over a finite horizon where the static game is played at each stage. We perform a mathematical analysis of the static game finding three Nash Equilibria (NEs) in pure strategies and one in mixed strategies. A numerical simulation of the repeated game is also presented and novel and valuable insight into the setting is given thanks to the definition of a new metric, the price of delayed updates (PoDU), which shows that the decentralized solution provides results close to the centralized optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21633v1</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Emanuele Corrado Raphael Catania, Alessandro Buratto, Giovanni Perin</dc:creator>
    </item>
    <item>
      <title>Robust Deep Reinforcement Learning in Robotics via Adaptive Gradient-Masked Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2503.20844</link>
      <description>arXiv:2503.20844v1 Announce Type: cross 
Abstract: Deep reinforcement learning (DRL) has emerged as a promising approach for robotic control, but its realworld deployment remains challenging due to its vulnerability to environmental perturbations. Existing white-box adversarial attack methods, adapted from supervised learning, fail to effectively target DRL agents as they overlook temporal dynamics and indiscriminately perturb all state dimensions, limiting their impact on long-term rewards. To address these challenges, we propose the Adaptive Gradient-Masked Reinforcement (AGMR) Attack, a white-box attack method that combines DRL with a gradient-based soft masking mechanism to dynamically identify critical state dimensions and optimize adversarial policies. AGMR selectively allocates perturbations to the most impactful state features and incorporates a dynamic adjustment mechanism to balance exploration and exploitation during training. Extensive experiments demonstrate that AGMR outperforms state-of-the-art adversarial attack methods in degrading the performance of the victim agent and enhances the victim agent's robustness through adversarial defense mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20844v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongyuan Zhang, Tianyang Duan, Zheng Lin, Dong Huang, Zihan Fang, Zekai Sun, Ling Xiong, Hongbin Liang, Heming Cui, Yong Cui, Yue Gao</dc:creator>
    </item>
    <item>
      <title>DemoQuanDT: A Carrier-Grade QKD Network</title>
      <link>https://arxiv.org/abs/2503.21186</link>
      <description>arXiv:2503.21186v1 Announce Type: cross 
Abstract: Quantum Key Distribution Networks (QKDN) enable secure communication even in the age of powerful quantum computers. In the hands of a network operator, which can offer its service to many users, the economic viability of a QKDN increases significantly. The highly challenging operator-user relationship in a large-scale network setting demands additional requirements to ensure carrier-grade operation. Addressing this challenge, this work presents a carrier-grade QKDN architecture, which combines the functional QKDN architecture with the operational perspective of a network operator, ultimately enhancing the economic viability of QKDN. The focus is on the network and key management aspects of a QKDN while assuming state-of-the-art commercial QKD-Modules. The presented architecture was rolled out within an in-field demonstrator, connecting the cities of Berlin and Bonn over a link distance of 923 km across Germany. We could show, that the proposed network architecture is feasible, integrable, and scalable making it suitable for deployment in real-world networks. Overall, the presented carrier-grade QKDN architecture promises to serve as a blueprint for network operators providing QKD-based services to their customers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21186v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Horoschenkoff, J. Henrich, R. B\"ohn, I. Khan, J. R\"odiger, M. Gunkel, M. Bauch, J. Benda, P. Bl\"acker, E. Eichhammer, U. Eismann, G. Frenck, H. Griesser, W. Jontofsohn, N. Kopshoff, S. R\"ohrich, F. Seidl, N. Schark, E. Sollner, D. von Blanckenburg, A. Heinemann, M. Stiemerling, M. G\"artner</dc:creator>
    </item>
    <item>
      <title>Intelligent IoT Attack Detection Design via ODLLM with Feature Ranking-based Knowledge Base</title>
      <link>https://arxiv.org/abs/2503.21674</link>
      <description>arXiv:2503.21674v1 Announce Type: cross 
Abstract: The widespread adoption of Internet of Things (IoT) devices has introduced significant cybersecurity challenges, particularly with the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks. Traditional machine learning (ML) techniques often fall short in detecting such attacks due to the complexity of blended and evolving patterns. To address this, we propose a novel framework leveraging On-Device Large Language Models (ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for intelligent IoT network attack detection. By implementing feature ranking techniques and constructing both long and short KBs tailored to model capacities, the proposed framework ensures efficient and accurate detection of DDoS attacks while overcoming computational and privacy limitations. Simulation results demonstrate that the optimized framework achieves superior accuracy across diverse attack types, especially when using compact models in edge computing environments. This work provides a scalable and secure solution for real-time IoT security, advancing the applicability of edge intelligence in cybersecurity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21674v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satvik Verma, Qun Wang, E. Wes Bethel</dc:creator>
    </item>
  </channel>
</rss>
