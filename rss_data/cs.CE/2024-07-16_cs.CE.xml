<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 04:00:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Data Analysis on Credit Card Debt: Rate of Consumption and Impact on Individuals and the US Economy</title>
      <link>https://arxiv.org/abs/2407.11146</link>
      <description>arXiv:2407.11146v1 Announce Type: new 
Abstract: This paper provides a comprehensive examination of the evolution of credit cards in the United States, tracing their historical development, causes, consequences, and impact on both individuals and the economy. It delves into the transformation of credit cards from specialized merchant cards to ubiquitous financial tools, driven by legal changes like the Marquette decision. Credit card debt has emerged as a significant financial challenge for many Americans due to economic factors, consumerism, high healthcare costs, and financial illiteracy. The consequences of this debt on individuals are extensive, affecting their financial well-being, credit scores, savings, and even their physical and mental health. On a larger scale, credit cards stimulate consumer spending, drive e-commerce growth, and generate revenue for financial institutions, but they can also contribute to economic instability if not managed responsibly. The paper emphasizes various strategies to prevent and manage credit card debt, including financial education, budgeting, responsible credit card uses, and professional counselling. Empirical studies support the relationship between credit card debt and factors such as financial literacy and consumer behavior. Regression analysis reveals that personal consumption and GDP positively impacts credit card debt indicating that responsible management is essential. The paper offers comprehensive recommendations for addressing credit card debt challenges and maximizing the benefits of credit card usage, encompassing financial education, policy reforms, and public awareness campaigns. These recommendations aim to transform credit cards into tools that empower individuals financially and contribute to economic stability, rather than sources of financial stress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11146v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5121/csit.2024.140401</arxiv:DOI>
      <arxiv:journal_reference>Computer Science &amp; Information Technology (CS &amp; IT), ISSN : 2231 - 5403, Volume 14, Number 04, February 2024</arxiv:journal_reference>
      <dc:creator>Mayowa Akinwande, Alexander Lopez, Tobi Yusuf, Austine Unuriode, Babatunde Yusuf, Toyyibat Yussuph, Stanley Okoro</dc:creator>
    </item>
    <item>
      <title>DEDEM: Discontinuity Embedded Deep Energy Method for solving fracture mechanics problems</title>
      <link>https://arxiv.org/abs/2407.11346</link>
      <description>arXiv:2407.11346v1 Announce Type: new 
Abstract: Physics-Informed Neural Networks (PINNs) have aroused great attention for its ability to address forward and inverse problems of partial differential equations. However, approximating discontinuous functions by neural networks poses a considerable challenge, which results in high computational demands and low accuracy to solve fracture mechanics problems within standard PINNs framework. In this paper, we present a novel method called Discontinuity Embedded Deep Energy Method (DEDEM) for modeling fracture mechanics problems. In this method, interfaces and internal boundaries with weak/strong discontinuities are represented by discontinuous functions constructed by signed distance functions, then the representations are embedded to the input of the neural network so that specific discontinuous features can be imposed to the neural network solution. Results demonstrate that DEDEM can accurately model the mechanical behaviors of cracks on a large variety of fracture problems. Besides, it is also found that DEDEM achieves significantly higher computational efficiency and accuracy than the existing methods based on domain decomposition techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11346v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyang Zhao, Qian Shao</dc:creator>
    </item>
    <item>
      <title>Mechanistic interpretability of large language models with applications to the financial services industry</title>
      <link>https://arxiv.org/abs/2407.11215</link>
      <description>arXiv:2407.11215v1 Announce Type: cross 
Abstract: Large Language Models such as GPTs (Generative Pre-trained Transformers) exhibit remarkable capabilities across a broad spectrum of applications. Nevertheless, due to their intrinsic complexity, these models present substantial challenges in interpreting their internal decision-making processes. This lack of transparency poses critical challenges when it comes to their adaptation by financial institutions, where concerns and accountability regarding bias, fairness, and reliability are of paramount importance. Mechanistic interpretability aims at reverse engineering complex AI models such as transformers. In this paper, we are pioneering the use of mechanistic interpretability to shed some light on the inner workings of large language models for use in financial services applications. We offer several examples of how algorithmic tasks can be designed for compliance monitoring purposes. In particular, we investigate GPT-2 Small's attention pattern when prompted to identify potential violation of Fair Lending laws. Using direct logit attribution, we study the contributions of each layer and its corresponding attention heads to the logit difference in the residual stream. Finally, we design clean and corrupted prompts and use activation patching as a causal intervention method to localize our task completion components further. We observe that the (positive) heads $10.2$ (head $2$, layer $10$), $10.7$, and $11.3$, as well as the (negative) heads $9.6$ and $10.6$ play a significant role in the task completion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11215v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashkan Golgoon, Khashayar Filom, Arjun Ravi Kannan</dc:creator>
    </item>
    <item>
      <title>Separable Operator Networks</title>
      <link>https://arxiv.org/abs/2407.11253</link>
      <description>arXiv:2407.11253v1 Announce Type: cross 
Abstract: Operator learning has become a powerful tool in machine learning for modeling complex physical systems. Although Deep Operator Networks (DeepONet) show promise, they require extensive data acquisition. Physics-informed DeepONets (PI-DeepONet) mitigate data scarcity but suffer from inefficient training processes. We introduce Separable Operator Networks (SepONet), a novel framework that significantly enhances the efficiency of physics-informed operator learning. SepONet uses independent trunk networks to learn basis functions separately for different coordinate axes, enabling faster and more memory-efficient training via forward-mode automatic differentiation. We provide theoretical guarantees for SepONet using the universal approximation theorem and validate its performance through comprehensive benchmarking against PI-DeepONet. Our results demonstrate that for the 1D time-dependent advection equation, when targeting a mean relative $\ell_{2}$ error of less than 6% on 100 unseen variable coefficients, SepONet provides up to $112 \times$ training speed-up and $82 \times$ GPU memory usage reduction compared to PI-DeepONet. Similar computational advantages are observed across various partial differential equations, with SepONet's efficiency gains scaling favorably as problem complexity increases. This work paves the way for extreme-scale learning of continuous mappings between infinite-dimensional function spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11253v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xinling Yu, Sean Hooten, Ziyue Liu, Yequan Zhao, Marco Fiorentino, Thomas Van Vaerenbergh, Zheng Zhang</dc:creator>
    </item>
    <item>
      <title>Heterogenous Multi-Source Data Fusion Through Input Mapping and Latent Variable Gaussian Process</title>
      <link>https://arxiv.org/abs/2407.11268</link>
      <description>arXiv:2407.11268v1 Announce Type: cross 
Abstract: Artificial intelligence and machine learning frameworks have served as computationally efficient mapping between inputs and outputs for engineering problems. These mappings have enabled optimization and analysis routines that have warranted superior designs, ingenious material systems and optimized manufacturing processes. A common occurrence in such modeling endeavors is the existence of multiple source of data, each differentiated by fidelity, operating conditions, experimental conditions, and more. Data fusion frameworks have opened the possibility of combining such differentiated sources into single unified models, enabling improved accuracy and knowledge transfer. However, these frameworks encounter limitations when the different sources are heterogeneous in nature, i.e., not sharing the same input parameter space. These heterogeneous input scenarios can occur when the domains differentiated by complexity, scale, and fidelity require different parametrizations. Towards addressing this void, a heterogeneous multi-source data fusion framework is proposed based on input mapping calibration (IMC) and latent variable Gaussian process (LVGP). In the first stage, the IMC algorithm is utilized to transform the heterogeneous input parameter spaces into a unified reference parameter space. In the second stage, a multi-source data fusion model enabled by LVGP is leveraged to build a single source-aware surrogate model on the transformed reference space. The proposed framework is demonstrated and analyzed on three engineering case studies (design of cantilever beam, design of ellipsoidal void and modeling properties of Ti6Al4V alloy). The results indicate that the proposed framework provides improved predictive accuracy over a single source model and transformed but source unaware model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11268v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yigitcan Comlek, Sandipp Krishnan Ravi, Piyush Pandita, Sayan Ghosh, Liping Wang, Wei Chen</dc:creator>
    </item>
    <item>
      <title>Intelligent Cross-Organizational Process Mining: A Survey and New Perspectives</title>
      <link>https://arxiv.org/abs/2407.11280</link>
      <description>arXiv:2407.11280v1 Announce Type: cross 
Abstract: Process mining, as a high-level field in data mining, plays a crucial role in enhancing operational efficiency and decision-making across organizations. In this survey paper, we delve into the growing significance and ongoing trends in the field of process mining, advocating a specific viewpoint on its contents, application, and development in modern businesses and process management, particularly in cross-organizational settings. We first summarize the framework of process mining, common industrial applications, and the latest advances combined with artificial intelligence, such as workflow optimization, compliance checking, and performance analysis. Then, we propose a holistic framework for intelligent process analysis and outline initial methodologies in cross-organizational settings, highlighting both challenges and opportunities. This particular perspective aims to revolutionize process mining by leveraging artificial intelligence to offer sophisticated solutions for complex, multi-organizational data analysis. By integrating advanced machine learning techniques, we can enhance predictive capabilities, streamline processes, and facilitate real-time decision-making. Furthermore, we pinpoint avenues for future investigations within the research community, encouraging the exploration of innovative algorithms, data integration strategies, and privacy-preserving methods to fully harness the potential of process mining in diverse, interconnected business environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11280v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiyuan Yang, Zheshun Wu, Yong Chu, Zhenghua Chen, Zenglin Xu, Qingsong Wen</dc:creator>
    </item>
    <item>
      <title>No Questions Asked: Effects of Transparency on Stablecoin Liquidity During the Collapse of Silicon Valley Bank</title>
      <link>https://arxiv.org/abs/2407.11716</link>
      <description>arXiv:2407.11716v1 Announce Type: cross 
Abstract: Fiat-pegged stablecoins are by nature exposed to spillover effects during market turmoil in Traditional Finance (TradFi). We observe a difference in TradFi market shocks impact between various stablecoins, in particular, USD Coin (USDC) and Tether USDT (USDT), the former with a higher reporting frequency and transparency than the latter. We investigate this, using top USDC and USDT liquidity pools in Uniswap, by adapting the Marginal Cost of Immediacy (MCI) measure to Uniswap's Automated Market Maker, and then conducting Difference-in-Differences analysis on MCI and Total Value Locked (TVL) in USD, as well as measuring liquidity concentration across different providers. Results show that the Silicon Valley Bank (SVB) event reduced USDC's TVL dominance over USDT, increased USDT's liquidity cost relative to USDC, and liquidity provision remained concentrated with pool-specific trends. These findings reveal a flight-to-safety behavior and counterintuitive effects of stablecoin transparency: USDC's frequent and detailed disclosures led to swift market reactions, while USDT's opacity and less frequent reporting provided a safety net against immediate impacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11716v1</guid>
      <category>q-fin.TR</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Walter Hernandez Cruz, Jiahua Xu, Paolo Tasca, Carlo Campajola</dc:creator>
    </item>
    <item>
      <title>ProLLaMA: A Protein Language Model for Multi-Task Protein Language Processing</title>
      <link>https://arxiv.org/abs/2402.16445</link>
      <description>arXiv:2402.16445v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved remarkable performance in multiple Natural Language Processing (NLP) tasks. Under the premise that protein sequences constitute the protein language, Protein Language Models(PLMs) have advanced the field of protein engineering. However, as of now, unlike LLMs in NLP, PLMs cannot handle the protein understanding task and the protein generation task simultaneously in the Protein Language Processing (PLP) field. This prompts us to delineate the inherent limitations in current PLMs: (i) the lack of natural language capabilities, (ii) insufficient instruction understanding, and (iii) high training resource demands. To address these challenges, we introduce a training framework to transform any general LLM into a PLM capable of handling multiple PLP tasks. To improve training efficiency, we propose Protein Vocabulary Pruning (PVP) for general LLMs. We construct a multi-task instruction dataset containing 13 million samples with superfamily information, facilitating better modeling of protein sequence-function landscapes. Through these methods, we develop the ProLLaMA model, the first known PLM to handle multiple PLP tasks simultaneously. Experiments show that ProLLaMA achieves state-of-the-art results in the unconditional protein sequence generation task. In the controllable protein sequence generation task, ProLLaMA can design novel proteins with desired functionalities. As for the protein understanding task, ProLLaMA achieves a 62\% exact match rate in superfamily prediction. Codes, model weights, and datasets are available at \url{https://github.com/PKU-YuanGroup/ProLLaMA} and \url{https://huggingface.co/GreatCaptainNemo}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16445v2</guid>
      <category>cs.CE</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liuzhenghao Lv, Zongying Lin, Hao Li, Yuyang Liu, Jiaxi Cui, Calvin Yu-Chian Chen, Li Yuan, Yonghong Tian</dc:creator>
    </item>
  </channel>
</rss>
