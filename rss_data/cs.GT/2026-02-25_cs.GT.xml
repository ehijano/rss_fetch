<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Feb 2026 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Interview Scheduling for Stable Matching</title>
      <link>https://arxiv.org/abs/2602.20358</link>
      <description>arXiv:2602.20358v1 Announce Type: new 
Abstract: The study of stable matchings usually relies on the assumption that agents' preferences over the opposite side are complete and known. In many real markets, however, preferences might be uncertain and revealed only through costly interactions such as interviews. We show how to reach interim-stable matchings, under which all matched pairs must have interviewed and agents use expected utilities whenever true values remain unknown, while minimizing both the expected number of interviews and the expected number of interview rounds. We introduce two adaptive algorithms that produce interim-stable matchings: one operates sequentially, and another is a hybrid algorithm that begins by scheduling some interviews in parallel and continues sequentially. Focusing on cases where agents are ex-ante indifferent between agents on the other side, we show that the sequential algorithm performs 2 interviews per agent in expectation. We complement this by showing that any algorithm that performs less than 2 interviews per agent, does not always guarantee interim-stability. We also demonstrate that the hybrid algorithm requires only polylogarithmic expected number of rounds, while still performing only about 2 interviews per agent in expectation. Additionally, the interviews scheduled by our algorithms guarantee an interim-stable matching when Deferred-Acceptance is run after all interviews are completed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20358v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moshe Babaioff, Rotem Gil, Assaf Romm</dc:creator>
    </item>
    <item>
      <title>Competition Versus Complexity in Multiple-Selection Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2602.20398</link>
      <description>arXiv:2602.20398v1 Announce Type: new 
Abstract: Competition complexity formalizes a compelling intuition: rather than refining the mechanism, how much additional competition is sufficient for a simple mechanism to compete with an optimal one? We begin the study of this question in multi-unit pricing for welfare maximization using prophet inequalities. An online decision-maker observes $m \geq k$ nonnegative values drawn independently from a known distribution, may select up to $k$ of them, and aims to maximize the expected sum of selected values. The benchmark is a prophet who observes a sequence of length $n \geq k$ and selects the $k$ largest values. We focus on the widely adopted class of single-threshold algorithms and fully characterize their $(1-\varepsilon)$-competition complexity. Notably, our results reveal a sharp competition-induced phase transition: in the absence of competition, single-threshold algorithms are fundamentally limited to a $1-1/\sqrt{2k\pi}$ fraction of the prophet value, whereas even a $1\%$ multiplicative increase beyond $n$ observations suffices to achieve a $1-\exp(-\Theta(k))$ fraction. Another notable result happens when $k=1$: we show that the $(1-\varepsilon)$-competition complexity is exactly $\ln(1/\varepsilon)$, fully resolving an open question by Brustle et al. [Math. Oper. Res. 2024]. Our analysis is based on infinite-dimensional linear programming and duality arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20398v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Cruz-Ossa, Sebastian Perez-Salazar, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Markets are competitive if and only if P != NP</title>
      <link>https://arxiv.org/abs/2602.20415</link>
      <description>arXiv:2602.20415v1 Announce Type: new 
Abstract: I prove that competitive market outcomes require computational intractability. If P = NP, firms can efficiently solve the collusion detection problem, identifying deviations from cooperative agreements in complex, noisy markets and thereby making collusion sustainable as an equilibrium. If P != NP, the collusion detection problem is computationally infeasible for markets satisfying a natural instance-hardness condition on their demand structure, rendering punishment threats non-credible and collusion unstable. Combined with Maymin (2011), who proved that market efficiency requires P = NP, this yields a fundamental impossibility: markets can be informationally efficient or competitive, but not both. Artificial intelligence, by expanding firms' computational capabilities, is pushing markets from the competitive regime toward the collusive regime, explaining the empirical emergence of algorithmic collusion without explicit coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20415v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>econ.TH</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Z. Maymin</dc:creator>
    </item>
    <item>
      <title>Prior-Agnostic Incentive-Compatible Exploration</title>
      <link>https://arxiv.org/abs/2602.20465</link>
      <description>arXiv:2602.20465v1 Announce Type: new 
Abstract: In bandit settings, optimizing long-term regret metrics requires exploration, which corresponds to sometimes taking myopically sub-optimal actions. When a long-lived principal merely recommends actions to be executed by a sequence of different agents (as in an online recommendation platform) this provides an incentive misalignment: exploration is "worth it" for the principal but not for the agents. Prior work studies regret minimization under the constraint of Bayesian Incentive-Compatibility in a static stochastic setting with a fixed and common prior shared amongst the agents and the algorithm designer.
  We show that (weighted) swap regret bounds on their own suffice to cause agents to faithfully follow forecasts in an approximate Bayes Nash equilibrium, even in dynamic environments in which agents have conflicting prior beliefs and the mechanism designer has no knowledge of any agents beliefs. To obtain these bounds, it is necessary to assume that the agents have some degree of uncertainty not just about the rewards, but about their arrival time -- i.e. their relative position in the sequence of agents served by the algorithm. We instantiate our abstract bounds with concrete algorithms for guaranteeing adaptive and weighted regret in bandit settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20465v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ramya Ramalingam, Osbert Bastani, Aaron Roth</dc:creator>
    </item>
    <item>
      <title>Maximin Share Guarantees via Limited Cost-Sensitive Sharing</title>
      <link>https://arxiv.org/abs/2602.20541</link>
      <description>arXiv:2602.20541v1 Announce Type: new 
Abstract: We study the problem of fairly allocating indivisible goods when limited sharing is allowed, that is, each good may be allocated to up to $k$ agents, while incurring a cost for sharing. While classic maximin share (MMS) allocations may not exist in many instances, we demonstrate that allowing controlled sharing can restore fairness guarantees that are otherwise unattainable in certain scenarios. (1) Our first contribution shows that exact maximin share (MMS) allocations are guaranteed to exist whenever goods are allowed to be cost-sensitively shared among at least half of the agents and the number of agents is even; for odd numbers of agents, we obtain a slightly weaker MMS guarantee. (2) We further design a Shared Bag-Filling Algorithm that guarantees a $(1 - C)(k - 1)$-approximate MMS allocation, where $C$ is the maximum cost of sharing a good. Notably, when $(1 - C)(k - 1) \geq 1$, our algorithm recovers an exact MMS allocation. (3) We additionally introduce the Sharing Maximin Share (SMMS) fairness notion, a natural extension of MMS to the $k$-sharing setting. (4) We show that SMMS allocations always exist under identical utilities and for instances with two agents. (5) We construct a counterexample to show the impossibility of the universal existence of an SMMS allocation. (6) Finally, we establish a connection between SMMS and constrained MMS (CMMS), yielding approximation guarantees for SMMS via existing CMMS results. These contributions provide deep theoretical insights for the problem of fair resource allocation when a limited sharing of resources are allowed in multi-agent environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20541v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.65109/LGSS5881</arxiv:DOI>
      <dc:creator>Hana Salavcova, Martin \v{C}ern\'y, Arpita Biswas</dc:creator>
    </item>
    <item>
      <title>The Tragedy of the Commons in Multi-Population Resource Games</title>
      <link>https://arxiv.org/abs/2602.20603</link>
      <description>arXiv:2602.20603v1 Announce Type: new 
Abstract: Self-optimizing behaviors can lead to outcomes where collective benefits are ultimately destroyed, a well-known phenomenon known as the ``tragedy of the commons".
  These scenarios are widely studied using game-theoretic approaches to analyze strategic agent decision-making.
  In this paper, we examine this phenomenon in a bi-level decision-making hierarchy, where low-level agents belong to multiple distinct populations, and high-level agents make decisions that impact the choices of the local populations they represent.
  We study strategic interactions in a context where the populations benefit from a common environmental resource that degrades with higher extractive efforts made by high-level agents.
  We characterize a unique symmetric Nash equilibrium in the high-level game, and investigate its consequences on the common resource.
  While the equilibrium resource level degrades as the number of populations grows large, there are instances where it does not become depleted.
  We identify such regions, as well as the regions where the resource does deplete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20603v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yamin Vahmian, Keith Paarporn</dc:creator>
    </item>
    <item>
      <title>Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization</title>
      <link>https://arxiv.org/abs/2602.20846</link>
      <description>arXiv:2602.20846v1 Announce Type: new 
Abstract: Standard game theory explains cooperation in repeated games through conditional strategies such as Tit-for-Tat (TfT), but these require continuous computation that imposes physical costs on embodied agents. We propose a three-layer Body-Reservoir Governance (BRG) architecture: (1) a body reservoir (echo state network) whose $d$-dimensional state performs implicit inference over interaction history, serving as both decision-maker and anomaly detector, (2) a cognitive filter providing costly strategic tools activated on demand, and (3) a metacognitive governance layer with receptivity parameter $\alpha \in [0,1]$. At full body governance ($\alpha=1$), closed-loop dynamics satisfy a self-consistency equation: cooperation is expressed as the reservoir's fixed point, not computed. Strategy complexity cost is defined as the KL divergence between the reservoir's state distribution and its habituated baseline. Body governance reduces this cost, with action variance decreasing up to $1600\times$ with dimension $d$. A dynamic sentinel generates a composite discomfort signal from the reservoir's own state, driving adaptive $\alpha(t)$: near baseline during cooperation, rapidly dropping upon defection to activate cognitive retaliation. Overriding the body incurs thermodynamic cost proportional to internal state distortion. The sentinel achieves the highest payoff across all conditions, outperforming static body governance, TfT, and EMA baselines. A dimension sweep ($d \in \{5,\ldots,100\}$) shows implicit inference scales with bodily richness ($23\times$ to $1600\times$ variance reduction), attributable to reservoir dynamics. A phase diagram in $(d, \tau_{\mathrm{env}})$ space reveals governance regime transitions near $d \approx 20$. The framework reinterprets cooperation as the minimum-dissipation response of an adapted dynamical system -- emergent from embodied dynamics rather than computed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20846v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.NE</category>
      <category>nlin.AO</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Nakamura</dc:creator>
    </item>
    <item>
      <title>Fair Division with Soft Conflicts</title>
      <link>https://arxiv.org/abs/2602.20929</link>
      <description>arXiv:2602.20929v1 Announce Type: new 
Abstract: We study the fair division of indivisible goods with conflicts between pairs of goods, represented by a graph $G = (V, E)$. We consider ``soft'' conflicts: assigning two adjacent goods to the same agent is allowed, but we seek allocations that are envy-free up to one good (EF1) while keeping the number of such conflict violations small.
  We propose a linear-time algorithm for general additive valuations that finds an EF1 allocation with at most $|E|/n + O(|E|^{1-1/(2n-2)})$ violations, for any constant number of agents $n$. The leading term $|E|/n$ matches the worst-case bound on the number of violations. We use a novel approach that combines an algorithm for fair division with cardinality constraints from Biswas \&amp; Barman (2018) and a geometric ``closest points'' argument. For identical additive valuations, we also propose a simple round-robin-based algorithm that finds an EF1 allocation with at most $|E|/n$ violations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20929v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hirotaka Yoneda, Masataka Yoneda</dc:creator>
    </item>
    <item>
      <title>Stability Under Valuation Updates in Coalition Formation</title>
      <link>https://arxiv.org/abs/2602.21041</link>
      <description>arXiv:2602.21041v1 Announce Type: new 
Abstract: Coalition formation studies how to partition a set of agents into disjoint coalitions under consideration of their preferences. We study the classical objective of stability in a variant of additively separable hedonic games where agents can change their valuations. Our objective is to find a stable partition after each change. To minimize the reconfiguration cost, we search for nearby stable coalition structures. Our focus is on stability concepts based on single-agent deviations. We present a detailed picture of the complexity of finding nearby stable coalition structures in additively separable hedonic games, for both symmetric and non-symmetric valuations. Our results show that the problem is NP-complete for Nash stability, individual stability, contractual Nash stability, and contractual individual stability. We complement these results by presenting polynomial-time algorithms for contractual Nash stability and contractual individual stability under restricted symmetric valuations. Finally, we show that these algorithms guarantee a bounded average distance over long sequences of updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21041v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fabian Frank, Matija Novakovi\'c, Ren\'e Romen</dc:creator>
    </item>
    <item>
      <title>Robust Mechanism Design with Anonymous Information</title>
      <link>https://arxiv.org/abs/2602.20429</link>
      <description>arXiv:2602.20429v1 Announce Type: cross 
Abstract: In practice, auction data are often endogenously censored and anonymous, revealing only limited outcome statistics rather than full bid profiles. We study robust auction design when the seller observes only aggregated, anonymous order statistics and seeks to maximize worst-case expected revenue over all product distributions consistent with the observed statistic. We show that simple and widely used mechanisms are robustly optimal. Specifically, posted pricing is robustly optimal given the distribution of the highest value; the Myerson auction designed for the unique consistent i.i.d. distribution is robustly optimal given the lowest value distribution; and the second-price auction with an optimal reserve is robustly optimal when an intermediate order statistic is observed and the implied i.i.d. distribution is regular above its reserve. More generally, for a broad class of monotone symmetric mechanisms depending only on the top k order statistics, including multi-unit and position auctions, the worst-case revenue is attained under the i.i.d. distribution consistent with the observed k-th order statistic. Our results provide a tractable foundation for non-discriminatory auction design, where fairness and privacy are intrinsic consequences of the information structure rather than imposed constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20429v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Tang, Shixin Wang</dc:creator>
    </item>
    <item>
      <title>Revenue Non-monotonicity in Matching Markets</title>
      <link>https://arxiv.org/abs/2602.20439</link>
      <description>arXiv:2602.20439v1 Announce Type: cross 
Abstract: The Vickrey-Clarke-Groves (VCG) mechanism is infamously revenue
  non-monotone in combinatorial auctions. I.e., when a buyer increases
  their value for a bundle of items, the total auction revenue may decrease.
  Combinatorial auctions exhibit complementarities which broadly
  result in complexities in auction theory. This brief note shows
  that non-monotonicity in multi-item auctions is not a result of
  complementarities, and in fact, VCG is revenue non-monotone even in matching
  markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20439v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Hartline</dc:creator>
    </item>
    <item>
      <title>Revisiting the Unitary Actor Assumption: Toward Realistic Aggregation of Individual Preferences in Strategy Research</title>
      <link>https://arxiv.org/abs/2602.20518</link>
      <description>arXiv:2602.20518v1 Announce Type: cross 
Abstract: The long-standing unitary-actor assumption in strategy research -- treating firms as monolithic entities with coherent preferences -- misses that organizations are coalitions of individuals with diverse and often conflicting goals. Although behavioral perspectives have challenged this assumption, the field lacks an operational method for deriving an organizational utility function from the disparate preferences of its members and the specific structures used to aggregate them. We develop a mathematical framework that (i) maps individual utility functions into choice probabilities via a random-utility model, (ii) combines those probabilities using an explicit aggregation structure (e.g., unanimity or polyarchy), and (iii) recovers an organizational utility function that rationalizes the collective behavior. This establishes organizational utility functions as operationally meaningful: they summarize and predict organizational choice, yet are generally not simple averages of members' utilities. Instead, aggregation structures systematically reshape preferences -- unanimity approximates the pointwise minima of underlying utility functions, amplifying risk aversion; polyarchy approximates the pointwise maxima, promoting risk-seeking. We illustrate strategic implications in Cournot competition and principal-agent settings, showing how internal aggregation structures shift competitive and collaborative outcomes. Overall, the framework provides a parsimonious way to retrofit unitary-actor models with behaviorally grounded organizational preferences, reconciling the coalition view of the firm with rigorous and tractable strategic analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20518v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe A. Csaszar, John C. Eklund</dc:creator>
    </item>
    <item>
      <title>Decentralized Trading Networks: Equilibria and Fairness</title>
      <link>https://arxiv.org/abs/2602.20868</link>
      <description>arXiv:2602.20868v1 Announce Type: cross 
Abstract: We explore stability and fairness considerations in decentralized networked markets with bilateral contracts, building on the trading networks framework [Hatfield et al., 2013]. In our trading network game, we show that a well-defined subset of Nash equilibria can be supported as competitive equilibria. Considering an offer-based trading dynamic as well as a stochastic price clock market, we prove new convergence results to Nash equilibrium and competitive equilibrium, providing a rationale for stability properties in decentralized, dynamic trading networks. Turning to the tension between fairness and (core) stability, we prove several negative results: inessential agents always receive zero utility in any core outcome, and even essential agents can get zero utility in all core outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20868v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Finster, Paul W. Goldberg, Edwin Lock, Matilde Tullii</dc:creator>
    </item>
    <item>
      <title>Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning</title>
      <link>https://arxiv.org/abs/2602.21020</link>
      <description>arXiv:2602.21020v1 Announce Type: cross 
Abstract: Multi-agent imitation learning (MA-IL) aims to learn optimal policies from expert demonstrations of interactions in multi-agent interactive domains. Despite existing guarantees on the performance of the resulting learned policies, characterizations of how far the learned polices are from a Nash equilibrium are missing for offline MA-IL. In this paper, we demonstrate impossibility and hardness results of learning low-exploitable policies in general $n$-player Markov Games. We do so by providing examples where even exact measure matching fails, and demonstrating a new hardness result on characterizing the Nash gap given a fixed measure matching error. We then show how these challenges can be overcome using strategic dominance assumptions on the expert equilibrium. Specifically, for the case of dominant strategy expert equilibria, assuming Behavioral Cloning error $\epsilon_{\text{BC}}$, this provides a Nash imitation gap of $\mathcal{O}\left(n\epsilon_{\text{BC}}/(1-\gamma)^2\right)$ for a discount factor $\gamma$. We generalize this result with a new notion of best-response continuity, and argue that this is implicitly encouraged by standard regularization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21020v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Bergerault, Volkan Cevher, Negar Mehr</dc:creator>
    </item>
    <item>
      <title>The Price of Competitive Information Disclosure</title>
      <link>https://arxiv.org/abs/2504.10459</link>
      <description>arXiv:2504.10459v2 Announce Type: replace 
Abstract: In many decision-making scenarios, individuals strategically choose what information to disclose to optimize their own outcomes. It is unclear whether such strategic information disclosure can lead to good societal outcomes. To address this question, we consider a competitive Bayesian persuasion model in which multiple agents selectively disclose information about their qualities to a principal, who aims to choose the candidates with the highest qualities. Using the price-of-anarchy framework, we quantify the inefficiency of such strategic disclosure. We show that the price of anarchy is at most a constant when the agents have independent quality distributions, even if their utility functions are heterogeneous. This result provides the first theoretical guarantee on the limits of inefficiency in Bayesian persuasion with competitive information disclosure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10459v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Banerjee, Kamesh Munagala, Yiheng Shen, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>Efficiently Computing Equilibria in Budget-Aggregation Games</title>
      <link>https://arxiv.org/abs/2509.08767</link>
      <description>arXiv:2509.08767v3 Announce Type: replace 
Abstract: Budget aggregation deals with the social choice problem of distributing an exogenously given budget among a set of public projects, given agents' preferences. Taking a game-theoretic perspective, we study budget-aggregation games where each agent has virtual decision power over some fraction of the budget. We investigate the structure and show efficient computability of Nash equilibria for various common preference models in this setting. In particular, we show that equilibria for Leontief utilities can be found in polynomial time, solving an open problem from Brandt et al. [2023], and give an explicit polynomial-time algorithm for computing equilibria for $\ell_1$ preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08767v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Becker, Alexander Fries, Matthias Greger, Erel Segal-Halevi</dc:creator>
    </item>
  </channel>
</rss>
