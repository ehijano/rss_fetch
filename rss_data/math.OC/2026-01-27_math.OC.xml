<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Block-Alternating Iterative Approach for a Class of Non-Convex Optimization Problems</title>
      <link>https://arxiv.org/abs/2601.17128</link>
      <description>arXiv:2601.17128v1 Announce Type: new 
Abstract: Constrained non-convex optimization problems frequently arise in control applications. Solving such problems is inherently challenging, as existing methods often converge to suboptimal local minima or incur prohibitive computational costs. To address this challenge, this paper proposes a novel block-alternating iterative method that decomposes the original problem into variable-specific subproblems, which are solved iteratively. Under the assumption that the problem is convex with respect to each decision variable, the proposed approach reformulates the original problem into a sequence of convex subproblems. Theoretical results are established regarding the convergence and optimality of the method. In addition, a numerical example and a real-world control engineering application are presented to demonstrate its effectiveness. Finally, this paper introduces a ready-to-use Python platform that implements the proposed method, together with existing algorithms, to facilitate comparison and adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17128v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anran Li, John P. Swensen, Mehdi Hosseinzadeh</dc:creator>
    </item>
    <item>
      <title>A Unified Kantorovich Duality for Multimarginal Optimal Transport</title>
      <link>https://arxiv.org/abs/2601.17171</link>
      <description>arXiv:2601.17171v1 Announce Type: new 
Abstract: Multimarginal optimal transport (MOT) has gained increasing attention in recent years, notably due to its relevance in machine learning and statistics, where one seeks to jointly compare and align multiple probability distributions. This paper presents a unified and complete Kantorovich duality theory for MOT problem on general Polish product spaces with bounded continuous cost function. For marginal compact spaces, the duality identity is derived through a convex-analytic reformulation, that identifies the dual problem as a Fenchel-Rockafellar conjugate. We obtain dual attainment and show that optimal potentials may always be chosen in the class of $c$-conjugate families, thereby extending classical two-marginal conjugacy principle into a genuinely multimarginal setting. In non-compact setting, where direct compactness arguments are unavailable, we recover duality via a truncation-tightness procedure based on weak compactness of multimarginal transference plans and boundedness of the cost. We prove that the dual value is preserved under restriction to compact subsets and that admissible dual families can be regularized into uniformly bounded $c$-conjugate potentials. The argument relies on a refined use of $c$-splitting sets and their equivalence with multimarginal $c$-cyclical monotonicity. We then obtain dual attainment and exact primal-dual equality for MOT on arbitrary Polish spaces, together with a canonical representation of optimal dual potentials by $c$-conjugacy. These results provide a structural foundation for further developments in probabilistic and statistical analysis of MOT, including stability, differentiability, and asymptotic theory under marginal perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17171v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yehya Cheryala, Mokhtar Z. Alaya, Salim Bouzebda</dc:creator>
    </item>
    <item>
      <title>A Partially Observed Stochastic Linear Stackelberg Differential Game with Poisson Jumps under Mean-Variance Criteria</title>
      <link>https://arxiv.org/abs/2601.17362</link>
      <description>arXiv:2601.17362v1 Announce Type: new 
Abstract: In this paper, a partially observed stochastic linear Stackelberg differential game with mean-variance criteria is studied. Randomness comes from Brownian motions and Poisson random measures. which leads to a circular dependency. We follow the orthogonal decomposition method to overcome the circular dependency of the control and state processes. Both original problems of the follower and leader are decomposed into several fully observed problems with mean-variance criteria. During these processes, non-linear stochastic filtering with Poisson random measures, developed in this paper, plays an important role. Besides the follower's problem is embedded into a class of auxiliary stochastic linear-quadratic optimal control problem of stochastic differential equations with Poisson jumps, the leader's problem is also embedded into a class of auxiliary stochastic linear-quadratic optimal control problem of forward-backward stochastic differential equations with Poisson jumps. Observable state feedback Stackelberg equilibria are obtained, via some Riccati equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17362v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jingtao Lin, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Winning Criteria for Open Games: A Game-Theoretic Approach to Prefix Codes</title>
      <link>https://arxiv.org/abs/2601.17521</link>
      <description>arXiv:2601.17521v1 Announce Type: new 
Abstract: We study two-player games with alternating moves played on infinite trees. Our main focus is on the case where the trees are full (regular) and the winning set is open (with respect to the product topology on the tree). Gale and Stewart showed that in this setting one of the players always has a winning strategy, though it is not known in advance which player. We present simple necessary conditions for the first player to have a winning strategy, and establish an equivalence between winning sets that guarantee a win for the first player and maximal prefix codes. Using this equivalence, we derive a necessary algebraic condition for winning, and exhibit a family of games for which this algebraic condition is in fact equivalent to winning. We introduce the concept of coverings, and show that by covering the graph with an infinite labeled tree corresponding to the free group, we can derive a simple trait of maximal prefix codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17521v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dean Kraizberg</dc:creator>
    </item>
    <item>
      <title>Robust Spacecraft Low-Thrust Trajectory Design: A Chance-Constrained Covariance-Steering Approach</title>
      <link>https://arxiv.org/abs/2601.17629</link>
      <description>arXiv:2601.17629v1 Announce Type: new 
Abstract: This paper proposes a systematic method for generating practical and robust low-thrust spacecraft trajectories. One contribution is to consider the change in mass of the spacecraft at two levels: a) the propulsive acceleration and b) the intensity of the stochastic disturbances. A covariance variable formulation is considered, which is computationally more efficient than the factorized covariance implementation. The proposed approach is applied to two- (i.e., planar) and three-dimensional heliocentric phases of spacecraft flight from Earth to Mars under the restricted two-body dynamics. The results highlight the importance of keeping track of mass change to generate more realistic, robust solutions for interplanetary space missions to avoid underestimation of mission risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17629v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meysam Babapour, Ehsan Taheri</dc:creator>
    </item>
    <item>
      <title>Multi-Criteria Inverse Robustness in Radiotherapy Planning Using Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2601.17750</link>
      <description>arXiv:2601.17750v1 Announce Type: new 
Abstract: Radiotherapy planning naturally leads to a multi-criteria optimization problem which is subject to different sources of uncertainty. In order to find the desired treatment plan, a decision maker must balance these objectives as well as the level of robustness towards uncertainty against each other. This paper showcases a quantitative approach to do so, which combines the theoretical model with the ability to deal with practical challenges. To this end, the uncertainty, which can be expressed via the so-called dose-influence matrix, is modelled using interval matrices. We use inverse robustness to introduce an additional objective, which aims to maximize the volume of the uncertainty set. A multi-criteria approach allows to handle the uncertainty while keeping appropriate values of the other objective functions. We solve the resulting quadratically constrained quadratic optimization problem (QCQP) by first relaxing it to a convex semidefinite problem (SDP) and then reconstructing optimal solutions of the QCQP from solutions of the SDP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17750v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Schr\"oeder, Yair Censor, Philipp S\"uss, Karl-Heinz K\"ufer</dc:creator>
    </item>
    <item>
      <title>Differentiable Integer Linear Programming is not Differentiable &amp; it's not a mere technical problem</title>
      <link>https://arxiv.org/abs/2601.17800</link>
      <description>arXiv:2601.17800v1 Announce Type: new 
Abstract: We show how the differentiability method employed in the paper ``Differentiable Integer Linear Programming'', Geng, et al., 2025 as shown in its theorem 5 is incorrect. Moreover, there already exists some downstream work that inherits the same error. The underlying reason comes from that, though being continuous in expectation, the surrogate loss is discontinuous in almost every realization of the randomness, for the stochastic gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17800v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thanawat Sornwanee</dc:creator>
    </item>
    <item>
      <title>Quadratic Programming over Linearly Ordered Fields: Decidability and Attainment of Optimal Solutions</title>
      <link>https://arxiv.org/abs/2601.17969</link>
      <description>arXiv:2601.17969v1 Announce Type: new 
Abstract: Classical existence theorems and solution methods for quadratic programming traditionally rely on the analytical properties of real numbers, specifically compactness and completeness. These tools are unavailable in general linearly ordered fields, such as the field of rational numbers or non-Archimedean structures, rendering standard analytical proofs insufficient in these general algebraic settings. In this paper, we establish a unified algebraic framework for the decidability of indefinite quadratic programming subject to linear constraints over general linearly ordered fields. We prove a generalized Eaves' theorem, demonstrating that if a quadratic function -- encompassing convex, non-convex, or degenerate (linear) cases -- is bounded from below on a polyhedron, the minimum is attained within the field itself, regardless of topological completeness. Our approach replaces classical analytical arguments with algebraic induction on dimension and polyhedral decomposition. Based on this foundation, we propose an exact, deterministic algorithm within the Blum--Shub--Smale model of computation that decides boundedness and computes a global minimizer using only field operations. We show that the problem is solvable in finite time via a recursive search over orthant-restricted facets. Finally, we note that linearly constrained quadratic programming represents the maximal class of polynomial optimization problems where exact solutions are structurally guaranteed within the original field, thereby demarcating the algebraic boundary of exact optimization over ordered structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17969v1</guid>
      <category>math.OC</category>
      <category>math.LO</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmytro O. Plutenko</dc:creator>
    </item>
    <item>
      <title>On maximum hands-off restricted hybrid control for discrete-time switched linear systems</title>
      <link>https://arxiv.org/abs/2601.17980</link>
      <description>arXiv:2601.17980v1 Announce Type: new 
Abstract: This paper deals with design of maximum hands-off hybrid control sequences for discrete-time switched linear systems. It is a sparsest combination of a discrete control sequence (i.e. the switching sequence) and a continuous control sequence, both satisfying pre-specified restrictions on the admissible actions, that steers a given initial state of the switched system to the origin of the state-space in a pre-specified duration of time. Given the subsystems dynamics, the sets of admissible continuous and discrete control, the initial state and the time horizon, we present a new algorithm that, under certain conditions on the subsystems dynamics and the admissible control, designs maximum hands-off hybrid control sequences for the resulting switched system. The key apparatuses for our analysis are graph theory and linear algebra. Numerical examples are presented to demonstrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17980v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darsana U, Atreyee Kundu</dc:creator>
    </item>
    <item>
      <title>Application of log-Chebyshev approximation and tropical algebra to multicriteria problems of pairwise comparisons</title>
      <link>https://arxiv.org/abs/2601.17999</link>
      <description>arXiv:2601.17999v1 Announce Type: new 
Abstract: We consider multicriteria problems of evaluating absolute ratings (scores, priorities, weights) of given alternatives for making decisions, which are compared in pairs under several criteria. Given matrices of pairwise comparisons of alternatives for each criterion and a matrix of pairwise comparisons of the criteria, the aim is to calculate a vector of individual ratings of alternatives. We formulate the problem as the Chebyshev approximation of matrices on the logarithmic scale by a common consistent matrix (a symmetrically reciprocal matrix of unit rank). We rearrange the approximation problem as a multi-objective optimization problem of finding a vector that determines the consistent matrix and hence yields a vector of ratings in question. The problem is then transformed into a series of optimization problems in the framework of tropical algebra, which focuses on the theory and application of algebraic systems with idempotent operations. To solve the optimization problems, we apply methods and results of tropical optimization, which yield analytical solutions in a form ready for further analysis and straightforward computation. To illustrate the technique implemented, we give a numerical example of solving a known problem, and compare the obtained solution with results provided by classical methods of analytic hierarchy process and weighted geometrical means.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17999v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Krivulin</dc:creator>
    </item>
    <item>
      <title>Isolated Calmness in Regularized Convex Optimization</title>
      <link>https://arxiv.org/abs/2601.18038</link>
      <description>arXiv:2601.18038v1 Announce Type: new 
Abstract: This paper studies the isolated calmness of the optimal solution mapping and the associated Lagrange system for regularized convex composite optimization problems. Several necessary and sufficient conditions for this property are established. These conditions are geometric in nature and relatively simple to verify. To support the analysis, we also develop a so-called zero-product property for second-order structures, namely the graphical derivative of the subgradient mapping of convex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18038v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tran T. A. Nghia, Huy N. Pham</dc:creator>
    </item>
    <item>
      <title>Controllability of wave-heat and heat-wave cascades</title>
      <link>https://arxiv.org/abs/2601.18212</link>
      <description>arXiv:2601.18212v1 Announce Type: new 
Abstract: We study boundary controllability of one-dimensional coupled hyperbolic-parabolic cascades, focusing on the fine structure of reachable sets. The main model is a wave-heat cascade in which a boundary control acts on the wave equation and drives the heat equation through an internal coupling. We provide a sharp minimal time for the hyperbolic part (T &gt; 2L) and a complete spectral characterization of exact controllability in weighted Hilbert spaces, whose definition depends explicitly on the coupling profile through a sequence of modal coefficients. In particular, internal couplings may generate nonstandard highly irregular controllability spaces and yield a generic (full measure) but non-robust controllability property. The analysis relies on Riesz basis decompositions and on an Ingham-M{\"u}ntz inequality. We also prove that the exact controllability space is not invariant along Hilbert Uniqueness Method trajectories: even if both endpoints belong to the controllability space, the associated minimal-energy trajectory may leave it at intermediate times. Finally, we compare with the reversed (heat-wave) cascade and discuss how reversing the direction of the coupling transfers the loss of regularity between the parabolic and hyperbolic components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18212v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Lhachemi (L2S), Christophe Prieur (GIPSA-INFINITY), Emmanuel Tr\'elat (LJLL)</dc:creator>
    </item>
    <item>
      <title>Exact Controllability for Stochastic First-Order Multi-Dimensional Hyperbolic Systems</title>
      <link>https://arxiv.org/abs/2601.18270</link>
      <description>arXiv:2601.18270v1 Announce Type: new 
Abstract: This paper investigates the exact controllability problem for multi-dimensional stochastic first-order symmetric hyperbolic systems with control inputs acting in two distinct ways: an internal control applied to the diffusion term and a boundary control applied to the drift term. By means of a classical duality argument, the controllability problem is reduced to an observability estimate for the corresponding backward stochastic system. The main technical contribution is the establishment of a new global Carleman estimate for such backward systems, combined with a weighted energy identity. This enables us to prove the desired observability inequality under a geometric structural condition (Condition \ref{cond1}), which ensures that all characteristic rays propagate toward the boundary within a finite time. As a result, we obtain exact controllability provided the control time $T$ exceeds a sharp threshold $T_0$ given explicitly in terms of the system geometry. Furthermore, we complement the positive result with several negative controllability theorems, which demonstrate that both controls are necessary and must act in a distributed manner. Our analysis not only extends controllability theory from deterministic to stochastic multi-dimensional hyperbolic systems but also provides, as a byproduct, new results for deterministic systems under a structural hypothesis. Applications to stochastic traffic flow, epidemiological models, and shallow-water equations are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18270v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zengyu Li, Qi L\"u, Yu Wang, Haitian Yang</dc:creator>
    </item>
    <item>
      <title>Line Spectral Estimation Using a G-Filter: Atomic Norm Minimization with Multiple Output Vectors</title>
      <link>https://arxiv.org/abs/2601.18279</link>
      <description>arXiv:2601.18279v1 Announce Type: new 
Abstract: We propose an atomic norm minimization (ANM) estimator of frequencies in a noisy complex sinusoidal signal that integrates Georgiou's filter bank (G-filter) with multiple output vectors (MOV). Unlike our previous work on the G-filter version of ANM which is restricted to a single filtered output vector, the proposed method in this paper uses MOV to improve data utilization and robustness of the estimate. The ANM problem with MOV can be reformulated as a semidefinite program thanks to a Carath\'eodory--Fej\'er-type decomposition for output covariance matrices of the G-filter. Numerical simulations demonstrate that the proposed approach significantly outperforms the standard ANM and the G-filter version of ANM with a single output vector in recovering the correct number of frequency components when the frequencies fall within the band(s) selected by the G-filter, particularly in the low SNR regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18279v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiale Tang, Bin Zhu</dc:creator>
    </item>
    <item>
      <title>On strong valid inequalities for a class of mixed-integer nonlinear sets with box constraints</title>
      <link>https://arxiv.org/abs/2601.18358</link>
      <description>arXiv:2601.18358v1 Announce Type: new 
Abstract: In this paper, we investigate the mixed-integer nonlinear set with box constraints $X = \{(w,x)\in R\times Z^n:w\leq f(a^Tx),0\leq x\leq \mu\}$, where $f$ is a univariate concave function, $a\in R^n$, and $\mu\in Z^n_{++}$. This set arises as a substructure in many mixed-integer nonlinear optimization models and encompasses, as special cases, several previously investigated mixed-integer sets, namely the submodular maximization set, the mixed-integer knapsack set, and the mixed-integer polyhedral conic set. We present the first comprehensive polyhedral study of conv($X$). In particular, we derive a class of seed inequalities for a two-dimensional restriction of $X$, obtained by fixing all but one of the $x$ variables to their bounds in $X$, and develop two lifting procedures to obtain strong valid inequalities for conv($X$). In the first lifting procedure, we derive a subadditive approximation for the exact lifting function of the seed inequalities, and lift all fixed variables in a single phase. In the second lifting procedure, we first lift variables fixed at their lower bounds before those at their upper bounds (and vice versa), using subadditive exact and approximation lifting functions, respectively. The derived single- and two-phase lifted inequalities are shown to be facet-defining for conv($X$) under mild conditions. Moreover, for the aforementioned special cases of conv($X$), we show that the proposed lifted inequalities can either unify existing strong valid inequalities or yield new facet-defining inequalities. Finally, extensive computational experiments on expected utility maximization and weapon-target assignment problems demonstrate that the proposed lifted inequalities can substantially strengthen the continuous relaxations and significantly improve the overall computational performance of branch-and-cut algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18358v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyan Li, Yan-Ru Wang, Wei-Kun Chen, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Polyhedral results for two classes of submodular sets with GUB constraints</title>
      <link>https://arxiv.org/abs/2601.18360</link>
      <description>arXiv:2601.18360v1 Announce Type: new 
Abstract: In this paper, we investigate the polyhedral structure of two submodular sets with generalized upper bound (GUB) constraints, which arise as important substructures in various real-world applications. We derive a class of strong valid inequalities for the two sets using sequential lifting techniques. The proposed lifted inequalities are facet-defining for the convex hulls of two sets and are stronger than the well-known extended polymatroid inequalities (EPIs). We provide a more compact characterization of these inequalities and show that each of them can be computed in linear time. Moreover, the proposed lifted inequalities, together with bound and GUB constraints, can completely characterize the convex hulls of the two sets, and can be separated using a combinatorial polynomial-time algorithm. Finally, computational results on probabilistic covering location and multiple probabilistic knapsack problems demonstrate the superiority of the proposed lifted inequalities over the EPIs within a branch-and-cut framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18360v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weikang Qian, Keyan Li, Wei-Kun Chen, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>Tight semidefinite programming relaxations for sparse box-constrained quadratic programs</title>
      <link>https://arxiv.org/abs/2601.18545</link>
      <description>arXiv:2601.18545v1 Announce Type: new 
Abstract: We introduce a new class of semidefinite programming (SDP) relaxations for sparse box-constrained quadratic programs, obtained by a novel integration of the Reformulation Linearization Technique into standard SDP relaxations while explicitly exploiting the sparsity of the problem. The resulting relaxations are not implied by the existing LP and SDP relaxations for this class of optimization problems. We establish a sufficient condition under which the convex hull of the feasible region of the lifted quadratic program is SDP-representable; the proof is constructive and yields an explicit extended formulation. Although the resulting SDP may be of exponential size in general, we further identify additional structural conditions on the sparsity of the optimization problem that guarantee the existence of a polynomial-size SDP-representable formulation, which can be constructed in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18545v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aida Khajavirad</dc:creator>
    </item>
    <item>
      <title>Global Optimization of Atomic Clusters via Physically-Constrained Tensor Train Decomposition</title>
      <link>https://arxiv.org/abs/2601.18592</link>
      <description>arXiv:2601.18592v1 Announce Type: new 
Abstract: The global optimization of atomic clusters represents a fundamental challenge in computational chemistry and materials science due to the exponential growth of local minima with system size (i.e., the curse of dimensionality). We introduce a novel framework that overcomes this limitation by exploiting the low-rank structure of potential energy surfaces through Tensor Train (TT) decomposition. Our approach combines two complementary TT-based strategies: the algebraic TTOpt method, which utilizes maximum volume sampling, and the probabilistic PROTES method, which employs generative sampling. A key innovation is the development of physically-constrained encoding schemes that incorporate molecular constraints directly into the discretization process. We demonstrate the efficacy of our method by identifying global minima of Lennard-Jones clusters containing up to 45 atoms. Furthermore, we establish its practical applicability to real-world systems by optimizing 20-atom carbon clusters using a machine-learned Moment Tensor Potential, achieving geometries consistent with quantum-accurate simulations. This work establishes TT-decomposition as a powerful tool for molecular structure prediction and provides a general framework adaptable to a wide range of high-dimensional optimization problems in computational material science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18592v1</guid>
      <category>math.OC</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NE</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Konstantin Sozykin, Nikita Rybin, Andrei Chertkov, Anh-Huy Phan, Ivan Oseledets, Alexander Shapeev, Ivan Novikov, Gleb Ryzhakov</dc:creator>
    </item>
    <item>
      <title>A Unique Inverse Decomposition of Positive Definite Matrices under Linear Constraints</title>
      <link>https://arxiv.org/abs/2601.18662</link>
      <description>arXiv:2601.18662v1 Announce Type: new 
Abstract: We study a nonlinear decomposition of a positive definite matrix into two components: the inverse of another positive definite matrix and a symmetric matrix constrained to lie in a prescribed linear subspace. Equivalently, the inverse component is required to belong to the orthogonal complement of that subspace with respect to the trace inner product. Under a sharp nondegeneracy condition on the subspace, we show that every positive definite matrix admits a \emph{unique} decomposition of this form.
  This decomposition admits a variational characterization as the unique minimizer of a strictly convex log-determinant optimization problem, which in turn yields a natural dual formulation that can be efficiently exploited computationally. We derive several properties, including the stability of the decomposition.
  We further develop feasibility-preserving Newton-type algorithms with provable convergence guarantees and analyze their per-iteration complexity in terms of algebraic properties of the decomposed matrix and the underlying subspace. Finally, we show that the proposed decomposition arises naturally in exponential utility maximization, a central problem in mathematical finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18662v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Dolinsky, Or Zuk</dc:creator>
    </item>
    <item>
      <title>Self-Organizing Railway Traffic Management</title>
      <link>https://arxiv.org/abs/2601.17017</link>
      <description>arXiv:2601.17017v1 Announce Type: cross 
Abstract: Improving traffic management in case of perturbation is one of the main challenges in today's railway research. The great majority of the existing literature proposes approaches to make centralized decisions to minimize delay propagation. In this paper, we propose a new paradigm to the same aim: we design and implement a modular process to allow trains to self-organize. This process consists in having trains identifying their neighbors, formulating traffic management hypotheses, checking their compatibility and selecting the best ones through a consensus mechanism. Finally, these hypotheses are merged into a directly applicable traffic plan. In a thorough experimental analysis on a portion of the Italian network, we compare the results of self-organization with those of a state-of-the-art centralized approach. In particular, we make this comparison mimicking a realistic deployment thanks to a closed-loop framework including a microscopic railway simulator. The results indicate that self-organization achieves better results than the centralized algorithm, specifically thanks to the definition and exploitation of the instance decomposition allowed by the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17017v1</guid>
      <category>cs.CY</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Naldini, Fabio Oddi, Leo D'Amato, Gr\'egory Marli\`ere, Vito Trianni, Paola Pellegrini</dc:creator>
    </item>
    <item>
      <title>Set-Based Reachability for Low-Thrust Spacecraft in Two-Body and Cislunar Dynamical Systems</title>
      <link>https://arxiv.org/abs/2601.17155</link>
      <description>arXiv:2601.17155v1 Announce Type: cross 
Abstract: This paper investigates the application of zonotope-based reachability analysis to low-thrust spacecraft in both two-body and cislunar environments. Reachable sets are generated under two-body and circular restricted three-body (CR3BP) dynamics using set-based methods that approximate nonlinear systems via Taylor expansions. A state-dependent coefficient (SDC) parameterization is also explored to represent nonlinear dynamics in a pseudo-linear form, enabling efficient matrix based propagation of reachable sets. Applications include Earth-Mars transfer and cislunar scenarios such as L1 and L2 Halo orbits and Near Rectilinear Halo Orbits (NRHOs). The resulting reachable sets are used for safe trajectory generation and tracking, with comparisons drawn between model predictive control (MPC) and LQR-based station-keeping. The proposed approach provides a scalable framework for analyzing spacecraft behavior under complex dynamics and control constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17155v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>2025 AAS/AIAA Astrodynamics Specialist Conference, Boston, Massachusetts</arxiv:journal_reference>
      <dc:creator>Jinaykumar Patel, Kamesh Subbarao</dc:creator>
    </item>
    <item>
      <title>Learning Market Making with Closing Auctions</title>
      <link>https://arxiv.org/abs/2601.17247</link>
      <description>arXiv:2601.17247v1 Announce Type: cross 
Abstract: In this work, we investigate the market-making problem on a trading session in which a continuous phase on a limit order book is followed by a closing auction. Whereas standard optimal market-making models typically rely on terminal inventory penalties to manage end-of-day risk, ignoring the significant liquidity events available in closing auctions, we propose a Deep Q-Learning framework that explicitly incorporates this mechanism. We introduce a market-making framework designed to explicitly anticipate the closing auction, continuously refining the projected clearing price as the trading session evolves. We develop a generative stochastic market model to simulate the trading session and to emulate the market. Our theoretical model and Deep Q-Learning method is applied on the generator in two settings: (1) when the mid price follows a rough Heston model with generative data from this stochastic model; and (2) when the mid price corresponds to historical data of assets from the S&amp;P 500 index and the performance of our algorithm is compared with classical benchmarks from optimal market making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17247v1</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius Graf, Thibaut Mastrolia</dc:creator>
    </item>
    <item>
      <title>A New Look at the Ensemble Kalman Filter for Inverse Problems: Duality, Non-Asymptotic Analysis and Convergence Acceleration</title>
      <link>https://arxiv.org/abs/2601.17305</link>
      <description>arXiv:2601.17305v1 Announce Type: cross 
Abstract: This work presents new results and understanding of the Ensemble Kalman filter (EnKF) for inverse problems. In particular, using a Lagrangian dual perspective we show that EnKF can be derived from the sample average approximation (SAA) of the Lagrangian dual function. The beauty of this new duality perspective is that it facilitates us to prove and numerically verify a novel non-asymptotic convergence result for the EnKF. Motivated by the new perspective, we also present a new convergence improvement strategy for the Ensemble Kalman Inversion Algorithm (EnKI), which is an iterative version of the EnKF for inverse problems. In particular, we propose an adaptive multiplicative correction to the sample covariance matrix at each iteration and we call this new algorithm as EnKI-MC (I). Based on the new duality perspective, we derive an expression for the optimal correction factor at each iteration of the EnKI algorithm to accelerate the convergence. In addition, we also consider an ensemble specific multiplicative covariance correction strategy (EnKI-MC (II)) where a different correction is employed for each ensemble. By viewing EnKI through the lens of fixed-point iteration, we also provide theoretical results that guarantees the convergence of EnKI-MC (I) algorithm. Numerical investigations for the deconvolution problem, initial condition inversion in advection-convection problem, initial condition inversion in a Lorenz 96 model, and inverse problem constrained by elliptic partial differential equation are conducted to verify the non-asymptotic results for EnKF and to assess the performance of convergence improvement strategies for EnKI. The numerical results suggest that the proposed strategies for EnKI not only led to faster convergence in comparison to the currently employed techniques but also better quality solutions at termination of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17305v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C G Krishnanunni, Jonathan Wittmer, Tan Bui-Thanh, Quoc P. Nguyen</dc:creator>
    </item>
    <item>
      <title>Minimizing Completion Times of Stochastic Jobs on Parallel Machines is Hard</title>
      <link>https://arxiv.org/abs/2601.17425</link>
      <description>arXiv:2601.17425v1 Announce Type: cross 
Abstract: This paper considers the scheduling of stochastic jobs on parallel identical machines to minimize the expected total weighted completion time. While this is a classical problem with a significant body of research on approximation algorithms over the past two decades, constant-factor performance guarantees are currently known only under very restrictive assumptions on the input distributions, even when all job weights are identical. This algorithmic difficulty is striking given the lack of corresponding complexity results: to date, it is conceivable that the problem could be solved optimally in polynomial time.
  We address this gap with hardness results that demonstrate the problem's inherent intractability. For the special case of discrete two-point processing time distributions and unit weights, we prove that deciding whether there exists a scheduling policy with expected cost at most a given threshold is #P-hard. Furthermore, we show that evaluating the expected objective value of the standard (W)SEPT greedy policy is itself #P-hard. These represent the first hardness results for scheduling independent stochastic jobs and min-sum objective that do not merely rely on the intractability of the underlying deterministic counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17425v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Moseley, Kirk Pruhs, Marc Uetz, Rudy Zhou</dc:creator>
    </item>
    <item>
      <title>Uniqueness and stability in bottom detection through surface measurements of water waves</title>
      <link>https://arxiv.org/abs/2601.17639</link>
      <description>arXiv:2601.17639v1 Announce Type: cross 
Abstract: This paper investigates the geometric inverse problem of recovering the bottom shape from surface measurements of water waves. Using the general water-waves system on a bounded subdomain of the fluid domain, we address this inverse problem, focusing on the identifiability and the stability issues. We establish uniqueness and derive logarithmic stability estimates in the determination of the bathymetry on any fixed smooth, bounded, open domain
  ${\mathcal O}\subset {\mathbb R} ^d$, $d=1,2$, from the knowledge of the free surface, its first time derivative, the velocity potential at a given instant $t_0$ within $\mathcal O $, and the knowledge of the bottom along $\partial \mathcal O$. No further assumptions are required for uniqueness. For stability, we impose only a \textit{local fatness} condition on the region between the bottom profiles, allowing us to adapt the size estimates method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17639v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noureddine Lamsahel, Lionel Rosier</dc:creator>
    </item>
    <item>
      <title>A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization</title>
      <link>https://arxiv.org/abs/2601.17646</link>
      <description>arXiv:2601.17646v1 Announce Type: cross 
Abstract: Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlev\'e-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17646v1</guid>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karim Bounja, Lahcen Laayouni, Abdeljalil Sakat</dc:creator>
    </item>
    <item>
      <title>Composite Adaptive Control Barrier Functions for Safety-Critical Systems with Parametric Uncertainty</title>
      <link>https://arxiv.org/abs/2601.17683</link>
      <description>arXiv:2601.17683v1 Announce Type: cross 
Abstract: Control barrier functions guarantee safety but typically require accurate system models. Parametric uncertainty invalidates these guarantees. Existing robust methods maintain safety via worst-case bounds, limiting performance, while modular learning schemes decouple estimation from safety, permitting state violations during training. This paper presents the composite adaptive control barrier function (CaCBF) algorithm for nonlinear control-affine systems subject to linear parametric uncertainty. We derive adaptation laws from a composite energy function comprising a logarithmic safety barrier, a control Lyapunov function, and a parameter error term. We prove that CaCBF guarantees the forward invariance of the safe set and the uniform boundedness of the closed-loop system. This safety guarantee holds without requiring parameter convergence. Simulations of adaptive cruise control, an omnidirectional robot, and a planar drone demonstrate the efficacy of the CaCBF algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17683v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadreza Kamaldar</dc:creator>
    </item>
    <item>
      <title>A PDE Derivation of the Schr\"odinger--Bass Bridge</title>
      <link>https://arxiv.org/abs/2601.17863</link>
      <description>arXiv:2601.17863v1 Announce Type: cross 
Abstract: This short paper announces the main results of \cite{SBB2026}, where the Schr\"odinger--Bass Bridge (SBB) problem is introduced and studied in full generality. Here we provide a direct PDE derivation of the SBB system in dimension one, showing how the optimal coupling problem that interpolates between the classical Schr\"odinger bridge and the Bass martingale transport can be solved explicitly via Legendre transforms and the heat equation. A key insight is that the optimal SBB process is a Stretched Schr\"odinger Bridge: the composition of a monotone transport map with a Schr\"odinger bridge. This extends the stretched Brownian motion representation of Bass martingales to the semimartingale setting and provides a unified framework that recovers both the Sinkhorn algorithm (in the limit $\beta \to \infty$) and the Bass construction (as $\beta \to 0$). We refer to \cite{SBB2026} for complete proofs, the multidimensional setting, strong duality, dual attainment, and further developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17863v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Alouadi, Pierre Henry-Labord\`ere, Gr\'egoire Loeper, Othmane Mazhar, Huy\^en Pham, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Robust Learning of a Group DRO Neuron</title>
      <link>https://arxiv.org/abs/2601.18115</link>
      <description>arXiv:2601.18115v1 Announce Type: cross 
Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbol{\lambda} \in \Delta_K$, where the objective is $\sum_{i \in [K]}\lambda_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(\sigma(\mathbf w\cdot\mathbf x)-y)^2 - \nu d_f(\boldsymbol\lambda,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $\nu \geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18115v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guyang Cao, Shuyao Li, Sushrut Karmalkar, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Decentralized Multi-product Pricing: Diagonal Dominance, Nash Equilibrium, and Price of Anarchy</title>
      <link>https://arxiv.org/abs/2601.18117</link>
      <description>arXiv:2601.18117v1 Announce Type: cross 
Abstract: Decentralized decision making in multi--product firms can lead to efficiency losses when autonomous decision makers fail to internalize cross--product demand interactions. This paper quantifies the magnitude of such losses by analyzing the Price of Anarchy in a pricing game in which each decision maker independently sets prices to maximize its own product--level revenue. We model demand using a linear system that captures both substitution and complementarity effects across products. We first establish existence and uniqueness of a pure--strategy Nash equilibrium under economically standard diagonal dominance conditions. Our main contribution is the derivation of a tight worst--case lower bound on the ratio between decentralized revenue and the optimal centralized revenue. We show that this efficiency loss is governed by a single scalar parameter, denoted by $\mu$, which measures the aggregate strength of cross--price effects relative to own--price sensitivities. In particular, we prove that the revenue ratio is bounded below by $4(1-\mu)/(2-\mu)^2$, and we demonstrate the tightness of this bound by constructing a symmetric market topology in which the bound is exactly attained. We further refine the analysis by providing an instance--exact characterization of efficiency loss based on the spectral properties of the demand interaction matrix. Together, these results offer a quantitative framework for assessing the trade--off between centralized pricing and decentralized autonomy in multi--product firms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18117v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boxiao Chen, Jiashuo Jiang, Stefanus Jasin</dc:creator>
    </item>
    <item>
      <title>Topology optimization of passively moving rigid bodies in unsteady flows</title>
      <link>https://arxiv.org/abs/2601.18272</link>
      <description>arXiv:2601.18272v1 Announce Type: cross 
Abstract: This study proposes the topology optimization method for moving rigid bodies subjected to forces from fluid flow, such as sails and turbines, with an unsteady time-dependent formulation. Unlike existing topology optimization frameworks in which rigid-body motion drives the flow, which is referred to as $\textit{active}$, the present study considers rigid-body motion induced by fluid forces, i.e., $\textit{passive}$. The equations of motion governing the rigid-body dynamics are solved in a coupled manner with the continuity equation and the momentum conservation equations. The rigid body is represented on a design grid that is separated from the analysis grid on which the state and adjoint fields are defined. After updating the rigid body motion, the body is mapped onto the analysis grid. The fluid equations are solved using the lattice kinetic scheme, an extended version of the lattice Boltzmann method, owing to its suitability for unsteady flows. Design sensitivities based on the adjoint variable method are presented and applied to two- and three-dimensional problems involving translational and rotational motions. The optimized shapes for each problem are discussed from a physical perspective and compared with a reference shape or their binarized counterparts, providing insights into the effectiveness of the proposed method as well as its limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18272v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuta Tanabe, Kentaro Yaji, Kuniharu Ushijima</dc:creator>
    </item>
    <item>
      <title>Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control</title>
      <link>https://arxiv.org/abs/2601.18313</link>
      <description>arXiv:2601.18313v1 Announce Type: cross 
Abstract: This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18313v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Teruki Kato, Ryotaro Shima, Kenji Kashima</dc:creator>
    </item>
    <item>
      <title>ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule</title>
      <link>https://arxiv.org/abs/2601.18681</link>
      <description>arXiv:2601.18681v1 Announce Type: cross 
Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fr\'echet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18681v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang, Wenpin Tang, Xunyu Zhou</dc:creator>
    </item>
    <item>
      <title>Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data</title>
      <link>https://arxiv.org/abs/2601.18728</link>
      <description>arXiv:2601.18728v1 Announce Type: cross 
Abstract: Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18728v1</guid>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Willem Diepeveen, Oscar Leong</dc:creator>
    </item>
    <item>
      <title>Low-Bit Quantization of Bandlimited Graph Signals via Iterative Methods</title>
      <link>https://arxiv.org/abs/2601.18782</link>
      <description>arXiv:2601.18782v1 Announce Type: cross 
Abstract: We study the quantization of real-valued bandlimited signals on graphs, focusing on low-bit representations. We propose iterative noise-shaping algorithms for quantization, including sampling approaches with and without vertex replacement. The methods leverage the spectral properties of the graph Laplacian and exploit graph incoherence to achieve high-fidelity approximations. Theoretical guarantees are provided for the random sampling method, and extensive numerical experiments on synthetic and real-world graphs illustrate the efficiency and robustness of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18782v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.GR</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Felix Krahmer, He Lyu, Rayan Saab, Jinna Qian, Anna Veselovska, Rongrong Wang</dc:creator>
    </item>
    <item>
      <title>Path Planning for Aerial Relays via Probabilistic Roadmaps</title>
      <link>https://arxiv.org/abs/2310.11752</link>
      <description>arXiv:2310.11752v4 Announce Type: replace 
Abstract: Autonomous unmanned aerial vehicles (UAVs) can be utilized as aerial relays to serve users far from terrestrial infrastructure. Unfortunately, existing algorithms for aerial relay path planning cannot accommodate general flight constraints or channel models. This is required in practice due to connectivity constraints, the presence of obstacles (e.g., buildings), and regulations. This paper proposes a framework that overcomes these limitations by spatially discretizing the flight region. To cope with the resulting exponential growth in complexity, the framework adopts a probabilistic roadmap approach, where a shortest path is found through a graph of randomly generated states. To attain high optimality with affordable complexity, the probability distribution used to generate these states is designed based on heuristic path planners with theoretical guarantees. The algorithms derived in this framework not only overcome the main limitations of existing schemes but also entail smaller computational complexity. Extensive theoretical and numerical results corroborate the merits of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11752v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Q. Viet, Daniel Romero</dc:creator>
    </item>
    <item>
      <title>Immunity to Increasing Condition Numbers of Linear Superiorization versus Linear Programming</title>
      <link>https://arxiv.org/abs/2407.18709</link>
      <description>arXiv:2407.18709v2 Announce Type: replace 
Abstract: Given a family of linear constraints and a linear objective function one can consider whether to apply a Linear Programming (LP) algorithm or use a Linear Superiorization (LinSup) algorithm on this data. In the LP methodology one aims at finding an optimal point, i.e., a point that fulfills the constraints and has the minimal value of the objective function over these constraints. The Linear Superiorization approach considers the same data as linear programming problems but instead of attempting to solve those with linear programming methods it employs perturbation resilient feasibility-seeking algorithms and steers them toward a feasible point with reduced (not necessarily minimal) objective function value. This aim of the superiorization method (SM) is less demanding than aiming to reach full-fledged constrained optimality and it places more importance on reaching feasibility than on reaching optimality. Previous studies (e. g. [12]) compared LP and LinSup in terms of their respective outputs and the resources they use. This paper is a follow-up analysis of [12], where we investigate classical LP approaches and LinSup in terms of their sensitivity to condition numbers of the system of linear constraints. Condition numbers are a measure for the impact of deviations in the input data on the output of a problem and, in particular, they describe the factor of error propagation when given wrong or erroneous data. Therefore, the ability of LP and LinSup to cope with increased condition numbers, thus with ill-posed problems, is an important matter to consider which was not studied until now. We investigate experimentally the advantages and disadvantages of both LP and LinSup on exemplary problems of linear programming with multiple condition numbers and different problem dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18709v2</guid>
      <category>math.OC</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Schr\"oder, Yair Censor, Philipp S\"uss, Karl-Heinz K\"ufer</dc:creator>
    </item>
    <item>
      <title>A Probabilistic Approach to Shape Derivatives</title>
      <link>https://arxiv.org/abs/2409.15967</link>
      <description>arXiv:2409.15967v2 Announce Type: replace 
Abstract: We introduce a novel mesh-free and direct method for computing the shape derivative in PDE-constrained shape optimization problems. Our approach is based on a probabilistic representation of the shape derivative and is applicable for second-order semilinear elliptic PDEs with Dirichlet boundary conditions and a general class of target functions. The probabilistic representation derives from an extension of a boundary sensitivity result for diffusion processes due to Costantini, Gobet and El Karoui [14]. Moreover, we present a simulation methodology based on our results that does not necessarily require a mesh of the relevant domain, and provide Taylor tests to verify its numerical accuracy</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15967v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luka Schlegel (University of Trier), Volker Schulz (University of Trier), Frank T. Seifried (University of Trier), Maximilian W\"urschmidt (University of Trier)</dc:creator>
    </item>
    <item>
      <title>NOMADS: Non-Markovian Optimization-based Modeling for Approximate Dynamics with Spatially-homogeneous Memory</title>
      <link>https://arxiv.org/abs/2409.19978</link>
      <description>arXiv:2409.19978v2 Announce Type: replace 
Abstract: We propose a system identification method, Non-Markovian Optimization-based Modeling for Approximate Dynamics with Spatially-homogeneous memory (NOMADS), for identifying linear dynamical systems from a set of multi-dimensional time-series data obtained through multiple partially excited experiments. NOMADS formulates model identification as a convex optimization problem, in which the state-space coefficient matrices and a memory kernel are estimated jointly under physically motivated constraints using projected gradient descent. The proposed framework models memory effects through a spatially homogeneous kernel, enabling scalable identification of non-Markovian dynamics while keeping the number of free parameters moderate. This structure allows NOMADS to integrate information from multiple multi-dimensional time-series data even when no single experiment provides full excitation. In the Markovian setting, physical constraints can be incorporated to enforce conservation laws. Numerical experiments on synthetic data demonstrate that NOMADS achieves substantially improved generalization accuracy compared to existing DMD-based methods even for noisy train data, and reproduces energy conservation in the Markovian case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19978v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryoji Anzaki, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal control with measurable coefficients via $L^p$-viscosity solutions and applications to optimal advertising</title>
      <link>https://arxiv.org/abs/2502.02352</link>
      <description>arXiv:2502.02352v2 Announce Type: replace 
Abstract: Stochastic optimal control control problems with merely measurable coefficients are not well understood. In this manuscript, we consider fully non-linear stochastic optimal control problems in infinite horizon with measurable coefficients and (local) uniformly elliptic diffusion. Using the theory of $L^p$-viscosity solutions, we show existence of an $L^p$-viscosity solution $v\in W_{\rm loc}^{2,p}$ of the Hamilton-Jacobi-Bellman (HJB) equation, which, in turn, is also a strong solution (i.e. it satisfies the HJB equation pointwise a.e.). We are then led to prove verification theorems, providing necessary and sufficient conditions for optimality. These results allow us to construct optimal feedback controls and to characterize the value function as the unique $L^p$-viscosity solution of the HJB equation. To the best of our knowledge, these are the first results for fully non-linear stochastic optimal control problems with measurable coefficients. We use the theory developed to solve a stochastic optimal control problem arising in economics within the context of optimal advertising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02352v2</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>math.PR</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo</dc:creator>
    </item>
    <item>
      <title>Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning</title>
      <link>https://arxiv.org/abs/2503.04668</link>
      <description>arXiv:2503.04668v3 Announce Type: replace 
Abstract: In this paper, we propose a novel distributed data-driven optimization scheme. In detail, we focus on the so-called aggregative framework, a scenario in which a set of agents aim to cooperatively minimize the sum of local costs, each depending on both local decision variables and an aggregation of all of them. We consider a data-driven setup where each objective function is unknown and can be sampled at a single point per iteration (thanks to, e.g., feedback from users or sensors). We address this scenario through a distributed algorithm combining three components: (i) a learning part leveraging neural networks to learn the local costs descent direction, (ii) an optimization routine steering the estimates according to the learned direction to minimize the global cost, and (iii) a tracking mechanism locally reconstructing the unavailable global quantities. Using tools from system theory, i.e., timescale separation and averaging theory, we formally prove that in strongly convex setups, the distributed scheme linearly converges to a neighborhood of the optimum, whose radius depends on the accuracy of the neural networks. Finally, numerical simulations validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04668v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Brumali, Guido Carnevale, Giuseppe Notarstefano</dc:creator>
    </item>
    <item>
      <title>Constrained Parameter Update Law for Adaptive Control</title>
      <link>https://arxiv.org/abs/2504.19412</link>
      <description>arXiv:2504.19412v3 Announce Type: replace 
Abstract: In this paper, a constrained parameter update law is derived in the context of adaptive control. The parameter update law is based on constrained optimization technique where a Lagrangian is formulated to incorporate the constraints on the parameters using inverse Barrier function. The constrained parameter update law is used to develop a adaptive tracking controller and the overall stability of the adaptive controller along with the constrained parameter update law is shown using Lyapunov analysis and development in stability of constrained primal-dual dynamics. The performance of the constrained parameter update law is tested in simulation for keeping the parameters within constraints and convergence to true parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19412v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ashwin P. Dani</dc:creator>
    </item>
    <item>
      <title>An efficient second-order cone programming approach for dynamic optimal transport on staggered grid discretization</title>
      <link>https://arxiv.org/abs/2505.05424</link>
      <description>arXiv:2505.05424v2 Announce Type: replace 
Abstract: This paper proposes an efficient numerical method based on second-order cone programming (SOCP) to solve dynamic optimal transport (DOT) problems with quadratic cost on staggered grid discretization. By properly reformulating discretized DOT problems into a linear SOCP, the proposed method eliminates the interpolation matrices and thus avoids solving a series of cubic equations and linear systems induced by interpolation. Then, by taking advantage of the SOCP reformulation, we can solve them efficiently by a computationally highly economical implementation of an inexact decomposition-based proximal augmented Lagrangian method. Moreover, we have made the proposed approach an open-source software package. Numerical experiments on various DOT problems suggest that the proposed approach performs significantly more efficiently than state-of-the-art software packages. In addition, it exhibits prominent robustness to problems with non-negative measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05424v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Chen, Youyicun Lin, Yuxuan Zhou</dc:creator>
    </item>
    <item>
      <title>Research on Optimal Control Problem Based on Reinforcement Learning under Knightian Uncertainty</title>
      <link>https://arxiv.org/abs/2506.13207</link>
      <description>arXiv:2506.13207v2 Announce Type: replace 
Abstract: Considering that the decision-making environment faced by reinforcement learning (RL) agents is full of Knightian uncertainty, this paper describes the exploratory state dynamics equation in Knightian uncertainty to study the entropy-regularized relaxed stochastic control problem in a Knightian uncertainty environment. By employing stochastic analysis theory and the dynamic programming principle under nonlinear expectation, we derive the Hamilton-Jacobi-Bellman (HJB) equation and solve for the optimal policy that achieves a trade-off between exploration and exploitation. Subsequently, for the linear-quadratic (LQ) case, we examine the agent's optimal randomized feedback control under both state-dependent and state-independent reward scenarios, proving that the optimal randomized feedback control follows a Gaussian distribution in the LQ framework. Furthermore, we investigate how the degree of Knightian uncertainty affects the variance of the optimal feedback policy. Additionally, we establish the solvability equivalence between non-exploratory and exploratory LQ problems under Knightian uncertainty and analyze the associated exploration cost. Finally, we provide an LQ example and validate the theoretical findings through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13207v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyu Li, Chen Fei, Weiyin Fei</dc:creator>
    </item>
    <item>
      <title>A generalized canonical metric for optimization on the indefinite Stiefel manifold</title>
      <link>https://arxiv.org/abs/2509.16113</link>
      <description>arXiv:2509.16113v2 Announce Type: replace 
Abstract: Various tasks in scientific computing can be modeled as an optimization problem on the indefinite Stiefel manifold. We address this using the Riemannian approach, which basically consists of equipping the feasible set with a Riemannian metric, preparing geometric tools such as orthogonal projections, formulae for Riemannian gradient, retraction and then extending an unconstrained optimization algorithm on the Euclidean space to the established manifold. The choice for the metric undoubtedly has a great influence on the method. In the previous work [D.V. Tiep and N.T. Son, A Riemannian gradient descent method for optimization on the indefinite Stiefel manifold, arXiv:2410.22068v2[math.OC]], a tractable metric, which is indeed a family of Riemannian metrics defined by a symmetric positive-definite matrix depending on the contact point, has been used. In general, it requires solving a Lyapunov matrix equation every time when the gradient of the cost function is needed, which might significantly contribute to the computational cost. To address this issue, we propose a new Riemannian metric for the indefinite Stiefel manifold. Furthermore, we construct the associated geometric structure, including a so-called quasi-geodesic and propose a retraction based on this curve. We then numerically verify the performance of the Riemannian gradient descent method associated with the new geometry and compare it with the previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16113v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinh Van Tiep, Duong Thi Viet An, Nguyen Thi Ngoc Oanh, Nguyen Thanh Son</dc:creator>
    </item>
    <item>
      <title>Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results</title>
      <link>https://arxiv.org/abs/2511.00752</link>
      <description>arXiv:2511.00752v3 Announce Type: replace 
Abstract: This paper introduces a novel model-free, real-time unicycle-based source seeking design. This design autonomously steers the unicycle dynamic system towards the extremum point of an objective function or physical/scalar signal that is unknown expression-wise, but accessible via measurements. A key contribution of this paper is that the introduced design converges exponentially to the extremum point of objective functions (or scalar signals) that behave locally like a higher-degree power function (e.g., fourth-degree polynomial function) as opposed to locally quadratic objective functions, the usual case in literature. We provide theoretical results and design characterization, supported by a variety of simulation results that demonstrate the robustness of the proposed design, including cases with different initial conditions and measurement delays/noise. Also, for the first time in the literature, we provide experimental robotic results that demonstrate the effectiveness of the proposed design and its exponential convergence ability. These experimental results confirm that the proposed exponentially convergent extremum seeking design can be practically realized on a physical robotic platform under real-world sensing and actuation constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00752v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Palanikumar, Ahmed A. Elgohary, Victoria Grushkovskaya, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>A Unified Phase-Field Fourier Neural Network Framework for Topology Optimization</title>
      <link>https://arxiv.org/abs/2511.14623</link>
      <description>arXiv:2511.14623v2 Announce Type: replace 
Abstract: We propose Alternating Phase-Field Fourier Neural Networks (APF-FNNs) as a unified and physics-based framework for topology optimization. The approach decouples the design problem by representing the state, adjoint, and topology fields with three separate Fourier neural networks, which are trained via a stable collaborative alternating scheme applicable to both self-adjoint and non-self-adjoint problems. To obtain well-resolved designs, the Ginzburg--Landau energy functional is embedded in the loss of the topology network as an intrinsic regularizer, naturally enforcing smooth and distinct interfaces between the two phases. Phase-field updates are driven by adjoint-based optimality conditions, and design sensitivities are evaluated efficiently using automatic differentiation, ensuring that the gradients correspond to exact total derivatives rather than naive partial derivatives. In contrast to classical phase-field methods, APF-FNNs exploit these physically consistent design gradients directly, avoiding pseudo-time gradient-flow solvers. By formulating physics-driven losses from variational principles or strong-form PDE residuals, the framework is broadly applicable to 2D and 3D benchmark problems, including compliance minimization, eigenvalue maximization, and Stokes/Navier--Stokes flow optimization. Across these examples, APF-FNNs consistently yield competitive performance and well-resolved topologies, establishing a versatile and scalable foundation for physics-driven computational design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14623v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Li, Xindi Hu, Helin Gong, Wei Gong, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>A Smooth Approximation Framework for Weakly Convex Optimization</title>
      <link>https://arxiv.org/abs/2512.09720</link>
      <description>arXiv:2512.09720v3 Announce Type: replace 
Abstract: Standard complexity analyses for weakly convex optimization rely on the Moreau envelope technique proposed by Davis and Drusvyatskiy (2019). The main insight is that nonsmooth algorithms, such as proximal subgradient, proximal point, and their stochastic variants, implicitly minimize a smooth surrogate function induced by the Moreau envelope. Meanwhile, explicit smoothing, which directly minimizes a smooth approximation of the objective, has long been recognized as an efficient strategy for nonsmooth optimization. In this paper, we generalize the notion of smoothable functions, which was proposed by Beck and Teboulle (2012) for nonsmooth convex optimization. This generalization provides a unified viewpoint on several important smoothing techniques for weakly convex optimization, including Nesterov-type smoothing and Moreau envelope smoothing. Our theory yields a framework for designing smooth approximation algorithms for both deterministic and stochastic weakly convex problems with provable complexity guarantees. Furthermore, our theory extends to the smooth approximation of non-Lipschitz functions, allowing for complexity analysis even when global Lipschitz continuity does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09720v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Deng, Wenzhi Gao</dc:creator>
    </item>
    <item>
      <title>Extragradient methods with complexity guarantees for hierarchical variational inequalities</title>
      <link>https://arxiv.org/abs/2512.20791</link>
      <description>arXiv:2512.20791v2 Announce Type: replace 
Abstract: In the framework of a real Hilbert space we consider the problem of approaching solutions to a class of hierarchical variational inequality problems, subsuming several other problem classes including certain mathematical programs under equilibrium constraints, constrained min-max problems, hierarchical game problems, optimal control under VI constraints, and simple bilevel optimization problems. For this general problem formulation, we establish rates of convergence in terms of suitably constructed gap functions, measuring feasibility gaps and optimality gaps. We present worst-case iteration complexity results on both levels of the variational problem, as well as weak convergence under a geometric weak sharpness condition on the lower level solution set. Our results match and improve the state of the art in terms of their iteration complexity and the generality of the problem formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20791v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pavel Dvurechensky, Meggie Marschner, Shimrit Shtern, Mathias Staudigl</dc:creator>
    </item>
    <item>
      <title>Robustness of the Frank-Wolfe Method under Inexact Oracles and the Cost of Linear Minimization</title>
      <link>https://arxiv.org/abs/2601.11548</link>
      <description>arXiv:2601.11548v2 Announce Type: replace 
Abstract: We investigate the robustness of the Frank-Wolfe method when gradients are computed inexactly and examine the relative computational cost of the linear minimization oracle (LMO) versus projection. For smooth nonconvex functions, we establish a convergence guarantee of order $\mathcal{O}(1/\sqrt{k}+\delta)$ for Frank-Wolfe with a $\delta$--oracle. Our results strengthen previous analyses for convex objectives and show that the oracle errors do not accumulate asymptotically. We further prove that approximate projections cannot be computationally cheaper than accurate LMOs, thus extending to the case of inexact projections. These findings reinforce the robustness and efficiency of the Frank-Wolfe framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11548v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Hu</dc:creator>
    </item>
    <item>
      <title>Simulation-Optimization Approaches for the Network Immunization Problem with Quarantining</title>
      <link>https://arxiv.org/abs/2406.15814</link>
      <description>arXiv:2406.15814v2 Announce Type: replace-cross 
Abstract: Vaccination has played an important role in preventing the spread of infectious diseases. However, the limited availability of vaccines and personnel at the roll-out of a new vaccine and the costs of vaccination campaigns often limit how many people can be vaccinated. Network immunization thus focuses on selecting a fixed-size subset of individuals to vaccinate so as to minimize the disease spread. In this paper, we consider simulation-optimization approaches for this selection problem. Here, the simulation of disease spread in an activity-based contact graph allows us to consider the effect of contact tracing and a limited willingness to test and quarantine. First, we develop a stochastic programming heuristic based on sampling infection forests from the simulation. Second, we propose a genetic algorithm tailored to the immunization problem that combines simulation runs of different sizes to balance the time needed to find promising solutions with the uncertainty resulting from simulation. Both approaches are tested on data from a major university in Denmark and disease characteristics representing those of COVID-19. Our results show that the proposed methods are competitive with a large number of centrality-based measures over a range of disease parameters and that especially the stochastic programming heuristic can outperform them for a considerable number of these instances. Finally, we compare network immunization against our previously proposed approach of limiting distinct contacts. Although, independently, network immunization has a larger impact in reducing disease spread, we show that the combination of both methods reduces the disease spread even further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15814v2</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2026.01.019</arxiv:DOI>
      <dc:creator>Rowan Hoogervorst, Evelien van der Hurk, David Pisinger</dc:creator>
    </item>
    <item>
      <title>NPA Hierarchy for Quantum Isomorphism and Homomorphism Indistinguishability</title>
      <link>https://arxiv.org/abs/2407.10635</link>
      <description>arXiv:2407.10635v3 Announce Type: replace-cross 
Abstract: Man\v{c}inska and Roberson [FOCS'20] showed that two graphs are quantum isomorphic if and only if they admit the same number of homomorphisms from any planar graph. Atserias et al. [JCTB'19] proved that quantum isomorphism is undecidable in general, which motivates the study of its relaxations. In the classical setting, Roberson and Seppelt [ICALP'23] characterized the feasibility of each level of the Lasserre hierarchy of semidefinite programming relaxations of graph isomorphism in terms of equality of homomorphism counts from an appropriate graph class. The NPA hierarchy, a noncommutative generalization of the Lasserre hierarchy, provides a sequence of semidefinite programming relaxations for quantum isomorphism. In the quantum setting, we show that the feasibility of each level of the NPA hierarchy for quantum isomorphism is equivalent to equality of homomorphism counts from an appropriate class of planar graphs. Combining this characterization with the convergence of the NPA hierarchy, and noting that the union of these classes is the set of all planar graphs, we obtain a new proof of the result of Man\v{c}inska and Roberson [FOCS'20] that avoids the use of quantum groups. Moreover, this homomorphism indistinguishability characterization also yields a randomized polynomial-time algorithm deciding exact feasibility of each fixed level of the NPA hierarchy of SDP relaxations for quantum isomorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10635v3</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prem Nigam Kar, David E. Roberson, Tim Seppelt, Peter Zeman</dc:creator>
    </item>
    <item>
      <title>Error analysis for stochastic gradient optimization schemes using modified equations</title>
      <link>https://arxiv.org/abs/2411.05538</link>
      <description>arXiv:2411.05538v2 Announce Type: replace-cross 
Abstract: We consider a class of stochastic gradient optimization schemes. Assuming that the objective function is strongly convex, we prove weak error estimates which are uniform in time for the error between the solution of the numerical scheme, and the solutions of continuous-time modified (or high-resolution) differential equations at first and second orders, with respect to the time-step size. At first order, the modified equation is deterministic, whereas at second order the modified equation is stochastic and depends on a modified objective function. We go beyond existing results where the error estimates have been considered only on finite time intervals and were not uniform in time. This allows us to then provide a rigorous complexity analysis of the method in the large time and small time-step size regimes. We provide numerical experiments to illustrate the convergence results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05538v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles-Edouard Br\'ehier, Marc Dambrine, Nassim En-Nebbazi</dc:creator>
    </item>
    <item>
      <title>Shape optimization for piecewise parameter identification in inverse diffusion problems with a single boundary measurement</title>
      <link>https://arxiv.org/abs/2503.14764</link>
      <description>arXiv:2503.14764v3 Announce Type: replace-cross 
Abstract: This paper explores the reconstruction of a space-dependent parameter in inverse diffusion problems, proposing a shape-optimization-based approach. We consider a Robin boundary condition, physically motivated in diffuse optical tomography to model partial reflection of light at tissue boundaries [Arr99, GFB83a]. This ensures well-posedness of the forward problem, while related inverse problems with Dirichlet or Neumann conditions have also been considered in previous studies [Mef21]. The main objective is to recover the absorption coefficient from a single boundary measurement. While conventional gradient-based methods rely on the Frechet derivative of a cost functional with respect to the unknown parameter, we also utilize its Eulerian derivative with respect to the unknown boundary interface for recovery. This non-conventional approach addresses parameter recovery when only a single boundary measurement can be obtained, providing a method for its reconstruction. Numerical experiments confirm the effectiveness of the proposed method, even for intricate and non-convex boundary interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14764v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manabu Machida, Hirofumi Notsu, Julius Fergy Tiongson Rabago</dc:creator>
    </item>
    <item>
      <title>An extrapolated and provably convergent algorithm for nonlinear matrix decomposition with the ReLU function</title>
      <link>https://arxiv.org/abs/2503.23832</link>
      <description>arXiv:2503.23832v2 Announce Type: replace-cross 
Abstract: ReLU matrix decomposition (RMD) is the following problem: given a sparse, nonnegative matrix $X$ and a factorization rank $r$, identify a rank-$r$ matrix $\Theta$ such that $X\approx \max(0,\Theta)$. RMD is a particular instance of nonlinear matrix decomposition (NMD) that finds application in data compression, matrix completion with entries missing not at random, and manifold learning. The standard RMD model minimizes the least squares error, that is, $\|X - \max(0,\Theta)\|_F^2$. The corresponding optimization problem, Least-Squares RMD (LS-RMD), is nondifferentiable and highly nonconvex. This motivated Saul to propose an alternative model, \revise{dubbed Latent-RMD}, where a latent variable $Z$ is introduced and satisfies $\max(0,Z)=X$ while minimizing $\|Z - \Theta\|_F^2$ (``A nonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J.\ Math.\ Data Sci., 2022). Our first contribution is to show that the two formulations may yield different low-rank solutions $\Theta$. We then consider a reparametrization of the Latent-RMD, called 3B-RMD, in which $\Theta$ is substituted by a low-rank product $WH$, where $W$ has $r$ columns and $H$ has $r$ rows. Our second contribution is to prove the convergence of a block coordinate descent (BCD) approach applied to 3B-RMD. Our third contribution is a novel extrapolated variant of BCD, dubbed eBCD, which we prove is also convergent under mild assumptions. We illustrate the significant acceleration effect of eBCD compared to eBCD, and also show that eBCD performs well against the state of the art on synthetic and real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23832v2</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Gillis, Margherita Porcelli, Giovanni Seraghiti</dc:creator>
    </item>
    <item>
      <title>Architecture independent generalization bounds for overparametrized deep ReLU networks</title>
      <link>https://arxiv.org/abs/2504.05695</link>
      <description>arXiv:2504.05695v5 Announce Type: replace-cross 
Abstract: We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05695v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anandatheertha Bapu, Thomas Chen, Chun-Kai Kevin Chien, Patricia Mu\~noz Ewald, Andrew G. Moore</dc:creator>
    </item>
    <item>
      <title>Variational quantum algorithms for permutation-based combinatorial problems: Optimal ansatz generation with applications to quadratic assignment problems and beyond</title>
      <link>https://arxiv.org/abs/2505.05981</link>
      <description>arXiv:2505.05981v3 Announce Type: replace-cross 
Abstract: We present a quantum variational algorithm based on a novel circuit that generates all permutations that can be spanned by one- and two-qubits permutation gates. The construction of the circuits follows from group-theoretical results, most importantly the Bruhat decomposition of the group generated by the \(\mathtt{cx}\) gates. These circuits require a number of qubits that scale logarithmically with the permutation dimension, and are therefore employable in near-term applications. We further augment the circuits with ancilla qubits to enlarge their span, and with these we build ansatze to tackle permutation-based optimization problems such as quadratic assignment problems, and graph isomorphisms. The resulting quantum algorithm, \textsc{QuPer}, is competitive with respect to classical heuristics and we could simulate its behavior up to a problem with $256$ variables, requiring $20$ qubits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05981v3</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dylan Laplace Mermoud, Andrea Simonetto, Sourour Elloumi</dc:creator>
    </item>
    <item>
      <title>Backpressure-based Mean-field Type Game for Scheduling in Multi-Hop Wireless Sensor Networks</title>
      <link>https://arxiv.org/abs/2506.03059</link>
      <description>arXiv:2506.03059v2 Announce Type: replace-cross 
Abstract: We propose a Mean-Field Type Game (MFTG) framework for effective scheduling in multi-hop wireless sensor networks (WSNs) using backpressure as a performance criterion. Traditional backpressure algorithms leverage queue differentials to regulate data flow and maintain network stability. In this work, we extend the backpressure framework by incorporating a mean-field term into the cost functional, capturing the global behavior of the system alongside local dynamics. The resulting model utilizes the strengths of non-cooperative mean-field type games, enabling nodes to make decentralized decisions based on both individual queue states and system mean-field effects while accounting for stochastic network interactions. By leveraging the interplay between backpressure dynamics and mean-field coupling, the approach balances local optimization with global efficiency. Numerical simulations demonstrate the efficacy of the proposed method in handling congestion and scheduling in large-scale WSNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03059v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Salah Eddine Choutri, Boualem Djehiche, Prajwal Chauhan, Saif Eddin Jabari</dc:creator>
    </item>
    <item>
      <title>When and How Unlabeled Data Provably Improve In-Context Learning</title>
      <link>https://arxiv.org/abs/2506.15329</link>
      <description>arXiv:2506.15329v2 Announce Type: replace-cross 
Abstract: Recent research shows that in-context learning (ICL) can be effective even when demonstrations have missing or incorrect labels. To shed light on this capability, we examine a canonical setting where the demonstrations are drawn according to a binary Gaussian mixture model (GMM) and a certain fraction of the demonstrations have missing labels. We provide a comprehensive theoretical study to show that: (1) The loss landscape of one-layer linear attention models recover the optimal fully-supervised estimator but completely fail to exploit unlabeled data; (2) In contrast, multilayer or looped transformers can effectively leverage unlabeled data by implicitly constructing estimators of the form $\sum_{i\ge 0} a_i (X^\top X)^iX^\top y$ with $X$ and $y$ denoting features and partially-observed labels (with missing entries set to zero). We characterize the class of polynomials that can be expressed as a function of depth and draw connections to Expectation Maximization, an iterative pseudo-labeling algorithm commonly used in semi-supervised learning. Importantly, the leading polynomial power is exponential in depth, so mild amount of depth/looping suffices. As an application of theory, we propose looping off-the-shelf tabular foundation models to enhance their semi-supervision capabilities. Extensive evaluations on real-world datasets show that our method significantly improves the semisupervised tabular learning performance over the standard single pass inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15329v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingcong Li, Xiangyu Chang, Muti Kara, Xiaofeng Liu, Amit Roy-Chowdhury, Samet Oymak</dc:creator>
    </item>
    <item>
      <title>Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise</title>
      <link>https://arxiv.org/abs/2509.22500</link>
      <description>arXiv:2509.22500v2 Announce Type: replace-cross 
Abstract: Constrained optimization is a powerful framework for enforcing requirements on neural networks. These constrained deep learning problems are typically solved using first-order methods on their min-max Lagrangian formulation, but such approaches often suffer from oscillations and can fail to find all local solutions. While the Augmented Lagrangian method (ALM) addresses these issues, practitioners often favor dual optimistic ascent schemes (PI control) on the standard Lagrangian, which perform well empirically but lack formal guarantees. In this paper, we establish a previously unknown equivalence between these approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient descent-ascent on the Augmented Lagrangian. This finding allows us to transfer the robust theoretical guarantees of the ALM to the dual optimistic setting, proving it converges linearly to all local solutions. Furthermore, the equivalence provides principled guidance for tuning the optimism hyper-parameter. Our work closes a critical gap between the empirical success of dual optimistic methods and their theoretical foundation in the single-step, first-order regime commonly used in constrained deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22500v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Ramirez, Simon Lacoste-Julien</dc:creator>
    </item>
    <item>
      <title>Network-Optimised Spiking Neural Network for Event-Driven Networking</title>
      <link>https://arxiv.org/abs/2509.23516</link>
      <description>arXiv:2509.23516v4 Announce Type: replace-cross 
Abstract: Delay-coupled systems often require low-latency decisions from sparse telemetry, where dense fixed-step neural inference is wasteful and can degrade near stability margins. We introduce Network-Optimised Spiking (NOS), a trainable two-state event-driven dynamical unit for delayed, graph-coupled streams, whose states map to a fast load variable and a slower recovery resource. NOS uses bounded excitability for finite buffers, explicit leak terms for service and damping, and graph-local coupling with per-link gates and communication delays, with differentiable resets compatible with surrogate-gradient training and neuromorphic execution. We prove existence and uniqueness of subthreshold equilibria, derive Jacobian-based stability conditions, and obtain a scalar network stability threshold that separates topology from node dynamics via a Perron-mode spectral condition. A stochastic arrival model aligned with telemetry smoothing explains increased variability as systems approach stability boundaries. On delayed graph forecasting and early-warning tasks from queue telemetry, NOS improves detection F1 and detection latency over MLP, RNN/GRU, and temporal GNN baselines under a common residual-based protocol, while providing calibration rules for resource-constrained deployments. Code and Demos: https://mbilal84.github.io/nos-snn-networking/</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23516v4</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Bilal</dc:creator>
    </item>
    <item>
      <title>Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets</title>
      <link>https://arxiv.org/abs/2510.19950</link>
      <description>arXiv:2510.19950v3 Announce Type: replace-cross 
Abstract: In financial applications, reinforcement learning (RL) agents are commonly trained on historical data, where their actions do not influence prices. However, during deployment, these agents trade in live markets where their own transactions can shift asset prices, a phenomenon known as market impact. This mismatch between training and deployment environments can significantly degrade performance. Traditional robust RL approaches address this model misspecification by optimizing the worst-case performance over a set of uncertainties, but typically rely on symmetric structures that fail to capture the directional nature of market impact. To address this issue, we develop a novel class of elliptic uncertainty sets. We establish both implicit and explicit closed-form solutions for the worst-case uncertainty under these sets, enabling efficient and tractable robust policy evaluation. Experiments on single-asset and multi-asset trading tasks demonstrate that our method achieves superior Sharpe ratio and remains robust under increasing trade volumes, offering a more faithful and scalable approach to RL in financial markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19950v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaocong Ma, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Tail Distribution of Regret in Optimistic Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2511.18247</link>
      <description>arXiv:2511.18247v2 Announce Type: replace-cross 
Abstract: We derive instance-dependent tail bounds for the regret of optimism-based reinforcement learning in finite-horizon tabular Markov decision processes with unknown transition dynamics. Focusing on a UCBVI-type algorithm, we characterize the tail distribution of the cumulative regret $R_K$ over $K$ episodes, rather than only its expectation or a single high-probability quantile. We analyze two natural exploration-bonus schedules: (i) a $K$-dependent scheme that explicitly incorporates the total number of episodes $K$, and (ii) a $K$-independent scheme that depends only on the current episode index. For both settings, we obtain an upper bound on $\Pr(R_K \ge x)$ that exhibits a distinctive two-regime structure: a sub-Gaussian tail starting from an instance-dependent scale $m_K$ up to a transition threshold, followed by a sub-Weibull tail beyond that point. We further derive corresponding instance-dependent bounds on the expected regret $\mathbb{E}[R_K]$. The proposed algorithm depends on a tuning parameter $\alpha$, which balances the expected regret and the range over which the regret exhibits a sub-Gaussian tail. To the best of our knowledge, our results provide one of the first comprehensive tail-regret guarantees for a standard optimistic algorithm in episodic reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18247v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sajad Khodadadian, Mehrdad Moharrami</dc:creator>
    </item>
    <item>
      <title>A uniformity principle for spatial matching</title>
      <link>https://arxiv.org/abs/2601.13426</link>
      <description>arXiv:2601.13426v2 Announce Type: replace-cross 
Abstract: Platforms matching spatially distributed supply to demand face a fundamental design choice: given a fixed total budget of service range, how should it be allocated across supply nodes ex ante, i.e. before supply and demand locations are realized, to maximize fulfilled demand? We model this problem using bipartite random geometric graphs where $n$ supply and $m$ demand nodes are uniformly distributed on $[0,1]^k$ ($k \ge 1$), and edges form when demand falls within a supply node's service region, the volume of which is determined by its service range. Since each supply node serves at most one demand, platform performance is determined by the expected size of a maximum matching. We establish a uniformity principle: whenever one service range allocation is more uniform than the other, the more uniform allocation yields a larger expected matching. This principle emerges from diminishing marginal returns to range expanding service range, and limited interference between supply nodes due to bounded ranges naturally fragmenting the graph. For $k=1$, we further characterize the expected matching size through a Markov chain embedding and derive closed-form expressions for special cases. Our results provide theoretical guidance for optimizing service range allocation and designing incentive structures in ride-hailing, on-demand labor markets, and drone delivery networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13426v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Ameen, Flore Sentenac, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>CLASP: An online learning algorithm for Convex Losses And Squared Penalties</title>
      <link>https://arxiv.org/abs/2601.16072</link>
      <description>arXiv:2601.16072v2 Announce Type: replace-cross 
Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{\beta,1-\beta\}}\right)$ and cumulative squared penalty $O\left(T^{1-\beta}\right)$ for any $\beta \in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16072v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo N. Ferreira, Jo\~ao Xavier, Cl\'audia Soares</dc:creator>
    </item>
    <item>
      <title>A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2601.16399</link>
      <description>arXiv:2601.16399v2 Announce Type: replace-cross 
Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16399v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Sujay Bhatt, Sumitra Ganesh, Alec Koppel</dc:creator>
    </item>
  </channel>
</rss>
