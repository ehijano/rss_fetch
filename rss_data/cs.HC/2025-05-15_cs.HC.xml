<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 May 2025 01:29:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp</title>
      <link>https://arxiv.org/abs/2505.08894</link>
      <description>arXiv:2505.08894v1 Announce Type: new 
Abstract: Recent advances in generative AI, such as ChatGPT, have transformed access to information in education, knowledge-seeking, and everyday decision-making. However, in many developing regions, access remains a challenge due to the persistent digital divide. To help bridge this gap, we developed WaLLM - a custom AI chatbot over WhatsApp, a widely used communication platform in developing regions. Beyond answering queries, WaLLM offers several features to enhance user engagement: a daily top question, suggested follow-up questions, trending and recent queries, and a leaderboard-based reward system. Our service has been operational for over 6 months, amassing over 14.7K queries from approximately 100 users. In this paper, we present WaLLM's design and a systematic analysis of logs to understand user interactions. Our results show that 55% of user queries seek factual information. "Health and well-being" was the most popular topic (28%), including queries about nutrition and disease, suggesting users view WaLLM as a reliable source. Two-thirds of users' activity occurred within 24 hours of the daily top question. Users who accessed the "Leaderboard" interacted with WaLLM 3x as those who did not. We conclude by discussing implications for culture-based customization, user interface design, and appropriate calibration of users' trust in AI systems for developing regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08894v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiba Eltigani, Rukhshan Haroon, Asli Kocak, Abdullah Bin Faisal, Noah Martin, Fahad Dogar</dc:creator>
    </item>
    <item>
      <title>Performance Gains of LLMs With Humans in a World of LLMs Versus Humans</title>
      <link>https://arxiv.org/abs/2505.08902</link>
      <description>arXiv:2505.08902v1 Announce Type: new 
Abstract: Currently, a considerable research effort is devoted to comparing LLMs to a group of human experts, where the term "expert" is often ill-defined or variable, at best, in a state of constantly updating LLM releases. Without proper safeguards in place, LLMs will threaten to cause harm to the established structure of safe delivery of patient care which has been carefully developed throughout history to keep the safety of the patient at the forefront. A key driver of LLM innovation is founded on community research efforts which, if continuing to operate under "humans versus LLMs" principles, will expedite this trend. Therefore, research efforts moving forward must focus on effectively characterizing the safe use of LLMs in clinical settings that persist across the rapid development of novel LLM models. In this communication, we demonstrate that rather than comparing LLMs to humans, there is a need to develop strategies enabling efficient work of humans with LLMs in an almost symbiotic manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08902v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas McCullum, Pelagie Ami Agassi, Leo Anthony Celi, Daniel K. Ebner, Chrystinne Oliveira Fernandes, Rachel S. Hicklen, Mkliwa Koumbia, Lisa Soleymani Lehmann, David Restrepo</dc:creator>
    </item>
    <item>
      <title>Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work</title>
      <link>https://arxiv.org/abs/2505.08939</link>
      <description>arXiv:2505.08939v1 Announce Type: new 
Abstract: As generative AI tools become integrated into design workflows, students increasingly engage with these tools not just as aids, but as collaborators. This study analyzes reflections from 33 student teams in an HCI design course to examine the kinds of judgments students make when using AI tools. We found both established forms of design judgment (e.g., instrumental, appreciative, quality) and emergent types: agency-distribution judgment and reliability judgment. These new forms capture how students negotiate creative responsibility with AI and assess the trustworthiness of its outputs. Our findings suggest that generative AI introduces new layers of complexity into design reasoning, prompting students to reflect not only on what AI produces, but also on how and when to rely on it. By foregrounding these judgments, we offer a conceptual lens for understanding how students engage in co-creative sensemaking with AI in design contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08939v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3698061.3734399</arxiv:DOI>
      <dc:creator>Suchismita Naik, Prakash Shukla, Ike Obi, Jessica Backus, Nancy Rasche, Paul Parsons</dc:creator>
    </item>
    <item>
      <title>Positioning Monocular Optical See Through Head Worn Displays in Glasses for Everyday Wear</title>
      <link>https://arxiv.org/abs/2505.09047</link>
      <description>arXiv:2505.09047v1 Announce Type: new 
Abstract: Head-worn displays for everyday wear in the form of regular eyeglasses are technically feasible with recent advances in waveguide technology. One major design decision is determining where in the user's visual field to position the display. Centering the display in the principal point of gaze (PPOG) allows the user to switch attentional focus between the virtual and real images quickly, and best performance often occurs when the display is centered in PPOG or is centered vertically below PPOG. However, these positions are often undesirable in that they are considered interruptive or are associated with negative social perceptions by users. Offsetting the virtual image may be preferred when tasks involve driving, walking, or social interaction. This paper consolidates findings from recent studies on monocular optical see-through HWDs (OST-HWDs), focusing on potential for interruption, comfort, performance, and social perception. For text-based tasks, which serve as a proxy for many monocular OST-HWD tasks, we recommend a 15{\deg} horizontal field of view (FOV) with the virtual image in the right lens vertically centered but offset to +8.7{\deg} to +23.7{\deg} toward the ear. Glanceable content can be offset up to +30{\deg} for short interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09047v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parth Arora, Ethan Kimmel, Katherine Huang, Tyler Kwok, Yukun Song, Sofia Vempala, Georgianna Lin, Ozan Cakmakci, Thad Starner</dc:creator>
    </item>
    <item>
      <title>EcoSphere: A Decision-Support Tool for Automated Carbon Emission and Cost Optimization in Sustainable Urban Development</title>
      <link>https://arxiv.org/abs/2505.09054</link>
      <description>arXiv:2505.09054v1 Announce Type: new 
Abstract: The construction industry is a major contributor to global greenhouse gas emissions, with embodied carbon being a key component. This study develops EcoSphere, an innovative software designed to evaluate and balance embodied and operational carbon emissions with construction and environmental costs in urban planning. Using high-resolution data from the National Structure Inventory, combined with computer vision and natural language processing applied to Google Street View and satellite imagery, EcoSphere categorizes buildings by structural and material characteristics with a bottom-up approach, creating a baseline emissions dataset. By simulating policy scenarios and mitigation strategies, EcoSphere provides policymakers and non-experts with actionable insights for sustainable development in cities and provide them with a vision of the environmental and financial results of their decisions. Case studies in Chicago and Indianapolis showcase how EcoSphere aids in assessing policy impacts on carbon emissions and costs, supporting data-driven progress toward carbon neutrality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09054v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Siavash Ghorbany, Ming Hu, Siyuan Yao, Matthew Sisk, Chaoli Wang</dc:creator>
    </item>
    <item>
      <title>Display Content, Display Methods and Evaluation Methods of the HCI in Explainable Recommender Systems: A Survey</title>
      <link>https://arxiv.org/abs/2505.09065</link>
      <description>arXiv:2505.09065v1 Announce Type: new 
Abstract: Explainable Recommender Systems (XRS) aim to provide users with understandable reasons for the recommendations generated by these systems, representing a crucial research direction in artificial intelligence (AI). Recent research has increasingly focused on the algorithms, display, and evaluation methodologies of XRS. While current research and reviews primarily emphasize the algorithmic aspects, with fewer studies addressing the Human-Computer Interaction (HCI) layer of XRS. Additionally, existing reviews lack a unified taxonomy for XRS and there is insufficient attention given to the emerging area of short video recommendations. In this study, we synthesize existing literature and surveys on XRS, presenting a unified framework for its research and development. The main contributions are as follows: 1) We adopt a lifecycle perspective to systematically summarize the technologies and methods used in XRS, addressing challenges posed by the diversity and complexity of algorithmic models and explanation techniques. 2) For the first time, we highlight the application of multimedia, particularly video-based explanations, along with its potential, technical pathways, and challenges in XRS. 3) We provide a structured overview of evaluation methods from both qualitative and quantitative dimensions. These findings provide valuable insights for the systematic design, progress, and testing of XRS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09065v1</guid>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiqing Li, Yue Xu, Yuefeng Li, Yinghui Huang</dc:creator>
    </item>
    <item>
      <title>PLanet: Formalizing Experimental Design</title>
      <link>https://arxiv.org/abs/2505.09094</link>
      <description>arXiv:2505.09094v1 Announce Type: new 
Abstract: Carefully constructed experimental designs are essential for drawing valid, generalizable conclusions from scientific studies. Unfortunately, experimental design plans can be difficult to specify, communicate clearly, and relate to alternatives. In response, we introduce a grammar of experimental design that provides composable operators for constructing assignment procedures (e.g., Latin square). We implement this grammar in PLanet, a domain-specific language (DSL) that constructs assignment plans in three stages: experimental unit specification, trial-order construction, and order-to-unit mapping. We evaluate PLanet's expressivity by taking a purposive sample of recent CHI and UIST publications, representing their experiments as programs in PLanet, and identifying ambiguities and alternatives. In our evaluation, PLanet could express 11 out of 12 experiments found in sampled papers. Additionally, we found that PLanet constructs helped make complex design choices explicit when the researchers omit technical language describing their study designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09094v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>London Bielicke, Anna Zhang, Shruti Tyagi, Emery Berger, Adam Chlipala, Eunice Jun</dc:creator>
    </item>
    <item>
      <title>PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence</title>
      <link>https://arxiv.org/abs/2505.09115</link>
      <description>arXiv:2505.09115v1 Announce Type: new 
Abstract: Advance Care Planning (ACP) allows individuals to specify their preferred end-of-life life-sustaining treatments before they become incapacitated by injury or terminal illness (e.g., coma, cancer, dementia). While online ACP offers high accessibility, it lacks key benefits of clinical consultations, including personalized value exploration, immediate clarification of decision consequences. To bridge this gap, we conducted two formative studies: 1) shadowed and interviewed 3 ACP teams consisting of physicians, nurses, and social workers (18 patients total), and 2) interviewed 14 users of ACP websites. Building on these insights, we designed PreCare in collaboration with 6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed to guide users through exploring personal values, gaining ACP knowledge, and supporting informed decision-making. A usability study (n=12) showed that PreCare achieved a System Usability Scale (SUS) rating of excellent. A comparative evaluation (n=12) showed that PreCare's AI assistants significantly improved exploration of personal values, knowledge, and decisional confidence, and was preferred by 92% of participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09115v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Lun Hsu (National Taiwan University), Yun-Rung Chou (National Taiwan University), Chiao-Ju Chang (National Taiwan University), Yu-Cheng Chang (National Taiwan University), Zer-Wei Lee (National Taiwan University), Rokas Gipi\v{s}kis (Vilnius University), Rachel Li (University of California, Berkeley), Chih-Yuan Shih (National Taiwan University Hospital), Jen-Kuei Peng (National Taiwan University Hospital), Hsien-Liang Huang (National Taiwan University Hospital), Jaw-Shiun Tsai (National Taiwan University Hospital), Mike Y. Chen</dc:creator>
    </item>
    <item>
      <title>An Initial Exploration of Default Images in Text-to-Image Generation</title>
      <link>https://arxiv.org/abs/2505.09166</link>
      <description>arXiv:2505.09166v1 Announce Type: new 
Abstract: In the creative practice of text-to-image generation (TTI), images are generated from text prompts. However, TTI models are trained to always yield an output, even if the prompt contains unknown terms. In this case, the model may generate what we call "default images": images that closely resemble each other across many unrelated prompts. We argue studying default images is valuable for designing better solutions for TTI and prompt engineering. In this paper, we provide the first investigation into default images on Midjourney, a popular image generator. We describe our systematic approach to create input prompts triggering default images, and present the results of our initial experiments and several small-scale ablation studies. We also report on a survey study investigating how default images affect user satisfaction. Our work lays the foundation for understanding default images in TTI and highlights challenges and future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09166v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannu Simonen, Atte Kiviniemi, Jonas Oppenlaender</dc:creator>
    </item>
    <item>
      <title>Educational impacts of generative artificial intelligence on learning and performance of engineering students in China</title>
      <link>https://arxiv.org/abs/2505.09208</link>
      <description>arXiv:2505.09208v1 Announce Type: new 
Abstract: With the rapid advancement of generative artificial intelligence(AI), its potential applications in higher education have attracted significant attention. This study investigated how 148 students from diverse engineering disciplines and regions across China used generative AI, focusing on its impact on their learning experience and the opportunities and challenges it poses in engineering education. Based on the surveyed data, we explored four key areas: the frequency and application scenarios of AI use among engineering students, its impact on students' learning and performance, commonly encountered challenges in using generative AI, and future prospects for its adoption in engineering education. The results showed that more than half of the participants reported a positive impact of generative AI on their learning efficiency, initiative, and creativity, with nearly half believing it also enhanced their independent thinking. However, despite acknowledging improved study efficiency, many felt their actual academic performance remained largely unchanged and expressed concerns about the accuracy and domain-specific reliability of generative AI. Our findings provide a first-hand insight into the current benefits and challenges generative AI brings to students, particularly Chinese engineering students, while offering several recommendations, especially from the students' perspective, for effectively integrating generative AI into engineering education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09208v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Fan, Kunyang Deng, Fangxue Liu</dc:creator>
    </item>
    <item>
      <title>A Note on Semantic Diffusion</title>
      <link>https://arxiv.org/abs/2505.09283</link>
      <description>arXiv:2505.09283v1 Announce Type: new 
Abstract: This paper provides an in-depth examination of the concept of semantic diffusion as a complementary instrument to large language models (LLMs) for design applications. Conventional LLMs and diffusion models fail to induce a convergent, iterative refinement process: each invocation of the diffusion mechanism spawns a new stochastic cycle, so successive outputs do not relate to prior ones and convergence toward a desired design is not guaranteed. The proposed hybrid framework - "LLM + semantic diffusion" - resolves this limitation by enforcing an approximately convergent search procedure, thereby formally addressing the problem of localized design refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09283v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander P. Ryjov, Alina A. Egorova</dc:creator>
    </item>
    <item>
      <title>AfforDance: Personalized AR Dance Learning System with Visual Affordance</title>
      <link>https://arxiv.org/abs/2505.09376</link>
      <description>arXiv:2505.09376v1 Announce Type: new 
Abstract: We propose AfforDance, an augmented reality (AR)-based dance learning system that generates personalized learning content and enhances learning through visual affordances. Our system converts user-selected dance videos into interactive learning experiences by integrating 3D reference avatars, audio synchronization, and adaptive visual cues that guide movement execution. This work contributes to personalized dance education by offering an adaptable, user-centered learning interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09376v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyunyoung Han, Jongwon Jang, Kitaeg Shim, Sang Ho Yoon</dc:creator>
    </item>
    <item>
      <title>Utilization of Skin Color Change for Image-based Tactile Sensing</title>
      <link>https://arxiv.org/abs/2505.09402</link>
      <description>arXiv:2505.09402v1 Announce Type: new 
Abstract: Measurement of pressure distribution applied to a fingertip is crucial for the teleoperation of robots and human computer interface. Previous studies have acquired pressure distribution by affixing a sensor array to the fingertip or by optically recording the deformation of an object. However, these existing methods inhibit the fingertip from directly contacting the texture, and the pressure applied to the fingertip is measured indirectly. In this study, we propose a method to measure pressure distribution by directly touching a transparent object, focusing on the change in skin color induced by the applied pressure, caused by blood flow. We evaluated the relationship between pressure and skin color change when local pressure is applied, and found a correlation between the pressure and the color change. However, the contact area and the color change area did not align perfectly. We further explored the factor causing the spatial non-uniformity of the color change, by accounting for the stress distribution using finite element analysis. These results suggest that the proposed measurement method can be utilized to measure the internal stress distribution, and it is anticipated to serve as a simple sensor in the field of human computer interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09402v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.medengphy.2025.104357</arxiv:DOI>
      <arxiv:journal_reference>Medical Engineering and Physics 140 (2025) 104357</arxiv:journal_reference>
      <dc:creator>Seitaro Kaneko, Hiroki Ishizuka, Hidenori Yoshimura, Hiroyuki Kajimoto</dc:creator>
    </item>
    <item>
      <title>Card Sorting Simulator: Augmenting Design of Logical Information Architectures with Large Language Models</title>
      <link>https://arxiv.org/abs/2505.09478</link>
      <description>arXiv:2505.09478v1 Announce Type: new 
Abstract: Card sorting is a common ideation technique that elicits information on users' mental organization of content and functionality by having them sort items into categories. For more robust card sorting research, digital card sorting tools could benefit from providing quick automated feedback. Our objective of this research is to advance toward an instrument that applies artificial intelligence (AI) to augment card sorting. For this purpose, we develop the Card Sorting Simulator, a prototype tool that leverages Large Language Models (LLMs) to generate informative categorizations of cards. To illuminate how aligned the simulation is with card sorting by actual participants, and to inform the instrument's design decisions, we conducted a generalizability-focused comparative study. We obtained 28 pre-existing card sorting studies from real practitioners, comprising 1,399 participants, along with diverse contents and origins. With this dataset, we conducted a comprehensive and nuanced analysis of the agreement between actual card sorting results (clusterings of cards) and synthetic clusterings across a multitude of LLMs and prompt designs. Mutual information scores indicate a good degree of agreement to real result clustering, although similarity matrices also demonstrate inconsistencies from mental models, which can be attributed to their top-down nature. Furthermore, the number of cards or complexity of their labels impact the accuracy of its simulation. These findings bolster the case for AI augmentation in card sorting research as a source of meaningful preliminary feedback and highlight the need for further study for the development and validation of intelligent user research tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09478v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduard Kuric, Peter Demcak, Matus Krajcovic</dc:creator>
    </item>
    <item>
      <title>Partnership through Play: Investigating How Long-Distance Couples Use Digital Games to Facilitate Intimacy</title>
      <link>https://arxiv.org/abs/2505.09509</link>
      <description>arXiv:2505.09509v1 Announce Type: new 
Abstract: Long-distance relationships (LDRs) have become more common in the last few decades, primarily among young adults pursuing educational or employment opportunities. A common way for couples in LDRs to spend time together is by playing multiplayer video games, which are often a shared hobby and therefore a preferred joint activity. However, games are relatively understudied in the context of relational maintenance for LDRs. In this work, we used a mixed-methods approach to collect data on the experiences of 13 couples in LDRs who frequently play games together. We investigated different values around various game mechanics and modalities and found significant differences in couple play styles, and also detail how couples appropriate game mechanics to express affection to each other virtually. We also created prototypes and design implications based on couples' needs surrounding the lack of physical sensation and memorabilia storage in most popular games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09509v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3715336.3735773</arxiv:DOI>
      <dc:creator>Nisha Devasia, Adrian Rodriguez, Logan Tuttle, Julie Kientz</dc:creator>
    </item>
    <item>
      <title>Evaluation Metrics for Misinformation Warning Interventions: Challenges and Prospects</title>
      <link>https://arxiv.org/abs/2505.09526</link>
      <description>arXiv:2505.09526v1 Announce Type: new 
Abstract: Misinformation has become a widespread issue in the 21st century, impacting numerous areas of society and underscoring the need for effective intervention strategies. Among these strategies, user-centered interventions, such as warning systems, have shown promise in reducing the spread of misinformation. Many studies have used various metrics to evaluate the effectiveness of these warning interventions. However, no systematic review has thoroughly examined these metrics in all studies. This paper provides a comprehensive review of existing metrics for assessing the effectiveness of misinformation warnings, categorizing them into four main groups: behavioral impact, trust and credulity, usability, and cognitive and psychological effects. Through this review, we identify critical challenges in measuring the effectiveness of misinformation warnings, including inconsistent use of cognitive and attitudinal metrics, the lack of standardized metrics for affective and emotional impact, variations in user trust, and the need for more inclusive warning designs. We present an overview of these metrics and propose areas for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09526v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hussaini Zubairu, Abdelrahaman Abdou, Ashraf Matrawy</dc:creator>
    </item>
    <item>
      <title>Beyond Likes: How Normative Feedback Complements Engagement Signals on Social Media</title>
      <link>https://arxiv.org/abs/2505.09583</link>
      <description>arXiv:2505.09583v2 Announce Type: new 
Abstract: Many online platforms incorporate engagement signals--such as likes and upvotes--into their content ranking systems and interface design. These signals are designed to boost user engagement. However, they can unintentionally elevate content that is less inclusive and may not support normatively desirable behavior. This issue becomes especially concerning when toxic content correlates strongly with popularity indicators such as likes and upvotes. In this study, we propose structured prosocial feedback as a complementary signal to likes and upvotes--one that highlights content quality based on normative criteria to help address the limitations of conventional engagement signals. We begin by designing and implementing a machine learning feedback system powered by a large language model (LLM), which evaluates user comments based on principles of positive psychology, such as individual well-being, constructive social media use, and character strengths. We then conduct a pre-registered user study to examine how existing peer-based and the new expert-based feedback interact to shape users' selection of comments in a social media setting. Results show that peer feedback increases conformity to popularity cues, while expert feedback shifts preferences toward normatively higher-quality content. Moreover, incorporating expert feedback alongside peer evaluations improves alignment with expert assessments and contributes to a less toxic community environment. This illustrates the added value of normative cues--such as expert scores generated by LLMs using psychological rubrics--and underscores the potential benefits of incorporating such signals into platform feedback systems to foster healthier online environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09583v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Wu, Mingduo Zhao</dc:creator>
    </item>
    <item>
      <title>FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations</title>
      <link>https://arxiv.org/abs/2505.08904</link>
      <description>arXiv:2505.08904v1 Announce Type: cross 
Abstract: What happens when a rideshare driver is suddenly locked out of the platform connecting them to riders, wages, and daily work? Deactivation-the abrupt removal of gig workers' platform access-typically occurs through arbitrary AI and algorithmic decisions with little explanation or recourse. This represents one of the most severe forms of algorithmic control and often devastates workers' financial stability. Recent U.S. state policies now mandate appeals processes and recovering compensation during the period of wrongful deactivation based on past earnings. Yet, labor organizers still lack effective tools to support these complex, error-prone workflows. We designed FareShare, a computational tool automating lost wage estimation for deactivated drivers, through a 6 month partnership with the State of Washington's largest rideshare labor union. Over the following 3 months, our field deployment of FareShare registered 178 account signups. We observed that the tool could reduce lost wage calculation time by over 95%, eliminate manual data entry errors, and enable legal teams to generate arbitration-ready reports more efficiently. Beyond these gains, the deployment also surfaced important socio-technical challenges around trust, consent, and tool adoption in high-stakes labor contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08904v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Varun Nagaraj Rao, Samantha Dalal, Andrew Schwartz, Amna Liaqat, Dana Calacci, Andr\'es Monroy-Hern\'andez</dc:creator>
    </item>
    <item>
      <title>S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment</title>
      <link>https://arxiv.org/abs/2505.09068</link>
      <description>arXiv:2505.09068v1 Announce Type: cross 
Abstract: This paper introduces S-DAT (Synthetic-Divergent Association Task), a scalable, multilingual framework for automated assessment of divergent thinking (DT) -a core component of human creativity. Traditional creativity assessments are often labor-intensive, language-specific, and reliant on subjective human ratings, limiting their scalability and cross-cultural applicability. In contrast, S-DAT leverages large language models and advanced multilingual embeddings to compute semantic distance -- a language-agnostic proxy for DT. We evaluate S-DAT across eleven diverse languages, including English, Spanish, German, Russian, Hindi, and Japanese (Kanji, Hiragana, Katakana), demonstrating robust and consistent scoring across linguistic contexts. Unlike prior DAT approaches, the S-DAT shows convergent validity with other DT measures and correct discriminant validity with convergent thinking. This cross-linguistic flexibility allows for more inclusive, global-scale creativity research, addressing key limitations of earlier approaches. S-DAT provides a powerful tool for fairer, more comprehensive evaluation of cognitive flexibility in diverse populations and can be freely assessed online: https://sdat.iol.zib.de/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09068v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jennifer Haase, Paul H. P. Hanel, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Manifesto for Putting 'Chartjunk' in the Trash 2021!</title>
      <link>https://arxiv.org/abs/2109.10132</link>
      <description>arXiv:2109.10132v3 Announce Type: replace 
Abstract: In this provocation we ask the visualization research community to join us in removing chartjunk from our research lexicon. We present an etymology of chartjunk, framing its provocative origins as misaligned, and harmful, to the ways the term is currently used by visualization researchers. We call on the community to dissolve chartjunk from the ways we talk about, write about, and think about the graphical devices we design and study. As a step towards this goal we contribute a performance of maintenance through a trio of acts: editing the Wikipedia page on chartjunk, cutting out chartjunk from IEEE papers, and scanning and posting a repository of the pages with chartjunk removed to invite the community to re-imagine how we describe visualizations. This contribution blurs the boundaries between research, activism, and maintenance art, and is intended to inspire the community to join us in taking out the trash.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.10132v3</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Derya Akbaba, Jack Wilburn, Main T. Nance, Miriah Meyer</dc:creator>
    </item>
    <item>
      <title>Behavioral Sensing and Intervention Paradigm: A Review of Closed-Loop Approaches for Ingestion Health</title>
      <link>https://arxiv.org/abs/2505.03185</link>
      <description>arXiv:2505.03185v3 Announce Type: replace 
Abstract: Ingestive behavior plays a critical role in health, yet many existing interventions remain limited to static guidance or manual self-tracking. With the increasing integration of sensors and perceptual computing, recent systems have begun to support closed-loop interventions that dynamically sense user behavior and provide feedback during or around ingestion episodes. In this survey, we review 136 studies that leverage sensor-enabled or interaction-mediated approaches to influence eating behavior. We propose a behavioral closed-loop paradigm comprising three core components: target behaviors, sensing modalities, and feedback strategies. A taxonomy of sensing and intervention modalities is presented, organized along human- and environment-based dimensions. Our analysis also examines evaluation methods and design trends across different modality-behavior pairings. This review reveals prevailing patterns and critical gaps, offering design insights for future adaptive and context-aware ingestion health interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03185v3</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Fang, Yanuo Zhou, Ka I Chan, Jiajin Li, Zeyi Sun, Zhengnan Li, Zicong Fu, Hongjing Piao, Haodong Xu, Yuanchun Shi, Yuntao Wang</dc:creator>
    </item>
    <item>
      <title>Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering</title>
      <link>https://arxiv.org/abs/2505.04260</link>
      <description>arXiv:2505.04260v2 Announce Type: replace 
Abstract: As large language models (LLMs) improve in their capacity to serve as personal AI assistants, their ability to output uniquely tailored, personalized responses that align with the soft preferences of their users is essential for enhancing user satisfaction and retention. However, untrained lay users have poor prompt specification abilities and often struggle with conveying their latent preferences to AI assistants. To address this, we leverage activation steering to guide LLMs to align with interpretable preference dimensions during inference. In contrast to memory-based personalization methods that require longer user history, steering is extremely lightweight and can be easily controlled by the user via an linear strength factor. We embed steering into three different interactive chatbot interfaces and conduct a within-subjects user study (n=14) to investigate how end users prefer to personalize their conversations. The results demonstrate the effectiveness of preference-based steering for aligning real-world conversations with hidden user preferences, and highlight further insights on how diverse values around control, usability, and transparency lead users to prefer different interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04260v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica Y. Bo, Tianyu Xu, Ishan Chatterjee, Katrina Passarella-Ward, Achin Kulshrestha, D Shin</dc:creator>
    </item>
    <item>
      <title>Partisan Fact-Checkers' Warnings Can Effectively Correct Individuals' Misbeliefs About Political Misinformation</title>
      <link>https://arxiv.org/abs/2505.08048</link>
      <description>arXiv:2505.08048v2 Announce Type: replace 
Abstract: Political misinformation, particularly harmful when it aligns with individuals' preexisting beliefs and political ideologies, has become widespread on social media platforms. In response, platforms like Facebook and X introduced warning messages leveraging fact-checking results from third-party fact-checkers to alert users against false content. However, concerns persist about the effectiveness of these fact-checks, especially when fact-checkers are perceived as politically biased. To address these concerns, this study presents findings from an online human-subject experiment (N=216) investigating how the political stances of fact-checkers influence their effectiveness in correcting misbeliefs about political misinformation. Our findings demonstrate that partisan fact-checkers can decrease the perceived accuracy of political misinformation and correct misbeliefs without triggering backfire effects. This correction is even more pronounced when the misinformation aligns with individuals' political ideologies. Notably, while previous research suggests that fact-checking warnings are less effective for conservatives than liberals, our results suggest that explicitly labeled partisan fact-checkers, positioned as political counterparts to conservatives, are particularly effective in reducing conservatives' misbeliefs toward pro-liberal misinformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08048v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sian Lee, Haeseung Seo, Aiping Xiong, Dongwon Lee</dc:creator>
    </item>
    <item>
      <title>A Call to Arms: AI Should be Critical for Social Media Analysis of Conflict Zones</title>
      <link>https://arxiv.org/abs/2311.00810</link>
      <description>arXiv:2311.00810v3 Announce Type: replace-cross 
Abstract: The massive proliferation of social media data represents a transformative opportunity for conflict studies and for tracking the proliferation and use of weaponry, as conflicts are increasingly documented in these online spaces. At the same time, the scale and types of data available are problematic for traditional open-source intelligence. This paper focuses on identifying specific weapon systems and the insignias of the armed groups using them as documented in the Ukraine war, as these tasks are critical to operational intelligence and tracking weapon proliferation, especially given the scale of international military aid given to Ukraine. The large scale of social media makes manual assessment difficult, however, so this paper presents early work that uses computer vision models to support this task. We demonstrate that these models can both identify weapons embedded in images shared in social media and how the resulting collection of military-relevant images and their post times interact with the offline, real-world conflict. Not only can we then track changes in the prevalence of images of tanks, land mines, military trucks, etc., we find correlations among time series data associated with these images and the daily fatalities in this conflict. This work shows substantial opportunity for examining similar online documentation of conflict contexts, and we also point to future avenues where computer vision can be further improved for these open-source intelligence tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00810v3</guid>
      <category>cs.CY</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Afia Abedin, Abdul Bais, Cody Buntain, Laura Courchesne, Brian McQuinn, Matthew E. Taylor, Muhib Ullah</dc:creator>
    </item>
    <item>
      <title>Triple-identity Authentication: The Future of Secure Access</title>
      <link>https://arxiv.org/abs/2505.02004</link>
      <description>arXiv:2505.02004v2 Announce Type: replace-cross 
Abstract: In a typical authentication process, the local system verifies the user's identity using a stored hash value generated by a cross-system hash algorithm. This article shifts the research focus from traditional password encryption to the establishment of gatekeeping mechanisms for effective interactions between a system and the outside world. Here, we propose a triple-identity authentication system to achieve this goal. Specifically, this local system opens the inner structure of its hash algorithm to all user credentials, including the login name, login password, and authentication password. When a login credential is entered, the local system hashes it and then creates a unique identifier using intermediate hash elements randomly selected from the open algorithm. Importantly, this locally generated unique identifier (rather than the stored hash produced by the open algorithm) is utilized to verify the user's combined identity, which is generated by combining the entered credential with the International Mobile Equipment Identity and the International Mobile Subscriber Identity. The verification process is implemented at each interaction point: the login name field, the login password field, and the server's authentication point. Thus, within the context of this triple-identity authentication system, we establish a robust gatekeeping mechanism for system interactions, ultimately providing a level of security that is equivalent to multi-factor authentication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02004v2</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Suyun Borjigin</dc:creator>
    </item>
  </channel>
</rss>
