<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Feb 2025 05:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quantum Machine Learning in Precision Medicine and Drug Discovery -- A Game Changer for Tailored Treatments?</title>
      <link>https://arxiv.org/abs/2502.18639</link>
      <description>arXiv:2502.18639v1 Announce Type: new 
Abstract: The digitization of healthcare presents numerous challenges, including the complexity of biological systems, vast data generation, and the need for personalized treatment plans. Traditional computational methods often fall short, leading to delayed and sometimes ineffective diagnoses and treatments. Quantum Computing (QC) and Quantum Machine Learning (QML) offer transformative advancements with the potential to revolutionize medicine. This paper summarizes areas where QC promises unprecedented computational power, enabling faster, more accurate diagnostics, personalized treatments, and enhanced drug discovery processes. However, integrating quantum technologies into precision medicine also presents challenges, including errors in algorithms and high costs. We show that mathematically-based techniques for specifying, developing, and verifying software (formal methods) can enhance the reliability and correctness of QC. By providing a rigorous mathematical framework, formal methods help to specify, develop, and verify systems with high precision. In genomic data analysis, formal specification languages can precisely (1) define the behavior and properties of quantum algorithms designed to identify genetic markers associated with diseases. Model checking tools can systematically explore all possible states of the algorithm to (2) ensure it behaves correctly under all conditions, while theorem proving techniques provide mathematical (3) proof that the algorithm meets its specified properties, ensuring accuracy and reliability. Additionally, formal optimization techniques can (4) enhance the efficiency and performance of quantum algorithms by reducing resource usage, such as the number of qubits and gate operations. Therefore, we posit that formal methods can significantly contribute to enabling QC to realize its full potential as a game changer in precision medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18639v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>quant-ph</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Markus Bertl, Alan Mott, Salvatore Sinno, Bhavika Bhalgamiya</dc:creator>
    </item>
    <item>
      <title>DROID: Discrete-Time Simulation for Ring-Oscillator-Based Ising Design</title>
      <link>https://arxiv.org/abs/2502.19399</link>
      <description>arXiv:2502.19399v1 Announce Type: new 
Abstract: Many combinatorial problems can be mapped to Ising machines, i.e., networks of coupled oscillators that settle to a minimum-energy ground state, from which the problem solution is inferred. This work proposes DROID, a novel event-driven method for simulating the evolution of a CMOS Ising machine to its ground state. The approach is accurate under general delay-phase relations that include the effects of the transistor nonlinearities and is computationally efficient. On a realistic-size all-to-all coupled ring oscillator array, DROID is nearly four orders of magnitude faster than a traditional HSPICE simulation in predicting the evolution of a coupled oscillator system and is demonstrated to attain a similar distribution of solutions as the hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19399v1</guid>
      <category>cs.ET</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhimanyu Kumar, Ramprasath S., Chris H. Kim, Ulya R. Karpuzcu, Sachin S. Sapatnekar</dc:creator>
    </item>
    <item>
      <title>Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions</title>
      <link>https://arxiv.org/abs/2502.18470</link>
      <description>arXiv:2502.18470v1 Announce Type: cross 
Abstract: Spatial reasoning remains a challenge for Large Language Models (LLMs), which struggle with spatial data retrieval and reasoning. We propose Spatial Retrieval-Augmented Generation (Spatial-RAG), a framework that extends RAG to spatial tasks by integrating sparse spatial retrieval (spatial databases) and dense semantic retrieval (LLM-based similarity). A multi-objective ranking strategy balances spatial constraints and semantic relevance, while an LLM-guided generator ensures coherent responses. Experiments on a real-world tourism dataset show that Spatial-RAG significantly improves spatial question answering, bridging the gap between LLMs and spatial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18470v1</guid>
      <category>cs.IR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dazhou Yu, Riyang Bao, Gengchen Mai, Liang Zhao</dc:creator>
    </item>
    <item>
      <title>Blending Optimal Control and Biologically Plausible Learning for Noise-Robust Physical Neural Networks</title>
      <link>https://arxiv.org/abs/2502.19053</link>
      <description>arXiv:2502.19053v1 Announce Type: cross 
Abstract: The rapidly increasing computational demands for artificial intelligence (AI) have spurred the exploration of computing principles beyond conventional digital computers. Physical neural networks (PNNs) offer efficient neuromorphic information processing by harnessing the innate computational power of physical processes; however, training their weight parameters is computationally expensive. We propose a training approach for substantially reducing this training cost. Our training approach merges an optimal control method for continuous-time dynamical systems with a biologically plausible training method--direct feedback alignment. In addition to the reduction of training time, this approach achieves robust processing even under measurement errors and noise without requiring detailed system information. The effectiveness was numerically and experimentally verified in an optoelectronic delay system. Our approach significantly extends the range of physical systems practically usable as PNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19053v1</guid>
      <category>physics.app-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.134.017301</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett., 134, 017301 (2025)</arxiv:journal_reference>
      <dc:creator>Satoshi Sunada, Tomoaki Niiyama, Kazutaka Kanno, Rin Nogami, Andr\'e R\"ohm, Takato Awano, Atsushi Uchida</dc:creator>
    </item>
    <item>
      <title>Effects of Linear Modulation of Electrotactile Signals Using a Novel Device on Sensation Naturalness and Perceptual Intensity</title>
      <link>https://arxiv.org/abs/2502.19066</link>
      <description>arXiv:2502.19066v1 Announce Type: cross 
Abstract: Electrotactile feedback is a promising method for delivering haptic sensations, but challenges such as the naturalness of sensations hinder its adoption in commercial devices. In this study, we introduce a novel device that enables the exploration of complex stimulation signals to enhance sensation naturalness. We designed six stimulation signals with linearly modulated frequency, amplitude, or both, across two frequency levels based on a ramp-and-hold shape, aiming to replicate sensation of pressing a button. Our results showed that these modulated signals achieve higher naturalness scores than tonic stimulations, with a 6.8% improvement. Moreover, we examined the relationship between perceived intensity and signal energy for these stimulation patterns. Our findings indicate that, under conditions of constant perceived intensity, signal energy is not uniform across different stimulation patterns. Instead, there is a distinct relationship between the energy levels of different patterns, which is consistently reflected in the energy of the stimulations selected by the participants. Based on our findings, we propose a predictive model that estimates the desired intensity for any stimulation pattern using this relationship between signal energies and the user's preferred intensity for a single reference pattern. This model demonstrated high reliability, with a mean R2 score of 83.33%. Using this approach, intensity calibration for different stimulation patterns can be streamlined, reducing calibration time by 87.5%, as only one out of eight reference pattern must be calibrated. These findings highlight the potential of stimulation signal modulation to improve sensation quality and validate the viability of our predictive model for automating intensity calibration. This approach is an essential step toward delivering complex and naturalistic sensations in advanced haptic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19066v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amirhossein Bayat, Melika Emami, Rahim Tafazolli, Atta Quddus</dc:creator>
    </item>
    <item>
      <title>All-in-One Analog AI Accelerator: On-Chip Training and Inference with Conductive-Metal-Oxide/HfOx ReRAM Devices</title>
      <link>https://arxiv.org/abs/2502.04524</link>
      <description>arXiv:2502.04524v3 Announce Type: replace 
Abstract: Analog in-memory computing is an emerging paradigm designed to efficiently accelerate deep neural network workloads. Recent advancements have focused on either inference or training acceleration. However, a unified analog in-memory technology platform-capable of on-chip training, weight retention, and long-term inference acceleration-has yet to be reported. This work presents an all-in-one analog AI accelerator, combining these capabilities to enable energy-efficient, continuously adaptable AI systems. The platform leverages an array of analog filamentary conductive-metal-oxide (CMO)/HfOx resistive switching memory cells (ReRAM) integrated into the back-end-of-line (BEOL). The array demonstrates reliable resistive switching with voltage amplitudes below 1.5 V, compatible with advanced technology nodes. The array's multi-bit capability (over 32 stable states) and low programming noise (down to 10 nS) enable a nearly ideal weight transfer process, more than an order of magnitude better than other memristive technologies. Inference performance is validated through matrix-vector multiplication simulations on a 64x64 array, achieving a root-mean-square error improvement by a factor of 10 at 1 second and 3 at 10 years after programming, compared to state-of-the-art. Training accuracy closely matching the software equivalent is achieved across different datasets. The CMO/HfOx ReRAM technology lays the foundation for efficient analog systems accelerating both inference and training in deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04524v3</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donato Francesco Falcone, Victoria Clerico, Wooseok Choi, Tommaso Stecconi, Folkert Horst, Laura Begon-Lours, Matteo Galetta, Antonio La Porta, Nikhil Garg, Fabien Alibart, Bert Jan Offrein, Valeria Bragaglia</dc:creator>
    </item>
    <item>
      <title>Implementing Quantum Generative Adversarial Network (qGAN) and QCBM in Finance</title>
      <link>https://arxiv.org/abs/2308.08448</link>
      <description>arXiv:2308.08448v2 Announce Type: replace-cross 
Abstract: Quantum machine learning (QML) is a cross-disciplinary subject made up of two of the most exciting research areas: quantum computing and classical machine learning (ML), with ML and artificial intelligence (AI) being projected as the first fields that will be impacted by the rise of quantum machines. Quantum computers are being used today in drug discovery, material &amp; molecular modelling and finance. In this work, we discuss some upcoming active new research areas in application of quantum machine learning (QML) in finance. We discuss certain QML models that has become areas of active interest in the financial world for various applications. We use real world financial dataset and compare models such as qGAN (quantum generative adversarial networks) and QCBM (quantum circuit Born machine) among others, using simulated environments. For the qGAN, we define quantum circuits for discriminators and generators and show promises of future quantum advantage via QML in finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08448v2</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santanu Ganguly</dc:creator>
    </item>
    <item>
      <title>A Digital Twin Framework for Physical-Virtual Integration in V2X-Enabled Connected Vehicle Corridors</title>
      <link>https://arxiv.org/abs/2410.00356</link>
      <description>arXiv:2410.00356v2 Announce Type: replace-cross 
Abstract: Transportation Cyber-Physical Systems (T-CPS) enhance safety and mobility by integrating cyber and physical transportation systems. A key component of T-CPS is the Digital Twin (DT), a virtual representation that enables simulation, analysis, and optimization through real-time data exchange and communication. Although existing studies have explored DTs for vehicles, communications, pedestrians, and traffic, real-world validations and implementations of DTs that encompass infrastructure, vehicles, signals, communications, and more remain limited due to several challenges. These include accessing real-world connected infrastructure, integrating heterogeneous, multi-sourced data, ensuring real-time data processing, and synchronizing the digital and physical systems. To address these challenges, this study develops a traffic DT based on a real-world connected vehicle corridor. Leveraging the Cellular Vehicle-to-Everything (C-V2X) infrastructure in the corridor, along with communication, computing, and simulation technologies, the proposed DT accurately replicates physical vehicle behaviors, signal timing, communications, and traffic patterns within the virtual environment. Building upon the previous data pipeline, the digital system ensures robust synchronization with the physical environment. Moreover, the DT's scalable and redundant architecture enhances data integrity, making it capable of supporting future large-scale C-V2X deployments. Furthermore, its ability to provide feedback to the physical system is demonstrated through applications such as signal timing adjustments, vehicle advisory messages, and incident notifications. The proposed DT is a vital tool in T-CPS, enabling real-time traffic monitoring, prediction, and optimization to enhance the reliability and safety of transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00356v2</guid>
      <category>cs.RO</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keshu Wu, Pei Li, Yang Cheng, Steven T. Parker, Bin Ran, David A. Noyce, Xinyue Ye</dc:creator>
    </item>
  </channel>
</rss>
