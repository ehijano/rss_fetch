<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Jan 2026 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Do people expect different behavior from large language models acting on their behalf? Evidence from norm elicitations in two canonical economic games</title>
      <link>https://arxiv.org/abs/2601.15312</link>
      <description>arXiv:2601.15312v1 Announce Type: new 
Abstract: While delegating tasks to large language models (LLMs) can save people time, there is growing evidence that offloading tasks to such models produces social costs. We use behavior in two canonical economic games to study whether people have different expectations when decisions are made by LLMs acting on their behalf instead of themselves. More specifically, we study the social appropriateness of a spectrum of possible behaviors: when LLMs divide resources on our behalf (Dictator Game and Ultimatum Game) and when they monitor the fairness of splits of resources (Ultimatum Game). We use the Krupka-Weber norm elicitation task to detect shifts in social appropriateness ratings. Results of two pre-registered and incentivized experimental studies using representative samples from the UK and US (N = 2,658) show three key findings. First, people find that offers from machines - when no acceptance is necessary - are judged to be less appropriate than when they come from humans, although there is no shift in the modal response. Second - when acceptance is necessary - it is more appropriate for a person to reject offers from machines than from humans. Third, receiving a rejection of an offer from a machine is no less socially appropriate than receiving the same rejection from a human. Overall, these results suggest that people apply different norms for machines deciding on how to split resources but are not opposed to machines enforcing the norms. The findings are consistent with offers made by machines now being viewed as having both a cognitive and emotional component.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15312v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pawe{\l} Niszczota, Elia Antoniou</dc:creator>
    </item>
    <item>
      <title>On the closest balanced game</title>
      <link>https://arxiv.org/abs/2601.15318</link>
      <description>arXiv:2601.15318v1 Announce Type: new 
Abstract: Cooperative games with nonempty core are called balanced, and the set of balanced games is a polyhedron. Given a game with empty core, we look for the closest balanced game, in the sense of the (weighted) Euclidean distance, i.e., the orthogonal projection of the game on the set of balanced games. Besides an analytical approach which becomes rapidly intractable, we propose a fast algorithm to find the closest balanced game, avoiding exponential complexity for the optimization problem, and being able to run up to 20 players. We show experimentally that the probability that the closest game has a core reduced to a singleton tends to 1 when the number of players grow. We provide a mathematical proof that the proportion of facets whose games have a non-singleton core tends to 0 when the number of players grow, by finding an expression of the aymptotic growth of the number of minimal balanced collections. This permits to prove mathematically the experimental result. Consequently, taking the core of the projected game defines a new solution concept, which we call least square core due to its analogy with the least core, and our result shows that the probability that this is a point solution tends to 1 when the number of players grow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15318v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Garc\'ia-Segador, Michel Grabisch, Dylan Laplace Mermoud, Pedro Miranda</dc:creator>
    </item>
    <item>
      <title>Rules Create Unequal Rewards: Elite Tennis Players Allocate Resources Efficiently</title>
      <link>https://arxiv.org/abs/2601.15327</link>
      <description>arXiv:2601.15327v1 Announce Type: new 
Abstract: In many competitive settings, from education to politics, rules do not reward effort evenly, and thresholds (e.g., grade cutoffs or electoral majorities) make some moments disproportionately important. Success thus depends on efficiently allocating limited resources. However, empirical demonstration has been difficult because effort allocation is rarely observable and feedback is often delayed, limiting our understanding of expertise. Professional tennis provides an ideal natural experiment. Because each game resets after a player wins four points and points in a lost game are wasted, the value of a point varies sharply across scores. Efficient allocation should therefore win games without wasting points, conserving resources for future games. Such allocation manifests in score-dependent point-winning probabilities, from which we derive each player's Pareto frontier-the theoretical limit of the trade-off between game-winning probability and the expected points per game. Here, we show that top players operate closer to this frontier, converting points to game wins more efficiently. Optimal strategies reduce the probability of winning points when the player is far behind (e.g.,0-2, 0-3). This behavior is psychologically difficult-letting go of the current game-but represents a rational energy conservation strategy. Top players exhibit this pattern especially in return games, where winning points is harder than in service games, requiring them to drastically vary their efforts, consistent with game-theoretic predictions. These findings suggest that elite performance reflects efficient adaptation to rule-created value structures; knowing when to give up may be as fundamental to expertise as knowing when to compete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15327v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masatsugu Yoshizawa, Yuta Kawamoto, Daisuke Takeshita</dc:creator>
    </item>
    <item>
      <title>Equal-Pay Contracts</title>
      <link>https://arxiv.org/abs/2601.15478</link>
      <description>arXiv:2601.15478v1 Announce Type: new 
Abstract: We study multi-agent contract design, where a principal incentivizes a team of agents to take costly actions that jointly determine the project success via a combinatorial reward function. While prior work largely focuses on unconstrained contracts that allow heterogeneous payments across agents, many real-world environments limit payment dispersion. Motivated by this, we study equal-pay contracts, where all agents receive identical payments. Our results also extend to nearly-equal-pay contracts where any two payments are identical up to a constant factor.
  We provide both algorithmic and hardness results across a broad hierarchy of reward functions, under both binary and combinatorial action models. While we focus on equal-pay contracts, our analysis also yields new insights into unconstrained contract design, and resolves two important open problems. On the positive side, we design polynomial-time O(1)-approximation algorithms for (i) submodular rewards under combinatorial actions, and (ii) XOS rewards under binary actions. These guarantees are tight: We rule out the existence of (i) a PTAS for combinatorial actions, even for gross substitutes rewards (unless P = NP), and (ii) any O(1)-approximation for XOS rewards with combinatorial actions. Crucially, our hardness results hold even for unconstrained contracts, thereby settling the corresponding open problems in this setting.
  Finally, we quantify the loss induced by fairness via the price of equality, defined as the worst-case ratio between the optimal principal's utility achievable by unconstrained contracts and that achievable by equal-pay contracts. We obtain a bound of $\Theta(\log n/ \log \log n)$, where $n$ is the number of agents. This gap is tight in a strong sense: the upper bound applies even for XOS rewards with combinatorial actions, while the lower bound arises already for additive rewards with binary actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15478v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michal Feldman, Yoav Gal-Tzur, Tomasz Ponitka, Maya Schlesinger</dc:creator>
    </item>
    <item>
      <title>How to Tamper with a Parliament: Strategic Campaigns in Apportionment Elections</title>
      <link>https://arxiv.org/abs/2601.15855</link>
      <description>arXiv:2601.15855v1 Announce Type: new 
Abstract: In parliamentary elections, parties compete for a limited, typically fixed number of seats. Most parliaments are assembled using apportionment methods that distribute the seats based on the parties' vote counts. Common apportionment methods include divisor sequence methods (like D'Hondt or Sainte-Lagu\"e), the largest-remainder method, and first-past-the-post. In many countries, an electoral threshold is implemented to prevent very small parties from entering the parliament. Further, several countries have apportionment systems that incorporate multiple districts. We study how computationally hard it is to change the election outcome (i.e., to increase or limit the influence of a distinguished party) by convincing a limited number of voters to change their vote. We refer to these bribery-style attacks as \emph{strategic campaigns} and study the corresponding problems in terms of their computational (both classical and parameterized) complexity. We also run extensive experiments on real-world election data and study the effectiveness of optimal campaigns, in particular as opposed to using heuristic bribing strategies and with respect to the influence of the threshold and the influence of the number of districts. For apportionment elections with threshold, finally, we propose -- as an alternative to the standard top-choice mode -- the second-chance mode where voters of parties below the threshold receive a second chance to vote for another party, and we establish computational complexity results also in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15855v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcss.2025.103700</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computer and System Sciences, Volume 155, February 2026, 103700</arxiv:journal_reference>
      <dc:creator>Robert Bredereck, Piotr Faliszewski, Micha{\l} Furdyna, Andrzej Kaczmarczyk, Joanna Kaczmarek, Martin Lackner, Christian Lau{\ss}mann, J\"org Rothe, Tessa Seeger</dc:creator>
    </item>
    <item>
      <title>Minimum Envy Graphical House Allocation Beyond Identical Valuations</title>
      <link>https://arxiv.org/abs/2601.15864</link>
      <description>arXiv:2601.15864v1 Announce Type: new 
Abstract: House allocation is an extremely well-studied problem in the field of fair allocation, where the goal is to assign $n$ houses to $n$ agents while satisfying certain fairness criterion, e.g., envy-freeness. To model social interactions, the Graphical House Allocation framework introduces a social graph $G$, in which each vertex corresponds to an agent, and an edge $(u, v)$ corresponds to the potential of agent $u$ to envy the agent $v$, based on their allocations and valuations. In undirected social graphs, the potential for envy is in both the directions. In the Minimum Envy Graphical House Allocation (ME-GHA) problem, given a set of $n$ agents, $n$ houses, a social graph, and agent's valuation functions, the goal is to find an allocation that minimizes the total envy summed up over all the edges of $G$. Recent work, [Hosseini et al., AAMAS 2023, AAMAS 2024] studied ME-GHA in the regime of polynomial-time algorithms, and designed exact and approximation algorithms, for certain graph classes under identical agent valuations. We initiate the study of \gha with non-identical valuations, a setting that has so far remained unexplored. We investigate the multivariate (parameterized) complexity of \gha by identifying structural restrictions on the social graph and valuation functions that yield tractability. We also design moderately exponential-time algorithms for several graph classes, and a polynomial-time algorithm for {binary valuations that returns an allocation with envy at most one when the social graph has maximum degree at most one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15864v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanmay Inamdar, Pallavi Jain, Pranjal Pandey</dc:creator>
    </item>
    <item>
      <title>Ecosystem Competition and Cross-Market Subsidization: A Dynamic Theory of Platform Pricing</title>
      <link>https://arxiv.org/abs/2601.15303</link>
      <description>arXiv:2601.15303v1 Announce Type: cross 
Abstract: Platform giants in China have operated with persistently compressed margins in highly concentrated markets for much of the past decade, despite market shares exceeding 60\% in core segments. Standard theory predicts otherwise: either the weaker firm exits, or survivors raise prices to monopoly levels. We argue the puzzle dissolves once firms are viewed as ecosystem optimizers rather than single-market profit maximizers. We develop a dynamic game in which a firm's willingness to subsidize depends on the spillover value its users generate in adjacent markets -- what we call \textit{ecosystem complementarity}. When this complementarity is strong enough, perpetual below-cost pricing emerges as the unique stable equilibrium. The result is not predation in the classical sense; there is no recoupment phase. It is a permanent state of subsidized competition, rational for each firm individually but potentially inefficient in aggregate. We characterize the equilibrium, establish its dynamic stability, and show that welfare losses compound over time as capital flows into subsidy wars rather than innovation. The model's predictions are consistent with observed patterns in Chinese platform markets and suggest that effective antitrust intervention should target cross-market capital flows rather than prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15303v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Chen</dc:creator>
    </item>
    <item>
      <title>The Impossibility of Cohesion Without Fragmentation</title>
      <link>https://arxiv.org/abs/2601.15317</link>
      <description>arXiv:2601.15317v1 Announce Type: cross 
Abstract: Most models in game theory and network formation implicitly assume that relations between agents are feasible whenever incentives are aligned or interaction opportunities exist. Under this premise analytical attention is directed toward equilibrium efficiency or probabilistic link formation while the possibility that a relation may be structurally infeasible is rarely examined. This paper develops a static axiomatic framework in which relation maintenance is treated as a problem of structural compatibility rather than strategic choice or stochastic realization. Agents occupy positions in an abstract space and relations are subject to minimum conditions defined over these positions. A bifurcation event such as a vote declaration or institutional assignment fixes agents positions and thereby determines which relations are compatible. We identify position dependent gain axes as the key source of structural selectivity and prove an impossibility result under any non degenerate positional constraint no bifurcation event can preserve all relations. Instead the post event network necessarily exhibits either the simultaneous emergence of fragmentation and cohesion or a degenerate trivial case in which constraints are position independent. The result is purely structural and does not rely on preferences beliefs incentives or dynamic adjustment. It establishes a fundamental limit on universally cohesive outcomes and reframes division not as a failure of design or coordination but as a logical consequence of positional constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15317v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisuke Hirota</dc:creator>
    </item>
    <item>
      <title>Stabilizing Welfare-Maximizing Decisions via Endogenous Transfers</title>
      <link>https://arxiv.org/abs/2601.15563</link>
      <description>arXiv:2601.15563v1 Announce Type: cross 
Abstract: Many multiagent systems rely on collective decision-making among self-interested agents, which raises deep questions about coalition formation and stability. We study social choice with endogenous, outcome-contingent transfers, where agents voluntarily form contracts that redistribute utility depending on the collective decision, allowing fully strategic, incentive-aligned coalition formation. We show that under consensus rules, individually rational strong Nash equilibria (IR-SNE) always exist, implementing welfare-maximizing outcomes with feasible transfers, and provide a simple, efficient algorithm to construct them. For more general anonymous, monotonic, and resolute rules, we identify necessary conditions for profitable deviations, sharply limiting destabilizing coalitions. By bridging cooperative and noncooperative perspectives, our approach shows that transferable utility can achieve core-like stability, restoring efficiency and budget balance even where classical impossibility results apply. Overall, this framework offers a practical and robust way to coordinate large-scale strategic multiagent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15563v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Kavner</dc:creator>
    </item>
    <item>
      <title>Screening for Choice Sets</title>
      <link>https://arxiv.org/abs/2601.15580</link>
      <description>arXiv:2601.15580v1 Announce Type: cross 
Abstract: We study a screening problem in which an agent privately observes a set of feasible technologies and can strategically disclose only a subset to the principal. The principal then takes an action whose payoff consequences for both players are publicly known. Under the assumption that the possible technology sets are ordered by set inclusion, we show that the optimal mechanism promises the agent a utility that is weakly increasing as the reported set expands, and the choice of the principal maximizes her own utility subject to this promised utility constraint. Moreover, the optimal promised utility either coincides with the agent's utility under the complete information benchmark or remains locally constant, with the number of constant segments bounded by the number of downward-sloping segments of the complete information benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15580v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan Gan, Yingkai Li</dc:creator>
    </item>
    <item>
      <title>Average Unfairness in Routing Games</title>
      <link>https://arxiv.org/abs/2601.16187</link>
      <description>arXiv:2601.16187v1 Announce Type: cross 
Abstract: We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16187v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pan-Yang Su, Arwa Alanqary, Bryce L. Ferguson, Manxi Wu, Alexandre M. Bayen, Shankar Sastry</dc:creator>
    </item>
    <item>
      <title>Scalable Board Expansion within a General Game System</title>
      <link>https://arxiv.org/abs/2601.16216</link>
      <description>arXiv:2601.16216v1 Announce Type: cross 
Abstract: This thesis explores the use of a General Game System (GGS) to support the automatic expansion of game boards in boardless games. Traditional implementations of such games often rely on oversized static boards defined from the start, even though large portions of these boards may never be used during gameplay. This approach leads to unnecessary complexity. To address this issue, this thesis propose a dynamic board expansion mechanism in which the game board grows automatically during play.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16216v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.SE</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ementine Sacr\'e</dc:creator>
    </item>
    <item>
      <title>Disentangling trust from cooperation: Trust as reduced monitoring across social dilemmas</title>
      <link>https://arxiv.org/abs/2509.04143</link>
      <description>arXiv:2509.04143v3 Announce Type: replace 
Abstract: It is commonly assumed that trust increases cooperation. However, game-theoretic models often fail to distinguish between cooperative actions and trust, making it difficult to independently measure trust and determine how its effects vary in different social dilemmas. To address this, we build on influential theories that equate trust with reduced monitoring of an agent's actions. We implement this as a heuristic that cognitively bounded agents can use in repeated games to avoid spending time and effort always monitoring their partner. Agents using this heuristic reduce monitoring of a partner's actions once a threshold level of cooperativeness has been observed -- providing a measurable and architecture-agnostic definition of trust. Using evolutionary game theory, we systematically analyse the success of strategies that use this trust heuristic across the entire space of two-player symmetric social dilemma games. We demonstrate that trust-as-reduced-monitoring facilitates cooperation in two different ways. First, when monitoring is costly, trust heuristics allow for higher levels of cooperation in social dilemmas where the temptation to defect is high. Second, when agents can make action errors, trust heuristics promote cooperation even in coordination problems. Our results disentangle trust from cooperation, and provide a behavioural measure of trust that applies across interaction types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04143v3</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cedric Perret, The Anh Han, Elias Fern\'andez Domingos, Theodor Cimpeanu, Simon T. Powers</dc:creator>
    </item>
    <item>
      <title>Bipartiteness in Progressive Second-Price Multi-Auction Networks with Perfect Substitute</title>
      <link>https://arxiv.org/abs/2511.19225</link>
      <description>arXiv:2511.19225v2 Announce Type: replace 
Abstract: We consider a bipartite network of buyers and sellers, where the sellers run locally independent Progressive Second-Price (PSP) auctions, and buyers may participate in multiple auctions, forming a multi-auction market with perfect substitute. The paper develops a projection-based influence framework for decentralized PSP auctions. We formalize primary and expanded influence sets using projections on the active bid index set and show how partial orders on bid prices govern allocation, market shifts, and the emergence of saturated one-hop shells. Our results highlight the robustness of PSP auctions in decentralized environments by introducing saturated components and a structured framework for phase transitions in multi-auction dynamics. This structure ensures deterministic coverage of the strategy space, enabling stable and truthful embedding in the larger game. We further model intra-round dynamics using an index to capture coordinated asynchronous seller updates coupled through buyers' joint constraints. Together, these constructions explain how local interactions propagate across auctions and gives premise for coherent equilibria--without requiring global information or centralized control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19225v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordana Blazek, Frederick C. Harris Jr</dc:creator>
    </item>
    <item>
      <title>Games with $\omega$-Automatic Preference Relations</title>
      <link>https://arxiv.org/abs/2503.04759</link>
      <description>arXiv:2503.04759v3 Announce Type: replace-cross 
Abstract: This paper investigates Nash equilibria (NEs) in multi-player turn-based games on graphs, where player preferences are modeled as $\omega$-automatic relations via deterministic parity automata. Unlike much of the existing literature, which focuses on specific reward functions, our results apply to any preference relation definable by an $\omega$-automatic relation. We analyze the computational complexity of determining the existence of an NE (possibly under some constraints), verifying whether a given strategy profile forms an NE, and checking whether a specific outcome can be realized by an NE. When a (constrained) NE exists, we show that there always exists one with finite-memory strategies. Finally, we explore fundamental properties of $\omega$-automatic relations and their implications for the existence of equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04759v3</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.MFCS.2025.31</arxiv:DOI>
      <dc:creator>V\'eronique Bruy\`ere, Christophe Grandmont, Jean-Fran\c{c}ois Raskin</dc:creator>
    </item>
    <item>
      <title>Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism</title>
      <link>https://arxiv.org/abs/2601.15249</link>
      <description>arXiv:2601.15249v2 Announce Type: replace-cross 
Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15249v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>stat.ME</category>
      <pubDate>Fri, 23 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garrett G. Wen, Buxin Su, Natalie Collina, Zhun Deng, Weijie Su</dc:creator>
    </item>
  </channel>
</rss>
