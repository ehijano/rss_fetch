<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Temporal Dynamics beyond the Exceptional Point in the Ikeda Map with Balanced Gain and Loss</title>
      <link>https://arxiv.org/abs/2406.17783</link>
      <description>arXiv:2406.17783v1 Announce Type: new 
Abstract: We investigate the temporal dynamics of the Ikeda Map with Balanced Gain and Loss and in the presence of feedback loops with saturation nonlinearity. From the bifurcation analysis, we find that the temporal evolution of optical power undergoes period quadrupling at the exceptional point (EP) of the system and beyond that, chaotic dynamics emerge in the system and this has been further corroborated from the Largest Lyapunov Exponent (LLE) of the model. For a closer inspection, we analyzed the parameter basin of the system, which further leads to our inference that the Ikeda Map with Balanced Gain and Loss exhibits the emergence of chaotic dynamics beyond the exceptional point (EP). Furthermore, we find that the temporal dynamics beyond the EP regime leads to the onset of Extreme Events (EE) in this system via attractor merging crisis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17783v1</guid>
      <category>eess.SP</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jyoti Prasad Deka, Amarendra K. Sarma</dc:creator>
    </item>
    <item>
      <title>Scalable Near-Field Localization Based on Partitioned Large-Scale Antenna Array</title>
      <link>https://arxiv.org/abs/2406.17784</link>
      <description>arXiv:2406.17784v1 Announce Type: new 
Abstract: This paper studies a passive localization system, where an extremely large-scale antenna array (ELAA) is deployed at the base station (BS) to locate a user equipment (UE) residing in its near-field (Fresnel) region. We propose a novel algorithm, named array partitioning-based location estimation (APLE), for scalable near-field localization. The APLE algorithm is developed based on the basic assumption that, by partitioning the ELAA into multiple subarrays, the UE can be approximated as in the far-field region of each subarray. We establish a Bayeian inference framework based on the geometric constraints between the UE location and the angles of arrivals (AoAs) at different subarrays. Then, the APLE algorithm is designed based on the message-passing principle for the localization of the UE. APLE exhibits linear computational complexity with the number of BS antennas, leading to a significant reduction in complexity compared to existing methods. We further propose an enhanced APLE (E-APLE) algorithm that refines the location estimate obtained from APLE by following the maximum likelihood principle. The E-APLE algorithm achieves superior localization accuracy compared to APLE while maintaining a linear complexity with the number of BS antennas. Numerical results demonstrate that the proposed APLE and E-APLE algorithms outperform the existing baselines in terms of localization accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17784v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojun Yuan, Yuqing Zheng, Mingchen Zhang, Boyu Teng, Wenjun Jiang</dc:creator>
    </item>
    <item>
      <title>DeepSense-V2V: A Vehicle-to-Vehicle Multi-Modal Sensing, Localization, and Communications Dataset</title>
      <link>https://arxiv.org/abs/2406.17908</link>
      <description>arXiv:2406.17908v1 Announce Type: new 
Abstract: High data rate and low-latency vehicle-to-vehicle (V2V) communication are essential for future intelligent transport systems to enable coordination, enhance safety, and support distributed computing and intelligence requirements. Developing effective communication strategies, however, demands realistic test scenarios and datasets. This is important at the high-frequency bands where more spectrum is available, yet harvesting this bandwidth is challenged by the need for direction transmission and the sensitivity of signal propagation to blockages. This work presents the first large-scale multi-modal dataset for studying mmWave vehicle-to-vehicle communications. It presents a two-vehicle testbed that comprises data from a 360-degree camera, four radars, four 60 GHz phased arrays, a 3D lidar, and two precise GPSs. The dataset contains vehicles driving during the day and night for 120 km in intercity and rural settings, with speeds up to 100 km per hour. More than one million objects were detected across all images, from trucks to bicycles. This work further includes detailed dataset statistics that prove the coverage of various situations and highlights how this dataset can enable novel machine-learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17908v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joao Morais, Gouranga Charan, Nikhil Srinivas, Ahmed Alkhateeb</dc:creator>
    </item>
    <item>
      <title>V2X Sidelink Positioning in FR1: From Ray-Tracing and Channel Estimation to Bayesian Tracking</title>
      <link>https://arxiv.org/abs/2406.17950</link>
      <description>arXiv:2406.17950v1 Announce Type: new 
Abstract: Sidelink positioning research predominantly focuses on the snapshot positioning problem, often within the mmWave band. Only a limited number of studies have delved into vehicle-to-anything (V2X) tracking within sub-6 GHz bands. In this paper, we investigate the V2X sidelink tracking challenges over sub-6 GHz frequencies. We propose a Kalman-filter-based tracking approach that leverages the estimated error covariance lower bounds (EECLBs) as measurement covariance, alongside a gating method to augment tracking performance. Through simulations employing ray-tracing data and super-resolution channel parameter estimation, we validate the feasibility of sidelink tracking using our proposed tracking filter with two novel EECLBs. Additionally, we demonstrate the efficacy of the gating method in identifying line-of-sight paths and enhancing tracking performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17950v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yu Ge, Maximilian Stark, Musa Furkan Keskin, Hui Chen, Guillaume Jornod, Thomas Hansen, Frank Hofmann, Henk Wymeersch</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals</title>
      <link>https://arxiv.org/abs/2406.18069</link>
      <description>arXiv:2406.18069v1 Announce Type: new 
Abstract: Large language models (LLMs) have captured significant interest from both academia and industry due to their impressive performance across various textual tasks. However, the potential of LLMs to analyze physiological time-series data remains an emerging research field. Particularly, there is a notable gap in the utilization of LLMs for analyzing wearable biosignals to achieve cuffless blood pressure (BP) measurement, which is critical for the management of cardiovascular diseases. This paper presents the first work to explore the capacity of LLMs to perform cuffless BP estimation based on wearable biosignals. We extracted physiological features from electrocardiogram (ECG) and photoplethysmogram (PPG) signals and designed context-enhanced prompts by combining these features with BP domain knowledge and user information. Subsequently, we adapted LLMs to BP estimation tasks through instruction tuning. To evaluate the proposed approach, we conducted assessments of ten advanced LLMs using a comprehensive public dataset of wearable biosignals from 1,272 participants. The experimental results demonstrate that the optimally fine-tuned LLM significantly surpasses conventional task-specific baselines, achieving an estimation error of 0.00 $\pm$ 9.25 mmHg for systolic BP and 1.29 $\pm$ 6.37 mmHg for diastolic BP. Notably, the ablation studies highlight the benefits of our context enhancement strategy, leading to an 8.9% reduction in mean absolute error for systolic BP estimation. This paper pioneers the exploration of LLMs for cuffless BP measurement, providing a potential solution to enhance the accuracy of cuffless BP measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18069v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zengding Liu, Chen Chen, Jiannong Cao, Minglei Pan, Jikui Liu, Nan Li, Fen Miao, Ye Li</dc:creator>
    </item>
    <item>
      <title>High Resolution Millimeter Wave Imaging Based on FMCW Radar Systems at W-Band</title>
      <link>https://arxiv.org/abs/2406.18244</link>
      <description>arXiv:2406.18244v1 Announce Type: new 
Abstract: In this paper, we present a unique $\text {2D}$ high resolution, compact, low-cost, low-weight, and highly accurate millimeter wave (mm-Wave) imagery system capable of operating in all weather conditions. We describe mm-Wave imaging process in detail and present several novel signal processing methods with their applications. To create the array, we utilize the Synthetic Aperture Radar (SAR) concept. The imagery system presented in this work, can strongly compete with Lidar systems as the reolution limit is at the same level. Furthermore, in contrast to the Lidar systems, our imagery system can operate in heavy rain and dense fog and produce high quality images.
  We use our custom-made Frequency Modulated Continuous Wave (FMCW) radar operating at W-band with $\text {33 GHz}$ bandwidth for data collection and present the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18244v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shahrokh Hamidi, M. R. Nezhad-Ahmadi</dc:creator>
    </item>
    <item>
      <title>Neural Network-Based RIS Assisted NLoS DoA Estimation</title>
      <link>https://arxiv.org/abs/2406.18306</link>
      <description>arXiv:2406.18306v1 Announce Type: new 
Abstract: This paper presents a learning-based approach for Direction of Arrival (DoA) estimation using a Reconfigurable Intelligent Surface (RIS) in a Non-Line-of-Sight (NLoS) scenario. The key innovation is the employment of a novel Neural Network (NN)-based fully connected layer, referred to as the NN-based RIS layer, within a generic Multi-Layer Perceptron (MLP) structure.
  The NN-based RIS layer is designed to learn the optimal RIS phase shifts that are tailored for the DoA estimation task. To achieve this, the pre-processed real-valued observations are fed into the RIS layer, which has a specialized structure. Unlike regular neural network layers, the weights of the NN-based RIS layer are constrained to be sinusoidal functions, with the phase arguments being the tunable parameters during the training process. This allows the layer to emulate the functionality of an RIS.
  Accordingly, the standard feed-forward and back-propagation procedures are modified to accommodate the unique structure of the NN-based RIS layer. Numerical simulations demonstrate that the proposed machine learning-based approach outperforms conventional non-learning-based methods for DoA estimation under almost every practical SNR range in an RIS-assisted scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18306v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasin Azhdari, Mahmoud Farhang</dc:creator>
    </item>
    <item>
      <title>CmWave and Sub-THz: Key Radio Enablers and Complementary Spectrum for 6G</title>
      <link>https://arxiv.org/abs/2406.18391</link>
      <description>arXiv:2406.18391v1 Announce Type: new 
Abstract: Sixth-generation (6G) networks are poised to revolutionize communication by exploring alternative spectrum options, aiming to capitalize on strengths while mitigating limitations in current fifth-generation (5G) spectrum. This paper explores the potential opportunities and emerging trends for cmWave and sub-THz spectra as key radio enablers. This paper poses and answers three key questions regarding motivation of additional spectrum to explore the strategic implementation and benefits of cmWave and sub-THz spectra. Also, we show using case studies how these complementary spectrum bands will enable new applications in 6G, such as integrated sensing and communication (ISAC), re-configurable intelligent surfaces (RIS) and non-terrestrial networks (NTN). Numerical simulations reveal that the ISAC performance of cmWave and sub-THz spectra outperforms that of existing 5G spectrum, including sub-6 GHz and mmWave. Additionally, we illustrate the effective interplay between RIS and NTN to counteract the effects of high attenuation at sub-THz frequencies. Finally, ongoing standardization endeavors, challenges and promising directions are elucidated for these complementary spectrum bands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18391v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mayur V. Katwe, Aryan Kaushik, Keshav Singh, Marco Di Renzo, Shu Sun, Doohwan Lee, Ana G. Armada, Yonina C. Eldar, Octavia A. Dobre, Theodore S. Rappaport</dc:creator>
    </item>
    <item>
      <title>L-Sort: An Efficient Hardware for Real-time Multi-channel Spike Sorting with Localization</title>
      <link>https://arxiv.org/abs/2406.18425</link>
      <description>arXiv:2406.18425v1 Announce Type: new 
Abstract: Spike sorting is essential for extracting neuronal information from neural signals and understanding brain function. With the advent of high-density microelectrode arrays (HDMEAs), the challenges and opportunities in multi-channel spike sorting have intensified. Real-time spike sorting is particularly crucial for closed-loop brain computer interface (BCI) applications, demanding efficient hardware implementations. This paper introduces L-Sort, an hardware design for real-time multi-channel spike sorting. Leveraging spike localization techniques, L-Sort achieves efficient spike detection and clustering without the need to store raw signals during detection. By incorporating median thresholding and geometric features, L-Sort demonstrates promising results in terms of accuracy and hardware efficiency. We assessed the detection and clustering accuracy of our design with publicly available datasets recorded using high-density neural probes (Neuropixel). We implemented our design on an FPGA and compared the results with state of the art. Results show that our designs consume less hardware resource comparing with other FPGA-based spike sorting hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18425v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuntao Han, Shiwei Wang, Alister Hamilton</dc:creator>
    </item>
    <item>
      <title>Multicarrier ISAC: Advances in Waveform Design, Signal Processing and Learning under Non-Idealities</title>
      <link>https://arxiv.org/abs/2406.18476</link>
      <description>arXiv:2406.18476v1 Announce Type: new 
Abstract: This paper addresses the topic of integrated sensing and communications (ISAC) in 5G and emerging 6G wireless networks. ISAC systems operate within shared, congested or even contested spectrum, aiming to deliver high performance in both wireless communications and radio frequency (RF) sensing. The expected benefits include more efficient utilization of spectrum, power, hardware (HW) and antenna resources. Focusing on multicarrier (MC) systems, which represent the most widely used communication waveforms, it explores the co-design and optimization of waveforms alongside multiantenna transceiver signal processing for communications and both monostatic and bistatic sensing applications of ISAC. Moreover, techniques of high practical relevance for overcoming and even harnessing challenges posed by non-idealities in actual transceiver implementations are considered. To operate in highly dynamic radio environments and target scenarios, both model-based structured optimization and learning-based methodologies for ISAC systems are covered, assessing their adaptability and learning capabilities under real-world conditions. The paper presents trade-offs in communication-centric and radar-sensing-centric approaches, aiming for an optimized balance in densely used spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18476v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Visa Koivunen, Musa Furkan Keskin, Henk Wymeersch, Mikko Valkama, Nuria Gonz\'alez-Prelcic</dc:creator>
    </item>
    <item>
      <title>Design and Implementation of a Low-Power Low-Noise Biopotential Amplifier in 28 nm CMOS Technology with a Compact Die-Area of 2500~\si{\micro\meter\squared}</title>
      <link>https://arxiv.org/abs/2406.17779</link>
      <description>arXiv:2406.17779v1 Announce Type: cross 
Abstract: This paper presents a compact low-power, low-noise bioamplifier for multi-channel electrode arrays, aimed at recording action potentials. The design we put forth attains a notable decrease in both size and power consumption. This is achieved by incorporating an active lowpass filter that doesn't rely on bulky DC-blocking capacitors, and by utilizing the TSMC 28 nm HPC CMOS technology. This paper presents extensive simulation results of noise and results from measured performance. With a mid-band gain of 58 dB, a -~3~dB bandwidth of 7 kHz (from 150 Hz to 7.1 kHz), and an input-referred noise of 15.8~\si{\micro\volt_{rms}} corresponding to a NEF of 12. The implemented design achieves a favourable trade-off between noise, area, and power consumption, surpassing previous findings in terms of size and power. The amplifier occupies the smallest area of 2500~\si{\micro\meter\squared} and consumes only 3.4~\si{\micro\watt} from a 1.2 V power supply corresponding to a power efficiency factor of 175 and an area efficiency factor of 0.43, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17779v1</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esmaeil Ranjbar Koleibi, Konin Koua, William Lemaire, Maher Benhouria, Marwan Besrour, Takwa Omrani, J\'er\'emy M\'enard, Louis-Philippe Gauthier, Montassar Dridi, Mahziar Serri Mazandarani, Benoit Gosselin, S\'ebastien Royand R\'ejean Fontaine</dc:creator>
    </item>
    <item>
      <title>CNN-based Compressor Mass Flow Estimator in Industrial Aircraft Vapor Cycle System</title>
      <link>https://arxiv.org/abs/2406.17788</link>
      <description>arXiv:2406.17788v1 Announce Type: cross 
Abstract: In Vapor Cycle Systems, the mass flow sensor playsa key role for different monitoring and control purposes. However,physical sensors can be inaccurate, heavy, cumbersome, expensive orhighly sensitive to vibrations, which is especially problematic whenembedded into an aircraft. The conception of a virtual sensor, basedon other standard sensors, is a good alternative. This paper has twomain objectives. Firstly, a data-driven model using a ConvolutionalNeural Network is proposed to estimate the mass flow of thecompressor. We show that it significantly outperforms the standardPolynomial Regression model (thermodynamic maps), in terms of thestandard MSE metric and Engineer Performance metrics. Secondly,a semi-automatic segmentation method is proposed to compute theEngineer Performance metrics for real datasets, as the standard MSEmetric may pose risks in analyzing the dynamic behavior of VaporCycle Systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17788v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Reverdi (IRIT, IMT), Sixin Zhang (IRIT), Sa\"id Aoues (IMT), Fabrice Gamboa (IMT), Serge Gratton (IRIT), Thomas Pellegrini (IRIT)</dc:creator>
    </item>
    <item>
      <title>Filtering Reconfigurable Intelligent Computational Surface for RF Spectrum Purification</title>
      <link>https://arxiv.org/abs/2406.18055</link>
      <description>arXiv:2406.18055v1 Announce Type: cross 
Abstract: The increasing demand for communication is degrading the electromagnetic (EM) transmission environment due to severe EM interference, significantly reducing the efficiency of the radio frequency (RF) spectrum. Metasurfaces, a promising technology for controlling desired EM waves, have recently received significant attention from both academia and industry. However, the potential impact of out-of-band signals has been largely overlooked, leading to RF spectrum pollution and degradation of wireless transmissions. To address this issue, we propose a novel surface structure called the Filtering Reconfigurable Intelligent Computational Surface (FRICS). We introduce two types of FRICS structures: one that dynamically reflects resonance band signals through a tunable spatial filter while absorbing out-of-band signals using metamaterials and the other one that dynamically amplifies in-band signals using computational metamaterials while reflecting out-of-band signals. To evaluate the performance of FRICS, we implement it in device-to-device (D2D) communication and vehicular-to-everything (V2X) scenarios. The experiments demonstrate the superiority of FRICS in signal-to-interference-noise ratio (SINR) and energy efficiency (EE). Finally, we discuss the critical challenges faced and promising techniques for implementing FRICS in future wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18055v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaining Wang, Bo Yang, Zhiwen Yu, Xuelin Cao, M\'erouane Debbah, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>A Jammer-Mitigating 267 Mb/s 3.78 mm$^2$ 583 mW 32$\times$8 Multi-User MIMO Receiver in 22FDX</title>
      <link>https://arxiv.org/abs/2406.18149</link>
      <description>arXiv:2406.18149v1 Announce Type: cross 
Abstract: We present the first multi-user (MU) multiple-input multiple-output (MIMO) receiver ASIC that mitigates jamming attacks. The ASIC implements a recent nonlinear algorithm that performs joint jammer mitigation (via spatial filtering) and data detection (using a box prior on the data symbols). Our design supports 8 user equipments (UEs) and 32 basestation (BS) antennas, QPSK and 16-QAM with soft-outputs, and enables the mitigation of single-antenna barrage jammers and smart jammers. The fabricated 22 nm FD-SOI ASIC includes preprocessing, has a core area of 3.78 mm$^2$, achieves a throughput of 267 Mb/s while consuming 583 mW, and is the only existing design that enables reliable data detection under jamming attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18149v1</guid>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Bucheli, Oscar Casta\~neda, Gian Marti, Christoph Studer</dc:creator>
    </item>
    <item>
      <title>FedAQ: Communication-Efficient Federated Edge Learning via Joint Uplink and Downlink Adaptive Quantization</title>
      <link>https://arxiv.org/abs/2406.18156</link>
      <description>arXiv:2406.18156v1 Announce Type: cross 
Abstract: Federated learning (FL) is a powerful machine learning paradigm which leverages the data as well as the computational resources of clients, while protecting clients' data privacy. However, the substantial model size and frequent aggregation between the server and clients result in significant communication overhead, making it challenging to deploy FL in resource-limited wireless networks. In this work, we aim to mitigate the communication overhead by using quantization. Previous research on quantization has primarily focused on the uplink communication, employing either fixed-bit quantization or adaptive quantization methods. In this work, we introduce a holistic approach by joint uplink and downlink adaptive quantization to reduce the communication overhead. In particular, we optimize the learning convergence by determining the optimal uplink and downlink quantization bit-length, with a communication energy constraint. Theoretical analysis shows that the optimal quantization levels depend on the range of model gradients or weights. Based on this insight, we propose a decreasing-trend quantization for the uplink and an increasing-trend quantization for the downlink, which aligns with the change of the model parameters during the training process. Experimental results show that, the proposed joint uplink and downlink adaptive quantization strategy can save up to 66.7% energy compared with the existing schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18156v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linping Qu, Shenghui Song, Chi-Ying Tsui</dc:creator>
    </item>
    <item>
      <title>EmT: A Novel Transformer for Generalized Cross-subject EEG Emotion Recognition</title>
      <link>https://arxiv.org/abs/2406.18345</link>
      <description>arXiv:2406.18345v1 Announce Type: cross 
Abstract: Integrating prior knowledge of neurophysiology into neural network architecture enhances the performance of emotion decoding. While numerous techniques emphasize learning spatial and short-term temporal patterns, there has been limited emphasis on capturing the vital long-term contextual information associated with emotional cognitive processes. In order to address this discrepancy, we introduce a novel transformer model called emotion transformer (EmT). EmT is designed to excel in both generalized cross-subject EEG emotion classification and regression tasks. In EmT, EEG signals are transformed into a temporal graph format, creating a sequence of EEG feature graphs using a temporal graph construction module (TGC). A novel residual multi-view pyramid GCN module (RMPG) is then proposed to learn dynamic graph representations for each EEG feature graph within the series, and the learned representations of each graph are fused into one token. Furthermore, we design a temporal contextual transformer module (TCT) with two types of token mixers to learn the temporal contextual information. Finally, the task-specific output module (TSO) generates the desired outputs. Experiments on four publicly available datasets show that EmT achieves higher results than the baseline methods for both EEG emotion classification and regression tasks. The code is available at https://github.com/yi-ding-cs/EmT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18345v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Ding, Chengxuan Tong, Shuailei Zhang, Muyun Jiang, Yong Li, Kevin Lim Jun Liang, Cuntai Guan</dc:creator>
    </item>
    <item>
      <title>Sensorless model-based tension control for a cable-driven exosuit</title>
      <link>https://arxiv.org/abs/2406.18412</link>
      <description>arXiv:2406.18412v1 Announce Type: cross 
Abstract: Cable-driven exosuits have the potential to support individuals with motor disabilities across the continuum of care. When supporting a limb with a cable, force sensors are often used to measure tension. However, force sensors add cost, complexity, and distal components. This paper presents a design and control approach to remove the force sensor from an upper limb cable-driven exosuit. A mechanical design for the exosuit was developed to maximize passive transparency. Then, a data-driven friction identification was conducted on a mannequin test bench to design a model-based tension controller. Seventeen healthy participants raised and lowered their right arms to evaluate tension tracking, movement quality, and muscular effort. Questionnaires on discomfort, physical exertion, and fatigue were collected. The proposed strategy allowed tracking the desired assistive torque with an RMSE of 0.71 Nm (18%) at 50% gravity support. During the raising phase, the EMG signals of the anterior deltoid, trapezius, and pectoralis major were reduced on average compared to the no-suit condition by 30%, 38%, and 38%, respectively. The posterior deltoid activity was increased by 32% during lowering. Position tracking was not significantly altered, whereas movement smoothness significantly decreased. This work demonstrates the feasibility and effectiveness of removing the force sensor from a cable-driven exosuit. A significant increase in discomfort in the lower neck and right shoulder indicated that the ergonomics of the suit could be improved. Overall this work paves the way towards simpler and more affordable exosuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18412v1</guid>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Elena Bardi, Adrian Esser, Peter Wolf, Marta Gandolla, Emilia Ambrosini, Alessandra Pedrocchi, Robert Riener</dc:creator>
    </item>
    <item>
      <title>Differential error feedback for communication-efficient decentralized learning</title>
      <link>https://arxiv.org/abs/2406.18418</link>
      <description>arXiv:2406.18418v1 Announce Type: cross 
Abstract: Communication-constrained algorithms for decentralized learning and optimization rely on local updates coupled with the exchange of compressed signals. In this context, differential quantization is an effective technique to mitigate the negative impact of compression by leveraging correlations between successive iterates. In addition, the use of error feedback, which consists of incorporating the compression error into subsequent steps, is a powerful mechanism to compensate for the bias caused by the compression. Under error feedback, performance guarantees in the literature have so far focused on algorithms employing a fusion center or a special class of contractive compressors that cannot be implemented with a finite number of bits. In this work, we propose a new decentralized communication-efficient learning approach that blends differential quantization with error feedback. The approach is specifically tailored for decentralized learning problems where agents have individual risk functions to minimize subject to subspace constraints that require the minimizers across the network to lie in low-dimensional subspaces. This constrained formulation includes consensus or single-task optimization as special cases, and allows for more general task relatedness models such as multitask smoothness and coupled optimization. We show that, under some general conditions on the compression noise, and for sufficiently small step-sizes $\mu$, the resulting communication-efficient strategy is stable both in terms of mean-square error and average bit rate: by reducing $\mu$, it is possible to keep the estimation errors small (on the order of $\mu$) without increasing indefinitely the bit rate as $\mu\rightarrow 0$. The results establish that, in the small step-size regime and with a finite number of bits, it is possible to attain the performance achievable in the absence of compression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18418v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roula Nassif, Stefan Vlaski, Marco Carpentiero, Vincenzo Matta, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Optimal Signal Processing for Common Randomness Generation over MIMO Gaussian Channels with Applications in Identification</title>
      <link>https://arxiv.org/abs/2011.05929</link>
      <description>arXiv:2011.05929v2 Announce Type: replace 
Abstract: Common randomness (CR), as a resource, is not commonly exploited in existing practical communication systems. In the CR generation framework, both the sender and receiver aim to generate a common random variable observable to both, ideally with low error probability. The availability of this CR allows us to implement correlated random protocols that can lead to faster and more efficient algorithms. Previous work focused on CR generation over perfect channels with limited capacity. In our work, we consider the problem of CR generation from independent and identically distributed (i.i.d.) samples of a correlated finite source with one-way communication over a Gaussian channel. We first derive the CR capacity for single-input single-output (SISO) Gaussian channels. This result is then used for the derivation of the CR capacity in the multiple-input multiple-output (MIMO) case. CR plays a key role in the identification scheme since it may allow a significant increase in the identification capacity of channels. In the identification framework, the decoder is interested in knowing \emph{whether} a specific message of special interest to him has been sent or not, rather than knowing \emph{what} the received message is. In many new applications, such as several machine-to-machine and human-to-machine systems and the tactile internet, this post-Shannon scheme is more efficient than classical transmission. In our work, we also consider a CR-assisted secure identification scheme and develop a lower bound on the corresponding secure identification capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.05929v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Ezzine, Wafa Labidi, Christian Deppe, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Secure Identification for Gaussian Channels and Identification for Multi-Antenna Gaussian Channels</title>
      <link>https://arxiv.org/abs/2011.06443</link>
      <description>arXiv:2011.06443v2 Announce Type: replace 
Abstract: New applications in modern communications are demanding robust and ultra-reliable low latency information exchange such as machine-to-machine and human-to-machine communications. For many of these applications, the identification approach of Ahlswede and Dueck is much more efficient than the classical message transmission scheme proposed by Shannon. Previous studies concentrate mainly on identification over discrete channels. For discrete channels, it was proved that identification is robust under channels uncertainty. Furthermore, optimal identification schemes that are secure and robust against jamming attacks have been considered. However, no results for continuous channels have yet been established. That is why we focus on the continuous case: the Gaussian channel for its known practical relevance. We deal with secure identification over Gaussian channels. Provable secure communication is of a high interest for future communication systems. A key technique for implementing secure communication is the physical layer security based on information theoretic security. We model this with the wiretap channel. In particular, we provide a suitable coding scheme for the Gaussian wiretap channel (GWC) and determine the corresponding secure identification capacity. We also consider Multiple-Input Multiple-Output (MIMO) Gaussian channels and provide an efficient signal-processing scheme. This scheme allows a separation of signal-processing and Gaussian coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2011.06443v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wafa Labidi, Christian Deppe, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Towards Synthesizing Twelve-Lead Electrocardiograms from Two Asynchronous Leads</title>
      <link>https://arxiv.org/abs/2103.00006</link>
      <description>arXiv:2103.00006v4 Announce Type: replace 
Abstract: The electrocardiogram (ECG) records electrical signals in a non-invasive way to observe the condition of the heart, typically looking at the heart from 12 different directions. Several types of the cardiac disease are diagnosed by using 12-lead ECGs Recently, various wearable devices have enabled immediate access to the ECG without the use of wieldy equipment. However, they only provide ECGs with a couple of leads. This results in an inaccurate diagnosis of cardiac disease due to lacking of required leads. We propose a deep generative model for ECG synthesis from two asynchronous leads to ten leads. It first represents a heart condition referring to two leads, and then generates ten leads based on the represented heart condition. Both the rhythm and amplitude of leads generated resemble those of the original ones, while the technique removes noise and the baseline wander appearing in the original leads. As a data augmentation method, our model improves the classification performance of models compared with models using ECGs with only one or two leads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.00006v4</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong-Yeon Jo, Young Sang Choi, Jong-Hwan Jang, Joon-Myoung Kwon</dc:creator>
    </item>
    <item>
      <title>Few-Shot Recognition and Classification Framework for Jamming Signal: A CGAN-Based Fusion CNN Approach</title>
      <link>https://arxiv.org/abs/2311.05273</link>
      <description>arXiv:2311.05273v3 Announce Type: replace 
Abstract: Subject to intricate environmental variables, the precise classification of jamming signals holds paramount significance in the effective implementation of anti-jamming strategies within communication systems. In light of this imperative, we propose an innovative fusion algorithm based on conditional generative adversarial network (CGAN) and convolutional neural network (CNN), which aims to deal with the difficulty in applying deep learning (DL) algorithms due to the instantaneous nature of jamming signals in practical communication systems. Compared with previous methods, our algorithm embeds jamming category labels to constrain the range of generated signals in the frequency domain by using the CGAN model, which simultaneously captures potential label information while learning the distribution of signal data thus achieves an 8% improvement in accuracy even when working with a few-sample dataset. Real-world satellite communication scenarios are simulated by adopting hardware platform, and we validate our algorithm by using the resulting time-domain waveform data. The experimental results indicate that our algorithm still performs extremely well, which demonstrates significant potential for practical application in real-world communication scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05273v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuhui Ding, Yue Zhang, Gaoyang Li, Xiaozheng Gao, Neng Ye, Dusit Niyato, Kai Yang</dc:creator>
    </item>
    <item>
      <title>Proactive Blockage Prediction for UAV assisted Handover in Future Wireless Network</title>
      <link>https://arxiv.org/abs/2402.04332</link>
      <description>arXiv:2402.04332v2 Announce Type: replace 
Abstract: The future wireless communication applications demand seamless connectivity, higher throughput, and low latency, for which the millimeter-wave (mmWave) band is considered a potential technology. Nevertheless, line-of-sight (LoS) is often mandatory for mmWave band communication, and it renders these waves sensitive to sudden changes in the environment. Therefore, it is necessary to maintain the LoS link for a reliable connection. One such technique to maintain LoS is using proactive handover (HO). However, proactive HO is challenging, requiring continuous information about the surrounding wireless network to anticipate potential blockage. This paper presents a proactive blockage prediction mechanism where an unmanned aerial vehicle (UAV) is used as the base station for HO. The proposed scheme uses computer vision (CV) to obtain potential blocking objects, user speed, and location. To assess the effectiveness of the proposed scheme, the system is evaluated using a publicly available dataset for blockage prediction. The study integrates scenarios from Vision-based Wireless (ViWi) and UAV channel modeling, generating wireless data samples relevant to UAVs. The antenna modeling on the UAV end incorporates a polarization-matched scenario to optimize signal reception. The results demonstrate that UAV-assisted Handover not only ensures seamless connectivity but also enhances overall network performance by 20%. This research contributes to the advancement of proactive blockage mitigation strategies in wireless networks, showcasing the potential of UAVs as dynamic and adaptable base stations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04332v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iftikhar Ahmad, Ahsan Raza Khan, Abdul Jabbar, Muhammad Alquraan, Lina Mohjazi, Masood Ur Rehman, Muhammad Ali Imran, Ahmed Zoha, Sajjad Hussain</dc:creator>
    </item>
    <item>
      <title>WhaleNet: a Novel Deep Learning Architecture for Marine Mammals Vocalizations on Watkins Marine Mammal Sound Database</title>
      <link>https://arxiv.org/abs/2402.17775</link>
      <description>arXiv:2402.17775v2 Announce Type: replace 
Abstract: Marine mammal communication is a complex field, hindered by the diversity of vocalizations and environmental factors. The Watkins Marine Mammal Sound Database (WMMD) constitutes a comprehensive labeled dataset employed in machine learning applications. Nevertheless, the methodologies for data preparation, preprocessing, and classification documented in the literature exhibit considerable variability and are typically not applied to the dataset in its entirety. This study initially undertakes a concise review of the state-of-the-art benchmarks pertaining to the dataset, with a particular focus on clarifying data preparation and preprocessing techniques. Subsequently, we explore the utilization of the Wavelet Scattering Transform (WST) and Mel spectrogram as preprocessing mechanisms for feature extraction. In this paper, we introduce \textbf{WhaleNet} (Wavelet Highly Adaptive Learning Ensemble Network), a sophisticated deep ensemble architecture for the classification of marine mammal vocalizations, leveraging both WST and Mel spectrogram for enhanced feature discrimination. By integrating the insights derived from WST and Mel representations, we achieved an improvement in classification accuracy by $8-10\%$ over existing architectures, corresponding to a classification accuracy of $97.61\%$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17775v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Licciardi (Politecnico di Torino, Istituto Nazionale di Fisica Nucleare Sezione di Torino), Davide Carbone (Politecnico di Torino, Istituto Nazionale di Fisica Nucleare Sezione di Torino)</dc:creator>
    </item>
    <item>
      <title>Joint Power Allocation and Beamforming Design for Active IRS-Aided Directional Modulation Secure Systems</title>
      <link>https://arxiv.org/abs/2406.09192</link>
      <description>arXiv:2406.09192v2 Announce Type: replace 
Abstract: Since the secrecy rate (SR) performance improvement obtained by secure directional modulation (DM) network is limited, an active intelligent reflective surface (IRS)-assisted DM network is considered to attain a high SR. To address the SR maximization problem, a novel method based on Lagrangian dual transform and closed-form fractional programming algorithm (LDT-CFFP) is proposed, where the solutions to base station (BS) beamforming vectors and IRS reflection coefficient matrix are achieved. However, the computational complexity of LDT-CFFP method is high . To reduce its complexity, a blocked IRS-assisted DM network is designed. To meet the requirements of the network performance, a power allocation (PA) strategy is proposed and adopted in the system. Specifically, the system power between BS and IRS, as well as the transmission power for confidential messages (CM) and artificial noise (AN) from the BS, are allocated separately. Then we put forward null-space projection (NSP) method, maximum-ratio-reflecting (MRR) algorithm and PA strategy (NSP-MRR-PA) to solve the SR maximization problem. The CF solutions to BS beamforming vectors and IRS reflection coefficient matrix are respectively attained via NSP and MRR algorithms. For the PA factors, we take advantage of exhaustive search (ES) algorithm, particle swarm optimization (PSO) and simulated annealing (SA) algorithm to search for the solutions. From simulation results, it is verified that the LDT-CFFP method derives a higher SR gain over NSP-MRR-PA method. For NSP-MRR-PA method, the number of IRS units in each block possesses a significant SR performance. In addition, the application PA strategies, namely ES, PSO, SA methods outperforms the other PA strategies with fixed PA factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09192v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Zhao, Xiaoyu Wang, Kaibo Zhou, Xuehui Wang, Yan Wang, Wei Gao, Ruiqi Liu, Feng Shu</dc:creator>
    </item>
    <item>
      <title>ECGrecover: a Deep Learning Approach for Electrocardiogram Signal Completion</title>
      <link>https://arxiv.org/abs/2406.16901</link>
      <description>arXiv:2406.16901v2 Announce Type: replace 
Abstract: In this work, we address the challenge of reconstructing the complete 12-lead ECG signal from incomplete parts of it. We focus on two main scenarii: (i) reconstructing missing signal segments within an ECG lead and (ii) recovering missing leads from a single-lead. We propose a model with a U-Net architecture trained on a novel objective function to address the reconstruction problem. This function incorporates both spatial and temporal aspects of the ECG by combining the distance in amplitude between the reconstructed and real signals with the signal trend. Through comprehensive assessments using both a real-life dataset and a publicly accessible one, we demonstrate that the proposed approach consistently outperforms state-of-the-art methods based on generative adversarial networks and a CopyPaste strategy. Our proposed model demonstrates superior performance in standard distortion metrics and preserves critical ECG characteristics, particularly the P, Q, R, S, and T wave coordinates. Two emerging clinical applications emphasize the relevance of our work. The first is the increasing need to digitize paper-stored ECGs for utilization in AI-based applications (automatic annotation and risk-quantification), often limited to digital ECG complete 10s recordings. The second is the widespread use of wearable devices that record ECGs but typically capture only a small subset of the 12 standard leads. In both cases, a non-negligible amount of information is lost or not recorded, which our approach aims to recover to overcome these limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16901v2</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Lence, Ahmad Fall, Federica Granese, Blaise Hanczar, Joe-Elie Salem, Jean-Daniel Zucker, Edi Prifti</dc:creator>
    </item>
    <item>
      <title>Benchmarking mortality risk prediction from electrocardiograms</title>
      <link>https://arxiv.org/abs/2406.17002</link>
      <description>arXiv:2406.17002v2 Announce Type: replace 
Abstract: Several recent high-impact studies leverage large hospital-owned electrocardiographic (ECG) databases to model and predict patient mortality. MIMIC-IV, released September 2023, is the first comparable public dataset and includes 800,000 ECGs from a U.S. hospital system. Previously, the largest public ECG dataset was Code-15, containing 345,000 ECGs collected during routine care in Brazil. These datasets now provide an excellent resource for a broader audience to explore ECG survival modeling. Here, we benchmark survival model performance on Code-15 and MIMIC-IV with two neural network architectures, compare four deep survival modeling approaches to Cox regressions trained on classifier outputs, and evaluate performance at one to ten years. Our results yield AUROC and concordance scores comparable to past work (circa 0.8) and reasonable AUPRC scores (MIMIC-IV: 0.4-0.5, Code-15: 0.05-0.13) considering the fraction of ECG samples linked to a mortality (MIMIC-IV: 27\%, Code-15: 4\%). When evaluating models on the opposite dataset, AUROC and concordance values drop by 0.1-0.15, which may be due to cohort differences. All code and results are made public.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17002v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Platon Lukyanenko, Joshua Mayourian, Mingxuan Liu, John K. Triedman, Sunil J. Ghelani, William G. La Cava</dc:creator>
    </item>
    <item>
      <title>Design Space Exploration for Particle Detector Read-out Implementations in Matlab and Simulink on the Example of the SHiP SBT</title>
      <link>https://arxiv.org/abs/2402.03122</link>
      <description>arXiv:2402.03122v3 Announce Type: replace-cross 
Abstract: On a very fundamental level, particle detectors share similar requirements for their read-out chain. This is reflected in the way that typical read-out solutions are developed, where a previous design is taken and modified to fit some changes in requirements. One of the two common approaches is the current-based read-out, where the waveform of the sensor output is sampled in order to later extract information from there. This approach is used in many detector applications using scintillation based detectors, including PET. With this contribution, we will introduce how we use Matlab in order to simulate the read-out electronics of particle detectors. We developed this simulation approach as a base for our ongoing development of software-defined read-out ASICs that cover the requirements of a variety of particle detector types. Simulink was chosen as a base for our developments as it allows simulation of mixed-signal systems and comes with built-in toolkits to aid in developments of such systems. With our approach, we want to take a new look at how we approach designing such a read-out, with a focus on digital signal processing close to the sensor, making use of known signal characteristics and modern methods of communications engineering. We are taking into account the time profile of an event, the bandwidth-limiting properties of the sensor and attached electronics, digitization stages and finally the parameterization of approaches for digital processing of the signal. We will show how we are applying the design approach to the development of a read-out for the proposed SHiP SBT detector, which is a scintillation based detector relying on SiPMs sensors, using this as an example for our modelling approach and show preliminary results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03122v3</guid>
      <category>physics.ins-det</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian R\"ossing, David Arutinov, Alessia Brignoli, Horst Fischer, Christian Grewing, Heiko Lacker, Fairhurst Lyons, Andr\'e Zambanini, Stefan van Waasen</dc:creator>
    </item>
    <item>
      <title>Listening to the Noise: Blind Denoising with Gibbs Diffusion</title>
      <link>https://arxiv.org/abs/2402.19455</link>
      <description>arXiv:2402.19455v2 Announce Type: replace-cross 
Abstract: In recent years, denoising problems have become intertwined with the development of deep generative models. In particular, diffusion models are trained like denoisers, and the distribution they model coincide with denoising priors in the Bayesian picture. However, denoising through diffusion-based posterior sampling requires the noise level and covariance to be known, preventing blind denoising. We overcome this limitation by introducing Gibbs Diffusion (GDiff), a general methodology addressing posterior sampling of both the signal and the noise parameters. Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional diffusion model trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters. Our theoretical analysis highlights potential pitfalls, guides diagnostic usage, and quantifies errors in the Gibbs stationary distribution caused by the diffusion model. We showcase our method for 1) blind denoising of natural images involving colored noises with unknown amplitude and spectral index, and 2) a cosmology problem, namely the analysis of cosmic microwave background data, where Bayesian inference of "noise" parameters means constraining models of the evolution of the Universe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19455v2</guid>
      <category>stat.ML</category>
      <category>astro-ph.CO</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Heurtel-Depeiges, Charles C. Margossian, Ruben Ohana, Bruno R\'egaldo-Saint Blancard</dc:creator>
    </item>
    <item>
      <title>Towards Task-Compatible Compressible Representations</title>
      <link>https://arxiv.org/abs/2405.10244</link>
      <description>arXiv:2405.10244v2 Announce Type: replace-cross 
Abstract: We identify an issue in multi-task learnable compression, in which a representation learned for one task does not positively contribute to the rate-distortion performance of a different task as much as expected, given the estimated amount of information available in it. We interpret this issue using the predictive $\mathcal{V}$-information framework. In learnable scalable coding, previous work increased the utilization of side-information for input reconstruction by also rewarding input reconstruction when learning this shared representation. We evaluate the impact of this idea in the context of input reconstruction more rigorously and extended it to other computer vision tasks. We perform experiments using representations trained for object detection on COCO 2017 and depth estimation on the Cityscapes dataset, and use them to assist in image reconstruction and semantic segmentation tasks. The results show considerable improvements in the rate-distortion performance of the assisted tasks. Moreover, using the proposed representations, the performance of the base tasks are also improved. Results suggest that the proposed method induces simpler representations that are more compatible with downstream processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10244v2</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anderson de Andrade, Ivan Baji\'c</dc:creator>
    </item>
  </channel>
</rss>
