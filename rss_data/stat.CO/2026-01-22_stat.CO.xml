<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Jan 2026 02:37:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Semi-Supervised Mixture Models under the Concept of Missing at Radom with Margin Confidence and Aranda Ordaz Function</title>
      <link>https://arxiv.org/abs/2601.14631</link>
      <description>arXiv:2601.14631v1 Announce Type: cross 
Abstract: This paper presents a semi-supervised learning framework for Gaussian mixture modelling under a Missing at Random (MAR) mechanism. The method explicitly parameterizes the missingness mechanism by modelling the probability of missingness as a function of classification uncertainty. To quantify classification uncertainty, we introduce margin confidence and incorporate the Aranda Ordaz (AO) link function to flexibly capture the asymmetric relationships between uncertainty and missing probability. Based on this formulation, we develop an efficient Expectation Conditional Maximization (ECM) algorithm that jointly estimates all parameters appearing in both the Gaussian mixture model (GMM) and the missingness mechanism, and subsequently imputes the missing labels by a Bayesian classifier derived from the fitted mixture model. This method effectively alleviates the bias induced by ignoring the missingness mechanism while enhancing the robustness of semi-supervised learning. The resulting uncertainty-aware framework delivers reliable classification performance in realistic MAR scenarios with substantial proportions of missing labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14631v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinyang Liao, Ziyang Lyu</dc:creator>
    </item>
    <item>
      <title>Physical Layer Security in Massive MIMO: Challenges and Open Research Directions Against Passive Eavesdroppers</title>
      <link>https://arxiv.org/abs/2601.15024</link>
      <description>arXiv:2601.15024v1 Announce Type: cross 
Abstract: Massive Multiple-Input Multiple-Output (MIMO) has become a crucial enabling technology for 5G and beyond, providing previously unheard-of increases in energy and spectrum efficiency. It is still difficult to guarantee secure communication in these systems, particularly when it comes to passive eavesdroppers whose base station is unaware of their channel state information. By taking advantage of the inherent randomness of wireless channels, Physical Layer Security (PLS) offers a promising paradigm; however, its efficacy in massive MIMO is heavily reliant on resource allocation and transmission strategies. In this work, the performance of secure transmission schemes, such as Maximum Ratio Transmission (MRT), Zero-Forcing (ZF), and Artificial Noise (AN)-aided beamforming, is examined when passive eavesdroppers are present. This work will use extensive Monte Carlo simulations to assess important performance metrics such as energy efficiency, secrecy outage probability, and secrecy sum rate under different system parameters (e.g., number of antennas, Signal-to-Noise Ratio (SNR), power allocation). The results aim to provide comparative insight into the strengths and limitations of different PLS strategies and to highlight open research directions to design scalable, energy-efficient, and robust secure transmission techniques in future 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15024v1</guid>
      <category>eess.SP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nipun Agarwal</dc:creator>
    </item>
    <item>
      <title>On the unconventional Hug integrator</title>
      <link>https://arxiv.org/abs/2502.10199</link>
      <description>arXiv:2502.10199v2 Announce Type: replace-cross 
Abstract: Hug is a recently proposed iterative mapping used to design efficient updates in Markov chain Monte Carlo (MCMC) methods. Hug generates proposals that remain very close to hypersurfaces (level sets) of constant probabilty density. We analyse a generalization of Hug from hypersurfaces to manifolds of arbitrary dimensions, not necessarily arising in a sampling context. The analysis is based on interpreting, in a nonstandard way, Hug as a consistent discretization of a system of differential equations with a rather complicated structure. The proof of convergence of this discretization includes a number of unusual features we explore fully, in particular a supraconvergence property is established, whereby second order of convergence is attained with consistency of the first order. We uncover and discuss an unexpected property of the solutions of the underlying dynamical system that manifest itself by the existence of Hug trajectories that fail to cover the manifold of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10199v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christophe Andrieu, J. M. Sanz-Serna</dc:creator>
    </item>
    <item>
      <title>BlockingPy: approximate nearest neighbours for blocking of records for entity resolution</title>
      <link>https://arxiv.org/abs/2504.04266</link>
      <description>arXiv:2504.04266v4 Announce Type: replace-cross 
Abstract: Entity resolution (probabilistic record linkage, deduplication) is a key step in scientific analysis and data science pipelines involving multiple data sources. The objective of entity resolution is to link records without common unique identifiers that refer to the same entity (e.g., person, company). However, without identifiers, researchers need to specify which records to compare in order to calculate matching probability and reduce computational complexity. One solution is to deterministically block records based on some common variables, such as names, dates of birth or sex or use phonetic algorithms. However, this approach assumes that these variables are free of errors and completely observed, which is often not the case. To address this challenge, we have developed a Python package, BlockingPy, which uses blocking using modern approximate nearest neighbour search and graph algorithms to reduce the number of comparisons. The package supports both CPU and GPU execution. In this paper, we present the design of the package, its functionalities and two case studies related to official statistics. The presented software will be useful for researchers interested in linking data from various sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04266v4</guid>
      <category>stat.AP</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tymoteusz Strojny, Maciej Ber\k{e}sewicz</dc:creator>
    </item>
    <item>
      <title>AI-boosted rare event sampling to characterize extreme weather</title>
      <link>https://arxiv.org/abs/2510.27066</link>
      <description>arXiv:2510.27066v2 Announce Type: replace-cross 
Abstract: Weather extremes pose major societal risks, especially in a changing climate, but due to their rarity, they are difficult to study using limited observations or complex climate models. We introduce AI+RES, a framework coupling fast AI weather forecasts with a high-fidelity physics model using a rare-event algorithm to efficiently characterize extremes. This approach enables the study of the statistics and physics of very rare events, such as once per millennium heatwaves at two orders-of-magnitude lower computational cost. AI+RES can be applied broadly across climate science and other fields concerned with rare events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27066v2</guid>
      <category>physics.ao-ph</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amaury Lancelin, Alex Wikner, Laurent Dubus, Cl\'ement Le Priol, Dorian S. Abbot, Freddy Bouchet, Pedram Hassanzadeh, Jonathan Weare</dc:creator>
    </item>
  </channel>
</rss>
