<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Cautions on Tail Index Regressions</title>
      <link>https://arxiv.org/abs/2510.01535</link>
      <description>arXiv:2510.01535v1 Announce Type: new 
Abstract: We revisit tail-index regressions. For linear specifications, we find that the usual full-rank condition can fail because conditioning on extreme outcomes causes regressors to degenerate to constants. More generally, the conditional distribution of the covariates in the tails concentrates on the values at which the tail index is minimized. Away from those points, the conditional density tends to zero. For local nonparametric tail index regression, the convergence rate can be very slow. We conclude with practical suggestions for applied work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01535v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thomas T. Yang</dc:creator>
    </item>
    <item>
      <title>Weak Identification with Bounds in a Class of Minimum Distance Models</title>
      <link>https://arxiv.org/abs/2012.11222</link>
      <description>arXiv:2012.11222v5 Announce Type: replace 
Abstract: When parameters are weakly identified, bounds on the parameters may provide a valuable source of information. Existing weak identification estimation and inference results are unable to combine weak identification with bounds. Within a class of minimum distance models, this paper proposes identification-robust inference that incorporates information from bounds when parameters are weakly identified. This paper demonstrates the value of the bounds and identification-robust inference in a simple latent factor model and a simple GARCH model. This paper also demonstrates the identification-robust inference in an empirical application, a factor model for parental investments in children.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.11222v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Fletcher Cox</dc:creator>
    </item>
    <item>
      <title>Smooth Tests for Normality in ANOVA</title>
      <link>https://arxiv.org/abs/2110.04849</link>
      <description>arXiv:2110.04849v3 Announce Type: replace 
Abstract: The normality assumption for random errors is fundamental in the analysis of variance (ANOVA) models, yet it is seldom subjected to formal testing in practice. In this paper, we develop Neyman's smooth tests for assessing normality in a broad class of ANOVA models. The proposed test statistics are constructed via the Gaussian probability integral transformation of ANOVA residuals and are shown to follow an asymptotic Chi-square distribution under the null hypothesis, with degrees of freedom determined by the dimension of the smooth model. We further propose a data-driven selection of the model dimension based on a modified Schwarz's criterion. Monte Carlo simulations demonstrate that the tests maintain the nominal size and achieve high power against a wide range of alternatives. Our framework thus provides a systematic and effective tool for formally validating the normality assumption in ANOVA models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.04849v3</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peiwen Jia, Xiaojun Song, Haoyu Wei</dc:creator>
    </item>
    <item>
      <title>Synthetic Blips: Generalizing Synthetic Controls for Dynamic Treatment Effects</title>
      <link>https://arxiv.org/abs/2210.11003</link>
      <description>arXiv:2210.11003v2 Announce Type: replace 
Abstract: We propose a generalization of the synthetic control and interventions methods to the setting with dynamic treatment effects. We consider the estimation of unit-specific treatment effects from panel data collected under a general treatment sequence. Here, each unit receives multiple treatments sequentially, according to an adaptive policy that depends on a latent, endogenously time-varying confounding state. Under a low-rank latent factor model assumption, we develop an identification strategy for any unit-specific mean outcome under any sequence of interventions. The latent factor model we propose admits linear time-varying and time-invariant dynamical systems as special cases. Our approach can be viewed as an identification strategy for structural nested mean models -- a widely used framework for dynamic treatment effects -- under a low-rank latent factor assumption on the blip effects. Unlike these models, however, it is more permissive in observational settings, thereby broadening its applicability. Our method, which we term synthetic blip effects, is a backwards induction process in which the blip effect of a treatment at each period and for a target unit is recursively expressed as a linear combination of the blip effects of a group of other units that received the designated treatment. This strategy avoids the combinatorial explosion in the number of units that would otherwise be required by a naive application of prior synthetic control and intervention methods in dynamic treatment settings. We provide estimation algorithms that are easy to implement in practice and yield estimators with desirable properties. Using unique Korean firm-level panel data, we demonstrate how the proposed framework can be used to estimate individualized dynamic treatment effects and to derive optimal treatment allocation rules in the context of financial support for exporting firms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11003v2</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anish Agarwal, Sukjin Han, Dwaipayan Saha, Vasilis Syrgkanis, Haeyeon Yoon</dc:creator>
    </item>
    <item>
      <title>Partial Identification of Structural Vector Autoregressions with Non-Centred Stochastic Volatility</title>
      <link>https://arxiv.org/abs/2404.11057</link>
      <description>arXiv:2404.11057v2 Announce Type: replace 
Abstract: We consider structural vector autoregressions that are identified through stochastic volatility under Bayesian estimation. Three contributions emerge from our exercise. First, we show that a non-centred parameterization of stochastic volatility yields a marginal prior for the conditional variances of structural shocks that is centred on homoskedasticity, with strong shrinkage and heavy tails -- unlike the common centred parameterization. This feature makes it well suited for assessing partial identification of any shock of interest. Second, Monte Carlo experiments on small and large systems indicate that the non-centred setup estimates structural parameters more precisely and normalizes conditional variances efficiently. Third, revisiting prominent fiscal structural vector autoregressions, we show how the non-centred approach identifies tax shocks that are consistent with estimates reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11057v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Helmut L\"utkepohl (Freie Universit\"at Berlin and DIW Berlin), Fei Shang (South China University of Technology and Yuexiu Capital Holdings Group), Luis Uzeda (Bank of Canada), Tomasz Wo\'zniak (University of Melbourne)</dc:creator>
    </item>
    <item>
      <title>Nonlinear Forecast Error Variance Decompositions with Hermite Polynomials</title>
      <link>https://arxiv.org/abs/2503.11416</link>
      <description>arXiv:2503.11416v2 Announce Type: replace 
Abstract: A novel approach to Forecast Error Variance Decompositions (FEVD) in nonlinear Structural Vector Autoregressive models with Gaussian innovations is proposed, called the Hermite FEVD (HFEVD). This method employs a Hermite polynomial expansion to approximate the future trajectory of a nonlinear process. The orthogonality of Hermite polynomials under the Gaussian density facilitates the construction of the decomposition, providing a separation of shock effects by time horizon, by components of the structural innovation and by degree of nonlinearity. A link between the HFEVD and nonlinear Impulse Response Functions is established and distinguishes between marginal and interaction contributions of shocks. Simulation results from standard nonlinear models are provided as illustrations and an application to fiscal policy shocks is examined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11416v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quinlan Lee</dc:creator>
    </item>
    <item>
      <title>Partial Identification in Moment Models with Incomplete Data--A Conditional Optimal Transport Approach</title>
      <link>https://arxiv.org/abs/2503.16098</link>
      <description>arXiv:2503.16098v2 Announce Type: replace 
Abstract: In this paper, we develop a unified approach to study partial identification of a finite-dimensional parameter defined by a general moment model with incomplete data. We establish a novel characterization of the identified set for the true parameter in terms of a continuum of inequalities defined by conditional optimal transport. For the special case of an affine moment model, we show that the identified set is convex and that its support function can be easily computed by solving a conditional optimal transport problem. For parameters that may not satisfy the moment model, we propose a two-step procedure to construct its identified set. Finally, we demonstrate the generality and effectiveness of our approach through several running examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16098v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yanqin Fan, Hyeonseok Park, Brendan Pass, Xuetao Shi</dc:creator>
    </item>
    <item>
      <title>Breakdown Analysis for Instrumental Variables with Binary Outcomes</title>
      <link>https://arxiv.org/abs/2507.10242</link>
      <description>arXiv:2507.10242v4 Announce Type: replace 
Abstract: This paper studies the partial identification of treatment effects in Instrumental Variables (IV) settings with binary outcomes under violations of independence. I derive the identified sets for the treatment parameters of interest in the setting, as well as breakdown values for conclusions regarding the true treatment effects. I derive $\sqrt{N}$-consistent nonparametric estimators for the bounds of treatment effects and for breakdown values. These results can be used to assess the robustness of empirical conclusions obtained under the assumption that the instrument is independent from potential quantities, which is a pervasive concern in studies that use IV methods with observational data. In the empirical application, I show that the conclusions regarding the effects of family size on female unemployment using same-sex siblings as the instrument are highly sensitive to violations of independence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10242v4</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Picchetti</dc:creator>
    </item>
    <item>
      <title>Policy-Oriented Binary Classification: Improving (KD-)CART Final Splits for Subpopulation Targeting</title>
      <link>https://arxiv.org/abs/2502.15072</link>
      <description>arXiv:2502.15072v2 Announce Type: replace-cross 
Abstract: Policymakers often use recursive binary split rules to partition populations based on binary outcomes and target subpopulations whose probability of the binary event exceeds a threshold. We call such problems Latent Probability Classification (LPC). Practitioners typically employ Classification and Regression Trees (CART) for LPC. We prove that in the context of LPC, classic CART and the knowledge distillation method, whose student model is a CART (referred to as KD-CART), are suboptimal. We propose Maximizing Distance Final Split (MDFS), which generates split rules that strictly dominate CART/KD-CART under the unique intersect assumption. MDFS identifies the unique best split rule, is consistent, and targets more vulnerable subpopulations than CART/KD-CART. To relax the unique intersect assumption, we additionally propose Penalized Final Split (PFS) and weighted Empirical risk Final Split (wEFS). Through extensive simulation studies, we demonstrate that the proposed methods predominantly outperform CART/KD-CART. When applied to real-world datasets, MDFS generates policies that target more vulnerable subpopulations than the CART/KD-CART.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15072v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lei Bill Wang, Zhenbang Jiao, Fangyi Wang</dc:creator>
    </item>
    <item>
      <title>Online Multivariate Regularized Distributional Regression for High-dimensional Probabilistic Electricity Price Forecasting</title>
      <link>https://arxiv.org/abs/2504.02518</link>
      <description>arXiv:2504.02518v2 Announce Type: replace-cross 
Abstract: Probabilistic electricity price forecasting (PEPF) is vital for short-term electricity markets, yet the multivariate nature of day-ahead prices - spanning 24 consecutive hours - remains underexplored. At the same time, real-time decision-making requires methods that are both accurate and fast. We introduce an online algorithm for multivariate distributional regression models, allowing an efficient modelling of the conditional means, variances, and dependence structures of electricity prices. The approach combines multivariate distributional regression with online coordinate descent and LASSO-type regularization, enabling scalable estimation in high-dimensional covariate spaces. Additionally, we propose a regularized estimation path over increasingly complex dependence structures, allowing for early stopping and avoiding overfitting. In a case study of the German day-ahead market, our method outperforms a wide range of benchmarks, showing that modeling dependence improves both calibration and predictive accuracy. Furthermore, we analyse the trade-off between predictive accuracy and computational costs for batch and online estimation and provide an high-performing open-source Python implementation in the ondil package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02518v2</guid>
      <category>stat.ML</category>
      <category>econ.EM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Hirsch</dc:creator>
    </item>
  </channel>
</rss>
