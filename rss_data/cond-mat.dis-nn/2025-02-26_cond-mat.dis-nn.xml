<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Feb 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exact mobility edges in quasiperiodic network models with slowly varying potentials</title>
      <link>https://arxiv.org/abs/2502.17876</link>
      <description>arXiv:2502.17876v1 Announce Type: new 
Abstract: Quasiperiodic potentials without self-duality are always hard to derive the exact mobility edges (MEs). Here, we propose a new class of network models with exactly solvable MEs, characterized by quasiperiodic slowly varying potentials that do not exhibit hidden self-duality. We present two methods to derive the MEs, the first involves integrating out the periodic sites to obtain an effective Hamiltonian with effective potential $g(E)V$ and effective eigenenergy $f(E)$, which directly yields the MEs at $f(E) = \pm(2t\pm g(E)V)$, and the second is to connect the localized-delocalized transition points of the quasiperiodic slowly varying models and the real-complex transition points of the eigenvalue equations. To illustrate this, we take quasiperiodic mosaic slowly varying models as examples, and we find that the MEs obtained from the two methods are the same. Furthermore, we generalize our methods to quasiperiodic network models and propose a possible experimental realization based on optical waveguide systems, showing that the Anderson transition can be observed even using small physical systems (with $L = 50 - 100$). Our results may provide insight into understanding and realizing exact MEs in experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17876v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hai-Tao Hu, Yang Chen, Xiaoshui Lin, Ai-Min Guo, Guangcan Guo, Ming Gong, Zijing Lin</dc:creator>
    </item>
    <item>
      <title>Higher-order contagion processes in 1.99 dimensions</title>
      <link>https://arxiv.org/abs/2502.18004</link>
      <description>arXiv:2502.18004v1 Announce Type: cross 
Abstract: Higher-order interactions have recently emerged as a promising framework for describing new dynamical phenomena in heterogeneous contagion processes. However, a fundamental open question is how to understand their contribution in the eyes of the physics of critical phenomena. Based on mesoscopic field-theoretic Langevin descriptions, we show that: (i) pairwise mechanisms as facilitation or thresholding are formally equivalent to higher-order ones, (ii) pairwise interactions at coarse-grained scales govern the higher-order contact process and, (iii) classical Imry-Ma arguments hold for networks with low spectral dimension. In short, we demonstrate that classical field theories, grounded on model symmetries and/or network dimensionality, still capture the nature of the phase transition, also predicting finite-size effects in real and synthetic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18004v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandro Melon, Andrea Gabrielli, Pablo Villegas</dc:creator>
    </item>
    <item>
      <title>Persistent Homology for Structural Characterization in Disordered Systems</title>
      <link>https://arxiv.org/abs/2411.14390</link>
      <description>arXiv:2411.14390v5 Announce Type: replace 
Abstract: We propose a unified framework based on persistent homology (PH) to characterize both local and global structures in disordered systems. It can simultaneously generate local and global descriptors using the same algorithm and data structure, and has shown to be highly effective and interpretable in predicting particle rearrangements and classifying global phases. We also demonstrated that using a single variable enables a linear SVM to achieve nearly perfect three-phase classification. Inspired by this discovery, we define a non-parametric metric, the Separation Index (SI), which not only achieves this classification without sacrificing significant performance but also establishes a connection between particle environments and the global phase structure. Our methods provide an effective framework for understanding and analyzing the properties of disordered materials, with broad potential applications in materials science and even wider studies of complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14390v5</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>An Wang, Li Zou</dc:creator>
    </item>
    <item>
      <title>Sparse Edge Encoder (SEE): I. Visual recognition in neuronal networks</title>
      <link>https://arxiv.org/abs/2211.15278</link>
      <description>arXiv:2211.15278v2 Announce Type: replace-cross 
Abstract: In the past few decades, there have been intense debates whether the brain operates at a critical state. To verify the criticality hypothesis in the neuronal networks is challenging and the accumulating experimental and theoretical results remain controversial at this point. Here we simulate how visual information of a nature image is processed by the finite Kinouchi-Copelli neuronal network, extracting the trends of the mutual information (how sensible the neuronal network is), the dynamical range (how sensitive the network responds to external stimuli) and the statistical fluctuations (how criticality is defined in conventional statistical physics). It is rather remarkable that the optimized state for visual recognition, although close to, does not coincide with the critical state where the statistical fluctuations reach the maximum. Different images and/or network sizes of course lead to differences in details but the trend of the information optimization remains the same. Our findings pave the first step to investigate how the information processing is optimized in different neuronal networks and suggest that the criticality hypothesis may not be necessary to explain why a neuronal network can process information smartly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.15278v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chia-Ying Lin, Mei Ian Sam, Yi-Ching Tsai, Hsiu-Hau Lin</dc:creator>
    </item>
    <item>
      <title>Stability-Aware Training of Machine Learning Force Fields with Differentiable Boltzmann Estimators</title>
      <link>https://arxiv.org/abs/2402.13984</link>
      <description>arXiv:2402.13984v3 Announce Type: replace-cross 
Abstract: Machine learning force fields (MLFFs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations, limiting their ability to model phenomena occurring over longer timescales and compromising the quality of estimated observables. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which leverages joint supervision from reference quantum-mechanical calculations and system observables. StABlE Training iteratively runs many MD simulations in parallel to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. We achieve efficient end-to-end automatic differentiation through MD simulations using our Boltzmann Estimator, a generalization of implicit differentiation techniques to a broader class of stochastic algorithms. Unlike existing techniques based on active learning, our approach requires no additional ab-initio energy and forces calculations to correct instabilities. We demonstrate our methodology across organic molecules, tetrapeptides, and condensed phase systems, using three modern MLFF architectures. StABlE-trained models achieve significant improvements in simulation stability, data efficiency, and agreement with reference observables. The stability improvements cannot be matched by reducing the simulation timestep; thus, StABlE Training effectively allows for larger timesteps. By incorporating observables into the training process alongside first-principles calculations, StABlE Training can be viewed as a general semi-empirical framework applicable across MLFF architectures and systems. This makes it a powerful tool for training stable and accurate MLFFs, particularly in the absence of large reference datasets. Our code is available at https://github.com/ASK-Berkeley/StABlE-Training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13984v3</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2025</arxiv:journal_reference>
      <dc:creator>Sanjeev Raja, Ishan Amin, Fabian Pedregosa, Aditi S. Krishnapriyan</dc:creator>
    </item>
  </channel>
</rss>
