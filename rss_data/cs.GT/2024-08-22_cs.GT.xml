<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Aug 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Swim till You Sink: Computing the Limit of a Game</title>
      <link>https://arxiv.org/abs/2408.11146</link>
      <description>arXiv:2408.11146v1 Announce Type: new 
Abstract: During 2023, two interesting results were proven about the limit behavior of game dynamics: First, it was shown that there is a game for which no dynamics converges to the Nash equilibria. Second, it was shown that the sink equilibria of a game adequately capture the limit behavior of natural game dynamics. These two results have created a need and opportunity to articulate a principled computational theory of the meaning of the game that is based on game dynamics. Given any game in normal form, and any prior distribution of play, we study the problem of computing the asymptotic behavior of a class of natural dynamics called the noisy replicator dynamics as a limit distribution over the sink equilibria of the game. When the prior distribution has pure strategy support, we prove this distribution can be computed efficiently, in near-linear time to the size of the best-response graph. When the distribution can be sampled -- for example, if it is the uniform distribution over all mixed strategy profiles -- we show through experiments that the limit distribution of reasonably large games can be estimated quite accurately through sampling and simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11146v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashida Hakim, Jason Milionis, Christos Papadimitriou, Georgios Piliouras</dc:creator>
    </item>
    <item>
      <title>Optimal Guarantees for Online Selection Over Time</title>
      <link>https://arxiv.org/abs/2408.11224</link>
      <description>arXiv:2408.11224v1 Announce Type: new 
Abstract: Prophet inequalities are a cornerstone in optimal stopping and online decision-making. Traditionally, they involve the sequential observation of $n$ non-negative independent random variables and face irrevocable accept-or-reject choices. The goal is to provide policies that provide a good approximation ratio against the optimal offline solution that can access all the values upfront -- the so-called prophet value. In the prophet inequality over time problem (POT), the decision-maker can commit to an accepted value for $\tau$ units of time, during which no new values can be accepted. This creates a trade-off between the duration of commitment and the opportunity to capture potentially higher future values.
  In this work, we provide best possible worst-case approximation ratios in the IID setting of POT for single-threshold algorithms and the optimal dynamic programming policy. We show a single-threshold algorithm that achieves an approximation ratio of $(1+e^{-2})/2\approx 0.567$, and we prove that no single-threshold algorithm can surpass this guarantee. With our techniques, we can analyze simple algorithms using $k$ thresholds and show that with $k=3$ it is possible to get an approximation ratio larger than $\approx 0.602$. Then, for each $n$, we prove it is possible to compute the tight worst-case approximation ratio of the optimal dynamic programming policy for instances with $n$ values by solving a convex optimization program. A limit analysis of the first-order optimality conditions yields a nonlinear differential equation showing that the optimal dynamic programming policy's asymptotic worst-case approximation ratio is $\approx 0.618$. Finally, we extend the discussion to adversarial settings and show an optimal worst-case approximation ratio of $\approx 0.162$ when the values are streamed in random order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11224v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Perez-Salazar, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>MEV Capture and Decentralization in Execution Tickets</title>
      <link>https://arxiv.org/abs/2408.11255</link>
      <description>arXiv:2408.11255v1 Announce Type: new 
Abstract: We provide an economic model of Execution Tickets and use it to study the ability of the Ethereum protocol to capture MEV from block construction. We demonstrate that Execution Tickets extract all MEV when all buyers are homogeneous, risk neutral and face no capital costs. We also show that MEV capture decreases with risk aversion and capital costs. Moreover, when buyers are heterogeneous, MEV capture can be especially low and a single dominant buyer can extract much of the MEV. This adverse effect can be partially mitigated by the presence of a Proposer Builder Separation (PBS) mechanism, which gives ET buyers access to a market of specialized builders, but in practice centralization vectors still persist. With PBS, ETs are concentrated among those with the highest ex-ante MEV extraction ability and lowest cost of capital. We show how it is possible that large investors that are not builders but have substantial advantage in capital cost can come to dominate the ET market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11255v1</guid>
      <category>cs.GT</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonah Burian, Davide Crapis, Fahad Saleh</dc:creator>
    </item>
    <item>
      <title>Satisfaction and Regret in Stackelberg Games</title>
      <link>https://arxiv.org/abs/2408.11340</link>
      <description>arXiv:2408.11340v1 Announce Type: new 
Abstract: This paper introduces the new concept of (follower) satisfaction in Stackelberg games and compares the standard Stackelberg game with its satisfaction version. Simulation results are presented which suggest that the follower adopting satisfaction generally increases leader utility. This important new result is proven for the case where leader strategies to commit to are restricted to be deterministic (pure strategies). The paper then addresses the application of regret based algorithms to the Stackelberg problem. Although it is known that the follower adopts a no-regret position in a Stackelberg solution, this is not generally the case for the leader. The report examines the convergence behaviour of unconditional and conditional regret matching (RM) algorithms in the Stackelberg setting. The paper shows that, in the examples considered, that these algorithms either converge to any pure Nash equilibria for the simultaneous move game, or to some mixed strategies which do not have the "no-regret" property. In one case, convergence of the conditional RM algorithm over both players to a solution "close" to the Stackelberg case was observed. The paper argues that further research in this area, in particular when applied in the satisfaction setting could be fruitful.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11340v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Langford White, Duong Nguyen, Hung Nguyen</dc:creator>
    </item>
    <item>
      <title>Technical Report: Coopetition in Heterogeneous Cross-Silo Federated Learning</title>
      <link>https://arxiv.org/abs/2408.11355</link>
      <description>arXiv:2408.11355v1 Announce Type: new 
Abstract: In cross-silo federated learning (FL), companies collaboratively train a shared global model without sharing heterogeneous data. Prior related work focused on algorithm development to tackle data heterogeneity. However, the dual problem of coopetition, i.e., FL collaboration and market competition, remains under-explored. This paper studies the FL coopetition using a dynamic two-period game model. In period 1, an incumbent company trains a local model and provides model-based services at a chosen price to users. In period 2, an entrant company enters, and both companies decide whether to engage in FL collaboration and then compete in selling model-based services at different prices to users. Analyzing the two-period game is challenging due to data heterogeneity, and that the incumbent's period one pricing has a temporal impact on coopetition in period 2, resulting in a non-concave problem. To address this issue, we decompose the problem into several concave sub-problems and develop an algorithm that achieves a global optimum. Numerical results on three public datasets show two interesting insights. First, FL training brings model performance gain as well as competition loss, and collaboration occurs only when the performance gain outweighs the loss. Second, data heterogeneity can incentivize the incumbent to limit market penetration in period 1 and promote price competition in period 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11355v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Huang, Justin Dachille, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Verifying Approximate Equilibrium in Auctions</title>
      <link>https://arxiv.org/abs/2408.11445</link>
      <description>arXiv:2408.11445v1 Announce Type: new 
Abstract: In practice, most auction mechanisms are not strategy-proof, so equilibrium analysis is required to predict bidding behavior. In many auctions, though, an exact equilibrium is not known and one would like to understand whether -- manually or computationally generated -- bidding strategies constitute an approximate equilibrium. We develop a framework and methods for estimating the distance of a strategy profile from equilibrium, based on samples from the prior and either bidding strategies or sample bids. We estimate an agent's utility gain from deviating to strategies from a constructed finite subset of the strategy space. We use PAC-learning to give error bounds, both for independent and interdependent prior distributions. The primary challenge is that one may miss large utility gains by considering only a finite subset of the strategy space. Our work differs from prior research in two critical ways. First, we explore the impact of bidding strategies on altering opponents' perceived prior distributions -- instead of assuming the other agents to bid truthfully. Second, we delve into reasoning with interdependent priors, where the type of one agent may imply a distinct distribution for other agents. Our main contribution lies in establishing sufficient conditions for strategy profiles and a closeness criterion for conditional distributions to ensure that utility gains estimated through our finite subset closely approximate the maximum gains. To our knowledge, ours is the first method to verify approximate equilibrium in any auctions beyond single-item ones. Also, ours is the first sample-based method for approximate equilibrium verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11445v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian R. Pieroth, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Individually Stable Dynamics in Coalition Formation over Graphs</title>
      <link>https://arxiv.org/abs/2408.11488</link>
      <description>arXiv:2408.11488v1 Announce Type: new 
Abstract: Coalition formation over graphs is a well studied class of games whose players are vertices and feasible coalitions must be connected subgraphs.  In this setting, the existence and computation of equilibria, under various notions of stability, has attracted a lot of attention. However, the natural process by which players, starting from any feasible state, strive to reach an equilibrium after a series of unilateral improving deviations, has been less studied. We investigate the convergence of dynamics towards individually stable outcomes under the following perspective: what are the most general classes of preferences and graph topologies guaranteeing convergence? To this aim, on the one hand, we cover a hierarchy of preferences, ranging from the most general to a subcase of additively separable preferences, including individually rational and monotone cases. On the other hand, given that convergence may fail in graphs admitting a cycle even in our most restrictive preference class, we analyze acyclic graph topologies such as trees, paths, and stars.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11488v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Angelo Fanelli (LAMSADE), Laurent Gourv\`es (LAMSADE), Ayumi Igarashi (UTokyo), Luca Moscardelli (Ud'A)</dc:creator>
    </item>
    <item>
      <title>Minimizing Rosenthal's Potential in Monotone Congestion Games</title>
      <link>https://arxiv.org/abs/2408.11489</link>
      <description>arXiv:2408.11489v1 Announce Type: new 
Abstract: Congestion games are attractive  because they can model many concrete situations where some competing entities interact through the use of some shared resources, and also because they always admit pure Nash equilibria which correspond to the local minima of a potential function. We explore the problem of computing a state of minimum potential in this setting. Using the maximum number of resources that a player can use at a time, and the possible symmetry in the players' strategy spaces, we settle the complexity of the problem for instances  having monotone (i.e., either non-decreasing or non-increasing) latency functions on their resources. The picture, delineating polynomial and NP-hard cases, is complemented with tight approximation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11489v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vittorio Bil\`o (LAMSADE), Angelo Fanelli (LAMSADE), Laurent Gourv\`es (LAMSADE), Christos Tsoufis (LAMSADE), Cosimo Vinci</dc:creator>
    </item>
    <item>
      <title>Von Neumann's minimax theorem through Fourier-Motzkin elimination</title>
      <link>https://arxiv.org/abs/2408.11504</link>
      <description>arXiv:2408.11504v1 Announce Type: new 
Abstract: Fourier-Motzkin elimination, a standard method for solving systems of linear inequalities, leads to an elementary, short, and self-contained proof of von Neumann's minimax theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11504v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Voorneveld</dc:creator>
    </item>
    <item>
      <title>On the Distortion of Committee Election with 1-Euclidean Preferences and Few Distance Queries</title>
      <link>https://arxiv.org/abs/2408.11755</link>
      <description>arXiv:2408.11755v1 Announce Type: new 
Abstract: We consider committee election of $k \geq 3$ (out of $m \geq k+1$) candidates, where the voters and the candidates are associated with locations on the real line. Each voter's cardinal preferences over candidates correspond to her distance to the candidate locations, and each voter's cardinal preferences over committees is defined as her distance to the nearest candidate elected in the committee. We consider a setting where the true distances and the locations are unknown. We can nevertheless have access to degraded information which consists of an order of candidates for each voter. We investigate the best possible distortion (a worst-case performance criterion) wrt. the social cost achieved by deterministic committee election rules based on ordinal preferences submitted by $n$ voters and few additional distance queries. We show that for any $k \geq 3$, the best possible distortion of any deterministic algorithm that uses at most $k-3$ distance queries cannot be bounded by any function of $n$, $m$ and $k$. We present deterministic algorithms for $k$-committee election with distortion of $O(n)$ with $O(k)$ distance queries and $O(1)$ with $O(k \log n)$ distance queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11755v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Fotakis, Laurent Gourv\`es, Panagiotis Patsilinakos</dc:creator>
    </item>
    <item>
      <title>Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</title>
      <link>https://arxiv.org/abs/2408.11607</link>
      <description>arXiv:2408.11607v1 Announce Type: cross 
Abstract: Recent works have provided algorithms by which decentralised agents, which may be connected via a communication network, can learn equilibria in Mean-Field Games from a single, non-episodic run of the empirical system. However, these algorithms are given for tabular settings: this computationally limits the size of players' observation space, meaning that the algorithms are not able to handle anything but small state spaces, nor to generalise beyond policies depending on the ego player's state to so-called 'population-dependent' policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the population's mean-field distribution in the observation for each player's policy, it is arguably unrealistic to assume that decentralised agents would have access to this global information: we therefore additionally provide new algorithms that allow agents to estimate the global empirical distribution based on a local neighbourhood, and to improve this estimate via communication over a given network. Our experiments showcase how the communication network allows decentralised agents to estimate the mean-field distribution for population-dependent policies, and that exchanging policy information helps networked agents to outperform both independent and even centralised agents in function-approximation settings, by an even greater margin than in tabular settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11607v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Benjamin, Alessandro Abate</dc:creator>
    </item>
    <item>
      <title>$\alpha$-Rank-Collections: Analyzing Expected Strategic Behavior with Uncertain Utilities</title>
      <link>https://arxiv.org/abs/2211.10317</link>
      <description>arXiv:2211.10317v4 Announce Type: replace 
Abstract: Game theory relies heavily on the availability of cardinal utility functions, but in fields such as matching markets, only ordinal preferences are typically elicited. The literature focuses on mechanisms with simple dominant strategies, but many real-world applications lack dominant strategies, making the intensity of preferences between outcomes important for determining strategies. Even though precise information about cardinal utilities is not available, some data about the likelihood of utility functions is often accessible. We propose to use Bayesian games to formalize uncertainty about the decision-makers' utilities by viewing them as a collection of normal-form games. Instead of searching for the Bayes-Nash equilibrium, we study how uncertainty in utilities is reflected in uncertainty of strategic play. To do this, we introduce a novel solution concept called $\alpha$-Rank-collections, which extends $\alpha$-Rank to Bayesian games. This allows us to analyze strategic play in, for example, non-strategyproof matching markets, for which appropriate solution concepts are currently lacking. $\alpha$-Rank-collections characterize the expected probability of encountering a certain strategy profile under replicator dynamics in the long run, rather than predicting a specific equilibrium strategy profile. We experimentally evaluate $\alpha$-Rank-collections using instances of the Boston mechanism, finding that our solution concept provides more nuanced predictions compared to Bayes-Nash equilibria. Additionally, we prove that $\alpha$-Rank-collections are invariant to positive affine transformations, a standard property for a solution concept, and are efficient to approximate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.10317v4</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian R. Pieroth, Martin Bichler</dc:creator>
    </item>
    <item>
      <title>Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models</title>
      <link>https://arxiv.org/abs/2408.05241</link>
      <description>arXiv:2408.05241v3 Announce Type: replace-cross 
Abstract: As the performance of larger, newer Large Language Models continues to improve for strategic Theory of Mind (ToM) tasks, the demand for these state-of-the-art models increases commensurately. However, their deployment is costly both in terms of processing power and time. In this paper, we investigate the feasibility of creating smaller, highly-performing specialized algorithms by way of fine-tuning. To do this, we first present a large pre-trained model with 20 unique scenarios that combine different social contexts with games of varying social dilemmas, record its answers, and use them for Q&amp;A fine-tuning on a smaller model of the same family. Our focus is on in-context game-theoretic decision-making, the same domain within which human interaction occurs and that requires both a theory of mind (or a semblance thereof) and an understanding of social dynamics. The smaller model is therefore trained not just on the answers provided, but also on the motivations provided by the larger model, which should contain advice and guidelines to navigate both strategic dilemmas and social cues. We find that the fine-tuned smaller language model consistently bridged the gap in performance between the smaller pre-trained version of the model and its larger relative and that its improvements extended in areas and contexts beyond the ones provided in the training examples, including on out-of-sample scenarios that include completely different game structures. On average for all games, through fine-tuning, the smaller model showed a 46% improvement measured as alignment towards the behavior of the larger model, with 100% representing indistinguishable behavior. When presented with out-of-sample social contexts and games, the fine-tuned model still displays remarkable levels of alignment, reaching an improvement of 18% and 28% respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05241v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nunzio Lore, Alireza Sepehr Ilami, Babak Heydari</dc:creator>
    </item>
  </channel>
</rss>
