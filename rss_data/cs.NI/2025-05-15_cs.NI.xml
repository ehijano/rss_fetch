<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 May 2025 01:29:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Entanglement Generation for Quantum Routing</title>
      <link>https://arxiv.org/abs/2505.08958</link>
      <description>arXiv:2505.08958v1 Announce Type: new 
Abstract: Entanglement generation in long-distance quantum networks is a difficult process due to resource limitations and the probabilistic nature of entanglement swapping. To maximize success probability, existing quantum routing algorithms employ computationally expensive solutions (e.g., linear programming) to determine which links to entangle and use for end-to-end entanglement generation. Such optimization methods, however, cannot meet the delay requirements of real-world quantum networks, necessitating swift yet efficient real-time optimization models. In this paper, we propose reinforcement learning (RL)-based models to determine which links to entangle and proactively swap to meet connection requests. We show that the proposed RL-based approach is 20x faster compared to linear programming. Moreover, we show that one can take advantage of the longevity of entanglements to (i) cache entangled links for future use and (ii) proactively swap entanglement on high-demand path segments, thereby increasing the likelihood of request success. Through comprehensive simulations, we demonstrate that caching unused entanglements leads to a 10-15% improvement in the performance of state-of-the-art quantum routing algorithms. Complementing caching with proactive entanglement swapping further enhances the request success rate by up to 52.55%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08958v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tasdiqul Islam, Md Arifuzzaman, Engin Arslan</dc:creator>
    </item>
    <item>
      <title>QUIC Steps: Evaluating Pacing Strategies in QUIC Implementations</title>
      <link>https://arxiv.org/abs/2505.09222</link>
      <description>arXiv:2505.09222v1 Announce Type: new 
Abstract: Pacing is a key mechanism in modern transport protocols, used to regulate packet transmission timing to minimize traffic burstiness, lower latency, and reduce packet loss. Standardized in 2021, QUIC is a UDP-based protocol designed to improve upon the TCP / TLS stack. While the QUIC protocol recommends pacing, and congestion control algorithms like BBR rely on it, the user-space nature of QUIC introduces unique challenges. These challenges include coarse-grained timers, system call overhead, and OS scheduling delays, all of which complicate precise packet pacing. This paper investigates how pacing is implemented differently across QUIC stacks, including quiche, picoquic, and ngtcp2, and evaluates the impact of system-level features like GSO and Linux qdiscs on pacing. Using a custom measurement framework and a passive optical fiber tap, we establish a baseline with default settings and systematically explore the effects of qdiscs, hardware offloading using the ETF qdisc, and GSO on pacing precision and network performance. We also extend and evaluate a kernel patch to enable pacing of individual packets within GSO buffers, combining batching efficiency with precise pacing. Kernel-assisted and purely user-space pacing approaches are compared. We show that pacing with only user-space timers can work well, as demonstrated by picoquic with BBR. With quiche, we identify FQ as a qdisc well-suited for pacing QUIC traffic, as it is relatively easy to use and offers precise pacing based on packet timestamps. Our findings provide new insights into the trade-offs involved in implementing pacing in QUIC and highlight potential optimizations for real-world applications like video streaming and video calls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09222v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3730985</arxiv:DOI>
      <dc:creator>Marcel Kempf, Simon Tietz, Benedikt Jaeger, Johannes Sp\"ath, Georg Carle, Johannes Zirngibl</dc:creator>
    </item>
    <item>
      <title>Interplay Between AI and Space-Air-Ground Integrated Network: The Road Ahead</title>
      <link>https://arxiv.org/abs/2505.09259</link>
      <description>arXiv:2505.09259v1 Announce Type: new 
Abstract: Space-air-ground integrated network (SAGIN) is envisioned as a key network architecture for achieving ubiquitous coverage in the next-generation communication system. Concurrently, artificial intelligence (AI) plays a pivotal role in managing the complex control of SAGIN, thereby enhancing its automation and flexibility. Despite this, there remains a significant research gap concerning the interaction between AI and SAGIN. In this context, we first present a promising approach for developing a generalized AI model capable of executing multiple tasks simultaneously in SAGIN. Subsequently, we propose a framework that leverages software-defined networking (SDN) and AI technologies to manage the resources and services across the entire SAGIN. Particularly, we demonstrate the real-world applicability of our proposed framework through a comprehensive case study. These works pave the way for the deep integration of SAGIN and AI in future wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09259v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Wu, Xi Wang, Yi Hu, Shuai Han, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>RAG-Enabled Intent Reasoning for Application-Network Interaction</title>
      <link>https://arxiv.org/abs/2505.09339</link>
      <description>arXiv:2505.09339v1 Announce Type: new 
Abstract: Intent-based network (IBN) is a promising solution to automate network operation and management. IBN aims to offer human-tailored network interaction, allowing the network to communicate in a way that aligns with the network users' language, rather than requiring the network users to understand the technical language of the network/devices. Nowadays, different applications interact with the network, each with its own specialized needs and domain language. Creating semantic languages (i.e., ontology-based languages) and associating them with each application to facilitate intent translation lacks technical expertise and is neither practical nor scalable. To tackle the aforementioned problem, we propose a context-aware AI framework that utilizes machine reasoning (MR), retrieval augmented generation (RAG), and generative AI technologies to interpret intents from different applications and generate structured network intents. The proposed framework allows for generalized/domain-specific intent expression and overcomes the drawbacks of large language models (LLMs) and vanilla-RAG framework. The experimental results show that our proposed intent-RAG framework outperforms the LLM and vanilla-RAG framework in intent translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09339v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salwa Mostafa, Mohamed K. Abdel-Aziz, Mohammed S. Elbamby, Mehdi Bennis</dc:creator>
    </item>
    <item>
      <title>Instant AoI Optimization through Relay Location Selection in Disaster Multi-hop Communication</title>
      <link>https://arxiv.org/abs/2505.09386</link>
      <description>arXiv:2505.09386v1 Announce Type: new 
Abstract: Meteorological disasters such as typhoons, forest fires, and floods can damage the communication infrastructures, which will further disable the communication capabilities of cellular networks. The multi-hop wireless communication based on IoT devices (e.g., rescue robots, UAVs, and mobile devices) becomes an available and rapidly deployable communication approach for search and rescue operations. However, Age of Information (AoI), an emerging network performance metric, has not been comprehensively investigated in this multi-hop model. In this paper, we first construct a UAV-relayed wireless network model and formulate the end-to-end instant AoI. Then we derive the optimal location of the relay UAV to achieve the minimum instant AoI by mathematical analysis. Simulations show that the derived relay location can always guarantee the optimal AoI and outperform other schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09386v1</guid>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Gao, Zezhi Zeng</dc:creator>
    </item>
    <item>
      <title>Wormhole Detection Based on Z-Score And Neighbor Table Comparison</title>
      <link>https://arxiv.org/abs/2505.09405</link>
      <description>arXiv:2505.09405v1 Announce Type: new 
Abstract: Wormhole attacks can cause serious disruptions to the network topology in disaster rescue opportunity networks.
  By establishing false Wormhole(WH) links, malicious nodes can mislead legitimate paths in the network, further causing serious consequences such as traffic analysis attacks (i.e., by eavesdropping and monitoring exchanged traffic), denial of service (DoS) or selective packet loss attacks. This paper uses rescue equipment (vehicle-mounted base stations, rescue control centers, etc.) as an effective third-party auditor (TPA), and combines the commonly used Z-Score (Standard Score) data processing method to propose a new detection method based on pure mathematical statistics for detecting wormhole attacks. Finally, we perform a large number of simulations to evaluate the proposed method. Since our proposed strategy does not require auxiliary equipment such as GPS positioning and timers, as a pure data statistical analysis method, it is obviously more economically valuable, feasible, and practical than other strategies in disaster relief.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09405v1</guid>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zezhi Zeng</dc:creator>
    </item>
    <item>
      <title>Dimensioning and Optimization of Reliability Coverage in Local 6G Networks</title>
      <link>https://arxiv.org/abs/2505.09440</link>
      <description>arXiv:2505.09440v1 Announce Type: new 
Abstract: Enabling vertical use cases for the sixth generation (6G) wireless networks, such as automated manufacturing, immersive extended reality (XR), and self-driving fleets, will require network designs that meet reliability and latency targets in well-defined service areas. In order to establish a quantifiable design objective, we introduce the novel concept of reliability coverage, defined as the percentage area covered by communication services operating under well-defined reliability and performance targets. Reliability coverage allows us to unify the different network design tasks occurring at different time scales, namely resource orchestration and allocation, resulting in a single framework for dimensioning and optimization in local 6G networks. The two time scales, when considered together, yield remarkably consistent results and allow us to observe how stringent reliability/latency requirements translate into the increased wireless network resource demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09440v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacek Kibi{\l}da, Dian Echevarr\'ia P\'erez, Andr\'e Gomes, Onel L. Alcaraz L\'opez, Arthur S. de Sena, Nurul Huda Mahmood, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.08837</link>
      <description>arXiv:2505.08837v1 Announce Type: cross 
Abstract: The security of cloud environments, such as Amazon Web Services (AWS), is complex and dynamic. Static security policies have become inadequate as threats evolve and cloud resources exhibit elasticity [1]. This paper addresses the limitations of static policies by proposing a security policy management framework that uses reinforcement learning (RL) to adapt dynamically. Specifically, we employ deep reinforcement learning algorithms, including deep Q Networks and proximal policy optimization, enabling the learning and continuous adjustment of controls such as firewall rules and Identity and Access Management (IAM) policies. The proposed RL based solution leverages cloud telemetry data (AWS Cloud Trail logs, network traffic data, threat intelligence feeds) to continuously refine security policies, maximizing threat mitigation, and compliance while minimizing resource impact. Experimental results demonstrate that our adaptive RL based framework significantly outperforms static policies, achieving higher intrusion detection rates (92% compared to 82% for static policies) and substantially reducing incident detection and response times by 58%. In addition, it maintains high conformity with security requirements and efficient resource usage. These findings validate the effectiveness of adaptive reinforcement learning approaches in improving cloud security policy management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08837v1</guid>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Saqib, Dipkumar Mehta, Fnu Yashu, Shubham Malhotra</dc:creator>
    </item>
    <item>
      <title>Toward Accessible and Safe Live Streaming Using Distributed Content Filtering with MoQ</title>
      <link>https://arxiv.org/abs/2505.08990</link>
      <description>arXiv:2505.08990v1 Announce Type: cross 
Abstract: Live video streaming is increasingly popular on social media platforms. With the growth of live streaming comes an increased need for robust content moderation to remove dangerous, illegal, or otherwise objectionable content. Whereas video on demand distribution enables offline content analysis, live streaming imposes restrictions on latency for both analysis and distribution. In this paper, we present extensions to the in-progress Media Over QUIC Transport protocol that enable real-time content moderation in one-to-many video live streams. Importantly, our solution removes only the video segments that contain objectionable content, allowing playback resumption as soon as the stream conforms to content policies again. Content analysis tasks may be transparently distributed to arbitrary client devices. We implement and evaluate our system in the context of light strobe removal for photosensitive viewers, finding that streaming clients experience an increased latency of only one group-of-pictures duration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08990v1</guid>
      <category>cs.MM</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew C. Freeman</dc:creator>
    </item>
    <item>
      <title>DNS Query Forgery: A Client-Side Defense Against Mobile App Traffic Profiling</title>
      <link>https://arxiv.org/abs/2505.09374</link>
      <description>arXiv:2505.09374v1 Announce Type: cross 
Abstract: Mobile applications continuously generate DNS queries that can reveal sensitive user behavioral patterns even when communications are encrypted. This paper presents a privacy enhancement framework based on query forgery to protect users against profiling attempts that leverage these background communications. We first mathematically model user profiles as probability distributions over interest categories derived from mobile application traffic. We then evaluate three query forgery strategies -- uniform sampling, TrackMeNot-based generation, and an optimized approach that minimizes Kullback-Leibler divergence -- to quantify their effectiveness in obfuscating user profiles. Then we create a synthetic dataset comprising 1,000 user traces constructed from real mobile application traffic and we extract the user profiles based on DNS traffic. Our evaluation reveals that a 50\% privacy improvement is achievable with less than 20\% traffic overhead when using our approach, while achieving 100\% privacy protection requires approximately 40-60\% additional traffic. We further propose a modular system architecture for practical implementation of our protection mechanisms on mobile devices. This work offers a client-side privacy solution that operates without third-party trust requirements, empowering individual users to defend against traffic analysis without compromising application functionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09374v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Jimenez-Berenguel, C\'esar Gil, Carlos Garcia-Rubio, Jordi Forn\'e, Celeste Campo</dc:creator>
    </item>
    <item>
      <title>MDTP -- An Adaptive Multi-Source Data Transfer Protocol</title>
      <link>https://arxiv.org/abs/2505.09597</link>
      <description>arXiv:2505.09597v1 Announce Type: cross 
Abstract: Scientific data volume is growing in size, and as a direct result, the need for faster transfers is also increasing. The scientific community has sought to leverage parallel transfer methods using multi-threaded and multi-source download models to reduce download times. In multi-source transfers, a client downloads data from multiple replicated servers in parallel. Tools such as Aria2 and BitTorrent support such multi-source transfers and have shown improved transfer times.
  In this work, we introduce Multi-Source Data Transfer Protocol, MDTP, which further improves multi-source transfer performance. MDTP logically divides a file request into smaller chunk requests and distributes the chunk requests across multiple servers. Chunk sizes are adapted based on each server's performance but selected in a way that ensures each round of requests completes around the same time. We formulate this chunk-size allocation problem as a variant of the bin-packing problem, where adaptive chunking efficiently fills the available capacity "bins" corresponding to each server.
  Our evaluation shows that MDTP reduces transfer times by 10-22% compared to Aria2, the fastest alternative. Comparisons with other protocols, such as static chunking and BitTorrent, demonstrate even greater improvements. Additionally, we show that MDTP distributes load proportionally across all available replicas, not just the fastest ones, which improves throughput. Finally, we show MDTP maintains high throughput even when latency increases or bandwidth to the fastest server decreases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09597v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sepideh Abdollah, Craig Partridge, Susmit Shannigrahi</dc:creator>
    </item>
    <item>
      <title>A Quick Primer on Machine Learning in Wireless Communications</title>
      <link>https://arxiv.org/abs/2312.17713</link>
      <description>arXiv:2312.17713v5 Announce Type: replace 
Abstract: This is our final issue of the quick primer on the use of Python to build a wireless communications prototype. This prototype simulates multiple-input and multiple-output (MIMO) systems for a single orthogonal frequency division multiplexing (OFDM) symbol. Further, it shows several artificial intelligence (AI) and machine learning (ML) use cases and introduces the deepwireless library for code implementation. The intent of this primer is to empower the reader with the means to efficiently create reproducible simulations related to AI and ML in wireless communications on inexpensive computing devices. This primer has sprung from a draft aligned with the syllabus of a graduate course (EESC 7v86) -- which we created to be first taught in Fall 2022 -- and has since evolved to where it stands today.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17713v5</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faris B. Mismar</dc:creator>
    </item>
    <item>
      <title>Edge-Disjoint Spanning Trees on Star-Product Networks</title>
      <link>https://arxiv.org/abs/2403.12231</link>
      <description>arXiv:2403.12231v2 Announce Type: replace 
Abstract: A star-product operation may be used to create large graphs from smaller factor graphs. Network topologies based on star-products demonstrate several advantages including low-diameter, high scalability, modularity and others. Many state-of-the-art diameter-2 and -3 topologies~(Slim Fly, Bundlefly, PolarStar etc.) can be represented as star products.
  In this paper, we explore constructions of edge-disjoint spanning trees~(EDSTs) in star-product topologies. EDSTs expose multiple parallel disjoint pathways in the network and can be leveraged to accelerate collective communication, enhance fault tolerance and network recovery, and manage congestion.
  Our EDSTs have provably maximum or near-maximum cardinality which amplifies their benefits. We further analyze their depths and show that for one of our constructions, all trees have order of the depth of the EDSTs of the factor graphs, and for all other constructions, a large subset of the trees have that depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12231v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>math.CO</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kelly Isham, Laura Monroe, Kartik Lakhotia, Aleyah Dawkins, Daniel Hwang, Ales Kubicek</dc:creator>
    </item>
    <item>
      <title>Distributing Intelligence in 6G Programmable Data Planes for Effective In-Network Intrusion Prevention</title>
      <link>https://arxiv.org/abs/2410.24013</link>
      <description>arXiv:2410.24013v3 Announce Type: replace 
Abstract: The problem of attacks on new generation network infrastructures is becoming increasingly relevant, given the widening of the attack surface of these networks resulting from the greater number of devices that will access them in the future (sensors, actuators, vehicles, household appliances, etc.). Approaches to the design of intrusion detection systems must evolve and go beyond the traditional concept of perimeter control to build on new paradigms that exploit the typical characteristics of future 5G and 6G networks, such as in-network computing and intelligent programmable data planes. The aim of this research is to propose a disruptive paradigm in which devices in a typical data plane of a future programmable network have anomaly detection capabilities and cooperate in a fully distributed fashion to act as an ML-enabled Intrusion Prevention System ``embedded" into the network. The reported proof-of-concept experiments demonstrate that the proposed paradigm allows working effectively and with a good level of precision while occupying overall less CPU and RAM resources of the devices involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24013v3</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.2025.3544828</arxiv:DOI>
      <arxiv:journal_reference>IEEE Network, vol. 39, no. 3, 26 Feb. 2025, pp. 319-25</arxiv:journal_reference>
      <dc:creator>Mattia G. Spina, Floriano De Rango, Edoardo Scalzo, Francesca Guerriero, Antonio Iera</dc:creator>
    </item>
    <item>
      <title>Goal-Oriented Random Access (GORA)</title>
      <link>https://arxiv.org/abs/2503.03291</link>
      <description>arXiv:2503.03291v2 Announce Type: replace 
Abstract: We propose Goal-Oriented Random Access (GORA), where transmitters jointly optimize what to send and when to access the shared channel to a common access point, considering the ultimate goal of the information transfer at its final destination. This goal is captured by an objective function, which is expressed as a general (not necessarily monotonic) function of the Age of Information. Our findings reveal that, under certain conditions, it may be desirable for transmitters to delay channel access intentionally and, when accessing the channel, transmit aged samples to reach a specific goal at the receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03291v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2025.3567862</arxiv:DOI>
      <dc:creator>Ahsen Topbas, Cagri Ari, Onur Kaya, Elif Uysal</dc:creator>
    </item>
    <item>
      <title>Intelligent Product 3.0: Decentralised AI Agents and Web3 Intelligence Standards</title>
      <link>https://arxiv.org/abs/2505.07835</link>
      <description>arXiv:2505.07835v2 Announce Type: replace 
Abstract: Twenty-five years ago, the specification of the Intelligent Product was established, envisaging real-time connectivity that not only enables products to gather accurate data about themselves but also allows them to assess and influence their own destiny. Early work by the Auto-ID project focused on creating a single, open-standard repository for storing and retrieving product information, laying a foundation for scalable connectivity. A decade later, the approach was revisited in light of low-cost RFID systems that promised a low-cost link between physical goods and networked information environments. Since then, advances in blockchain, Web3, and artificial intelligence have introduced unprecedented levels of resilience, consensus, and autonomy. By leveraging decentralised identity, blockchain-based product information and history, and intelligent AI-to-AI collaboration, this paper examines these developments and outlines a new specification for the Intelligent Product 3.0, illustrating how decentralised and AI-driven capabilities facilitate seamless interaction between physical AI and everyday products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07835v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex C. Y. Wong, Duncan McFarlane, C. Ellarby, M. Lee, M. Kuok</dc:creator>
    </item>
    <item>
      <title>Design and Operation of Shared Machine Learning Clusters on Campus</title>
      <link>https://arxiv.org/abs/2110.01556</link>
      <description>arXiv:2110.01556v2 Announce Type: replace-cross 
Abstract: Amid the rapid advancements in large machine learning (ML) models, universities worldwide are investing substantial funds and efforts into GPU clusters. However, managing a shared GPU cluster poses a pyramid of challenges, from hardware configuration to resource allocation among users.
  This paper introduces SING, a full-stack solution designed to streamline the management of shared GPU clusters in academic institutions. Motivated by the pressing need for efficient resource sharing and the challenges posed by limited staffing, we present a comprehensive view of SING's architecture and design choices, which achieves operational efficiency (i.e., low maintenance cost and high resource utilization). We also share experience and insights from the real-world operations of SING, including analysis of its usage patterns and management of incidents and failures.
  This paper is part of our ongoing effort to improve the management of shared ML clusters. We open-source relevant resources to facilitate the development and operation of similar clusters for ML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.01556v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3669940.3707266</arxiv:DOI>
      <dc:creator>Kaiqiang Xu, Decang Sun, Hao Wang, Zhenghang Ren, Xinchen Wan, Xudong Liao, Zilong Wang, Junxue Zhang, Kai Chen</dc:creator>
    </item>
  </channel>
</rss>
