<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 01:36:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Prompting the Professoriate: A Qualitative Study of Instructor Perspectives on LLMs in Data Science Education</title>
      <link>https://arxiv.org/abs/2509.12283</link>
      <description>arXiv:2509.12283v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shifted in just a few years from novelty to ubiquity, raising fundamental questions for data science education. Tasks once used to teach coding, writing, and problem-solving can now be completed by LLMs, forcing educators to reconsider both pedagogy and assessment. To understand how instructors are adapting, we conducted semi-structured interviews with 42 instructors from 33 institutions in 10 countries in June and July 2025. Our qualitative analysis reveals a pragmatic mix of optimism and concern. Many respondents view LLMs as inevitable classroom tools -- comparable to calculators or Wikipedia -- while others worry about de-skilling, misplaced confidence, and uneven integration across institutions. Around 58 per cent have already introduced demonstrations, guided activities, or make extensive use of LLMs in their courses, though most expect change to remain slow and uneven. That said, 31 per cent have not used LLMs to teach students and do not plan to. We highlight some instructional innovations, including AI-aware assessments, reflective use of LLMs as tutors, and course-specific chatbots. By sharing these perspectives, we aim to help data science educators adapt collectively to ensure curricula keep pace with technological change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12283v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ana Elisa Lopez-Miranda, Tiffany Timbers, Rohan Alexander</dc:creator>
    </item>
    <item>
      <title>Prompt Commons: Collective Prompting as Governance for Urban AI</title>
      <link>https://arxiv.org/abs/2509.12415</link>
      <description>arXiv:2509.12415v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are entering urban governance, yet their outputs are highly sensitive to prompts that carry value judgments. We propose Prompt Commons - a versioned, community-maintained repository of prompts with governance metadata, licensing, and moderation - to steer model behaviour toward pluralism. Using a Montreal dataset (443 human prompts; 3,317 after augmentation), we pilot three governance states (open, curated, veto-enabled). On a contested policy benchmark, a single-author prompt yields 24 percent neutral outcomes; commons-governed prompts raise neutrality to 48-52 percent while retaining decisiveness where appropriate. In a synthetic incident log, a veto-enabled regime reduces time-to-remediation for harmful outputs from 30.5 +/- 8.9 hours (open) to 5.6 +/- 1.5 hours. We outline licensing (CC BY/BY-SA for prompts with optional OpenRAIL-style restrictions for artefacts), auditable moderation, and safeguards against dominance capture. Prompt governance offers a practical lever for cities to align AI with local values and accountability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12415v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rashid Mushkani</dc:creator>
    </item>
    <item>
      <title>Funding AI for Good: A Call for Meaningful Engagement</title>
      <link>https://arxiv.org/abs/2509.12455</link>
      <description>arXiv:2509.12455v1 Announce Type: new 
Abstract: Artificial Intelligence for Social Good (AI4SG) is a growing area exploring AI's potential to address social issues like public health. Yet prior work has shown limited evidence of its tangible benefits for intended communities, and projects frequently face inadequate community engagement and sustainability challenges. Funding agendas play a crucial role in framing AI4SG initiatives and shaping their approaches. Through a qualitative analysis of 35 funding documents -- representing about $410 million USD in total investments, we reveal dissonances between AI4SG's stated intentions for positive social impact and the techno-centric approaches that some funding agendas promoted. Drawing on our findings, we offer recommendations for funders to scaffold approaches that balance both contextual understanding and technical capacities in future funding call designs. We call for greater engagement between AI4SG funders and the HCI community to support community engagement work in the funding program design process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12455v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hongjin Lin, Anna Kawakami, Catherine D'Ignazio, Kenneth Holstein, Krzysztof Gajos</dc:creator>
    </item>
    <item>
      <title>Qualitative Research in an Era of AI: A Pragmatic Approach to Data Analysis, Workflow, and Computation</title>
      <link>https://arxiv.org/abs/2509.12503</link>
      <description>arXiv:2509.12503v1 Announce Type: new 
Abstract: Rapid computational developments - particularly the proliferation of artificial intelligence (AI) - increasingly shape social scientific research while raising new questions about in-depth qualitative methods such as ethnography and interviewing. Building on classic debates about using computers to analyze qualitative data, we revisit longstanding concerns and assess possibilities and dangers in an era of automation, AI chatbots, and 'big data.' We first historicize developments by revisiting classical and emergent concerns about qualitative analysis with computers. We then introduce a typology of contemporary modes of engagement - streamlining workflows, scaling up projects, hybrid analytical approaches, and the sociology of computation - alongside rejection of computational analyses. We illustrate these approaches with detailed workflow examples from a large-scale ethnographic study and guidance for solo researchers. We argue for a pragmatic sociological approach that moves beyond dualisms of technological optimism versus rejection to show how computational tools - simultaneously dangerous and generative - can be adapted to support longstanding qualitative aims when used carefully in ways aligned with core methodological commitments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12503v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Corey M. Abramson, Zhuofan Li, Tara Prendergast, Daniel Dohan</dc:creator>
    </item>
    <item>
      <title>An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies</title>
      <link>https://arxiv.org/abs/2509.12577</link>
      <description>arXiv:2509.12577v1 Announce Type: new 
Abstract: In an era of increasing societal fragmentation, political polarization, and erosion of public trust in institutions, representative deliberative assemblies are emerging as a promising democratic forum for developing effective policy outcomes on complex global issues. Despite theoretical attention, there remains limited empirical work that systematically traces how specific ideas evolve, are prioritized, or are discarded during deliberation to form policy recommendations. Addressing these gaps, this work poses two central questions: (1) How might we trace the evolution and distillation of ideas into concrete recommendations within deliberative assemblies? (2) How does the deliberative process shape delegate perspectives and influence voting dynamics over the course of the assembly? To address these questions, we develop LLM-based methodologies for empirically analyzing transcripts from a tech-enhanced in-person deliberative assembly. The framework identifies and visualizes the space of expressed suggestions. We also empirically reconstruct each delegate's evolving perspective throughout the assembly. Our methods contribute novel empirical insights into deliberative processes and demonstrate how LLMs can surface high-resolution dynamics otherwise invisible in traditional assembly outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12577v1</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Elinor Poole-Dayan, Deb Roy, Jad Kabbara</dc:creator>
    </item>
    <item>
      <title>Introducing the A2AJ's Canadian Legal Data: An open-source alternative to CanLII for the era of computational law</title>
      <link>https://arxiv.org/abs/2509.13032</link>
      <description>arXiv:2509.13032v1 Announce Type: new 
Abstract: The Access to Algorithmic Justice project (A2AJ) is an open-source alternative to the Canadian Legal Information Institute (CanLII). At a moment when technology promises to enable new ways of working with law, CanLII is becoming an impediment to the free access of law and access to justice movements because it restricts bulk and programmatic access to Canadian legal data. This means that Canada is staring down a digital divide: well-resourced actors have the best new technological tools and, because CanLII has disclaimed leadership, the public only gets second-rate tools. This article puts CanLII in its larger historical context and shows how long and deep efforts to democratize access to Canadian legal data are, and how often they are thwarted by private industry. We introduce the A2AJ's Canadian Legal Data project, which provides open access to over 116,000 court decisions and 5,000 statutes through multiple channels including APIs, machine learning datasets, and AI integration protocols. Through concrete examples, we demonstrate how open legal data enables courts to conduct evidence-based assessments and allows developers to create tools for practitioners serving low-income communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13032v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Wallace, Sean Rehaag</dc:creator>
    </item>
    <item>
      <title>Designing the Hybrid Cooperative: A Socio-Technical Architecture for Scalable, Global Coordination Using Blockchain</title>
      <link>https://arxiv.org/abs/2509.13156</link>
      <description>arXiv:2509.13156v1 Announce Type: new 
Abstract: Blockchain has been promoted as a remedy for coordination in fragmented, multi-stakeholder ecosystems, yet many projects stall at pilot stage. Using a design-science approach, we develop the Hybrid Cooperative (HC), a digitally native governance architecture that combines smart-contract coordination with a minimal, code-deferent legal interface and jurisdictional modules. This selective decentralization decentralizes rules where programmability lowers agency and verification costs, and centralizes only what is needed for enforceability. A post-case evaluation against two traceability initiatives in supply chains illustrates how the HC improves distributed task management, verifiable information, incentive alignment, institutional interoperability, and scalable, contestable governance. The paper contributes to Information Systems by specifying a socio-technical model for scalable, multi-stakeholder coordination across regulatory and organizational boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13156v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrik Axelsen, Jan Damsgaard</dc:creator>
    </item>
    <item>
      <title>Beyond Private or Public: Large Language Models as Quasi-Public Goods in the AI Economy</title>
      <link>https://arxiv.org/abs/2509.13265</link>
      <description>arXiv:2509.13265v1 Announce Type: new 
Abstract: This paper conceptualizes Large Language Models (LLMs) as a form of mixed public goods within digital infrastructure, analyzing their economic properties through a comprehensive theoretical framework. We develop mathematical models to quantify the non-rivalry characteristics, partial excludability, and positive externalities of LLMs. Through comparative analysis of open-source and closed-source development paths, we identify systematic differences in resource allocation efficiency, innovation trajectories, and access equity. Our empirical research evaluates the spillover effects and network externalities of LLMs across different domains, including knowledge diffusion, innovation acceleration, and industry transformation. Based on these findings, we propose policy recommendations for balancing innovation incentives with equitable access, including public-private partnership mechanisms, computational resource democratization, and governance structures that optimize social welfare. This interdisciplinary approach contributes to understanding the economic nature of foundation AI models and provides policy guidance for their development as critical digital infrastructure</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13265v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukun Zhang, TianYang Zhang</dc:creator>
    </item>
    <item>
      <title>V-Math: An Agentic Approach to the Vietnamese National High School Graduation Mathematics Exams</title>
      <link>https://arxiv.org/abs/2509.12251</link>
      <description>arXiv:2509.12251v1 Announce Type: cross 
Abstract: This paper develops an autonomous agentic framework called V-Math that aims to assist Vietnamese high school students in preparing for the National High School Graduation Mathematics Exams (NHSGMEs). The salient framework integrates three specialized AI agents: a specification-matrix-conditioned question generator, a solver/explainer for detailed step-by-step reasoning, and a personalized tutor that adapts to student performance. Beyond enabling self-paced student practice, V-Math supports teachers by generating innovative, compliant exam questions and building diverse, high-quality question banks. This reduces manual workload and enriches instructional resources. We describe the system architecture, focusing on practice modes for learners and teacher-oriented features for question generation. Preliminary evaluations demonstrate that V-Math produces matrix-aligned exams with high solution accuracy, delivers coherent explanations, and enhances the variety of practice materials. These results highlight its potential to support scalable, equitable mathematics preparation aligned with national standards while also empowering teachers through AI-assisted exam creation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12251v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duong Q. Nguyen, Quy P. Nguyen, Nguyen Van Nhon, Quang-Thinh Bui, H. Nguyen-Xuan</dc:creator>
    </item>
    <item>
      <title>Digital Voices of Survival: From Social Media Disclosures to Support Provisions for Domestic Violence Victims</title>
      <link>https://arxiv.org/abs/2509.12288</link>
      <description>arXiv:2509.12288v1 Announce Type: cross 
Abstract: Domestic Violence (DV) is a pervasive public health problem characterized by patterns of coercive and abusive behavior within intimate relationships. With the rise of social media as a key outlet for DV victims to disclose their experiences, online self-disclosure has emerged as a critical yet underexplored avenue for support-seeking. In addition, existing research lacks a comprehensive and nuanced understanding of DV self-disclosure, support provisions, and their connections. To address these gaps, this study proposes a novel computational framework for modeling DV support-seeking behavior alongside community support mechanisms. The framework consists of four key components: self-disclosure detection, post clustering, topic summarization, and support extraction and mapping. We implement and evaluate the framework with data collected from relevant social media communities. Our findings not only advance existing knowledge on DV self-disclosure and online support provisions but also enable victim-centered digital interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12288v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanlun Wang, Zhe Fu, Wangjiaxuan Xin, Lina Zhou, Shashi Kiran Chandrappa</dc:creator>
    </item>
    <item>
      <title>Secure Human Oversight of AI: Exploring the Attack Surface of Human Oversight</title>
      <link>https://arxiv.org/abs/2509.12290</link>
      <description>arXiv:2509.12290v1 Announce Type: cross 
Abstract: Human oversight of AI is promoted as a safeguard against risks such as inaccurate outputs, system malfunctions, or violations of fundamental rights, and is mandated in regulation like the European AI Act. Yet debates on human oversight have largely focused on its effectiveness, while overlooking a critical dimension: the security of human oversight. We argue that human oversight creates a new attack surface within the safety, security, and accountability architecture of AI operations. Drawing on cybersecurity perspectives, we analyze attack vectors that threaten the requirements of effective human oversight, thereby undermining the safety of AI operations. Such attacks may target the AI system, its communication with oversight personnel, or the personnel themselves. We then outline hardening strategies to mitigate these risks. Our contributions are: (1) introducing a security perspective on human oversight, and (2) providing an overview of attack vectors and hardening strategies to enable secure human oversight of AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12290v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas C. Ditz, Veronika Lazar, Elmar Lichtme{\ss}, Carola Plesch, Matthias Heck, Kevin Baum, Markus Langer</dc:creator>
    </item>
    <item>
      <title>What News Recommendation Research Did (But Mostly Didn't) Teach Us About Building A News Recommender</title>
      <link>https://arxiv.org/abs/2509.12361</link>
      <description>arXiv:2509.12361v1 Announce Type: cross 
Abstract: One of the goals of recommender systems research is to provide insights and methods that can be used by practitioners to build real-world systems that deliver high-quality recommendations to actual people grounded in their genuine interests and needs. We report on our experience trying to apply the news recommendation literature to build POPROX, a live platform for news recommendation research, and reflect on the extent to which the current state of research supports system-building efforts. Our experience highlights several unexpected challenges encountered in building personalization features that are commonly found in products from news aggregators and publishers, and shows how those difficulties are connected to surprising gaps in the literature. Finally, we offer a set of lessons learned from building a live system with a persistent user base and highlight opportunities to make future news recommendation research more applicable and impactful in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12361v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Higley, Robin Burke, Michael D. Ekstrand, Bart P. Knijnenburg</dc:creator>
    </item>
    <item>
      <title>Physical Complexity of a Cognitive Artifact</title>
      <link>https://arxiv.org/abs/2509.12495</link>
      <description>arXiv:2509.12495v1 Announce Type: cross 
Abstract: Cognitive science and theoretical computer science both seek to classify and explain the difficulty of tasks. Mechanisms of intelligence are those that reduce task difficulty. Here we map concepts from the computational complexity of a physical puzzle, the Soma Cube, onto cognitive problem-solving strategies through a ``Principle of Materiality''. By analyzing the puzzle's branching factor, measured through search tree outdegree, we quantitatively assess task difficulty and systematically examine how different strategies modify complexity. We incrementally refine a trial-and-error search by layering preprocessing (cognitive chunking), value ordering (cognitive free-sorting), variable ordering (cognitive scaffolding), and pruning (cognitive inference). We discuss how the competent use of artifacts reduces effective time complexity by exploiting physical constraints and propose a model of intelligence as a library of algorithms that recruit the capabilities of both mind and matter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12495v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\"ulce Karde\c{s}, David Krakauer, Joshua Grochow</dc:creator>
    </item>
    <item>
      <title>A comparison of pipelines for the translation of a low resource language based on transformers</title>
      <link>https://arxiv.org/abs/2509.12514</link>
      <description>arXiv:2509.12514v1 Announce Type: cross 
Abstract: This work compares three pipelines for training transformer-based neural networks to produce machine translators for Bambara, a Mand\`e language spoken in Africa by about 14,188,850 people. The first pipeline trains a simple transformer to translate sentences from French into Bambara. The second fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures for French-to-Bambara translation. Models from the first two pipelines were trained with different hyperparameter combinations to improve BLEU and chrF scores, evaluated on both test sentences and official Bambara benchmarks. The third pipeline uses language distillation with a student-teacher dual neural network to integrate Bambara into a pre-trained LaBSE model, which provides language-agnostic embeddings. A BERT extension is then applied to LaBSE to generate translations. All pipelines were tested on Dokotoro (medical) and Bayelemagaba (mixed domains). Results show that the first pipeline, although simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on Bayelemagaba), consistent with low-resource translation results. On the Yiri dataset, created for this work, it achieves 33.81% BLEU and 41% chrF. Instructor-based models perform better on single datasets than on aggregated collections, suggesting they capture dataset-specific patterns more effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12514v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chiara Bonfanti, Michele Colombino, Giulia Coucourde, Faeze Memari, Stefano Pinardi, Rosa Meo</dc:creator>
    </item>
    <item>
      <title>CattleSense -- A Multisensory Approach to Optimize Cattle Well-Being</title>
      <link>https://arxiv.org/abs/2509.12617</link>
      <description>arXiv:2509.12617v1 Announce Type: cross 
Abstract: CattleSense is an innovative application of Internet of Things (IoT) technology for the comprehensive monitoring and management of cattle well-being. This research paper outlines the design and implementation of a sophisticated system using a Raspberry Pi Module 4B, RFID Card Reader, Electret Arduino Microphone Module, DHT11 Sensor, Arduino UNO, Neo-6M GPS Sensor, and Heartbeat Sensor. The system aims to provide real-time surveillance of the environment in which Cows are present and individual Cow parameters such as location, milking frequency, and heartbeat fluctuations. The primary objective is to simplify managing the Cattle in the shed, ensuring that the Cattle are healthy and safe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12617v1</guid>
      <category>eess.SY</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ASET60340.2024.10708764</arxiv:DOI>
      <dc:creator>Srijesh Pillai, M. I. Jawid Nazir</dc:creator>
    </item>
    <item>
      <title>DoubleAgents: Exploring Mechanisms of Building Trust with Proactive AI</title>
      <link>https://arxiv.org/abs/2509.12626</link>
      <description>arXiv:2509.12626v1 Announce Type: cross 
Abstract: Agentic workflows promise efficiency, but adoption hinges on whether people actually trust systems that act on their behalf. We present DoubleAgents, an agentic planning tool that embeds transparency and control through user intervention, value-reflecting policies, rich state visualizations, and uncertainty flagging for human coordination tasks. A built-in respondent simulation generates realistic scenarios, allowing users to rehearse, refine policies, and calibrate their reliance before live use. We evaluate DoubleAgents in a two-day lab study (n=10), two deployments (n=2), and a technical evaluation. Results show that participants initially hesitated to delegate but grew more reliant as they experienced transparency, control, and adaptive learning during simulated cases. Deployment results demonstrate DoubleAgents' real-world relevance and usefulness, showing that the effort required scaled appropriately with task complexity and contextual data. We contribute trust-by-design patterns and mechanisms for proactive AI -- consistency, controllability, and explainability -- along with simulation as a safe path to build and calibrate trust over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12626v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Long, Xuanming Zhang, Sitong Wang, Zhou Yu, Lydia B Chilton</dc:creator>
    </item>
    <item>
      <title>Podcasts as a Medium for Participation in Collective Action: A Case Study of Black Lives Matter</title>
      <link>https://arxiv.org/abs/2509.13197</link>
      <description>arXiv:2509.13197v1 Announce Type: cross 
Abstract: We study how participation in collective action is articulated in podcast discussions, using the Black Lives Matter (BLM) movement as a case study. While research on collective action discourse has primarily focused on text-based content, this study takes a first step toward analyzing audio formats by using podcast transcripts. Using the Structured Podcast Research Corpus (SPoRC), we investigated spoken language expressions of participation in collective action, categorized as problem-solution, call-to-action, intention, and execution. We identified podcast episodes discussing racial justice after important BLM-related events in May and June of 2020, and extracted participatory statements using a layered framework adapted from prior work on social media. We examined the emotional dimensions of these statements, detecting eight key emotions and their association with varying stages of activism. We found that emotional profiles vary by stage, with different positive emotions standing out during calls-to-action, intention, and execution. We detected negative associations between collective action and negative emotions, contrary to theoretical expectations. Our work contributes to a better understanding of how activism is expressed in spoken digital discourse and how emotional framing may depend on the format of the discussion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13197v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theodora Moldovan, Arianna Pera, Davide Vega, Luca Maria Aiello</dc:creator>
    </item>
    <item>
      <title>Digital Discrimination in Dating Apps and the Dutch Breeze case</title>
      <link>https://arxiv.org/abs/2409.15828</link>
      <description>arXiv:2409.15828v2 Announce Type: replace 
Abstract: In 2023, the Netherlands Institute for Human Rights, the Dutch non-discrimination authority, decided that Breeze, a Dutch dating app, was justified in suspecting that their algorithm discriminated against dark-skinned users. Consequently, the Institute decided that Breeze must prevent this discrimination based on ethnicity. This paper analyses the decision and explores three questions.What are the main points of the Breeze decision? Is the discrimination based on ethnicity in Breeze's matching algorithm illegal? We also explore a more general question: how can dating apps mitigate or stop discrimination in their matching algorithms? We illustrate the legal and technical difficulties dating apps face in tackling discrimination and highlight some promising solutions. We analyse the Breeze decision in-depth, combining insights from computer science and law. We discuss the implications of this judgment for scholarship and practice in the field of fair and non-discriminatory machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15828v2</guid>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim de Jonge, Frederik Zuiderveen Borgesius</dc:creator>
    </item>
    <item>
      <title>Reviewing Uses of Regulatory Compliance Monitoring</title>
      <link>https://arxiv.org/abs/2501.10362</link>
      <description>arXiv:2501.10362v4 Announce Type: replace 
Abstract: Organizations need to manage numerous business processes for delivering their services and products to customers. One important consideration thereby lies in the adherence to regulations such as laws, guidelines, or industry standards. In order to monitor adherence of their business processes to regulations -- in other words, their regulatory compliance -- organizations make use of various techniques that draw on process execution data of IT systems that support these processes. Previous research has investigated conformance checking, an operation of process mining, for the domains in which it is applied, its operationalization of regulations, the techniques being used, and the presentation of results produced. However, other techniques for regulatory compliance monitoring, which we summarize as compliance checking techniques, have not yet been investigated regarding these aspects in a structural manner. To this end, this work presents a systematic literature review on uses of regulatory compliance monitoring of business processes, thereby offering insights into the various techniques being used, their application and the results they generate. We highlight commonalities and differences between the approaches and find that various steps are performed manually; we also provide further impulses for research on compliance monitoring and its use in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10362v4</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Finn Klessascheck, Luise Pufahl</dc:creator>
    </item>
    <item>
      <title>AI Governance in Higher Education: A course design exploring regulatory, ethical and practical considerations</title>
      <link>https://arxiv.org/abs/2509.06176</link>
      <description>arXiv:2509.06176v2 Announce Type: replace 
Abstract: As artificial intelligence (AI) systems permeate critical sectors, the need for professionals who can address ethical, legal and governance challenges has become urgent. Current AI ethics education remains fragmented, often siloed by discipline and disconnected from practice. This paper synthesizes literature and regulatory developments to propose a modular, interdisciplinary curriculum that integrates technical foundations with ethics, law and policy. We highlight recurring operational failures in AI - bias, misspecified objectives, generalization errors, misuse and governance breakdowns - and link them to pedagogical strategies for teaching AI governance. Drawing on perspectives from the EU, China and international frameworks, we outline a semester plan that emphasizes integrated ethics, stakeholder engagement and experiential learning. The curriculum aims to prepare students to diagnose risks, navigate regulation and engage diverse stakeholders, fostering adaptive and ethically grounded professionals for responsible AI governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06176v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Weuts (KU Leuven, Belgium), Johannes Bleher (University of Hohenheim, Germany), Hannah Bleher (University of Bonn, Germany), Rozanne Tuesday Flores (Bukidnon State University, Philippines), Guo Xuanyang (Southwest University of Political Science and Law, China), Pawe{\l} Pujszo (College of Europe, Natolin, Poland), Zsolt Alm\'asi (P\'azm\'any P\'eter Catholic University, Hungary)</dc:creator>
    </item>
    <item>
      <title>National Running Club Database: Assessing Collegiate Club Athletes' Cross Country Race Results</title>
      <link>https://arxiv.org/abs/2509.10600</link>
      <description>arXiv:2509.10600v2 Announce Type: replace 
Abstract: The National Running Club Database (NRCD) aggregates 15,397 race results of 5,585 athletes from the 2023 and 2024 cross country seasons. This paper introduces the NRCD dataset, which provides insights into individual athlete progressions, enabling data-driven decision-making. Analysis reveals that runners' improvement per calendar day for women, racing 6,000m, and men, racing 8,000m, is more pronounced in athletes with slower initial race times and those who race more frequently. Additionally, we factor in course conditions, including weather and elevation gain, to standardize improvement. While the NRCD shows a gender imbalance, 3,484 men vs. 2,101 women, the racing frequency between genders is comparable. This publication makes the NRCD dataset accessible to the research community, addressing a previous challenge where smaller datasets, often limited to 500 entries, had to be manually scraped from the internet. Focusing on club athletes rather than elite professionals offers a unique lens into the performance of real-world runners who balance competition with academics and other commitments. These results serve as a valuable resource for runners, coaches, and teams, bridging the gap between raw data and applied sports science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10600v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan A. Karr Jr, Ben Darden, Nicholas Pell, Ryan M. Fryer, Kayla Ambrose, Evan Hall, Ramzi K. Bualuan, Nitesh V. Chawla</dc:creator>
    </item>
    <item>
      <title>Adapting Public Personas: A Multimodal Study of U.S. Legislators' Cross-Platform Social Media Strategies</title>
      <link>https://arxiv.org/abs/2509.10720</link>
      <description>arXiv:2509.10720v2 Announce Type: replace 
Abstract: Current cross-platform social media analyses primarily focus on the textual features of posts, often lacking multimodal analysis due to past technical limitations. This study addresses this gap by examining how U.S. legislators in the 118th Congress strategically use social media platforms to adapt their public personas by emphasizing different topics and stances. Leveraging the Large Multimodal Models (LMMs) for fine-grained text and image analysis, we examine 540 legislators personal website and social media, including Facebook, X (Twitter), TikTok. We find that legislators tailor their topics and stances to project distinct public personas on different platforms. Democrats tend to prioritize TikTok, which has a younger user base, while Republicans are more likely to express stronger stances on established platforms such as Facebook and X (Twitter), which offer broader audience reach. Topic analysis reveals alignment with constituents' key concerns, while stances and polarization vary by platform and topic. Large-scale image analysis shows Republicans employing more formal visuals to project authority, whereas Democrats favor campaign-oriented imagery. These findings highlight the potential interplay between platform features, audience demographics, and partisan goals in shaping political communication. By providing insights into multimodal strategies, this study contributes to understanding the role of social media in modern political discourse and communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10720v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weihong Qi, Anushka Dave, Chen Ling</dc:creator>
    </item>
    <item>
      <title>Argumentative Experience: Reducing Confirmation Bias on Controversial Issues through LLM-Generated Multi-Persona Debates</title>
      <link>https://arxiv.org/abs/2412.04629</link>
      <description>arXiv:2412.04629v5 Announce Type: replace-cross 
Abstract: Multi-persona debate systems powered by large language models (LLMs) show promise in reducing confirmation bias, which can fuel echo chambers and social polarization. However, empirical evidence remains limited on whether they meaningfully shift user attention toward belief-challenging content, promote belief change, or outperform traditional debiasing strategies. To investigate this, we compare an LLM-based multi-persona debate system with a two-stance retrieval-based system, exposing participants to multiple viewpoints on controversial topics. By collecting eye-tracking data, belief change measures, and qualitative feedback, our results show that while the debate system does not significantly increase attention to opposing views, or make participants shift away from prior beliefs, it does provide a buffering effect against bias caused by individual cognitive tendency. These findings shed light on both the promise and limits of multi-persona debate systems in information seeking, and we offer design insights to guide future work toward more balanced and reflective information engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04629v5</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Li Shi, Houjiang Liu, Yian Wong, Utkarsh Mujumdar, Dan Zhang, Jacek Gwizdka, Matthew Lease</dc:creator>
    </item>
    <item>
      <title>Break the Checkbox: Challenging Closed-Style Evaluations of Cultural Alignment in LLMs</title>
      <link>https://arxiv.org/abs/2502.08045</link>
      <description>arXiv:2502.08045v3 Announce Type: replace-cross 
Abstract: A large number of studies rely on closed-style multiple-choice surveys to evaluate cultural alignment in Large Language Models (LLMs). In this work, we challenge this constrained evaluation paradigm and explore more realistic, unconstrained approaches. Using the World Values Survey (WVS) and Hofstede Cultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger cultural alignment in less constrained settings, where responses are not forced. Additionally, we show that even minor changes, such as reordering survey choices, lead to inconsistent outputs, exposing the limitations of closed-style evaluations. Our findings advocate for more robust and flexible evaluation frameworks that focus on specific cultural proxies, encouraging more nuanced and accurate assessments of cultural alignment in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08045v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohsinul Kabir, Ajwad Abrar, Sophia Ananiadou</dc:creator>
    </item>
  </channel>
</rss>
