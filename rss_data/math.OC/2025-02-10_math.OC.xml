<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Feb 2025 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Near-Optimal Sample Complexity for MDPs via Anchoring</title>
      <link>https://arxiv.org/abs/2502.04477</link>
      <description>arXiv:2502.04477v1 Announce Type: new 
Abstract: We study a new model-free algorithm to compute $\varepsilon$-optimal policies for average reward Markov decision processes, in the weakly communicating case. Given a generative model, our procedure combines a recursive sampling technique with Halpern's anchored iteration, and computes an $\varepsilon$-optimal policy with sample and time complexity $\widetilde{O}(|\mathcal{S}||\mathcal{A}|\|h^*\|_{\text{sp}}^{2}/\varepsilon^{2})$ both in high probability and in expectation. To our knowledge, this is the best complexity among model-free algorithms, matching the known lower bound up to a factor $\|h^*\|_{\text{sp}}$. Although the complexity bound involves the span seminorm $\|h^*\|_{\text{sp}}$ of the unknown bias vector, the algorithm requires no prior knowledge and implements a stopping rule which guarantees with probability 1 that the procedure terminates in finite time. We also analyze how these techniques can be adapted for discounted MDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04477v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongmin Lee, Mario Bravo, Roberto Cominetti</dc:creator>
    </item>
    <item>
      <title>State estimator design using Jordan based long short-term memory networks</title>
      <link>https://arxiv.org/abs/2502.04518</link>
      <description>arXiv:2502.04518v1 Announce Type: new 
Abstract: State estimation of a dynamical system refers to estimating the state of a system given an imperfect model, noisy measurements and some or no information about the initial state. While Kalman filtering is optimal for estimation of linear systems with Gaussian noises, calculation of optimal estimators for nonlinear systems is challenging. We focus on establishing a pathway to optimal estimation of high-order systems by using recurrent connections motivated by Jordan recurrent neural networks(JRNs). The results are compared to the corresponding Elman structure based long short-term memory network(ELSTM) and the KF for linear and EKF for nonlinear systems. The results suggest that for nonlinear systems, the use of long short-term memory networks can improve estimation error and also computation time. Also, the Jordan based long short-term memory networks(JLSTMs) require less training to achieve performance similar to ELSTMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04518v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avneet Kaur, Kirsten Morris</dc:creator>
    </item>
    <item>
      <title>Stability of Jordan Recurrent Neural Network Estimator</title>
      <link>https://arxiv.org/abs/2502.04551</link>
      <description>arXiv:2502.04551v1 Announce Type: new 
Abstract: State estimation involves finding the states of a noisy dynamical system with a noisy initial condition using noisy measurements, given a model of the system. Many methods exist for state estimation of dynamical systems. For linear dynamical systems with white Gaussian noises of known mean and variance, Kalman filtering is an optimal state estimation algorithm. While several extensions of the Kalman filter to nonlinear systems exist, either the method is not optimal or calculation is not feasible. Several approaches using neural networks have been developed in recent years. While these approaches seem to work numerically, stability and convergence guarantees do not exist. In this paper, we propose to use a Jordan recurrent neural network (JRN) for state estimation. An input-to-state stability (ISS) analysis of the error dynamics is used. Our results are compared to the Kalman filter for the linear case and the extended Kalman filter for the nonlinear case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04551v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avneet Kaur, Ruikun Zhou, Jun Liu, Kirsten Morris</dc:creator>
    </item>
    <item>
      <title>Automatic Ply Partitioning for Laminar Composite Process Planning</title>
      <link>https://arxiv.org/abs/2502.04586</link>
      <description>arXiv:2502.04586v1 Announce Type: new 
Abstract: This work introduces an automated ply partitioning strategy for large-scale laminar composite manufacturing. It specifically targets the problem of fabricating large plies from available spooled materials, while minimizing the adverse effects on part quality. The proposed method inserts fiber-aligned seams sequentially until each resulting sub-ply can be manufactured from available materials, while simultaneously enforcing constraints to avoid quality issues induced by the stacking of seams across multiple plies. Leveraging the developable nature of individual plies, the partitioning problem is cast as a sequence of one-dimensional piecewise linear optimization problems, thus allowing for efficient local optimization via linear programming. We experimentally demonstrate that coupling the local search with a greedy global search produces the same results as an exhaustive search. The resulting automated method provides an efficient and robust alternative to the existing trial-and-error approach, and can be readily integrated into state-of-the-art composite design workflows. In addition, this formulation enables the inclusion of common constraints regarding laminate thickness tolerance, sub-ply geometry, stay-out zones, material wastage, etc. The efficacy of the proposed method is demonstrated through its application to the surface of an airplane wing and to the body panels of an armored vehicle, each subject to various performance and manufacturing-related geometric constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04586v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Garner, Amir Mirzendehdel</dc:creator>
    </item>
    <item>
      <title>A Bregman ADMM for Bethe variational problem</title>
      <link>https://arxiv.org/abs/2502.04613</link>
      <description>arXiv:2502.04613v1 Announce Type: new 
Abstract: In this work, we propose a novel Bregman ADMM with nonlinear dual update to solve the Bethe variational problem (BVP), a key optimization formulation in graphical models and statistical physics. Our algorithm provides rigorous convergence guarantees, even if the objective function of BVP is non-convex and non-Lipschitz continuous on the boundary. A central result of our analysis is proving that the entries in local minima of BVP are strictly positive, effectively resolving non-smoothness issues caused by zero entries. Beyond theoretical guarantees, the algorithm possesses high level of separability and parallelizability to achieve highly efficient subproblem computation. Our Bregman ADMM can be easily extended to solve quantum Bethe variational problem. Numerical experiments are conducted to validate the effectiveness and robustness of the proposed method. Based on this research, we have released an open-source package of the proposed method at https://github.com/TTYmath/BADMM-BVP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04613v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuehaw Khoo, Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Error Bounds for a Class of Cone-Convex Inclusion Problems</title>
      <link>https://arxiv.org/abs/2502.04716</link>
      <description>arXiv:2502.04716v1 Announce Type: new 
Abstract: In this paper, we investigate error bounds for cone-convex inclusion problems in finite-dimensional settings of the form $f(x)\in K$, where $K$ is a smooth cone and $f$ is a continuously differentiable and $K$-concave function. We show that local error bounds for the inclusion can be characterized by the Abadie constraint qualification around the reference point. In the case where $f$ is an affine function, we precisely identify the conditions under which the inclusion admits global error bounds. Additionally, we derive some properties of smooth cones, as well as regular cones and strictly convex cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04716v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen Quang Huy, Nguyen Huy Hung, Nguyen Van Tuyen, Hoang Ngoc Tuan</dc:creator>
    </item>
    <item>
      <title>Variational integrators for a new Lagrangian approach to control affine systems with a quadratic Lagrange term</title>
      <link>https://arxiv.org/abs/2502.04742</link>
      <description>arXiv:2502.04742v1 Announce Type: new 
Abstract: In this work, we analyse the discretisation of a recently proposed new Lagrangian approach to optimal control problems of affine-controlled second-order differential equations with cost functions quadratic in the controls. We propose exact discrete and semi-discrete versions of the problem, providing new tools to develop numerical methods. Discrete necessary conditions for optimality are derived and their equivalence with the continuous version is proven. A family of low-order integration schemes is devised to find approximate optimality conditions, and used to solve a low-thrust orbital transfer problem. Non-trivial equivalent standard direct methods are constructed. Noether's theorem for the new Lagrangian approach is investigated in the exact and approximate cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04742v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Konopik, Rodrigo T. Sato Mart\'in de Almagro, Sofya Maslovksaya, Sina Ober-Bl\"obaum, Sigrid Leyendecker</dc:creator>
    </item>
    <item>
      <title>A non-zero-sum game with reinforcement learning under mean-variance framework</title>
      <link>https://arxiv.org/abs/2502.04788</link>
      <description>arXiv:2502.04788v1 Announce Type: new 
Abstract: In this paper, we investigate a competitive market involving two agents who consider both their own wealth and the wealth gap with their opponent. Both agents can invest in a financial market consisting of a risk-free asset and a risky asset, under conditions where model parameters are partially or completely unknown. This setup gives rise to a non-zero-sum differential game within the framework of reinforcement learning (RL). Each agent aims to maximize his own Choquet-regularized, time-inconsistent mean-variance objective. Adopting the dynamic programming approach, we derive a time-consistent Nash equilibrium strategy in a general incomplete market setting. Under the additional assumption of a Gaussian mean return model, we obtain an explicit analytical solution, which facilitates the development of a practical RL algorithm. Notably, the proposed algorithm achieves uniform convergence, even though the conventional policy improvement theorem does not apply to the equilibrium policy. Numerical experiments demonstrate the robustness and effectiveness of the algorithm, underscoring its potential for practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04788v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyi Guo, Xia Han, Hao Wang, Kam Chuen Yuen</dc:creator>
    </item>
    <item>
      <title>A Regularized Newton Method for Nonconvex Optimization with Global and Local Complexity Guarantees</title>
      <link>https://arxiv.org/abs/2502.04799</link>
      <description>arXiv:2502.04799v1 Announce Type: new 
Abstract: We consider the problem of finding an $\epsilon$-stationary point of a nonconvex function with a Lipschitz continuous Hessian and propose a quadratic regularized Newton method incorporating a new class of regularizers constructed from the current and previous gradients. The method leverages a recently developed linear conjugate gradient approach with a negative curvature monitor to solve the regularized Newton equation. Notably, our algorithm is adaptive, requiring no prior knowledge of the Lipschitz constant of the Hessian, and achieves a global complexity of $O(\epsilon^{-\frac{3}{2}}) + \tilde O(1)$ in terms of the second-order oracle calls, and $\tilde O(\epsilon^{-\frac{7}{4}})$ for Hessian-vector products, respectively. Moreover, when the iterates converge to a point where the Hessian is positive definite, the method exhibits quadratic local convergence. Preliminary numerical results illustrate the competitiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04799v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Zhou, Jintao Xu, Chenglong Bao, Chao Ding, Jun Zhu</dc:creator>
    </item>
    <item>
      <title>Coherent Local Explanations for Mathematical Optimization</title>
      <link>https://arxiv.org/abs/2502.04840</link>
      <description>arXiv:2502.04840v1 Announce Type: new 
Abstract: The surge of explainable artificial intelligence methods seeks to enhance transparency and explainability in machine learning models. At the same time, there is a growing demand for explaining decisions taken through complex algorithms used in mathematical optimization. However, current explanation methods do not take into account the structure of the underlying optimization problem, leading to unreliable outcomes. In response to this need, we introduce Coherent Local Explanations for Mathematical Optimization (CLEMO). CLEMO provides explanations for multiple components of optimization models, the objective value and decision variables, which are coherent with the underlying model structure. Our sampling-based procedure can provide explanations for the behavior of exact and heuristic solution algorithms. The effectiveness of CLEMO is illustrated by experiments for the shortest path problem, the knapsack problem, and the vehicle routing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04840v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daan Otto, Jannis Kurtz, S. Ilker Birbil</dc:creator>
    </item>
    <item>
      <title>On the optimal control of initial velocity in a hyperbolic beam equation by the variational method</title>
      <link>https://arxiv.org/abs/2502.04936</link>
      <description>arXiv:2502.04936v1 Announce Type: new 
Abstract: We study the problem of controlling the initial condition of a vibrating beam. The optimal control problem seeks to determine solutions of initial velocity that assure the approach of the state of the beam to a given target function in the $L^2-$norm. We prove both the existence and uniqueness of the optimal solution. Employing identities based on the adjoint and difference problems, we determine the Fr\'echet derivative of the cost functional. We further derive the necessary optimality conditions of this control problem. Finally, we provide a sketch of a gradient-based algorithm, that rests on the explicit formula of the gradient of the cost functional, to obtain numerical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04936v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yesim Akbulut, Bismark Singh</dc:creator>
    </item>
    <item>
      <title>Passive feedback control for nonlinear systems</title>
      <link>https://arxiv.org/abs/2502.04987</link>
      <description>arXiv:2502.04987v1 Announce Type: new 
Abstract: Dynamical systems can be used to model a broad class of physical processes, and conservation laws give rise to system properties like passivity or port-Hamiltonian structure. An important problem in practical applications is to steer dynamical systems to prescribed target states, and feedback controllers combining a regulator and an observer are a powerful tool to do so. However, controllers designed using classical methods do not necessarily obey energy principles, which makes it difficult to model the controller-plant interaction in a structured manner. In this paper, we show that a particular choice of the observer gain gives rise to passivity properties of the controller that are independent of the plant structure. Furthermore, we state conditions for the controller to have a port-Hamiltonian realization and show that a model order reduction scheme can be deduced using the framework of nonlinear balanced truncation. In addition, we propose a novel passivity preserving discrete gradient scheme for the time discretization of passive systems. To illustrate our results, we numerically realize the controller using the policy iteration and compare it to a controller where the observer gain is given by the extended Kalman filter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04987v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Breiten, Attila Karsai</dc:creator>
    </item>
    <item>
      <title>Stochastic internal habit formation and optimality</title>
      <link>https://arxiv.org/abs/2502.05081</link>
      <description>arXiv:2502.05081v1 Announce Type: new 
Abstract: Growth models with internal habit formation have been studied in various settings under the assumption of deterministic dynamics. The purpose of this paper is to explore a stochastic version of the model in Carroll et al. [1997, 2000], one the most influential on the subject. The goal is twofold: on one hand, to determine how far we can advance in the technical study of the model; on the other, to assess whether at least some of the deterministic outcomes remain valid in the stochastic setting. The resulting optimal control problem proves to be challenging, primarily due to the lack of concavity in the objective function. This feature is present in the model even in the deterministic case (see, e.g., Bambi and Gozzi [2020]). We develop an approach based on Dynamic Programming to establish several useful results, including the regularity of the solution to the corresponding HJB equation and a verification theorem. There results lay the groundwork for studying the model optimal paths and comparing them with the deterministic case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05081v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Aleandri, Alessandro Bondi, Fausto Gozzi</dc:creator>
    </item>
    <item>
      <title>Extreme-Scale EV Charging Infrastructure Planning for Last-Mile Delivery Using High-Performance Parallel Computing</title>
      <link>https://arxiv.org/abs/2502.05152</link>
      <description>arXiv:2502.05152v1 Announce Type: new 
Abstract: This paper addresses stochastic charger location and allocation (SCLA) problems under queue congestion for last-mile delivery using electric vehicles (EVs). The objective is to decide where to open charging stations and how many chargers of each type to install, subject to budgetary and waiting-time constraints. We formulate the problem as a mixed-integer non-linear program, where each station-charger pair is modeled as a multiserver queue with stochastic arrivals and service times to capture the notion of waiting in fleet operations. The model is extremely large, with billions of variables and constraints for a typical metropolitan area; and even loading the model in solver memory is difficult, let alone solving it. To address this challenge, we develop a Lagrangian-based dual decomposition framework that decomposes the problem by station and leverages parallelization on high-performance computing systems, where the subproblems are solved by using a cutting plane method and their solutions are collected at the master level. We also develop a three-step rounding heuristic to transform the fractional subproblem solutions into feasible integral solutions. Computational experiments on data from the Chicago metropolitan area with hundreds of thousands of households and thousands of candidate stations show that our approach produces high-quality solutions in cases where existing exact methods cannot even load the model in memory. We also analyze various policy scenarios, demonstrating that combining existing depots with newly built stations under multiagency collaboration substantially reduces costs and congestion. These findings offer a scalable and efficient framework for developing sustainable large-scale EV charging networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05152v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Waquar Kaleem, Taner Cokyasar, Jeffrey Larson, Omer Verbas, Tanveer Hossain Bhuiyan, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control</title>
      <link>https://arxiv.org/abs/2502.03640</link>
      <description>arXiv:2502.03640v1 Announce Type: cross 
Abstract: Control policies that can achieve high task performance and satisfy safety constraints are desirable for any system, including multi-agent systems (MAS). One promising technique for ensuring the safety of MAS is distributed control barrier functions (CBF). However, it is difficult to design distributed CBF-based policies for MAS that can tackle unknown discrete-time dynamics, partial observability, changing neighborhoods, and input constraints, especially when a distributed high-performance nominal policy that can achieve the task is unavailable. To tackle these challenges, we propose DGPPO, a new framework that simultaneously learns both a discrete graph CBF which handles neighborhood changes and input constraints, and a distributed high-performance safe policy for MAS with unknown discrete-time dynamics. We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that, compared with existing methods, our DGPPO framework obtains policies that achieve high task performance (matching baselines that ignore the safety constraints), and high safety rates (matching the most conservative baselines), with a constant set of hyperparameters across all environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03640v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>Synergistic Traffic Assignment</title>
      <link>https://arxiv.org/abs/2502.04343</link>
      <description>arXiv:2502.04343v1 Announce Type: cross 
Abstract: Traffic assignment analyzes traffic flows in road networks that emerge due to traveler interaction. Traditionally, travelers are assumed to use private cars, so road costs grow with the number of users due to congestion. However, in sustainable transit systems, travelers share vehicles s.t. more users on a road lead to higher sharing potential and reduced cost per user. Thus, we invert the usual avoidant traffic assignment (ATA) and instead consider synergistic traffic assignment (STA) where road costs decrease with use.
  We find that STA is significantly different from ATA from a game-theoretical point of view. We show that a simple iterative best-response method with simultaneous updates converges to an equilibrium state. This enables efficient computation of equilibria using optimized speedup techniques for shortest-path queries. In contrast, ATA requires slower sequential updates or more complicated iteration schemes that only approximate an equilibrium. Experiments with a realistic scenario for the city of Stuttgart indicate that STA indeed quickly converges to an equilibrium. We envision STA as a part of software-defined transportation systems that dynamically adapt to current travel demand. As a first demonstration, we show that an STA equilibrium can be used to incorporate traveler synergism in a simple bus line planning algorithm to potentially greatly reduce the required vehicle resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04343v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Bl\"asius (Karlsruhe Institute of Technology), Adrian Feilhauer (Karlsruhe Institute of Technology), Markus Jung (Karlsruhe Institute of Technology), Moritz Laupichler (Karlsruhe Institute of Technology), Peter Sanders (Karlsruhe Institute of Technology), Michael Z\"undorf (Karlsruhe Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>The Mini Wheelbot: A Testbed for Learning-based Balancing, Flips, and Articulated Driving</title>
      <link>https://arxiv.org/abs/2502.04582</link>
      <description>arXiv:2502.04582v1 Announce Type: cross 
Abstract: The Mini Wheelbot is a balancing, reaction wheel unicycle robot designed as a testbed for learning-based control. It is an unstable system with highly nonlinear yaw dynamics, non-holonomic driving, and discrete contact switches in a small, powerful, and rugged form factor. The Mini Wheelbot can use its wheels to stand up from any initial orientation - enabling automatic environment resets in repetitive experiments and even challenging half flips. We illustrate the effectiveness of the Mini Wheelbot as a testbed by implementing two popular learning-based control algorithms. First, we showcase Bayesian optimization for tuning the balancing controller. Second, we use imitation learning from an expert nonlinear MPC that uses gyroscopic effects to reorient the robot and can track higher-level velocity and orientation commands. The latter allows the robot to drive around based on user commands - for the first time in this class of robots. The Mini Wheelbot is not only compelling for testing learning-based control algorithms, but it is also just fun to work with, as demonstrated in the video of our experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04582v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Hose, Jan Weisgerber, Sebastian Trimpe</dc:creator>
    </item>
    <item>
      <title>Joint State and Noise Covariance Estimation</title>
      <link>https://arxiv.org/abs/2502.04584</link>
      <description>arXiv:2502.04584v1 Announce Type: cross 
Abstract: This paper tackles the problem of jointly estimating the noise covariance matrix alongside primary parameters (such as poses and points) from measurements corrupted by Gaussian noise. In such settings, the noise covariance matrix determines the weights assigned to individual measurements in the least squares problem. We show that the joint problem exhibits a convex structure and provide a full characterization of the optimal noise covariance estimate (with analytical solutions) within joint maximum a posteriori and likelihood frameworks and several variants. Leveraging this theoretical result, we propose two novel algorithms that jointly estimate the primary parameters and the noise covariance matrix. To validate our approach, we conduct extensive experiments across diverse scenarios and offer practical insights into their application in robotics and computer vision estimation problems with a particular focus on SLAM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04584v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasra Khosoussi, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Robust Quantum Control for Bragg Pulse Design in Atom Interferometry</title>
      <link>https://arxiv.org/abs/2502.04618</link>
      <description>arXiv:2502.04618v1 Announce Type: cross 
Abstract: We formulate a robust optimal control algorithm to synthesize minimum energy pulses that can transfer a cold atom system into various momentum states. The algorithm uses adaptive linearization of the evolution operator and sequential quadratic programming to iterate the control towards a minimum energy signal that achieves optimal target state fidelity. Robustness to parameter variation is achieved using Legendre polynomial approximation over the domain of variation. The method is applied to optimize the Bragg beamsplitting operation in ultra-cold atom interferometry. Even in the presence of 10-40% variability in the initial momentum dispersion of the atomic cloud and the intensity of the optical pulse, the algorithm reliably converges to a control protocol that robustly achieves unprecedented momentum levels with high fidelity for a single-frequency multi-photon Bragg diffraction scheme (e.g. $|\pm 40\hbar k\rangle$). Advantages of the proposed method are demonstrated by comparison to stochastic optimization using sampled parameter values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04618v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Andre Luiz P. de Lima, Andrew Harter, Ceren Uzun, Jr-Shin Li, Anatoly Zlotnik, Michael J. Martin, Malcolm G. Boshier</dc:creator>
    </item>
    <item>
      <title>Building Rome with Convex Optimization</title>
      <link>https://arxiv.org/abs/2502.04640</link>
      <description>arXiv:2502.04640v1 Announce Type: cross 
Abstract: Global bundle adjustment is made easy by depth prediction and convex optimization. We (i) propose a scaled bundle adjustment (SBA) formulation that lifts 2D keypoint measurements to 3D with learned depth, (ii) design an empirically tight convex semidfinite program (SDP) relaxation that solves SBA to certfiable global optimality, (iii) solve the SDP relaxations at extreme scale with Burer-Monteiro factorization and a CUDA-based trust-region Riemannian optimizer (dubbed XM), (iv) build a structure from motion (SfM) pipeline with XM as the optimization engine and show that XM-SfM dominates or compares favorably with existing SfM pipelines in terms of reconstruction quality while being faster, more scalable, and initialization-free.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04640v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Han, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Dynamic Incentive Selection for Hierarchical Convex Model Predictive Control</title>
      <link>https://arxiv.org/abs/2502.04642</link>
      <description>arXiv:2502.04642v1 Announce Type: cross 
Abstract: In this paper, we discuss incentive design for hierarchical model predictive control (MPC) systems viewed as Stackelberg games. We consider a hierarchical MPC formulation where, given a lower-level convex MPC (LoMPC), the upper-level system solves a bilevel MPC (BiMPC) subject to the constraint that the lower-level system inputs are optimal for the LoMPC. Such hierarchical problems are challenging due to optimality constraints in the BiMPC formulation. We analyze an incentive Stackelberg game variation of the problem, where the BiMPC provides additional incentives for the LoMPC cost function, which grants the BiMPC influence over the LoMPC inputs. We show that for such problems, the BiMPC can be reformulated as a simpler optimization problem, and the optimal incentives can be iteratively computed without knowing the LoMPC cost function. We extend our formulation for the case of multiple LoMPCs and propose an algorithm that finds bounded suboptimal solutions for the BiMPC. We demonstrate our algorithm for a dynamic price control example, where an independent system operator (ISO) sets the electricity prices for electric vehicle (EV) charging with the goal of minimizing a social cost and satisfying electricity generation constraints. Notably, our method scales well to large EV population sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04642v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akshay Thirugnanam, Koushil Sreenath</dc:creator>
    </item>
    <item>
      <title>End-to-End Learning Framework for Solving Non-Markovian Optimal Control</title>
      <link>https://arxiv.org/abs/2502.04649</link>
      <description>arXiv:2502.04649v1 Announce Type: cross 
Abstract: Integer-order calculus often falls short in capturing the long-range dependencies and memory effects found in many real-world processes. Fractional calculus addresses these gaps via fractional-order integrals and derivatives, but fractional-order dynamical systems pose substantial challenges in system identification and optimal control due to the lack of standard control methodologies. In this paper, we theoretically derive the optimal control via \textit{linear quadratic regulator} (LQR) for \textit{fractional-order linear time-invariant }(FOLTI) systems and develop an end-to-end deep learning framework based on this theoretical foundation. Our approach establishes a rigorous mathematical model, derives analytical solutions, and incorporates deep learning to achieve data-driven optimal control of FOLTI systems. Our key contributions include: (i) proposing an innovative system identification method control strategy for FOLTI systems, (ii) developing the first end-to-end data-driven learning framework, \textbf{F}ractional-\textbf{O}rder \textbf{L}earning for \textbf{O}ptimal \textbf{C}ontrol (FOLOC), that learns control policies from observed trajectories, and (iii) deriving a theoretical analysis of sample complexity to quantify the number of samples required for accurate optimal control in complex real-world problems. Experimental results indicate that our method accurately approximates fractional-order system behaviors without relying on Gaussian noise assumptions, pointing to promising avenues for advanced optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04649v1</guid>
      <category>cs.SY</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaole Zhang, Peiyu Zhang, Xiongye Xiao, Shixuan Li, Vasileios Tzoumas, Vijay Gupta, Paul Bogdan</dc:creator>
    </item>
    <item>
      <title>Adversarially-Robust TD Learning with Markovian Data: Finite-Time Rates and Fundamental Limits</title>
      <link>https://arxiv.org/abs/2502.04662</link>
      <description>arXiv:2502.04662v1 Announce Type: cross 
Abstract: One of the most basic problems in reinforcement learning (RL) is policy evaluation: estimating the long-term return, i.e., value function, corresponding to a given fixed policy. The celebrated Temporal Difference (TD) learning algorithm addresses this problem, and recent work has investigated finite-time convergence guarantees for this algorithm and variants thereof. However, these guarantees hinge on the reward observations being always generated from a well-behaved (e.g., sub-Gaussian) true reward distribution. Motivated by harsh, real-world environments where such an idealistic assumption may no longer hold, we revisit the policy evaluation problem from the perspective of adversarial robustness. In particular, we consider a Huber-contaminated reward model where an adversary can arbitrarily corrupt each reward sample with a small probability $\epsilon$. Under this observation model, we first show that the adversary can cause the vanilla TD algorithm to converge to any arbitrary value function. We then develop a novel algorithm called Robust-TD and prove that its finite-time guarantees match that of vanilla TD with linear function approximation up to a small $O(\epsilon)$ term that captures the effect of corruption. We complement this result with a minimax lower bound, revealing that such an additive corruption-induced term is unavoidable. To our knowledge, these results are the first of their kind in the context of adversarial robustness of stochastic approximation schemes driven by Markov noise. The key new technical tool that enables our results is an analysis of the Median-of-Means estimator with corrupted, time-correlated data that might be of independent interest to the literature on robust statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04662v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sreejeet Maity, Aritra Mitra</dc:creator>
    </item>
    <item>
      <title>Effective multipliers for weights whose log are H\"older continuous. Application to the cost of fast boundary controls for the 1D Schr{\"o}dinger equation</title>
      <link>https://arxiv.org/abs/2502.04859</link>
      <description>arXiv:2502.04859v1 Announce Type: cross 
Abstract: We give a simple proof of the Beurling-Malliavin multiplier theorem (BM1) in the particular case of weights that verify the usual finite logarithmic integral condition and such that their log are H{\"o}lder continuous with exponent less than 1. Our proof has the advantage to give an explicit version of BM1, in the sense that one can give precise estimates from below and above for the multiplier, in terms of the exponential type we want to reach, and the constants appearing in the H{\"o}lder condition of our weights. The same ideas can be applied to a particular weight, that will lead to an improvement on the estimation of the cost of fast boundary controls for the 1D Schr{\"o}dinger equation on a segment. Our proof is mainly based on the use of a modified Hilbert transform together with its link with the harmonic extension in the complex upper half plane and some modified conjugate harmonic extension in the upper half plane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04859v1</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Lissy (CERMICS)</dc:creator>
    </item>
    <item>
      <title>Output-Feedback Full-State Targeting Model Predictive Control for Station-Keeping on Near-Rectilinear Halo Orbits</title>
      <link>https://arxiv.org/abs/2502.05013</link>
      <description>arXiv:2502.05013v1 Announce Type: cross 
Abstract: We develop a model predictive control (MPC) policy for station-keeping (SK) on a Near-Rectilinear Halo Orbit (NRHO). The proposed policy achieves full-state tracking of a reference NRHO via a two-maneuver control horizon placed one revolution apart. Our method abides by the typical mission requirement that at most one maneuver is used for SK during each NRHO revolution. Simultaneously, the policy has sufficient controllability for full-state tracking, making it immune to phase deviation issues in the along-track direction of the reference NRHO, a common drawback of existing SK methods with a single maneuver per revolution. We report numerical simulations with a navigation filter to demonstrate the MPC's performance with output feedback. Our approach successfully maintains the spacecraft's motion in the vicinity of the reference in both space and phase, with tighter tracking than state-of-the-art SK methods and comparable delta-V performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05013v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuri Shimane, Stefano Di Cairano, Koki Ho, Avishai Weiss</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency</title>
      <link>https://arxiv.org/abs/2502.05028</link>
      <description>arXiv:2502.05028v1 Announce Type: cross 
Abstract: Coordinating multiple agents to collaboratively maximize submodular functions in unpredictable environments is a critical task with numerous applications in machine learning, robot planning and control. The existing approaches, such as the OSG algorithm, are often hindered by their poor approximation guarantees and the rigid requirement for a fully connected communication graph. To address these challenges, we firstly present a $\textbf{MA-OSMA}$ algorithm, which employs the multi-linear extension to transfer the discrete submodular maximization problem into a continuous optimization, thereby allowing us to reduce the strict dependence on a complete graph through consensus techniques. Moreover, $\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoid sub-optimal stationary points. To eliminate the computationally intensive projection operations in $\textbf{MA-OSMA}$, we also introduce a projection-free $\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KL divergence by mixing a uniform distribution. Theoretically, we confirm that both algorithms achieve a regret bound of $\widetilde{O}(\sqrt{\frac{C_{T}T}{1-\beta}})$ against a $(\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where $C_{T}$ is the deviation of maximizer sequence, $\beta$ is the spectral gap of the network and $c$ is the joint curvature of submodular objectives. This result significantly improves the $(\frac{1}{1+c})$-approximation provided by the state-of-the-art OSG algorithm. Finally, we demonstrate the effectiveness of our proposed algorithms through simulation-based multi-target tracking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05028v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qixin Zhang, Zongqi Wan, Yu Yang, Li Shen, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>Preference-aware compensation policies for crowdsourced on-demand services</title>
      <link>https://arxiv.org/abs/2502.05060</link>
      <description>arXiv:2502.05060v1 Announce Type: cross 
Abstract: Crowdsourced on-demand services offer benefits such as reduced costs, faster service fulfillment times, greater adaptability, and contributions to sustainable urban transportation in on-demand delivery contexts. However, the success of an on-demand platform that utilizes crowdsourcing relies on finding a compensation policy that strikes a balance between creating attractive offers for gig workers and ensuring profitability. In this work, we examine a dynamic pricing problem for an on-demand platform that sets request-specific compensation of gig workers in a discrete-time framework, where requests and workers arrive stochastically. The operator's goal is to determine a compensation policy that maximizes the total expected reward over the time horizon. Our approach introduces compensation strategies that explicitly account for gig worker request preferences. To achieve this, we employ the Multinomial Logit model to represent the acceptance probabilities of gig workers, and, as a result, derive an analytical solution that utilizes post-decision states. Subsequently, we integrate this solution into an approximate dynamic programming algorithm. We compare our algorithm against benchmark algorithms, including formula-based policies and an upper bound provided by the full information linear programming solution. Our algorithm demonstrates consistent performance across diverse settings, achieving improvements of at least 2.5-7.5% in homogeneous gig worker populations and 9% in heterogeneous populations over benchmarks, based on fully synthetic data. For real-world data, it surpasses benchmarks by 8% in weak and 20% in strong location preference scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05060v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgina Nouli, Axel Parmentier, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>Nonlocal perimeters and variations: Extremality and decomposability for finite and infinite horizons</title>
      <link>https://arxiv.org/abs/2502.05149</link>
      <description>arXiv:2502.05149v1 Announce Type: cross 
Abstract: We analyze the extremality and decomposability properties with respect to two types of nonlocal perimeters available in the literature, the Gagliardo perimeter based on the eponymous seminorms and the nonlocal distributional Caccioppoli perimeter, both with finite and infinite interaction ranges. A nonlocal notion of indecomposability associated to these perimeters is introduced, and we prove that in both cases it can be characterized solely in terms of the interaction range or horizon $\varepsilon$. Utilizing this, we show that it is possible to uniquely decompose a set into its $\varepsilon$-connected components, establishing a nonlocal analogue of the decomposition theorem of Ambrosio, Caselles, Masnou and Morel. Moreover, the extreme points of the balls induced by the Gagliardo and nonlocal total variation seminorm are identified, which naturally correspond to the two nonlocal perimeters. Surprisingly, while the extreme points in the former case are normalized indicator functions of $\varepsilon$-simple sets, akin to the classical TV-ball, in the latter case they are instead obtained from a nonlocal transformation applied to the extreme points of the TV-ball. Finally, we explore the nonlocal-to-local transition via a $\Gamma$-limit as $\varepsilon \rightarrow 0$ for both perimeters, recovering the classical Caccioppoli perimeter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05149v1</guid>
      <category>math.FA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcello Carioni, Leonardo Del Grande, Jos\'e A. Iglesias, Hidde Sch\"onberger</dc:creator>
    </item>
    <item>
      <title>Network Design for the Traffic Assignment Problem with Mixed-Integer Frank-Wolfe</title>
      <link>https://arxiv.org/abs/2402.00166</link>
      <description>arXiv:2402.00166v3 Announce Type: replace 
Abstract: We tackle the network design problem for centralized traffic assignment, which can be cast as a mixed-integer convex optimization (MICO) problem. For this task, we propose different formulations and solution methods in both a deterministic and a stochastic setting in which the demand is unknown in the design phase. We leverage the recently proposed Boscia framework, which can solve MICO problems when the main nonlinearity stems from a differentiable objective function. Boscia tackles these problems by branch-and-bound with continuous relaxations solved approximately with Frank-Wolfe algorithms. We compare different linear relaxations and the corresponding subproblems solved by Frank-Wolfe, and alternative problem formulations to identify the situations in which each performs best. Our experiments evaluate the different approaches on instances from the Transportation Networks library and highlight the suitability of the mixed-integer Frank-Wolfe algorithm for this problem. In particular, we find that the Boscia framework is particularly applicable to this problem and that a mixed-integer linear Frank-Wolfe subproblem performs well for the deterministic case, while a penalty-based approach, with decoupled feasible regions for the design and flow variables, dominates other approaches for stochastic instances with many scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00166v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kartikey Sharma, Deborah Hendrych, Mathieu Besan\c{c}on, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Decentralized Finite-Sum Optimization over Time-Varying Networks</title>
      <link>https://arxiv.org/abs/2402.02490</link>
      <description>arXiv:2402.02490v3 Announce Type: replace 
Abstract: We consider decentralized time-varying stochastic optimization problems where each of the functions held by the nodes has a finite sum structure. Such problems can be efficiently solved using variance reduction techniques. Our aim is to explore the lower complexity bounds (for communication and number of stochastic oracle calls) and find optimal algorithms. The paper studies strongly convex and nonconvex scenarios. To the best of our knowledge, variance reduced schemes and lower bounds for time-varying graphs have not been studied in the literature. For nonconvex objectives, we obtain lower bounds and develop an optimal method GT-PAGE. For strongly convex objectives, we propose the first decentralized time-varying variance-reduction method ADOM+VR and establish lower bound in this scenario, highlighting the open question of matching the algorithms complexity and lower bounds even in static network case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02490v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Metelev, Savelii Chezhegov, Alexander Rogozin, Aleksandr Beznosikov, Alexander Sholokhov, Alexander Gasnikov, Dmitry Kovalev</dc:creator>
    </item>
    <item>
      <title>Approximation of shape optimization problems with non-smooth PDE constraints</title>
      <link>https://arxiv.org/abs/2406.15146</link>
      <description>arXiv:2406.15146v5 Announce Type: replace 
Abstract: This paper is concerned with a shape optimization problem governed by a non-smooth PDE, i.e., the nonlinearity in the state equation is not necessarily differentiable. We follow the functional variational approach of [40] where the set of admissible shapes is parametrized by a large class of continuous mappings. This methodology allows for both boundary and topological variations. It has the advantage that one can rewrite the shape optimization problem as a control problem in a function space. To overcome the lack of convexity of the set of admissible controls, we provide an essential density property. This permits us to show that each parametrization associated to the optimal shape is the limit of global optima of non-smooth distributed optimal control problems. The admissible set of the approximating minimization problems is a convex subset of a Hilbert space of functions. Moreover, its structure is such that one can derive strong stationary optimality conditions [6]. The present manuscript provides the basis for the investigations from [5], where necessary conditions in form of an optimality system have been recently established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15146v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Livia Betz</dc:creator>
    </item>
    <item>
      <title>A Fast and Effective Breakpoints Heuristic Algorithm for the Quadratic Knapsack Problem</title>
      <link>https://arxiv.org/abs/2408.12183</link>
      <description>arXiv:2408.12183v2 Announce Type: replace 
Abstract: The Quadratic Knapsack Problem (QKP) involves selecting a subset of elements that maximizes the sum of pairwise and singleton utilities without exceeding a given budget. The pairwise utilities are nonnegative, the singleton utilities may be positive, negative, or zero, and the node costs are nonnegative. We introduce a Breakpoints Algorithm for QKP, named QKBP, which is based on a technique proposed in \cite{Hoc09} for efficiently generating the concave envelope of the solutions to the relaxation of the problem for all values of the budget. Our approach utilizes the fact that breakpoints in the concave envelopes are optimal solutions for their respective budgets. For budgets between breakpoints, a fast greedy heuristic derives high-quality solutions from the optimal solutions of adjacent breakpoints. The QKBP algorithm is a heuristic which is highly scalable due to an efficient parametric cut procedure used to generate the concave envelope. This efficiency is further improved by a newly developed compact problem formulation. Our extensive computational study on both existing and new benchmark instances, with up to 10,000 elements, shows that while some leading algorithms perform well on a few instances, QKBP consistently delivers high-quality solutions regardless of instance size, density, or budget. Moreover, QKBP achieves these results in significantly faster running times than all leading algorithms. The source code of the QKBP algorithm, the benchmark instances, and the detailed results are publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12183v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2024.12.019</arxiv:DOI>
      <dc:creator>Dorit S. Hochbaum, Philipp Baumann, Olivier Goldschmidt, Yiqing Zhang</dc:creator>
    </item>
    <item>
      <title>Faster Acceleration for Steepest Descent</title>
      <link>https://arxiv.org/abs/2409.19200</link>
      <description>arXiv:2409.19200v2 Announce Type: replace 
Abstract: Recent advances (Sherman, 2017; Sidford and Tian, 2018; Cohen et al., 2021) have overcome the fundamental barrier of dimension dependence in the iteration complexity of solving $\ell_\infty$ regression with first-order methods. Yet it remains unclear to what extent such acceleration can be achieved for general $\ell_p$ smooth functions. In this paper, we propose a new accelerated first-order method for convex optimization under non-Euclidean smoothness assumptions. In contrast to standard acceleration techniques, our approach uses primal-dual iterate sequences taken with respect to $\textit{differing}$ norms, which are then coupled using an $\textit{implicitly}$ determined interpolation parameter. For $\ell_p$ norm smooth problems in $d$ dimensions, our method provides an iteration complexity improvement of up to $O(d^{1-\frac{2}{p}})$ in terms of calls to a first-order oracle, thereby allowing us to circumvent long-standing barriers in accelerated non-Euclidean steepest descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19200v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Site Bai, Brian Bullins</dc:creator>
    </item>
    <item>
      <title>GCBF+: A Neural Graph Control Barrier Function Framework for Distributed Safe Multi-Agent Control</title>
      <link>https://arxiv.org/abs/2401.14554</link>
      <description>arXiv:2401.14554v4 Announce Type: replace-cross 
Abstract: Distributed, scalable, and safe control of large-scale multi-agent systems is a challenging problem. In this paper, we design a distributed framework for safe multi-agent control in large-scale environments with obstacles, where a large number of agents are required to maintain safety using only local information and reach their goal locations. We introduce a new class of certificates, termed graph control barrier function (GCBF), which are based on the well-established control barrier function theory for safety guarantees and utilize a graph structure for scalable and generalizable distributed control of MAS. We develop a novel theoretical framework to prove the safety of an arbitrary-sized MAS with a single GCBF. We propose a new training framework GCBF+ that uses graph neural networks to parameterize a candidate GCBF and a distributed control policy. The proposed framework is distributed and is capable of taking point clouds from LiDAR, instead of actual state information, for real-world robotic applications. We illustrate the efficacy of the proposed method through various hardware experiments on a swarm of drones with objectives ranging from exchanging positions to docking on a moving target without collision. Additionally, we perform extensive numerical experiments, where the number and density of agents, as well as the number of obstacles, increase. Empirical results show that in complex environments with agents with nonlinear dynamics (e.g., Crazyflie drones), GCBF+ outperforms the hand-crafted CBF-based method with the best performance by up to 20% for relatively small-scale MAS with up to 256 agents, and leading reinforcement learning (RL) methods by up to 40% for MAS with 1024 agents. Furthermore, the proposed method does not compromise on the performance, in terms of goal reaching, for achieving high safety rates, which is a common trade-off in RL-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14554v4</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TRO.2025.3530348</arxiv:DOI>
      <dc:creator>Songyuan Zhang, Oswin So, Kunal Garg, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>Safety-Critical Planning and Control for Dynamic Obstacle Avoidance Using Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2403.19122</link>
      <description>arXiv:2403.19122v3 Announce Type: replace-cross 
Abstract: Dynamic obstacle avoidance is a challenging topic for optimal control and optimization-based trajectory planning problems. Many existing works use Control Barrier Functions (CBFs) to enforce safety constraints for control systems. CBFs are typically formulated based on the distance to obstacles, or integrated with path planning algorithms as a safety enhancement tool. However, these approaches usually require knowledge of the obstacle boundary equations or have very slow computational efficiency. In this paper, we propose a framework based on model predictive control (MPC) with discrete-time high-order CBFs (DHOCBFs) to generate a collision-free trajectory. The DHOCBFs are first obtained from convex polytopes generated through grid mapping, without the need to know the boundary equations of obstacles. Additionally, a path planning algorithm is incorporated into this framework to ensure the global optimality of the generated trajectory. We demonstrate through numerical examples that our framework allows a unicycle robot to safely and efficiently navigate tight, dynamically changing environments with both convex and nonconvex obstacles. By comparing our method to established CBF-based benchmarks, we demonstrate superior computing efficiency, length optimality, and feasibility in trajectory generation and obstacle avoidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19122v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Yihui Mao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>Balanced truncation with conformal maps</title>
      <link>https://arxiv.org/abs/2405.15656</link>
      <description>arXiv:2405.15656v2 Announce Type: replace-cross 
Abstract: We consider the problem of constructing reduced models for large scale systems with poles in general domains in the complex plane (as opposed to, e.g., the open left-half plane or the open unit disk). Our goal is to design a model reduction scheme, building upon theoretically established methodologies, yet encompassing this new class of models. To this aim, we develop a balanced truncation framework through conformal maps to handle poles in general domains. The major difference from classical balanced truncation resides in the formulation of the Gramians. We show that these new Gramians can still be computed by solving modified Lyapunov equations for specific conformal maps. A numerical algorithm to perform balanced truncation with conformal maps is developed and is tested on three numerical examples, namely a heat model, the Schr\"odinger equation, and the undamped linear wave equation, the latter two having spectra on the imaginary axis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15656v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Borghi, Tobias Breiten, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Accuracy of the Ensemble Kalman Filter in the Near-Linear Setting</title>
      <link>https://arxiv.org/abs/2409.09800</link>
      <description>arXiv:2409.09800v2 Announce Type: replace-cross 
Abstract: The filtering distribution captures the statistics of the state of a dynamical system from partial and noisy observations. Classical particle filters provably approximate this distribution in quite general settings; however they behave poorly for high dimensional problems, suffering weight collapse. This issue is circumvented by the ensemble Kalman filter which is an equal-weight interacting particle system. However, this finite particle system is only proven to approximate the true filter in the linear Gaussian case. In practice, however, it is applied in much broader settings; as a result, establishing its approximation properties more generally is important. There has been recent progress in the theoretical analysis of the algorithm, establishing stability and error estimates in non-Gaussian settings, but the assumptions on the dynamics and observation models rule out the unbounded vector fields that arise in practice and the analysis applies only to the mean field limit of the ensemble Kalman filter. The present work establishes error bounds between the filtering distribution and the finite particle ensemble Kalman filter when the dynamics and observation vector fields may be unbounded, allowing linear growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09800v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Calvello, Pierre Monmarch\'e, Andrew M. Stuart, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Chorded cycle facets of the clique partitioning polytope</title>
      <link>https://arxiv.org/abs/2411.03407</link>
      <description>arXiv:2411.03407v2 Announce Type: replace-cross 
Abstract: The $q$-chorded $k$-cycle inequalities are a class of valid inequalities for the clique partitioning polytope. It is known that for $q \in \{2, \tfrac{k-1}{2}\}$, these inequalities induce facets of the clique partitioning polytope if and only if $k$ is odd. Here, we characterize such facets for arbitrary $k$ and $q$. More specifically, we prove that the $q$-chorded $k$-cycle inequalities induce facets of the clique partitioning polytope if and only if two conditions are satisfied: $k = 1$ mod $q$, and if $k=3q+1$ then $q=3$ or $q$ is even. This establishes the existence of many facets induced by $q$-chorded $k$-cycle inequalities beyond those previously known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03407v2</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannik Irmai, Lucas Fabian Naumann, Bjoern Andres</dc:creator>
    </item>
    <item>
      <title>Online Experimental Design With Estimation-Regret Trade-off Under Network Interference</title>
      <link>https://arxiv.org/abs/2412.03727</link>
      <description>arXiv:2412.03727v2 Announce Type: replace-cross 
Abstract: Network interference has attracted significant attention in the field of causal inference, encapsulating various sociological behaviors where the treatment assigned to one individual within a network may affect the outcomes of others, such as their neighbors. A key challenge in this setting is that standard causal inference methods often assume independent treatment effects among individuals, which may not hold in networked environments. To estimate interference-aware causal effects, a traditional approach is to inherit the independent settings, where practitioners randomly assign experimental participants into different groups and compare their outcomes. While effective in offline settings, this strategy becomes problematic in sequential experiments, where suboptimal decision persists, leading to substantial regret. To address this issue, we introduce a unified interference-aware framework for online experimental design. Compared to existing studies, we extend the definition of arm space by utilizing the statistical concept of exposure mapping, which allows for a more flexible and context-aware representation of treatment effects in networked settings. Crucially, we establish a Pareto-optimal trade-off between estimation accuracy and regret under the network concerning both time period and arm space, which remains superior to baseline models even without network interference. Furthermore, we propose an algorithmic implementation and discuss its generalization across different learning settings and network topology</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03727v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiheng Zhang, Zichen Wang</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Min-Max Langevin Dynamics and Algorithm</title>
      <link>https://arxiv.org/abs/2412.20471</link>
      <description>arXiv:2412.20471v2 Announce Type: replace-cross 
Abstract: We study zero-sum games in the space of probability distributions over the Euclidean space $\mathbb{R}^d$ with entropy regularization, in the setting when the interaction function between the players is smooth and strongly convex-strongly concave. We prove an exponential convergence guarantee for the mean-field min-max Langevin dynamics to compute the equilibrium distribution of the zero-sum game. We also study the finite-particle approximation of the mean-field min-max Langevin dynamics, both in continuous and discrete times. We prove biased convergence guarantees for the continuous-time finite-particle min-max Langevin dynamics to the stationary mean-field equilibrium distribution with an explicit bias term which does not scale with the number of particles. We also prove biased convergence guarantees for the discrete-time finite-particle min-max Langevin algorithm to the stationary mean-field equilibrium distribution with an additional bias term which scales with the step size and the number of particles. This provides an explicit iteration complexity for the average particle along the finite-particle algorithm to approximately compute the equilibrium distribution of the zero-sum game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20471v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cai, Siddharth Mitra, Xiuyuan Wang, Andre Wibisono</dc:creator>
    </item>
  </channel>
</rss>
