<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Jul 2024 04:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generalizing self-normalized importance sampling with couplings</title>
      <link>https://arxiv.org/abs/2406.19974</link>
      <description>arXiv:2406.19974v1 Announce Type: new 
Abstract: An essential problem in statistics and machine learning is the estimation of expectations involving PDFs with intractable normalizing constants. The self-normalized importance sampling (SNIS) estimator, which normalizes the IS weights, has become the standard approach due to its simplicity. However, the SNIS has been shown to exhibit high variance in challenging estimation problems, e.g, involving rare events or posterior predictive distributions in Bayesian statistics. Further, most of the state-of-the-art adaptive importance sampling (AIS) methods adapt the proposal as if the weights had not been normalized. In this paper, we propose a framework that considers the original task as estimation of a ratio of two integrals. In our new formulation, we obtain samples from a joint proposal distribution in an extended space, with two of its marginals playing the role of proposals used to estimate each integral. Importantly, the framework allows us to induce and control a dependency between both estimators. We propose a construction of the joint proposal that decomposes in two (multivariate) marginals and a coupling. This leads to a two-stage framework suitable to be integrated with existing or new AIS and/or variational inference (VI) algorithms. The marginals are adapted in the first stage, while the coupling can be chosen and adapted in the second stage. We show in several examples the benefits of the proposed methodology, including an application to Bayesian prediction with misspecified models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19974v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Branchini, V\'ictor Elvira</dc:creator>
    </item>
    <item>
      <title>Exact Bayesian Gaussian Cox Processes Using Random Integral</title>
      <link>https://arxiv.org/abs/2406.19722</link>
      <description>arXiv:2406.19722v1 Announce Type: cross 
Abstract: A Gaussian Cox process is a popular model for point process data, in which the intensity function is a transformation of a Gaussian process. Posterior inference of this intensity function involves an intractable integral (i.e., the cumulative intensity function) in the likelihood resulting in doubly intractable posterior distribution. Here, we propose a nonparametric Bayesian approach for estimating the intensity function of an inhomogeneous Poisson process without reliance on large data augmentation or approximations of the likelihood function. We propose to jointly model the intensity and the cumulative intensity function as a transformed Gaussian process, allowing us to directly bypass the need of approximating the cumulative intensity function in the likelihood. We propose an exact MCMC sampler for posterior inference and evaluate its performance on simulated data. We demonstrate the utility of our method in three real-world scenarios including temporal and spatial event data, as well as aggregated time count data collected at multiple resolutions. Finally, we discuss extensions of our proposed method to other point processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19722v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingjing Tang, Julia Palacios</dc:creator>
    </item>
    <item>
      <title>Electrostatics-based particle sampling and approximate inference</title>
      <link>https://arxiv.org/abs/2406.20044</link>
      <description>arXiv:2406.20044v1 Announce Type: cross 
Abstract: A new particle-based sampling and approximate inference method, based on electrostatics and Newton mechanics principles, is introduced with theoretical ground, algorithm design and experimental validation. This method simulates an interacting particle system (IPS) where particles, i.e. the freely-moving negative charges and spatially-fixed positive charges with magnitudes proportional to the target distribution, interact with each other via attraction and repulsion induced by the resulting electric fields described by Poisson's equation. The IPS evolves towards a steady-state where the distribution of negative charges conforms to the target distribution. This physics-inspired method offers deterministic, gradient-free sampling and inference, achieving comparable performance as other particle-based and MCMC methods in benchmark tasks of inferring complex densities, Bayesian logistic regression and dynamical system identification. A discrete-time, discrete-space algorithmic design, readily extendable to continuous time and space, is provided for usage in more general inference problems occurring in probabilistic machine learning scenarios such as Bayesian inference, generative modelling, and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.20044v1</guid>
      <category>cs.AI</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yongchao Huang</dc:creator>
    </item>
    <item>
      <title>Covariance Expressions for Multi-Fidelity Sampling with Multi-Output, Multi-Statistic Estimators: Application to Approximate Control Variates</title>
      <link>https://arxiv.org/abs/2310.00125</link>
      <description>arXiv:2310.00125v2 Announce Type: replace 
Abstract: We provide a collection of results on covariance expressions between Monte Carlo based multi-output mean, variance, and Sobol main effect variance estimators from an ensemble of models. These covariances can be used within multi-fidelity uncertainty quantification strategies that seek to reduce the estimator variance of high-fidelity Monte Carlo estimators with an ensemble of low-fidelity models. Such covariance expressions are required within approaches like the approximate control variate and multi-level best linear unbiased estimator. While the literature provides these expressions for some single-output cases such as mean and variance, our results are relevant to both multiple function outputs and multiple statistics across any sampling strategy. Following the description of these results, we use them within an approximate control variate scheme to show that leveraging multiple outputs can dramatically reduce estimator variance compared to single-output approaches. Synthetic examples are used to highlight the effects of optimal sample allocation and pilot sample estimation. A flight-trajectory simulation of entry, descent, and landing is used to demonstrate multi-output estimation in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00125v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas O. Dixon, James E. Warner, Geoffrey F. Bomarito, Alex A. Gorodetsky</dc:creator>
    </item>
    <item>
      <title>Markov chain Monte Carlo without evaluating the target: an auxiliary variable approach</title>
      <link>https://arxiv.org/abs/2406.05242</link>
      <description>arXiv:2406.05242v2 Announce Type: replace 
Abstract: In sampling tasks, it is common for target distributions to be known up to a normalising constant. However, in many situations, evaluating even the unnormalised distribution can be costly or infeasible. This issue arises in scenarios such as sampling from the Bayesian posterior for tall datasets and the 'doubly-intractable' distributions. In this paper, we begin by observing that seemingly different Markov chain Monte Carlo (MCMC) algorithms, such as the exchange algorithm, PoissonMH, and TunaMH, can be unified under a simple common procedure. We then extend this procedure into a novel framework that allows the use of auxiliary variables in both the proposal and acceptance-rejection steps. We develop the theory of the new framework, applying it to existing algorithms to simplify and extend their results. Several new algorithms emerge from this framework, with improved performance demonstrated on both synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05242v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Yuan, Guanyang Wang</dc:creator>
    </item>
    <item>
      <title>A Spatial-statistical model to analyse historical rutting data</title>
      <link>https://arxiv.org/abs/2401.03633</link>
      <description>arXiv:2401.03633v3 Announce Type: replace-cross 
Abstract: Pavement rutting poses a significant challenge in flexible pavements, necessitating costly asphalt resurfacing. To address this issue comprehensively, we propose an advanced Bayesian hierarchical framework of latent Gaussian models with spatial components. Our model provides a thorough diagnostic analysis, pinpointing areas exhibiting unexpectedly high rutting rates. Incorporating spatial and random components, and important explanatory variables like annual average daily traffic (traffic intensity), asphalt type, rut depth and lane width, our proposed models account for and estimate the influence of these variables on rutting. This approach not only quantifies uncertainties and discerns locations at the highest risk of requiring maintenance, but also uncover spatial dependencies in rutting (millimetre/year). We apply our models to a data set spanning eleven years (2010-2020). Our findings emphasise the systematic unexplained spatial rutting effect, where some of the rutting variability is accounted for by spatial components, asphalt type, in conjunction with traffic intensity, is also found to be the primary driver of rutting. Furthermore, the spatial dependencies uncovered reveal road sections experiencing more than 1 millimeter of rutting beyond annual expectations. This leads to a halving of the expected pavement lifespan in these areas. Our study offers valuable insights, presenting maps indicating expected rutting, and identifying locations with accelerated rutting rates, resulting in a reduction in pavement life expectancy of at least 10 years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03633v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natoya O. A. S. Jourdain, Ingelin Steinsland, Mamoona Birkhez-Shami, Emil Vedvik, William Olsen, Dagfin Gryteselv, Doreen Siebert, Alex Klein-Paste</dc:creator>
    </item>
    <item>
      <title>Weighted Particle-Based Optimization for Efficient Generalized Posterior Calibration</title>
      <link>https://arxiv.org/abs/2405.04845</link>
      <description>arXiv:2405.04845v3 Announce Type: replace-cross 
Abstract: In the realm of statistical learning, the increasing volume of accessible data and increasing model complexity necessitate robust methodologies. This paper explores two branches of robust Bayesian methods in response to this trend. The first is generalized Bayesian inference, which introduces a learning rate parameter to enhance robustness against model misspecifications. The second is Gibbs posterior inference, which formulates inferential problems using generic loss functions rather than probabilistic models. In such approaches, it is necessary to calibrate the spread of the posterior distribution by selecting a learning rate parameter. The study aims to enhance the generalized posterior calibration (GPC) algorithm proposed by [1]. Their algorithm chooses the learning rate to achieve the nominal frequentist coverage probability, but it is computationally intensive because it requires repeated posterior simulations for bootstrap samples. We propose a more efficient version of the GPC inspired by sequential Monte Carlo (SMC) samplers. A target distribution with a different learning rate is evaluated without posterior simulation as in the reweighting step in SMC sampling. Thus, the proposed algorithm can reach the desirable value within a few iterations. This improvement substantially reduces the computational cost of the GPC. Its efficacy is demonstrated through synthetic and real data applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04845v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Tanaka</dc:creator>
    </item>
  </channel>
</rss>
