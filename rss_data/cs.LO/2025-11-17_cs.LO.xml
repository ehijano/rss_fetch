<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Nov 2025 04:05:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Knowledge Reasoning Involving Four Types of Syllogisms</title>
      <link>https://arxiv.org/abs/2511.10916</link>
      <description>arXiv:2511.10916v1 Announce Type: new 
Abstract: This paper studies the validity and discourse reasoning of non-trivial generalized syllogisms involving the quantifiers in Square{most} and Square{all} from the perspective of knowledge reasoning. Firstly, this paper presents knowledge representations for these syllogisms and formally proves the validity of generalized syllogism AMI-1. Subsequently, 19 non-trivial generalized syllogisms, 22 non-trivial valid generalized modal syllogisms, 8 valid classical syllogisms, and 24 valid classical modal syllogisms are respectively deduced from the valid generalized syllogism AMI-1 on the basis of deductive reasoning. Additionally, this paper discusses how to judge the validity of discourse reasoning nested by the above four types of syllogisms, which have four types of figures and different forms. In conclusion, such formal deductions not only provide a theoretical foundation for English language information processing, but also provide methodological insights for studying other syllogistic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10916v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Wei, Liheng Hao</dc:creator>
    </item>
    <item>
      <title>Arity hierarchies for quantifiers closed under partial polymorphisms</title>
      <link>https://arxiv.org/abs/2511.11326</link>
      <description>arXiv:2511.11326v1 Announce Type: new 
Abstract: We investigate the expressive power of generalized quantifiers closed under partial polymorphism conditions motivated by the study of constraint satisfaction problems. We answer a number of questions arising from the work of Dawar and Hella (CSL 2024) where such quantifiers were introduced. For quantifiers closed under partial near-unanimity polymorphisms, we establish hierarchy results clarifying the interplay between the arity of the polymorphisms and of the quantifiers: The expressive power of $(\ell+1)$-ary quantifiers closed under $\ell$-ary partial near-unanimity polymorphisms is strictly between the class of all quantifiers of arity $\ell-1$ and $\ell$. We also establish an infinite hierarchy based on the arity of quantifiers with a fixed arity of partial near-unanimity polymorphisms. Finally, we prove inexpressiveness results for quantifiers with a partial Maltsev polymorphism. The separation results are proved using novel algebraic constructions in the style of Cai-F\"urer-Immerman and the quantifier pebble games of Dawar and Hella (2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11326v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuj Dawar, Lauri Hella, Benedikt Pago</dc:creator>
    </item>
    <item>
      <title>Universal Safety Controllers with Learned Prophecies</title>
      <link>https://arxiv.org/abs/2511.11390</link>
      <description>arXiv:2511.11390v1 Announce Type: new 
Abstract: \emph{Universal Safety Controllers (USCs)} are a promising logical control framework that guarantees the satisfaction of a given temporal safety specification when applied to any realizable plant model. Unlike traditional methods, which synthesize one logical controller over a given detailed plant model, USC synthesis constructs a \emph{generic controller} whose outputs are conditioned by plant behavior, called \emph{prophecies}. Thereby, USCs offer strong generalization and scalability benefits over classical logical controllers. However, the exact computation and verification of prophecies remain computationally challenging. In this paper, we introduce an approximation algorithm for USC synthesis that addresses these limitations via learning. Instead of computing exact prophecies, which reason about sets of trees via automata, we only compute under- and over-approximations from (small) example plants and infer computation tree logic (CTL) formulas as representations of prophecies. The resulting USC generalizes to unseen plants via a verification step and offers improved efficiency and explainability through small and concise CTL prophecies, which remain human-readable and interpretable. Experimental results demonstrate that our learned prophecies remain generalizable, yet are significantly more compact and interpretable than their exact tree automata representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11390v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernd Finkbeiner, Niklas Metzger, Satya Prakash Nayak, Anne-Kathrin Schmuck</dc:creator>
    </item>
    <item>
      <title>Towards Assume-Guarantee Verification of Abilities in Stochastic Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2511.10649</link>
      <description>arXiv:2511.10649v1 Announce Type: cross 
Abstract: Model checking of strategic abilities is a notoriously hard problem, even more so in the realistic case of agents with imperfect information, acting in a stochastic environment. Assume-guarantee reasoning can be of great help here, providing a way to decompose the complex problem into a small set of easier subproblems.
  In this paper, we propose several schemes for assume-guarantee verification of probabilistic alternating-time temporal logic with imperfect information. We prove the soundness of the schemes, and discuss their completeness. On the way, we also propose a new variant of (non-probabilistic) alternating-time logic, where the strategic modalities capture "achieving at most $\varphi$," analogous to Levesque's logic of "only knowing."</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10649v1</guid>
      <category>cs.MA</category>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wojciech Jamroga, Damian Kurpiewski, {\L}ukasz Mikulski</dc:creator>
    </item>
    <item>
      <title>From Proof to Program: Characterizing Tool-Induced Reasoning Hallucinations in Large Language Models</title>
      <link>https://arxiv.org/abs/2511.10899</link>
      <description>arXiv:2511.10899v1 Announce Type: cross 
Abstract: Tool-augmented Language Models (TaLMs) can invoke external tools to solve problems beyond their parametric capacity. However, it remains unclear whether these tool-enabled gains reflect trustworthy reasoning. Focusing on the Code Interpreter tool, we show that even when tools are selected and executed correctly, TaLMs treat tool outputs as substitutes for reasoning, producing solutions that appear correct but lack coherent justification. We term this failure mode Tool-Induced Myopia (TIM), and study it using PYMATH, a benchmark of 1,679 competition-level mathematical problems for which Python code is helpful but not sufficient. We further develop a multi-dimensional evaluation suite to quantify reasoning degradation in TaLMs relative to their non-tool counterparts. Our findings reveal that while TaLMs achieve up to a 19.3 percentage point gain in final-answer accuracy, their reasoning behavior consistently deteriorates (e.g., non-tool LLMs win up to 41.5% more often in pairwise comparisons of the reasoning process). This degradation intensifies with tool use; the more frequently a model invokes tools, the less coherent its reasoning becomes. Moreover, tool use shifts errors from arithmetic mistakes toward global reasoning failures (logic, assumption, creativity); with TIM present in ~55% of high-risk cases. Finally, we propose a preference-optimization-based framework that realigns TaLMs to use tools as assistive evidence, improving both final-answer accuracy and reasoning depth under tool use. Codes and data are available at: https://github.com/megagonlabs/TIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10899v1</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farima Fatahi Bayat, Pouya Pezeshkpour, Estevam Hruschka</dc:creator>
    </item>
    <item>
      <title>Automata-less Monitoring via Trace-Checking (Extended Version)</title>
      <link>https://arxiv.org/abs/2511.11072</link>
      <description>arXiv:2511.11072v1 Announce Type: cross 
Abstract: In runtime verification, monitoring consists of analyzing the current execution of a system and determining, on the basis of the observed finite trace, whether all its possible continuations satisfy or violate a given specification. This is typically done by synthesizing a monitor--often a Deterministic Finite State Automaton (DFA)--from logical specifications expressed in Linear Temporal Logic (LTL) or in its finite-word variant (LTLf). Unfortunately, the size of the resulting DFA may incur a doubly exponential blow-up in the size of the formula. In this paper, we identify some conditions under which monitoring can be done without constructing such a DFA. We build on the notion of intentionally safe and cosafe formulas, introduced in [Kupferman &amp; Vardi, FMSD, 2001], to show that monitoring of these formulas can be carried out through trace-checking, that is, by directly evaluating them on the current system trace, with a polynomial complexity in the size of both the trace and the formula. In addition, we investigate the complexity of recognizing intentionally safe and cosafe formulas for the safety and cosafety fragments of LTL and LTLf. As for LTLf, we show that all formulas in these fragments are intentionally safe and cosafe, thus removing the need for the check. As for LTL, we prove that the problem is in PSPACE, significantly improving over the EXPSPACE complexity of full LTL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11072v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Brunello, Luca Geatti, Angelo Montanari, Nicola Saccomanno</dc:creator>
    </item>
    <item>
      <title>Can You Tell the Difference? Contrastive Explanations for ABox Entailments</title>
      <link>https://arxiv.org/abs/2511.11281</link>
      <description>arXiv:2511.11281v1 Announce Type: cross 
Abstract: We introduce the notion of contrastive ABox explanations to answer questions of the type "Why is a an instance of C, but b is not?". While there are various approaches for explaining positive entailments (why is C(a) entailed by the knowledge base) as well as missing entailments (why is C(b) not entailed) in isolation, contrastive explanations consider both at the same time, which allows them to focus on the relevant commonalities and differences between a and b. We develop an appropriate notion of contrastive explanations for the special case of ABox reasoning with description logic ontologies, and analyze the computational complexity for different variants under different optimality criteria, considering lightweight as well as more expressive description logics. We implemented a first method for computing one variant of contrastive explanations, and evaluated it on generated problems for realistic knowledge bases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11281v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Koopmann, Yasir Mahmood, Axel-Cyrille Ngonga Ngomo, Balram Tiwari</dc:creator>
    </item>
    <item>
      <title>On Polynomial-Time Decidability of k-Negations Fragments of First-Order Theories</title>
      <link>https://arxiv.org/abs/2407.18420</link>
      <description>arXiv:2407.18420v2 Announce Type: replace 
Abstract: This paper introduces a generic framework that provides sufficient conditions for guaranteeing polynomial-time decidability of fixed-negation fragments of first-order theories that adhere to certain fixed-parameter tractability requirements. It enables deciding sentences of such theories with arbitrary existential quantification, conjunction and a fixed number of negation symbols in polynomial time. It was recently shown by Nguyen and Pak [SIAM J. Comput. 51(2): 1--31 (2022)] that an even more restricted such fragment of Presburger arithmetic (the first-order theory of the integers with addition and order) is NP-hard. In contrast, by application of our framework, we show that the fixed negation fragment of weak Presburger arithmetic, which drops the order relation from Presburger arithmetic in favour of equality, is decidable in polynomial time. We give two further examples of instantiations of our framework, showing polynomial-time decidability of the fixed negation fragments of weak linear real arithmetic and of the restriction of Presburger arithmetic in which each inequality contains at most one variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18420v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Haase, Alessio Mansutti, Amaury Pouly</dc:creator>
    </item>
    <item>
      <title>Contextual Refinement of Higher-Order Concurrent Probabilistic Programs</title>
      <link>https://arxiv.org/abs/2511.10135</link>
      <description>arXiv:2511.10135v2 Announce Type: replace 
Abstract: We present Foxtrot, the first higher-order separation logic for proving contextual refinement of higher-order concurrent probabilistic programs with higher-order local state. From a high level, Foxtrot inherits various concurrency reasoning principles from standard concurrent separation logic, e.g. invariants and ghost resources, and supports advanced probabilistic reasoning principles for reasoning about complex probability distributions induced by concurrent threads, e.g. tape presampling and induction by error amplification. The integration of these strong reasoning principles is highly non-trivial due to the combination of probability and concurrency in the language and the complexity of the Foxtrot model; the soundness of the logic relies on a version of the axiom of choice within the Iris logic, which is not used in earlier work on Iris-based logics. We demonstrate the expressiveness of Foxtrot on a wide range of examples, including the adversarial von Neumann coin and the $\mathsf{randombytes\_uniform}$ function of the Sodium cryptography software library.
  All results have been mechanized in the Rocq proof assistant and the Iris separation logic framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10135v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwing Hei Li, Alejandro Aguirre, Joseph Tassarotti, Lars Birkedal</dc:creator>
    </item>
    <item>
      <title>Work-Efficient Query Evaluation with PRAMs</title>
      <link>https://arxiv.org/abs/2301.08178</link>
      <description>arXiv:2301.08178v3 Announce Type: replace-cross 
Abstract: The article studies query evaluation in parallel constant time in the CRCW PRAM model. While it is well-known that all relational algebra queries can be evaluated in constant time on an appropriate CRCW PRAM model, this article is interested in the efficiency of evaluation algorithms, that is, in the number of processors or, asymptotically equivalent, in the work. Naive evaluation in the parallel setting results in huge (polynomial) bounds on the work of such algorithms and in presentations of the result sets that can be extremely scattered in memory. The article discusses some obstacles for constant-time PRAM query evaluation. It presents algorithms for relational operators and explores three settings, in which efficient sequential query evaluation algorithms exist: acyclic queries, semijoin algebra queries, and join queries -- the latter in the worst-case optimal framework. Under mild assumptions -- that data values are numbers of polynomial size in the size of the database or that the relations of the database are suitably sorted -- constant-time algorithms are presented that are weakly work-efficient in the sense that work $\mathcal{O}(T^{1+\varepsilon})$ can be achieved, for every $\varepsilon&gt;0$, compared to the time $T$ of an optimal sequential algorithm. Important tools are the algorithms for approximate prefix sums and compaction from Goldberg and Zwick (1995).</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08178v3</guid>
      <category>cs.DB</category>
      <category>cs.LO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens Keppeler, Thomas Schwentick, Christopher Spinrath</dc:creator>
    </item>
  </channel>
</rss>
