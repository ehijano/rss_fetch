<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Aug 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An improved local search based algorithm for $k^-$-star partition</title>
      <link>https://arxiv.org/abs/2508.09361</link>
      <description>arXiv:2508.09361v1 Announce Type: new 
Abstract: We study the $k^-$-star partition problem that aims to find a minimum collection of vertex-disjoint stars, each having at most $k$ vertices to cover all vertices in a simple undirected graph $G = (V, E)$. Our main contribution is an improved $O(|V|^3)$-time $(\frac k2 - \frac {k-2}{8k-14})$-approximation algorithm.
  Our algorithm starts with a $k^-$-star partition with the least $1$-stars and a key idea is to distinguish critical vertices, each of which is either in a $2$-star or is the center of a $3$-star in the current solution. Our algorithm iteratively updates the solution by three local search operations so that the vertices in each star in the final solution produced cannot be adjacent to too many critical vertices. We present an amortization scheme to prove the approximation ratio in which the critical vertices are allowed to receive more tokens from the optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09361v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingyang Gong, Guohui Lin, Brendan Mumey</dc:creator>
    </item>
    <item>
      <title>A Classical Quadratic Speedup for Planted $k$XOR</title>
      <link>https://arxiv.org/abs/2508.09422</link>
      <description>arXiv:2508.09422v1 Announce Type: new 
Abstract: A recent work of Schmidhuber et al (QIP, SODA, &amp; Phys. Rev. X 2025) exhibited a quantum algorithm for the noisy planted $k$XOR problem running quartically faster than all known classical algorithms. In this work, we design a new classical algorithm that is quadratically faster than the best previous one, in the case of large constant $k$. Thus for such $k$, the quantum speedup of Schmidhuber et al. becomes only quadratic (though it retains a space advantage). Our algorithm, which also works in the semirandom case, combines tools from sublinear-time algorithms (essentially, the birthday paradox) and polynomial anticoncentration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09422v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meghal Gupta, William He, Ryan O'Donnell, Noah G. Singer</dc:creator>
    </item>
    <item>
      <title>Retroactive Monotonic Priority Queues via Range Searching</title>
      <link>https://arxiv.org/abs/2508.09892</link>
      <description>arXiv:2508.09892v1 Announce Type: new 
Abstract: The best known fully retroactive priority queue costs $O(\log^2 m \log \log m)$ time per operation, where $m$ is the number of operations performed on the data structure. In contrast, standard (non-retroactive) and partially retroactive priority queues cost $O(\log m)$ time per operation. So far, it is unknown whether this $O(\log m)$ bound can be achieved for fully retroactive priority queues.
  In this work, we study a restricted variant of priority queues known as monotonic priority queues. We show that finding the minimum in a retroactive monotonic priority queue is a special case of the range-searching problem. We design a fully retroactive monotonic priority queue with a cost of $O(\log m + T(m))$ time per operation, where $T(m)$ is the maximum between the query and the update time of a specific range-searching data structure with $m$ elements. Finally, we design a fully retroactive monotonic priority queue that costs $O(\log m \log \log m)$ time per operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09892v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Castro, Rosiane de Freitas</dc:creator>
    </item>
    <item>
      <title>Online Prediction with Limited Selectivity</title>
      <link>https://arxiv.org/abs/2508.09592</link>
      <description>arXiv:2508.09592v1 Announce Type: cross 
Abstract: Selective prediction [Dru13, QV19] models the scenario where a forecaster freely decides on the prediction window that their forecast spans. Many data statistics can be predicted to a non-trivial error rate without any distributional assumptions or expert advice, yet these results rely on that the forecaster may predict at any time. We introduce a model of Prediction with Limited Selectivity (PLS) where the forecaster can start the prediction only on a subset of the time horizon. We study the optimal prediction error both on an instance-by-instance basis and via an average-case analysis. We introduce a complexity measure that gives instance-dependent bounds on the optimal error. For a randomly-generated PLS instance, these bounds match with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09592v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Licheng Liu, Mingda Qiao</dc:creator>
    </item>
    <item>
      <title>Catch Me If You Can: Finding the Source of Infections in Temporal Networks</title>
      <link>https://arxiv.org/abs/2412.10877</link>
      <description>arXiv:2412.10877v2 Announce Type: replace 
Abstract: Source detection (SD) is the task of finding the origin of a spreading process in a network. Algorithms for SD help us combat diseases, misinformation, pollution, and more, and have been studied by physicians, physicists, sociologists, and computer scientists. The field has received considerable attention and been analyzed in many settings (e.g., under different models of spreading processes), yet all previous work shares the same assumption that the network the spreading process takes place in has the same structure at every point in time. For example, if we consider how a disease spreads through a population, it is unrealistic to assume that two people can either never or at every time infect each other, rather such an infection is possible precisely when they meet. Therefore, we propose an extended model of SD based on temporal graphs, where each link between two nodes is only present at some time step. Temporal graphs have become a standard model of time-varying graphs, and, recently, researchers have begun to study infection problems (such as influence maximization) on temporal graphs (arXiv:2303.11703, [Gayraud et al., 2015]). We give the first formalization of SD on temporal graphs. For this, we employ the standard SIR model of spreading processes ([Hethcote, 1989]). We give both lower bounds and algorithms for the SD problem in a number of different settings, such as with consistent or dynamic source behavior and on general graphs as well as on trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10877v2</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Bals, Michelle D\"oring, Nicolas Klodt, George Skretas</dc:creator>
    </item>
    <item>
      <title>Dynamic Network Discovery via Infection Tracing</title>
      <link>https://arxiv.org/abs/2412.10881</link>
      <description>arXiv:2412.10881v2 Announce Type: replace 
Abstract: Researchers, policy makers, and engineers need to make sense of data from spreading processes as diverse as rumor spreading in social networks, viral infections, and water contamination. Classical questions include predicting infection behavior in a given network or deducing the network structure from infection data. Most of the research on network infections studies static graphs, that is, the connections in the network are assumed to not change. More recently, temporal graphs, in which connections change over time, have been used to more accurately represent real-world infections, which rarely occur in unchanging networks. We propose a model for temporal graph discovery that is consistent with previous work on static graphs and embraces the greater expressiveness of temporal graphs. For this model, we give algorithms and lower bounds which are often tight. We analyze different variations of the problem, which make our results widely applicable and it also clarifies which aspects of temporal infections make graph discovery easier or harder. We round off our analysis with an experimental evaluation of our algorithm on real-world interaction data from the Stanford Network Analysis Project and on temporal Erd\H{o}s-Renyi graphs. On Erd\H{o}s-Renyi graphs, we uncover a threshold behavior, which can be explained by a novel connectivity parameter that we introduce during our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10881v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Bals, Michelle D\"oring, Nicolas Klodt, George Skretas</dc:creator>
    </item>
    <item>
      <title>Distributed Triangle Detection is Hard in Few Rounds</title>
      <link>https://arxiv.org/abs/2504.01802</link>
      <description>arXiv:2504.01802v2 Announce Type: replace 
Abstract: In the distributed triangle detection problem, we have an $n$-vertex network $G=(V,E)$ with one player for each vertex of the graph who sees the edges incident on the vertex. The players communicate in synchronous rounds using the edges of this network and have a limited bandwidth of $O(\log{n})$ bits over each edge. The goal is to detect whether or not $G$ contains a triangle as a subgraph in a minimal number of rounds.
  We prove that any protocol (deterministic or randomized) for distributed triangle detection requires $\Omega(\log\log{n})$ rounds of communication. Prior to our work, only one-round lower bounds were known for this problem.
  The primary technique for proving these types of distributed lower bounds is via reductions from two-party communication complexity. However, it has been known for a while that this approach is provably incapable of establishing any meaningful lower bounds for distributed triangle detection. Our main technical contribution is a new information theoretic argument which combines recent advances on multi-pass graph streaming lower bounds with the point-to-point communication aspects of distributed models, and can be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01802v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Janani Sundaresan</dc:creator>
    </item>
    <item>
      <title>Controlling tail risk in two-slope ski rental</title>
      <link>https://arxiv.org/abs/2508.06809</link>
      <description>arXiv:2508.06809v2 Announce Type: replace 
Abstract: We study the optimal solution to a general two-slope ski rental problem with a tail risk, i.e., the chance of the competitive ratio exceeding a value $\gamma$ is bounded by $\delta$. This extends the recent study of tail bounds for ski rental by [Dinitz et al. SODA 2024] to the two-slope version defined by [Lotker et al. IPL 2008]. In this version, even after "buying" we must still pay a rental cost at each time step, though it is lower after buying. This models many real-world "rent-or-buy" scenarios where a one-time investment decreases (but does not eliminate) the per-time cost.
  Despite this being a simple extension of the classical problem, we find that adding tail risk bounds creates a fundamentally different solution structure. For example, in our setting there is a possibility that we never buy in an optimal solution (which can also occur without tail bounds), but more strangely (and unlike the case without tail bounds or the classical case with tail bounds) we also show that the optimal solution might need to have nontrivial probabilities of buying even at finite points beyond the time corresponding to the buying cost. Moreover, in many regimes there does not exist a unique optimal solution. As our first contribution, we develop a series of structure theorems to characterize some features of optimal solutions.
  The complex structure of optimal solutions makes it more difficult to develop an algorithm to compute such a solution. As our second contribution, we utilize our structure theorems to design two algorithms: one based on a greedy algorithm combined with binary search that is fast but yields arbitrarily close to optimal solutions, and a slower algorithm based on linear programming which computes exact optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06809v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiming Cui, Michael Dinitz</dc:creator>
    </item>
    <item>
      <title>Semi-Bandit Learning for Monotone Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2312.15427</link>
      <description>arXiv:2312.15427v2 Announce Type: replace-cross 
Abstract: Stochastic optimization is a widely used approach for optimization under uncertainty, where uncertain input parameters are modeled by random variables. Exact or approximation algorithms have been obtained for several fundamental problems in this area. However, a significant limitation of this approach is that it requires full knowledge of the underlying probability distributions. Can we still get good (approximation) algorithms if these distributions are unknown, and the algorithm needs to learn them through repeated interactions? In this paper, we resolve this question for a large class of ''monotone'' stochastic problems, by providing a generic online learning algorithm with $\sqrt{T\log(T)}$ regret relative to the best approximation algorithm (under known distributions). Importantly, our online algorithm works in a semi-bandit setting, where in each period, the algorithm only observes samples from the random variables that were actually probed. Moreover, our result extends to settings with censored and binary feedback, where the policy only observes truncated or thresholded versions of the probed variables. Our framework applies to several fundamental problems such as prophet inequality, Pandora's box, stochastic knapsack, single-resource revenue management and sequential posted pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15427v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arpit Agarwal, Rohan Ghuge, Viswanath Nagarajan, Zhengjia Zhuo</dc:creator>
    </item>
    <item>
      <title>A Note on Approximating Weighted Nash Social Welfare with Additive Valuations</title>
      <link>https://arxiv.org/abs/2404.15607</link>
      <description>arXiv:2404.15607v3 Announce Type: replace-cross 
Abstract: We give the first $O(1)$-approximation for the weighted Nash Social Welfare problem with additive valuations. The approximation ratio we obtain is $e^{1/e} + \epsilon \approx 1.445 + \epsilon$, which matches the best known approximation ratio for the unweighted case.
  Both our algorithm and analysis are simple. We solve a natural configuration LP for the problem, and obtain the allocation of items to agents using a randomized version of the Shmoys-Tardos rounding algorithm developed for unrelated machine scheduling problems. In the analysis, we show that the approximation ratio of the algorithm is at most the worst gap between the Nash social welfare of the optimum allocation and that of an EF1 allocation, for an unweighted Nash Social Welfare instance with identical additive valuations. This was shown to be at most $e^{1/e} \approx 1.445$ by Barman, Krishnamurthy and Vaish, leading to our approximation ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15607v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.17</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 17, 1-12</arxiv:journal_reference>
      <dc:creator>Yuda Feng, Shi Li</dc:creator>
    </item>
    <item>
      <title>No-Regret M${}^{\natural}$-Concave Function Maximization: Stochastic Bandit Algorithms and Hardness of Adversarial Full-Information Setting</title>
      <link>https://arxiv.org/abs/2405.12439</link>
      <description>arXiv:2405.12439v2 Announce Type: replace-cross 
Abstract: M${}^{\natural}$-concave functions, a.k.a. gross substitute valuation functions, play a fundamental role in many fields, including discrete mathematics and economics. In practice, perfect knowledge of M${}^{\natural}$-concave functions is often unavailable a priori, and we can optimize them only interactively based on some feedback. Motivated by such situations, we study online M${}^{\natural}$-concave function maximization problems, which are interactive versions of the problem studied by Murota and Shioura (1999). For the stochastic bandit setting, we present $O(T^{-1/2})$-simple regret and $O(T^{2/3})$-regret algorithms under $T$ times access to unbiased noisy value oracles of M${}^{\natural}$-concave functions. A key to proving these results is the robustness of the greedy algorithm to local errors in M${}^{\natural}$-concave function maximization, which is one of our main technical results. While we obtain those positive results for the stochastic setting, another main result of our work is an impossibility in the adversarial setting. We prove that, even with full-information feedback, no algorithms that run in polynomial time per round can achieve $O(T^{1-c})$ regret for any constant $c &gt; 0$. Our proof is based on a reduction from the matroid intersection problem for three matroids, which would be a novel approach to establishing the hardness in online learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12439v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taihei Oki, Shinsaku Sakaue</dc:creator>
    </item>
  </channel>
</rss>
