<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 02:25:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>HyperFlexis: Joint Design of Algorithms and Systems for Multi-SLO Serving and Fast Scaling</title>
      <link>https://arxiv.org/abs/2508.15919</link>
      <description>arXiv:2508.15919v1 Announce Type: new 
Abstract: Modern large language model (LLM) serving systems face challenges from highly variable requests with diverse lengths, priorities, and stage-specific service-level objectives (SLOs). Meeting these requires real-time scheduling, rapid and cost-effective scaling, and support for both collocated and disaggregated Prefill/Decode (P/D) architectures.
  We present \textbf{HyperFlexis}, a unified LLM serving system that integrates algorithmic and system-level innovations to jointly optimize scheduling and scaling under multiple SLOs. It features a multi-SLO-aware scheduler that leverages budget estimation and request prioritization to ensure proactive SLO compliance for both new and ongoing requests. The system supports prefill- and decode-stage multi-SLO scheduling for P/D-disaggregated architectures and KV cache transfers. It also enables cost-effective scaling decisions, prefill-decode instance linking during scaling, and rapid P/D role transitions. To accelerate scaling and reduce cold-start latency, a device-to-device (D2D) weight transfer mechanism is proposed that lowers weight loading overhead by up to \textbf{19.39$\times$}. These optimizations allow the system to achieve up to \textbf{4.44$\times$} higher SLO attainment, \textbf{65.82\%} lower request latency, and cost parity with state-of-the-art baselines. The code will be released soon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15919v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zahra Yousefijamarani, Xinglu Wang, Qian Wang, Morgan Lindsay Heisler, Taha Shabani, Niloofar Gholipour, Parham Yassini, Hong Chang, Kan Chen, Qiantao Zhang, Xiaolong Bai, Jiannan Wang, Ying Xiong, Yong Zhang, Zhenan Fan</dc:creator>
    </item>
    <item>
      <title>Generalizing Brooks' theorem via Partial Coloring is Hard Classically and Locally</title>
      <link>https://arxiv.org/abs/2508.16308</link>
      <description>arXiv:2508.16308v1 Announce Type: new 
Abstract: We investigate the classical and distributed complexity of \emph{$k$-partial $c$-coloring} where $c=k$, a natural generalization of Brooks' theorem where each vertex should be colored from the palette $\{1,\ldots,c\} = \{1,\ldots,k\}$ such that it must have at least $\min\{k, \deg(v)\}$ neighbors colored differently. Das, Fraigniaud, and Ros{\'{e}}n~[OPODIS 2023] showed that the problem of $k$-partial $(k+1)$-coloring admits efficient centralized and distributed algorithms and posed an open problem about the status of the distributed complexity of $k$-partial $k$-coloring. We show that the problem becomes significantly harder when the number of colors is reduced from $k+1$ to $k$ for every constant $k\geq 3$.
  In the classical setting, we prove that deciding whether a graph admits a $k$-partial $k$-coloring is NP-complete for every constant $k \geq 3$, revealing a sharp contrast with the linear-time solvable $(k+1)$-color case. For the distributed LOCAL model, we establish an $\Omega(n)$-round lower bound for computing $k$-partial $k$-colorings, even when the graph is guaranteed to be $k$-partial $k$-colorable. This demonstrates an exponential separation from the $O(\log^2 k \cdot \log n)$-round algorithms known for $(k+1)$-colorings.
  Our results leverage novel structural characterizations of ``hard instances'' where partial coloring reduces to proper coloring, and we construct intricate graph gadgets to prove lower bounds via indistinguishability arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16308v1</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Bok, Avinandan Das, Anna Gujgiczer, Nikola Jedli\v{c}kov\'a</dc:creator>
    </item>
    <item>
      <title>Towards Integrated Energy-Communication-Transportation Hub: A Base-Station-Centric Design in 5G and Beyond</title>
      <link>https://arxiv.org/abs/2508.15833</link>
      <description>arXiv:2508.15833v1 Announce Type: cross 
Abstract: The rise of 5G communication has transformed the telecom industry for critical applications. With the widespread deployment of 5G base stations comes a significant concern about energy consumption. Key industrial players have recently shown strong interest in incorporating energy storage systems to store excess energy during off-peak hours, reducing costs and participating in demand response. The fast development of batteries opens up new possibilities, such as the transportation area. An effective method is needed to maximize base station battery utilization and reduce operating costs. In this trend towards next-generation smart and integrated energy-communication-transportation (ECT) infrastructure, base stations are believed to play a key role as service hubs. By exploring the overlap between base station distribution and electric vehicle charging infrastructure, we demonstrate the feasibility of efficiently charging EVs using base station batteries and renewable power plants at the Hub. Our model considers various factors, including base station traffic conditions, weather, and EV charging behavior. This paper introduces an incentive mechanism for setting charging prices and employs a deep reinforcement learning-based method for battery scheduling. Experimental results demonstrate the effectiveness of our proposed ECT-Hub in optimizing surplus energy utilization and reducing operating costs, particularly through revenue-generating EV charging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15833v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linfeng Shen, Guanzhen Wu, Cong Zhang, Xiaoyi Fan, Jiangchuan Liu</dc:creator>
    </item>
    <item>
      <title>Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication</title>
      <link>https://arxiv.org/abs/2508.16268</link>
      <description>arXiv:2508.16268v1 Announce Type: cross 
Abstract: This Paper proposes a self-healing, automated network of Raspberry Pi devices designed for deployment in scenarios where traditional networking is unavailable. Leveraging the low-power, long-range capabilities of the LoRa (Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the research addresses challenges such as limited bandwidth, data collisions, and node failures. Given that LoRa's packet-based system is incompatible with conventional IaC tools like Ansible and Terraform, which rely on TCP/IP networking, the research adapts IaC principles within a containerised architecture deployed across a Raspberry Pi cluster. Evaluation experiments indicate that fragmenting data packets and retransmitting any missed fragments can mitigate LoRa's inherent throughput and packet size limitations, although issues such as collisions and line-of-sight interference persist. An automated failover mechanism was integrated into the architecture, enabling unresponsive services to be redeployed to alternative nodes within one second, demonstrating the system's resilience in maintaining operational continuity despite node or service failures. The paper also identifies practical challenges, including the necessity for time-slotting transmissions to prevent data packet overlap and collisions. Future research should explore the integration of mesh networking to enhance range, develop more advanced scheduling algorithms, and adopt cutting-edge low-power wide-area network (LPWAN) techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16268v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rob Carson, Mohamed Chahine Ghanem, Feriel Bouakkaz</dc:creator>
    </item>
    <item>
      <title>Hybrid Classical-Quantum Supercomputing: A demonstration of a multi-user, multi-QPU and multi-GPU environment</title>
      <link>https://arxiv.org/abs/2508.16297</link>
      <description>arXiv:2508.16297v1 Announce Type: cross 
Abstract: Achieving a practical quantum advantage for near-term applications is widely expected to rely on hybrid classical-quantum algorithms. To deliver this practical advantage to users, high performance computing (HPC) centers need to provide a suitable software and hardware stack that supports algorithms of this type. In this paper, we describe the world's first implementation of a classical-quantum environment in an HPC center that allows multiple users to execute hybrid algorithms on multiple quantum processing units (QPUs) and GPUs. Our setup at the Poznan Supercomputing and Networking Center (PCSS) aligns with current HPC norms: the computing hardware including QPUs is installed in an active data center room with standard facilities; there are no special considerations for networking, power, and cooling; we use Slurm for workload management as well as the NVIDIA CUDA-Q extension API for classical-quantum interactions. We demonstrate applications of this environment for hybrid classical-quantum machine learning and optimisation. The aim of this work is to provide the community with an experimental example for further research and development on how quantum computing can practically enhance and extend HPC capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16297v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateusz Slysz, Piotr Rydlichowski, Krzysztof Kurowski, Omar Bacarezza, Esperanza Cuenca Gomez, Zohim Chandani, Bettina Heim, Pradnya Khalate, William R. Clements, James Fletcher</dc:creator>
    </item>
    <item>
      <title>On the Duality of Task and Actor Programming Models</title>
      <link>https://arxiv.org/abs/2508.16522</link>
      <description>arXiv:2508.16522v1 Announce Type: cross 
Abstract: Programming models for distributed and heterogeneous machines are rapidly growing in popularity to meet the demands of modern workloads. Task and actor models are common choices that offer different trade-offs between development productivity and achieved performance. Task-based models offer better productivity and composition of software, whereas actor-based models routinely deliver better peak performance due to lower overheads. While task-based and actor-based models appear to be different superficially, we demonstrate these programming models are duals of each other. Importantly, we show that this duality extends beyond functionality to performance, and elucidate techniques that let task-based systems deliver performance competitive with actor-based systems without compromising productivity. We apply these techniques to both Realm, an explicitly parallel task-based runtime, as well as Legion, an implicitly parallel task-based runtime. We show these techniques reduce Realm's overheads by between 1.7-5.3x, coming within a factor of two of the overheads imposed by heavily optimized actor-based systems like Charm++ and MPI. We further show that our techniques enable between 1.3-5.0x improved strong scaling of unmodified Legion applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16522v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohan Yadav, Joseph Guman, Sean Treichler, Michael Garland, Alex Aiken, Fredrik Kjolstad, Michael Bauer</dc:creator>
    </item>
    <item>
      <title>Distributed Computation with Local Advice</title>
      <link>https://arxiv.org/abs/2405.04519</link>
      <description>arXiv:2405.04519v2 Announce Type: replace 
Abstract: In this work we study local computation with advice: the goal is to solve a graph problem $\Pi$ with a distributed algorithm in $T(\Delta)$ communication rounds, for some function $T$ that only depends on the maximum degree $\Delta$ of the graph, and the key question is how many bits of advice per node are needed. 
  Some of our results regard Locally Checkable Labeling problems (LCLs), which are constraint-satisfaction graph problems that can be defined with a finite set of valid input/output-labeled neighborhoods.
  Our main results are:
  - Any LCL can be solved with only $1$ bit of advice per node in graphs with sub-exponential growth. Moreover, we can make the set of nodes that carry advice bits arbitrarily sparse. As a corollary, any LCL admits a locally checkable proof with $1$ bit per node in graphs with sub-exponential growth.
  - The assumption of sub-exponential growth is complemented by a conditional lower bound: assuming the Exponential-Time Hypothesis, there are locally checkable labeling problems that cannot be solved in general with any constant number of bits per node.
  - In any graph we can find an almost-balanced orientation with $1$ bit of advice per node, and again we can make the advice arbitrarily sparse. As a corollary, we can also compress an arbitrary subset of edges so that a node of degree $d$ stores only $d/2 + 2$ bits, and we can decompress it locally, in $T(\Delta)$ rounds.
  - In any graph of maximum degree $\Delta$, we can find a $\Delta$-coloring (if it exists) with $1$ bit of advice per node, and again, we can make the advice arbitrarily sparse.
  - In any $3$-colorable graph, we can find a $3$-coloring with $1$ bit of advice per node. As a corollary, in bounded-degree graphs there is a locally checkable proof that certifies $3$-colorability with $1$ bit of advice per node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04519v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alkida Balliu, Sebastian Brandt, Fabian Kuhn, Krzysztof Nowicki, Dennis Olivetti, Eva Rotenberg, Jukka Suomela</dc:creator>
    </item>
    <item>
      <title>Did we miss P In CAP? Partial Progress Conjecture under Asynchrony</title>
      <link>https://arxiv.org/abs/2501.00021</link>
      <description>arXiv:2501.00021v2 Announce Type: replace 
Abstract: Each application developer desires to provide its users with consistent results and an always-available system despite failures. Boldly, the CALM theorem disagrees. It states that it is hard to design a system that is both consistent and available under network partitions; select at most two out of these three properties. One possible solution is to design coordination-free monotonic applications. However, a majority of real-world applications require coordination. We resolve this dilemma by conjecturing that partial progress is possible under network partitions. This partial progress ensures the system appears responsive to a subset of clients and achieves non-zero throughput during failures. To this extent, we present the design of our CASSANDRA consensus protocol that allows partitioned replicas to order client requests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00021v2</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junchao Chen, Suyash Gupta, Daniel P. Hughes, Mohammad Sadoghi</dc:creator>
    </item>
    <item>
      <title>MSCCL++: Rethinking GPU Communication Abstractions for Cutting-edge AI Applications</title>
      <link>https://arxiv.org/abs/2504.09014</link>
      <description>arXiv:2504.09014v3 Announce Type: replace 
Abstract: Modern cutting-edge AI applications are being developed over fast-evolving, heterogeneous, nascent hardware devices. This requires frequent reworking of the AI software stack to adopt bottom-up changes from new hardware, which takes time for general-purpose software libraries. Consequently, real applications often develop custom software stacks optimized for their specific workloads and hardware. Custom stacks help in quick development and optimization, but incur a lot of redundant efforts across applications in writing non-portable code. This paper discusses an alternative communication library interface for AI applications that offers both portability and performance by reducing redundant efforts while maintaining flexibility for customization. We present MSCCL++, a novel abstraction of GPU communication based on separation of concerns: (1) a primitive interface provides a minimal hardware abstraction as a common ground for software and hardware developers to write custom communication, and (2) higher-level portable interfaces and specialized implementations enable optimization for different workloads and hardware environments. This approach makes the primitive interface reusable across applications while enabling highly flexible optimization. Compared to state-of-the-art baselines (NCCL, RCCL, and MSCCL), MSCCL++ achieves speedups of up to 5.4$\times$ for collective communication and up to 15% for real-world AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure, and is also adopted by RCCL, the GPU collective communication library maintained by AMD. MSCCL++ is open-source and available at https://github.com/microsoft/mscclpp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09014v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aashaka Shah, Abhinav Jangda, Binyang Li, Caio Rocha, Changho Hwang, Jithin Jose, Madan Musuvathi, Olli Saarikivi, Peng Cheng, Qinghua Zhou, Roshan Dathathri, Saeed Maleki, Ziyue Yang</dc:creator>
    </item>
    <item>
      <title>Dynamic Optimization of Storage Systems Using Reinforcement Learning Techniques</title>
      <link>https://arxiv.org/abs/2501.00068</link>
      <description>arXiv:2501.00068v2 Announce Type: replace-cross 
Abstract: The exponential growth of data-intensive applications has placed unprecedented demands on modern storage systems, necessitating dynamic and efficient optimization strategies. Traditional heuristics employed for storage performance optimization often fail to adapt to the variability and complexity of contemporary workloads, leading to significant performance bottlenecks and resource inefficiencies. To address these challenges, this paper introduces RL-Storage, a novel reinforcement learning (RL)-based framework designed to dynamically optimize storage system configurations. RL-Storage leverages deep Q-learning algorithms to continuously learn from real-time I/O patterns and predict optimal storage parameters, such as cache size, queue depths, and readahead settings[1].This work underscores the transformative potential of reinforcement learning techniques in addressing the dynamic nature of modern storage systems. By autonomously adapting to workload variations in real time, RL-Storage provides a robust and scalable solution for optimizing storage performance, paving the way for next-generation intelligent storage infrastructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00068v2</guid>
      <category>cs.OS</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiyu Cheng, Chang Zhou, Yang Zhao</dc:creator>
    </item>
    <item>
      <title>Robustness of deep learning classification to adversarial input on GPUs: asynchronous parallel accumulation is a source of vulnerability</title>
      <link>https://arxiv.org/abs/2503.17173</link>
      <description>arXiv:2503.17173v2 Announce Type: replace-cross 
Abstract: The ability of machine learning (ML) classification models to resist small, targeted input perturbations -- known as adversarial attacks -- is a key measure of their safety and reliability. We show that floating-point non-associativity (FPNA) coupled with asynchronous parallel programming on GPUs is sufficient to result in misclassification, without any perturbation to the input. Additionally, we show that standard adversarial robustness results may be overestimated up to 4.6 when not considering machine-level details. We develop a novel black-box attack using Bayesian optimization to discover external workloads that can change the instruction scheduling which bias the output of reductions on GPUs and reliably lead to misclassification. Motivated by these results, we present a new learnable permutation (LP) gradient-based approach to learning floating-point operation orderings that lead to misclassifications. The LP approach provides a worst-case estimate in a computationally efficient manner, avoiding the need to run identical experiments tens of thousands of times over a potentially large set of possible GPU states or architectures. Finally, using instrumentation-based testing, we investigate parallel reduction ordering across different GPU architectures under external background workloads, when utilizing multi-GPU virtualization, and when applying power capping. Our results demonstrate that parallel reduction ordering varies significantly across architectures under the first two conditions, substantially increasing the search space required to fully test the effects of this parallel scheduler-based vulnerability. These results and the methods developed here can help to include machine-level considerations into adversarial robustness assessments, which can make a difference in safety and mission critical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17173v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sanjif Shanmugavelu, Mathieu Taillefumier, Christopher Culver, Vijay Ganesh, Oscar Hernandez, Ada Sedova</dc:creator>
    </item>
    <item>
      <title>Denoising Application Performance Models with Noise-Resilient Priors</title>
      <link>https://arxiv.org/abs/2504.10996</link>
      <description>arXiv:2504.10996v3 Announce Type: replace-cross 
Abstract: As parallel codes are scaled to larger computing systems, performance models play a crucial role in identifying potential bottlenecks. However, constructing these models analytically is often challenging. Empirical models based on performance measurements provide a practical alternative, but measurements on high-performance computing (HPC) systems are frequently affected by noise, which can lead to misleading predictions. To mitigate the impact of noise, we introduce application-specific dynamic priors into the modeling process. These priors are derived from noise-resilient measurements of computational effort, combined with domain knowledge about common algorithms used in communication routines. By incorporating these priors, we effectively constrain the model's search space, eliminating complexity classes that capture noise rather than true performance characteristics. This approach keeps the models closely aligned with theoretical expectations and substantially enhances their predictive accuracy. Moreover, it reduces experimental overhead by cutting the number of repeated measurements by half.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10996v3</guid>
      <category>cs.PF</category>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gustavo de Morais, Alexander Gei{\ss}, Alexandru Calotoiu, Gregor Corbin, Ahmad Tarraf, Torsten Hoefler, Bernd Mohr, Felix Wolf</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience</title>
      <link>https://arxiv.org/abs/2508.00596</link>
      <description>arXiv:2508.00596v2 Announce Type: replace-cross 
Abstract: In decentralized federated learning (FL), multiple clients collaboratively learn a shared machine learning (ML) model by leveraging their privately held datasets distributed across the network, through interactive exchange of the intermediate model updates. To ensure data security, cryptographic techniques are commonly employed to protect model updates during aggregation. Despite growing interest in secure aggregation, existing works predominantly focus on protocol design and computational guarantees, with limited understanding of the fundamental information-theoretic limits of such systems. Moreover, optimal bounds on communication and key usage remain unknown in decentralized settings, where no central aggregator is available. Motivated by these gaps, we study the problem of decentralized secure aggregation (DSA) from an information-theoretic perspective. Specifically, we consider a network of $K$ fully-connected users, each holding a private input -- an abstraction of local training data -- who aim to securely compute the sum of all inputs. The security constraint requires that no user learns anything beyond the input sum, even when colluding with up to $T$ other users. We characterize the optimal rate region, which specifies the minimum achievable communication and secret key rates for DSA. In particular, we show that to securely compute one symbol of the desired input sum, each user must (i) transmit at least one symbol to others, (ii) hold at least one symbol of secret key, and (iii) all users must collectively hold no fewer than $K - 1$ independent key symbols. Our results establish the fundamental performance limits of DSA, providing insights for the design of provably secure and communication-efficient protocols in distributed learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00596v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhang, Zhou Li, Shuangyang Li, Kai Wan, Derrick Wing Kwan Ng, Giuseppe Caire</dc:creator>
    </item>
  </channel>
</rss>
