<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SY</link>
    <description>cs.SY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Jul 2024 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust Optimal Network Topology Switching for Zero Dynamics Attacks</title>
      <link>https://arxiv.org/abs/2407.18440</link>
      <description>arXiv:2407.18440v1 Announce Type: new 
Abstract: The intrinsic, sampling, and enforced zero dynamics attacks (ZDAs) are among the most detrimental but common stealthy attacks in robotics, aerospace, and cyber-physical systems. They exploit internal dynamics, discretization, redundancy/asynchronous actuation and sensing, to construct disruptive attacks that are completely stealthy in the measurement. Surprisingly, they work even when the systems are both controllable and observable. This paper presents a novel framework to robustly and optimally detect and mitigate ZDAs for networked linear control systems. We define controllability, observability, robustness, and sensitivity metrics, written explicitly in terms of the system topology, thereby proposing a robust and optimal switching topology formulation for resilient ZDA detection and mitigation. We equivalently reformulate this problem as a rank-constrained optimization problem (i.e., optimization with a convex objective function subject to convex constraints and rank constraints) and solve it using a convex rank minimization approach. The effectiveness of our method is demonstrated using networked dynamics subject to ZDAs</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18440v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroyasu Tsukamoto, Joshua D. Ibrahim, Joudi Hajar, James Ragan, Soon-Jo Chung, Fred Y. Hadaegh</dc:creator>
    </item>
    <item>
      <title>Regret-Optimal Defense Against Stealthy Adversaries: A System Level Approach</title>
      <link>https://arxiv.org/abs/2407.18448</link>
      <description>arXiv:2407.18448v1 Announce Type: new 
Abstract: Modern control designs in robotics, aerospace, and cyber-physical systems heavily depend on real-world data obtained through the system outputs. In the face of system faults and malicious attacks, however, these outputs can be compromised to misrepresent some portion of the system information that critically affects their secure and trustworthy operation. In this paper, we introduce a novel regret-optimal control framework for designing controllers that render a linear system robust against stealthy attacks, including sensor and actuator attacks, as well as external disturbances. In particular, we establish (a) a convex optimization-based system metric to quantify the regret with the worst-case stealthy attack (the true performance minus the optimal performance in hindsight with the knowledge of the stealthy attack), which improves and adaptively interpolates $\mathcal{H}_2$ and $\mathcal{H}_{\infty}$ norms in the presence of stealthy adversaries, (b) an optimization problem for minimizing the regret of 1 expressed in the system level parameterization, which is useful for its localized and distributed implementation in large-scale systems, and (c) a rank-constrained optimization problem (i.e., optimization with a convex objective subject to convex constraints and rank constraints) equivalent to the optimization problem of (b). Finally, we conduct a numerical simulation which showcases the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18448v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroyasu Tsukamoto, Joudi Hajar, Soon-Jo Chung, Fred Y. Hadaegh</dc:creator>
    </item>
    <item>
      <title>Finite-time and bumpless transfer control of asynchronously switched systems: An output feedback control approach</title>
      <link>https://arxiv.org/abs/2407.18481</link>
      <description>arXiv:2407.18481v1 Announce Type: new 
Abstract: In this paper, the finite-time control and bumpless transfer control are investigated for switched systems under asynchronously switching. First, a class of dynamic output feedback controllers are designed to stabilize the switched system with measurable system outputs. Considering the improvement of transient performance, the bumpless transfer control and finite-time control are further studied in the controller design. To avoid the control bumps, a practical filter is introduced to make the control signal smoother and continuous. Furthermore, to derive a finite-time bounded system state over short-time intervals, the finite-time analysis is considered in managing the switching process with the average dwell time. New criteria are proposed to analyze the finite-time stability and finite-time boundedness for the closed-loop system and solvable conditions are newly proposed to optimize the controller gain. Finally, the superiorities of the proposed method are validated through an application to a boost converter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18481v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo-Ran Liu, Zhen Wu, Xian Du, Zhongyang Fei</dc:creator>
    </item>
    <item>
      <title>On the Number of Observation Nodes in Boolean Networks</title>
      <link>https://arxiv.org/abs/2407.18560</link>
      <description>arXiv:2407.18560v1 Announce Type: new 
Abstract: A Boolean network (BN) is called observable if any initial state can be uniquely determined from the output sequence. In the existing literature on observability of BNs, there is almost no research on the relationship between the number of observation nodes and the observability of BNs, which is an important and practical issue. In this paper, we mainly focus on three types of BNs with $n$ nodes (i.e., $K$-AND-OR-BNs, $K$-XOR-BNs, and $K$-NC-BNs, where $K$ is the number of input nodes for each node and NC means nested canalyzing) and study the upper and lower bounds of the number of observation nodes for these BNs. First, we develop a novel technique using information entropy to derive a general lower bound of the number of observation nodes, and conclude that the number of observation nodes cannot be smaller than $\left[(1-K)+\frac{2^{K}-1}{2^{K}}\log_{2}(2^{K}-1)\right]n$ to ensure that any $K$-AND-OR-BN is observable, and similarly, some lower bound is also obtained for $K$-NC-BNs. Then for any type of BN, we also develop two new techniques to infer the general lower bounds, using counting identical states at time 1 and counting the number of fixed points, respectively. On the other hand, we derive nontrivial upper bounds of the number of observation nodes by combinatorial analysis of several types of BNs. Specifically, we indicate that $\left(\frac{2^{K}-K-1}{2^{K}-1}\right)n,~1$, and $\lceil \frac{n}{K}\rceil$ are the best case upper bounds for $K$-AND-OR-BNs, $K$-XOR-BNs, and $K$-NC-BN, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18560v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangjie Sun, Wai-Ki Ching, Tatsuya Akutsu</dc:creator>
    </item>
    <item>
      <title>Piecewise constant tuning gain based singularity-free MRAC with application to aircraft control systems</title>
      <link>https://arxiv.org/abs/2407.18596</link>
      <description>arXiv:2407.18596v1 Announce Type: new 
Abstract: This paper introduces an innovative singularity-free output feedback model reference adaptive control (MRAC) method applicable to a wide range of continuous-time linear time-invariant (LTI) systems with general relative degrees. Unlike existing solutions such as Nussbaum and multiple-model-based methods, which manage unknown high-frequency gains through persistent switching and repeated parameter estimation, the proposed method circumvents these issues without prior knowledge of the high-frequency gain or additional design conditions. The key innovation of this method lies in transforming the estimation error equation into a linear regression form via a modified MRAC law with a piecewise constant tuning gain developed in this work. This represents a significant departure from existing MRAC systems, where the estimation error equation is typically in a bilinear regression form. The linear regression form facilitates the direct estimation of all unknown parameters, thereby simplifying the adaptive control process. The proposed method preserves closed-loop stability and ensures asymptotic output tracking, overcoming some of the limitations associated with existing methods like Nussbaum and multiple-model based methods. The practical efficacy of the developed MRAC method is demonstrated through detailed simulation results within an aircraft control system scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18596v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhipeng Zhang, Yanjun Zhang, Jian Sun</dc:creator>
    </item>
    <item>
      <title>Atmospheric Density-Compensating Model Predictive Control for Targeted Reentry of Drag-Modulated Spacecraft</title>
      <link>https://arxiv.org/abs/2407.18762</link>
      <description>arXiv:2407.18762v1 Announce Type: new 
Abstract: This paper presents an estimation and control framework that enables the targeted reentry of a drag-modulated spacecraft in the presence of atmospheric density uncertainty. In particular, an extended Kalman filter (EKF) is used to estimate the in-flight density errors relative to the atmospheric density used to generate the nominal guidance trajectory. This information is leveraged within a model predictive control (MPC) strategy to improve tracking performance, reduce control effort, and increase robustness to actuator saturation compared to the state-of-the-art approach. The estimation and control framework is tested in a Monte Carlo simulation campaign with historical space weather data. These simulation efforts demonstrate that the proposed framework is able to stay within 100 km of the guidance trajectory at all points in time for 98.4% of cases. The remaining 1.6% of cases were pushed away from the guidance by large density errors, many due to significant solar storms and flares, that could not physically be compensated for by the drag control device. For the successful cases, the proposed framework was able to guide the spacecraft to the desired location at the entry interface altitude with a mean error of 12.1 km and 99.7% of cases below 100 km.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18762v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex D. Hayes, Ryan J. Caverly</dc:creator>
    </item>
    <item>
      <title>Leader-Follower Formation and Tracking Control of Underactuated Surface Vessels</title>
      <link>https://arxiv.org/abs/2407.18844</link>
      <description>arXiv:2407.18844v1 Announce Type: new 
Abstract: This paper presents a simple control approach for global trajectory tracking and formation control of underactuated surface vessels equipped with only two propellers. The control approach exploits the inherent cascaded structure of the vehicle dynamics and is divided into control designs at the kinematics level and the kinetics level. A controller with a low-gain feature is designed at the kinematics level by incorporating the cascaded system method, persistency of excitation, and the small-gain theorem. Furthermore, a PD+ controller is designed to achieve the velocity tracking at the kinetics level. The proposed control laws are partially linear and saturated linear and easy to implement. Based on a leader-follower scheme, our control approach applies to the formation tracking control problem of multi-vehicle systems under a directed spanning tree topology. Our main results guarantee uniform global asymptotic stability for the closed-loop system, which implies robustness with respect to perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18844v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Wang, Antonio Loria</dc:creator>
    </item>
    <item>
      <title>Flexible and Cost-Effective Spherical to Cartesian Coordinate Conversion Using 3-D CORDIC Algorithm on FPGA</title>
      <link>https://arxiv.org/abs/2407.18255</link>
      <description>arXiv:2407.18255v1 Announce Type: cross 
Abstract: In computer science, transforming spherical coordinates into Cartesian coordinates is an important mathematical operation. The CORDIC (Coordinate Rotation Digital Computer) iterative algorithm can perform this operation, as well as trigonometric functions and vector rotations, using only simple arithmetic operations like addition, subtraction, and bit-shifting. This research paper presents hardware architecture for a 3-D CORDIC processor using Quartus II 7.1 ALTERA software, which enables easy modifications and design changes due to its regularity and simplicity. The proposed 3-D CORDIC model is evaluated by comparing the calculated results with the simulated results to determine its accuracy. The results were satisfaction and the proposed model could be suitable for numerous real-time applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18255v1</guid>
      <category>cs.AR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>International Journal of Intelligent Systems and Applications in Engineering, 12(4), 815-823, 2024</arxiv:journal_reference>
      <dc:creator>Nadia Salem, Sami Serhan, Khawla Al-Tarawneh, Ra'fat Al-Msie'deen</dc:creator>
    </item>
    <item>
      <title>Adaptive Terminal Sliding Mode Control Using Deep Reinforcement Learning for Zero-Force Control of Exoskeleton Robot Systems</title>
      <link>https://arxiv.org/abs/2407.18309</link>
      <description>arXiv:2407.18309v1 Announce Type: cross 
Abstract: This paper introduces a novel zero-force control method for upper-limb exoskeleton robots, which are used in a variety of applications including rehabilitation, assistance, and human physical capability enhancement. The proposed control method employs an Adaptive Integral Terminal Sliding Mode (AITSM) controller, combined with an exponential reaching law and Proximal Policy Optimization (PPO), a type of Deep Reinforcement Learning (DRL). The PPO system incorporates an attention mechanism and Long Short-Term Memory (LSTM) neural networks, enabling the controller to selectively focus on relevant system states, adapt to changing behavior, and capture long-term dependencies. This controller is designed to manage a 5-DOF upper-limb exoskeleton robot with zero force, even amidst system uncertainties. The controller uses an integral terminal sliding surface to ensure finite-time convergence to the desired state, a crucial feature for applications requiring quick responses. It also includes an exponential switching control term to reduce chattering and improve system accuracy. The controller's adaptability, facilitated by the PPO system, allows real-time parameter adjustments based on system feedback, making the controller robust and capable of dealing with uncertainties and disturbances that could affect the performance of the exoskeleton. The proposed control method's effectiveness and superiority are confirmed through numerical simulations and comparisons with existing control methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18309v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morteza Mirzaee, Reza Kazemi</dc:creator>
    </item>
    <item>
      <title>Phase transition in a kinetic mean-field game model of inertial self-propelled agents</title>
      <link>https://arxiv.org/abs/2407.18400</link>
      <description>arXiv:2407.18400v1 Announce Type: cross 
Abstract: The framework of Mean-field Games (MFGs) is used for modelling the collective dynamics of large populations of non-cooperative decision-making agents. We formulate and analyze a kinetic MFG model for an interacting system of non-cooperative motile agents with inertial dynamics and finite-range interactions, where each agent is minimizing a biologically inspired cost function. By analyzing the associated coupled forward-backward in time system of nonlinear Fokker-Planck and Hamilton-Jacobi-Bellman equations, we obtain conditions for closed-loop linear stability of the spatially homogeneous MFG equilibrium that corresponds to an ordered state with non-zero mean speed. Using a combination of analysis and numerical simulations, we show that when energetic cost of control is reduced below a critical value, this equilibrium loses stability, and the system transitions to a travelling wave solution. Our work provides a game-theoretic perspective to the problem of collective motion in non-equilibrium biological and bio-inspired systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18400v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piyush Grover, Mandy Huo</dc:creator>
    </item>
    <item>
      <title>Multiphysics Modeling on Photoconductive Antennas for Terahertz Applications</title>
      <link>https://arxiv.org/abs/2407.18465</link>
      <description>arXiv:2407.18465v1 Announce Type: cross 
Abstract: Terahertz lies at the juncture between RF and optical electromagnetism, serving as a transition from mm-Wave to infrared photonics. Terahertz technology has been used for industrial quality control, security imaging, and high-speed communications, and often generated through optoelectronic solutions by using photoconductive antennas. In this paper, Multiphysics simulations on semi insulating GaAs, grapheneenhanced photoconductive antennas are conducted to effectively decouple optical responses of semiconductor carrier generation/drift from Terahertz radiation computation, which provides a comprehensive and integrated platform for future terahertz photoconductive antenna designs</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18465v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boxun Yan, Bundel Pooja, Chi-Hou Chan, Mau-Chung Frank Chang</dc:creator>
    </item>
    <item>
      <title>On Asymptotic Analysis of Perturbed Sweeping Processes with Application to Optimization</title>
      <link>https://arxiv.org/abs/2407.18469</link>
      <description>arXiv:2407.18469v1 Announce Type: cross 
Abstract: Convergence analysis of constrained optimization methods from the dynamical systems viewpoint has attracted considerable attention because it provides a geometric demonstration towards the shadowing trajectory of a numerical scheme. In this work, we establish a tight connection between a continuous-time nonsmooth dynamical system called a perturbed sweeping process (PSP) and a proximal stochastic approximation scheme. Theoretical results are obtained by analyzing the asymptotic pseudo trajectory of a PSP. We show that under mild assumptions a proximal stochastic approximation scheme converges to an internally chain transitive invariant set of the corresponding PSP. Furthermore, given the existence of a Lyapunov function $V$ with respect to a set $\Lambda$, convergence to $\Lambda$ can be established if $V(\Lambda)$ has an empty interior. Based on these theoretical results, we are able to provide a useful framework for convergence analysis of proximal gradient methods. Illustrative examples are provided to determine the convergence of proximal variants of gradient methods (including accelerated gradient methods). Finally, numerical simulations are conducted to confirm the validity of theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18469v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoyue Xia, Jun Du, Chunxiao Jiang, H. Vincent Poor, Yong Ren</dc:creator>
    </item>
    <item>
      <title>Integrating Posture Control in Speech Motor Models: A Parallel-Structured Simulation Approach</title>
      <link>https://arxiv.org/abs/2407.18516</link>
      <description>arXiv:2407.18516v1 Announce Type: cross 
Abstract: Posture is an essential aspect of motor behavior, necessitating continuous muscle activation to counteract gravity. It remains stable under perturbation, aiding in maintaining bodily balance and enabling movement execution. Similarities have been observed between gross body postures and speech postures, such as those involving the jaw, tongue, and lips, which also exhibit resilience to perturbations and assist in equilibrium and movement. Although postural control is a recognized element of human movement and balance, particularly in broader motor skills, it has not been adequately incorporated into existing speech motor control models, which typically concentrate on the gestures or motor commands associated with specific speech movements, overlooking the influence of postural control and gravity. Here we introduce a model that aligns speech posture and movement, using simulations to explore whether speech posture within this framework mirrors the principles of bodily postural control. Our findings indicate that, akin to body posture, speech posture is also robust to perturbation and plays a significant role in maintaining local segment balance and enhancing speech production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18516v1</guid>
      <category>eess.AS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yadong Liu, Sidney Fels, Arian Shamei, Najeeb Khan, Bryan Gick</dc:creator>
    </item>
    <item>
      <title>PANDORA: The Open-Source, Structurally Elastic Humanoid Robot</title>
      <link>https://arxiv.org/abs/2407.18558</link>
      <description>arXiv:2407.18558v1 Announce Type: cross 
Abstract: In this work, the novel, open-source humanoid robot, PANDORA, is presented where a majority of the structural elements are manufactured using 3D-printed compliant materials. As opposed to contemporary approaches that incorporate the elastic element into the actuator mechanisms, PANDORA is designed to be compliant under load, or in other words, structurally elastic. This design approach lowers manufacturing cost and time, design complexity, and assembly time while introducing controls challenges in state estimation, joint and whole-body control. This work features an in-depth description on the mechanical and electrical subsystems including details regarding additive manufacturing benefits and drawbacks, usage and placement of sensors, and networking between devices. In addition, the design of structural elastic components and their effects on overall performance from an estimation and control perspective are discussed. Finally, results are presented which demonstrate the robot completing a robust balancing objective in the presence of disturbances and stepping behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18558v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor W. Herron, Alexander J. Fuge, Benjamin C. Beiter, Zachary J. Fuge, Nicholas J. Tremaroli, Stephen Welch, Maxwell Stelmack, Madeline Kogelis, Philip Hancock, Ivan Fischman Ekman Simoes, Christian Runyon, Isaac Pressgrove, Alexander Leonessa</dc:creator>
    </item>
    <item>
      <title>Matching Input and Output Devices and Physical Disabilities for Human-Robot Workstations</title>
      <link>https://arxiv.org/abs/2407.18563</link>
      <description>arXiv:2407.18563v1 Announce Type: cross 
Abstract: As labor shortage is rising at an alarming rate, it is imperative to enable all people to work, particularly people with disabilities and elderly people. Robots are often used as universal tool to assist people with disabilities. However, for such human-robot workstations universal design fails. We mitigate the challenges of selecting an individualized set of input and output devices by matching devices required by the work process and individual disabilities adhering to the Convention on the Rights of Persons with Disabilities passed by the United Nations. The objective is to facilitate economically viable workstations with just the required devices, hence, lowering overall cost of corporate inclusion and during redesign of workplaces. Our work focuses on developing an efficient approach to filter input and output devices based on a person's disabilities, resulting in a tailored list of usable devices. The methodology enables an automated assessment of devices compatible with specific disabilities defined in International Classification of Functioning, Disability and Health. In a mock-up, we showcase the synthesis of input and output devices from disabilities, thereby providing a practical tool for selecting devices for individuals with disabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18563v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Weidemann, Nils Mandischer, Burkhard Corves</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Sustainable Energy: A Survey</title>
      <link>https://arxiv.org/abs/2407.18597</link>
      <description>arXiv:2407.18597v1 Announce Type: cross 
Abstract: The transition to sustainable energy is a key challenge of our time, requiring modifications in the entire pipeline of energy production, storage, transmission, and consumption. At every stage, new sequential decision-making challenges emerge, ranging from the operation of wind farms to the management of electrical grids or the scheduling of electric vehicle charging stations. All such problems are well suited for reinforcement learning, the branch of machine learning that learns behavior from data. Therefore, numerous studies have explored the use of reinforcement learning for sustainable energy. This paper surveys this literature with the intention of bridging both the underlying research communities: energy and machine learning. After a brief introduction of both fields, we systematically list relevant sustainability challenges, how they can be modeled as a reinforcement learning problem, and what solution approaches currently exist in the literature. Afterwards, we zoom out and identify overarching reinforcement learning themes that appear throughout sustainability, such as multi-agent, offline, and safe reinforcement learning. Lastly, we also cover standardization of environments, which will be crucial for connecting both research fields, and highlight potential directions for future work. In summary, this survey provides an extensive overview of reinforcement learning methods for sustainable energy, which may play a vital role in the energy transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18597v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Koen Ponse, Felix Kleuker, M\'arton Fej\'er, \'Alvaro Serra-G\'omez, Aske Plaat, Thomas Moerland</dc:creator>
    </item>
    <item>
      <title>Optimal Control on Positive Cones</title>
      <link>https://arxiv.org/abs/2407.18774</link>
      <description>arXiv:2407.18774v1 Announce Type: cross 
Abstract: An optimal control problem on finite-dimensional positive cones is stated. Under a critical assumption on the cone, the corresponding Bellman equation is satisfied by a linear function, which can be computed by convex optimization. A separate theorem relates the assumption on the cone to the existence of minimal elements in certain subsets of the dual cone. Three special cases are derived as examples. The first one, where the positive cone is the set of positive semi-definite matrices, reduces to standard linear quadratic control. The second one, where the positive cone is a polyhedron, reduces to a recent result on optimal control of positive systems. The third special case corresponds to linear quadratic control with additional structure, such as spatial invariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18774v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Pates, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Kalman Filtering over Finite and Infinite Horizon</title>
      <link>https://arxiv.org/abs/2407.18837</link>
      <description>arXiv:2407.18837v1 Announce Type: cross 
Abstract: This paper investigates the distributionally robust filtering of signals generated by state-space models driven by exogenous disturbances with noisy observations in finite and infinite horizon scenarios. The exact joint probability distribution of the disturbances and noise is unknown but assumed to reside within a Wasserstein-2 ambiguity ball centered around a given nominal distribution. We aim to derive a causal estimator that minimizes the worst-case mean squared estimation error among all possible distributions within this ambiguity set. We remove the iid restriction in prior works by permitting arbitrarily time-correlated disturbances and noises. In the finite horizon setting, we reduce this problem to a semi-definite program (SDP), with computational complexity scaling with the time horizon. For infinite horizon settings, we characterize the optimal estimator using Karush-Kuhn-Tucker (KKT) conditions. Although the optimal estimator lacks a rational form, i.e., a finite-dimensional state-space realization, it can be fully described by a finite-dimensional parameter. {Leveraging this parametrization, we propose efficient algorithms that compute the optimal estimator with arbitrary fidelity in the frequency domain.} Moreover, given any finite degree, we provide an efficient convex optimization algorithm that finds the finite-dimensional state-space estimator that best approximates the optimal non-rational filter in ${\cal H}_\infty$ norm. This facilitates the practical implementation of the infinite horizon filter without having to grapple with the ill-scaled SDP from finite time. Finally, numerical simulations demonstrate the effectiveness of our approach in practical scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18837v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taylan Kargin, Joudi Hajar, Vikrant Malik, Babak Hassibi</dc:creator>
    </item>
    <item>
      <title>SHANGUS: Deep Reinforcement Learning Meets Heuristic Optimization for Speedy Frontier-Based Exploration of Autonomous Vehicles in Unknown Spaces</title>
      <link>https://arxiv.org/abs/2407.18892</link>
      <description>arXiv:2407.18892v1 Announce Type: cross 
Abstract: This paper introduces SHANGUS, an advanced framework combining Deep Reinforcement Learning (DRL) with heuristic optimization to improve frontier-based exploration efficiency in unknown environments, particularly for intelligent vehicles in autonomous air services, search and rescue operations, and space exploration robotics. SHANGUS harnesses DRL's adaptability and heuristic prioritization, markedly enhancing exploration efficiency, reducing completion time, and minimizing travel distance. The strategy involves a frontier selection node to identify unexplored areas and a DRL navigation node using the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm for robust path planning and dynamic obstacle avoidance. Extensive experiments in ROS2 and Gazebo simulation environments show SHANGUS surpasses representative traditional methods like the Nearest Frontier (NF), Novel Frontier-Based Exploration Algorithm (CFE), and Goal-Driven Autonomous Exploration (GDAE) algorithms, especially in complex scenarios, excelling in completion time, travel distance, and exploration rate. This scalable solution is suitable for real-time autonomous navigation in fields such as industrial automation, autonomous driving, household robotics, and space exploration. Future research will integrate additional sensory inputs and refine heuristic functions to further boost SHANGUS's efficiency and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18892v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seunghyeop Nam, Tuan Anh Nguyen, Eunmi Choi, Dugki Min</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Wireless Scheduling in Distributed Networked Control</title>
      <link>https://arxiv.org/abs/2109.12562</link>
      <description>arXiv:2109.12562v4 Announce Type: replace 
Abstract: We consider a joint uplink and downlink scheduling problem of a fully distributed wireless networked control system (WNCS) with a limited number of frequency channels. Using elements of stochastic systems theory, we derive a sufficient stability condition of the WNCS, which is stated in terms of both the control and communication system parameters. Once the condition is satisfied, there exists a stationary and deterministic scheduling policy that can stabilize all plants of the WNCS. By analyzing and representing the per-step cost function of the WNCS in terms of a finite-length countable vector state, we formulate the optimal transmission scheduling problem into a Markov decision process and develop a deep reinforcement learning (DRL) based framework for solving it. To tackle the challenges of a large action space in DRL, we propose novel action space reduction and action embedding methods for the DRL framework that can be applied to various algorithms, including Deep Q-Network (DQN), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed Deep Deterministic Policy Gradient (TD3). Numerical results show that the proposed algorithm significantly outperforms benchmark policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.12562v4</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaoyang Pang, Kang Huang, Daniel E. Quevedo, Branka Vucetic, Yonghui Li, Wanchun Liu</dc:creator>
    </item>
    <item>
      <title>Load Restoration in Islanded Microgrids: Formulation and Solution Strategies</title>
      <link>https://arxiv.org/abs/2111.02054</link>
      <description>arXiv:2111.02054v4 Announce Type: replace 
Abstract: Adverse circumstances such as extreme weather events can cause significant disruptions to normal operation of electric distribution systems (DS), which includes isolating parts of the DS due to damaged transmission equipment. In this paper, we consider the problem of load restoration in a microgrid (MG) that is islanded from the upstream DS. The MG contains sources of distributed generation such as microturbines and renewable energy sources, as well as energy storage systems (ESS). We formulate the load restoration task as a non-convex optimization problem. This problem embodies the physics of the MG by leveraging a branch flow model, while incorporating salient phenomenon in islanded MGs such as the need for internal frequency regulation, and complementarity requirements arising in ESS operations. Since the formulated optimization problem is non-convex, we introduce a convex relaxation which can be solved through model predictive control as a baseline method. However, in order to solve the problem considering its full non-convexity, we leverage a policy-learning method called constrained policy optimization, a tailored version of which is used as our proposed algorithm. The aforementioned approaches, along with an additional deep learning method are compared through extensive simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.02054v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shourya Bose, Yu Zhang</dc:creator>
    </item>
    <item>
      <title>A Survey on Reinforcement Learning in Aviation Applications</title>
      <link>https://arxiv.org/abs/2211.02147</link>
      <description>arXiv:2211.02147v3 Announce Type: replace 
Abstract: Compared with model-based control and optimization methods, reinforcement learning (RL) provides a data-driven, learning-based framework to formulate and solve sequential decision-making problems. The RL framework has become promising due to largely improved data availability and computing power in the aviation industry. Many aviation-based applications can be formulated or treated as sequential decision-making problems. Some of them are offline planning problems, while others need to be solved online and are safety-critical. In this survey paper, we first describe standard RL formulations and solutions. Then we survey the landscape of existing RL-based applications in aviation. Finally, we summarize the paper, identify the technical gaps, and suggest future directions of RL research in aviation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02147v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2024.108911</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence Volume 136, Part A Engineering Applications of Artificial Intelligence, Vol 136, October 2024, 108911</arxiv:journal_reference>
      <dc:creator>Pouria Razzaghi, Amin Tabrizian, Wei Guo, Shulu Chen, Abenezer Taye, Ellis Thompson, Alexis Bregeon, Ali Baheri, Peng Wei</dc:creator>
    </item>
    <item>
      <title>Soft-Minimum and Soft-Maximum Barrier Functions for Safety with Actuation Constraints</title>
      <link>https://arxiv.org/abs/2305.10620</link>
      <description>arXiv:2305.10620v4 Announce Type: replace 
Abstract: This paper presents two new control approaches for guaranteed safety (remaining in a safe set) subject to actuator constraints (the control is in a convex polytope). The control signals are computed using real-time optimization, including linear and quadratic programs subject to affine constraints, which are shown to be feasible. The first control method relies on a soft-minimum barrier function that is constructed using a finite-time-horizon prediction of the system trajectories under a known backup control. The main result shows that the control is continuous and satisfies the actuator constraints, and a subset of the safe set is forward invariant under the control. Next, we extend this method to allow from multiple backup controls. This second approach relies on a combined soft-maximum/soft-minimum barrier function, and it has properties similar to the first. We demonstrate these controls on numerical simulations of an inverted pendulum and a nonholonomic ground robot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10620v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedram Rabiee, Jesse B. Hoagg</dc:creator>
    </item>
    <item>
      <title>Physics-Guided Actor-Critic Reinforcement Learning for Swimming in Turbulence</title>
      <link>https://arxiv.org/abs/2406.10242</link>
      <description>arXiv:2406.10242v2 Announce Type: replace 
Abstract: Turbulent diffusion causes particles placed in proximity to separate. We investigate the required swimming efforts to maintain a particle close to its passively advected counterpart. We explore optimally balancing these efforts with the intended goal by developing and comparing a novel Physics-Informed Reinforcement Learning (PIRL) strategy with prescribed control (PC) and standard physics-agnostic Reinforcement Learning strategies. Our PIRL scheme, coined the Actor-Physicist, is an adaptation of the Actor-Critic algorithm in which the Neural Network parameterized Critic is replaced with an analytically derived physical heuristic function (the physicist). This strategy is then compared with an analytically computed optimal PC policy derived from a stochastic optimal control formulation and standard physics-agnostic Actor-Critic type algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10242v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>nlin.CD</category>
      <category>physics.flu-dyn</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Koh, Laurent Pagnier, Michael Chertkov</dc:creator>
    </item>
    <item>
      <title>A Physical-Layer Orchestration Framework for Open System Models of Autonomous RISs</title>
      <link>https://arxiv.org/abs/2304.10858</link>
      <description>arXiv:2304.10858v3 Announce Type: replace-cross 
Abstract: To obviate the control of reconfigurable intelligent surfaces (RISs) and related overhead, recent works envisioned the concept of autonomous RISs: Intelligent devices capable of autonomously deciding their reflection states. This paradigm is enabled by hybrid RIS (HRIS), a hardware solution that integrates sensing and channel estimation (CHEST) capabilities, enabling autonomous operation. Autonomous RISs operate independently alongside other network entities, promoting open communication system models for RISs. However, this autonomy introduces a significant challenge: How to schedule the operation of the autonomous RIS over time and frequency to minimize its impact on the network? This paper introduces a physical layer (PHY) orchestration framework within a massive multiple-input multiple-output (mMIMO) network to address this challenge. Our framework highlights an engineering trade-off termed the "autonomous RIS trade-off," which examines the performance implications of autonomy. Through mathematical analysis and numerical results, we describe the HRIS feasibility region, illustrating the conditions under which autonomous RISs are viable when properly deployed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10858v3</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Croisfelt, Francesco Devoti, Fabio Saggese, Vincenzo Sciancalepore, Xavier Costa-P\'erez, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Achieving Realistic Cyclist Behavior in SUMO using the SimRa Dataset</title>
      <link>https://arxiv.org/abs/2305.01763</link>
      <description>arXiv:2305.01763v2 Announce Type: replace-cross 
Abstract: Increasing the modal share of bicycle traffic to reduce carbon emissions, reduce urban car traffic, and to improve the health of citizens, requires a shift away from car-centric city planning. For this, traffic planners often rely on simulation tools such as SUMO which allow them to study the effects of construction changes before implementing them. Similarly, studies of vulnerable road users, here cyclists, also use such models to assess the performance of communication-based road traffic safety systems. The cyclist model in SUMO, however, is very imprecise as SUMO cyclists behave either like slow cars or fast pedestrians, thus, casting doubt on simulation results for bicycle traffic. In this paper, we analyze acceleration, deceleration, velocity, and intersection left-turn behavior of cyclists in a large dataset of real world cycle tracks. We use the results to improve the existing cyclist model in SUMO and add three more detailed cyclist models and implement them in SUMO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01763v2</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.comcom.2023.04.015</arxiv:DOI>
      <arxiv:journal_reference>Elsevier Computer Communications, vol. 205, pp. 97-107, May 2023</arxiv:journal_reference>
      <dc:creator>Ahmet-Serdar Karakaya, Ioan-Alexandru Stef, Konstantin K\"ohler, Julian Heinovski, Falko Dressler, David Bermbach</dc:creator>
    </item>
    <item>
      <title>Where to Decide? Centralized vs. Distributed Vehicle Assignment for Platoon Formation</title>
      <link>https://arxiv.org/abs/2310.09580</link>
      <description>arXiv:2310.09580v3 Announce Type: replace-cross 
Abstract: Platooning is a promising cooperative driving application for future intelligent transportation systems. In order to assign vehicles to platoons, some algorithm for platoon formation is required. Such vehicle-to-platoon assignments have to be computed on-demand, e.g., when vehicles join or leave the freeways. In order to get best results from platooning, individual properties of involved vehicles have to be considered during the assignment computation. In this paper, we explore the computation of vehicle-to-platoon assignments as an optimization problem based on similarity between vehicles. We define the similarity and, vice versa, the deviation among vehicles based on the desired driving speed of vehicles and their position on the road. We create three approaches to solve this assignment problem: centralized solver, centralized greedy, and distributed greedy, using a Mixed Integer Programming (MIP) solver and greedy heuristics, respectively.Conceptually, the approaches differ in both knowledge about vehicles as well as methodology. We perform a large-scale simulation study using PlaFoSim to compare all approaches. While the distributed greedy approach seems to have disadvantages due to the limited local knowledge, it performs as good as the centralized solver approach across most metrics. Both outperform the centralized greedy approach, which suffers from synchronization and greedy selection effects. The centralized solver approach however assumes global knowledge and requires a complex MIP solver to compute vehicle-to-platoon assignments. Overall, the distributed greedy approach achieves close to optimal results but requires the least assumptions and complexity.Therefore, we consider the distributed greedy approach the best approach among all presented approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09580v3</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TITS.2024.3426615</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Intelligent Transportation Systems, 2024</arxiv:journal_reference>
      <dc:creator>Julian Heinovski, Falko Dressler</dc:creator>
    </item>
    <item>
      <title>Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2403.09793</link>
      <description>arXiv:2403.09793v3 Announce Type: replace-cross 
Abstract: Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot's navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot's exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot's social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, which states that social acting is oriented toward the acting of others. The DRL policy is trained in an environment where other agents interact socially integrated and reward the robot's behavior individually. The simulation results indicate that the proposed socially integrated navigation approach outperforms a socially aware approach in terms of ego navigation performance while significantly reducing the negative impact on all agents within the environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09793v3</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Fl\"ogel, Lars Fischer, Thomas Rudolf, Tobias Sch\"urmann, S\"oren Hohmann</dc:creator>
    </item>
    <item>
      <title>Modeling the Lane-Change Reactions to Merging Vehicles for Highway On-Ramp Simulations</title>
      <link>https://arxiv.org/abs/2404.09851</link>
      <description>arXiv:2404.09851v2 Announce Type: replace-cross 
Abstract: Enhancing simulation environments to replicate real-world driver behavior is essential for developing Autonomous Vehicle technology. While some previous works have studied the yielding reaction of lag vehicles in response to a merging car at highway on-ramps, the possible lane-change reaction of the lag car has not been widely studied. In this work we aim to improve the simulation of the highway merge scenario by including the lane-change reaction in addition to yielding behavior of main-lane lag vehicles, and we evaluate two different models for their ability to capture this reactive lane-change behavior. To tune the payoff functions of these models, a novel naturalistic dataset was collected on U.S. highways that provided several hours of merge-specific data to learn the lane change behavior of U.S. drivers. To make sure that we are collecting a representative set of different U.S. highway geometries in our data, we surveyed 50,000 U.S. highway on-ramps and then selected eight representative sites. The data were collected using roadside-mounted lidar sensors to capture various merge driver interactions. The models were demonstrated to be configurable for both keep-straight and lane-change behavior. The models were finally integrated into a high-fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09851v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/IV55156.2024.10588857</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE Intelligent Vehicles Symposium (IV)</arxiv:journal_reference>
      <dc:creator>Dustin Holley, Jovin Dsa, Hossein Nourkhiz Mahjoub, Gibran Ali, Tyler Naes, Ehsan Moradi-Pari, Pawan Sai Kallepalli</dc:creator>
    </item>
    <item>
      <title>Weyl Calculus and Exactly Solvable Schr\"{o}dinger Bridges with Quadratic State Cost</title>
      <link>https://arxiv.org/abs/2407.15245</link>
      <description>arXiv:2407.15245v2 Announce Type: replace-cross 
Abstract: Schr\"{o}dinger bridge--a stochastic dynamical generalization of optimal mass transport--exhibits a learning-control duality. Viewed as a stochastic control problem, the Schr\"{o}dinger bridge finds an optimal control policy that steers a given joint state statistics to another while minimizing the total control effort subject to controlled diffusion and deadline constraints. Viewed as a stochastic learning problem, the Schr\"{o}dinger bridge finds the most-likely distribution-valued trajectory connecting endpoint distributional observations, i.e., solves the two point boundary-constrained maximum likelihood problem over the manifold of probability distributions. Recent works have shown that solving the Schr\"{o}dinger bridge problem with state cost requires finding the Markov kernel associated with a reaction-diffusion PDE where the state cost appears as a state-dependent reaction rate. We explain how ideas from Weyl calculus in quantum mechanics, specifically the Weyl operator and the Weyl symbol, can help determine such Markov kernels. We illustrate these ideas by explicitly finding the Markov kernel for the case of quadratic state cost via Weyl calculus, recovering our earlier results but avoiding tedious computation with Hermite polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15245v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Wenqing Wang, Abhishek Halder</dc:creator>
    </item>
  </channel>
</rss>
