<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Jul 2025 01:27:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Effective Bayesian Modeling of Large Spatiotemporal Count Data Using Autoregressive Gamma Processes</title>
      <link>https://arxiv.org/abs/2507.19915</link>
      <description>arXiv:2507.19915v1 Announce Type: cross 
Abstract: We put forward a new Bayesian modeling strategy for spatiotemporal count data that enables efficient posterior sampling. Most previous models for such data decompose logarithms of the response Poisson rates into fixed effects and spatial random effects, where the latter is typically assumed to follow a latent Gaussian process, the conditional autoregressive model, or the intrinsic conditional autoregressive model. Since log-Gaussian is not conjugate to Poisson, such implementations must resort to either approximation methods like INLA or Metropolis moves on latent states in MCMC algorithms for model fitting and exhibit several approximation and posterior sampling challenges. Instead of modeling logarithms of spatiotemporal frailties jointly as a Gaussian process, we construct a spatiotemporal autoregressive gamma process guaranteed stationary across the time dimension. We decompose latent Poisson variables to permit fully conjugate Gibbs sampling of spatiotemporal frailties and design a sparse spatial dependence structure to get a linear computational complexity that facilitates efficient posterior computation. Our model permits convenient Bayesian predictive machinery based on posterior samples that delivers satisfactory performance in predicting at new spatial locations and time intervals. We have performed extensive simulation experiments and real data analyses, which corroborated our model's accurate parameter estimation, model fitting, and out-of-sample prediction capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19915v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Cheng, Cheng Li</dc:creator>
    </item>
    <item>
      <title>Computation of Optimal Type-II Progressing Censoring Scheme Using Genetic Algorithm Approach</title>
      <link>https://arxiv.org/abs/2507.20001</link>
      <description>arXiv:2507.20001v1 Announce Type: cross 
Abstract: The experimenter must perform a legitimate search in the entire set of feasible censoring schemes to identify the optimal type II progressive censoring scheme, when applied to a life-testing experiment. Current recommendations are limited to small sample sizes. Exhaustive search strategies are not practically feasible for large sample sizes. This paper proposes a meta-heuristic algorithm based on the genetic algorithm for large sample sizes. The algorithm is found to provide optimal or near-optimal solutions for small sample sizes and large sample sizes. Our suggested optimal criterion is based on the cost function and is scale-invariant for both location-scale and log-location-scale distribution families. To investigate how inaccurate parameter values or cost coefficients may affect the optimal solution, a sensitivity analysis is also taken into account.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20001v1</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ujjwal Roy, Ritwik Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Clustering data with values missing at random using scale mixtures of multivariate skew-normal distributions</title>
      <link>https://arxiv.org/abs/2507.20329</link>
      <description>arXiv:2507.20329v1 Announce Type: cross 
Abstract: Handling missing data is a major challenge in model-based clustering, especially when the data exhibit skewness and heavy tails. We address this by extending the finite mixture of scale mixtures of multivariate skew-normal (FMSMSN) family to accommodate incomplete data under a missing at random (MAR) mechanism. Unlike previous work that is limited to one of the special cases of the FMSMSN family, our method offers a cluster analysis methodology for the entire family that accounts for skewness and excess kurtosis amidst data with missing values. The multivariate skew-normal distribution, as parameterised by \cite{azzalini1996} and \cite{arnoldbeaver} includes the normal distribution as a special case, which ensures that our method is flexible toward existing symmetric model-based clustering techniques under a normality assumption. We derive the distributional properties of the missing components of the data and propose an augmented EM-type algorithm tailored for incomplete observations. The modified E-step yields closed-form expressions for the conditional expectations of the missing values. The simulation experiments showcase the flexibility of the FMSMSN family in both clustering performance and parameter recovery for varying percentages of missing values, while incorporating the effects of sample size and cluster proximity. Finally, we illustrate the practical utility of the proposed method by applying special cases of the FMSMSN family to global CO2 emissions data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20329v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Pillay, Cristina Tortora, Antonio Punzo, Andriette Bekker</dc:creator>
    </item>
    <item>
      <title>Independence Testing for Mixed Data</title>
      <link>https://arxiv.org/abs/2507.20609</link>
      <description>arXiv:2507.20609v1 Announce Type: cross 
Abstract: We consider the problem of testing independence in mixed-type data that combine count variables with positive, absolutely continuous variables. We first introduce two distinct classes of test statistics in the bivariate setting, designed to test independence between the components of a bivariate mixed-type vector. These statistics are then extended to the multivariate context to accommodate: (i) testing independence between vectors of different types and possibly different dimensions, and (ii) testing total independence among all components of vectors with different types. The construction is based on the recently introduced Baringhaus-Gaigall transformation, which characterizes the joint distribution of such data. We establish the asymptotic properties of the resulting tests and, through an extensive power study, demonstrate that the proposed approach is both competitive and flexible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20609v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dana Bucalo Jeli\'c, Marija Cupari\'c, Bojana Milo\v{s}evi\'c</dc:creator>
    </item>
    <item>
      <title>LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale Multi-view Clustering</title>
      <link>https://arxiv.org/abs/2507.20980</link>
      <description>arXiv:2507.20980v1 Announce Type: cross 
Abstract: Deep anchor-based multi-view clustering methods enhance the scalability of neural networks by utilizing representative anchors to reduce the computational complexity of large-scale clustering. Despite their scalability advantages, existing approaches often incorporate anchor structures in a heuristic or task-agnostic manner, either through post-hoc graph construction or as auxiliary components for message passing. Such designs overlook the core structural demands of anchor-based clustering, neglecting key optimization principles. To bridge this gap, we revisit the underlying optimization problem of large-scale anchor-based multi-view clustering and unfold its iterative solution into a novel deep network architecture, termed LargeMvC-Net. The proposed model decomposes the anchor-based clustering process into three modules: RepresentModule, NoiseModule, and AnchorModule, corresponding to representation learning, noise suppression, and anchor indicator estimation. Each module is derived by unfolding a step of the original optimization procedure into a dedicated network component, providing structural clarity and optimization traceability. In addition, an unsupervised reconstruction loss aligns each view with the anchor-induced latent space, encouraging consistent clustering structures across views. Extensive experiments on several large-scale multi-view benchmarks show that LargeMvC-Net consistently outperforms state-of-the-art methods in terms of both effectiveness and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20980v1</guid>
      <category>cs.CV</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shide Du, Chunming Wu, Zihan Fang, Wendi Zhao, Yilin Wu, Changwei Wang, Shiping Wang</dc:creator>
    </item>
    <item>
      <title>Dimension-free Relaxation Times of Informed MCMC Samplers on Discrete Spaces</title>
      <link>https://arxiv.org/abs/2404.03867</link>
      <description>arXiv:2404.03867v2 Announce Type: replace 
Abstract: Convergence analysis of Markov chain Monte Carlo methods in high-dimensional statistical applications is increasingly recognized. In this paper, we develop general mixing time bounds for Metropolis-Hastings algorithms on discrete spaces by building upon and refining some recent theoretical advancements in Bayesian model selection problems. We establish sufficient conditions for a class of informed Metropolis-Hastings algorithms to attain relaxation times that are independent of the problem dimension. These conditions are grounded in the high-dimensional statistical theory and allow for possibly multimodal posterior distributions. We obtain our results through two independent techniques: the multicommodity flow method and single-element drift condition analysis; we find that the latter yields a slightly tighter mixing time bound. Our results are readily applicable to a broad spectrum of statistical problems with discrete parameter spaces, as we demonstrate using both theoretical and numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03867v2</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunwoong Chang, Quan Zhou</dc:creator>
    </item>
    <item>
      <title>Prediction of microstructural representativity from a single image</title>
      <link>https://arxiv.org/abs/2410.19568</link>
      <description>arXiv:2410.19568v2 Announce Type: replace 
Abstract: In this study, we present a method for predicting the representativity of the phase fraction observed in a single image (2D or 3D) of a material. Traditional approaches often require large datasets and extensive statistical analysis to estimate the Integral Range, a key factor in determining the variance of microstructural properties. Our method leverages the Two-Point Correlation function to directly estimate the variance from a single image, thereby enabling phase fraction prediction with associated confidence levels. We validate our approach using open-source datasets, demonstrating its efficacy across diverse microstructures. This technique significantly reduces the data requirements for representativity analysis, providing a practical tool for material scientists and engineers working with limited microstructural data. To make the method easily accessible, we have created a web-application, www.imagerep.io, for quick, simple and informative use of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19568v2</guid>
      <category>stat.CO</category>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/advs.202414149</arxiv:DOI>
      <arxiv:journal_reference>Advanced Science 2025</arxiv:journal_reference>
      <dc:creator>Amir Dahari, Ronan Docherty, Steve Kench, Samuel J. Cooper</dc:creator>
    </item>
    <item>
      <title>Analysis and conditional optimization of projection estimates for distribution of random variable using Legendre polynomials</title>
      <link>https://arxiv.org/abs/2506.14822</link>
      <description>arXiv:2506.14822v2 Announce Type: replace 
Abstract: Algorithms for jointly obtaining projection estimates of the density and distribution function of a random variable using Legendre polynomials are proposed. For these algorithms, a problem of the conditional optimization is solved. Such optimization allows one to increase the approximation accuracy with minimum computational costs. The proposed algorithms are tested on examples with different degrees of smoothness of the density. A projection estimate of the density is compared to a histogram that is often used in applications to estimate distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14822v2</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/a18080466</arxiv:DOI>
      <arxiv:journal_reference>Algorithms 2025, 18(8), 466</arxiv:journal_reference>
      <dc:creator>Tatyana A. Averina, Konstantin A. Rybakov</dc:creator>
    </item>
    <item>
      <title>Markov chain entropy games and the geometry of their Nash equilibria</title>
      <link>https://arxiv.org/abs/2310.04115</link>
      <description>arXiv:2310.04115v3 Announce Type: replace-cross 
Abstract: We introduce and study a two-player zero-sum game between a probabilist and Nature defined by a convex function $f$, a finite collection $\mathcal{B}$ of Markov generators (or its convex hull), and a target distribution $\pi$. The probabilist selects a mixed strategy $\mu \in \mathcal{P}(\mathcal{B})$, the set of probability measures on $\mathcal{B}$, while Nature adopts a pure strategy and selects a $\pi$-reversible Markov generator $M$. The probabilist receives a payoff equal to the $f$-divergence $D_f(M \| L)$, where $L$ is drawn according to $\mu$. We prove that this game always admits a mixed strategy Nash equilibrium and satisfies a minimax identity. In contrast, a pure strategy equilibrium may fail to exist. We develop a projected subgradient method to compute approximate mixed strategy equilibria with provable convergence guarantees. Connections to information centroids, Chebyshev centers, and Bayes risk are discussed. This paper extends earlier minimax results on $f$-divergences to the context of Markov generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04115v3</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>Analysis of multivariate event times under informative censoring using vine copula</title>
      <link>https://arxiv.org/abs/2502.20608</link>
      <description>arXiv:2502.20608v2 Announce Type: replace-cross 
Abstract: The study of times to nonterminal events of different types and their interrelation is a compelling area of interest. The primary challenge in analyzing such multivariate event times is the presence of informative censoring by the terminal event. While numerous statistical methods have been proposed for a single nonterminal event, i.e., semi-competing risks data, there remains a dearth of tools for analyzing times to multiple nonterminal events. This article introduces a novel analysis framework that leverages the vine copula to directly estimate the joint density of multivariate times to nonterminal and terminal events. Unlike the few existing methods based on multivariate or nested copulas, the developed approach excels in capturing the heterogeneous dependence between each pair of event times (nonterminal-terminal and between-nonterminal) in terms of strength and structure. We propose a likelihood-based estimation and inference procedure, which can be implemented efficiently in sequential stages. Through extensive simulation studies, we demonstrate the satisfactory finite-sample performance of our proposed stage-wise estimators and analytical variance estimators, as well as their advantages over existing methods. We apply the developed approach to data from a crowdfunding platform to investigate the relationship between various types of creator-backer interactions and a creator's lifetime on the platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20608v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyuan Chen, Yiwei Li, Qian M. Zhou</dc:creator>
    </item>
  </channel>
</rss>
