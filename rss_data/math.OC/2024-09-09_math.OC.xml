<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Sep 2024 02:49:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inferring Global Exponential Stability Properties using Lie-bracket Approximations</title>
      <link>https://arxiv.org/abs/2409.03871</link>
      <description>arXiv:2409.03871v1 Announce Type: new 
Abstract: In the present paper, a novel result for inferring uniform global, not semi-global, exponential stability in the sense of Lyapunov with respect to input-affine systems from global uniform exponential stability properties with respect to their associated Lie-bracket systems is shown. The result is applied to adapt dither frequencies to find a sufficiently high gain in adaptive control of linear unknown systems, and a simple numerical example is simulated to support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03871v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Weber, Bahman Gharesifard, Christian Ebenbauer</dc:creator>
    </item>
    <item>
      <title>Time-Triggered Reduced Desensitization Formulation For Solving Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2409.03884</link>
      <description>arXiv:2409.03884v1 Announce Type: new 
Abstract: Fuel-optimal trajectories are inherently sensitive to variations in model parameters, such as propulsion system thrust magnitude. This inherent sensitivity can lead to dispersions in cost-functional values, when model parameters have uncertainties. Desensitized optimal control aims at generating robust optimal solutions while taking into account uncertainties in the model parameters. While desensitization techniques typically apply along the entire flight time, this paper introduces a novel time-triggered desensitization mechanism by modifying a recently developed desensitization method -- the Reduced Desensitization Formulation (RDF). By selectively desensitizing over specific time intervals of trajectories, we demonstrate the improved optimality of desensitized trajectories. We investigate the effects of temporal desensitization on the final cost and trajectory by considering thrust magnitude uncertainty for two classes of low-thrust trajectory optimization problems: 1) minimum-fuel rendezvous maneuvers and 2) orbit-raising maneuvers. Results show that temporal desensitization can achieve similar dispersion levels to full mission desensitization with an improved final cost functional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03884v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Praveen Jawaharlal Ayyanathan, Ehsan Taheri</dc:creator>
    </item>
    <item>
      <title>Maximizing On-Bill Savings through Battery Management Optimization</title>
      <link>https://arxiv.org/abs/2409.03942</link>
      <description>arXiv:2409.03942v1 Announce Type: new 
Abstract: In many power grids, a large portion of the energy costs for commercial and industrial consumers are set with reference to the coincident peak load, the demand during the maximum system-wide peak, and their own maximum peak load, the non-coincident peak load. Coincident-peak based charges reflect the allocation of infrastructure updates to end-users for increased capacity, the amount the grid can handle, and for improvement of the transmission, the ability to transport energy across the network. Demand charges penalize the stress on the grid caused by each consumer's peak demand. Microgrids with a local generator, controllable loads, and/or a battery technology have the flexibility to cut their peak load contributions and thereby significantly reduce these charges. This paper investigates the optimal planning of microgrid technology for electricity bill reduction. The specificity of our approach is the leveraging of a scenario generator engine to incorporate probability estimates of coincident peaks and non-coincident peaks into the optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03942v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Carmona, Xinshuo Yang, Siddharth Bhela, Claire Zeng</dc:creator>
    </item>
    <item>
      <title>Open-loop Pareto-Nash equilibria in multi-objective interval differential games</title>
      <link>https://arxiv.org/abs/2409.04012</link>
      <description>arXiv:2409.04012v1 Announce Type: new 
Abstract: The paper explores n-player multi-objective interval differential games, where the terminal payoff function and integral payoff function of players are both interval-vector-valued functions. Firstly, by leveraging the partial order relationship among interval vectors, we establish the concept of (weighted) open-loop Pareto-Nash equilibrium for multi-objective interval differential games and derive two theorems regarding the existence of such equilibria. Secondly, necessary conditions for open-loop Pareto-Nash equilibria in n-player interval differential games are derived through constructing Hamilton functions in an interval form and applying the Pontryagin maximum principle. Subsequently, sufficient conditions for their existence are provided by defining a maximization Hamilton function and utilizing its concavity. Finally, a two-player linear quadratic interval differential game is discussed along with a specific calculation method to determine its open-loop Pareto-Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04012v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Li, Du Zou, Deyi Li, Yuqiang Feng</dc:creator>
    </item>
    <item>
      <title>A policy iteration algorithm for non-Markovian control problems</title>
      <link>https://arxiv.org/abs/2409.04037</link>
      <description>arXiv:2409.04037v1 Announce Type: new 
Abstract: In this paper, we propose a new policy iteration algorithm to compute the value function and the optimal controls of continuous time stochastic control problems. The algorithm relies on successive approximations using linear-quadratic control problems which can all be solved explicitly, and only require to solve recursively linear PDEs in the Markovian case. Though our procedure fails in general to produce a non-decreasing sequence like the standard algorithm, it can be made arbitrarily close to being monotone. More importantly, we recover the standard exponential speed of convergence for both the value and the controls, through purely probabilistic arguments which are significantly simpler than in the classical case. Our proof also accommodates non-Markovian dynamics as well as volatility control, allowing us to obtain the first convergence results in the latter case for a state process in multi-dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04037v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan Possama\"i, Ludovic Tangpi</dc:creator>
    </item>
    <item>
      <title>Communication efficient quasi-Newton distributed optimization based on the Douglas-Rachford envelope</title>
      <link>https://arxiv.org/abs/2409.04049</link>
      <description>arXiv:2409.04049v1 Announce Type: new 
Abstract: We consider distributed optimization in the client-server setting. By use of Douglas-Rachford splitting to the dual of the sum problem, we design a BFGS method that requires minimal communication (sending/receiving one vector per round for each client). Our method is line search free and achieves superlinear convergence. Experiments are also used to demonstrate the merits in decreasing communication and computation costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04049v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dingran Yi, Nikolaos M. Freris</dc:creator>
    </item>
    <item>
      <title>Approximate D-optimal design and equilibrium measure *</title>
      <link>https://arxiv.org/abs/2409.04058</link>
      <description>arXiv:2409.04058v1 Announce Type: new 
Abstract: We introduce a variant of the D-optimal design of experiments problem with a more general information matrix that takes into account the representation of the design space S. The main motivation is that if S $\subset$ R d is the unit ball, the unit box or the canonical simplex, then remarkably, for every dimension d and every degree n, the equilibrium measure of S (in pluripotential theory) is an optimal solution. Equivalently, for each degree n, the unique optimal solution is the vector of moments (up to degree 2n) of the equilibrium measure of S. Hence nding an optimal design reduces to nding a cubature for the equilibrium measure, with atoms in S, positive weights, and exact up to degree 2n. In addition, any resulting sequence of atomic D-optimal measures converges to the equilibrium measure of S for the weak-star topology, as n increases. Links with Fekete sets of points are also discussed. More general compact basic semialgebraic sets are also considered, and a previously developed two-step design algorithm is easily adapted to this new variant of D-optimal design problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04058v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didier Henrion (LAAS-POP), Jean Bernard Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>Automatic Generation of Examinations in the Automatic Control Courses</title>
      <link>https://arxiv.org/abs/2409.04075</link>
      <description>arXiv:2409.04075v1 Announce Type: new 
Abstract: Final written examination is the most important part of summative assessment in automatic control courses. Preparation of the examinations with a given number of points according to the concept of Constructive Alignment (which could be the main concept in future automatic control education) takes significant amount of time of the educator and motivates development of a toolkit for automatic compilation of examination problems. A decision support Matlab-LATEX toolkit based on random number generators for selection of examination problems is described in this report to facilitate the alignment. The toolkit allows application of Stepwise Constructive Alignment (a new method described in this report), where the alignment is achieved by a number of software runs associated with random trials. In each step the educator manually selects suitable problems before each run based on evaluation of the random choice from the previous run. Automatic generation of the examination together with solutions for the course 'Process control and measurement techniques' is presented as an example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04075v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ifacol.2024.08.460</arxiv:DOI>
      <dc:creator>Alexander Stotsky, Torsten Wik</dc:creator>
    </item>
    <item>
      <title>Tighter Analysis for Decentralized Stochastic Gradient Method: Impact of Data Homogeneity</title>
      <link>https://arxiv.org/abs/2409.04092</link>
      <description>arXiv:2409.04092v1 Announce Type: new 
Abstract: This paper studies the effect of data homogeneity on multi-agent stochastic optimization. We consider the decentralized stochastic gradient (DSGD) algorithm and perform a refined convergence analysis. Our analysis is explicit on the similarity between Hessian matrices of local objective functions which captures the degree of data homogeneity. We illustrate the impact of our analysis through studying the transient time, defined as the minimum number of iterations required for a distributed algorithm to achieve comparable performance as its centralized counterpart. When the local objective functions have similar Hessian, the transient time of DSGD can be as small as ${\cal O}(n^{2/3}/\rho^{8/3})$ for smooth (possibly non-convex) objective functions, ${\cal O}(\sqrt{n}/\rho)$ for strongly convex objective functions, where $n$ is the number of agents and $\rho$ is the spectral gap of graph. These findings provide a theoretical justification for the empirical success of DSGD. Our analysis relies on a novel observation with higher-order Taylor approximation for gradient maps that can be of independent interest. Numerical simulations validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04092v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>Output Feedback Minimax Adaptive Control</title>
      <link>https://arxiv.org/abs/2409.04115</link>
      <description>arXiv:2409.04115v1 Announce Type: new 
Abstract: This paper formulates adaptive controller design as a minimax dual control problem. The objective is to design a controller that minimizes the worst-case performance over a set of uncertain systems. The uncertainty is described by a set of linear time-invariant systems with unknown parameters. The main contribution is a common framework for both state feedback and output feedback control. We show that for finite uncertainty sets, the minimax dual control problem admits a finite-dimensional information state. This information state can be used to design adaptive controllers that ensure that the closed-loop has finite gain. The controllers are derived from a set of Bellman inequalities that are amenable to numerical solutions. The proposed framework is illustrated on a challenging numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04115v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olle Kjellqvist, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>A General Method for Optimal Decentralized Control with Current State/Output Feedback Strategy</title>
      <link>https://arxiv.org/abs/2409.04144</link>
      <description>arXiv:2409.04144v1 Announce Type: new 
Abstract: This paper explores the decentralized control of linear deterministic systems in which different controllers operate based on distinct state information, and extends the findings to the output feedback scenario. Assuming the controllers have a linear state feedback structure, we derive the expression for the controller gain matrices using the matrix maximum principle. This results in an implicit expression that couples the gain matrices with the state. By reformulating the backward Riccati equation as a forward equation, we overcome the coupling between the backward Riccati equation and the forward state equation. Additionally, we employ a gradient descent algorithm to find the solution to the implicit equation. This approach is validated through simulation examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04144v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongdan Li, Yawen Sun, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Fixed Topology Minimum-Length Trees with Neighborhoods</title>
      <link>https://arxiv.org/abs/2409.04152</link>
      <description>arXiv:2409.04152v1 Announce Type: new 
Abstract: In this paper, we introduce the Fixed Topology Minimum-Length Tree with Neighborhood Problem, which aims to embed a rooted tree-shaped graph into a $d$-dimensional metric space while minimizing its total length provided that the nodes must be embedded to some restricted areas. This problem has significant applications in efficiently routing cables or pipelines in engineering designs. We propose novel mathematical optimization-based approaches to solve different versions of the problem based on the domain for the embedding. In cases where the embedding maps to a continuous space, we provide several Mixed Integer Nonlinear Optimization formulations. If the embedding is to a network, we derive a mixed integer linear programming formulation as well as a dimensionality reduction methodology that allows for solving larger problems in less CPU time. A data-driven methodology is also proposed to construct a proper network based on the instance of the problem. We report the results of a battery of computational experiments that validate our proposal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04152v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Gabriel Gonz\'alez, Justo Puerto</dc:creator>
    </item>
    <item>
      <title>Stationarity in nonsmooth optimization between geometrical motivation and topological relevance</title>
      <link>https://arxiv.org/abs/2409.04222</link>
      <description>arXiv:2409.04222v1 Announce Type: new 
Abstract: The goal of this paper is to compare alternative stationarity notions in structured nonsmooth optimization (SNO). Here, nonsmoothness is caused by complementarity, vanishing, orthogonality type, switching, or disjunctive constraints. On one side, we consider geometrically motivated notions of $\widehat N$-, $N$-, and $\overline{N}$-stationarity in terms of Fr\'echet, Mordukhovich, and Clarke normal cones to the feasible set, respectively. On the other side, we advocate the notion of topologically relevant T-stationarity, which adequately captures the global structure of SNO. Our main findings say that (a) $\widehat N$-stationary points include all local minimizers; (b) $N$-stationary points, which are not $\widehat N$-stationary, correspond to the singular saddle points of first order; (c) T-stationary points, which are not $N$-stationary, correspond to the regular saddle points of first order; (d) $\overline{N}$-stationary points, which are not T-stationary, are irrelevant for optimization purposes. Overall, a hierarchy of stationarity notions for SNO is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04222v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Shikhman</dc:creator>
    </item>
    <item>
      <title>Refined Bounds on Near Optimality Finite Window Policies in POMDPs and Their Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.04351</link>
      <description>arXiv:2409.04351v1 Announce Type: new 
Abstract: Finding optimal policies for Partially Observable Markov Decision Processes (POMDPs) is challenging due to their uncountable state spaces when transformed into fully observable Markov Decision Processes (MDPs) using belief states. Traditional methods such as dynamic programming or policy iteration are difficult to apply in this context, necessitating the use of approximation methods on belief states or other techniques. Recently, in (Journal of Machine Learning Research, vol. 23, pp. 1-46, 2022) and (Mathematics of Operations Research, vol. 48, pp. 2066-2093, Nov. 2023), it was shown that sliding finite window based policies are near-optimal for POMDPs with standard Borel valued hidden state spaces, and can be learned via reinforcement learning, with error bounds explicitly dependent on a uniform filter stability term involving total variation in expectation and sample path-wise, respectively. In this paper, we refine these performance bounds and (i) extend them to bounds via uniform filter stability in expected Wasserstein distance leading to an error bound in expectation, and (ii) complementary conditions bounds via uniform filter stability in sample path-wise total variation distance leading to a uniform error bound. We present explicit examples. Our approach thus provides complementary and more refined bounds on the error terms in both total variation and Wasserstein metrics, offering more relaxed and stronger bounds over the approximation error in POMDP solutions on the performance and near optimality of sliding finite window control policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04351v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunus Emre Demirci, Ali Devran Kara, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Two Pareto Optimum-based Heuristic Algorithms for Minimizing Tardiness and Late Jobs in the Single Machine Flowshop Problem</title>
      <link>https://arxiv.org/abs/2409.03778</link>
      <description>arXiv:2409.03778v1 Announce Type: cross 
Abstract: Flowshop problems play a prominent role in operations research, and have considerable practical significance. The single-machine flowshop problem is of particular theoretical interest. Until now the problem of minimizing late jobs or job tardiness can only be solved exactly by computationally-intensive methods such as dynamic programming or linear programming.
  In this paper we introduce, test, and optimize two new heuristic algorithms for mixed tardiness and late job minimization in single-machine flowshops. The two algorithms both build partial schedules iteratively. Both also retain Pareto optimal solutions at intermediate stages, to take into account both tardiness and late jobs within the partial schedule, as well as the effect of partial completion time on not-yet scheduled jobs.
  Both algorithms can be applied to scenarios with hundreds of jobs, with execution times running from less than a second to a few minutes. Although they are slower than dispatch rule-based heuristics, the solutions obtained are far better. We also compare a neural-network solution, which performs poorly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03778v1</guid>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Gradwohl, Guidio Sewa, Oke Blessing Oghojafor, Richard Wilouwou, Muminu Adamu, Christopher Thron</dc:creator>
    </item>
    <item>
      <title>Sequential bi-level regularized inversion with application to hidden reaction law discovery</title>
      <link>https://arxiv.org/abs/2409.03834</link>
      <description>arXiv:2409.03834v1 Announce Type: cross 
Abstract: In this article, we develop and present a novel regularization scheme for ill-posed inverse problems governed by nonlinear partial differential equations (PDEs). In [43], the author suggested a bi-level regularization framework. This study significantly improves upon the bi-level algorithm by sequential initialization, yielding accelerated convergence and demonstrable multi-scale effect, while retaining regularizing effect with respect to noise and allows for the usage of inexact PDE solvers. The sequential bi-level approach illustrates its universality through several reaction-diffusion applications, in which the nonlinear reaction law needs to be determined. To demonstrate the applicability of our algorithms, we moreover prove that the proposed tangential cone condition is satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03834v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tram Thi Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Control for Chance-Constrained Signal Temporal Logic Specifications</title>
      <link>https://arxiv.org/abs/2409.03855</link>
      <description>arXiv:2409.03855v1 Announce Type: cross 
Abstract: We consider distributionally robust optimal control of stochastic linear systems under signal temporal logic (STL) chance constraints when the disturbance distribution is unknown. By assuming that the underlying predicate functions are Lipschitz continuous and the noise realizations are drawn from a distribution having a concentration of measure property, we first formulate the underlying chance-constrained control problem as stochastic programming with constraints on expectations and propose a solution using a distributionally robust approach based on the Wasserstein metric. We show that by choosing a proper Wasserstein radius, the original chance-constrained optimization can be satisfied with a user-defined confidence level. A numerical example illustrates the efficacy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03855v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arash Bahari Kordabad, Eleftherios E. Vlahakis, Lars Lindemann, Dimos V. Dimarogonas, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>Asynchronous Stochastic Approximation and Average-Reward Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.03915</link>
      <description>arXiv:2409.03915v1 Announce Type: cross 
Abstract: This paper studies asynchronous stochastic approximation (SA) algorithms and their application to reinforcement learning in semi-Markov decision processes (SMDPs) with an average-reward criterion. We first extend Borkar and Meyn's stability proof method to accommodate more general noise conditions, leading to broader convergence guarantees for asynchronous SA algorithms. Leveraging these results, we establish the convergence of an asynchronous SA analogue of Schweitzer's classical relative value iteration algorithm, RVI Q-learning, for finite-space, weakly communicating SMDPs. Furthermore, to fully utilize the SA results in this application, we introduce new monotonicity conditions for estimating the optimal reward rate in RVI Q-learning. These conditions substantially expand the previously considered algorithmic framework, and we address them with novel proof arguments in the stability and convergence analysis of RVI Q-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03915v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huizhen Yu, Yi Wan, Richard S. Sutton</dc:creator>
    </item>
    <item>
      <title>Online Residual Learning from Offline Experts for Pedestrian Tracking</title>
      <link>https://arxiv.org/abs/2409.04069</link>
      <description>arXiv:2409.04069v2 Announce Type: cross 
Abstract: In this paper, we consider the problem of predicting unknown targets from data. We propose Online Residual Learning (ORL), a method that combines online adaptation with offline-trained predictions. At a lower level, we employ multiple offline predictions generated before or at the beginning of the prediction horizon. We augment every offline prediction by learning their respective residual error concerning the true target state online, using the recursive least squares algorithm. At a higher level, we treat the augmented lower-level predictors as experts, adopting the Prediction with Expert Advice framework. We utilize an adaptive softmax weighting scheme to form an aggregate prediction and provide guarantees for ORL in terms of regret. We employ ORL to boost performance in the setting of online pedestrian trajectory prediction. Based on data from the Stanford Drone Dataset, we show that ORL can demonstrate best-of-both-worlds performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04069v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasios Vlachos, Anastasios Tsiamis, Aren Karapetyan, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Algorithms for Finding the Best Pure Nash Equilibrium in Edge-weighted Budgeted Maximum Coverage Games</title>
      <link>https://arxiv.org/abs/2409.04078</link>
      <description>arXiv:2409.04078v1 Announce Type: cross 
Abstract: This paper introduces a new integer programming game (IPG) named the Edge-weighted Budgeted Maximum Coverage (EBMC) game and proposes a new algorithm, the Best Response Plus (BR-plus) algorithm, for finding the best Pure Nash Equilibrium (PNE). We demonstrate this methodology by optimizing county-level decisions to prevent aquatic invasive species (AIS) in Minnesota lakes, where each county-level decision makers has self-serving objectives while AIS is an interconnected issue that crosses county borders. Specifically, we develop EBMC games to model the strategic interactions among county-level decision-makers with two variations in utility functions. We also study and prove the existence of a PNE in these models under specified conditions. We advance the current state-of-the-art, which is limited to only a few players, by presenting the BR-plus algorithm that can handle a large set of players via utilizing the best response dynamics for finding PNE in normal-form games. Experimental results show that our BR-plus algorithm offers computational advantages over the ZR algorithm, especially in larger games, on both random and real-world networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04078v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunwoo Lee, Robert Hildebrand, Wenbo Cai, \.I. Esra B\"uy\"uktahtak{\i}n</dc:creator>
    </item>
    <item>
      <title>A Stackelberg Game based on the Secretary Problem: Optimal Response is History Dependent</title>
      <link>https://arxiv.org/abs/2409.04153</link>
      <description>arXiv:2409.04153v1 Announce Type: cross 
Abstract: This article considers a problem arising from a two-player game based on the classical secretary problem. First, Player 1 selects one object from a sequence as in the secretary problem. All of the other objects are then presented to Player 2 in the same order as in the original sequence. The goal of both players is to select the best object. The optimal response of Player 2 is adapted to the optimal strategy in the secretary problem. This means that when Player 2 observes an object that is the best seen so far, it can be inferred whether Player 1 selected one of the earlier objects in the original sequence. However, Player 2 cannot compare the current object with the one selected by Player 1. Hence, this game defines an auxiliary problem in which Player 2 has incomplete information on the relative rank of an object. It is shown that the optimal strategy of Player 2 is based on both the number of objects to have appeared and the probability that the current object is better than the object chosen by Player 1 (if Player 1 chose an earlier object in the sequence). However, this probability is dependent on the previously observed objects. A lower bound on the optimal expected reward in the auxiliary problem is defined by limiting the memory of Player 2. An upper bound is derived by giving Player 2 additional information at appropriate times. The methods used illustrate approaches that can be used to approximate the optimal reward in a stopping problem when there is incomplete information on the ranks of objects and/or the optimal strategy is history dependent, as in the Robbins' problem</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04153v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Ramsey</dc:creator>
    </item>
    <item>
      <title>Towards a Socially Acceptable Competitive Equilibrium in Energy Markets</title>
      <link>https://arxiv.org/abs/2409.04157</link>
      <description>arXiv:2409.04157v1 Announce Type: cross 
Abstract: This paper addresses the problem of energy sharing between a population of price-taking agents who adopt decentralized primal-dual gradient dynamics to find the Competitive Equilibrium (CE). Although the CE is efficient, it does not ensure fairness and can potentially lead to high prices. As the agents and market operator share a social responsibility to keep the price below a certain socially acceptable threshold, we propose an approach where the agents modify their utility functions in a decentralized way. We introduce a dynamic feedback controller for the primal-dual dynamics to steer the agents to a Socially acceptable Competitive Equilibrium (SCE). We demonstrate our theoretical findings in a case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04157v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koorosh Shomalzadeh, Nima Monshizadeh</dc:creator>
    </item>
    <item>
      <title>Probabilistic Representation for Viscosity Solutions to Double-Obstacle Quasi-Variational Inequalities</title>
      <link>https://arxiv.org/abs/2409.04207</link>
      <description>arXiv:2409.04207v1 Announce Type: cross 
Abstract: We prove the existence and uniqueness of viscosity solutions to quasi-variational inequalities (QVIs) with both upper and lower obstacles. In contrast to most previous works, we allow all involved coefficients to depend on the state variable and do not assume any type of monotonicity. It is well known that double obstacle QVIs are related to zero-sum games of impulse control, and our existence result is derived by considering a sequence of such games. Full generality is obtained by allowing one player in the game to randomize their control. A by-product of our result is that the corresponding zero-sum game has a value, which is a direct consequence of viscosity comparison.
  Utilizing recent results for backward stochastic differential equations (BSDEs), we find that the unique viscosity solution to our QVI is related to optimal stopping of BSDEs with constrained jumps and, in particular, to the corresponding non-linear Snell envelope. This gives a new probabilistic representation for double obstacle QVIs. It should be noted that we consider the min-max version (or equivalently the max-min version); however, the conditions under which solutions to the min-max and max-min versions coincide remain unknown and is a topic left for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04207v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Magnus Perninge</dc:creator>
    </item>
    <item>
      <title>Minimization of the Pseudospectral Abscissa of a Quadratic Matrix Polynomial</title>
      <link>https://arxiv.org/abs/2409.04297</link>
      <description>arXiv:2409.04297v1 Announce Type: cross 
Abstract: For a quadratic matrix polynomial dependent on parameters and a given tolerance $\epsilon &gt; 0$, the minimization of the $\epsilon$-pseudospectral abscissa over the set of permissible parameter values is discussed, with applications in damping optimization and brake squeal reductions in mind. An approach is introduced that is based on nonsmooth and global optimization (or smooth optimization techniques such as BFGS if there are many parameters) equipped with a globally convergent criss-cross algorithm to compute the $\epsilon$-pseudospectral abscissa objective when the matrix polynomial is of small size. For the setting when the matrix polynomial is large, a subspace framework is introduced, and it is argued formally that it solves the minimization problem globally. The subspace framework restricts the parameter-dependent matrix polynomial to small subspaces, and thus solves the minimization problem for such restricted small matrix polynomials. It then expands the subspaces using the minimizers for the restricted polynomials. The proposed approach makes the global minimization of the $\epsilon$-pseudospectral abscissa possible for a quadratic matrix polynomial dependent on a few parameters and for sizes up to at least a few hundreds. This is illustrated on several examples originating from damping optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04297v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volker Mehrmann, Emre Mengi</dc:creator>
    </item>
    <item>
      <title>A naive aggregation algorithm for improving generalization in a class of learning problems</title>
      <link>https://arxiv.org/abs/2409.04352</link>
      <description>arXiv:2409.04352v1 Announce Type: cross 
Abstract: In this brief paper, we present a naive aggregation algorithm for a typical learning problem with expert advice setting, in which the task of improving generalization, i.e., model validation, is embedded in the learning process as a sequential decision-making problem. In particular, we consider a class of learning problem of point estimations for modeling high-dimensional nonlinear functions, where a group of experts update their parameter estimates using the discrete-time version of gradient systems, with small additive noise term, guided by the corresponding subsample datasets obtained from the original dataset. Here, our main objective is to provide conditions under which such an algorithm will sequentially determine a set of mixing distribution strategies used for aggregating the experts' estimates that ultimately leading to an optimal parameter estimate, i.e., as a consensus solution for all experts, which is better than any individual expert's estimate in terms of improved generalization or learning performances. Finally, as part of this work, we present some numerical results for a typical case of nonlinear regression problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04352v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K Befekadu</dc:creator>
    </item>
    <item>
      <title>Exact augmented Lagrangians for constrained optimization problems in Hilbert spaces II: Applications</title>
      <link>https://arxiv.org/abs/2305.03897</link>
      <description>arXiv:2305.03897v2 Announce Type: replace 
Abstract: This two-part study is devoted to the analysis of the so-called exact augmented Lagrangians, introduced by Di Pillo and Grippo for finite dimensional optimization problems, in the case of optimization problems in Hilbert spaces. In the second part of our study we present applications of the general theory of exact augmented Lagrangians to several constrained variational problems and optimal control problems, including variational problems with additional constraints at the boundary, isoperimetric problems, problems with nonholonomic equality constraints (PDE constraints), and optimal control problems for linear evolution equations. We provide sufficient conditions for augmented Lagrangians for these problems to be globally/completely exact, that is, conditions under which a constrained variational problem/optimal control problem becomes equivalent to the problem of unconstrained minimization of the corresponding exact augmented Lagrangian in primal and dual variables simultaneously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03897v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. V. Dolgopolik</dc:creator>
    </item>
    <item>
      <title>The Cooperative Maximal Covering Location Problem with ordered partial attractions</title>
      <link>https://arxiv.org/abs/2305.15169</link>
      <description>arXiv:2305.15169v3 Announce Type: replace 
Abstract: The Maximal Covering Location Problem (MCLP) is a classical location problem where a company maximizes the demand covered by placing a given number of facilities, and each demand node is covered if the closest facility is within a predetermined radius. In the cooperative version of the problem (CMCLP), it is assumed that the facilities of the decision maker act cooperatively to increase the customersz' attraction towards the company. In this sense, a demand node is covered if the aggregated partial attractions (or partial coverings) of open facilities exceed a threshold. In this work, we generalize the CMCLP introducing an Ordered Median function (OMf), a function that assigns importance weights to the sorted partial attractions of each customer and then aggregates the weighted attractions to provide the total level of attraction. We name this problem the Ordered Cooperative Maximum Covering Location Problem (OCMCLP). The OMf serves as a means to compute the total attraction of each customer to the company as an aggregation of ordered partial attractions and constitutes a unifying framework for CMCLP models.
  We introduce a multiperiod stochastic non-linear formulation for the CMCLP with an embedded assignment problem characterizing the ordered cooperative covering. For this model, two exact solution approaches are presented: a MILP reformulation with valid inequalities and an effective approach based on Generalized Benders' cuts. Extensive computational experiments are provided to test our results with randomly generated data and the problem is illustrated with a case study of locating charging stations for electric vehicles in the city of Trois-Rivi\`eres, Qu\'ebec (Canada).</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15169v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cor.2024.106782</arxiv:DOI>
      <arxiv:journal_reference>Dom\'inguez, C., G\'azquez, R., Morales, J. M., &amp; Pineda, S. (2024). The Cooperative Maximal Covering Location Problem with ordered partial attractions. Computers &amp; Operations Research, 170, 106782</arxiv:journal_reference>
      <dc:creator>Concepci\'on Dom\'inguez, Ricardo G\'azquez, Juan Miguel Morales, Salvador Pineda</dc:creator>
    </item>
    <item>
      <title>Optimality Conditions for Interval-Valued Optimization Problems on Riemannian Manifolds Under a Total Order Relation</title>
      <link>https://arxiv.org/abs/2309.09396</link>
      <description>arXiv:2309.09396v5 Announce Type: replace 
Abstract: This article explores fundamental properties of convex interval-valued functions defined on Riemannian manifolds. The study employs generalized Hukuhara directional differentiability to derive KKT-type optimality conditions for an interval-valued optimization problem on Riemannian manifolds. Based on type of functions involved in optimization problems, we consider the following cases:
  1. objective function as well as constraints are real-valued;
  2. objective function is interval-valued, and constraints are real-valued;
  3. objective function as well as constraints are interval-valued.
  The whole theory is justified with the help of examples. The order relation that we use throughout the paper is a total order relation defined on the collection of all closed and bounded intervals in $\mathbb{R}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09396v5</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Ahmad Bhat, Akhlad Iqbal, Mahwash Aftab</dc:creator>
    </item>
    <item>
      <title>Towards An Analytical Framework for Dynamic Potential Games</title>
      <link>https://arxiv.org/abs/2310.02259</link>
      <description>arXiv:2310.02259v3 Announce Type: replace 
Abstract: Potential game is an emerging notion and framework for studying N-player games, especially with heterogeneous players. In this paper, we build an analytical framework for dynamic potential games. We prove that a game is a dynamic potential game if and only if each player's value function can be decomposed as a potential function and a residual term which is solely dependent on other players' policies. This decomposition is consistent with the result in the static setting and enables us to identify and analyze an important and new class of dynamic potential games called the distributed game. Moreover, we prove that a game is a dynamic potential game if the value function has a symmetric Jacobian. This generalizes the differential characterization for static potential games by replacing the classical derivative with a new notation of functional derivative with respect to Markov policies. For a general class of continuous-time stochastic games, we explicitly characterize their potential functions. In particular, we show that the potential function of linear-quadratic games can be studied through a system of linear ODEs. Furthermore, under a rank condition on control coefficients, we prove a linear-quadratic game is a Markov potential game if and only if all players have identical cost functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02259v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Two-sided Assortment Optimization: Adaptivity Gaps and Approximation Algorithms</title>
      <link>https://arxiv.org/abs/2403.08929</link>
      <description>arXiv:2403.08929v4 Announce Type: replace 
Abstract: To address the challenge of choice congestion in matching markets, in this work, we introduce a two-sided assortment optimization framework under general choice preferences. The goal in this problem is to maximize the expected number of matches by deciding which assortments are displayed to the agents and the order in which they are shown. In this context, we identify several classes of policies that platforms can use in their design. Our goals are: (1) to measure the value that one class of policies has over another one, and (2) to approximately solve the optimization problem itself for a given class. For (1), we define the adaptivity gap as the worst-case ratio between the optimal values of two different policy classes. First, we show that the gap between the class of policies that statically show assortments to one-side first and the class of policies that adaptively show assortments to one-side first is exactly $1-1/e$. Second, we show that the gap between the latter class of policies and the fully adaptive class of policies that show assortments to agents one by one is exactly $1/2$. We also note that the worst policies are those who simultaneously show assortments to all the agents, in fact, we show that their adaptivity gap even with respect to one-sided static policies can be arbitrarily small. For (2), we first show that there exists a polynomial time policy that achieves a $1/4$ approximation factor within the class of policies that adaptively show assortments to agents one by one. Finally, when agents' preferences are governed by multinomial-logit models, we show that a 0.082 approximation factor can be obtained within the class of policies that show assortments to all agents at once.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08929v4</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar El Housni, Alfredo Torrico, Ulysse Hennebelle</dc:creator>
    </item>
    <item>
      <title>Optimal Experimental Design for Universal Differential Equations</title>
      <link>https://arxiv.org/abs/2408.07143</link>
      <description>arXiv:2408.07143v2 Announce Type: replace 
Abstract: Complex dynamic systems are typically either modeled using expert knowledge in the form of differential equations or via data-driven universal approximation models such as artificial neural networks (ANN). While the first approach has advantages with respect to interpretability, transparency, data-efficiency, and extrapolation, the second approach is able to learn completely unknown functional relations from data and may result in models that can be evaluated more efficiently. To combine the complementary advantages, universal differential equations (UDE) have been suggested. They replace unknown terms in the differential equations with ANN. Such hybrid models allow to both encode prior domain knowledge, such as first principles, and to learn unknown mechanisms from data. Often, data for the training of UDE can only be obtained via costly experiments. We consider optimal experimental design (OED) for planning of experiments and generating data needed to train UDE. The number of weights in the embedded ANN usually leads to an overfitting of the regression problem. To make the OED problem tractable for optimization, we propose and compare dimension reduction methods that are based on lumping of weights and singular value decomposition of the Fisher information matrix (FIM), respectively. They result in lower-dimensional variational differential equations, which are easier to solve and yield regular FIM. Our numerical results showcase the advantages of OED for UDE, such as increased data-efficiency and better extrapolation properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07143v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Plate, Carl Julius Martensen, Sebastian Sager</dc:creator>
    </item>
    <item>
      <title>Revenue Management with Calendar-Aware and Dependent Demands: Asymptotically Tight Fluid Approximations</title>
      <link>https://arxiv.org/abs/2409.02637</link>
      <description>arXiv:2409.02637v2 Announce Type: replace 
Abstract: When modeling the demand in revenue management systems, a natural approach is to focus on a canonical interval of time, such as a week, so that we forecast the demand over each week in the selling horizon. Ideally, we would like to use random variables with general distributions to model the demand over each week. The current demand can give a signal for the future demand, so we also would like to capture the dependence between the demands over different weeks. Prevalent demand models in the literature, which are based on a discrete-time approximation to a Poisson process, are not compatible with these needs. In this paper, we focus on revenue management models that are compatible with a natural approach for forecasting the demand. Building such models through dynamic programming is not difficult. We divide the selling horizon into multiple stages, each stage being a canonical interval of time on the calendar. We have random number of customer arrivals in each stage, whose distribution is arbitrary and depends on the number of arrivals in the previous stage. The question we seek to answer is the form of the corresponding fluid approximation. We give the correct fluid approximation in the sense that it yields asymptotically optimal policies. The form of our fluid approximation is surprising as its constraints use expected capacity consumption of a resource up to a certain time period, conditional on the demand in the stage just before the time period in question. As the resource capacities and number of stages increase with the same rate, our performance guarantee converges to one. To our knowledge, this result gives the first asymptotically optimal policy under dependent demands with arbitrary distributions. Our computational experiments indicate that using the correct fluid approximation can make a dramatic impact in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02637v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiyuan Li, Paat Rusmevichientong, Huseyin Topaloglu</dc:creator>
    </item>
    <item>
      <title>Convolution Bounds on Quantile Aggregation</title>
      <link>https://arxiv.org/abs/2007.09320</link>
      <description>arXiv:2007.09320v5 Announce Type: replace-cross 
Abstract: Quantile aggregation with dependence uncertainty has a long history in probability theory with wide applications in finance, risk management, statistics, and operations research. Using a recent result on inf-convolution of quantile-based risk measures, we establish new analytical bounds for quantile aggregation which we call convolution bounds. Convolution bounds both unify every analytical result available in quantile aggregation and enlighten our understanding of these methods. These bounds are the best available in general. Moreover, convolution bounds are easy to compute, and we show that they are sharp in many relevant cases. They also allow for interpretability on the extremal dependence structure. The results directly lead to bounds on the distribution of the sum of random variables with arbitrary dependence. We discuss relevant applications in risk management and economics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.09320v5</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Blanchet, Henry Lam, Yang Liu, Ruodu Wang</dc:creator>
    </item>
    <item>
      <title>The Stochastic Proximal Distance Algorithm</title>
      <link>https://arxiv.org/abs/2210.12277</link>
      <description>arXiv:2210.12277v4 Announce Type: replace-cross 
Abstract: Stochastic versions of proximal methods have gained much attention in statistics and machine learning. These algorithms tend to admit simple, scalable forms, and enjoy numerical stability via implicit updates. In this work, we propose and analyze a stochastic version of the recently proposed proximal distance algorithm, a class of iterative optimization methods that recover a desired constrained estimation problem as a penalty parameter $\rho \rightarrow \infty$. By uncovering connections to related stochastic proximal methods and interpreting the penalty parameter as the learning rate, we justify heuristics used in practical manifestations of the proximal distance method, establishing their convergence guarantees for the first time. Moreover, we extend recent theoretical devices to establish finite error bounds and a complete characterization of convergence rates regimes. We validate our analysis via a thorough empirical study, also showing that unsurprisingly, the proposed method outpaces batch versions on popular learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12277v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyu Jiang, Jason Xu</dc:creator>
    </item>
    <item>
      <title>The minimum number of chains in a noncrossing partition of a poset</title>
      <link>https://arxiv.org/abs/2302.00874</link>
      <description>arXiv:2302.00874v2 Announce Type: replace-cross 
Abstract: The notion of noncrossing partitions of a partially ordered set (poset) is introduced here. When the poset in question is $[n]=\{1,2,\dots, n\}$ with the complete order of natural numbers, conventional noncrossing partitions arise. The minimum possible number of chains contained in a noncrossing partition of a poset clearly reflects the structural complexity of the poset. For the poset $[n]$, this number is just one. However, for a generic poset, it is a challenging task to determine the minimum number. Our main result in the paper is some characterization of this quantity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00874v2</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Filomat, 38(8) (2024), 2915--2922</arxiv:journal_reference>
      <dc:creator>Ricky X. F. Chen</dc:creator>
    </item>
  </channel>
</rss>
