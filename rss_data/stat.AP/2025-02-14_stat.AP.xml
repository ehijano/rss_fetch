<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Feb 2025 05:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mortality simulations for insured and general populations</title>
      <link>https://arxiv.org/abs/2502.08814</link>
      <description>arXiv:2502.08814v1 Announce Type: new 
Abstract: This study presents a framework for high-resolution mortality simulations tailored to insured and general populations. Due to the scarcity of detailed demographic-specific mortality data, we leverage Iterative Proportional Fitting (IPF) and Monte Carlo simulations to generate refined mortality tables that incorporate age, gender, smoker status, and regional distributions. This methodology enhances public health planning and actuarial analysis by providing enriched datasets for improved life expectancy projections and insurance product development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08814v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asmik Nalmpatian, Christian Heumann</dc:creator>
    </item>
    <item>
      <title>Warnings based on risk matrices: a coherent framework with consistent evaluation</title>
      <link>https://arxiv.org/abs/2502.08891</link>
      <description>arXiv:2502.08891v1 Announce Type: new 
Abstract: Risk matrices are widely used across a range of fields and have found increasing utility in warning decision practices globally. However, their application in this context presents challenges, which range from potentially perverse warning outcomes to a lack of objective verification (i.e., evaluation) methods. This paper introduces a coherent framework for generating multi-level warnings from risk matrices to address these challenges. The proposed framework is general, is based on probabilistic forecasts of hazard severity or impact and is compatible with the Common Alerting Protocol (CAP). Moreover, it includes a family of consistent scoring functions for objectively evaluating the predictive performance of risk matrix assessments and the warnings they produce. These scoring functions enable the ranking of forecasters or warning systems and the tracking of system improvements by rewarding accurate probabilistic forecasts and compliance with warning service directives. A synthetic experiment demonstrates the efficacy of these scoring functions, while the framework is illustrated through warnings for heavy rainfall based on operational ensemble prediction system forecasts for Tropical Cyclone Jasper (Queensland, Australia, 2023). This work establishes a robust foundation for enhancing the reliability and verifiability of risk-based warning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08891v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert J. Taggart, David J. Wilke</dc:creator>
    </item>
    <item>
      <title>A Differential Index Measuring Rater's Capability in Educational Assessment</title>
      <link>https://arxiv.org/abs/2502.09099</link>
      <description>arXiv:2502.09099v1 Announce Type: new 
Abstract: A rater's ability to assign accurate scores can significantly impact the outcomes of educational assessments. However, common indices for evaluating rater characteristics typically focus on either their severity or their discrimination ability (i.e., skills to differentiate between students). Additionally, these indices are often developed without considering the rater's accuracy in scoring students at different ability levels. To address the limitations, this study proposes a single-value measure to assess a rater's capability of assigning accurate scores to students with varying ability levels. The measure is derived from the partial derivatives of each rater's passing rate concerning student ability. Mathematical derivations of the index under generalized multi-facet models and hierarchical rater models are provided. To ease the implementation of the index, this study develops parameter estimation using marginal likelihood and its Laplacian approximation which allows for efficient evaluation and processing of large datasets involving numerous students and raters. Simulation studies demonstrate the accuracy of parameter recovery using the approximate likelihood and show how the capability indices vary with different levels of rater severity. An empirical study further tests the practical applicability of the new measure, where raters evaluate essays on four topics: "family," "school," "sport," and "work." Results show that raters are most capable when rating the topic of family and least capable when rating sport, with individual raters displaying different capabilities across the various topics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09099v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Y. -G. Wang, J. Wu, X. Qiu</dc:creator>
    </item>
    <item>
      <title>Sequential Covariance Fitting for InSAR Phase Linking</title>
      <link>https://arxiv.org/abs/2502.09248</link>
      <description>arXiv:2502.09248v1 Announce Type: new 
Abstract: Traditional Phase-Linking (PL) algorithms are known for their high cost, especially with the huge volume of Synthetic Aperture Radar (SAR) images generated by Sentinel-1 SAR missions. Recently, a COvariance Fitting Interferometric Phase Linking (COFI-PL) approach has been proposed, which can be seen as a generic framework for existing PL methods. Although this method is less computationally expensive than traditional PL approaches, COFI-PL exploits the entire covariance matrix, which poses a challenge with the increasing time series of SAR images. However, COFI-PL, like traditional PL approaches, cannot accommodate the efficient inclusion of newly acquired SAR images. This paper overcomes this drawback by introducing a sequential integration of a block of newly acquired SAR images. Specifically, we propose a method for effectively addressing optimization problems associated with phase-only complex vectors on the torus based on the Majorization-Minimization framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09248v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dana El Hajjar, Guillaume Ginolhac, Yajing Yan, Mohammed Nabil El Korso</dc:creator>
    </item>
    <item>
      <title>Bayesian Matrix Factor Models for Demographic Analysis Across Age and Time</title>
      <link>https://arxiv.org/abs/2502.09255</link>
      <description>arXiv:2502.09255v1 Announce Type: new 
Abstract: Analyzing demographic data collected across multiple populations, time periods, and age groups is challenging due to the interplay of high dimensionality, demographic heterogeneity among groups, and stochastic variability within smaller groups. This paper proposes a Bayesian matrix factor model to address these challenges. By factorizing count data matrices as the product of low-dimensional latent age and time factors, the model achieves a parsimonious representation that mitigates overfitting and remains computationally feasible even when hundreds of subpopulations are involved. Smoothness in age factors and a dynamic evolution of time factors are achieved through informative priors, and an efficient Markov chain Monte Carlo algorithm is developed for posterior inference. Applying the model to Austrian district-level emigration data from 2002 to 2023 demonstrates its ability to reconstruct demographic processes using only a fraction of the parameters required by conventional factor models. Extensive cross-validation and out-of-sample forecasting exercises show that the proposed matrix factor model consistently outperforms standard benchmarks. Beyond statistical demography, the framework holds promise for a wide range of applications involving noisy, heterogeneous, and high-dimensional non-Gaussian matrix-valued data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09255v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregor Zens</dc:creator>
    </item>
    <item>
      <title>Project portfolio planning in the pharmaceutical industry - strategic objectives and quantitative optimization</title>
      <link>https://arxiv.org/abs/2502.09527</link>
      <description>arXiv:2502.09527v1 Announce Type: new 
Abstract: Many pharmaceutical companies face concerns with the maintenance of desired revenue levels. Sales forecasts for the current portfolio of products and projects may indicate a decline in revenue as the marketed products approach patent expiry. To counteract the potential downturn in revenue, and to establish revenue growth, an in-flow of new projects into the development phases is required. In this article, we devise an approach with which the in-flow of new projects could be optimized, while adhering to the objectives and constraints set on revenue targets, budget limitations and strategic considerations on the composition of the company's portfolio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09527v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Stig Johan Wiklund, Magnus Ytterstad, Frank Miller</dc:creator>
    </item>
    <item>
      <title>Statistical inference for Levy-driven graph supOU processes: From short- to long-memory in high-dimensional time series</title>
      <link>https://arxiv.org/abs/2502.08838</link>
      <description>arXiv:2502.08838v1 Announce Type: cross 
Abstract: This article introduces Levy-driven graph supOU processes, offering a parsimonious parametrisation for high-dimensional time-series, where dependencies between the individual components are governed via a graph structure. Specifically, we propose a model specification that allows for a smooth transition between short- and long-memory settings while accommodating a wide range of marginal distributions.
  We further develop an inference procedure based on the generalised method of moments, establish its asymptotic properties and demonstrate its strong finite sample performance through a simulation study.
  Finally, we illustrate the practical relevance of our new model and estimation method in an empirical study of wind capacity factors in an European electricity network context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08838v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Mehta, Almut E. D. Veraart</dc:creator>
    </item>
    <item>
      <title>Targeted Quality Measurement of Health Care Providers</title>
      <link>https://arxiv.org/abs/2105.02379</link>
      <description>arXiv:2105.02379v3 Announce Type: replace 
Abstract: Assessing the quality of cancer care administered by US health providers poses numerous challenges due to meaningful heterogeneity in patient populations. Patients undergoing oncology treatment exhibit substantial variation in disease presentation among other crucial characteristics. In this paper, we present a framework for institutional quality measurement that addresses this patient heterogeneity. Our framework follows recent advancements in health outcomes research, conceptualizing quality measurement as a causal inference problem. This approach enables us to use flexible covariate profiles to target specific patient populations of interest. We use different clinically relevant covariate profiles and evaluate methods for case-mix adjustments. These adjustments integrate weighting and regression modeling approaches in a progressive manner in order to reduce model extrapolation and allow for provider effect modification. We evaluate these methods in an extensive simulation study, comparing their performance in terms of point estimates and estimated rankings. We highlight the practical utility of weighting methods that can generate stable weights when covariate overlap is limited and alert investigators when case-mix adjustments are infeasible without some form of extrapolation that goes beyond the support of the observed data. In our study of cancer-care outcomes, we assess the performance of oncology practices for different profiles that correspond to important types of patients who may receive cancer care. We describe how the methods examined may be particularly important for high-stakes quality measurement, such as public reporting or performance-based payments. These methods have the potential to help inform individual patient health care decisions and contribute to progress toward more personalized quality measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.02379v3</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yige Li, Nancy L. Keating, Mary Beth Landrum, Jose R. Zubizarreta</dc:creator>
    </item>
    <item>
      <title>Targeting mediating mechanisms of social disparities with an interventional effects framework, applied to the gender pay gap in Western Germany</title>
      <link>https://arxiv.org/abs/2411.07368</link>
      <description>arXiv:2411.07368v4 Announce Type: replace 
Abstract: The Oaxaca-Blinder decomposition is a widely used method to explain social disparities. However, assigning causal meaning to its estimated components requires strong assumptions that often lack explicit justification. This paper emphasizes the importance of clearly defined estimands and their identification when targeting mediating mechanisms of social disparities. Three approaches are distinguished based on their scientific questions and assumptions: a mediation approach and two interventional approaches. The Oaxaca-Blinder decomposition and Monte Carlo simulation-based g-computation are discussed for estimation in relation to these approaches. The latter method is used in an interventional effects analysis of the observed gender pay gap in West Germany, using data from the 2017 German Socio-Economic Panel. Ten mediators, including indicators of human capital and job characteristics, are considered. Key findings indicate that the gender pay gap in log hourly wages could be reduced by up to 86% if these mediators were equally distributed between women and men. Substantial reductions could be achieved by aligning full-time employment and work experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07368v4</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christiane Didden</dc:creator>
    </item>
  </channel>
</rss>
