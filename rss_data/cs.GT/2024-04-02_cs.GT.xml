<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Apr 2024 19:06:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Policy Optimization finds Nash Equilibrium in Regularized General-Sum LQ Games</title>
      <link>https://arxiv.org/abs/2404.00045</link>
      <description>arXiv:2404.00045v1 Announce Type: new 
Abstract: In this paper, we investigate the impact of introducing relative entropy regularization on the Nash Equilibria (NE) of General-Sum $N$-agent games, revealing the fact that the NE of such games conform to linear Gaussian policies. Moreover, it delineates sufficient conditions, contingent upon the adequacy of entropy regularization, for the uniqueness of the NE within the game. As Policy Optimization serves as a foundational approach for Reinforcement Learning (RL) techniques aimed at finding the NE, in this work we prove the linear convergence of a policy optimization algorithm which (subject to the adequacy of entropy regularization) is capable of provably attaining the NE. Furthermore, in scenarios where the entropy regularization proves insufficient, we present a $\delta$-augmentation technique, which facilitates the achievement of an $\epsilon$-NE within the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00045v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Aneeq uz Zaman, Shubham Aggarwal, Melih Bastopcu, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Winning Without Observing Payoffs: Exploiting Behavioral Biases to Win Nearly Every Round</title>
      <link>https://arxiv.org/abs/2404.00150</link>
      <description>arXiv:2404.00150v1 Announce Type: new 
Abstract: Gameplay under various forms of uncertainty has been widely studied. Feldman et al. (2010) studied a particularly low-information setting in which one observes the opponent's actions but no payoffs, not even one's own, and introduced an algorithm which guarantees one's payoff nonetheless approaches the minimax optimal value (i.e., zero) in a symmetric zero-sum game. Against an opponent playing a minimax-optimal strategy, approaching the value of the game is the best one can hope to guarantee. However, a wealth of research in behavioral economics shows that people often do not make perfectly rational, optimal decisions. Here we consider whether it is possible to actually win in this setting if the opponent is behaviorally biased. We model several deterministic, biased opponents and show that even without knowing the game matrix in advance or observing any payoffs, it is possible to take advantage of each bias in order to win nearly every round (so long as the game has the property that each action beats and is beaten by at least one other action). We also provide a partial characterization of the kinds of biased strategies that can be exploited to win nearly every round, and provide algorithms for beating some kinds of biased strategies even when we don't know which strategy the opponent uses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00150v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ITCS.2024.18</arxiv:DOI>
      <dc:creator>Avrim Blum, Melissa Dutz</dc:creator>
    </item>
    <item>
      <title>Precision game engineering through reshaping strategic payoffs</title>
      <link>https://arxiv.org/abs/2404.00153</link>
      <description>arXiv:2404.00153v1 Announce Type: new 
Abstract: Nash equilibrium is a key concept in game theory fundamental for elucidating the equilibrium state of strategic interactions, finding applications in diverse fields such as economics, political science, and biology. However, the Nash equilibrium may not always align with the optimal or desired outcomes within a system. This article introduces a novel game engineering framework that tweaks strategic payoffs within a game to achieve a desired Nash equilibrium while averting undesired ones. Leveraging mixed-integer linear programming, this framework identifies intricate combinations of players and strategies and optimal perturbations to their payoffs that enable the shift from undesirable Nash equilibria to more favorable ones. We demonstrate the effectiveness and scalability of our approach on games of varying complexity, ranging from simple prototype games such as the Prisoner's Dilemma and Snowdrift games with two or more players to complex game configurations with as high as $10^6$ entries in the payoff matrix. These studies showcase the capability of this framework in efficiently identifying the alternative ways of reshaping strategic payoffs to secure desired Nash equilibria and preclude the undesired equilibrium states. Our game engineering framework offers a versatile toolkit for precision strategic decision-making with far-reaching implications across diverse domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00153v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elie Eshoa (Computer Science Department, Harvard John A. Paulson School of Engineering and Applied Sciences, Boston, MA, USA, Harvard Medical School, Boston, MA, USA), Ali R. Zomorrodi (Mucosal Immunology and Biology Research Center, Pediatrics Department, Massachusetts General Hospital, Boston, MA, USA, Harvard Medical School, Boston, MA, USA)</dc:creator>
    </item>
    <item>
      <title>An Abundance of Katherines: The Game Theory of Baby Naming</title>
      <link>https://arxiv.org/abs/2404.00732</link>
      <description>arXiv:2404.00732v1 Announce Type: new 
Abstract: In this paper, we study the highly competitive arena of baby naming. Through making several Extremely Reasonable Assumptions (namely, that parents are myopic, perfectly knowledgeable agents who pick a name based solely on its uniquness), we create a model which is not only tractable and clean, but also perfectly captures the real world. We then extend our investigation with numerical experiments, as well as analysis of large language model tools. We conclude by discussing avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00732v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katy Blumer, Kate Donahue, Katie Fritz, Kate Ivanovich, Katherine Lee, Katie Luo, Cathy Meng, Katie Van Koevering</dc:creator>
    </item>
    <item>
      <title>Smooth Information Gathering in Two-Player Noncooperative Games</title>
      <link>https://arxiv.org/abs/2404.00733</link>
      <description>arXiv:2404.00733v1 Announce Type: new 
Abstract: We present a mathematical framework for modeling two-player noncooperative games in which one player (the defender) is uncertain of the costs of the game and the second player's (the attacker's) intention but can preemptively allocate information-gathering resources to reduce this uncertainty. We obtain the defender's decisions by solving a two-stage problem. In Stage 1, the defender allocates information-gathering resources, and in Stage 2, the information-gathering resources output a signal that informs the defender about the costs of the game and the attacker's intent, and then both players play a noncooperative game. We provide a gradient-based algorithm to solve the two-stage game and apply this framework to a tower-defense game which can be interpreted as a variant of a Colonel Blotto game with smooth payoff functions and uncertainty over battlefield valuations. Finally, we analyze how optimal decisions shift with changes in information-gathering allocations and perturbations in the cost functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00733v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Palafox, Jesse Milzman, Dong Ho Lee, Ryan Park, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Settling the Communication Complexity of VCG-based Mechanisms for all Approximation Guarantees</title>
      <link>https://arxiv.org/abs/2404.00831</link>
      <description>arXiv:2404.00831v1 Announce Type: new 
Abstract: We consider truthful combinatorial auctions with items $M = [m]$ for sale to $n$ bidders, where each bidder $i$ has a private monotone valuation $v_i : 2^M \to R_+$. Among truthful mechanisms, maximal-in-range (MIR) mechanisms achieve the best-known approximation guarantees among all poly-communication deterministic truthful mechanisms in all previously-studied settings. Our work settles the communication necessary to achieve any approximation guarantee via an MIR mechanism. Specifically:
  Let MIRsubmod$(m,k)$ denote the best approximation guarantee achievable by an MIR mechanism using $2^k$ communication between bidders with submodular valuations over $m$ items. Then for all $k = \Omega(\log(m))$, MIRsubmod$(m,k) = \Omega(\sqrt{m/(k\log(m/k))})$. When $k = \Theta(\log(m))$, this improves the previous best lower bound for poly-comm. MIR mechanisms from $\Omega(m^{1/3}/\log^{2/3}(m))$ to $\Omega(\sqrt{m}/\log(m))$. We also have MIRsubmod$(m,k) = O(\sqrt{m/k})$. Moreover, our mechanism is optimal w.r.t. the value query and succinct representation models. When $k = \Theta(\log(m))$, this improves the previous best approximation guarantee for poly-comm. MIR mechanisms from $O(\sqrt{m})$ to $O(\sqrt{m/\log(m)})$.
  Let also MIRgen$(m,k)$ denote the best approximation guarantee achievable by an MIR mechanism using $2^k$ communication between bidders with general valuations over $m$ items. Then for all $k = \Omega(\log(m))$, MIRgen$(m,k) = \Omega(m/k)$. When $k = \Theta(\log(m))$, this improves the previous best lower bound for poly-comm. MIR mechanisms from $\Omega(m/\log^2(m))$ to $\Omega(m/\log(m))$. We also have MIRgen$(m,k) = O(m/k)$. Moreover, our mechanism is optimal w.r.t. the value query and succinct representation models. When $k = \Theta(\log(m))$, this improves the previous best approximation guarantee for poly-comm. MIR mechanisms from $O(m/\sqrt{\log(m)})$ to $O(m/\log(m))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00831v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3618260.3649706</arxiv:DOI>
      <dc:creator>Frederick V. Qiu, S. Matthew Weinberg</dc:creator>
    </item>
    <item>
      <title>Prophet Inequalities with Cancellation Costs</title>
      <link>https://arxiv.org/abs/2404.00527</link>
      <description>arXiv:2404.00527v1 Announce Type: cross 
Abstract: Most of the literature on online algorithms and sequential decision-making focuses on settings with "irrevocable decisions" where the algorithm's decision upon arrival of the new input is set in stone and can never change in the future. One canonical example is the classic prophet inequality problem, where realizations of a sequence of independent random variables $X_1, X_2,\ldots$ with known distributions are drawn one by one and a decision maker decides when to stop and accept the arriving random variable, with the goal of maximizing the expected value of their pick. We consider "prophet inequalities with recourse" in the linear buyback cost setting, where after accepting a variable $X_i$, we can still discard $X_i$ later and accept another variable $X_j$, at a \textit{buyback cost} of $f \times X_i$. The goal is to maximize the expected net reward, which is the value of the final accepted variable minus the total buyback cost. Our first main result is an optimal prophet inequality in the regime of $f \geq 1$, where we prove that we can achieve an expected reward $\frac{1+f}{1+2f}$ times the expected offline optimum. The problem is still open for $0&lt;f&lt;1$ and we give some partial results in this regime. In particular, as our second main result, we characterize the asymptotic behavior of the competitive ratio for small $f$ and provide almost matching upper and lower bounds that show a factor of $1-\Theta\left(f\log(\frac{1}{f})\right)$. Our results are obtained by two fundamentally different approaches: One is inspired by various proofs of the classical prophet inequality, while the second is based on combinatorial optimization techniques involving LP duality, flows, and cuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00527v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farbod Ekbatani, Rad Niazadeh, Pranav Nuti, Jan Vondrak</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion by Large Language Models</title>
      <link>https://arxiv.org/abs/2404.00806</link>
      <description>arXiv:2404.00806v1 Announce Type: cross 
Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs), and specifically GPT-4. We find that (1) LLM-based agents are adept at pricing tasks, (2) LLM-based pricing agents autonomously collude in oligopoly settings to the detriment of consumers, and (3) variation in seemingly innocuous phrases in LLM instructions ("prompts") may increase collusion. These results extend to auction settings. Our findings underscore the need for antitrust regulation regarding algorithmic pricing, and uncover regulatory challenges unique to LLM-based pricing agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00806v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer</dc:creator>
    </item>
    <item>
      <title>Steering game dynamics towards desired outcomes</title>
      <link>https://arxiv.org/abs/2404.01066</link>
      <description>arXiv:2404.01066v1 Announce Type: cross 
Abstract: The dynamic behavior of agents in games, which captures how their strategies evolve over time based on past interactions, can lead to a spectrum of undesirable behaviors, ranging from non-convergence to Nash equilibria to the emergence of limit cycles and chaos. To mitigate the effects of selfish behavior, central planners can use dynamic payments to guide strategic multi-agent systems toward stability and socially optimal outcomes. However, the effectiveness of such interventions critically relies on accurately predicting agents' responses to incentives and dynamically adjusting payments so that the system is guided towards the desired outcomes. These challenges are further amplified in real-time applications where the dynamics are unknown and only scarce data is available. To tackle this challenge, in this work we introduce the SIAR-MPC method, combining the recently introduced Side Information Assisted Regression (SIAR) method for system identification with Model Predictive Control (MPC). SIAR utilizes side-information constraints inherent to game theoretic applications to model agent responses to payments from scarce data, while MPC uses this model to facilitate dynamic payment adjustments. Our experiments demonstrate the efficiency of SIAR-MPC in guiding the system towards socially optimal equilibria, stabilizing chaotic behaviors, and avoiding specified regions of the state space. Comparative analyses in data-scarce settings show SIAR-MPC's superior performance over pairing MPC with Physics Informed Neural Networks (PINNs), a powerful system identification method that finds models satisfying specific constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01066v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilayda Canyakmaz, Iosif Sakos, Wayne Lin, Antonios Varvitsiotis, Georgios Piliouras</dc:creator>
    </item>
    <item>
      <title>Foundations of Cyber Resilience: The Confluence of Game, Control, and Learning Theories</title>
      <link>https://arxiv.org/abs/2404.01205</link>
      <description>arXiv:2404.01205v1 Announce Type: cross 
Abstract: Cyber resilience is a complementary concept to cybersecurity, focusing on the preparation, response, and recovery from cyber threats that are challenging to prevent. Organizations increasingly face such threats in an evolving cyber threat landscape. Understanding and establishing foundations for cyber resilience provide a quantitative and systematic approach to cyber risk assessment, mitigation policy evaluation, and risk-informed defense design. A systems-scientific view toward cyber risks provides holistic and system-level solutions. This chapter starts with a systemic view toward cyber risks and presents the confluence of game theory, control theory, and learning theories, which are three major pillars for the design of cyber resilience mechanisms to counteract increasingly sophisticated and evolving threats in our networks and organizations. Game and control theoretic methods provide a set of modeling frameworks to capture the strategic and dynamic interactions between defenders and attackers. Control and learning frameworks together provide a feedback-driven mechanism that enables autonomous and adaptive responses to threats. Game and learning frameworks offer a data-driven approach to proactively reason about adversarial behaviors and resilient strategies. The confluence of the three lays the theoretical foundations for the analysis and design of cyber resilience. This chapter presents various theoretical paradigms, including dynamic asymmetric games, moving horizon control, conjectural learning, and meta-learning, as recent advances at the intersection. This chapter concludes with future directions and discussions of the role of neurosymbolic learning and the synergy between foundation models and game models in cyber resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01205v1</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Structural Complexities of Matching Mechanisms</title>
      <link>https://arxiv.org/abs/2212.08709</link>
      <description>arXiv:2212.08709v3 Announce Type: replace 
Abstract: We study various novel complexity measures for two-sided matching mechanisms, applied to the two canonical strategyproof matching mechanisms, Deferred Acceptance (DA) and Top Trading Cycles (TTC). Our metrics are designed to capture the complexity of various structural (rather than computational) concerns, in particular ones of recent interest within economics. We consider a unified, flexible approach to formalizing our questions: Define a protocol or data structure performing some task, and bound the number of bits that it requires. Our main results apply this approach to four questions of general interest; for mechanisms matching applicants to institutions, our questions are:
  (1) How can one applicant affect the outcome matching?
  (2) How can one applicant affect another applicant's set of options?
  (3) How can the outcome matching be represented / communicated?
  (4) How can the outcome matching be verified?
  Holistically, our results show that TTC is more complex than DA, formalizing previous intuitions that DA has a simpler structure than TTC. For question (2), our result gives a new combinatorial characterization of which institutions are removed from each applicant's set of options when a new applicant is added in DA; this characterization may be of independent interest. For question (3), our result gives new tight lower bounds proving that the relationship between the matching and the priorities is more complex in TTC than in DA. We nonetheless showcase that this higher complexity of TTC is nuanced: By constructing new tight lower-bound instances and new verification protocols, we prove that DA and TTC are comparable in complexity under questions (1) and (4). This more precisely delineates the ways in which TTC is more complex than DA, and emphasizes that diverse considerations must factor into gauging the complexity of matching mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.08709v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannai A. Gonczarowski, Clayton Thomas</dc:creator>
    </item>
    <item>
      <title>Networked Anti-Coordination Games Meet Graphical Dynamical Systems: Equilibria and Convergence</title>
      <link>https://arxiv.org/abs/2301.02889</link>
      <description>arXiv:2301.02889v5 Announce Type: replace 
Abstract: Evolutionary anti-coordination games on networks capture real-world strategic situations such as traffic routing and market competition. In such games, agents maximize their utility by choosing actions that differ from their neighbors' actions. Two important problems concerning evolutionary games are the existence of a pure Nash equilibrium (NE) and the convergence time of the dynamics. In this work, we study these two problems for anti-coordination games under sequential and synchronous update schemes. For each update scheme, we examine two decision modes based on whether an agent considers its own previous action (self essential ) or not (self non-essential ) in choosing its next action. Using a relationship between games and dynamical systems, we show that for both update schemes, finding an NE can be done efficiently under the self non-essential mode but is computationally intractable under the self essential mode. To cope with this hardness, we identify special cases for which an NE can be obtained efficiently. For convergence time, we show that the best-response dynamics converges in a polynomial number of steps in the synchronous scheme for both modes; for the sequential scheme, the convergence time is polynomial only under the self non-essential mode. Through experiments, we empirically examine the convergence time and the equilibria for both synthetic and real-world networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02889v5</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zirou Qiu, Chen Chen, Madhav V. Marathe, S. S. Ravi, Daniel J. Rosenkrantz, Richard E. Stearns, Anil Vullikanti</dc:creator>
    </item>
    <item>
      <title>Polynomial-time Approximation Scheme for Equilibriums of Games</title>
      <link>https://arxiv.org/abs/2401.00747</link>
      <description>arXiv:2401.00747v2 Announce Type: replace 
Abstract: Whether a PTAS (polynomial-time approximation scheme) exists for equilibriums of games has been an open question, which relates to questions in three fields, the practicality of methods in algorithmic game theory, the problem of non-stationarity in training and curse of dimensionality in MARL (multi-agent reinforcement learning), and the implication that the complexity classes PPAD=FP in computational complexity theory. This paper introduces our discovery of the sufficient and necessary conditions for iterations based on dynamic programming and line search to approximate perfect equilibriums of dynamic games, out of which we construct a method proved to be a FPTAS (fully PTAS) for non-singular perfect equilibriums of dynamic games, where for almost any given dynamic game, all its perfect equilibriums are non-singular. Our discovery consists of cone interior dynamic programming and primal-dual unbiased regret minimization, which fit into existing theories. The former enables a dynamic programming operator to iteratively converge to a perfect equilibrium based on a concept called policy cone. The latter enables an interior-point line search to approximate a Nash equilibrium based on two concepts called primal-dual bias and unbiased central variety, solving a subproblem of the former. Validity of our discovery is cross-corroborated by a combination of theorem proofs, graphs of the three core concepts, and experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00747v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongbo Sun, Chongkun Xia, Junbo Tan, Bo Yuan, Xueqian Wang, Bin Liang</dc:creator>
    </item>
    <item>
      <title>Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities</title>
      <link>https://arxiv.org/abs/2302.07615</link>
      <description>arXiv:2302.07615v2 Announce Type: replace-cross 
Abstract: Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck - the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor even for minimization problems. The methods presented in this paper have the best theoretical guarantees of communication complexity and are significantly ahead of other methods for distributed variational inequalities. The theoretical results are confirmed by adversarial learning experiments on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07615v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Beznosikov, Martin Tak\'a\v{c}, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Red Teaming Game: A Game-Theoretic Framework for Red Teaming Language Models</title>
      <link>https://arxiv.org/abs/2310.00322</link>
      <description>arXiv:2310.00322v3 Announce Type: replace-cross 
Abstract: Deployable Large Language Models (LLMs) must conform to the criterion of helpfulness and harmlessness, thereby achieving consistency between LLMs outputs and human values. Red-teaming techniques constitute a critical way towards this criterion. Existing work rely solely on manual red team designs and heuristic adversarial prompts for vulnerability detection and optimization. These approaches lack rigorous mathematical formulation, thus limiting the exploration of diverse attack strategy within quantifiable measure and optimization of LLMs under convergence guarantees. In this paper, we present Red-teaming Game (RTG), a general game-theoretic framework without manual annotation. RTG is designed for analyzing the multi-turn attack and defense interactions between Red-team language Models (RLMs) and Blue-team Language Model (BLM). Within the RTG, we propose Gamified Red-teaming Solver (GRTS) with diversity measure of the semantic space. GRTS is an automated red teaming technique to solve RTG towards Nash equilibrium through meta-game analysis, which corresponds to the theoretically guaranteed optimization direction of both RLMs and BLM. Empirical results in multi-turn attacks with RLMs show that GRTS autonomously discovered diverse attack strategies and effectively improved security of LLMs, outperforming existing heuristic red-team designs. Overall, RTG has established a foundational framework for red teaming tasks and constructed a new scalable oversight technique for alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00322v3</guid>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengdong Ma, Ziran Yang, Minquan Gao, Hai Ci, Jun Gao, Xuehai Pan, Yaodong Yang</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Method for Optimal Investment Under Relative Performance Criteria Among Heterogeneous Agents</title>
      <link>https://arxiv.org/abs/2402.07365</link>
      <description>arXiv:2402.07365v2 Announce Type: replace-cross 
Abstract: Graphon games have been introduced to study games with many players who interact through a weighted graph of interaction. By passing to the limit, a game with a continuum of players is obtained, in which the interactions are through a graphon. In this paper, we focus on a graphon game for optimal investment under relative performance criteria, and we propose a deep learning method. The method builds upon two key ingredients: first, a characterization of Nash equilibria by forward-backward stochastic differential equations and, second, recent advances of machine learning algorithms for stochastic differential games. We provide numerical experiments on two different financial models. In each model, we compare the effect of several graphons, which correspond to different structures of interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07365v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Lauri\`ere, Ludovic Tangpi, Xuchen Zhou</dc:creator>
    </item>
  </channel>
</rss>
