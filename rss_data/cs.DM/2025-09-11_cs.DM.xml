<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DM</link>
    <description>cs.DM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Sep 2025 04:02:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Proof of the 2004 Albert-Grossman-Nowakowski-Wolfe Conjecture on Alternating Linear Clobber</title>
      <link>https://arxiv.org/abs/2509.08985</link>
      <description>arXiv:2509.08985v1 Announce Type: cross 
Abstract: Clobber is an alternate-turn two-player game introduced in 2001 by Albert, Grossman, Nowakowski and Wolfe. The board is a graph with each node colored black (x), white (o), or empty (-). Player Left has black stones, player Right has white stones. On a turn, a player takes one of their stones that is adjacent to an opponent stone and clobbers the opponent's stone (replaces it with theirs). Whoever cannot move loses. Linear clobber is clobber played on a path, for example, one row of a Go board. In 2004 Albert et al. conjectured that, for every even-length alternating-color linear clobber position except oxoxox, the first player has a winning strategy. We prove their conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08985v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinyue Chen, Taylor Folkersen, Kamillah Hasham, Ryan B. Hayward, David Lee, Owen Randall, Luke Schultz, Emily Vandermeer</dc:creator>
    </item>
    <item>
      <title>A New Algorithm for Computing Integer Hulls of 2D Polyhedral Sets</title>
      <link>https://arxiv.org/abs/2509.09134</link>
      <description>arXiv:2509.09134v1 Announce Type: cross 
Abstract: The $\texttt{IntegerHull}$ function is part of Maple's $\texttt{PolyhedralSets}$ library, which calculates the integer hull of a given polyhedral set. This algorithm works by translating the supporting hyperplanes of the facets of the input polyhedral set inwards till each hyperplane encounters at least one integer point. The polyhedral set is then divided into smaller regions and a brute force method is applied to find the remaining vertices.
  There are certain edge case scenarios where the computational cost of the existing algorithm can be high, for which we propose a new algorithm. We translate the supporting hyperplanes of the facets inwards from the (relative) opposite vertex till the hyperplanes encounter at least one integer point. Then, we can follow the same procedure as the old algorithm or use a recursive technique on the smaller regions.
  The edge case scenarios mentioned above occurs when there are integer points present on the supporting hyperplanes of the facets of the polyhedral set. This increases the region on which the brute force method is applied to find the remaining vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09134v1</guid>
      <category>math.CO</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chirantan Mukherjee</dc:creator>
    </item>
    <item>
      <title>Discrepancy Beyond Additive Functions with Applications to Fair Division</title>
      <link>https://arxiv.org/abs/2509.09252</link>
      <description>arXiv:2509.09252v1 Announce Type: cross 
Abstract: We consider a setting where we have a ground set $M$ together with real-valued set functions $f_1, \dots, f_n$, and the goal is to partition $M$ into two sets $S_1,S_2$ such that $|f_i(S_1) - f_i(S_2)|$ is small for every $i$. Many results in discrepancy theory can be stated in this form with the functions $f_i$ being additive. In this work, we initiate the study of the unstructured case where $f_i$ is not assumed to be additive. We show that even without the additivity assumption, the upper bound remains at most $O(\sqrt{n \log n})$.
  Our result has implications on the fair allocation of indivisible goods. In particular, we show that a consensus halving up to $O(\sqrt{n \log n})$ goods always exists for $n$ agents with monotone utilities. Previously, only an $O(n)$ bound was known for this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09252v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandros Hollender, Pasin Manurangsi, Raghu Meka, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>Characterization of the computed homology and cohomology bases -- technical report</title>
      <link>https://arxiv.org/abs/2509.09350</link>
      <description>arXiv:2509.09350v1 Announce Type: cross 
Abstract: Computing homology and cohomology is at the heart of many recent works and a key issue for topological data analysis. Among homological objects, homology generators are useful to locate or understand holes (especially for geometric objects). The present paper provides a characterization of the class of homology bases that are computed by standard algorithmic methods. The proof of this characterization relies on the Homological Discrete Vector Field, a combinatorial structure for computing homology, which encompasses several standard methods (persistent homology, tri-partitions, Smith Normal Form, discrete Morse theory). These results refine the combinatorial homology theory and provide novel ideas to gain more control over the computation of homology generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09350v1</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yann-Situ Gazull, Aldo Gonzalez-Lorenzo, Alexandra Bac</dc:creator>
    </item>
    <item>
      <title>Orthogonal Latin Squares of Order Ten with Two Relations: A SAT Investigation</title>
      <link>https://arxiv.org/abs/2509.09633</link>
      <description>arXiv:2509.09633v1 Announce Type: cross 
Abstract: A $k$-net($n$) is a combinatorial design equivalent to $k-2$ mutually orthogonal Latin squares of order $n$. A relation in a net is a linear dependency over $\mathbb{F}_2$ in the incidence matrix of the net. A computational enumeration of all orthogonal pairs of Latin squares of order 10 whose corresponding nets have at least two nontrivial relations was achieved by Delisle in 2010 and verified by an independent search of Myrvold. In this paper, we confirm the correctness of their exhaustive enumerations with a satisfiability (SAT) solver approach instead of using custom-written backtracking code. Performing the enumeration using a SAT solver has at least three advantages. First, it reduces the amount of trust necessary, as SAT solvers produce independently-verifiable certificates that their enumerations are complete. These certificates can be checked by formal proof verifiers that are relatively simple pieces of software, and therefore easier to trust. Second, it is typically more straightforward and less error-prone to use a SAT solver over writing search code. Third, it can be more efficient to use a SAT-based approach, as SAT solvers are highly optimized pieces of software incorporating backtracking-with-learning for improving the efficiency of the backtracking search. For example, the SAT solver completely enumerates all orthogonal pairs of Latin squares of order ten with two nontrivial relations in under 2 hours on a desktop machine, while Delisle's 2010 search used 11,700 CPU hours. Although computer hardware was slower in 2010, this alone cannot explain the improvement in the efficiency of our SAT-based search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09633v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Curtis Bright, Amadou Keita, Brett Stevens</dc:creator>
    </item>
    <item>
      <title>A Random Walk Approach to Broadcasting on Random Recursive Trees</title>
      <link>https://arxiv.org/abs/2405.04385</link>
      <description>arXiv:2405.04385v2 Announce Type: replace-cross 
Abstract: In the broadcasting problem on trees, a $\{-1,1\}$-message originating in an unknown node is passed along the tree with a certain error probability $q$. The goal is to estimate the original message without knowing the order in which the nodes were informed. We show a connection to random walks with memory effects and use this to develop a novel approach to analyse the majority estimator on random recursive trees. With this powerful approach, we study the entire group of very simple increasing trees as well as shape exchangeable trees together. This also extends Addario-Berry et al. (2022) who investigated this estimator for uniform and linear preferential attachment random recursive trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04385v2</guid>
      <category>math.PR</category>
      <category>cs.DM</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ernst Althaus, Lisa Hartung, Rebecca Steiner</dc:creator>
    </item>
    <item>
      <title>Nyldon Factorization of Thue-Morse Words and Fibonacci Words</title>
      <link>https://arxiv.org/abs/2507.23659</link>
      <description>arXiv:2507.23659v2 Announce Type: replace-cross 
Abstract: The Nyldon factorization is a string factorization that is a non-decreasing product of Nyldon words. Nyldon words and Nyldon factorizations are recently defined combinatorial objects inspired by the well-known Lyndon words and Lyndon factorizations. In this paper, we investigate the Nyldon factorization of several words. First, we fully characterize the Nyldon factorizations of the (finite) Fibonacci and the (finite) Thue-Morse words. Moreover, we show that there exists a non-decreasing product of Nyldon words that is a factorization of the infinite Thue-Morse word.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23659v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaisei Kishi, Kazuki Kai, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai</dc:creator>
    </item>
    <item>
      <title>Sharp Online Hardness for Large Balanced Independent Sets</title>
      <link>https://arxiv.org/abs/2508.20785</link>
      <description>arXiv:2508.20785v2 Announce Type: replace-cross 
Abstract: We study the algorithmic problem of finding large $\gamma$-balanced independent sets in dense random bipartite graphs; an independent set is $\gamma$-balanced if a $\gamma$ proportion of its vertices lie on one side of the bipartition. In the sparse regime, Perkins and Wang established tight bounds within the low-degree polynomial (LDP) framework, showing a factor-$1/(1-\gamma)$ statistical-computational gap via the Overlap Gap Property (OGP) framework tailored for stable algorithms. However, these techniques do not appear to extend to the dense setting. For the related large independent set problem in dense random graph, the best known algorithm is an online greedy procedure that is inherently unstable, and LDP algorithms are conjectured to fail even in the "easy" regime where greedy succeeds. We show that the largest $\gamma$-balanced independent set in dense random bipartite graphs has size $\alpha:=\frac{\log_b n}{\gamma(1-\gamma)}$ whp, where $n$ is the size of each bipartition, $p$ is the edge probability, and $b=1/(1-p)$. We design an online algorithm that achieves $(1-\epsilon)(1-\gamma)\alpha$ whp for any $\epsilon&gt;0$. We complement this with a sharp lower bound, showing that no online algorithm can achieve $(1+\epsilon)(1-\gamma)\alpha$ with nonnegligible probability. Our results suggest that the same factor-$1/(1-\gamma)$ gap is also present in the dense setting, supporting its conjectured universality. While the classical greedy procedure on $G(n,p)$ is straightforward, our algorithm is more intricate: it proceeds in two stages, incorporating a stopping time and suitable truncation to ensure that $\gamma$-balancedness-a global constraint-is met despite operating with limited information. Our lower bound utilizes the OGP framework; we build on a recent refinement of this framework for online models and extend it to the bipartite setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20785v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Dhawan, Eren C. K{\i}z{\i}lda\u{g}, Neeladri Maitra</dc:creator>
    </item>
    <item>
      <title>A threshold for online balancing of sparse i.i.d. vectors</title>
      <link>https://arxiv.org/abs/2509.02432</link>
      <description>arXiv:2509.02432v2 Announce Type: replace-cross 
Abstract: Consider the task of \textit{online} vector balancing for stochastic arrivals $(X_i)_{i \in [T]}$, where the time horizon satisfies $T = \Theta(n)$, and the $X_i$ are i.i.d uniform $d$--sparse $n$--dimensional binary vectors, with $2\leq d \le (\log\log n)^2/\log\log\log n$. We show that for this range of parameters, every online algorithm incurs discrepancy at least $\Omega(\log \log n)$, and there is an efficient algorithm which achieves a matching discrepancy bound of $O(\log\log n)$ w.h.p. This establishes an asymptotic gap, both existential and algorithmic, between the online and offline versions of the average--case Beck--Fiala problem. Strikingly, the optimal online discrepancy in the considered setting is order $\log \log n$, independent of $d$ and the norms of the vectors $(X_i)_i$. Our assumptions on $d$ are nearly optimal, as this independence ceases when $d=\omega((\log\log n)^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02432v2</guid>
      <category>math.PR</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dylan J. Altschuler, Konstantin Tikhomirov</dc:creator>
    </item>
  </channel>
</rss>
