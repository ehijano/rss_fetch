<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jan 2025 02:32:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Multilevel Network-assisted Congestion Feedback Mechanism for Network Congestion Control</title>
      <link>https://arxiv.org/abs/2501.08535</link>
      <description>arXiv:2501.08535v1 Announce Type: new 
Abstract: Network-assisted congestion control leveraging Explicit Congestion Notification (ECN) is an effective way to deal with congestion issues on the Internet. However, we believe that the existing ECN mechanism in the TCP/IP protocol stack may require further optimization to effectively address the evolving congestion challenges introduced by emerging technologies like immersive AR/VR applications and the burgeoning field of the Internet of Things (IoT). To that end, we propose a multilevel congestion notification mechanism called Enhanced ECN (EECN) that leverages the existing two ECN bits in the IP header to notify two levels of congestion in the network and uses the corresponding two bits in the TCP header to negotiate EECN during the handshake and echo congestion experienced back to the sender. Additionally, we propose a congestion control mechanism that triggers different congestion control responses based on the average RTT and multilevel congestion feedback received from the network, which yields promising results, highlighting the effectiveness of utilizing multilevel congestion feedback. The proposed EECN mechanism reduces packet drop by 70% compared to ECN, by 95% compared to TCP New Reno without ECN, and by 40% compared to VCP. The packets marked are reduced by 96% compared to ECN and 76% compared to VCP. Furthermore, the proposed approach reduces flow completion time by 61% compared to ECN and enhances the throughput of short-lived network flows, which are particularly pronounced in IoT environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08535v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Inayat Ali, Seungwoo Hong, Tae Yeon Kim</dc:creator>
    </item>
    <item>
      <title>Double reflections Assisted RIS Deployment and Energy-efficient Group Selection in mmWaves D2D Communication</title>
      <link>https://arxiv.org/abs/2501.08599</link>
      <description>arXiv:2501.08599v1 Announce Type: new 
Abstract: Reconfigurable intelligent surfaces (RISs) offer a viable way to improve the performance of multi-hop device-to-device (D2D) communication. However, due to the substantial propagation and penetration losses of the millimeter waves (mmWaves), a direct line of sight (LoS) link and close proximity of a device pair are required for a high data rate. Static obstacles like trees and buildings can easily impede the direct LoS connectivity between a device pair. Hence, RIS placement plays a crucial role in establishing an indirect LoS link between them. Therefore, in this work, we propose a set cover-based RIS deployment strategy for both single and double RIS-assisted D2D communication. In particular, we have demonstrated that permitting reflections via two consecutive RISs can greatly lower the RIS density in the environment, preventing resource waste and enabling the service of more obstructed device pairs. After the RIS deployment, for information transfer, we also propose an energy-efficient group selection criteria. Moreover, we prove that sometimes double reflections are more beneficial than single reflection, which is counter-intuitive. Numerical results show that our approach outperforms a random and a recent deployment strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08599v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lakshmikanta Sau, Sasthi C. Ghosh</dc:creator>
    </item>
    <item>
      <title>Extension of indoor mmW link radio coverage in non line-of-sight conditions</title>
      <link>https://arxiv.org/abs/2501.08644</link>
      <description>arXiv:2501.08644v1 Announce Type: new 
Abstract: In future wireless communication systems, millimeter waves (mmWaves) will play an important role in meeting high data rates. However, due to their short wavelengths, these mmWaves present high propagation losses and are highly attenuated by blocking. In this chapter, we seek to increase the indoor radio coverage at 60 GHz in non line-of-sight (NLOS) environments. Firstly, a metallic passive reflector is used in an L-shaped corridor. Secondly, an array of grooved metallic antennas of size 20 cm x 20 cm (corresponding to 80 grooves) is used in a T-shaped corridor. Next, the study focuses on the blockage losses caused by the human body. The results obtained in these different configurations show that it is possible to use beamforming to exploit a reflected path when the direct path is blocked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08644v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-56144-3</arxiv:DOI>
      <arxiv:journal_reference>Mohammed El Ghzaoui; Sudipta Das; Varakumari Samudrala; Nageswara Rao Medikondu. Next Generation Wireless Communication - Advances in Optical, mm-Wave, and THz Technologies, Springer Nature, 2024, 978-3-031-56144-3</arxiv:journal_reference>
      <dc:creator>Mbissane Dieng (IETR, INSA Rennes), Gheorghe Zaharia (IETR, INSA Rennes), Gha\"is El Zein (IETR, INSA Rennes), Rapha\"el Gillard (IETR, INSA Rennes), Renaud Loison (IETR, INSA Rennes)</dc:creator>
    </item>
    <item>
      <title>Can Millimeter-Wave Support Interactive Extended Reality Under Rapid Rotational Motion?</title>
      <link>https://arxiv.org/abs/2501.08751</link>
      <description>arXiv:2501.08751v1 Announce Type: new 
Abstract: Using Millimeter-Wave (mmWave) wireless communications is often named as the prime enabler for mobile interactive Extended Reality (XR), as it offers multi-gigabit data rates at millisecond-range latency. To achieve this, mmWave nodes must focus their energy towards each other, which is especially challenging in XR scenarios, where the transceiver on the user's XR device may rotate rapidly. To evaluate the feasibility of mmWave XR, we present the first throughput and latency evaluation of state-of-the-art mmWave hardware under rapid rotational motion, for different PHY and MAC-layer parameter configurations. We show that this parameter configuration has a significant impact on performance, and that specialized beamforming approaches for rapid rotational motion may be necessary to enable uninterrupted, high-quality mobile interactive XR experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08751v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICCWorkshops59551.2024.10615891</arxiv:DOI>
      <dc:creator>Jakob Struye, Hany Assasa, Barend Van Liempd, Arnout Diels, Jeroen Famaey</dc:creator>
    </item>
    <item>
      <title>Opportunities and Challenges for Virtual Reality Streaming over Millimeter-Wave: An Experimental Analysis</title>
      <link>https://arxiv.org/abs/2501.08752</link>
      <description>arXiv:2501.08752v1 Announce Type: new 
Abstract: Achieving extremely high-quality and truly immersive interactive Virtual Reality (VR) is expected to require a wireless link to the cloud, providing multi-gigabit throughput and extremely low latency. A prime candidate for fulfilling these requirements is millimeter-wave (mmWave) communications, operating in the 30 to 300 GHz bands, rather than the traditional sub-6 GHz. Evaluations with first-generation mmWave Wi-Fi hardware, based on the IEEE 802.11ad standard, have so far largely remained limited to lower-layer metrics. In this work, we present the first experimental analysis of the capabilities of mmWave for streaming VR content, using a novel testbed capable of repeatably creating blockage through mobility. Using this testbed, we show that (a) motion may briefly interrupt transmission, (b) a broken line of sight may degrade throughput unpredictably, and (c) TCP-based streaming frameworks need careful tuning to behave well over mmWave.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08752v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/NoF55974.2022.9942535</arxiv:DOI>
      <dc:creator>Jakob Struye, Hemanth Kumar Ravuri, Hany Assasa, Claudio Fiandrino, Filip Lemic, Joerg Widmer, Jeroen Famaey, Maria Torres Vega</dc:creator>
    </item>
    <item>
      <title>Leveraging LLM Agents for Translating Network Configurations</title>
      <link>https://arxiv.org/abs/2501.08760</link>
      <description>arXiv:2501.08760v1 Announce Type: new 
Abstract: Configuration translation is a critical and frequent task in network operations. When a network device is damaged or outdated, administrators need to replace it to maintain service continuity. The replacement devices may originate from different vendors, necessitating configuration translation to ensure seamless network operation. However, translating configurations manually is a labor-intensive and error-prone process. In this paper, we propose an intent-based framework for translating network configuration with Large Language Model (LLM) Agents. The core of our approach is an Intent-based Retrieval Augmented Generation (IRAG) module that systematically splits a configuration file into fragments, extracts intents, and generates accurate translations. We also design a two-stage verification method to validate the syntax and semantics correctness of the translated configurations. We implement and evaluate the proposed method on real-world network configurations. Experimental results show that our method achieves 97.74% syntax correctness, outperforming state-of-the-art methods in translation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08760v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunze Wei, Xiaohui Xie, Yiwei Zuo, Tianshuo Hu, Xinyi Chen, Kaiwen Chi, Yong Cui</dc:creator>
    </item>
    <item>
      <title>RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning</title>
      <link>https://arxiv.org/abs/2501.08848</link>
      <description>arXiv:2501.08848v1 Announce Type: new 
Abstract: Network simulation is pivotal in network modeling, assisting with tasks ranging from capacity planning to performance estimation. Traditional approaches such as Discrete Event Simulation (DES) face limitations in terms of computational cost and accuracy. This paper introduces RouteNet-Gauss, a novel integration of a testbed network with a Machine Learning (ML) model to address these challenges. By using the testbed as a hardware accelerator, RouteNet-Gauss generates training datasets rapidly and simulates network scenarios with high fidelity to real-world conditions. Experimental results show that RouteNet-Gauss significantly reduces prediction errors by up to 95% and achieves a 488x speedup in inference time compared to state-of-the-art DES-based methods. RouteNet-Gauss's modular architecture is dynamically constructed based on the specific characteristics of the network scenario, such as topology and routing. This enables it to understand and generalize to different network configurations beyond those seen during training, including networks up to 10x larger. Additionally, it supports Temporal Aggregated Performance Estimation (TAPE), providing configurable temporal granularity and maintaining high accuracy in flow performance metrics. This approach shows promise in improving both simulation efficiency and accuracy, offering a valuable tool for network operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08848v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos G\"uemes-Palau, Miquel Ferriol-Galm\'es, Jordi Paillisse-Vilanova, Albert L\'opez-Bresc\'o, Pere Barlet-Ros, Albert Cabellos-Aparicio</dc:creator>
    </item>
    <item>
      <title>3GPP Network Architecture Enhancement for Ambient IoT Service</title>
      <link>https://arxiv.org/abs/2501.08990</link>
      <description>arXiv:2501.08990v1 Announce Type: new 
Abstract: Ambient internet of things (A-IoT) paradigm is under study in 3GPP with the intention to provide a sustainable solution for the IoT market without any need to replace the batteries and operate in harsh environments where it is difficult to replenish batteries. This article provides insight on 3rd Generation Partnership Project (3GPP) discussions in Release 18 and 19 with the focus on network architecture aspects. 3GPP has recently decided to start normative work in its Radio Access Network (RAN) Working Group (WG) and discussions are ongoing to start a work item in other WGs with more focus on architecture aspects. We explore and analyze various aspects of system design related to architecture requirements to support A-IoT service, different architecture options to consider, security and authentication mechanisms for A-IoT devices as well as key challenges for standardization of A-IoT service.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08990v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dongjoo Kim, Philippe Godin, Bo Bjerrum, Pallab Gupta, M. Majid Butt</dc:creator>
    </item>
    <item>
      <title>CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks</title>
      <link>https://arxiv.org/abs/2501.08418</link>
      <description>arXiv:2501.08418v1 Announce Type: cross 
Abstract: Efficient resource allocation is essential for optimizing various tasks in wireless networks, which are usually formulated as generalized assignment problems (GAP). GAP, as a generalized version of the linear sum assignment problem, involves both equality and inequality constraints that add computational challenges. In this work, we present a novel Conditional Value at Risk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address GAP in vehicular networks (VNets). Our approach leverages a hybrid quantum-classical structure, integrating a tailored cost function that balances both objective and constraint-specific penalties to improve solution quality and stability. Using the CVaR-VQE model, we handle the GAP efficiently by focusing optimization on the lower tail of the solution space, enhancing both convergence and resilience on noisy intermediate-scale quantum (NISQ) devices. We apply this framework to a user-association problem in VNets, where our method achieves 23.5% improvement compared to the deep neural network (DNN) approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08418v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zijiang Yan, Hao Zhou, Jianhua Pei, Aryan Kaushik, Hina Tabassum, Ping Wang</dc:creator>
    </item>
    <item>
      <title>Broadband measurements and analysis of human blocking in a 60 GHz indoor radio channel</title>
      <link>https://arxiv.org/abs/2501.08647</link>
      <description>arXiv:2501.08647v1 Announce Type: cross 
Abstract: New millimeter-wave wireless communication systems can be strongly impacted by the blockage introduced by the human body. At 60 GHz, the coverage of these systems is relatively limited due to high propagation losses. Thus, beamforming allows to find a reflective path to replace the blocked one. In this work, the study focuses on the impact of a human blocker in a meeting room, to evaluate the blocking losses introduced by the human body at 60 GHz. The results obtained in terms of path loss and channel impulse response show that the attenuation by the human body is between 24 and 26 dB. Moreover, the results show that the use of beamforming allows to exploit the reflected paths to replace the direct link that can be blocked by the human body.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08647v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journ{\'e}es d'{\'e}tudes Propagation Radio{\'e}lectrique 2023 - Propagation radio{\'e}lectrique et caract{\'e}risation de l'environnement, SEE Groupe Ouest, INSA de Rennes et DGA Mi, Nov 2023, Rennes (Fance), France</arxiv:journal_reference>
      <dc:creator>Mbissane Dieng (IETR), Gheorghe I. Zaharia (IETR), Gha\"is El Zein (IETR)</dc:creator>
    </item>
    <item>
      <title>Digital Twin Online Channel Modeling: Challenges,Principles, and Applications</title>
      <link>https://arxiv.org/abs/2501.08680</link>
      <description>arXiv:2501.08680v1 Announce Type: cross 
Abstract: Different from traditional offline channel modeling, digital twin online channel modeling can sense and accurately characterize dynamic wireless channels in real time, and can therefore greatly assist 6G network optimization. This article proposes a novel promising framework and a step-by-step design procedure of digital twin online channel models (DTOCM). By enabling continuous visualization and accurate prediction of dynamic channel variations, DTOCM can synchronize the performance between simulated and real networks. We first explore the evolution and conceptual advancements of DTOCM, highlighting its visions and associated challenges. Then, we explain its operational principles, construction mechanisms, and applications to typical 6G scenarios. Subsequently, the real-time channel information provisioning and visualization capabilities of DTOCM are illustrated through our DTOCM platform based on practical scenarios. Finally, future research directions and open issues are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08680v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junling Li, Cheng-Xiang Wang, Chen Huang, Tianrun Qi, Tong Wu</dc:creator>
    </item>
    <item>
      <title>Automatic tuning of communication protocols for vehicular ad hoc networks using metaheuristics</title>
      <link>https://arxiv.org/abs/2501.08847</link>
      <description>arXiv:2501.08847v1 Announce Type: cross 
Abstract: The emerging field of vehicular ad hoc networks (VANETs) deals with a set of communicating vehicles which are able to spontaneously interconnect without any pre-existing infrastructure. In such kind of networks, it is crucial to make an optimal configuration of the communication protocols previously to the final network deployment. This way, a human designer can obtain an optimal QoS of the network beforehand. The problem we consider in this work lies in configuring the File Transfer protocol Configuration (FTC) with the aim of optimizing the transmission time, the number of lost packets, and the amount of data transferred in realistic VANET scenarios. We face the FTC with five representative state-of-the-art optimization techniques and compare their performance. These algorithms are: Particle Swarm Optimization (PSO), Differential Evolution (DE), Genetic Algorithm (GA), Evolutionary Strategy (ES), and Simulated Annealing (SA). For our tests, two typical environment instances of VANETs for Urban and Highway scenarios have been defined. The experiments using ns- 2 (a well-known realistic VANET simulator) reveal that PSO outperforms all the compared algorithms for both studied VANET instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08847v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2010.01.012</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence, 23(5), 795-805 (2010).</arxiv:journal_reference>
      <dc:creator>Jos\'e Garc\'ia-Nieto, Jamal Toutouh, Enrique Alba</dc:creator>
    </item>
    <item>
      <title>AI-RAN: Transforming RAN with AI-driven Computing Infrastructure</title>
      <link>https://arxiv.org/abs/2501.09007</link>
      <description>arXiv:2501.09007v1 Announce Type: cross 
Abstract: The radio access network (RAN) landscape is undergoing a transformative shift from traditional, communication-centric infrastructures towards converged compute-communication platforms. This article introduces AI-RAN which integrates both RAN and artificial intelligence (AI) workloads on the same infrastructure. By doing so, AI-RAN not only meets the performance demands of future networks but also improves asset utilization. We begin by examining how RANs have evolved beyond mobile broadband towards AI-RAN and articulating manifestations of AI-RAN into three forms: AI-for-RAN, AI-on-RAN, and AI-and-RAN. Next, we identify the key requirements and enablers for the convergence of communication and computing in AI-RAN. We then provide a reference architecture for advancing AI-RAN from concept to practice. To illustrate the practical potential of AI-RAN, we present a proof-of-concept that concurrently processes RAN and AI workloads utilizing NVIDIA Grace-Hopper GH200 servers. Finally, we conclude the article by outlining future work directions to guide further developments of AI-RAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09007v1</guid>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lopamudra Kundu, Xingqin Lin, Rajesh Gadiyar, Jean-Francois Lacasse, Shuvo Chowdhury</dc:creator>
    </item>
    <item>
      <title>Exploring the 6G Potentials: Immersive, Hyper Reliable, and Low-Latency Communication</title>
      <link>https://arxiv.org/abs/2407.11051</link>
      <description>arXiv:2407.11051v3 Announce Type: replace 
Abstract: The transition towards the sixth-generation (6G) wireless telecommunications networks introduces significant challenges for researchers and industry stakeholders. The 6G technology aims to enhance existing usage scenarios through supporting innovative applications that require stringent key performance indicators (KPIs). In some critical use cases of 6G, multiple KPIs, including immersive throughput, with an envisioned peak data rate of $1$ Tbps, hyper-reliability, in the range of $10^{-5}$ to $10^{-7}$, and hyper low-latency, between $0.1$ and $1$ ms, must be achieved simultaneously to deliver the expected service experience. However, this is challenging due to the conflicting nature of these KPIs. This article proposes a new service class of 6G as immersive, hyper reliable, and low-latency communication (IHRLLC), and introduces a potential network architecture to achieve the associated KPIs. Specifically, enhanced technologies, such as ultra-massive multiple-input multiple-output (umMIMO)-aided terahertz (THz) communications, reconfigurable intelligent surfaces (RIS), and non-terrestrial networks (NTN), are viewed as the key enablers for achieving immersive data rates and hyper reliability. Given the computational complexity involved in employing these technologies, we propose mathematical and computational enabling technologies, such as learn-to-optimize (L2O), generative-AI (GenAI), quantum computing, and network digital twin (NDT), to complement the proposed architecture and optimize the latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11051v3</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Afsoon Alidadi Shamsabadi, Animesh Yadav, Yasser Gadallah, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Erlang Model for Multi-type Data Flow</title>
      <link>https://arxiv.org/abs/2411.00792</link>
      <description>arXiv:2411.00792v3 Announce Type: replace 
Abstract: With the development of information technology, requirements for data flow have become diverse. When multi-type data flow (MDF) is used, games, videos, calls, etc. are all requirements. There may be a constant switch between these requirements, and also multiple requirements at the same time. Therefore, the demands of users change over time, which makes traditional teletraffic analysis not directly applicable. This paper proposes probabilistic models for the requirement of MDF, and analyzes in three states: non-tolerance, tolerance and delay. When the requirement random variables are co-distributed with respect to time, we prove the practicability of the Erlang Multirate Loss Model (EMLM) from a mathematical perspective by discretizing time and error analysis. An algorithm of pre-allocating resources is given to guild the construction of base resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00792v3</guid>
      <category>cs.NI</category>
      <category>math.PR</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liuquan Yao, Pei Yang, Zhichao Liu, Wenyan Li, Jianghua Liu, Zhi-Ming Ma</dc:creator>
    </item>
    <item>
      <title>RF-3DGS: Wireless Channel Modeling with Radio Radiance Field and 3D Gaussian Splatting</title>
      <link>https://arxiv.org/abs/2411.19420</link>
      <description>arXiv:2411.19420v2 Announce Type: replace 
Abstract: Precisely modeling radio propagation in complex environments has been a significant challenge, especially with the advent of 5G and beyond networks, where managing massive antenna arrays demands more detailed information. Traditional methods, such as empirical models and ray tracing, often fall short, either due to insufficient details or because of challenges for real-time applications. Inspired by the newly proposed 3D Gaussian Splatting method in the computer vision domain, which outperforms other methods in reconstructing optical radiance fields, we propose RF-3DGS, a novel approach that enables precise site-specific reconstruction of radio radiance fields from sparse samples. RF-3DGS can render radio spatial spectra at arbitrary positions within 2 ms following a brief 3-minute training period, effectively identifying dominant propagation paths. Furthermore, RF-3DGS can provide fine-grained Spatial Channel State Information (Spatial-CSI) of these paths, including the channel gain, the delay, the angle of arrival (AoA), and the angle of departure (AoD). Our experiments, calibrated through real-world measurements, demonstrate that RF-3DGS not only significantly improves reconstruction quality, training efficiency, and rendering speed compared to state-of-the-art methods, but also holds great potential for supporting wireless communication and advanced applications such as Integrated Sensing and Communication (ISAC). Code and dataset will be available at https://github.com/SunLab-UGA/RF-3DGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19420v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lihao Zhang, Haijian Sun, Samuel Berweger, Camillo Gentile, Rose Qingyang Hu</dc:creator>
    </item>
    <item>
      <title>Delay Sensitive Hierarchical Federated Learning with Stochastic Local Updates</title>
      <link>https://arxiv.org/abs/2302.04851</link>
      <description>arXiv:2302.04851v2 Announce Type: replace-cross 
Abstract: The impact of local averaging on the performance of federated learning (FL) systems is studied in the presence of communication delay between the clients and the parameter server. To minimize the effect of delay, clients are assigned into different groups, each having its own local parameter server (LPS) that aggregates its clients' models. The groups' models are then aggregated at a global parameter server (GPS) that only communicates with the LPSs. Such setting is known as hierarchical FL (HFL). Unlike most works in the literature, the number of local and global communication rounds in our work is randomly determined by the (different) delays experienced by each group of clients. Specifically, the number of local averaging rounds is tied to a wall-clock time period coined the sync time $S$, after which the LPSs synchronize their models by sharing them with the GPS. Such sync time $S$ is then reapplied until a global wall-clock time is exhausted.
  First, an upper bound on the deviation between the updated model at each LPS with respect to that available at the GPS is derived. This is then used as a tool to derive the convergence analysis of our proposed delay-sensitive HFL algorithm, first at each LPS individually, and then at the GPS. Our theoretical convergence bound showcases the effects of the whole system's parameters, including the number of groups, the number of clients per group, and the value of $S$. Our results show that the value of $S$ should be carefully chosen, especially since it implicitly governs how the delay statistics affect the performance of HFL in situations where training time is restricted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04851v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdulmoneam Ali, Ahmed Arafa</dc:creator>
    </item>
    <item>
      <title>EdgeSight: Enabling Modeless and Cost-Efficient Inference at the Edge</title>
      <link>https://arxiv.org/abs/2405.19213</link>
      <description>arXiv:2405.19213v2 Announce Type: replace-cross 
Abstract: Traditional ML inference is evolving toward modeless inference, which abstracts the complexity of model selection from users, allowing the system to automatically choose the most appropriate model for each request based on accuracy and resource requirements. While prior studies have focused on modeless inference within data centers, this paper tackles the pressing need for cost-efficient modeless inference at the edge -- particularly within its unique constraints of limited device memory, volatile network conditions, and restricted power consumption.
  To overcome these challenges, we propose EdgeSight, a system that provides cost-efficient EdgeSight serving for diverse DNNs at the edge. EdgeSight employs an edge-data center (edge-DC) architecture, utilizing confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. Additionally, it supports lossy inference in volatile network environments. Our experimental results show that EdgeSight outperforms existing systems by up to 1.6x in P99 latency for modeless services. Furthermore, our FPGA prototype demonstrates similar performance at certain accuracy levels, with a power consumption reduction of up to 3.34x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19213v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>ChonLam Lao, Jiaqi Gao, Ganesh Ananthanarayanan, Aditya Akella, Minlan Yu</dc:creator>
    </item>
    <item>
      <title>Integrated Push-and-Pull Update Model for Goal-Oriented Effective Communication</title>
      <link>https://arxiv.org/abs/2407.14092</link>
      <description>arXiv:2407.14092v2 Announce Type: replace-cross 
Abstract: This paper studies decision-making for goal-oriented effective communication. We consider an end-to-end status update system where a sensing agent (SA) observes a source, generates and transmits updates to an actuation agent (AA), while the AA takes actions to accomplish a goal at the endpoint. We integrate the push- and pull-based update communication models to obtain a push-and-pull model, which allows the transmission controller at the SA to decide to push an update to the AA and the query controller at the AA to pull updates by raising queries at specific time instances. To gauge effectiveness, we utilize a grade of effectiveness (GoE) metric incorporating updates' freshness, usefulness, and timeliness of actions as qualitative attributes. We then derive effect-aware policies to maximize the expected discounted sum of updates' effectiveness subject to induced costs. The effect-aware policy at the SA considers the potential effectiveness of communicated updates at the endpoint, while at the AA, it accounts for the probabilistic evolution of the source and importance of generated updates. Our results show the proposed push-and-pull model outperforms models solely based on push- or pull-based updates both in terms of efficiency and effectiveness. Additionally, using effect-aware policies at both agents enhances effectiveness compared to periodic and/or probabilistic effect-agnostic policies at either or both agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14092v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pouya Agheli, Nikolaos Pappas, Petar Popovski, Marios Kountouris</dc:creator>
    </item>
    <item>
      <title>Diffusion Models as Network Optimizers: Explorations and Analysis</title>
      <link>https://arxiv.org/abs/2411.00453</link>
      <description>arXiv:2411.00453v4 Announce Type: replace-cross 
Abstract: Network optimization is a fundamental challenge in the Internet of Things (IoT) network, often characterized by complex features that make it difficult to solve these problems. Recently, generative diffusion models (GDMs) have emerged as a promising new approach to network optimization, with the potential to directly address these optimization problems. However, the application of GDMs in this field is still in its early stages, and there is a noticeable lack of theoretical research and empirical findings. In this study, we first explore the intrinsic characteristics of generative models. Next, we provide a concise theoretical proof and intuitive demonstration of the advantages of generative models over discriminative models in network optimization. Based on this exploration, we implement GDMs as optimizers aimed at learning high-quality solution distributions for given inputs, sampling from these distributions during inference to approximate or achieve optimal solutions. Specifically, we utilize denoising diffusion probabilistic models (DDPMs) and employ a classifier-free guidance mechanism to manage conditional guidance based on input parameters. We conduct extensive experiments across three challenging network optimization problems. By investigating various model configurations and the principles of GDMs as optimizers, we demonstrate the ability to overcome prediction errors and validate the convergence of generated solutions to optimal solutions. We provide code and data at https://github.com/qiyu3816/DiffSG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00453v4</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2025.3528955</arxiv:DOI>
      <arxiv:journal_reference>IEEE Internet of Things Journal (2025)</arxiv:journal_reference>
      <dc:creator>Ruihuai Liang, Bo Yang, Pengyu Chen, Xianjin Li, Yifan Xue, Zhiwen Yu, Xuelin Cao, Yan Zhang, M\'erouane Debbah, H. Vincent Poor, Chau Yuen</dc:creator>
    </item>
  </channel>
</rss>
