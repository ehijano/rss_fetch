<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Mar 2024 04:01:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Invariant Properties of Linear-Iterative Distributed Averaging Algorithms and Application to Error Detection</title>
      <link>https://arxiv.org/abs/2403.06007</link>
      <description>arXiv:2403.06007v1 Announce Type: new 
Abstract: We consider the problem of average consensus in a distributed system comprising a set of nodes that can exchange information among themselves. We focus on a class of algorithms for solving such a problem whereby each node maintains a state and updates it iteratively as a linear combination of the states maintained by its in-neighbors, i.e., nodes from which it receives information directly. Averaging algorithms within this class can be thought of as discrete-time linear time-varying systems without external driving inputs and whose state matrix is column stochastic. As a result, the algorithms exhibit a global invariance property in that the sum of the state variables remains constant at all times. In this paper, we report on another invariance property for the aforementioned class of averaging algorithms. This property is local to each node and reflects the conservation of certain quantities capturing an aggregate of all the values received by a node from its in-neighbors and all the values sent by said node to its out-neighbors (i.e., nodes to which it sends information directly) throughout the execution of the averaging algorithm. We show how this newly-discovered invariant can be leveraged for detecting errors while executing the averaging algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06007v1</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoforos N. Hadjicostis, Alejandro D. Dominguez-Garcia</dc:creator>
    </item>
    <item>
      <title>IDEAS: Information-Driven EV Admission in Charging Station Considering User Impatience to Improve QoS and Station Utilization</title>
      <link>https://arxiv.org/abs/2403.06223</link>
      <description>arXiv:2403.06223v1 Announce Type: new 
Abstract: Our work delves into user behaviour at Electric Vehicle(EV) charging stations during peak times, particularly focusing on how impatience drives balking (not joining queues) and reneging (leaving queues prematurely). We introduce an Agent-based simulation framework that incorporates user optimism levels (pessimistic, standard, and optimistic) in the queue dynamics. Unlike previous work, this framework highlights the crucial role of human behaviour in shaping station efficiency for peak demand. The simulation reveals a key issue: balking often occurs due to a lack of queue insights, creating user dilemmas. To address this, we propose real-time sharing of wait time metrics with arriving EV users at the station. This ensures better Quality of Service (QoS) with user-informed queue joining and demonstrates significant reductions in reneging (up to 94%) improving the charging operation. Further analysis shows that charging speed decreases significantly beyond 80%, but most users prioritize full charges due to range anxiety, leading to a longer queue. To address this, we propose a two-mode, two-port charger design with power-sharing options. This allows users to fast-charge to 80% and automatically switch to slow charging, enabling fast charging on the second port. Thus, increasing fast charger availability and throughput by up to 5%. As the mobility sector transitions towards intelligent traffic, our modelling framework, which integrates human decision-making within automated planning, provides valuable insights for optimizing charging station efficiency and improving the user experience. This approach is particularly relevant during the introduction phase of new stations, when historical data might be limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06223v1</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Animesh Chattopadhyay, Subrat Kar</dc:creator>
    </item>
    <item>
      <title>Dynamics of Polarization Under Normative Institutions and Opinion Expression Stewarding</title>
      <link>https://arxiv.org/abs/2403.06264</link>
      <description>arXiv:2403.06264v1 Announce Type: new 
Abstract: Although there is mounting empirical evidence for the increase in affective polarization, few mechanistic models can explain its emergence at the population level. The question of how such a phenomenon can emerge from divergent opinions of a population on an ideological issue is still an open issue. In this paper, we establish that human normativity, that is, individual expression of normative opinions based on beliefs about the population, can lead to population-level polarization when ideological institutions distort beliefs in accordance with their objective of moving expressed opinion to one extreme. Using a game-theoretic model, we establish that individuals with more extreme opinions will have more extreme rhetoric and higher misperceptions about their outgroup members. Our model also shows that when social recommendation systems mediate institutional signals, we can observe the formation of different institutional communities, each with its unique community structure and characteristics. Using the model, we identify practical strategies platforms can implement, such as reducing exposure to signals from ideological institutions and a tailored approach to content moderation, both of which can rectify the affective polarization problem within its purview.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06264v1</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atrisha Sarkar, Gillian K. Hadfield</dc:creator>
    </item>
    <item>
      <title>The Geometry of Cyclical Social Trends</title>
      <link>https://arxiv.org/abs/2403.06376</link>
      <description>arXiv:2403.06376v1 Announce Type: new 
Abstract: We investigate the emergence of periodic behavior in opinion dynamics and its underlying geometry. For this, we use a bounded-confidence model with contrarian agents in a convolution social network. This means that agents adapt their opinions by interacting with their neighbors in a time-varying social network. Being contrarian, the agents are kept from reaching consensus. This is the key feature that allows the emergence of cyclical trends. We show that the systems either converge to nonconsensual equilibrium or are attracted to periodic or quasi-periodic orbits. We bound the dimension of the attractors and the period of cyclical trends. We exhibit instances where each orbit is dense and uniformly distributed within its attractor. We also investigate the case of randomly changing social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06376v1</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernard Chazelle, Kritkorn Karntikoon, Jakob Nogler</dc:creator>
    </item>
    <item>
      <title>Scalable Distributed Optimization Despite Byzantine Adversaries</title>
      <link>https://arxiv.org/abs/2403.06502</link>
      <description>arXiv:2403.06502v1 Announce Type: new 
Abstract: The problem of distributed optimization requires a group of networked agents to compute a parameter that minimizes the average of their local cost functions. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to ``Byzantine'' agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or assume certain statistical properties of the functions at the agents. In this paper, we provide two resilient, scalable, distributed optimization algorithms for multi-dimensional functions. Our schemes involve two filters, (1) a distance-based filter and (2) a min-max filter, which each remove neighborhood states that are extreme (defined precisely in our algorithms) at each iteration. We show that these algorithms can mitigate the impact of up to $F$ (unknown) Byzantine agents in the neighborhood of each regular agent. In particular, we show that if the network topology satisfies certain conditions, all of the regular agents' states are guaranteed to converge to a bounded region that contains the minimizer of the average of the regular agents' functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06502v1</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kananart Kuwaranancharoen, Lei Xin, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Generalising Multi-Agent Cooperation through Task-Agnostic Communication</title>
      <link>https://arxiv.org/abs/2403.06750</link>
      <description>arXiv:2403.06750v1 Announce Type: new 
Abstract: Existing communication methods for multi-agent reinforcement learning (MARL) in cooperative multi-robot problems are almost exclusively task-specific, training new communication strategies for each unique task. We address this inefficiency by introducing a communication strategy applicable to any task within a given environment. We pre-train the communication strategy without task-specific reward guidance in a self-supervised manner using a set autoencoder. Our objective is to learn a fixed-size latent Markov state from a variable number of agent observations. Under mild assumptions, we prove that policies using our latent representations are guaranteed to converge, and upper bound the value error introduced by our Markov state approximation. Our method enables seamless adaptation to novel tasks without fine-tuning the communication strategy, gracefully supports scaling to more agents than present during training, and detects out-of-distribution events in an environment. Empirical results on diverse MARL scenarios validate the effectiveness of our approach, surpassing task-specific communication strategies in unseen tasks. Our implementation of this work is available at https://github.com/proroklab/task-agnostic-comms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06750v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dulhan Jayalath, Steven Morad, Amanda Prorok</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning Enhanced Rate-Splitting Multiple Access for Interference Mitigation</title>
      <link>https://arxiv.org/abs/2403.05974</link>
      <description>arXiv:2403.05974v1 Announce Type: cross 
Abstract: This study explores the application of the rate-splitting multiple access (RSMA) technique, vital for interference mitigation in modern communication systems. It investigates the use of precoding methods in RSMA, especially in complex multiple-antenna interference channels, employing deep reinforcement learning. The aim is to optimize precoders and power allocation for common and private data streams involving multiple decision-makers. A multi-agent deep deterministic policy gradient (MADDPG) framework is employed to address this complexity, where decentralized agents collectively learn to optimize actions in a continuous policy space. We also explore the challenges posed by imperfect channel side information at the transmitter. Additionally, decoding order estimation is addressed to determine the optimal decoding sequence for common and private data sequences. Simulation results demonstrate the effectiveness of the proposed RSMA method based on MADDPG, achieving the upper bound in single-antenna scenarios and closely approaching theoretical limits in multi-antenna scenarios. Comparative analysis shows superiority over other techniques such as MADDPG without rate-splitting, maximal ratio transmission (MRT), zero-forcing (ZF), and leakage-based precoding methods. These findings highlight the potential of deep reinforcement learning-driven RSMA in reducing interference and enhancing system performance in communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05974v1</guid>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Osman Nuri Irkicatal, Elif Tugce Ceran, Melda Yuksel</dc:creator>
    </item>
    <item>
      <title>MATRIX: Multi-Agent Trajectory Generation with Diverse Contexts</title>
      <link>https://arxiv.org/abs/2403.06041</link>
      <description>arXiv:2403.06041v1 Announce Type: cross 
Abstract: Data-driven methods have great advantages in modeling complicated human behavioral dynamics and dealing with many human-robot interaction applications. However, collecting massive and annotated real-world human datasets has been a laborious task, especially for highly interactive scenarios. On the other hand, algorithmic data generation methods are usually limited by their model capacities, making them unable to offer realistic and diverse data needed by various application users. In this work, we study trajectory-level data generation for multi-human or human-robot interaction scenarios and propose a learning-based automatic trajectory generation model, which we call Multi-Agent TRajectory generation with dIverse conteXts (MATRIX). MATRIX is capable of generating interactive human behaviors in realistic diverse contexts. We achieve this goal by modeling the explicit and interpretable objectives so that MATRIX can generate human motions based on diverse destinations and heterogeneous behaviors. We carried out extensive comparison and ablation studies to illustrate the effectiveness of our approach across various metrics. We also presented experiments that demonstrate the capability of MATRIX to serve as data augmentation for imitation-based motion planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06041v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuo Xu, Rui Zhou, Yida Yin, Huidong Gao, Masayoshi Tomizuka, Jiachen Li</dc:creator>
    </item>
    <item>
      <title>ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes</title>
      <link>https://arxiv.org/abs/2403.06294</link>
      <description>arXiv:2403.06294v1 Announce Type: cross 
Abstract: There are two main barriers to using large language models (LLMs) in clinical reasoning. Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations. Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician's cognitive processes. This leads to user distrust. In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction. ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships. Ultimately, Reasoner(a symbolic solver) identify a series of rational and coherent arguments to support decision. ArgMed-Agents enables LLMs to mimic the process of clinical argumentative reasoning by generating explanations of reasoning in a self-directed manner. The setup experiments show that ArgMed-Agents not only improves accuracy in complex clinical decision reasoning problems compared to other prompt methods, but more importantly, it provides users with decision explanations that increase their confidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06294v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengxin Hong, Liang Xiao, Xin Zhang, Jianxia Chen</dc:creator>
    </item>
    <item>
      <title>Decentralized and Lifelong-Adaptive Multi-Agent Collaborative Learning</title>
      <link>https://arxiv.org/abs/2403.06535</link>
      <description>arXiv:2403.06535v1 Announce Type: cross 
Abstract: Decentralized and lifelong-adaptive multi-agent collaborative learning aims to enhance collaboration among multiple agents without a central server, with each agent solving varied tasks over time. To achieve efficient collaboration, agents should: i) autonomously identify beneficial collaborative relationships in a decentralized manner; and ii) adapt to dynamically changing task observations. In this paper, we propose DeLAMA, a decentralized multi-agent lifelong collaborative learning algorithm with dynamic collaboration graphs. To promote autonomous collaboration relationship learning, we propose a decentralized graph structure learning algorithm, eliminating the need for external priors. To facilitate adaptation to dynamic tasks, we design a memory unit to capture the agents' accumulated learning history and knowledge, while preserving finite storage consumption. To further augment the system's expressive capabilities and computational efficiency, we apply algorithm unrolling, leveraging the advantages of both mathematical optimization and neural networks. This allows the agents to `learn to collaborate' through the supervision of training tasks. Our theoretical analysis verifies that inter-agent collaboration is communication efficient under a small number of communication rounds. The experimental results verify its ability to facilitate the discovery of collaboration strategies and adaptation to dynamic learning scenarios, achieving a 98.80% reduction in MSE and a 188.87% improvement in classification accuracy. We expect our work can serve as a foundational technique to facilitate future works towards an intelligent, decentralized, and dynamic multi-agent system. Code is available at https://github.com/ShuoTang123/DeLAMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06535v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Tang, Rui Ye, Chenxin Xu, Xiaowen Dong, Siheng Chen, Yanfeng Wang</dc:creator>
    </item>
    <item>
      <title>FashionReGen: LLM-Empowered Fashion Report Generation</title>
      <link>https://arxiv.org/abs/2403.06660</link>
      <description>arXiv:2403.06660v1 Announce Type: cross 
Abstract: Fashion analysis refers to the process of examining and evaluating trends, styles, and elements within the fashion industry to understand and interpret its current state, generating fashion reports. It is traditionally performed by fashion professionals based on their expertise and experience, which requires high labour cost and may also produce biased results for relying heavily on a small group of people. In this paper, to tackle the Fashion Report Generation (FashionReGen) task, we propose an intelligent Fashion Analyzing and Reporting system based the advanced Large Language Models (LLMs), debbed as GPT-FAR. Specifically, it tries to deliver FashionReGen based on effective catwalk analysis, which is equipped with several key procedures, namely, catwalk understanding, collective organization and analysis, and report generation. By posing and exploring such an open-ended, complex and domain-specific task of FashionReGen, it is able to test the general capability of LLMs in fashion domain. It also inspires the explorations of more high-level tasks with industrial significance in other domains. Video illustration and more materials of GPT-FAR can be found in https://github.com/CompFashion/FashionReGen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06660v1</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yujuan Ding, Yunshan Ma, Wenqi Fan, Yige Yao, Tat-Seng Chua, Qing Li</dc:creator>
    </item>
    <item>
      <title>An AI-enabled Agent-Based Model and Its Application in Measles Outbreak Simulation for New Zealand</title>
      <link>https://arxiv.org/abs/2403.03434</link>
      <description>arXiv:2403.03434v2 Announce Type: replace 
Abstract: Agent Based Models (ABMs) have emerged as a powerful tool for investigating complex social interactions, particularly in the context of public health and infectious disease investigation. In an effort to enhance the conventional ABM, enabling automated model calibration and reducing the computational resources needed for scaling up the model, we have developed a tensorized and differentiable agent-based model by coupling Graph Neural Network (GNN) and Long Short-Term Memory (LSTM) network. The model was employed to investigate the 2019 measles outbreak occurred in New Zealand, demonstrating a promising ability to accurately simulate the outbreak dynamics, particularly during the peak period of repeated cases. This paper shows that by leveraging the latest Artificial Intelligence (AI) technology and the capabilities of traditional ABMs, we gain deeper insights into the dynamics of infectious disease outbreaks. This, in turn, helps us make more informed decision when developing effective strategies that strike a balance between managing outbreaks and minimizing disruptions to everyday life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03434v2</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sijin Zhang, Alvaro Orsi, Lei Chen</dc:creator>
    </item>
    <item>
      <title>Limited or Biased: Modeling Sub-Rational Human Investors in Financial Markets</title>
      <link>https://arxiv.org/abs/2210.08569</link>
      <description>arXiv:2210.08569v2 Announce Type: replace-cross 
Abstract: Human decision-making in real-life deviates significantly from the optimal decisions made by fully rational agents, primarily due to computational limitations or psychological biases. While existing studies in behavioral finance have discovered various aspects of human sub-rationality, there lacks a comprehensive framework to transfer these findings into an adaptive human model applicable across diverse financial market scenarios. In this study, we introduce a flexible model that incorporates five different aspects of human sub-rationality using reinforcement learning. Our model is trained using a high-fidelity multi-agent market simulator, which overcomes limitations associated with the scarcity of labeled data of individual investors. We evaluate the behavior of sub-rational human investors using hand-crafted market scenarios and SHAP value analysis, showing that our model accurately reproduces the observations in the previous studies and reveals insights of the driving factors of human behavior. Finally, we explore the impact of sub-rationality on the investor's Profit and Loss (PnL) and market quality. Our experiments reveal that bounded-rational and prospect-biased human behaviors improve liquidity but diminish price efficiency, whereas human behavior influenced by myopia, optimism, and pessimism reduces market liquidity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08569v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Penghang Liu, Kshama Dwarakanath, Svitlana S Vyetrenko, Tucker Balch</dc:creator>
    </item>
    <item>
      <title>Markov $\alpha$-Potential Games</title>
      <link>https://arxiv.org/abs/2305.12553</link>
      <description>arXiv:2305.12553v5 Announce Type: replace-cross 
Abstract: This paper proposes a new framework of Markov $\alpha$-potential games to study Markov games. In this new framework, Markov games are shown to be Markov $\alpha$-potential games, and the existence of an associated $\alpha$-potential function is established. Any optimizer of an $\alpha$-potential function is shown to be an $\alpha$-stationary NE. Two important classes of practically significant Markov games, Markov congestion games and the perturbed Markov team games, are studied via this framework of Markov $\alpha$-potential games, with explicit characterization of an upper bound for $\alpha$ and its relation to game parameters. Additionally, a semi-infinite linear programming based formulation is presented to obtain an upper bound for $\alpha$ for any Markov game. Furthermore, two equilibrium approximation algorithms, namely the projected gradient-ascent algorithm and the sequential maximum improvement algorithm, are presented along with their Nash regret analysis, and corroborated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12553v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Xinyu Li, Chinmay Maheshwari, Shankar Sastry, Manxi Wu</dc:creator>
    </item>
    <item>
      <title>Designing Equilibria in Concurrent Games with Social Welfare and Temporal Logic Constraints</title>
      <link>https://arxiv.org/abs/2306.03045</link>
      <description>arXiv:2306.03045v2 Announce Type: replace-cross 
Abstract: In game theory, mechanism design is concerned with the design of incentives so that a desired outcome of the game can be achieved. In this paper, we explore the concept of equilibrium design, where incentives are designed to obtain a desirable equilibrium that satisfies a specific temporal logic property. Our study is based on a framework where system specifications are represented as temporal logic formulae, games as quantitative concurrent game structures, and players' goals as mean-payoff objectives. We consider system specifications given by LTL and GR(1) formulae, and show that designing incentives to ensure that a given temporal logic property is satisfied on some/every Nash equilibrium of the game can be achieved in PSPACE for LTL properties and in NP/{\Sigma}P 2 for GR(1) specifications. We also examine the complexity of related decision and optimisation problems, such as optimality and uniqueness of solutions, as well as considering social welfare, and show that the complexities of these problems lie within the polynomial hierarchy. Equilibrium design can be used as an alternative solution to rational synthesis and verification problems for concurrent games with mean-payoff objectives when no solution exists or as a technique to repair concurrent games with undesirable Nash equilibria in an optimal way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03045v2</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, Michael Wooldridge</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Motion Planning with B\'ezier Curve Optimization under Kinodynamic Constraints</title>
      <link>https://arxiv.org/abs/2311.14145</link>
      <description>arXiv:2311.14145v2 Announce Type: replace-cross 
Abstract: Multi-Agent Motion Planning (MAMP) is a problem that seeks collision-free dynamically-feasible trajectories for multiple moving agents in a known environment while minimizing their travel time. MAMP is closely related to the well-studied Multi-Agent Path-Finding (MAPF) problem. Recently, MAPF methods have achieved great success in finding collision-free paths for a substantial number of agents. However, those methods often overlook the kinodynamic constraints of the agents, assuming instantaneous movement, which limits their practicality and realism. In this paper, we present a three-level MAPF-based planner called PSB to address the challenges posed by MAMP. PSB fully considers the kinodynamic capability of the agents and produces solutions with smooth speed profiles that can be directly executed by the controller. Empirically, we evaluate PSB within the domains of traffic intersection coordination for autonomous vehicles and obstacle-rich grid map navigation for mobile robots. PSB shows up to 49.79% improvements in solution cost compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14145v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LRA.2024.3363543</arxiv:DOI>
      <dc:creator>Jingtian Yan, Jiaoyang Li</dc:creator>
    </item>
  </channel>
</rss>
