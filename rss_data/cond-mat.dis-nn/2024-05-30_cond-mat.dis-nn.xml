<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 May 2024 01:50:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Are queries and keys always relevant? A case study on Transformer wave functions</title>
      <link>https://arxiv.org/abs/2405.18874</link>
      <description>arXiv:2405.18874v1 Announce Type: new 
Abstract: The dot product attention mechanism, originally designed for natural language processing (NLP) tasks, is a cornerstone of modern Transformers. It adeptly captures semantic relationships between word pairs in sentences by computing a similarity overlap between queries and keys. In this work, we explore the suitability of Transformers, focusing on their attention mechanisms, in the specific domain of the parametrization of variational wave functions to approximate ground states of quantum many-body spin Hamiltonians. Specifically, we perform numerical simulations on the two-dimensional $J_1$-$J_2$ Heisenberg model, a common benchmark in the field of quantum-many body systems on lattice. By comparing the performance of standard attention mechanisms with a simplified version that excludes queries and keys, relying solely on positions, we achieve competitive results while reducing computational cost and parameter usage. Furthermore, through the analysis of the attention maps generated by standard attention mechanisms, we show that the attention weights become effectively input-independent at the end of the optimization. We support the numerical results with analytical calculations, providing physical insights of why queries and keys should be, in principle, omitted from the attention mechanism when studying large systems. Interestingly, the same arguments can be extended to the NLP domain, in the limit of long input sentences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18874v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.CL</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riccardo Rende, Luciano Loris Viteritti</dc:creator>
    </item>
    <item>
      <title>Genuine topological Anderson insulator from impurity induced chirality reversal</title>
      <link>https://arxiv.org/abs/2405.19289</link>
      <description>arXiv:2405.19289v1 Announce Type: cross 
Abstract: We investigate a model of Dirac fermions with Haldane type mass impurities which open a global topological gap even in the dilute limit. Surprisingly, we find that the chirality of this mass term, i.e., the sign of the Chern number, can be reversed by tuning the magnitude of the single-impurity scattering. Consequently, the disorder induces a phase disconnected from the clean topological phase, i.e., a genuine topological Anderson insulator. In seeming contradiction to the expectation that mass disorder is an irrelevant perturbation to the clean integer quantum Hall transition, the tri-critical point separating these two Chern insulating phases and a thermal metal phase is located at zero impurity density and connected to the appearance of a zero energy bound state in the continuum corresponding to a divergent Haldane mass impurity. Our conclusions based on the T-matrix expansion are substantiated by large scale Chebyshev-Polynomial-Green-Function numerics. We discuss possible experimental platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19289v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Avedis Neehus, Frank Pollmann, Johannes Knolle</dc:creator>
    </item>
    <item>
      <title>Noisy Quantum Trees: Infinite Protection Without Correction</title>
      <link>https://arxiv.org/abs/2306.14294</link>
      <description>arXiv:2306.14294v3 Announce Type: replace-cross 
Abstract: We study quantum networks with tree structures, in which information propagates from a root to leaves. At each node in the network, the received qubit unitarily interacts with fresh ancilla qubits, after which each qubit is sent through a noisy channel to a different node in the next level. Therefore, as the tree depth grows, there is a competition between the irreversible effect of noise and the protection against such noise achieved by delocalization of information. In the classical setting, where each node simply copies the input bit into multiple output bits, this model has been studied as the broadcasting or reconstruction problem on trees, which has broad applications. In this work, we study the quantum version of this problem. We consider a Clifford encoder at each node that encodes the input qubit in a stabilizer code, along with a single qubit Pauli noise channel at each edge. Such noisy quantum trees describe a scenario in which one has access to a stream of fresh (low-entropy) ancilla qubits, but cannot perform error correction. Therefore, they provide a different perspective on quantum fault tolerance. Furthermore, they provide a useful model for describing the effect of noise within the encoders of concatenated codes. We prove that above certain noise thresholds, which depend on the properties of the code such as its distance, as well as the properties of the encoder, information decays exponentially with the depth of the tree. On the other hand, by studying certain efficient decoders, we prove that for codes with distance d&gt;=2 and for sufficiently small (but non-zero) noise, classical information and entanglement propagate over a noisy tree with infinite depth. Indeed, we find that this remains true even for binary trees with certain 2-qubit encoders at each node, which encode the received qubit in the binary repetition code with distance d=1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14294v3</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>hep-th</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiv Akshar Yadavalli, Iman Marvian</dc:creator>
    </item>
    <item>
      <title>Cascade of phase transitions in the training of Energy-based models</title>
      <link>https://arxiv.org/abs/2405.14689</link>
      <description>arXiv:2405.14689v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the feature encoding process in a prototypical energy-based generative model, the Restricted Boltzmann Machine (RBM). We start with an analytical investigation using simplified architectures and data structures, and end with numerical analysis of real trainings on real datasets. Our study tracks the evolution of the model's weight matrix through its singular value decomposition, revealing a series of phase transitions associated to a progressive learning of the principal modes of the empirical probability distribution. The model first learns the center of mass of the modes and then progressively resolve all modes through a cascade of phase transitions. We first describe this process analytically in a controlled setup that allows us to study analytically the training dynamics. We then validate our theoretical results by training the Bernoulli-Bernoulli RBM on real data sets. By using data sets of increasing dimension, we show that learning indeed leads to sharp phase transitions in the high-dimensional limit. Moreover, we propose and test a mean-field finite-size scaling hypothesis. This shows that the first phase transition is in the same universality class of the one we studied analytically, and which is reminiscent of the mean-field paramagnetic-to-ferromagnetic phase transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14689v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitrios Bachtis, Giulio Biroli, Aur\'elien Decelle, Beatriz Seoane</dc:creator>
    </item>
  </channel>
</rss>
