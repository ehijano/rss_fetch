<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Mar 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Difference-in-Differences with Unpoolable Data</title>
      <link>https://arxiv.org/abs/2403.15910</link>
      <description>arXiv:2403.15910v1 Announce Type: new 
Abstract: In this study, we identify and relax the assumption of data "poolability" in difference-in-differences (DID) estimation. Poolability, or the combination of observations from treated and control units into one dataset, is often not possible due to data privacy concerns. For instance, administrative health data stored in secure facilities is often not combinable across jurisdictions. We propose an innovative approach to estimate DID with unpoolable data: UN--DID. Our method incorporates adjustments for additional covariates, multiple groups, and staggered adoption. Without covariates, UN--DID and conventional DID give identical estimates of the average treatment effect on the treated (ATT). With covariates, we show mathematically and through simulations that UN--DID and conventional DID provide different, but equally informative, estimates of the ATT. An empirical example further underscores the utility of our methodology. The UN--DID method paves the way for more comprehensive analyses of policy impacts, even under data poolability constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15910v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunny Karim, Matthew D. Webb, Nichole Austin, Erin Strumpf</dc:creator>
    </item>
    <item>
      <title>Debiased Machine Learning when Nuisance Parameters Appear in Indicator Functions</title>
      <link>https://arxiv.org/abs/2403.15934</link>
      <description>arXiv:2403.15934v1 Announce Type: new 
Abstract: This paper studies debiased machine learning when nuisance parameters appear in indicator functions. An important example is maximized average welfare under optimal treatment assignment rules. For asymptotically valid inference for a parameter of interest, the current literature on debiased machine learning relies on Gateaux differentiability of the functions inside moment conditions, which does not hold when nuisance parameters appear in indicator functions. In this paper, we propose smoothing the indicator functions, and develop an asymptotic distribution theory for this class of models. The asymptotic behavior of the proposed estimator exhibits a trade-off between bias and variance due to smoothing. We study how a parameter which controls the degree of smoothing can be chosen optimally to minimize an upper bound of the asymptotic mean squared error. A Monte Carlo simulation supports the asymptotic distribution theory, and an empirical example illustrates the implementation of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15934v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gyungbae Park</dc:creator>
    </item>
    <item>
      <title>The Informativeness of Combined Experimental and Observational Data under Dynamic Selection</title>
      <link>https://arxiv.org/abs/2403.16177</link>
      <description>arXiv:2403.16177v1 Announce Type: new 
Abstract: This paper addresses the challenge of estimating the Average Treatment Effect on the Treated Survivors (ATETS; Vikstrom et al., 2018) in the absence of long-term experimental data, utilizing available long-term observational data instead. We establish two theoretical results. First, it is impossible to obtain informative bounds for the ATETS with no model restriction and no auxiliary data. Second, to overturn this negative result, we explore as a promising avenue the recent econometric developments in combining experimental and observational data (e.g., Athey et al., 2020, 2019); we indeed find that exploiting short-term experimental data can be informative without imposing classical model restrictions. Furthermore, building on Chesher and Rosen (2017), we explore how to systematically derive sharp identification bounds, exploiting both the novel data-combination principles and classical model restrictions. Applying the proposed method, we explore what can be learned about the long-run effects of job training programs on employment without long-term experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16177v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yechan Park, Yuya Sasaki</dc:creator>
    </item>
    <item>
      <title>Resistant Inference in Instrumental Variable Models</title>
      <link>https://arxiv.org/abs/2403.16844</link>
      <description>arXiv:2403.16844v1 Announce Type: new 
Abstract: The classical tests in the instrumental variable model can behave arbitrarily if the data is contaminated. For instance, one outlying observation can be enough to change the outcome of a test. We develop a framework to construct testing procedures that are robust to weak instruments, outliers and heavy-tailed errors in the instrumental variable model. The framework is constructed upon M-estimators. By deriving the influence functions of the classical weak instrument robust tests, such as the Anderson-Rubin test, K-test and the conditional likelihood ratio (CLR) test, we prove their unbounded sensitivity to infinitesimal contamination. Therefore, we construct contamination resistant/robust alternatives. In particular, we show how to construct a robust CLR statistic based on Mallows type M-estimators and show that its asymptotic distribution is the same as that of the (classical) CLR statistic. The theoretical results are corroborated by a simulation study. Finally, we revisit three empirical studies affected by outliers and demonstrate how the new robust tests can be used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16844v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens Klooster, Mikhail Zhelonkin</dc:creator>
    </item>
    <item>
      <title>Optimal testing in a class of nonregular models</title>
      <link>https://arxiv.org/abs/2403.16413</link>
      <description>arXiv:2403.16413v1 Announce Type: cross 
Abstract: This paper studies optimal hypothesis testing for nonregular statistical models with parameter-dependent support. We consider both one-sided and two-sided hypothesis testing and develop asymptotically uniformly most powerful tests based on the likelihood ratio process. The proposed one-sided test involves randomization to achieve asymptotic size control, some tuning constant to avoid discontinuities in the limiting likelihood ratio process, and a user-specified alternative hypothetical value to achieve the asymptotic optimality. Our two-sided test becomes asymptotically uniformly most powerful without imposing further restrictions such as unbiasedness. Simulation results illustrate desirable power properties of the proposed tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16413v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuya Shimizu, Taisuke Otsu</dc:creator>
    </item>
    <item>
      <title>Quasi-randomization tests for network interference</title>
      <link>https://arxiv.org/abs/2403.16673</link>
      <description>arXiv:2403.16673v1 Announce Type: cross 
Abstract: Many classical inferential approaches fail to hold when interference exists among the population units. This amounts to the treatment status of one unit affecting the potential outcome of other units in the population. Testing for such spillover effects in this setting makes the null hypothesis non-sharp. An interesting approach to tackling the non-sharp nature of the null hypothesis in this setup is constructing conditional randomization tests such that the null is sharp on the restricted population. In randomized experiments, conditional randomized tests hold finite sample validity. Such approaches can pose computational challenges as finding these appropriate sub-populations based on experimental design can involve solving an NP-hard problem. In this paper, we view the network amongst the population as a random variable instead of being fixed. We propose a new approach that builds a conditional quasi-randomization test. Our main idea is to build the (non-sharp) null distribution of no spillover effects using random graph null models. We show that our method is exactly valid in finite-samples under mild assumptions. Our method displays enhanced power over other methods, with substantial improvement in complex experimental designs. We highlight that the method reduces to a simple permutation test, making it easy to implement in practice. We conduct a simulation study to verify the finite-sample validity of our approach and illustrate our methodology to test for interference in a weather insurance adoption experiment run in rural China.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16673v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Supriya Tiwari, Pallavi Basu</dc:creator>
    </item>
    <item>
      <title>Privacy-Protected Spatial Autoregressive Model</title>
      <link>https://arxiv.org/abs/2403.16773</link>
      <description>arXiv:2403.16773v1 Announce Type: cross 
Abstract: Spatial autoregressive (SAR) models are important tools for studying network effects. However, with an increasing emphasis on data privacy, data providers often implement privacy protection measures that make classical SAR models inapplicable. In this study, we introduce a privacy-protected SAR model with noise-added response and covariates to meet privacy-protection requirements. However, in this scenario, the traditional quasi-maximum likelihood estimator becomes infeasible because the likelihood function cannot be formulated. To address this issue, we first consider an explicit expression for the likelihood function with only noise-added responses. However, the derivatives are biased owing to the noise in the covariates. Therefore, we develop techniques that can correct the biases introduced by noise. Correspondingly, a Newton-Raphson-type algorithm is proposed to obtain the estimator, leading to a corrected likelihood estimator. To further enhance computational efficiency, we introduce a corrected least squares estimator based on the idea of bias correction. These two estimation methods ensure both data security and the attainment of statistically valid estimators. Theoretical analysis of both estimators is carefully conducted, and statistical inference methods are discussed. The finite sample performances of different methods are demonstrated through extensive simulations and the analysis of a real dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16773v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danyang Huang, Ziyi Kong, Shuyuan Wu, Hansheng Wang</dc:creator>
    </item>
    <item>
      <title>Identification and Estimation of Unconditional Policy Effects of an Endogenous Binary Treatment: An Unconditional MTE Approach</title>
      <link>https://arxiv.org/abs/2010.15864</link>
      <description>arXiv:2010.15864v5 Announce Type: replace 
Abstract: This paper studies the identification and estimation of policy effects when treatment status is binary and endogenous. We introduce a new class of marginal treatment effects (MTEs) based on the influence function of the functional underlying the policy target. We show that an unconditional policy effect can be represented as a weighted average of the newly defined MTEs over the individuals who are indifferent about their treatment status. We provide conditions for point identification of the unconditional policy effects. When a quantile is the functional of interest, we introduce the UNconditional Instrumental Quantile Estimator (UNIQUE) and establish its consistency and asymptotic distribution. In the empirical application, we estimate the effect of changing college enrollment status, induced by higher tuition subsidy, on the quantiles of the wage distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.15864v5</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Martinez-Iriarte, Yixiao Sun</dc:creator>
    </item>
    <item>
      <title>On the Inconsistency of Cluster-Robust Inference and How Subsampling Can Fix It</title>
      <link>https://arxiv.org/abs/2308.10138</link>
      <description>arXiv:2308.10138v5 Announce Type: replace 
Abstract: Conventional methods of cluster-robust inference are inconsistent in the presence of unignorably large clusters. We formalize this claim by establishing a necessary and sufficient condition for the consistency of the conventional methods. We find that this condition for the consistency is rejected for a majority of empirical research papers. In this light, we propose a novel score subsampling method that achieves uniform size control over a broad class of data generating processes, covering that fails the conventional method. Simulation studies support these claims. With real data used by an empirical paper, we showcase that the conventional methods conclude significance while our proposed method concludes insignificance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10138v5</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harold D. Chiang, Yuya Sasaki, Yulong Wang</dc:creator>
    </item>
    <item>
      <title>Inference for Regression with Variables Generated from Unstructured Data</title>
      <link>https://arxiv.org/abs/2402.15585</link>
      <description>arXiv:2402.15585v2 Announce Type: replace 
Abstract: The leading strategy for analyzing unstructured data uses two steps. First, latent variables of economic interest are estimated with an upstream information retrieval model. Second, the estimates are treated as "data" in a downstream econometric model. We establish theoretical arguments for why this two-step strategy leads to biased inference in empirically plausible settings. More constructively, we propose a one-step strategy for valid inference that uses the upstream and downstream models jointly. The one-step strategy (i) substantially reduces bias in simulations; (ii) has quantitatively important effects in a leading application using CEO time-use data; and (iii) can be readily adapted by applied researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15585v2</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Battaglia, Timothy Christensen, Stephen Hansen, Szymon Sacher</dc:creator>
    </item>
    <item>
      <title>Online Action Learning in High Dimensions: A Conservative Perspective</title>
      <link>https://arxiv.org/abs/2009.13961</link>
      <description>arXiv:2009.13961v4 Announce Type: replace-cross 
Abstract: Sequential learning problems are common in several fields of research and practical applications. Examples include dynamic pricing and assortment, design of auctions and incentives and permeate a large number of sequential treatment experiments. In this paper, we extend one of the most popular learning solutions, the $\epsilon_t$-greedy heuristics, to high-dimensional contexts considering a conservative directive. We do this by allocating part of the time the original rule uses to adopt completely new actions to a more focused search in a restrictive set of promising actions. The resulting rule might be useful for practical applications that still values surprises, although at a decreasing rate, while also has restrictions on the adoption of unusual actions. With high probability, we find reasonable bounds for the cumulative regret of a conservative high-dimensional decaying $\epsilon_t$-greedy rule. Also, we provide a lower bound for the cardinality of the set of viable actions that implies in an improved regret bound for the conservative version when compared to its non-conservative counterpart. Additionally, we show that end-users have sufficient flexibility when establishing how much safety they want, since it can be tuned without impacting theoretical properties. We illustrate our proposal both in a simulation exercise and using a real dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.13961v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudio Cardoso Flores, Marcelo Cunha Medeiros</dc:creator>
    </item>
  </channel>
</rss>
