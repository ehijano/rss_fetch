<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Population Dynamics Control with Partial Observations</title>
      <link>https://arxiv.org/abs/2502.14079</link>
      <description>arXiv:2502.14079v1 Announce Type: new 
Abstract: We study the problem of controlling population dynamics, a class of linear dynamical systems evolving on the probability simplex, from the perspective of online non-stochastic control. While Golowich et.al. 2024 analyzed the fully observable setting, we focus on the more realistic, partially observable case, where only a low-dimensional representation of the state is accessible.
  In classical non-stochastic control, inputs are set as linear combinations of past disturbances. However, under partial observations, disturbances cannot be directly computed. To address this, Simchowitz et.al. 2020 proposed to construct oblivious signals, which are counterfactual observations with zero control, as a substitute. This raises several challenges in our setting: (1) how to construct oblivious signals under simplex constraints, where zero control is infeasible; (2) how to design a sufficiently expressive convex controller parameterization tailored to these signals; and (3) how to enforce the simplex constraint on control when projections may break the convexity of cost functions.
  Our main contribution is a new controller that achieves the optimal $\tilde{O}(\sqrt{T})$ regret with respect to a natural class of mixing linear dynamic controllers. To tackle these challenges, we construct signals based on hypothetical observations under a constant control adapted to the simplex domain, and introduce a new controller parameterization that approximates general control policies linear in non-oblivious observations. Furthermore, we employ a novel convex extension surrogate loss, inspired by Lattimore 2024, to bypass the projection-induced convexity issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14079v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhou Lu, Y. Jennifer Sun, Zhiyu Zhang</dc:creator>
    </item>
    <item>
      <title>A modified two-stage search framework for constrained multi-gradient descent</title>
      <link>https://arxiv.org/abs/2502.14104</link>
      <description>arXiv:2502.14104v1 Announce Type: new 
Abstract: \cite{desideri2012multiple} proposed a multi-gradient descent algorithm (MGDA) that can improve all objectives based on seeking the minim norm point in the convex hull consisting of objectives function gradients as the common descent direction, which has become the cornerstone of the multi-musk learning and multi-objective optimization. However, the logic to seek a common descent direction through finding the minim-norm point in the gradient convex hull may fail under constraints, no matter whether taking the constraints into consideration directly or projecting it into the feasible region after finding the common descent direction with no constraints. Therefore, we proposed a two-stage search framework. In the first stage, a min-max search algorithm is implemented to minimize the upper bound of the directional derivatives under constraints, and the weak Pareto stationary can be theoretically reached in the first stage. In the second stage, the Pareto stationary can be theoretically obtained through the minimization of the lower bound of the directional derivatives under constraints. In numerical studies, we show the effectiveness of our proposed framework from the calibration of the multi-regime fundamental diagram model and large-scale multi-objective portfolio problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14104v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edison Y. Lei, Yaobang Gong, Xianfeng Terry Yang</dc:creator>
    </item>
    <item>
      <title>Gaining efficiency in deep policy gradient method for continuous-time optimal control problems</title>
      <link>https://arxiv.org/abs/2502.14141</link>
      <description>arXiv:2502.14141v1 Announce Type: new 
Abstract: In this paper, we propose an efficient implementation of deep policy gradient method (PGM) for optimal control problems in continuous time. The proposed method has the ability to manage the allocation of computational resources, number of trajectories, and complexity of architecture of the neural network. This is, in particular, important for continuous-time problems that require a fine time discretization. Each step of this method focuses on a different time scale and learns a policy, modeled by a neural network, for a discretized optimal control problem. The first step has the coarsest time discretization. As we proceed to other steps, the time discretization becomes finer. The optimal trained policy in each step is also used to provide data for the next step. We accompany the multi-scale deep PGM with a theoretical result on allocation of computational resources to obtain a targeted efficiency and test our methods on the linear-quadratic stochastic optimal control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14141v1</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arash Fahim, Md. Arafatur Rahman</dc:creator>
    </item>
    <item>
      <title>Weighted Low-rank Approximation via Stochastic Gradient Descent on Manifolds</title>
      <link>https://arxiv.org/abs/2502.14174</link>
      <description>arXiv:2502.14174v1 Announce Type: new 
Abstract: We solve a regularized weighted low-rank approximation problem by a stochastic gradient descent on a manifold. To guarantee the convergence of our stochastic gradient descent, we establish a convergence theorem on manifolds for retraction-based stochastic gradient descents admitting confinements. On sample data from the Netflix Prize training dataset, our algorithm outperforms the existing stochastic gradient descent on Euclidean spaces. We also compare the accelerated line search on this manifold to the existing accelerated line search on Euclidean spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14174v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conglong Xu, Peiqi Yang, Hao Wu</dc:creator>
    </item>
    <item>
      <title>Small Gain Theorem-Based Robustness Analysis of Discrete-Time MJLSs with the Markov Chain on a Borel Space and Its Application to NCSs</title>
      <link>https://arxiv.org/abs/2502.14188</link>
      <description>arXiv:2502.14188v1 Announce Type: new 
Abstract: This paper is concerned with the robustness of discrete-time Markov jump linear systems (MJLSs) with the Markov chain on a Borel space. For this general class of MJLSs, a small gain theorem is first established and subsequently applied to derive a lower bound of the stability radius. On this basis, with the aid of the extended bounded real lemma and Schur complements, the robust stability problems for the MJLSs are tackled via linear matrix inequality (LMI) techniques. The novel contribution, primarily founded on the scenario where the state space of the Markov chain is restricted in a continuous set, lies in the formulation of a griding approach. The approach converts the existence problem of solutions of an inequality related to $H_{\infty}$ analysis, which is an infinite-dimensional challenge, into a finite-dimensional LMI feasibility problem. As an application, within the framework of MJLSs, a robustness issue of the sampled-data systems is addressed by using a Markov chain, which is determined by the initial distribution and the stochastic kernel, to model transmission delays existing in networked control systems (NCSs). Finally, the feasibility of the results is verified through two examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14188v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunjie Xiao, Ting Hou, Weihai Zhang, Feiqi Deng</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Linear Quadratic Regulator Without Initial Stability</title>
      <link>https://arxiv.org/abs/2502.14210</link>
      <description>arXiv:2502.14210v1 Announce Type: new 
Abstract: Inspired by REINFORCE, we introduce a novel receding-horizon algorithm for the Linear Quadratic Regulator (LQR) problem with unknown parameters. Unlike prior methods, our algorithm avoids reliance on two-point gradient estimates while maintaining the same order of sample complexity. Furthermore, it eliminates the restrictive requirement of starting with a stable initial policy, broadening its applicability. Beyond these improvements, we introduce a refined analysis of error propagation through the contraction of the Riemannian distance over the Riccati operator. This refinement leads to a better sample complexity and ensures improved convergence guarantees. Numerical simulations validate the theoretical results, demonstrating the method's practical feasibility and performance in realistic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14210v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Amirreza Neshaei Moghaddam, Alex Olshevsky, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>Anderson Accelerated Operator Splitting Methods for Convex-nonconvex Regularized Problems</title>
      <link>https://arxiv.org/abs/2502.14269</link>
      <description>arXiv:2502.14269v1 Announce Type: new 
Abstract: Convex-nonconvex (CNC) regularization is a novel paradigm that employs a nonconvex penalty function while maintaining the convexity of the entire objective function. It has been successfully applied to problems in signal processing, statistics, and machine learning. Despite its wide application, the computation of CNC regularized problems remains challenging and under-investigated. To fill the gap, we study several operator splitting methods and their Anderson accelerated counterparts for solving least squares problems with CNC regularization. We establish the global convergence of the proposed algorithm to an optimal point and demonstrate its practical speed-ups in various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14269v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Heng, Xiaoqian Liu, Eric C. Chi</dc:creator>
    </item>
    <item>
      <title>Clustering-based Low Rank Approximation Method</title>
      <link>https://arxiv.org/abs/2502.14331</link>
      <description>arXiv:2502.14331v1 Announce Type: new 
Abstract: We propose a clustering-based generalized low rank approximation method, which takes advantage of appealing features from both the generalized low rank approximation of matrices (GLRAM) and cluster analysis. It exploits a more general form of clustering generators and similarity metrics so that it is more suitable for matrix-structured data relative to conventional partitioning methods. In our approach, we first pre-classify the initial matrix collection into several small subset clusters and then sequentially compress the matrices within the clusters. This strategy enhances the numerical precision of the low-rank approximation. In essence, we combine the ideas of GLRAM and clustering into a hybrid algorithm for dimensionality reduction. The proposed algorithm can be viewed as the generalization of both techniques. Theoretical analysis and numerical experiments are established to validate the feasibility and effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14331v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yujun Zhu, Jie Zhu, Hizba Arshad, Zhongming Wang, Ju Ming</dc:creator>
    </item>
    <item>
      <title>Data-Driven Cooperative Output Regulation via Distributed Internal Model</title>
      <link>https://arxiv.org/abs/2502.14336</link>
      <description>arXiv:2502.14336v1 Announce Type: new 
Abstract: The existing result on the cooperative output regulation problem for unknown linear multi-agent systems using a data-driven distributed internal model approach is limited to the case where each follower is a single-input and single-output system and the communication network among all agents is an acyclic static digraph. In this paper, we further address the same problem for unknown linear multi-agent systems with multi-input and multi-output followers over a general static and connected digraph. Further we make two main improvements over the existing result. First, we derive a set of much simplified linear systems to be applied by the integral reinforcement learning technique. Thus, the number of the unknown variables governed by a sequence of linear algebraic equations is much smaller than that of the existing approach. Second, we show that the sequence of linear algebraic equations can be further decoupled to two sequences of linear algebraic equations. As a result of these two improvements, our approach not only drastically reduces the computational cost, but also significantly weakens the solvability conditions in terms of the the full column rank requirements for these equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14336v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liquan Lin, Jie Huang</dc:creator>
    </item>
    <item>
      <title>Algorithms for min-buying in networks</title>
      <link>https://arxiv.org/abs/2502.14459</link>
      <description>arXiv:2502.14459v1 Announce Type: new 
Abstract: The paper is motivated by pricing decisions faced by forecourt fuel retailers across their outlets on a road network. Through our modelling approach we are able adapt the network structure to a bipartite graph with demand nodes representing volumes of fuel from customers using a specific route that connects to the seller's outlet nodes that intersect that route on the network. Customers may have their demand satisfied at the lowest priced competitor on their route. However, the seller can satisfy some or all of this demand by matching or beating this price via one of their outlets intersecting the route. We give a practical extension to min-pricing by considering a binary logit variant for buyers evaluating the choice between two sellers. We derive two MIP formulations for min-buying in the case of general demand. We also propose several constructive heuristics, based on insertion and selection operations, suitable for problem instances beyond the scope of the exact methods. The performance of models and algorithms are evaluated in a numerical study and develop insights from the results. Importantly, we are able to highlight the value of price-matching decisions under buyer demand sensitivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14459v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aaditya Bhardwaj, Ben Black, Trivikram Dokka, Christopher Kirkbride</dc:creator>
    </item>
    <item>
      <title>Dynamic Preference-based Multi-modal Trip Planning of Public Transport and Shared Mobility</title>
      <link>https://arxiv.org/abs/2502.14528</link>
      <description>arXiv:2502.14528v1 Announce Type: new 
Abstract: The shift from private vehicles to public and shared transport is crucial to reducing emissions and meeting climate targets. Consequently, there is an urgent need to develop a multimodal transport trip planning approach that integrates public transport and shared mobility solutions, offering viable alternatives to private vehicle use. To this end, we propose a preference-based optimization framework for multi-modal trip planning with public transport, ride-pooling services, and shared micro-mobility fleets. We introduce a mixed-integer programming model that incorporates preferences into the objective function of the mathematical model. We present a meta-heuristic framework that incorporates a customized Adaptive Large Neighborhood Search algorithm and other tailored algorithms, to effectively manage dynamic requests through a rolling horizon approach. Numerical experiments are conducted using real transport network data in a suburban area of Rotterdam, the Netherlands. Model application results demonstrate that the proposed algorithm can efficiently obtain near-optimal solutions. Managerial insights are gained from comprehensive experiments that consider various passenger segments, costs of micro-mobility vehicles, and availability fluctuation of shared mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14528v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yimeng Zhang, Oded Cats, Shadi Sharif Azadeh</dc:creator>
    </item>
    <item>
      <title>Kharitonov's Theorem with Degree Drop: a Wronskian Approach</title>
      <link>https://arxiv.org/abs/2502.14754</link>
      <description>arXiv:2502.14754v1 Announce Type: new 
Abstract: In this paper, we present a simplified proof of Kharitonov's Theorem, an important result on determining the Hurwitz stability of interval polynomials. Our new approach to the proof, which is based on the Wronskian of a pair of polynomials, is not only more elementary in comparison to known methods, but is able to handle the degree drop case with ease.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14754v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <category>math.CV</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Elsinger, Anthony Stefan, Aaron Welters</dc:creator>
    </item>
    <item>
      <title>Noise-driven Synchronization of Vicsek Model in Mean</title>
      <link>https://arxiv.org/abs/2502.13993</link>
      <description>arXiv:2502.13993v1 Announce Type: cross 
Abstract: The Vicsek model has long stood as a pivotal framework in exploring collective behavior and self-organization, captivating the scientific community with its compelling dynamics. However, understanding how noise influences synchronization within this model and its associated phase transition characteristics has presented significant challenges. While numerous studies have focused on simulations due to the model's mathematical complexity, comprehensive theoretical analyses remain sparse. In this paper, we deliver a rigorous mathematical proof demonstrating that for any initial configuration of the Vicsek model, there exists a bound on noise amplitude such that if the noise amplitude is maintained within this bound, the system will achieve synchronization in mean. This finding not only lays a solid mathematical groundwork for the Vicsek model's phase transition theory but also underscores the critical role of noise in collective dynamics, enhancing our understanding of self-organizing systems in stochastic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13993v1</guid>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Su, Yongguang Yu, Ge Chen</dc:creator>
    </item>
    <item>
      <title>New Lower Bounds for Stochastic Non-Convex Optimization through Divergence Composition</title>
      <link>https://arxiv.org/abs/2502.14060</link>
      <description>arXiv:2502.14060v1 Announce Type: cross 
Abstract: We study fundamental limits of first-order stochastic optimization in a range of nonconvex settings, including L-smooth functions satisfying Quasar-Convexity (QC), Quadratic Growth (QG), and Restricted Secant Inequalities (RSI). While the convergence properties of standard algorithms are well-understood in deterministic regimes, significantly fewer results address the stochastic case, where only unbiased and noisy gradients are available. We establish new lower bounds on the number of noisy gradient queries to minimize these classes of functions, also showing that they are tight (up to a logarithmic factor) in all the relevant quantities characterizing each class. Our approach reformulates the optimization task as a function identification problem, leveraging divergence composition arguments to construct a challenging subclass that leads to sharp lower bounds. Furthermore, we present a specialized algorithm in the one-dimensional setting that achieves faster rates, suggesting that certain dimensional thresholds are intrinsic to the complexity of non-convex stochastic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14060v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mehdi Saad, Weicheng Lee, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>Aligned Multi Objective Optimization</title>
      <link>https://arxiv.org/abs/2502.14096</link>
      <description>arXiv:2502.14096v1 Announce Type: cross 
Abstract: To date, the multi-objective optimization literature has mainly focused on conflicting objectives, studying the Pareto front, or requiring users to balance tradeoffs. Yet, in machine learning practice, there are many scenarios where such conflict does not take place. Recent findings from multi-task learning, reinforcement learning, and LLMs training show that diverse related tasks can enhance performance across objectives simultaneously. Despite this evidence, such phenomenon has not been examined from an optimization perspective. This leads to a lack of generic gradient-based methods that can scale to scenarios with a large number of related objectives. To address this gap, we introduce the Aligned Multi-Objective Optimization framework, propose new algorithms for this setting, and provide theoretical guarantees of their superior performance compared to naive approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14096v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonathan Efroni (Bill), Ben Kertzu (Bill), Daniel Jiang (Bill), Jalaj Bhandari (Bill),  Zheqing (Bill),  Zhu, Karen Ullrich</dc:creator>
    </item>
    <item>
      <title>Zero loss guarantees and explicit minimizers for generic overparametrized Deep Learning networks</title>
      <link>https://arxiv.org/abs/2502.14114</link>
      <description>arXiv:2502.14114v1 Announce Type: cross 
Abstract: We determine sufficient conditions for overparametrized deep learning (DL) networks to guarantee the attainability of zero loss in the context of supervised learning, for the $\mathcal{L}^2$ cost and {\em generic} training data. We present an explicit construction of the zero loss minimizers without invoking gradient descent. On the other hand, we point out that increase of depth can deteriorate the efficiency of cost minimization using a gradient descent algorithm by analyzing the conditions for rank loss of the training Jacobian. Our results clarify key aspects on the dichotomy between zero loss reachability in underparametrized versus overparametrized DL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14114v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Andrew G. Moore</dc:creator>
    </item>
    <item>
      <title>Understanding SGD with Exponential Moving Average: A Case Study in Linear Regression</title>
      <link>https://arxiv.org/abs/2502.14123</link>
      <description>arXiv:2502.14123v1 Announce Type: cross 
Abstract: Exponential moving average (EMA) has recently gained significant popularity in training modern deep learning models, especially diffusion-based generative models. However, there have been few theoretical results explaining the effectiveness of EMA. In this paper, to better understand EMA, we establish the risk bound of online SGD with EMA for high-dimensional linear regression, one of the simplest overparameterized learning tasks that shares similarities with neural networks. Our results indicate that (i) the variance error of SGD with EMA is always smaller than that of SGD without averaging, and (ii) unlike SGD with iterate averaging from the beginning, the bias error of SGD with EMA decays exponentially in every eigen-subspace of the data covariance matrix. Additionally, we develop proof techniques applicable to the analysis of a broad class of averaging schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14123v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuheng Li, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>A Non-Asymptotic Theory of Seminorm Lyapunov Stability: From Deterministic to Stochastic Iterative Algorithms</title>
      <link>https://arxiv.org/abs/2502.14208</link>
      <description>arXiv:2502.14208v1 Announce Type: cross 
Abstract: We study the problem of solving fixed-point equations for seminorm-contractive operators and establish foundational results on the non-asymptotic behavior of iterative algorithms in both deterministic and stochastic settings. Specifically, in the deterministic setting, we prove a fixed-point theorem for seminorm-contractive operators, showing that iterates converge geometrically to the kernel of the seminorm. In the stochastic setting, we analyze the corresponding stochastic approximation (SA) algorithm under seminorm-contractive operators and Markovian noise, providing a finite-sample analysis for various stepsize choices.
  A benchmark for equation solving is linear systems of equations, where the convergence behavior of fixed-point iteration is closely tied to the stability of linear dynamical systems. In this special case, our results provide a complete characterization of system stability with respect to a seminorm, linking it to the solution of a Lyapunov equation in terms of positive semi-definite matrices. In the stochastic setting, we establish a finite-sample analysis for linear Markovian SA without requiring the Hurwitzness assumption.
  Our theoretical results offer a unified framework for deriving finite-sample bounds for various reinforcement learning algorithms in the average reward setting, including TD($\lambda$) for policy evaluation (which is a special case of solving a Poisson equation) and Q-learning for control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14208v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zaiwei Chen, Sheng Zhang, Zhe Zhang, Shaan Ul Haque, Siva Theja Maguluri</dc:creator>
    </item>
    <item>
      <title>Variance Reduction Methods Do Not Need to Compute Full Gradients: Improved Efficiency through Shuffling</title>
      <link>https://arxiv.org/abs/2502.14648</link>
      <description>arXiv:2502.14648v1 Announce Type: cross 
Abstract: In today's world, machine learning is hard to imagine without large training datasets and models. This has led to the use of stochastic methods for training, such as stochastic gradient descent (SGD). SGD provides weak theoretical guarantees of convergence, but there are modifications, such as Stochastic Variance Reduced Gradient (SVRG) and StochAstic Recursive grAdient algoritHm (SARAH), that can reduce the variance. These methods require the computation of the full gradient occasionally, which can be time consuming. In this paper, we explore variants of variance reduction algorithms that eliminate the need for full gradient computations. To make our approach memory-efficient and avoid full gradient computations, we use two key techniques: the shuffling heuristic and idea of SAG/SAGA methods. As a result, we improve existing estimates for variance reduction algorithms without the full gradient computations. Additionally, for the non-convex objective function, our estimate matches that of classic shuffling methods, while for the strongly convex one, it is an improvement. We conduct comprehensive theoretical analysis and provide extensive experimental results to validate the efficiency and practicality of our methods for large-scale machine learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14648v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Gleb Molodtsov, Savelii Chezhegov, Alexey Rebrikov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Robust Information Selection for Hypothesis Testing with Misclassification Penalties</title>
      <link>https://arxiv.org/abs/2502.14738</link>
      <description>arXiv:2502.14738v1 Announce Type: cross 
Abstract: We study the problem of robust information selection for a Bayesian hypothesis testing / classification task, where the goal is to identify the true state of the world from a finite set of hypotheses based on observations from the selected information sources. We introduce a novel misclassification penalty framework, which enables non-uniform treatment of different misclassification events. Extending the classical subset selection framework, we study the problem of selecting a subset of sources that minimize the maximum penalty of misclassification under a limited budget, despite deletions or failures of a subset of the selected sources. We characterize the curvature properties of the objective function and propose an efficient greedy algorithm with performance guarantees. Next, we highlight certain limitations of optimizing for the maximum penalty metric and propose a submodular surrogate metric to guide the selection of the information set. We propose a greedy algorithm with near-optimality guarantees for optimizing the surrogate metric. Finally, we empirically demonstrate the performance of our proposed algorithms in several instances of the information set selection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14738v1</guid>
      <category>stat.ML</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth Bhargav, Shreyas Sundaram, Mahsa Ghasemi</dc:creator>
    </item>
    <item>
      <title>EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</title>
      <link>https://arxiv.org/abs/2502.14760</link>
      <description>arXiv:2502.14760v1 Announce Type: cross 
Abstract: A fundamental problem in combinatorial optimization is identifying equivalent formulations, which can lead to more efficient solution strategies and deeper insights into a problem's computational complexity. The need to automatically identify equivalence between problem formulations has grown as optimization copilots--systems that generate problem formulations from natural language descriptions--have proliferated. However, existing approaches to checking formulation equivalence lack grounding, relying on simple heuristics which are insufficient for rigorous validation. Inspired by Karp reductions, in this work we introduce quasi-Karp equivalence, a formal criterion for determining when two optimization formulations are equivalent based on the existence of a mapping between their decision variables. We propose EquivaMap, a framework that leverages large language models to automatically discover such mappings, enabling scalable and reliable equivalence verification. To evaluate our approach, we construct the first open-source dataset of equivalent optimization formulations, generated by applying transformations such as adding slack variables or valid inequalities to existing formulations. Empirically, EquivaMap significantly outperforms existing methods, achieving substantial improvements in correctly identifying formulation equivalence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14760v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haotian Zhai, Connor Lawless, Ellen Vitercik, Liu Leqi</dc:creator>
    </item>
    <item>
      <title>Meshless Shape Optimization using Neural Networks and Partial Differential Equations on Graphs</title>
      <link>https://arxiv.org/abs/2502.14821</link>
      <description>arXiv:2502.14821v1 Announce Type: cross 
Abstract: Shape optimization involves the minimization of a cost function defined over a set of shapes, often governed by a partial differential equation (PDE). In the absence of closed-form solutions, one relies on numerical methods to approximate the solution. The level set method -- when coupled with the finite element method -- is one of the most versatile numerical shape optimization approaches but still suffers from the limitations of most mesh-based methods. In this work, we present a fully meshless level set framework that leverages neural networks to parameterize the level set function and employs the graph Laplacian to approximate the underlying PDE. Our approach enables precise computations of geometric quantities such as surface normals and curvature, and allows tackling optimization problems within the class of convex shapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14821v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Martinet, Leon Bungert</dc:creator>
    </item>
    <item>
      <title>Structural Stability Properties of Antithetic Integral (Rein) Control with Output Inhibition</title>
      <link>https://arxiv.org/abs/2201.13375</link>
      <description>arXiv:2201.13375v3 Announce Type: replace 
Abstract: Perfect adaptation is a well-studied biochemical homeostatic behavior lying at the core of biochemical regulation. While the concepts of homeostasis and perfect adaptation are not new, their underlying mechanisms and associated biochemical regulation motifs are not yet fully understood. Insights from control theory unraveled the connections between perfect adaptation and integral control, a prevalent engineering control strategy. In particular, the recently introduced Antithetic Integral Controller (AIC) has been shown to successfully ensure perfect adaptation properties to the network it is connected to. The complementary structure of the two molecules the AIC relies upon allows for a versatile way to control biochemical networks, a property which gave rise to an important body of literature pertaining to mathematically elucidating its properties, generalizing its structure, and developing experimental methods for its implementation. The Antithetic Integral Rein Controller (AIRC), an extension of the AIC in which both controller molecules are used for control, holds many promises as it supposedly overcomes certain limitations of the AIC. We focus here on an AIRC structure with output inhibition that combines two AICs in a single structure. We demonstrate that rhis controller ensure structural stability and structural perfect adaptation properties for the controlled network under mild assumptions, meaning that this property is independent of the parameters of the network and the controller. The results are very general and valid for the class of unimolecular mass-action networks as well as more general networks, including cooperative and Michaelis-Menten networks. We also provide a systematic and accessible computational way for verifying whether a given network satisfies the conditions under which the structural property would hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.13375v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.MN</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Corentin Briat, Mustafa Khammash</dc:creator>
    </item>
    <item>
      <title>A model-free first-order method for linear quadratic regulator with $\tilde{O}(1/\varepsilon)$ sampling complexity</title>
      <link>https://arxiv.org/abs/2212.00084</link>
      <description>arXiv:2212.00084v5 Announce Type: replace 
Abstract: We consider the classic stochastic linear quadratic regulator (LQR) problem under an infinite horizon average stage cost. By leveraging recent policy gradient methods from reinforcement learning, we obtain a first-order method that finds a stable feedback law whose objective function gap to the optima is at most $\varepsilon$ with high probability using $\tilde{O}(1/\varepsilon)$ samples, where $\tilde{O}$ hides polylogarithmic dependence on $\varepsilon$. Our proposed method seems to have the best dependence on $\varepsilon$ within the model-free literature without the assumption that all policies generated by the algorithm are stable almost surely, and it matches the best-known rate from the model-based literature, up to logarithmic factors. The improved dependence on $\varepsilon$ is achieved by showing the accuracy scales with the variance rather than the standard deviation of the gradient estimation error. Our developments that result in this improved sampling complexity fall in the category of actor-critic algorithms. The actor part involves a variational inequality formulation of the stochastic LQR problem, while in the critic part, we utilize a conditional stochastic primal-dual method and show that the algorithm has the optimal rate of convergence when paired with a shrinking multi-epoch scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00084v5</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Georgios Kotsalis, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Equilibrium transport with time-inconsistent costs: An application to matching problems in the job market</title>
      <link>https://arxiv.org/abs/2302.01498</link>
      <description>arXiv:2302.01498v5 Announce Type: replace 
Abstract: Given two probability measures on sequential data, we investigate the transport problem with time-inconsistent preferences in a discrete-time setting. Motivating examples are nonlinear objectives, state-dependent costs, and regularized optimal transport with general $f$-divergence. Under the bicausal constraint, we introduce the concept of equilibrium transport. Existence is proved in the semi-discrete Markovian case and the continuous non-Markovian case with strict quasiconvexity, while uniqueness also holds in the second case. We apply our framework to study inertia of two job markets, top-ranking executives and academia. The empirical analysis shows that a job market with stronger inertia is less efficient. The University of California (UC) postdoc job market has the strongest inertia even than that of executives, while there is no evidence of inertia in the UC faculty job market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01498v5</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Bingyan Han</dc:creator>
    </item>
    <item>
      <title>The Nonstationary Newsvendor with (and without) Predictions</title>
      <link>https://arxiv.org/abs/2305.07993</link>
      <description>arXiv:2305.07993v4 Announce Type: replace 
Abstract: The classic newsvendor model yields an optimal decision for a ``newsvendor'' selecting a quantity of inventory, under the assumption that the demand is drawn from a known distribution. Motivated by applications such as cloud provisioning and staffing, we consider a setting in which newsvendor-type decisions must be made sequentially, in the face of demand drawn from a stochastic process that is both unknown and nonstationary. All prior work on this problem either (a) assumes that the level of nonstationarity is known, or (b) imposes additional statistical assumptions that enable accurate predictions of the unknown demand. Our research tackles the Nonstationary Newsvendor without these assumptions, both with and without predictions.
  We first, in the setting without predictions, design a policy which we prove achieves order-optimal regret -- ours is the first policy to accomplish this without being given the level of nonstationarity of the underlying demand. We then, for the first time, introduce a model for generic (i.e. with no statistical assumptions) predictions with arbitrary accuracy, and propose a policy that incorporates these predictions without being given their accuracy. We upper bound the regret of this policy, and show that it matches the best achievable regret had the accuracy of the predictions been known.
  Our findings provide valuable insights on inventory management. Managers can make more informed and effective decisions in dynamic environments, reducing costs and enhancing service levels despite uncertain demand patterns. We empirically validate our new policy with experiments based on three real-world datasets containing thousands of time-series, showing that it succeeds in closing approximately 74% of the gap between the best approaches based on nonstationarity and predictions alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07993v4</guid>
      <category>math.OC</category>
      <category>econ.EM</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin An, Andrew A. Li, Benjamin Moseley, R. Ravi</dc:creator>
    </item>
    <item>
      <title>Equal area partitions of the sphere with diameter bounds, via optimal transport</title>
      <link>https://arxiv.org/abs/2306.16239</link>
      <description>arXiv:2306.16239v2 Announce Type: replace 
Abstract: We prove existence of equal area partitions of the unit sphere via optimal transport methods, accompanied by diameter bounds written in terms of Monge--Kantorovich distances. This can be used to obtain bounds on the expectation of the maximum diameter of partition sets, when points are uniformly sampled from the sphere. An application to the computation of sliced Monge--Kantorovich distances is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16239v2</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Kitagawa, Asuka Takatsu</dc:creator>
    </item>
    <item>
      <title>Stochastic Inertial Dynamics Via Time Scaling and Averaging</title>
      <link>https://arxiv.org/abs/2403.16775</link>
      <description>arXiv:2403.16775v2 Announce Type: replace 
Abstract: Our work is part of the close link between continuous-time dissipative dynamical systems and optimization algorithms, and more precisely here, in the stochastic setting. We aim to study stochastic convex minimization problems through the lens of stochastic inertial differential inclusions that are driven by the subgradient of a convex objective function. This will provide a general mathematical framework for analyzing the convergence properties of stochastic second-order inertial continuous-time dynamics involving vanishing viscous damping and measurable stochastic subgradient selections. Our chief goal in this paper is to develop a systematic and unified way that transfers the properties recently studied for first-order stochastic differential equations to second-order ones involving even subgradients in lieu of gradients. This program will rely on two tenets: time scaling and averaging, following an approach recently developed in the literature by one of the co-authors in the deterministic case.
  Under a mild integrability assumption involving the diffusion term and the viscous damping, our first main result shows that almost surely, there is weak convergence of the trajectory towards a minimizer of the objective function and fast convergence of the values and gradients. We also provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex, strongly convex, and (local) Polyak-Lojasiewicz case. Finally, using Tikhonov regularization with a properly tuned vanishing parameter, we can obtain almost sure strong convergence of the trajectory towards the minimum norm solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16775v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Continuous-Time Line-of-Sight Constrained Trajectory Planning for 6-Degree of Freedom Systems</title>
      <link>https://arxiv.org/abs/2410.22596</link>
      <description>arXiv:2410.22596v2 Announce Type: replace 
Abstract: Perception algorithms are ubiquitous in modern autonomy stacks, providing necessary environmental information to operate in the real world. Many of these algorithms depend on the visibility of keypoints, which must remain within the robot's line-of-sight (LoS), for reliable operation. This paper tackles the challenge of maintaining LoS on such keypoints during robot movement. We propose a novel method that addresses these issues by ensuring applicability to various sensor footprints, adaptability to arbitrary nonlinear system dynamics, and constant enforcement of LoS throughout the robot's path. Our experiments show that the proposed approach achieves significantly reduced LoS violation and runtime compared to existing state-of-the-art methods in several representative and challenging scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22596v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher R. Hayner, John M. Carson III, Beh\c{c}et A\c{c}{\i}kme\c{s}e, Karen Leung</dc:creator>
    </item>
    <item>
      <title>Relax-and-round strategies for solving the Unit Commitment problem with AC Power Flow constraints</title>
      <link>https://arxiv.org/abs/2501.11355</link>
      <description>arXiv:2501.11355v2 Announce Type: replace 
Abstract: The Unit Commitment problem with AC power flow constraints (UC-ACOPF) is a non-convex mixed-integer nonlinear programming (MINLP) problem encountered in power systems. Its combination of combinatorial complexity and non-convex nonlinear constraints makes it particularly challenging. A common approach to tackle this issue is to relax the integrality condition, but this often results in infeasible solutions. Consequently, rounding heuristics are frequently employed to restore integer feasibility. This paper addresses recent advancements in heuristics aimed at quickly obtaining feasible solutions for the UC-ACOPF problem, focusing specifically on direct relax-and-round strategies. We propose a model-based heuristic that rescales the solution of the integer-relaxed problem before rounding. Furthermore, we introduce rounding formulas designed to enforce combinatorial constraints and aim to maintain AC feasibility in the resulting solutions. These methodologies are compared against standard direct rounding techniques in the literature, applied to a 6-bus and a 118-bus test systems. Additionally, we integrate the proposed heuristics into an implementation of the Feasibility Pump (FP) method, demonstrating their utility and potential to enhance existing rounding strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11355v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>D. G\'omez, S. G\"ottlich, A. R\'ios, P. Salgado</dc:creator>
    </item>
    <item>
      <title>Efficient Sparse Flow Decomposition Methods for RNA Multi-Assembly</title>
      <link>https://arxiv.org/abs/2501.14662</link>
      <description>arXiv:2501.14662v2 Announce Type: replace 
Abstract: Decomposing a flow on a Directed Acyclic Graph (DAG) into a weighted sum of a small number of paths is an essential task in operations research and bioinformatics. This problem, referred to as Sparse Flow Decomposition (SFD), has gained significant interest, in particular for its application in RNA transcript multi-assembly, the identification of the multiple transcripts corresponding to a given gene and their relative abundance. Several recent approaches cast SFD variants as integer optimization problems, motivated by the NP-hardness of the formulations they consider. We propose an alternative formulation of SFD as a fitting problem on the conic hull of the flow polytope. By reformulating the problem on the flow polytope for compactness and solving it using specific variants of the Frank-Wolfe algorithm, we obtain a method converging rapidly to the minimizer of the chosen loss function while producing a parsimonious decomposition. Our approach subsumes previous formulations of SFD with exact and inexact flows and can model different priors on the error distributions. Computational experiments show that our method outperforms recent integer optimization approaches in runtime, but is also highly competitive in terms of reconstruction of the underlying transcripts, despite not explicitly minimizing the solution cardinality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14662v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Besan\c{c}on</dc:creator>
    </item>
    <item>
      <title>Compact Formulation of the First Evolution Equation for Optimal Control Computation</title>
      <link>https://arxiv.org/abs/1804.02980</link>
      <description>arXiv:1804.02980v2 Announce Type: replace-cross 
Abstract: The first evolution equation is derived under the Variation Evolving Method (VEM) that seeks optimal solutions with the variation evolution principle. To improve the performance, its compact form is developed. By replacing the states and costates variation evolution with that of the controls, the dimension-reduced Evolution Partial Differential Equation (EPDE) only solves the control variables along the variation time to get the optimal solution, and its definite conditions may be arbitrary. With this equation, the scale of the resulting Initial-value Problem (IVP), transformed via the semi-discrete method, is significantly reduced. Illustrative examples are solved and it is shown that the compact form evolution equation outperforms the primary form in the precision, and the efficiency may be higher for the dense discretization. Moreover, in discussing the connections to the classic iteration methods, it is uncovered that the computation scheme of the gradient method is the discrete implementation of the third evolution equation, and the compact form of the first evolution equation is a continuous realization of the Newton type iteration mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:1804.02980v2</guid>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Zhang, Fei Liao, Wei-Qi Qian</dc:creator>
    </item>
    <item>
      <title>Control Barrier Function based Attack-Recovery with Provable Guarantees</title>
      <link>https://arxiv.org/abs/2204.03077</link>
      <description>arXiv:2204.03077v2 Announce Type: replace-cross 
Abstract: This paper studies provable security guarantees for cyber-physical systems (CPS) under actuator attacks. In particular, we consider CPS safety and propose a new attack detection mechanism based on zeroing control barrier function (ZCBF) conditions. In addition, we design an adaptive recovery mechanism based on how close the system is to violating safety. We show that under certain conditions, the attack-detection mechanism is sound, i.e., there are no false negatives for adversarial attacks. We propose sufficient conditions for the initial conditions and input constraints so that the resulting CPS is secure by design. We also propose a novel hybrid control to account for attack detection delays and avoid Zeno behavior. Next, to efficiently compute the set of initial conditions, we propose a sampling-based method to verify whether a set is a viability domain. Specifically, we devise a method for checking a modified barrier function condition on a finite set of points to assess whether a set can be rendered forward invariant. Then, we propose an iterative algorithm to compute the set of initial conditions and input constraints set to limit the effect of an adversary if it compromises vulnerable inputs. Finally, we use a Quadratic Programming (QP) approach for online recovery (as well as nominal) control synthesis. We demonstrate the effectiveness of the proposed method in a simulation case study involving a quadrotor with an attack on its motors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.03077v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunal Garg, Ricardo G. Sanfelice, Alvaro A. Cardenas</dc:creator>
    </item>
    <item>
      <title>Hilbert's projective metric for functions of bounded growth and exponential convergence of Sinkhorn's algorithm</title>
      <link>https://arxiv.org/abs/2311.04041</link>
      <description>arXiv:2311.04041v3 Announce Type: replace-cross 
Abstract: Motivated by the entropic optimal transport problem in unbounded settings, we study versions of Hilbert's projective metric for spaces of integrable functions of bounded growth. These versions of Hilbert's metric originate from cones which are relaxations of the cone of all non-negative functions, in the sense that they include all functions having non-negative integral values when multiplied with certain test functions. We show that kernel integral operators are contractions with respect to suitable specifications of such metrics even for kernels which are not bounded away from zero, provided that the decay to zero of the kernel is controlled. As an application to entropic optimal transport, we show exponential convergence of Sinkhorn's algorithm in settings where the marginal distributions have sufficiently light tails compared to the growth of the cost function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04041v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephan Eckstein</dc:creator>
    </item>
    <item>
      <title>Efficiently Training Deep-Learning Parametric Policies using Lagrangian Duality</title>
      <link>https://arxiv.org/abs/2405.14973</link>
      <description>arXiv:2405.14973v2 Announce Type: replace-cross 
Abstract: Constrained Markov Decision Processes (CMDPs) are critical in many high-stakes applications, where decisions must optimize cumulative rewards while strictly adhering to complex nonlinear constraints. In domains such as power systems, finance, supply chains, and precision robotics, violating these constraints can result in significant financial or societal costs. Existing Reinforcement Learning (RL) methods often struggle with sample efficiency and effectiveness in finding feasible policies for highly and strictly constrained CMDPs, limiting their applicability in these environments. Stochastic dual dynamic programming is often used in practice on convex relaxations of the original problem, but they also encounter computational challenges and loss of optimality. This paper introduces a novel approach, Two-Stage Deep Decision Rules (TS-DDR), to efficiently train parametric actor policies using Lagrangian Duality. TS-DDR is a self-supervised learning algorithm that trains general decision rules (parametric policies) using stochastic gradient descent (SGD); its forward passes solve {\em deterministic} optimization problems to find feasible policies, and its backward passes leverage duality theory to train the parametric policy with closed-form gradients. TS-DDR inherits the flexibility and computational performance of deep learning methodologies to solve CMDP problems. Applied to the Long-Term Hydrothermal Dispatch (LTHD) problem using actual power system data from Bolivia, TS-DDR is shown to enhance solution quality and to reduce computation times by several orders of magnitude when compared to current state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14973v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrew Rosemberg, Alexandre Street, Davi M. Vallad\~ao, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification of Spectral Estimator and MLE for Orthogonal Group Synchronization</title>
      <link>https://arxiv.org/abs/2408.05944</link>
      <description>arXiv:2408.05944v2 Announce Type: replace-cross 
Abstract: Orthogonal group synchronization aims to recover orthogonal group elements from their noisy pairwise measurements. It has found numerous applications including computer vision, imaging science, and community detection. Due to the orthogonal constraints, it is often challenging to find the least squares estimator in presence of noise. In the recent years, semidefinite relaxation (SDR) and spectral methods have proven to be powerful tools in recovering the group elements. In particular, under additive Gaussian noise, the SDR exactly produces the maximum likelihood estimator (MLE), and both MLE and spectral methods are able to achieve near-optimal statistical error. In this work, we take one step further to quantify the uncertainty of the MLE and spectral estimators by considering their distributions. By leveraging the orthogonality constraints in the likelihood function, we obtain a second-order expansion of the MLE and spectral estimator with the leading terms as an anti-symmetric Gaussian random matrix that is on the tangent space of the orthogonal matrix. This also implies state-of-the-art min-max risk bounds and a confidence region of each group element as a by-product. Our works provide a general theoretical framework that is potentially useful to find an approximate distribution of the estimators arising from many statistical inference problems with manifold constraints. The numerical experiments confirm our theoretical contribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05944v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziliang Samuel Zhong, Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>Strongly-polynomial time and validation analysis of policy gradient methods</title>
      <link>https://arxiv.org/abs/2409.19437</link>
      <description>arXiv:2409.19437v4 Announce Type: replace-cross 
Abstract: This paper proposes a novel termination criterion, termed the advantage gap function, for finite state and action Markov decision processes (MDP) and reinforcement learning (RL). By incorporating this advantage gap function into the design of step size rules and deriving a new linear rate of convergence that is independent of the stationary state distribution of the optimal policy, we demonstrate that policy gradient methods can solve MDPs in strongly-polynomial time. To the best of our knowledge, this is the first time that such strong convergence properties have been established for policy gradient methods. Moreover, in the stochastic setting, where only stochastic estimates of policy gradients are available, we show that the advantage gap function provides close approximations of the optimality gap for each individual state and exhibits a sublinear rate of convergence at every state. The advantage gap function can be easily estimated in the stochastic case, and when coupled with easily computable upper bounds on policy values, they provide a convenient way to validate the solutions generated by policy gradient methods. Therefore, our developments offer a principled and computable measure of optimality for RL, whereas current practice tends to rely on algorithm-to-algorithm or baselines comparisons with no certificate of optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19437v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>How Does Critical Batch Size Scale in Pre-training?</title>
      <link>https://arxiv.org/abs/2410.21676</link>
      <description>arXiv:2410.21676v3 Announce Type: replace-cross 
Abstract: Training large-scale models under given resources requires careful design of parallelism strategies. In particular, the efficiency notion of critical batch size (CBS), concerning the compromise between time and compute, marks the threshold beyond which greater data parallelism leads to diminishing returns. To operationalize it, we propose a measure of CBS and pre-train a series of auto-regressive language models, ranging from 85 million to 1.2 billion parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and careful control of factors such as batch size, momentum, and learning rate along with its scheduling, we systematically investigate the impact of scale on CBS. Then we fit scaling laws with respect to model and data sizes to decouple their effects. Overall, our results demonstrate that CBS scales primarily with data size rather than model size, a finding we justify theoretically through the analysis of infinite-width limits of neural networks and infinite-dimensional least squares regression. Of independent interest, we highlight the importance of common hyper-parameter choices and strategies for studying large-scale pre-training beyond fixed training durations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21676v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade</dc:creator>
    </item>
    <item>
      <title>Rigidly breaking potential flows and a countable Alexandrov theorem for polytopes</title>
      <link>https://arxiv.org/abs/2411.05606</link>
      <description>arXiv:2411.05606v2 Announce Type: replace-cross 
Abstract: We study all the ways that a given convex body in $d$ dimensions can break into countably many pieces that move away from each other rigidly at constant velocity, with no rotation or shearing. The initial velocity field is locally constant, but may be continuous and/or fail to be integrable. For any choice of mass-velocity pairs for the pieces, such a motion can be generated by the gradient of a convex potential that is affine on each piece. We classify such potentials in terms of a countable version of a theorem of Alexandrov for convex polytopes, and prove a stability theorem. For bounded velocities, there is a bijection between the mass-velocity data and optimal transport flows (Wasserstein geodesics) that are locally incompressible.
  Given any rigidly breaking velocity field that is the gradient of a continuous potential, the convexity of the potential is established under any of several conditions, such as the velocity field being continuous, the potential being semi-convex, the mass measure generated by a convexified transport potential being absolutely continuous, or there being a finite number of pieces. Also we describe a number of curious and paradoxical examples having fractal structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05606v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian-Guo Liu, Robert L. Pego</dc:creator>
    </item>
    <item>
      <title>Optimizing quasi-dissipative evolution equations with the moment-SOS hierarchy</title>
      <link>https://arxiv.org/abs/2412.07361</link>
      <description>arXiv:2412.07361v2 Announce Type: replace-cross 
Abstract: We prove that there is no relaxation gap between a quasi-dissipative nonlinear evolution equation in a Hilbert space and its linear Liouville equation reformulation on probability measures. In other words, strong and generalized solutions of such equations are unique in the class of measure-valued solutions. As a major consequence, non-convex numerical optimization over these non-linear partial differential equations can be carried out with the infinite-dimensional moment-SOS hierarchy with global convergence guarantees. This covers in particular all reaction-diffusion equations with polynomial nonlinearity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07361v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saroj Prasad Chhatoi (LAAS-POP), Didier Henrion (LAAS-POP), Swann Marx (LS2N), Nicolas Seguin (IMAG, CRISAM)</dc:creator>
    </item>
    <item>
      <title>ID policy (with reassignment) is asymptotically optimal for heterogeneous weakly-coupled MDPs</title>
      <link>https://arxiv.org/abs/2502.06072</link>
      <description>arXiv:2502.06072v2 Announce Type: replace-cross 
Abstract: Heterogeneity poses a fundamental challenge for many real-world large-scale decision-making problems but remains largely understudied. In this paper, we study the fully heterogeneous setting of a prominent class of such problems, known as weakly-coupled Markov decision processes (WCMDPs). Each WCMDP consists of $N$ arms (or subproblems), which have distinct model parameters in the fully heterogeneous setting, leading to the curse of dimensionality when $N$ is large. We show that, under mild assumptions, a natural adaptation of the ID policy, although originally proposed for a homogeneous special case of WCMDPs, in fact achieves an $O(1/\sqrt{N})$ optimality gap in long-run average reward per arm for fully heterogeneous WCMDPs as $N$ becomes large. This is the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs. Our techniques highlight the construction of a novel projection-based Lyapunov function, which witnesses the convergence of rewards and costs to an optimal region in the presence of heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06072v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangcheng Zhang, Yige Hong, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Integrated Scheduling Model for Arrivals and Departures in Metroplex Terminal Area</title>
      <link>https://arxiv.org/abs/2502.12196</link>
      <description>arXiv:2502.12196v2 Announce Type: replace-cross 
Abstract: In light of the rapid expansion of civil aviation, addressing the delays and congestion phenomena in the vicinity of metroplex caused by the imbalance between air traffic flow and capacity is crucial. This paper first proposes a bi-level optimization model for the collaborative flight sequencing of arrival and departure flights in the metroplex with multiple airports, considering both the runway systems and TMA (Terminal Control Area) entry/exit fixes. Besides, the model is adaptive to various traffic scenarios. The genetic algorithm is employed to solve the proposed model. The Shanghai TMA, located in China, is used as a case study, and it includes two airports, Shanghai Hongqiao International Airport and Shanghai Pudong International Airport. The results demonstrate that the model can reduce arrival delay by 51.52%, departure delay by 18.05%, and the runway occupation time of departure flights by 23.83%. Furthermore, the model utilized in this study significantly enhances flight scheduling efficiency, providing a more efficient solution than the traditional FCFS (First Come, First Served) approach. Additionally, the algorithm employed offers further improvements over the NSGA II algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12196v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tonghe li, Jixin Liu, Hao Jiang, Weili Zeng, Lei Yang</dc:creator>
    </item>
  </channel>
</rss>
