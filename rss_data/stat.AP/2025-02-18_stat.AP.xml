<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>E-TRIALS: Empowering Data-Driven Decisions to Enhance Computer-Based Learning Platforms</title>
      <link>https://arxiv.org/abs/2502.10545</link>
      <description>arXiv:2502.10545v1 Announce Type: new 
Abstract: Computer-based learning platforms (CBLPs) have become a common medium in schools, transferring how students learn and interact with education content. A recent report by the Institute of Education Sciences revealed that 94\% of public schools now provide a computer for every student. The high percentage of students having their own computers highlights the need for researchers to investigate how students learn in CBLPs and identify instructional designs that can enhance their performance. In this paper, we introduce E-TRIALS, a tool by ASSISTments designed to conduct experiments and analyze student performance. Using data from three experiments, we propose a generalizable approach for analyzing experimental data and modeling results. We evaluate three Average Treatment Effect (ATE) estimators: Student's t-test $\hat{\tau}_{t-test}$, Ordinary Least Squares regression $\hat{\tau}_{OLS}$, and Leave-One-Out Potential outcomes (LOOP) $\hat{\tau}_{LOOP}$. Our approach can be used for future E-TRIALS experiments. Code used for this work is available at https://osf.io/xp6ch/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10545v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abubakir Siedahmed, Yanping Pei, Adam C Sales, Neil T Heffernan, Johann Gagnon-Bartsch</dc:creator>
    </item>
    <item>
      <title>A co-segmentation algorithm to predict emotional stress from passively sensed mHealth data</title>
      <link>https://arxiv.org/abs/2502.10558</link>
      <description>arXiv:2502.10558v1 Announce Type: new 
Abstract: We develop a data-driven co-segmentation algorithm of passively sensed and self-reported active variables collected through smartphones to identify emotionally stressful states in middle-aged and older patients with mood disorders undergoing therapy, some of whom also have chronic pain. Our method leverages the association between the different types of time series. These data are typically non-stationary, with meaningful associations often occurring only over short time windows. Traditional machine learning (ML) methods, when applied globally on the entire time series, often fail to capture these time-varying local patterns. Our approach first segments the passive sensing variables by detecting their change points, then examines segment-specific associations with the active variable to identify co-segmented periods that exhibit distinct relationships between stress and passively sensed measures. We then use these periods to predict future emotional stress states using standard ML methods. By shifting the unit of analysis from individual time points to data-driven segments of time and allowing for different associations in different segments, our algorithm helps detect patterns that only exist within short-time windows. We apply our method to detect periods of stress in patient data collected during ALACRITY Phase I study. Our findings indicate that the data-driven segmentation algorithm identifies stress periods more accurately than traditional ML methods that do not incorporate segmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10558v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Younghoon Kim, Sumanta Basu, Samprit Banerjee</dc:creator>
    </item>
    <item>
      <title>Modelling and short-term forecasting of seasonal mortality</title>
      <link>https://arxiv.org/abs/2502.10787</link>
      <description>arXiv:2502.10787v1 Announce Type: new 
Abstract: Excess mortality, i.e. the difference between expected and observed mortality, is used to quantify the death toll of mortality shocks, such as infectious disease-related epidemics and pandemics. However, predictions of expected mortality are sensitive to model assumptions. Among three specifications of a Serfling-Poisson regression for seasonal mortality, we analyse which one yields the most accurate predictions. We compare the Serfling-Poisson models with: 1) parametric effect for the trend and seasonality (SP), 2) non-parametric effect for the trend and seasonality (SP-STSS), also known as modulation model, and 3) non-parametric effect for the trend and parametric effect for the seasonality (SP-STFS). Forecasting is achieved with P-splines smoothing. The SP-STFS model resulted in more accurate historical forecasts of monthly rates from national statistical offices in 25 European countries. An application to the COVID-19 pandemic years illustrates how excess mortality can be used to evaluate the vulnerability of populations and aid public health planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10787v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ainhoa-Elena Leger, Silvia Rizzi, Ugofilippo Basellini</dc:creator>
    </item>
    <item>
      <title>Advances in Bayesian Modeling: Applications and Methods</title>
      <link>https://arxiv.org/abs/2502.11321</link>
      <description>arXiv:2502.11321v1 Announce Type: new 
Abstract: This paper explores the versatility and depth of Bayesian modeling by presenting a comprehensive range of applications and methods, combining Markov chain Monte Carlo (MCMC) techniques and variational approximations. Covering topics such as hierarchical modeling, spatial modeling, higher-order Markov chains, and Bayesian nonparametrics, the study emphasizes practical implementations across diverse fields, including oceanography, climatology, epidemiology, astronomy, and financial analysis. The aim is to bridge theoretical underpinnings with real-world applications, illustrating the formulation of Bayesian models, elicitation of priors, computational strategies, and posterior and predictive analyses. By leveraging different computational methods, this paper provides insights into model fitting, goodness-of-fit evaluation, and predictive accuracy, addressing computational efficiency and methodological challenges across various datasets and domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11321v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifei Yan, Juan Sosa, Carlos A. Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Comparison of Offset and Ratio Weighted Regressions in Tweedie Models with Application to Mid-Term Cancellations</title>
      <link>https://arxiv.org/abs/2502.11788</link>
      <description>arXiv:2502.11788v1 Announce Type: new 
Abstract: In property and casualty insurance, particularly in automobile insurance, risk exposure is traditionally associated with the coverage duration. However, factors such as early contract cancellations demand more precise modelling to ensure accurate premium pricing. This study introduces and compares two approaches for modelling total claims (or loss costs) in insurance portfolios with a high proportion of policies that have partial year exposure: the offset and ratio methods. We demonstrate that both approaches can be viewed as weighted regressions under the Tweedie distribution framework. Through an analysis based on the financial balance property, we find that the ratio approach outperforms the offset method. This comparison is illustrated using an automobile insurance portfolio, where a significant share of policyholders terminate their contracts before the coverage period concludes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11788v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boucher Jean-Philippe, Coulibaly Ra\"issa</dc:creator>
    </item>
    <item>
      <title>A Diagnostic to Find and Help Combat Positivity Issues - with a Focus on Continuous Treatments</title>
      <link>https://arxiv.org/abs/2502.11820</link>
      <description>arXiv:2502.11820v1 Announce Type: new 
Abstract: The positivity assumption is central in the identification of a causal effect, yet is rarely discussed, especially in conjunction with continuous treatments or Modified Treatment Policies. One common recommendation for dealing with a violation is to change the estimand. However, an applied researcher is faced with two problems: First, how can she tell whether there is a positivity violation given her estimand of interest, preferably without having to estimate a model first? Second, if she finds a problem with positivity, how should she change her estimand in order to arrive at an estimand which does not face the same issues? We suggest a novel diagnostic which allows the researcher to answer both questions by providing insights into how well an estimation for a certain estimand can be made for each observation using the data at hand. We provide a simulation study on the general behaviour of different MTPs at different levels of positivity violations and show how the diagnostic helps understand where bias is to be expected. We illustrate the application of our proposed diagnostic in a pharmacoepidemiological study based on data from CHAPAS-3, a trial comparing different treatment regimens for children living with HIV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11820v1</guid>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katharina Ring, Michael Schomaker</dc:creator>
    </item>
    <item>
      <title>Energy load forecasting using Terna public data: a free lunch multi-task combination approach</title>
      <link>https://arxiv.org/abs/2502.11873</link>
      <description>arXiv:2502.11873v1 Announce Type: new 
Abstract: We propose a quick-and-simple procedure to augment the accuracy of 15-minutes Italian load forecasts disaggregated by bidding zones published by Terna, the operator of the Italian electricity system. We show that a stacked-regression multi-task combination approach using Terna and daily random walk naive forecasts, is able to produce significantly more accurate forecasts immediately after Terna publishes on its data portal the energy load measurements for the previous day, and the forecasts for the current day.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11873v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Girolimetto, Tommaso Di Fonzo</dc:creator>
    </item>
    <item>
      <title>Forecasting Italian daily electricity generation disaggregated by geographical zones and energy sources using coherent forecast combination</title>
      <link>https://arxiv.org/abs/2502.11878</link>
      <description>arXiv:2502.11878v1 Announce Type: new 
Abstract: A novel approach is applied for improving forecast accuracy and achieving coherence in forecasting the Italian daily energy generation time series. In hierarchical frameworks such as national energy generation disaggregated by geographical zones and energy sources, independently generated base forecasts often result in inconsistencies across the constraints. We deal with this issue through a coherent balanced multi-task forecast combination approach, which combines unbiased forecasts from multiple experts while ensuring coherence. Applied to the daily Italian electricity generation data, our method shows superior accuracy compared to single-task base and combined forecasts, and a state-of-the-art single-expert reconciliation technique, demonstrating to be an effective approach to forecasting linearly constrained multiple time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11878v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Girolimetto, Tommaso Di Fonzo</dc:creator>
    </item>
    <item>
      <title>Seamless short- to mid-term probabilistic wind power forecasting</title>
      <link>https://arxiv.org/abs/2502.11960</link>
      <description>arXiv:2502.11960v1 Announce Type: new 
Abstract: This paper presents a method for probabilistic wind power forecasting that quantifies and integrates uncertainties from weather forecasts and weather-to-power conversion. By addressing both uncertainty sources, the method achieves state-of-the-art results for lead times of 6 to 162 hours, eliminating the need for separate models for short- and mid-term forecasting. It also improves short-term forecasts during high weather uncertainty periods, which methods based on deterministic weather forecasts fail to capture. The study reveals that weather-to-power uncertainty is more significant for short-term forecasts, while weather forecast uncertainty dominates mid-term forecasts, with the transition point varying between wind farms. Offshore farms typically see this shift at shorter lead times than onshore ones. The findings are supported by an extensive, reproducible case study comprising 73 wind farms in Great Britain over five years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11960v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Dantas, Jethro Browell</dc:creator>
    </item>
    <item>
      <title>Crime in Proportions: Applying Compositional Data Analysis to European Crime Trends for 2022</title>
      <link>https://arxiv.org/abs/2502.12099</link>
      <description>arXiv:2502.12099v1 Announce Type: new 
Abstract: This article investigates crime patterns across European countries in 2022 using Compositional Data Analysis (CoDA) to address limitations of traditional statistical approaches in dealing with the relative nature of crime data. Recognizing crime types as components of a whole, we employ CoDA to explore relationships between different crime categories while respecting their inherent interdependencies. The study utilizes k-means clustering to group countries based on their crime profiles, identifying three distinct clusters largely aligning with geographical locations. This clustering is visualized through t-SNE and geographic mapping, revealing regional similarities. Further analysis using Robust Principal Component Analysis on identified crime clusters reveals insightful relationships between specific crime types, such as homicide, smuggling, and financial crimes, and how their prevalence varies across countries. The findings reveals distinct crime patterns across Europe, highlighting regional commonalities while also highlighting divergences like Norway and Latvia that deviate from their expected geographical classifications. Moreover, the study identifies specific crime groups; for example, it pairs countries high in corruption and smuggling, such as Austria, with those countries that exhibit a higher relevance to homicide and smuggling, such as Luxembourg. It also points to the presence of financial crimes like fraud in countries such as Romania and Estonia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12099v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Onur Bat{\i}n Do\u{g}an, Fatma Sevin\c{c} Kurnaz</dc:creator>
    </item>
    <item>
      <title>Spatial modeling of mental health on outpatient morbidity in Kenya</title>
      <link>https://arxiv.org/abs/2502.10402</link>
      <description>arXiv:2502.10402v1 Announce Type: cross 
Abstract: A mental health disorder is a clinically significant impairment in a persons intellect, emotional control, or behavior. Mental disorders and outpatient morbidity are a challenge to public health in Kenya. The spatial distribution and study of factors associated with these conditions remain limited. The study aimed to conduct spatial modeling of mental health on outpatient mobility in Kenya. This project used spatial modeling to explore the relationship between infectious diseases and mental disorders. The results showed that mental health issues were not distributed uniformly, with higher frequency found in Western and Nairobi regions. Possible connections between HIV, TB, and STIs with mental health have been suggested by the substantial correlation found between infectious diseases and mental health issues. The spatial model demonstrated excellent validity and accuracy, providing policymakers with a useful tool to better allocate resources and enhance mental health treatments, especially in high-risk locations. In conclusion, the research improved knowledge of the spatial patterns of mental health disorders and guides intervention tactics and healthcare policies in Kenya and other comparable settings. Geographically tailored mental health intervention programs should be developed and implemented in accordance with the high-prevalence areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10402v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ndegwa Ruth wambui, Mwalili Samuel, Wamwea Charity</dc:creator>
    </item>
    <item>
      <title>Crop Yield Time-Series Data Prediction Based on Multiple Hybrid Machine Learning Models</title>
      <link>https://arxiv.org/abs/2502.10405</link>
      <description>arXiv:2502.10405v1 Announce Type: cross 
Abstract: Agriculture plays a crucial role in the global economy and social stability, and accurate crop yield prediction is essential for rational planting planning and decision-making. This study focuses on crop yield Time-Series Data prediction. Considering the crucial significance of agriculture in the global economy and social stability and the importance of accurate crop yield prediction for rational planting planning and decision-making, this research uses a dataset containing multiple crops, multiple regions, and data over many years to deeply explore the relationships between climatic factors (average rainfall, average temperature) and agricultural inputs (pesticide usage) and crop yield. Multiple hybrid machine learning models such as Linear Regression, Random Forest, Gradient Boost, XGBoost, KNN, Decision Tree, and Bagging Regressor are adopted for yield prediction. After evaluation, it is found that the Random Forest and Bagging Regressor models perform excellently in predicting crop yield with high accuracy and low error.As agricultural data becomes increasingly rich and time-series prediction techniques continue to evolve, the results of this study contribute to advancing the practical application of crop yield prediction in agricultural production management. The integration of time-series analysis allows for more dynamic, data-driven decision-making, enhancing the accuracy and reliability of crop yield forecasts over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10405v1</guid>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueru Yan, Yue Wang, Jialin Li, Jingwei Zhang, Xingye Mo</dc:creator>
    </item>
    <item>
      <title>Data Science Students Perspectives on Learning Analytics: An Application of Human-Led and LLM Content Analysis</title>
      <link>https://arxiv.org/abs/2502.10409</link>
      <description>arXiv:2502.10409v1 Announce Type: cross 
Abstract: Objective This study is part of a series of initiatives at a UK university designed to cultivate a deep understanding of students' perspectives on analytics that resonate with their unique learning needs. It explores collaborative data processing undertaken by postgraduate students who examined an Open University Learning Analytics Dataset (OULAD).
  Methods A qualitative approach was adopted, integrating a Retrieval-Augmented Generation (RAG) and a Large Language Model (LLM) technique with human-led content analysis to gather information about students' perspectives based on their submitted work. The study involved 72 postgraduate students in 12 groups.
  Findings The analysis of group work revealed diverse insights into essential learning analytics from the students' perspectives. All groups adopted a structured data science methodology. The questions formulated by the groups were categorised into seven themes, reflecting their specific areas of interest. While there was variation in the selected variables to interpret correlations, a consensus was found regarding the general results.
  Conclusion A significant outcome of this study is that students specialising in data science exhibited a deeper understanding of learning analytics, effectively articulating their interests through inferences drawn from their analyses. While human-led content analysis provided a general understanding of students' perspectives, the LLM offered nuanced insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10409v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghda Zahran, Jianfei Xu, Huizhi Liang, Matthew Forshaw</dc:creator>
    </item>
    <item>
      <title>Forecasting time series with constraints</title>
      <link>https://arxiv.org/abs/2502.10485</link>
      <description>arXiv:2502.10485v1 Announce Type: cross 
Abstract: Time series forecasting presents unique challenges that limit the effectiveness of traditional machine learning algorithms. To address these limitations, various approaches have incorporated linear constraints into learning algorithms, such as generalized additive models and hierarchical forecasting. In this paper, we propose a unified framework for integrating and combining linear constraints in time series forecasting. Within this framework, we show that the exact minimizer of the constrained empirical risk can be computed efficiently using linear algebra alone. This approach allows for highly scalable implementations optimized for GPUs. We validate the proposed methodology through extensive benchmarking on real-world tasks, including electricity demand forecasting and tourism forecasting, achieving state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10485v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Doum\`eche (LPSM, EDF R&amp;D OSIRIS), Francis Bach (DI-ENS, SIERRA), \'Eloi Bedek (EDF R&amp;D OSIRIS), G\'erard Biau (LPSM, IUF), Claire Boyer (LMO, IUF), Yannig Goude (EDF R&amp;D OSIRIS, LMO)</dc:creator>
    </item>
    <item>
      <title>Generative Adversarial Networks for High-Dimensional Item Factor Analysis: A Deep Adversarial Learning Algorithm</title>
      <link>https://arxiv.org/abs/2502.10650</link>
      <description>arXiv:2502.10650v1 Announce Type: cross 
Abstract: Advances in deep learning and representation learning have transformed item factor analysis (IFA) in the item response theory (IRT) literature by enabling more efficient and accurate parameter estimation. Variational Autoencoders (VAEs) have been one of the most impactful techniques in modeling high-dimensional latent variables in this context. However, the limited expressiveness of the inference model based on traditional VAEs can still hinder the estimation performance. This study introduces Adversarial Variational Bayes (AVB) algorithms as an improvement to VAEs for IFA with improved flexibility and accuracy. By bridging the strengths of VAEs and Generative Adversarial Networks (GANs), AVB incorporates an auxiliary discriminator network to reframe the estimation process as a two-player adversarial game and removes the restrictive assumption of standard normal distributions in the inference model. Theoretically, AVB can achieve similar or higher likelihood compared to VAEs. A further enhanced algorithm, Importance-weighted Adversarial Variational Bayes (IWAVB) is proposed and compared with Importance-weighted Autoencoders (IWAE). In an exploratory analysis of real empirical data, IWAVB demonstrated superior expressiveness by achieving a higher likelihood compared to IWAE. In confirmatory studies with simulated data, IWAVB achieved similar mean-square error results to IWAE while consistently achieving higher likelihoods. Moreover, in simulations where latent variables followed a multimodal distribution, IWAVB outperformed IWAE by providing more accurate parameter estimates. With its innovative use of GANs, IWAVB is shown to have the potential to extend IFA to handle large-scale data, facilitating the potential integration of psychometrics and multimodal data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10650v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanyu Luo, Feng Ji</dc:creator>
    </item>
    <item>
      <title>Robust Estimation of Item Parameters via Divergence Measures in Item Response Theory</title>
      <link>https://arxiv.org/abs/2502.10741</link>
      <description>arXiv:2502.10741v1 Announce Type: cross 
Abstract: Marginal maximum likelihood estimation (MMLE) in item response theory (IRT) is highly sensitive to aberrant responses, such as careless answering and random guessing, which can reduce estimation accuracy. To address this issue, this study introduces robust estimation methods for item parameters in IRT. Instead of empirically minimizing Kullback--Leibler divergence as in MMLE, the proposed approach minimizes the objective functions based on robust divergences, specifically density power divergence and {\gamma}-divergence. The resulting estimators are statistically consistent and asymptotically normal under appropriate regularity conditions. Furthermore, they offer a flexible trade-off between robustness and efficiency through hyperparameter tuning, forming a generalized estimation framework encompassing MMLE as a special case. To evaluate the effectiveness of the proposed methods, we conducted simulation experiments under various conditions, including scenarios with aberrant responses. The results demonstrated that the proposed methods surpassed existing ones in performance across various conditions. Moreover, numerical analysis of influence functions verified that increasing the hyperparameters effectively suppressed the impact of responses with low occurrence probabilities, which are potentially aberrant. These findings highlight that the proposed approach offers a robust alternative to MMLE, significantly enhancing measurement accuracy in testing and survey contexts prone to aberrant responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10741v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Itaya, Kenichi Hayashi</dc:creator>
    </item>
    <item>
      <title>Regression Modeling of the Count Relational Data with Exchangeable Dependencies</title>
      <link>https://arxiv.org/abs/2502.11255</link>
      <description>arXiv:2502.11255v1 Announce Type: cross 
Abstract: Relational data characterized by directed edges with count measurements are common in social science. Most existing methods either assume the count edges are derived from continuous random variables or model the edge dependency by parametric distributions. In this paper, we develop a latent multiplicative Poisson model for relational data with count edges. Our approach directly models the edge dependency of count data by the pairwise dependence of latent errors, which are assumed to be weakly exchangeable. This assumption not only covers a variety of common network effects, but also leads to a concise representation of the error covariance. In addition, the identification and inference of the mean structure, as well as the regression coefficients, depend on the errors only through their covariance. Such a formulation provides substantial flexibility for our model. Based on this, we propose a pseudo-likelihood based estimator for the regression coefficients, demonstrating its consistency and asymptotic normality. The newly suggested method is applied to a food-sharing network, revealing interesting network effects in gift exchange behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11255v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqin Du, Bailey K. Fosdick, Wen Zhou</dc:creator>
    </item>
    <item>
      <title>Stochastic Block Covariance Matrix Estimation</title>
      <link>https://arxiv.org/abs/2502.11332</link>
      <description>arXiv:2502.11332v1 Announce Type: cross 
Abstract: Motivated by a neuroscience application we study the problem of statistical estimation of a high-dimensional covariance matrix with a block structure. The block model embeds a structural assumption: the population of items (neurons) can be divided into latent sub-populations with shared associative covariation within blocks and shared associative or dis-associative covariation across blocks. Unlike the block diagonal assumption, our block structure incorporates positive or negative pairwise correlation between blocks. In addition to offering reasonable modeling choices in neuroscience and economics, the block covariance matrix assumption is interesting purely from the perspective of statistical estimation theory: (a) it offers in-built dimension reduction and (b) it resembles a regularized factor model without the need of choosing the number of factors. We discuss a hierarchical Bayesian estimation method to simultaneously recover the latent blocks and estimate the overall covariance matrix. We show with numerical experiments that a hierarchical structure and a shrinkage prior are essential to accurate recovery when several blocks are present.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11332v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunran Chen, Surya T Tokdar, Jennifer M Groh</dc:creator>
    </item>
    <item>
      <title>Searching for Low-Mass Exoplanets Amid Stellar Variability with a Fixed Effects Linear Model of Line-by-Line Shape Changes</title>
      <link>https://arxiv.org/abs/2502.11930</link>
      <description>arXiv:2502.11930v1 Announce Type: cross 
Abstract: The radial velocity (RV) method, also known as Doppler spectroscopy, is a powerful technique for exoplanet discovery and characterization. In recent years, progress has been made thanks to the improvements in the quality of spectra from new extreme precision RV spectrometers. However, detecting the RV signals of Earth-like exoplanets remains challenging, as the spectroscopic signatures of low-mass planets can be obscured or confused with intrinsic stellar variability. Changes in the shapes of spectral lines across time can provide valuable information for disentangling stellar activity from true Doppler shifts caused by low-mass exoplanets. In this work, we present a fixed effects linear model to estimate RV signals that controls for changes in line shapes by aggregating information from hundreds of spectral lines. Our methodology incorporates a wild-bootstrap approach for modeling uncertainty and cross-validation to control for overfitting. We evaluate the model's ability to remove stellar activity using solar observations from the NEID spectrograph, as the sun's true center-of-mass motion is precisely known. Including line shape-change covariates reduces the RV root-mean-square errors by approximately 70% (from 1.919 m s$^{-1}$ to 0.575 m s$^{-1}$) relative to using only the line-by-line Doppler shifts. The magnitude of the residuals is significantly less than that from traditional CCF-based RV estimators and comparable to other state-of-the-art methods for mitigating stellar variability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11930v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joseph Salzer, Jessi Cisewski-Kehe, Eric B. Ford, Lily L. Zhao</dc:creator>
    </item>
    <item>
      <title>On a Semiparametric Stochastic Volatility Model</title>
      <link>https://arxiv.org/abs/2502.11954</link>
      <description>arXiv:2502.11954v1 Announce Type: cross 
Abstract: This paper presents a novel approach to stochastic volatility (SV) modeling by utilizing nonparametric techniques that enhance our ability to capture the volatility of financial time series data, with a particular emphasis on the non-Gaussian behavior of asset return distributions. Although traditional parametric SV models can be useful, they often suffer from restrictive assumptions regarding errors, which may inadequately represent extreme values and tail behavior in financial returns. To address these limitations, we propose two semiparametric SV models that use data to better approximate error distributions. To facilitate the computation of model parameters, we developed a Markov Chain Monte Carlo (MCMC) method for estimating model parameters and volatility dynamics. Simulations and empirical tests on S&amp;P 500 data indicate that nonparametric models can minimize bias and variance in volatility estimation, providing a more accurate reflection of market expectations about volatility. This methodology serves as a promising alternative to conventional parametric models, improving precision in financial risk assessment and deepening our understanding of the volatility dynamics of financial returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11954v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Feng, Ashis Gangopadhyay</dc:creator>
    </item>
    <item>
      <title>Analytic models for active shooter incidents with civilian resistance</title>
      <link>https://arxiv.org/abs/2310.17111</link>
      <description>arXiv:2310.17111v2 Announce Type: replace 
Abstract: The number of active shooter incidents in the US has been increasing alarmingly. It is imperative for the government as well as the public to understand these events. Though both analytic and agent-based models have been proposed for studying active shooter incidents, there are only a few analytic models in the literature, and none incorporate civilian resistance. This article analytically investigates the survival probability of a civilian during an active shooter incident when he can hide, fight, or run, depending on whether or not he is in a closed arena and whether or not he is armed. The key findings are (i) the civilian's chance of survival decreases over time, irrespective of his action; (ii) there are desperate situations in which a civilian should fight back even if he is unarmed; (iii) carrying a firearm does not always increase the civilian's chance of survival during an active shooter incident; (iv) carrying a firearm makes "resistance" more likely to be the optimal action of the civilian; (v) "hide" might be the best action even if the civilian is armed; (vi) more armed civilians might increase a civilian's chance of survival, but it is not always the case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17111v2</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Hong</dc:creator>
    </item>
    <item>
      <title>Redistricting Reforms Reduce Gerrymandering by Constraining Partisan Actors</title>
      <link>https://arxiv.org/abs/2407.11336</link>
      <description>arXiv:2407.11336v2 Announce Type: replace 
Abstract: Political actors often manipulate redistricting plans to gain electoral advantages, a process known as gerrymandering. Several states have implemented institutional reforms to address this problem, such as establishing map-drawing commissions. Estimating the impact of such reforms is challenging because each state structures bundles of rules in different ways. We model redistricting as a sequential game, where each state's equilibrium solution summarizes multi-step institutional interactions as a single-dimensional score. We argue this score measures the leeway political actors have over the partisan lean of the final plan. Using a differences-in-differences design, we demonstrate that reforms reduce partisan bias and increase competitiveness when they constrain partisan actors. We perform a counterfactual policy analysis to estimate the effects of enacting recent reforms nationwide. Though commissions generally reduce bias, reforms that restrict partisan actors in multiple ways like removing veto points (Michigan) are much more effective than commissions where parties retain some control (Ohio).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11336v2</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cory McCartan, Christopher T. Kenny, Tyler Simko, Emma Ebowe, Michael Y. Zhao, Kosuke Imai</dc:creator>
    </item>
    <item>
      <title>Quantitative evaluation of unsupervised clustering algorithms for dynamic total-body PET image analysis</title>
      <link>https://arxiv.org/abs/2502.07511</link>
      <description>arXiv:2502.07511v2 Announce Type: replace 
Abstract: Background. Recently, dynamic total-body positron emission tomography (PET) imaging has become possible due to new scanner devices. While clustering algorithms have been proposed for PET analysis already earlier, there is still little research systematically evaluating these algorithms for processing of dynamic total-body PET images. Materials and methods. Here, we compare the performance of 15 unsupervised clustering methods, including K-means either by itself or after principal component analysis (PCA) or independent component analysis (ICA), Gaussian mixture model (GMM), fuzzy c-means (FCM), agglomerative clustering, spectral clustering, and several newer clustering algorithms, for classifying time activity curves (TACs) in dynamic PET images. We use dynamic total-body $^{15}$O-water PET images collected from 30 patients with suspected or confirmed coronary artery disease. To evaluate the clustering algorithms in a quantitative way, we use them to classify 5000 TACs from each image based on whether the curve is taken from brain, right heart ventricle, right kidney, lower right lung lobe, or urinary bladder. Results. According to our results, the best methods are GMM, FCM, and ICA combined with mini batch K-means, which classified the TACs with a median accuracies of 89\%, 83\%, and 81\%, respectively, in a processing time of half a second or less on average for each image. Conclusion. GMM, FCM, and ICA with mini batch K-means show promise for dynamic total-body PET analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07511v2</guid>
      <category>stat.AP</category>
      <category>cs.CV</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/03091902.2025.2466834</arxiv:DOI>
      <dc:creator>Oona Rainio, Maria K. Jaakkola, Riku Kl\'en</dc:creator>
    </item>
    <item>
      <title>Factor copula models for non-Gaussian longitudinal data</title>
      <link>https://arxiv.org/abs/2402.00668</link>
      <description>arXiv:2402.00668v3 Announce Type: replace-cross 
Abstract: This article presents factor copula approaches to model temporal dependency of non-Gaussian (continuous/discrete) longitudinal data. Factor copula models are canonical vine copulas which explain the underlying dependence structure of a multivariate data through latent variables, and therefore can be easily interpreted and implemented to unbalanced longitudinal data. We develop regression models for continuous, binary and ordinal longitudinal data including covariates, by using factor copula constructions with subject-specific latent variables. Considering homogeneous within-subject dependence, our proposed models allow for feasible parametric inference in moderate to high dimensional situations, using two-stage (IFM) estimation method. We assess the finite sample performance of the proposed models with extensive simulation studies. In the empirical analysis, the proposed models are applied for analysing different longitudinal responses of two real world data sets. Moreover, we compare the performances of these models with some widely used random effect models using standard model selection techniques and find substantial improvements. Our studies suggest that factor copula models can be good alternatives to random effect models and can provide better insights to temporal dependency of longitudinal data of arbitrary nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00668v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subhajit Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation</title>
      <link>https://arxiv.org/abs/2402.12649</link>
      <description>arXiv:2402.12649v2 Announce Type: replace-cross 
Abstract: Standard benchmarks of bias and fairness in large language models (LLMs) measure the association between social attributes implied in user prompts and short LLM responses. In the commonly studied domain of gender-occupation bias, we test whether these benchmarks are robust to lengthening the LLM responses as a measure of Realistic Use and Tangible Effects (i.e., RUTEd evaluations). From the current literature, we adapt three standard bias metrics (neutrality, skew, and stereotype), and we develop analogous RUTEd evaluations from three contexts of real-world use: children's bedtime stories, user personas, and English language learning exercises. We find that standard bias metrics have no significant correlation with the more realistic bias metrics. For example, selecting the least biased model based on the standard "trick tests" coincides with selecting the least biased model as measured in more realistic use no more than random chance. We suggest that there is not yet evidence to justify standard benchmarks as reliable proxies of real-world biases, and we encourage further development of context-specific RUTEd evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12649v2</guid>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander D'Amour</dc:creator>
    </item>
    <item>
      <title>MM Algorithms for Statistical Estimation in Quantile Regression</title>
      <link>https://arxiv.org/abs/2407.12348</link>
      <description>arXiv:2407.12348v3 Announce Type: replace-cross 
Abstract: Quantile regression \parencite{Koenker1978} is a robust and practically useful way to efficiently model quantile varying correlation and predict varied response quantiles of interest. This article constructs and tests MM algorithms, which are simple to code and have been suggested superior to some other prominent quantile regression methods in nonregularized problems \parencite{Pietrosanu2017}, in an array of linear quantile regression settings. Simulation studies comparing MM to existing tested methods and applications to various real data sets have corroborated our algorithms' effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12348v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Cheng, Anthony Yung Cheung Kuk</dc:creator>
    </item>
    <item>
      <title>Functional Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2410.03619</link>
      <description>arXiv:2410.03619v4 Announce Type: replace-cross 
Abstract: Heterogeneous functional data commonly arise in time series and longitudinal studies. To uncover the statistical structures of such data, we propose Functional Singular Value Decomposition (FSVD), a unified framework encompassing various tasks for the analysis of functional data with potential heterogeneity. We establish the mathematical foundation of FSVD by proving its existence and providing its fundamental properties. We then develop an implementation approach for noisy and irregularly observed functional data based on a novel alternating minimization scheme and provide theoretical guarantees for its convergence and estimation accuracy. The FSVD framework also introduces the concepts of intrinsic basis functions and intrinsic basis vectors, representing two fundamental structural aspects of random functions. These concepts enable FSVD to provide new and improved solutions to tasks including functional principal component analysis, factor models, functional clustering, functional linear regression, and functional completion, while effectively handling heterogeneity and irregular temporal sampling. Through extensive simulations, we demonstrate that FSVD-based methods consistently outperform existing methods across these tasks. To showcase the value of FSVD in real-world datasets, we apply it to extract temporal patterns from a COVID-19 case count dataset and perform data completion on an electronic health record dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03619v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianbin Tan, Pixu Shi, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Trend-encoded Probabilistic Multi-order Model: A Non-Machine Learning Approach for Enhanced Stock Market Forecasts</title>
      <link>https://arxiv.org/abs/2502.08144</link>
      <description>arXiv:2502.08144v2 Announce Type: replace-cross 
Abstract: In recent years, the dominance of machine learning in stock market forecasting has been evident. While these models have shown decreasing prediction errors, their robustness across different datasets has been a concern. A successful stock market prediction model minimizes prediction errors and showcases robustness across various data sets, indicating superior forecasting performance. This study introduces a novel multiple lag order probabilistic model based on trend encoding (TeMoP) that enhances stock market predictions through a probabilistic approach. Results across different stock indexes from nine countries demonstrate that the TeMoP outperforms the state-of-the-art machine learning models in predicting accuracy and stabilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08144v2</guid>
      <category>q-fin.CP</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peiwan Wang, Chenhao Cui, Yong Li</dc:creator>
    </item>
  </channel>
</rss>
