<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jan 2025 02:30:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Philip G. Wright, directed acyclic graphs, and instrumental variables</title>
      <link>https://arxiv.org/abs/2501.16395</link>
      <description>arXiv:2501.16395v1 Announce Type: new 
Abstract: Wright (1928) deals with demand and supply of oils and butter. In Appendix B of this book, Philip Wright made several fundamental contributions to causal inference. He introduced a structural equation model of supply and demand, established the identification of supply and demand elasticities via the method of moments and directed acyclical graphs, developed empirical methods for estimating demand elasticities using weather conditions as instruments, and proposed methods for counterfactual analysis of the welfare effect of imposing tariffs and taxes. Moreover, he took all of these methods to data. These ideas were far ahead, and much more profound than, any contemporary theoretical and empirical developments on causal inference in statistics or econometrics. This editorial aims to present P. Wright's work in a more modern framework, in a lecture note format that can be useful for teaching and linking to contemporary research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16395v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/ectj/utaf006</arxiv:DOI>
      <arxiv:journal_reference>The Econometrics Journal 28(1), (2025)</arxiv:journal_reference>
      <dc:creator>Jaap H. Abbring, Victor Chernozhukov, Iv\'an Fern\'andez-Val</dc:creator>
    </item>
    <item>
      <title>Bayesian Analyses of Structural Vector Autoregressions with Sign, Zero, and Narrative Restrictions Using the R Package bsvarSIGNs</title>
      <link>https://arxiv.org/abs/2501.16711</link>
      <description>arXiv:2501.16711v1 Announce Type: new 
Abstract: The R package bsvarSIGNs implements state-of-the-art algorithms for the Bayesian analysis of Structural Vector Autoregressions identified by sign, zero, and narrative restrictions. It offers fast and efficient estimation thanks to the deployment of frontier econometric and numerical techniques and algorithms written in C++. The core model is based on a flexible Vector Autoregression with estimated hyper-parameters of the Minnesota prior and the dummy observation priors. The structural model can be identified by sign, zero, and narrative restrictions, including a novel solution, making it possible to use the three types of restrictions at once. The package facilitates predictive and structural analyses using impulse responses, forecast error variance and historical decompositions, forecasting and conditional forecasting, as well as analyses of structural shocks and fitted values. All this is complemented by colourful plots, user-friendly summary functions, and comprehensive documentation. The package was granted the Di Cook Open-Source Statistical Software Award by the Statistical Society of Australia in 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16711v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolei Wang (University of Melbourne), Tomasz Wo\'zniak (University of Melbourne)</dc:creator>
    </item>
    <item>
      <title>Why is the estimation of metaorder impact with public market data so challenging?</title>
      <link>https://arxiv.org/abs/2501.17096</link>
      <description>arXiv:2501.17096v1 Announce Type: cross 
Abstract: Estimating market impact and transaction costs of large trades (metaorders) is a very important topic in finance. However, using models of price and trade based on public market data provide average price trajectories which are qualitatively different from what is observed during real metaorder executions: the price increases linearly, rather than in a concave way, during the execution and the amount of reversion after its end is very limited. We claim that this is a generic phenomenon due to the fact that even sophisticated statistical models are unable to correctly describe the origin of the autocorrelation of the order flow. We propose a modified Transient Impact Model which provides more realistic trajectories by assuming that only a fraction of the metaorder trading triggers market order flow. Interestingly, in our model there is a critical condition on the kernels of the price and order flow equations in which market impact becomes permanent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17096v1</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Naviglio, Giacomo Bormetti, Francesco Campigli, German Rodikov, Fabrizio Lillo</dc:creator>
    </item>
    <item>
      <title>Identifying causal effects with subjective ordinal outcomes</title>
      <link>https://arxiv.org/abs/2212.14622</link>
      <description>arXiv:2212.14622v4 Announce Type: replace 
Abstract: Survey questions often ask respondents to select from ordered scales where the meanings of the categories are subjective, leaving each individual free to apply their own definitions in answering. This paper studies the use of these responses as an outcome variable in causal inference, accounting for variation in interpretation of the categories across individuals. I find that when a continuous treatment variable is statistically independent of both i) potential outcomes; and ii) heterogeneity in reporting styles, a nonparametric regression of response category number on that treatment variable recovers a quantity proportional to an average causal effect among individuals who are on the margin between successive response categories. The magnitude of a given regression coefficient is not meaningful on its own, but the ratio of local regression derivatives with respect to two such treatment variables identifies the relative magnitudes of convex averages of their effects. These results can be seen as limiting cases of analogous results for binary treatment variables, though comparisons of magnitude involving discrete treatments are not as readily interpretable outside of the limit. I obtain a partial identification result for comparisons involving discrete treatments under further assumptions. An empirical application illustrates the results by revisiting the effects of income comparisons on subjective well-being, without assuming cardinality or interpersonal comparability of responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.14622v4</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonard Goff</dc:creator>
    </item>
    <item>
      <title>Difference-in-Differences with Compositional Changes</title>
      <link>https://arxiv.org/abs/2304.13925</link>
      <description>arXiv:2304.13925v2 Announce Type: replace 
Abstract: This paper studies difference-in-differences (DiD) setups with repeated cross-sectional data and potential compositional changes across time periods. We begin our analysis by deriving the efficient influence function and the semiparametric efficiency bound for the average treatment effect on the treated (ATT). We introduce nonparametric estimators that attain the semiparametric efficiency bound under mild rate conditions on the estimators of the nuisance functions, exhibiting a type of rate doubly robust (DR) property. Additionally, we document a trade-off related to compositional changes: We derive the asymptotic bias of DR DiD estimators that erroneously exclude compositional changes and the efficiency loss when one fails to correctly rule out compositional changes. We propose a nonparametric Hausman-type test for compositional changes based on these trade-offs. The finite sample performance of the proposed DiD tools is evaluated through Monte Carlo experiments and an empirical application. We consider extensions of our framework that accommodate double machine learning procedures with cross-fitting, and setups when some units are observed in both pre- and post-treatment periods. As a by-product of our analysis, we present a new uniform stochastic expansion of the local polynomial multinomial logit estimator, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13925v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro H. C. Sant'Anna, Qi Xu</dc:creator>
    </item>
    <item>
      <title>Causal clustering: design of cluster experiments under network interference</title>
      <link>https://arxiv.org/abs/2310.14983</link>
      <description>arXiv:2310.14983v3 Announce Type: replace 
Abstract: This paper studies the design of cluster experiments to estimate the global treatment effect in the presence of network spillovers. We provide a framework to choose the clustering that minimizes the worst-case mean-squared error of the estimated global effect. We show that optimal clustering solves a novel penalized min-cut optimization problem computed via off-the-shelf semi-definite programming algorithms. Our analysis also characterizes simple conditions to choose between any two cluster designs, including choosing between a cluster or individual-level randomization. We illustrate the method's properties using unique network data from the universe of Facebook's users and existing data from a field experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14983v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Davide Viviano, Lihua Lei, Guido Imbens, Brian Karrer, Okke Schrijvers, Liang Shi</dc:creator>
    </item>
    <item>
      <title>The Dynamic, the Static, and the Weak factor models and the analysis of high-dimensional time series</title>
      <link>https://arxiv.org/abs/2407.10653</link>
      <description>arXiv:2407.10653v2 Announce Type: replace 
Abstract: Several fundamental and closely interconnected issues related to factor models are reviewed and discussed: dynamic versus static loadings, rate-strong versus rate-weak factors, the concept of weakly common component recently introduced by Gersing et al. (2023), the irrelevance of cross-sectional ordering and the assumption of cross-sectional exchangeability, the impact of undetected strong factors, and the problem of combining common and idiosyncratic forecasts. Conclusions all point to the advantages of the General Dynamic Factor Model approach of Forni et al. (2000) over the widely used Static Approximate Factor Model introduced by Chamberlain and Rothschild (1983).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10653v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Barigozzi, Marc Hallin</dc:creator>
    </item>
    <item>
      <title>Bubble Modeling and Tagging: A Stochastic Nonlinear Autoregression Approach</title>
      <link>https://arxiv.org/abs/2401.07038</link>
      <description>arXiv:2401.07038v2 Announce Type: replace-cross 
Abstract: Economic and financial time series can feature locally explosive behavior when a bubble is formed. The economic or financial bubble, especially its dynamics, is an intriguing topic that has been attracting longstanding attention. To illustrate the dynamics of the local explosion itself, the paper presents a novel, simple, yet useful time series model, called the stochastic nonlinear autoregressive model, which is always strictly stationary and geometrically ergodic and can create long swings or persistence observed in many macroeconomic variables. When a nonlinear autoregressive coefficient is outside of a certain range, the model has periodically explosive behaviors and can then be used to portray the bubble dynamics. Further, the quasi-maximum likelihood estimation (QMLE) of our model is considered, and its strong consistency and asymptotic normality are established under minimal assumptions on innovation. A new model diagnostic checking statistic is developed for model fitting adequacy. In addition, two methods for bubble tagging are proposed, one from the residual perspective and the other from the null-state perspective. Monte Carlo simulation studies are conducted to assess the performances of the QMLE and the two bubble tagging methods in finite samples. Finally, the usefulness of the model is illustrated by an empirical application to the monthly Hang Seng Index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07038v2</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xuanling Yang, Dong Li, Ting Zhang</dc:creator>
    </item>
  </channel>
</rss>
