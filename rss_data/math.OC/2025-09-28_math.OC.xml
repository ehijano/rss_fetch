<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Sep 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Automated Algorithm Design via Nevanlinna-Pick Interpolation</title>
      <link>https://arxiv.org/abs/2509.21416</link>
      <description>arXiv:2509.21416v1 Announce Type: new 
Abstract: The synthesis of optimization algorithms typically follows a design-first-analyze-later approach, which often obscures fundamental performance limitations and hinders the systematic design of algorithms operating at the achievable theoretical boundaries. Recently, a framework based on frequency-domain techniques from robust control theory has emerged as a powerful tool for automating algorithm synthesis. By integrating the design and analysis stages, this framework enables the identification of fundamental performance limits. In this paper, we build on this framework and extend it to address algorithms for solving strongly convex problems with equality constraints. As a result, we obtain a new class of algorithms that offers sharp trade-off between number of matrix multiplication per iteration and convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21416v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim K. Ozaslan, Tryphon T. Georgiou, Mihailo R. Jovanovic</dc:creator>
    </item>
    <item>
      <title>Characterizations of Strongly Quasiconvex Functions</title>
      <link>https://arxiv.org/abs/2509.21580</link>
      <description>arXiv:2509.21580v1 Announce Type: new 
Abstract: We provide new necessary and sufficient conditons for ensuring strong quasiconvexity in the nonsmooth case and, as a consequence, we provide a proof for the differentiable case. Furthermore, we improve the quadratic growth property for strongly quasiconvex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21580v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nicolas Hadjisavvas, Felipe Lara</dc:creator>
    </item>
    <item>
      <title>A regret minimization approach to fixed-point iterations</title>
      <link>https://arxiv.org/abs/2509.21653</link>
      <description>arXiv:2509.21653v1 Announce Type: new 
Abstract: We propose a conversion scheme that turns regret minimizing algorithms into fixed point iterations, with convergence guarantees following from regret bounds. The resulting iterations can be seen as a grand extension of the classical Krasnoselskii--Mann iterations, as the latter are recovered by converting the Online Gradient Descent algorithm. This approach yields new simple iterations for finding fixed points of non-self operators. We also focus on converting algorithms from the AdaGrad family of regret minimizers, and thus obtain fixed point iterations with adaptive guarantees of a new kind. Numerical experiments on various problems demonstrate faster convergence of AdaGrad-based fixed point iterations over Krasnoselskii--Mann iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21653v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joon Kwon</dc:creator>
    </item>
    <item>
      <title>Regularized Overestimated Newton</title>
      <link>https://arxiv.org/abs/2509.21684</link>
      <description>arXiv:2509.21684v1 Announce Type: new 
Abstract: We propose Regularized Overestimated Newton (RON), a Newton-type method with low per-iteration cost and strong global and local convergence guarantees for smooth convex optimization. RON interpolates between gradient descent and globally regularized Newton, with behavior determined by the largest Hessian overestimation error. Globally, when the optimality gap of the objective is large, RON achieves an accelerated $O(n^{-2})$ convergence rate; when small, its rate becomes $O(n^{-1})$. Locally, RON converges superlinearly and linearly when the overestimation is exact and inexact, respectively, toward possibly non-isolated minima under the local Quadratic Growth (QG) condition. The linear rate is governed by an improved effective condition number depending on the overestimation error. Leveraging a recent randomized rank-$k$ Hessian approximation algorithm, we obtain a practical variant with $O(\text{dim}\cdot k^2)$ cost per iteration. When the Hessian rank is uniformly below $k$, RON achieves a per-iteration cost comparable to that of first-order methods while retaining the superior convergence rates even in degenerate local landscapes. We validate our theoretical findings through experiments on entropic optimal transport and inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21684v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danny Duan, Hanbaek Lyu</dc:creator>
    </item>
    <item>
      <title>Introducing Clause Cuts: Strong No-Good Cuts for MaxSAT Problems in Mixed Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2509.21687</link>
      <description>arXiv:2509.21687v1 Announce Type: new 
Abstract: In this paper we introduce Clause Cuts: linear inequalities obtained from clauses that are logically implied by a CNF formula, resembling strengthened no-good cuts. With these cuts, we tighten mixed-integer linear programming (MILP) formulations of random weighted partial MaxSAT problems, which have remained particularly challenging for core-guided complete MaxSAT solvers. Our approaches treat variables that attain integral values at the LP relaxation as partial assignments which are supplied to a SAT solver as assumptions. When infeasible, these assignments are ruled out with Clause Cuts which are further strengthened with the SAT solver. Two separation algorithms are introduced, one that utilizes a SAT-oracle and finds Clause Cuts in the set of variables with integral values, and another that uses the clauses learned by a conflict driven clause learning (CDCL) SAT solver while evaluating the partial assignment. Experiments on SATLIB benchmarks demonstrate substantial performance gains of up to two orders of magnitude compared to the general purpose MILP solver Gurobi 12, taking only 7.8% of Gurobi's runtime for the whole problem set. Results also surpass the specialized MaxSAT solver RC2, taking only 60% of its runtime. In some cases, our optimization takes only slightly longer than a single SAT call on the SAT-formula. We explain the source of these gains and the limitations of standard MILP formulations in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21687v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Engelhardt, Milan Adhikari, Jonasz Staszek, Alexander Martin</dc:creator>
    </item>
    <item>
      <title>Decentralized Detection with Many Sensors: Optimality of Exchangeable and Identical Encoding Policies</title>
      <link>https://arxiv.org/abs/2509.21724</link>
      <description>arXiv:2509.21724v1 Announce Type: new 
Abstract: We study a class of binary detection problems involving a single fusion center and a large or countably infinite number of sensors. Each sensor acts under a decentralized information structure, accessing only a local noisy observation related to the hypothesis. Based on this observation, sensors select policies to transmit a quantized signal through their actions to the fusion center, which makes the final decision using only these actions. This paper makes the following contributions: i) In the finitely many sensor setting, we provide a formal proof that an optimal encoding policy exists, and such an optimal policy is independent, deterministic, and of threshold type for the sensors and the maximum \emph{a posteriori} probability type for the fusion center; ii) For the finitely many sensor setting, we further show that an optimal encoding policy exhibits an exchangeability (permutation invariance) property; iii) We establish that an optimal encoding policy exists that is symmetric (identical) and independent across sensors in the infinitely many sensor setting under the error exponent cost; iv) Finally, we show that a symmetric optimal policy for the infinite population regime with the error exponent cost is approximately optimal for the large but finite sensor regime under the same cost criterion. We anticipate that the mathematical program used in the paper will find applications in several other massive communications applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21724v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Sanjari, Naci Saldi, Sinan Gezici, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Approximating value functions via corner Benders' cuts</title>
      <link>https://arxiv.org/abs/2509.21758</link>
      <description>arXiv:2509.21758v1 Announce Type: new 
Abstract: We introduce a novel technique to generate Benders' cuts from a conic relaxation ("corner") derived from a basis of a higher-dimensional polyhedron that we aim to outer approximate in a lower-dimensional space. To generate facet-defining inequalities for the epigraph associated to this corner, we develop a computationally-efficient algorithm based on a compact reverse polar formulation and a row generation scheme that handles the redundant inequalities. Via a known connection between arc-flow and path-flow formulations, we show that our method can recover the linear programming bound of a Dantzig-Wolfe formulation using multiple cuts in the projected space. In computational experiments, our generic technique enhances the performance of a problem-specific state-of-the-art algorithm for the vehicle routing problem with stochastic demands, a well-studied variant of the classic capacitated vehicle routing problem that accounts for customer demand uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21758v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matheus Jun Ota, Ricardo Fukasawa, Aleksandr M. Kazachkov</dc:creator>
    </item>
    <item>
      <title>Distributed Time-Varying Optimization via Unbiased Extremum Seeking</title>
      <link>https://arxiv.org/abs/2509.21814</link>
      <description>arXiv:2509.21814v1 Announce Type: new 
Abstract: This paper proposes a novel distributed optimization framework that addresses time-varying optimization problems without requiring explicit derivative information of the objective functions. Traditional distributed methods often rely on derivative computations, limiting their applicability when only real-time objective function measurements are available. Leveraging unbiased extremum seeking, we develop continuous-time algorithms that utilize local measurements and neighbor-shared data to collaboratively track time-varying optima. Key advancements include compatibility with directed communication graphs, customizable convergence rates (asymptotic, exponential, or prescribed-time), and the ability to handle dynamically evolving objectives. By integrating chirpy probing signals with time-varying frequencies, our unified framework achieves accelerated convergence while maintaining stability under mild assumptions. Theoretical guarantees are established through Lie bracket averaging and Lyapunov-based analysis, with linear matrix inequality conditions ensuring rigorous convergence. Numerical simulations validate the effectiveness of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21814v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xuebin Li, Xuefei Yang, Emilia Fridman, Mamadou Diagne, Jiebao Sun</dc:creator>
    </item>
    <item>
      <title>A Riemannian Accelerated Proximal Gradient Method</title>
      <link>https://arxiv.org/abs/2509.21897</link>
      <description>arXiv:2509.21897v1 Announce Type: new 
Abstract: Riemannian accelerated gradient methods have been well studied for smooth optimization, typically treating geodesically convex and geodesically strongly convex cases separately. However, their extension to nonsmooth problems on manifolds with theoretical acceleration remains underexplored. To address this issue, we propose a unified Riemannian accelerated proximal gradient method for problems of the form $F(x) = f(x) + h(x)$ on manifolds, where $f$ can be either geodesically convex or geodesically strongly convex, and $h$ is $\rho$-retraction-convex, possibly nonsmooth. We rigorously establish accelerated convergence rate under reasonable conditions. Additionally, we introduce a safeguard mechanism to ensure global convergence in non-convex settings. Numerical results validate the theoretical acceleration of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21897v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuailing Feng, Yuhang Jiang, Wen Huang, Shihui Ying</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Networks: a theoretical framework for Universal Approximation and training</title>
      <link>https://arxiv.org/abs/2509.21920</link>
      <description>arXiv:2509.21920v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) are widely regarded as a biologically-inspired and energy-efficient alternative to classical artificial neural networks. Yet, their theoretical foundations remain only partially understood. In this work, we develop a rigorous mathematical analysis of a representative SNN architecture based on Leaky Integrate-and-Fire (LIF) neurons with threshold-reset dynamics. Our contributions are twofold. First, we establish a universal approximation theorem showing that SNNs can approximate continuous functions on compact domains to arbitrary accuracy. The proof relies on a constructive encoding of target values via spike timing and a careful interplay between idealized $\delta$-driven dynamics and smooth Gaussian-regularized models. Second, we analyze the quantitative behavior of spike times across layers, proving well-posedness of the hybrid dynamics and deriving conditions under which spike counts remain stable, decrease, or in exceptional cases increase due to resonance phenomena or overlapping inputs. Together, these results provide a principled foundation for understanding both the expressive power and the dynamical constraints of SNNs, offering theoretical guarantees for their use in classification and signal processing tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21920v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umberto Biccari</dc:creator>
    </item>
    <item>
      <title>An Efficient ADMM Method for Ratio-Type Nonconvex and Nonsmooth Minimization in Sparse Recovery</title>
      <link>https://arxiv.org/abs/2509.21969</link>
      <description>arXiv:2509.21969v1 Announce Type: new 
Abstract: Sparse signal recovery based on nonconvex and nonsmooth optimization problems has significant applications and demonstrates superior performance in signal processing and machine learning. This work deals with a scale-invariant $\ell_{1/2}/\ell_{2}$ sparse minimization with nonconvex, nonseparable, ratio-type regularization to enhance the accuracy and stability of sparse recovery. Within the framework of the null space property, we analyze the conditions for exact and stable recovery in constrained minimization problem. For the unconstrained regularized minimization problem, we develop an alternating direction method of multipliers (ADMM) based on a splitting strategy and rigorously analyze its global convergence and linear convergence rate under reasonable assumptions. Numerical experiments demonstrate that the proposed method consistently outperforms existing approaches across diverse noise levels and measurement settings. Furthermore, experiments on neural network sparsity and generalization performance demonstrate that the method effectively improves prediction accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21969v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lang Yu, Nanjing Huang</dc:creator>
    </item>
    <item>
      <title>A note on the Davis-Yin three-operator splitting method</title>
      <link>https://arxiv.org/abs/2509.22032</link>
      <description>arXiv:2509.22032v1 Announce Type: new 
Abstract: This paper addresses the monotone inclusion problem in a real Hilbert space, with the objective of identifying a point \( x \in \mathcal{H} \) such that \( 0 \in Ax + Bx + Cx \), where \( A \) and \(C\) are maximal monotone operators and \( B \) is a \(\beta\)-cocoercive operator. The Davis-Yin three-operator splitting method constitutes a widely used algorithm for solving this problem. This method consists of two subproblems: the first entails a backward step, whereas the second comprises a backward step followed by a forward step. A natural question arises: is it possible to construct an algorithm that incorporates the forward step into the first subproblem? This paper addresses this question by introducing a novel splitting algorithm that integrates the forward step into the first subproblem. The proposed algorithm generalizes the Douglas-Rachford splitting method, the reflected forward-backward splitting method, and the forward-reflected-backward splitting method. We establish the weak convergence of the proposed algorithm in a general real Hilbert space under suitable stepsize conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22032v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maoran Wang, Xingju Cai</dc:creator>
    </item>
    <item>
      <title>A Variational Calculus for Optimal Control of the Generalized Riemann Problem for Hyperbolic Systems of Conservation Laws</title>
      <link>https://arxiv.org/abs/2509.22076</link>
      <description>arXiv:2509.22076v1 Announce Type: new 
Abstract: We develop a variational calculus for entropy solutions of the Generalized Riemann Problem (GRP) for strictly hyperbolic systems of conservation laws where the control is the initial state. The GRP has a discontinuous initial state with exactly one discontinuity and continuously differentiable ($C^1$) states left and right of it. The control consists of the $C^1$ parts of the initial state and the position of the discontinuity. Solutions of the problem are generally discontinuous since they contain shock curves. We assume the time horizon $T&gt;0$ to be sufficiently small such that no shocks interact and no new shocks are generated. Moreover, we assume that no rarefaction waves occur and that the jump of the initial state is sufficiently small.
  Since the shock positions depend on the control, a transformation to a reference space is used to fix the shock positions. In the reference space, we prove that the solution of the GRP between the shocks is continuously differentiable from the control space to $C^0$. In physical coordinates, this implies that the shock curves in $C^1$ and the states between the shocks in the topology of $C^0$ depend continuously differentiable on the control. As a consequence, we obtain the differentiability of tracking type objective functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22076v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannik Breitkopf, Stefan Ulbrich</dc:creator>
    </item>
    <item>
      <title>Stability Analysis of An Integrated Multistage Stochastic Programming and Markov Decision Process Problem</title>
      <link>https://arxiv.org/abs/2509.22194</link>
      <description>arXiv:2509.22194v1 Announce Type: new 
Abstract: In this paper, we consider an integrated MSP-MDP framework which captures features of Markov decision process (MDP) and multistage stochastic programming (MSP). The integrated framework allows one to study a dynamic decision-making process that involves both transition of system states and dynamic change of the stochastic environment affected respectively by potential endogenous uncertainties and exogenous uncertainties. The integrated model differs from classical MDP models by taking into account the effect of history-dependent exogenous uncertainty and distinguishes itself from standard MSP models by explicitly considering transition of states between stages. We begin by deriving dynamic nested reformulation of the problem and the Lipschitz continuity and convexity of the stage-wise optimal value functions. We then move on to investigate stability of the problem in terms of the optimal value and the set of optimal solutions under the perturbations of the probability distributions of the endogenous uncertainty and the exogenous uncertainty. Specifically, we quantify the effects of the perturbation of the two uncertainties on the optimal values and optimal solutions by deriving the error bounds in terms of Kantorovich metric and Fortet-Mourier metric of the probability distributions of the respective uncertainties. These results differ from the existing stability results established in terms of the filtration distance \cite{heitsch2009scenario} or the nested distance \cite{pflug2012distance}. We use some examples to explain the differences via tightness of the error bounds and applicability of the stability results. The results complement the existing stability results and provide new theoretical grounding for emerging integrated MSP-MDP models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22194v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyao Yang, Zhiping Chen, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Eco-Conscious Customers Behavior in Capacitated Two-Echelon Location-Routing Models for Sustainable Last-Mile Delivery</title>
      <link>https://arxiv.org/abs/2509.22357</link>
      <description>arXiv:2509.22357v1 Announce Type: new 
Abstract: This paper introduces a novel capacitated Two-Echelon Location-Routing Problem with Eco-conscious Customer Behavior (2E-LRP-ECB) aimed at enhancing the environmental sustainability of last-mile delivery (LMD) operations. The model jointly optimizes dynamic satellites location, vehicle routing, and customer delivery modes, explicitly accounting for (i) heterogeneous customer travel behaviors, (ii) heterogeneous fleet composition, and (iii) diverse emission profiles across both echelons. A piecewise linear formulation captures the additional emissions from first-echelon vehicle stops, while customer travel emissions are computed based on individual willingness and capacity to use zero-emission transport. The problem is solved exactly for a wide set of real-world-based instances under four operational strategies, differing in optimization objectives and second-echelon fleet composition. Computational experiments, including a case study with a major Portuguese LMD provider, highlight the environmental and operational tradeoffs inherent to strategic and operational choices such as fleet composition, satellite activation, and customer pick-up policies. Results reveal that minimizing distance can lead to substantial increases in emissions, while emissions-oriented strategies leverage customer travel to achieve significant sustainability gains without compromising service efficiency. A multi-objective analysis using the epsilon-constraint method produces Pareto frontiers and knee-point solutions, offering actionable insights for balancing operational efficiency and environmental impact in sustainable LMD design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22357v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Bonomi, Diana Jorge, Ana Barbosa-P\'ovoa</dc:creator>
    </item>
    <item>
      <title>Extremal Eigenvalues of Weighted Steklov Problems</title>
      <link>https://arxiv.org/abs/2509.22398</link>
      <description>arXiv:2509.22398v1 Announce Type: new 
Abstract: We study the optimization of Steklov eigenvalues with respect to a boundary density function $\rho$ on a bounded Lipschitz domain $\Omega \subset \mathbb{R}^N$. We investigate the minimization and maximization of $\lambda_k(\rho)$, the $k$th Steklov eigenvalue, over admissible densities satisfying pointwise bounds and a fixed integral constraint. Our analysis covers both first and higher-order eigenvalues and applies to general, not necessarily convex or simply connected, domains. We establish the existence of optimal solutions and provide structural characterizations: minimizers are bang--bang functions and may have disconnected support, while maximizers are not necessarily bang--bang. On circular domains, the minimization problem admits infinitely many minimizers generated by rotational symmetry, while the maximization problem has infinitely many distinct maximizers that are not symmetry-induced. We also show that the maps $\rho \mapsto \lambda_k(\rho)$ and $\rho \mapsto 1/\lambda_k(\rho)$ are generally neither convex nor concave, limiting the use of classical convex optimization tools. To address these challenges, we analyze the objective functional and introduce a Fr\'echet differentiable surrogate that enables the derivation of optimality conditions. We further design an efficient numerical algorithm, with experiments illustrating the difficulty of recovering optimal densities when they lack smoothness or exhibit oscillations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22398v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiu Yen Kao, Seyyed Abbas Mohammadi</dc:creator>
    </item>
    <item>
      <title>Safe-by-Design: Approximate Nonlinear Model Predictive Control with Real Time Feasibility</title>
      <link>https://arxiv.org/abs/2509.22422</link>
      <description>arXiv:2509.22422v1 Announce Type: new 
Abstract: This paper establishes relationships between continuous-time, receding horizon, nonlinear model predictive control (MPC) and control Lyapunov and control barrier functions (CLF/CBF). We show that, if the cost function "behaves well" for points in the terminal set, then the optimal value function and the feasible set, respectively, define a compatible CLF/CBF pair on the MPC's region of attraction. We then proceed to prove that any approximation of the value function and the feasible set also define a CLF/CBF pair, as long as those approximations satisfy the same "well behavedness" condition; and that a feasible state feedback can be computed by solving an infinitesimal version of the MPC problem. This methodology permits the formulation of continuous-time small-sized quadratic programs for feedback and enables approximate solutions of the nonlinear model predictive controller with theoretical safety and convergence guarantee. Finally, we demonstrate the effectiveness of the proposed approach when compared to other constrained control techniques through numerical experiments for nonlinear constrained spacecraft control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22422v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Olucak, Arthur Castello B. de Oliveira, Torbj{\o}rn Cunis</dc:creator>
    </item>
    <item>
      <title>On an optimization framework for damage localization in structures</title>
      <link>https://arxiv.org/abs/2509.22492</link>
      <description>arXiv:2509.22492v1 Announce Type: new 
Abstract: Efficient structural damage localization remains a challenge in structural health monitoring (SHM), particularly when the problem is coupled with uncertainty of conditions and complexity of structures. Traditional methods simply based on experimental data processing are often not sufficiently reliable, while complex models often struggle with computational inefficiency given the tremendous amount of model parameters. This paper focuses on closing the gap between data-driven SHM and physics-based model updating by offering a solution for real-world infrastructure. We first concentrate on fusing multi-source damage-sensitive features (DSF) based on experimental modal data into spatially mapped belief masses to pre-screen candidate damage locations. The resulting candidate damage locations are integrated into an inverse Finite Element method (FEM) model calibration process. We propose an optimization framework to identify the most probable damage scenario with single and multi-damage cases. We present the corresponding numerical results in this paper, which open the door to extend the application of the framework to a complex real bridge structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22492v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Owais Saleem, Tim Suchan, Natalie Rauter, Kathrin Welker</dc:creator>
    </item>
    <item>
      <title>A dynamical formulation of multi-marginal optimal transport</title>
      <link>https://arxiv.org/abs/2509.22494</link>
      <description>arXiv:2509.22494v1 Announce Type: new 
Abstract: We present a primal-dual dynamical formulation of the multi-marginal optimal transport problem for (semi-)convex cost functions. Even in the two-marginal setting, this formulation applies to cost functions not covered by the classical dynamical approach of Benamou-Brenier. Our dynamical formulation yields a convex optimization problem, enabling the use of convex optimization tools to find quasi-Monge solutions of the static multi-marginal problem for translation-invariant costs. We illustrate our results numerically with proximal splitting methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22494v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Pass, Yair Shenfeld</dc:creator>
    </item>
    <item>
      <title>Explicit Global Convergence Rates of BFGS without Line Search</title>
      <link>https://arxiv.org/abs/2509.22508</link>
      <description>arXiv:2509.22508v1 Announce Type: new 
Abstract: This paper studies the convergence rates of the Broyden--Fletcher--Goldfarb--Shanno~(BFGS) method without line search. We show that the BFGS method with an adaptive step size [Gao and Goldfarb, Optimization Methods and Software, 34(1):194-217, 2019] exhibits a two-phase non-asymptotic global convergence behavior when minimizing a strongly convex function, i.e., a linear convergence rate of $\mathcal{O}((1 - 1 / \varkappa)^{k})$ in the first phase and a superlinear convergence rate of $\mathcal{O}((\varkappa / k)^{k})$ in the second phase, where $k$ is the iteration counter and $\varkappa$ is the condition number. In contrast, the existing analysis only establishes asymptotic results. Furthermore, we propose a novel adaptive BFGS method without line search, which allows a larger step size by taking the gradient Lipschitz continuity into the algorithm design. We prove that our method achieves faster convergence when the initial point is far away from the optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22508v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianjiang Yu, Weiguo Gao, Luo Luo</dc:creator>
    </item>
    <item>
      <title>Linear Risk Sharing on Networks</title>
      <link>https://arxiv.org/abs/2509.21411</link>
      <description>arXiv:2509.21411v1 Announce Type: cross 
Abstract: Over the past decade alternatives to traditional insurance and banking have grown in popularity. The desire to encourage local participation has lead products such as peer-to-peer insurance, reciprocal contracts, and decentralized finance platforms to increasingly rely on network structures to redistribute risk among participants. In this paper, we develop a comprehensive framework for linear risk sharing (LRS), where random losses are reallocated through nonnegative linear operators which can accommodate a wide range of networks. Building on the theory of stochastic and doubly stochastic matrices, we establish conditions under which constraints such as budget balance, fairness, and diversification are guaranteed. The convex order framework allows us to compare different allocations rigorously, highlighting variance reduction and majorization as natural consequences of doubly stochastic mixing. We then extend the analysis to network-based sharing, showing how their topology shapes risk outcomes in complete, star, ring, random, and scale-free graphs. A second layer of randomness, where the sharing matrix itself is random, is introduced via Erd\H{o}s--R\'enyi and preferential-attachment networks, connecting risk-sharing properties to degree distributions. Finally, we study convex combinations of identity and network-induced operators, capturing the trade-off between self-retention and diversification. Our results provide design principles for fair and efficient peer-to-peer insurance and network-based risk pooling, combining mathematical soundness with economic interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21411v1</guid>
      <category>econ.TH</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arthur Charpentier, Philipp Ratz</dc:creator>
    </item>
    <item>
      <title>Scalable Second-order Riemannian Optimization for $K$-means Clustering</title>
      <link>https://arxiv.org/abs/2509.21675</link>
      <description>arXiv:2509.21675v1 Announce Type: cross 
Abstract: Clustering is a hard discrete optimization problem. Nonconvex approaches such as low-rank semidefinite programming (SDP) have recently demonstrated promising statistical and local algorithmic guarantees for cluster recovery. Due to the combinatorial structure of the $K$-means clustering problem, current relaxation algorithms struggle to balance their constraint feasibility and objective optimality, presenting tremendous challenges in computing the second-order critical points with rigorous guarantees. In this paper, we provide a new formulation of the $K$-means problem as a smooth unconstrained optimization over a submanifold and characterize its Riemannian structures to allow it to be solved using a second-order cubic-regularized Riemannian Newton algorithm. By factorizing the $K$-means manifold into a product manifold, we show how each Newton subproblem can be solved in linear time. Our numerical experiments show that the proposed method converges significantly faster than the state-of-the-art first-order nonnegative low-rank factorization method, while achieving similarly optimal statistical accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21675v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Xu, Chun-Ying Hou, Xiaohui Chen, Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>On Suboptimal Safety-Critical Tracking Controller Design</title>
      <link>https://arxiv.org/abs/2509.21726</link>
      <description>arXiv:2509.21726v1 Announce Type: cross 
Abstract: This paper proposes a novel framework for safety-critical optimal trajectory tracking in nonlinear systems based on the state-dependent Riccati equation (SDRE) methodology. By embedding barrier states into the system dynamics, the proposed strategy simultaneously ensures safety and tracking requirements, even in scenarios where these objectives may be inherently conflicting. A discounted pseudo-quadratic cost function is formulated to achieve a suboptimal trade-off between tracking accuracy, control effort, and safety objective. We present two distinct controller designs: one utilizing a single barrier state to enforce overall safety constraints, and another employing multiple barrier states to individually tuning the system's conservatism with respect to each safety constraint, providing enhanced flexibility in tuning the system's conservatism toward individual constraints. We establish sufficient conditions to ensure the solvability of the associated Riccati equations. The proposed safe controller is well-suited for real-time implementation in practical systems, given its reasonable computational requirements and compatibility with widely available embedded microprocessors. This is supported by simulation studies involving a mechanical system and a mobile robot collision avoidance scenario, where the safe SDRE controller consistently maintained safety while achieving trajectory tracking objectives in challenging conditions. Additionally, experimental results on a cable-driven parallel robot further demonstrate the practical applicability and effectiveness of the proposed method in real-world control tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21726v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yazdan Batmani, Saber Omidi</dc:creator>
    </item>
    <item>
      <title>Sharpness-Aware Minimization Can Hallucinate Minimizers</title>
      <link>https://arxiv.org/abs/2509.21818</link>
      <description>arXiv:2509.21818v1 Announce Type: cross 
Abstract: Sharpness-Aware Minimization (SAM) is a widely used method that steers training toward flatter minimizers, which typically generalize better. In this work, however, we show that SAM can converge to hallucinated minimizers -- points that are not minimizers of the original objective. We theoretically prove the existence of such hallucinated minimizers and establish conditions for local convergence to them. We further provide empirical evidence demonstrating that SAM can indeed converge to these points in practice. Finally, we propose a simple yet effective remedy for avoiding hallucinated minimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21818v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chanwoong Park, Uijeong Jang, Ernest K. Ryu, Insoon Yang</dc:creator>
    </item>
    <item>
      <title>Gamma-Convergence of Convex Functions, Conjugates, and Subdifferentials</title>
      <link>https://arxiv.org/abs/2509.21863</link>
      <description>arXiv:2509.21863v1 Announce Type: cross 
Abstract: This work establishes dual and subdifferential characterizations of Unicode ({\Gamma})-convergence for sequences of proper convex lower semicontinuous functions in weakly compactly generated Banach spaces. It is shown that such a sequence Unicode ({\Gamma})-converges in the strong topology to a limit function if and only if the sequence of conjugates Unicode ({\Gamma})-converges in the $w^*$-topology to the Fenchel conjugate. It is further proved that both conditions are equivalent to the graphical convergence of the associated subdifferentials with respect to the strong-$w^*$ product topology. Counterexamples demonstrate that these equivalences break down outside the weakly compactly generated setting. The analysis develops new arguments in separable Banach spaces and extends them to the general framework through separable reduction techniques. Additionally, we introduce several new rich families of convex functions that exhibit various separable reduction properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21863v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael Correa, Pedro P\'erez-Aros, Jos\'e Pablo Santander</dc:creator>
    </item>
    <item>
      <title>Zubov-Net: Adaptive Stability for Neural ODEs Reconciling Accuracy with Robustness</title>
      <link>https://arxiv.org/abs/2509.21879</link>
      <description>arXiv:2509.21879v1 Announce Type: cross 
Abstract: Despite neural ordinary differential equations (Neural ODEs) exhibiting intrinsic robustness under input perturbations due to their dynamical systems nature, recent approaches often involve imposing Lyapunov-based stability conditions to provide formal robustness guarantees. However, a fundamental challenge remains: the tension between robustness and accuracy, primarily stemming from the difficulty in imposing appropriate stability conditions. To address this, we propose an adaptive stable learning framework named Zubov-Net, which innovatively reformulates Zubov's equation into a consistency characterization between regions of attraction (RoAs) and prescribed RoAs (PRoAs). Building on this consistency, we introduce a new paradigm for actively controlling the geometry of RoAs by directly optimizing PRoAs to reconcile accuracy and robustness. Our approach is realized through tripartite losses (consistency, classification, and separation losses) and a parallel boundary sampling algorithm that co-optimizes the Neural ODE and the Lyapunov function. To enhance the discriminativity of Lyapunov functions, we design an input-attention-based convex neural network via a softmax attention mechanism that focuses on equilibrium-relevant features and also serves as weight normalization to maintain training stability in deep architectures. Theoretically, we prove that minimizing the tripartite loss guarantees consistent alignment of PRoAs-RoAs, trajectory stability, and non-overlapping PRoAs. Moreover, we establish stochastic convex separability with tighter probability bounds and fewer dimensionality requirements to justify the convex design in Lyapunov functions. Experimentally, Zubov-Net maintains high classification accuracy while significantly improving robustness against various stochastic noises and adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21879v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaoyang Luo, Yan Zou, Nanjing Huang</dc:creator>
    </item>
    <item>
      <title>Slicing Wasserstein Over Wasserstein Via Functional Optimal Transport</title>
      <link>https://arxiv.org/abs/2509.22138</link>
      <description>arXiv:2509.22138v1 Announce Type: cross 
Abstract: Wasserstein distances define a metric between probability measures on arbitrary metric spaces, including meta-measures (measures over measures). The resulting Wasserstein over Wasserstein (WoW) distance is a powerful, but computationally costly tool for comparing datasets or distributions over images and shapes. Existing sliced WoW accelerations rely on parametric meta-measures or the existence of high-order moments, leading to numerical instability. As an alternative, we propose to leverage the isometry between the 1d Wasserstein space and the quantile functions in the function space $L_2([0,1])$. For this purpose, we introduce a general sliced Wasserstein framework for arbitrary Banach spaces. Due to the 1d Wasserstein isometry, this framework defines a sliced distance between 1d meta-measures via infinite-dimensional $L_2$-projections, parametrized by Gaussian processes. Combining this 1d construction with classical integration over the Euclidean unit sphere yields the double-sliced Wasserstein (DSW) metric for general meta-measures. We show that DSW minimization is equivalent to WoW minimization for discretized meta-measures, while avoiding unstable higher-order moments and computational savings. Numerical experiments on datasets, shapes, and images validate DSW as a scalable substitute for the WoW distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22138v1</guid>
      <category>cs.LG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moritz Piening, Robert Beinert</dc:creator>
    </item>
    <item>
      <title>Learning from Delayed Feedback in Games via Extra Prediction</title>
      <link>https://arxiv.org/abs/2509.22426</link>
      <description>arXiv:2509.22426v1 Announce Type: cross 
Abstract: This study raises and addresses the problem of time-delayed feedback in learning in games. Because learning in games assumes that multiple agents independently learn their strategies, a discrepancy in optimization often emerges among the agents. To overcome this discrepancy, the prediction of the future reward is incorporated into algorithms, typically known as Optimistic Follow-the-Regularized-Leader (OFTRL). However, the time delay in observing the past rewards hinders the prediction. Indeed, this study firstly proves that even a single-step delay worsens the performance of OFTRL from the aspects of regret and convergence. This study proposes the weighted OFTRL (WOFTRL), where the prediction vector of the next reward in OFTRL is weighted $n$ times. We further capture an intuition that the optimistic weight cancels out this time delay. We prove that when the optimistic weight exceeds the time delay, our WOFTRL recovers the good performances that the regret is constant ($O(1)$-regret) in general-sum normal-form games, and the strategies converge to the Nash equilibrium as a subsequence (best-iterate convergence) in poly-matrix zero-sum games. The theoretical results are supported and strengthened by our experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22426v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kenshi Abe, Kaito Ariu</dc:creator>
    </item>
    <item>
      <title>Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise</title>
      <link>https://arxiv.org/abs/2509.22500</link>
      <description>arXiv:2509.22500v1 Announce Type: cross 
Abstract: Constrained optimization is a powerful framework for enforcing requirements on neural networks. These constrained deep learning problems are typically solved using first-order methods on their min-max Lagrangian formulation, but such approaches often suffer from oscillations and can fail to find all local solutions. While the Augmented Lagrangian method (ALM) addresses these issues, practitioners often favor dual optimistic ascent schemes (PI control) on the standard Lagrangian, which perform well empirically but lack formal guarantees. In this paper, we establish a previously unknown equivalence between these approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient descent-ascent on the Augmented Lagrangian. This finding allows us to transfer the robust theoretical guarantees of the ALM to the dual optimistic setting, proving it converges linearly to all local solutions. Furthermore, the equivalence provides principled guidance for tuning the optimism hyper-parameter. Our work closes a critical gap between the empirical success of dual optimistic methods and their theoretical foundation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22500v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Ramirez, Simon Lacoste-Julien</dc:creator>
    </item>
    <item>
      <title>Learning to Price Bundles: A GCN Approach for Mixed Bundling</title>
      <link>https://arxiv.org/abs/2509.22557</link>
      <description>arXiv:2509.22557v1 Announce Type: cross 
Abstract: Bundle pricing refers to designing several product combinations (i.e., bundles) and determining their prices in order to maximize the expected profit. It is a classic problem in revenue management and arises in many industries, such as e-commerce, tourism, and video games. However, the problem is typically intractable due to the exponential number of candidate bundles. In this paper, we explore the usage of graph convolutional networks (GCNs) in solving the bundle pricing problem. Specifically, we first develop a graph representation of the mixed bundling model (where every possible bundle is assigned with a specific price) and then train a GCN to learn the latent patterns of optimal bundles. Based on the trained GCN, we propose two inference strategies to derive high-quality feasible solutions. A local-search technique is further proposed to improve the solution quality. Numerical experiments validate the effectiveness and efficiency of our proposed GCN-based framework. Using a GCN trained on instances with 5 products, our methods consistently achieve near-optimal solutions (better than 97%) with only a fraction of computational time for problems of small to medium size. It also achieves superior solutions for larger size of problems compared with other heuristic methods such as bundle size pricing (BSP). The method can also provide high quality solutions for instances with more than 30 products even for the challenging cases where product utilities are non-additive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22557v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangyu Ding, Chenghan Wu, Guokai Li, Zizhuo Wang</dc:creator>
    </item>
    <item>
      <title>Effective Policy Learning for Multi-Agent Online Coordination Beyond Submodular Objectives</title>
      <link>https://arxiv.org/abs/2509.22596</link>
      <description>arXiv:2509.22596v1 Announce Type: cross 
Abstract: In this paper, we present two effective policy learning algorithms for multi-agent online coordination(MA-OC) problem. The first one, \texttt{MA-SPL}, not only can achieve the optimal $(1-\frac{c}{e})$-approximation guarantee for the MA-OC problem with submodular objectives but also can handle the unexplored $\alpha$-weakly DR-submodular and $(\gamma,\beta)$-weakly submodular scenarios, where $c$ is the curvature of the investigated submodular functions, $\alpha$ denotes the diminishing-return(DR) ratio and the tuple $(\gamma,\beta)$ represents the submodularity ratios. Subsequently, in order to reduce the reliance on the unknown parameters $\alpha,\gamma,\beta$ inherent in the \texttt{MA-SPL} algorithm, we further introduce the second online algorithm named \texttt{MA-MPL}. This \texttt{MA-MPL} algorithm is entirely \emph{parameter-free} and simultaneously can maintain the same approximation ratio as the first \texttt{MA-SPL} algorithm. The core of our \texttt{MA-SPL} and \texttt{MA-MPL} algorithms is a novel continuous-relaxation technique termed as \emph{policy-based continuous extension}. Compared with the well-established \emph{multi-linear extension}, a notable advantage of this new \emph{policy-based continuous extension} is its ability to provide a lossless rounding scheme for any set function, thereby enabling us to tackle the challenging weakly submodular objectives. Finally, extensive simulations are conducted to validate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22596v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qixin Zhang, Yan Sun, Can Jin, Xikun Zhang, Yao Shu, Puning Zhao, Li Shen, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization</title>
      <link>https://arxiv.org/abs/1807.03907</link>
      <description>arXiv:1807.03907v2 Announce Type: replace 
Abstract: Motivated by applications in Optimization, Game Theory, and the training of Generative Adversarial Networks, the convergence properties of first order methods in min-max problems have received extensive study. It has been recognized that they may cycle, and there is no good understanding of their limit points when they do not. When they converge, do they converge to local min-max solutions? We characterize the limit points of two basic first order methods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA). We show that both dynamics avoid unstable critical points for almost all initializations. Moreover, for small step sizes and under mild assumptions, the set of \{OGDA\}-stable critical points is a superset of \{GDA\}-stable critical points, which is a superset of local min-max solutions (strict in some cases). The connecting thread is that the behavior of these dynamics can be studied from a dynamical systems perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:1807.03907v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantinos Daskalakis, Ioannis Panageas</dc:creator>
    </item>
    <item>
      <title>Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information</title>
      <link>https://arxiv.org/abs/2304.13646</link>
      <description>arXiv:2304.13646v5 Announce Type: replace 
Abstract: Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings, with significantly lower costs, less computation time, and robustness to feature dimensions and nonlinearity of the underlying dependency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13646v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiyang Zhang, Junyi Liu, Xiaobo Zhao</dc:creator>
    </item>
    <item>
      <title>On the control of recurrent neural networks using constant inputs</title>
      <link>https://arxiv.org/abs/2410.17199</link>
      <description>arXiv:2410.17199v2 Announce Type: replace 
Abstract: This paper investigates the controllability of a broad class of recurrent neural networks widely used in theoretical neuroscience, including models of large-scale human brain dynamics. Motivated by emerging applications in non-invasive neurostimulation such as transcranial direct current stimulation (tDCS), we study the control synthesis of these networks using constant and piecewise constant inputs. The neural model considered is a continuous-time Hopfield-type system with nonlinear activation functions and arbitrary input matrices representing inter-regional brain interactions. Our main contribution is the formulation and solution of a control synthesis problem for such nonlinear systems using specific solution representations. These representations yield explicit algebraic conditions for synthesizing constant and piecewise constant controls that solve a two-point boundary value problem in state space up to higher-order corrections with respect to the time horizon. In particular, the input is constructed to satisfy a tractable small-time algebraic relation involving the Jacobian of the nonlinear drift, ensuring that the synthesis reduces to verifying conditions on the system matrices. For canonical input matrices that directly actuate $k$ nodes, this implies that the reachable set (with constant inputs) of a given initial state is an affine subspace whose dimension equals the input rank and whose basis can be computed efficiently using a thin QR factorization. Numerical simulations illustrate the theoretical results and demonstrate the effectiveness of the proposed synthesis in guiding the design of brain stimulation protocols for therapeutic and cognitive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17199v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Ruiqi Chen, ShiNung Ching</dc:creator>
    </item>
    <item>
      <title>Neural Operators for Adaptive Control of Freeway Traffic</title>
      <link>https://arxiv.org/abs/2410.20708</link>
      <description>arXiv:2410.20708v4 Announce Type: replace 
Abstract: Uncertainty and delayed reactions in human driving behavior lead to stop-and-go traffic congestion on freeways. The freeway traffic dynamics are governed by the Aw-Rascle-Zhang (ARZ) traffic Partial Differential Equation (PDE) models with unknown relaxation time. Motivated by the adaptive traffic control problem, this paper presents a neural operator (NO) based adaptive boundary control design for the coupled 2$\times$2 hyperbolic systems with uncertain spatially varying in-domain coefficients and boundary parameter. In traditional adaptive control for PDEs, solving backstepping kernel online is computationally intensive, as it requires significant resources at each time step to update the estimation of coefficients. To address this challenge, we use operator learning, i.e. DeepONet, to learn the mapping from system parameters to the kernels functions. DeepONet, a class of deep neural networks designed for approximating operators, has shown strong potential for approximating PDE backstepping designs in recent studies. Unlike previous works that focus on approximating single kernel equation associated with the scalar PDE system, we extend this framework to approximate PDE kernels for a class of the first-order coupled 2$\times$2 hyperbolic kernel equations. Our approach demonstrates that DeepONet is nearly two orders of magnitude faster than traditional PDE solvers for generating kernel functions, while maintaining a loss on the order of $10^{-3}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20708v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2025.112553</arxiv:DOI>
      <dc:creator>Kaijing Lv, Junmin Wang, Yihuai Zhang, Huan Yu</dc:creator>
    </item>
    <item>
      <title>Effectively Leveraging Momentum Terms in Stochastic Line Search Frameworks for Fast Optimization of Finite-Sum Problems</title>
      <link>https://arxiv.org/abs/2411.07102</link>
      <description>arXiv:2411.07102v2 Announce Type: replace 
Abstract: In this work, we address unconstrained finite-sum optimization problems, with particular focus on instances originating in large scale deep learning scenarios. Our main interest lies in the exploration of the relationship between recent line search approaches for stochastic optimization in the overparametrized regime and momentum directions. First, we point out that combining these two elements with computational benefits is not straightforward. To this aim, we propose a solution based on mini-batch persistency. We then introduce an algorithmic framework that exploits a mix of data persistency, conjugate-gradient type rules for the definition of the momentum parameter and stochastic line searches. The resulting algorithm provably possesses convergence properties under suitable assumptions and is empirically shown to outperform other popular methods from the literature, obtaining state-of-the-art results in both convex and nonconvex large scale training problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07102v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Davide Pucci</dc:creator>
    </item>
    <item>
      <title>On the Sharp Input-Output Analysis of Nonlinear Systems under Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2505.11688</link>
      <description>arXiv:2505.11688v2 Announce Type: replace 
Abstract: This paper is concerned with learning the input-output mapping of general nonlinear dynamical systems. While the existing literature focuses on Gaussian inputs and benign disturbances, we significantly broaden the scope of admissible control inputs and allow correlated, nonzero-mean, adversarial disturbances. With our reformulation as a linear combination of basis functions, we prove that the $\ell_2$-norm estimator overcomes the challenges as long as the probability that the system is under adversarial attack at a given time is smaller than a certain threshold. We provide an estimation error bound that decays with the input memory length and prove its optimality by constructing a problem instance that suffers from the same bound under adversarial attacks. Our work provides a sharp input-output analysis for a generic nonlinear and partially observed system under significantly generalized assumptions compared to existing works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11688v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Yuchen Fang, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Markov Perfect Equilibria in Discrete Finite-Player and Mean-Field Games</title>
      <link>https://arxiv.org/abs/2507.04540</link>
      <description>arXiv:2507.04540v2 Announce Type: replace 
Abstract: We study dynamic finite-player and mean-field stochastic games within the framework of Markov perfect equilibria (MPE). Our focus is on discrete time and space structures without monotonicity. Unlike their continuous-time analogues, discrete-time finite-player games generally do not admit unique MPE. However, we show that uniqueness is remarkably recovered when the time steps are sufficiently small, and we provide examples demonstrating the necessity of this assumption. This result, established without relying on any monotonicity conditions, underscores the importance of inertia in dynamic games. In both the finite-player and mean-field settings, we show that MPE correspond to solutions of the Nash-Lasry-Lions equation, which is known as the master equation in the mean-field case. We exploit this connection to establish the convergence of discrete-time finite-player games to their mean-field counterpart in short time. Finally, we prove the convergence of finite-player games to their continuous-time version on every time horizon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04540v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix H\"ofer, H. Mete Soner, Atilla Y{\i}lmaz</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Nonconvex Optimization under the Relaxed Smoothness</title>
      <link>https://arxiv.org/abs/2509.08726</link>
      <description>arXiv:2509.08726v2 Announce Type: replace 
Abstract: This paper studies decentralized optimization problem $f(\mathbf{x})=\frac{1}{m}\sum_{i=1}^m f_i(\mathbf{x})$, where each local function has the form of $f_i(\mathbf{x}) = {\mathbb E}\left[F(\mathbf{x};{\boldsymbol \xi}_i)\right]$ which is $(L_0,L_1)$-smooth but possibly nonconvex and the random variable ${\boldsymbol \xi}_i$ follows distribution ${\mathcal D}_i$. We propose a novel algorithm called decentralized normalized stochastic gradient descent (DNSGD), which can achieve an $\epsilon$-stationary point at each local agent. We present a new framework for analyzing decentralized first-order methods in the relaxed smooth setting, based on the Lyapunov function related to the product of the gradient norm and the consensus error. We show the upper bounds on the sample complexity of ${\mathcal O}(m^{-1}(L_f\sigma^2\Delta_f\epsilon^{-4} + \sigma^2\epsilon^{-2} + L_f^{-2}L_1^3\sigma^2\Delta_f\epsilon^{-1} + L_f^{-2}L_1^2\sigma^2))$ per agent and the communication complexity of $\tilde{\mathcal O}((L_f\epsilon^{-2} + L_1\epsilon^{-1})\gamma^{-1/2}\Delta_f)$, where $L_f=L_0 +L_1\zeta$, $\sigma^2$ is the variance of the stochastic gradient, $\Delta_f$ is the initial optimal function value gap, $\gamma$ is the spectral gap of the network, and $\zeta$ is the degree of the gradient dissimilarity. In the special case of $L_1=0$, the above results (nearly) match the lower bounds of decentralized stochastic nonconvex optimization under the standard smoothness. We also conduct numerical experiments to show the empirical superiority of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08726v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luo Luo, Xue Cui, Tingkai Jia, Cheng Chen</dc:creator>
    </item>
    <item>
      <title>Convergence, Duality and Well-Posedness in Convex Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2509.18304</link>
      <description>arXiv:2509.18304v2 Announce Type: replace 
Abstract: We consider the convex bilevel optimization problem, also known as simple bilevel programming. There are two challenges in solving convex bilevel optimization problems. Firstly, strong duality is not guaranteed due to the lack of Slater constraint qualification. Secondly, we demonstrate through an example that convergence of algorithms is not guaranteed even when usual subotimality gap bounds are present, due to the possibility of encountering super-optimal solutions. We show that strong duality (but not necessarily dual solvability) is exactly equivalent to ensuring correct asymptotic convergence of both inner and outer function values, and provide a simple condition that guarantees strong duality. Unfortunately, we also show that this simple condition is not sufficient to guarantee convergence to the optimal solution set. We draw connections to Levitin-Polyak well-posedness, and leverage this together with our strong duality equivalence to provide another condition that ensures convergence to the optimal solution set. We also discuss how our conditions have been implicitly present in existing algorithmic work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18304v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khanh-Hung Giang-Tran, Nam Ho-Nguyen, Fatma K{\i}l{\i}n\c{c}-Karzan, Lingqing Shen</dc:creator>
    </item>
    <item>
      <title>Online Resource Allocation with Average Budget Constraints</title>
      <link>https://arxiv.org/abs/2402.11425</link>
      <description>arXiv:2402.11425v5 Announce Type: replace-cross 
Abstract: We consider the problem of online resource allocation with average budget constraints. At each time point the decision maker makes an irrevocable decision of whether to accept or reject a request before the next request arrives with the goal to maximize the cumulative rewards. In contrast to existing literature requiring the total resource consumption is below a certain level, we require the average resource consumption per accepted request does not exceed a given threshold. This problem can be casted as an online knapsack problem with exogenous random budget replenishment, and can find applications in various fields such as online anomaly detection, sequential advertising, and per-capita public service providers. We start with general arrival distributions and show that a simple policy achieves a $O(\sqrt{T})$ regret. We complement the result by showing that such a regret growing rate is in general not improvable. We then shift our focus to discrete arrival distributions. We find that many existing re-solving heuristics in the online resource allocation literature, albeit achieve bounded loss in canonical settings, may incur a $\Omega(\sqrt{T})$ or even a $\Omega(T)$ regret. With the observation that canonical policies tend to be too optimistic and over accept arrivals, we propose a novel policy that incorporates budget safety buffers. It turns out that a little more safety can greatly enhance efficiency -- small additional logarithmic buffers suffice to reduce the regret from $\Omega(\sqrt{T})$ or even $\Omega(T)$ to $O(\ln^2 T)$. From a practical perspective, we extend the policy to the scenario with continuous arrival distributions, time-dependent information structures, as well as unknown $T$. We conduct both synthetic experiments and empirical applications on a time series data of New York City taxi passengers to validate the performance of our proposed policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11425v5</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruicheng Ao, Hongyu Chen, David Simchi-Levi, Feng Zhu</dc:creator>
    </item>
    <item>
      <title>Analysis of the SQP Method for Hyperbolic PDE-Constrained Optimization in Acoustic Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2405.05158</link>
      <description>arXiv:2405.05158v4 Announce Type: replace-cross 
Abstract: In this paper, the SQP method applied to a hyperbolic PDE-constrained optimization problem is considered. The model arises from the acoustic full waveform inversion in the time domain. The analysis is mainly challenging due to the involved hyperbolicity and second-order bilinear structure. This notorious character leads to an undesired effect of loss of regularity in the SQP method, calling for a substantial extension of developed parabolic techniques. We propose and analyze a novel strategy for the well-posedness and convergence analysis based on the use of a smooth-in-time initial condition, a tailored self-mapping operator, and a two-step estimation process along with Stampacchia's method for second-order wave equations. Our final theoretical result is the R-superlinear convergence of the SQP method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05158v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Ammann, Irwin Yousept</dc:creator>
    </item>
    <item>
      <title>Constrained Search in Imaginary Time</title>
      <link>https://arxiv.org/abs/2504.05332</link>
      <description>arXiv:2504.05332v2 Announce Type: replace-cross 
Abstract: We introduce an imaginary-time evolution method to evaluate the pure-state constrained-search functional from density-functional theory formulated on finite lattices. Simultaneously, it yields a potential that produces a prescribed density of an eigenstate. Besides being a computational scheme, this allows one to gain theoretical insights into the density-potential mapping. The method can be generalized to the optimization of the expectation value of a general self-adjoint operator on a finite-dimensional Hilbert space under a finite number of expectation-value constraints for commuting self-adjoint operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05332v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>quant-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/g4ch-5x8m</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. A 112, 032815 (2025)</arxiv:journal_reference>
      <dc:creator>Markus Penz, Robert van Leeuwen</dc:creator>
    </item>
    <item>
      <title>Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy</title>
      <link>https://arxiv.org/abs/2505.07614</link>
      <description>arXiv:2505.07614v3 Announce Type: replace-cross 
Abstract: Recent advancements in machine learning have improved performance while also increasing computational demands. While federated and distributed setups address these issues, their structure is vulnerable to malicious influences. In this paper, we address a specific threat, Byzantine attacks, where compromised clients inject adversarial updates to derail global convergence. We combine the trust scores concept with trial function methodology to dynamically filter outliers. Our methods address the critical limitations of previous approaches, allowing functionality even when Byzantine nodes are in the majority. Moreover, our algorithms adapt to widely used scaled methods like Adam and RMSProp, as well as practical scenarios, including local training and partial participation. We validate the robustness of our methods by conducting extensive experiments on both synthetic and real ECG data collected from medical institutions. Furthermore, we provide a broad theoretical analysis of our algorithms and their extensions to aforementioned practical setups. The convergence guarantees of our methods are comparable to those of classical algorithms developed without Byzantine interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07614v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gleb Molodtsov, Daniil Medyakov, Sergey Skorik, Nikolas Khachaturov, Shahane Tigranyan, Vladimir Aletov, Aram Avetisyan, Martin Tak\'a\v{c}, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm</title>
      <link>https://arxiv.org/abs/2505.16932</link>
      <description>arXiv:2505.16932v3 Announce Type: replace-cross 
Abstract: Computing the polar decomposition and the related matrix sign function has been a well-studied problem in numerical analysis for decades. Recently, it has emerged as an important subroutine within the Muon algorithm for training deep neural networks. However, the requirements of this application differ sharply from classical settings: deep learning demands GPU-friendly algorithms that prioritize high throughput over high precision. We introduce Polar Express, a new method for computing the polar decomposition. Like Newton-Schulz and other classical polynomial methods, our approach uses only matrix-matrix multiplications, making it very efficient on GPUs. Inspired by earlier work of Chen &amp; Chow and Nakatsukasa &amp; Freund, Polar Express adapts the update rule at each iteration by solving a minimax optimization problem. We prove that this strategy minimizes error in a worst-case sense, allowing Polar Express to converge as rapidly as possible both in the early iterations and asymptotically. We also address finite-precision issues, making it practical to use in bfloat16. When integrated into the Muon training framework, our method leads to consistent improvements in validation loss when training a GPT-2 model on one billion tokens from the FineWeb dataset, outperforming recent alternatives across a range of learning rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16932v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Amsel, David Persson, Christopher Musco, Robert M. Gower</dc:creator>
    </item>
    <item>
      <title>WeightLoRA: Keep Only Necessary Adapters</title>
      <link>https://arxiv.org/abs/2506.02724</link>
      <description>arXiv:2506.02724v2 Announce Type: replace-cross 
Abstract: The widespread utilization of language models in modern applications is inconceivable without Parameter-Efficient Fine-Tuning techniques, such as low-rank adaptation ($\texttt{LoRA}$), which adds trainable adapters to selected layers. Although $\texttt{LoRA}$ may obtain accurate solutions, it requires significant memory to train large models and intuition on which layers to add adapters. In this paper, we propose a novel method, $\texttt{WeightLoRA}$, which overcomes this issue by adaptive selection of the most critical $\texttt{LoRA}$ heads throughout the optimization process. As a result, we can significantly reduce the number of trainable parameters while maintaining the capability to obtain consistent or even superior metric values. We conduct experiments for a series of competitive benchmarks and DeBERTa, BART, and Llama models, comparing our method with different adaptive approaches. The experimental results demonstrate the efficacy of $\texttt{WeightLoRA}$ and the superior performance of $\texttt{WeightLoRA+}$ in almost all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02724v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Veprikov, Vladimir Solodkin, Alexander Zyl, Andrey Savchenko, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization</title>
      <link>https://arxiv.org/abs/2506.03725</link>
      <description>arXiv:2506.03725v2 Announce Type: replace-cross 
Abstract: Quite recently, large language models have made a significant breakthrough across various disciplines. However, training them is an extremely resource-intensive task, even for major players with vast computing resources. One of the methods gaining popularity in light of these challenges is Sign-SGD. This method can be applied both as a memory-efficient approach in single-node training and as a gradient compression technique in the distributed learning. Nevertheless, it is impossible to automatically determine the effective stepsize from the theoretical standpoint. Indeed, it depends on the parameters of the dataset to which we do not have access in the real-world learning paradigm. To address this issue, we design several variants of single-node deterministic Sign-SGD. We extend our approaches to practical scenarios: stochastic single-node and multi-node learning, methods with incorporated momentum. We conduct extensive experiments on real machine learning problems that emphasize the practical applicability of our ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03725v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Sergey Stanko, Gleb Molodtsov, Philip Zmushko, Grigoriy Evseev, Egor Petrov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Online Multi-Agent Control with Adversarial Disturbances</title>
      <link>https://arxiv.org/abs/2506.18814</link>
      <description>arXiv:2506.18814v2 Announce Type: replace-cross 
Abstract: Online multi-agent control problems, where many agents pursue competing and time-varying objectives, are widespread in domains such as autonomous robotics, economics, and energy systems. In these settings, robustness to adversarial disturbances is critical. In this paper, we study online control in multi-agent linear dynamical systems subject to such disturbances. In contrast to most prior work in multi-agent control, which typically assumes noiseless or stochastically perturbed dynamics, we consider an online setting where disturbances can be adversarial, and where each agent seeks to minimize its own sequence of convex losses. Under two feedback models, we analyze online gradient-based controllers with local policy updates. We prove per-agent regret bounds that are sublinear and near-optimal in the time horizon and that highlight different scalings with the number of agents. When agents' objectives are aligned, we further show that the multi-agent control problem induces a time-varying potential game for which we derive equilibrium tracking guarantees. Together, our results take a first step in bridging online control with online learning in games, establishing robust individual and collective performance guarantees in dynamic continuous-state environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18814v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Barakat, John Lazarsfeld, Georgios Piliouras, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning</title>
      <link>https://arxiv.org/abs/2509.14198</link>
      <description>arXiv:2509.14198v2 Announce Type: replace-cross 
Abstract: Residual-based adaptive strategies are widely used in scientific machine learning but remain largely heuristic. We introduce a unifying variational framework that formalizes these methods by integrating convex transformations of the residual. Different transformations correspond to distinct objective functionals: exponential weights target the minimization of uniform error, while linear weights recover the minimization of quadratic error. Within this perspective, adaptive weighting is equivalent to selecting sampling distributions that optimize the primal objective, thereby linking discretization choices directly to error metrics. This principled approach yields three benefits: (1) it enables systematic design of adaptive schemes across norms, (2) reduces discretization error through variance reduction of the loss estimator, and (3) enhances learning dynamics by improving the gradient signal-to-noise ratio. Extending the framework to operator learning, we demonstrate substantial performance gains across optimizers and architectures. Our results provide a theoretical justification of residual-based adaptivity and establish a foundation for principled discretization and training strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14198v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Juan Diego Toscano, Daniel T. Chen, Vivek Oommen, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion</title>
      <link>https://arxiv.org/abs/2509.19767</link>
      <description>arXiv:2509.19767v2 Announce Type: replace-cross 
Abstract: Vector search powers transformers technology, but real-world use demands hybrid queries that combine vector similarity with attribute filters (e.g., "top document in category X, from 2023"). Current solutions trade off recall, speed, and flexibility, relying on fragile index hacks that don't scale. We introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric framework that elevates filtering to ANN optimization constraints and introduces a convex fused space via a Lagrangian-like relaxation. Our method jointly embeds attributes and vectors through transformer-based convexification, turning hard filters into continuous, weighted penalties that preserve top-k semantics while enabling efficient approximate search. We prove that FusedANN reduces to exact filtering under high selectivity, gracefully relaxes to semantically nearest attributes when exact matches are insufficient, and preserves downstream ANN alpha-approximation guarantees. Empirically, FusedANN improves query throughput by eliminating brittle filtering stages, achieving superior recall-latency tradeoffs on standard hybrid benchmarks without specialized index hacks, delivering up to 3 times higher throughput and better recall than state-of-the-art hybrid and graph-based systems. Theoretically, we provide explicit error bounds and parameter selection rules that make FusedANN practical for production. This establishes a principled, scalable, and verifiable bridge between symbolic constraints and vector similarity, unlocking a new generation of filtered retrieval systems for large, hybrid, and dynamic NLP/ML workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19767v2</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>math.OC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Heidari, Wei Zhang, Ying Xiong</dc:creator>
    </item>
    <item>
      <title>Data-driven Neural Networks for Windkessel Parameter Calibration</title>
      <link>https://arxiv.org/abs/2509.21206</link>
      <description>arXiv:2509.21206v2 Announce Type: replace-cross 
Abstract: In this work, we propose a novel method for calibrating Windkessel (WK) parameters in a dimensionally reduced 1D-0D coupled blood flow model. To this end, we design a data-driven neural network (NN)trained on simulated blood pressures in the left brachial artery. Once trained, the NN emulates the pressure pulse waves across the entire simulated domain, i.e., over time, space and varying WK parameters, with negligible error and computational effort. To calibrate the WK parameters on a measured pulse wave, the NN is extended by dummy neurons and retrained only on these. The main objective of this work is to assess the effectiveness of the method in various scenarios -- particularly, when the exact measurement location is unknown or the data are affected by noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21206v2</guid>
      <category>q-bio.TO</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedikt Hoock, Tobias K\"oppl</dc:creator>
    </item>
  </channel>
</rss>
