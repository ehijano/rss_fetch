<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Apr 2024 04:01:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>UAV-Assisted Enhanced Coverage and Capacity in Dynamic MU-mMIMO IoT Systems: A Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2404.06726</link>
      <description>arXiv:2404.06726v1 Announce Type: new 
Abstract: This study focuses on a multi-user massive multiple-input multiple-output (MU-mMIMO) system by incorporating an unmanned aerial vehicle (UAV) as a decode-and-forward (DF) relay between the base station (BS) and multiple Internet-of-Things (IoT) devices. Our primary objective is to maximize the overall achievable rate (AR) by introducing a novel framework that integrates joint hybrid beamforming (HBF) and UAV localization in dynamic MU-mMIMO IoT systems. Particularly, HBF stages for BS and UAV are designed by leveraging slow time-varying angular information, whereas a deep reinforcement learning (RL) algorithm, namely deep deterministic policy gradient (DDPG) with continuous action space, is developed to train the UAV for its deployment. By using a customized reward function, the RL agent learns an optimal UAV deployment policy capable of adapting to both static and dynamic environments. The illustrative results show that the proposed DDPG-based UAV deployment (DDPG-UD) can achieve approximately 99.5% of the sum-rate capacity achieved by particle swarm optimization (PSO)-based UAV deployment (PSO-UD), while requiring a significantly reduced runtime at approximately 68.50% of that needed by PSO-UD, offering an efficient solution in dynamic MU-mMIMO environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06726v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MohammadMahdi Ghadaksaz, Mobeen Mahmood, Tho Le-Ngoc</dc:creator>
    </item>
    <item>
      <title>Harnessing the Power of AI-Generated Content for Semantic Communication</title>
      <link>https://arxiv.org/abs/2404.06765</link>
      <description>arXiv:2404.06765v1 Announce Type: new 
Abstract: Semantic Communication (SemCom) is envisaged as the next-generation paradigm to address challenges stemming from the conflicts between the increasing volume of transmission data and the scarcity of spectrum resources. However, existing SemCom systems face drawbacks, such as low explainability, modality rigidity, and inadequate reconstruction functionality. Recognizing the transformative capabilities of AI-generated content (AIGC) technologies in content generation, this paper explores a pioneering approach by integrating them into SemCom to address the aforementioned challenges. We employ a three-layer model to illustrate the proposed AIGC-assisted SemCom (AIGC-SCM) architecture, emphasizing its clear deviation from existing SemCom. Grounded in this model, we investigate various AIGC technologies with the potential to augment SemCom's performance. In alignment with SemCom's goal of conveying semantic meanings, we also introduce the new evaluation methods for our AIGC-SCM system. Subsequently, we explore communication scenarios where our proposed AIGC-SCM can realize its potential. For practical implementation, we construct a detailed integration workflow and conduct a case study in a virtual reality image transmission scenario. The results demonstrate our ability to maintain a high degree of alignment between the reconstructed content and the original source information, while substantially minimizing the data volume required for transmission. These findings pave the way for further enhancements in communication efficiency and the improvement of Quality of Service. At last, we present future directions for AIGC-SCM studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06765v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiru Wang, Wanting Yang, Zehui Xiong, Yuping Zhao, Tony Q. S. Quek, Zhu Han</dc:creator>
    </item>
    <item>
      <title>The 'Sandwich' meta-framework for architecture agnostic deep privacy-preserving transfer learning for non-invasive brainwave decoding</title>
      <link>https://arxiv.org/abs/2404.06868</link>
      <description>arXiv:2404.06868v1 Announce Type: new 
Abstract: Machine learning has enhanced the performance of decoding signals indicating human behaviour. EEG decoding, as an exemplar indicating neural activity and human thoughts non-invasively, has been helpful in neural activity analysis and aiding patients via brain-computer interfaces. However, training machine learning algorithms on EEG encounters two primary challenges: variability across data sets and privacy concerns using data from individuals and data centres. Our objective is to address these challenges by integrating transfer learning for data variability and federated learning for data privacy into a unified approach. We introduce the Sandwich as a novel deep privacy-preserving meta-framework combining transfer learning and federated learning. The Sandwich framework comprises three components: federated networks (first layers) that handle data set differences at the input level, a shared network (middle layer) learning common rules and applying transfer learning, and individual classifiers (final layers) for specific tasks of each data set. It enables the central network (central server) to benefit from multiple data sets, while local branches (local servers) maintain data and label privacy. We evaluated the `Sandwich' meta-architecture in various configurations using the BEETL motor imagery challenge, a benchmark for heterogeneous EEG data sets. Compared with baseline models, our `Sandwich' implementations showed superior performance. The best-performing model, the Inception Sandwich with deep set alignment (Inception-SD-Deepset), exceeded baseline methods by 9%. The `Sandwich' framework demonstrates significant advancements in federated deep transfer learning for diverse tasks and data sets. It outperforms conventional deep learning methods, showcasing the potential for effective use of larger, heterogeneous data sets with enhanced privacy as a model-agnostic meta-framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06868v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxi Wei, Jyotindra Narayan, A. Aldo Faisal</dc:creator>
    </item>
    <item>
      <title>Performance Bounds for Near-Field Multi-Antenna Range Estimation of Extended Targets</title>
      <link>https://arxiv.org/abs/2404.06949</link>
      <description>arXiv:2404.06949v1 Announce Type: new 
Abstract: In this paper, performance bounds for the multi-antenna near-field range estimation of extended targets are provided. First, analytic expressions of the ambiguity functions are obtained, emphasising the cooperation between the classical waveform delay, and the near-field phase shift information. The impact of estimating the range of an extended target with a point target model is analysed, showing that a model mismatch leads to severe performance degradation in the near-field region. Secondly, Cramer-Rao bounds are developed till expressions in which the parameters' impact is emphasised, namely the carrier frequency, the waveform central frequency and root-mean-square bandwidth. The near-field range information is shown to depend on the root-mean-square value of the propagation delay derivatives, this value scaling with the fourth power of the ratio between the antenna array dimension and the target range.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06949v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Thiran, Fran\c{c}ois De Saint Moulin, Claude Oestges, Luc Vandendorpe</dc:creator>
    </item>
    <item>
      <title>A 4x32Gb/s 1.8pJ/bit Collaborative Baud-Rate CDR with Background Eye-Climbing Algorithm and Low-Power Global Clock Distribution</title>
      <link>https://arxiv.org/abs/2404.07021</link>
      <description>arXiv:2404.07021v1 Announce Type: new 
Abstract: This paper presents design techniques for an energy-efficient multi-lane receiver (RX) with baud-rate clock and data recovery (CDR), which is essential for high-throughput low-latency communication in high-performance computing systems. The proposed low-power global clock distribution not only significantly reduces power consumption across multi-lane RXs but is capable of compensating for the frequency offset without any phase interpolators. To this end, a fractional divider controlled by CDR is placed close to the global phase locked loop. Moreover, in order to address the sub-optimal lock point of conventional baud-rate phase detectors, the proposed CDR employs a background eye-climbing algorithm, which optimizes the sampling phase and maximizes the vertical eye margin (VEM). Fabricated in a 28nm CMOS process, the proposed 4x32Gb/s RX shows a low integrated fractional spur of -40.4dBc at a 2500ppm frequency offset. Furthermore, it improves bit-error-rate performance by increasing the VEM by 17%. The entire RX achieves the energy efficiency of 1.8pJ/bit with the aggregate data rate of 128Gb/s.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07021v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihee Kim, Jia Park, Jiwon Shin, Hanseok Kim, Kahyun Kim, Haengbeom Shin, Ha-Jung Park, Woo-Seok Choi</dc:creator>
    </item>
    <item>
      <title>Secrecy Enhancement for UAV-enabled Integrated Sensing and Communication System</title>
      <link>https://arxiv.org/abs/2404.07024</link>
      <description>arXiv:2404.07024v1 Announce Type: new 
Abstract: In this correspondence, we propose an unmanned aerial vehicle (UAV)-enabled integrated sensing and communication (ISAC) system, where a full-duplex UAV equipped with uniform planar array (UPA) is adopted as a base station for the multiuser downlink communications, while sensing and jamming a passive ground eavesdropper. The goal of this work is to maximize the sum secrecy rate of ground users subject to the constraints of sensing accuracy and UAV's operational capability by jointly optimizing the transceiver beamforming and UAV's trajectory. To this end, we develop the algorithmic solution based on block coordinate descent (BCD) and semidefinite programming (SDP) relaxation techniques, whose performance is verified via simulations indicating its efficacy in improving communication security with the sufficient mission period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07024v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaedam Son, Seongah Jeong</dc:creator>
    </item>
    <item>
      <title>Net 835-Gb/s/{\lambda} Carrier- and LO-Free 100-km Transmission Using Channel-Aware Phase Retrieval Reception</title>
      <link>https://arxiv.org/abs/2404.07092</link>
      <description>arXiv:2404.07092v1 Announce Type: new 
Abstract: We experimentally demonstrate the first carrier- and LO-free 800G/{\lambda} receiver enabling direct compatibility with standard coherent transmitters via phase retrieval, achieving net 835-Gb/s transmission over 100-km SMF and record 8.27-b/s/Hz net optical spectral efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07092v1</guid>
      <category>eess.SP</category>
      <category>physics.optics</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanzi Huang, Haoshuo Chen, Qian Hu, Di Che, Yetian Huang, Brian Stern, Nicolas K. Fontaine, Mikael Mazur, Lauren Dallachiesa, Roland Ryf, Zhengxuan Li, Yingxiong Song</dc:creator>
    </item>
    <item>
      <title>Topological Feature Search Method for Multichannel EEG: Application in ADHD classification</title>
      <link>https://arxiv.org/abs/2404.06676</link>
      <description>arXiv:2404.06676v1 Announce Type: cross 
Abstract: In recent years, the preliminary diagnosis of Attention Deficit Hyperactivity Disorder (ADHD) using electroencephalography (EEG) has garnered attention from researchers. EEG, known for its expediency and efficiency, plays a pivotal role in the diagnosis and treatment of ADHD. However, the non-stationarity of EEG signals and inter-subject variability pose challenges to the diagnostic and classification processes. Topological Data Analysis (TDA) offers a novel perspective for ADHD classification, diverging from traditional time-frequency domain features. Yet, conventional TDA models are restricted to single-channel time series and are susceptible to noise, leading to the loss of topological features in persistence diagrams.This paper presents an enhanced TDA approach applicable to multi-channel EEG in ADHD. Initially, optimal input parameters for multi-channel EEG are determined. Subsequently, each channel's EEG undergoes phase space reconstruction (PSR) followed by the utilization of k-Power Distance to Measure (k-PDTM) for approximating ideal point clouds. Then, multi-dimensional time series are re-embedded, and TDA is applied to obtain topological feature information. Gaussian function-based Multivariate Kernel Density Estimation (MKDE) is employed in the merger persistence diagram to filter out desired topological feature mappings. Finally, persistence image (PI) method is utilized to extract topological features, and the influence of various weighting functions on the results is discussed.The effectiveness of our method is evaluated using the IEEE ADHD dataset. Results demonstrate that the accuracy, sensitivity, and specificity reach 85.60%, 83.61%, and 88.33%, respectively. Compared to traditional TDA methods, our method was effectively improved and outperforms typical nonlinear descriptors. These findings indicate that our method exhibits higher precision and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06676v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianming Cai, Guoying Zhao, Junbin Zang, Chen Zong, Zhidong Zhang, Chenyang Xue</dc:creator>
    </item>
    <item>
      <title>What is Learnt by the LEArnable Front-end (LEAF)? Adapting Per-Channel Energy Normalisation (PCEN) to Noisy Conditions</title>
      <link>https://arxiv.org/abs/2404.06702</link>
      <description>arXiv:2404.06702v1 Announce Type: cross 
Abstract: There is increasing interest in the use of the LEArnable Front-end (LEAF) in a variety of speech processing systems. However, there is a dearth of analyses of what is actually learnt and the relative importance of training the different components of the front-end. In this paper, we investigate this question on keyword spotting, speech-based emotion recognition and language identification tasks and find that the filters for spectral decomposition and the low pass filter used to estimate spectral energy variations exhibit no learning and the per-channel energy normalisation (PCEN) is the key component that is learnt. Following this, we explore the potential of adapting only the PCEN layer with a small amount of noisy data to enable it to learn appropriate dynamic range compression that better suits the noise conditions. This in turn enables a system trained on clean speech to work more accurately on noisy test data as demonstrated by the experimental results reported in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06702v1</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21437/Interspeech.2023-1617</arxiv:DOI>
      <arxiv:journal_reference>Interspeech 2023</arxiv:journal_reference>
      <dc:creator>Hanyu Meng, Vidhyasaharan Sethu, Eliathamby Ambikairajah</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Channel Estimation for Dense Array Systems</title>
      <link>https://arxiv.org/abs/2404.06806</link>
      <description>arXiv:2404.06806v1 Announce Type: cross 
Abstract: By deploying a large number of antennas with sub-half-wavelength spacing in a compact space, dense array systems(DASs) can fully unleash the multiplexing-and-diversity gains of limited apertures. To acquire these gains, accurate channel state information acquisition is necessary but challenging due to the large antenna numbers. To overcome this obstacle, this paper reveals that exploiting the high spatial correlation of DAS channels is crucial while designing the observation matrix for optimal/near-optimal channel estimation. Firstly, we prove that the observation matrix design is equivalent to a time-domain duality of multiple-input multiple-output precoding, which can be ideally addressed by the water-filling principle. For practical realizations, a novel ice-filling algorithm is proposed to design amplitude-and-phase controllable observation matrices, and a majorization-minimization algorithm is proposed to address the phase-only controllable case. Particularly, we prove that the ice-filling algorithm can be viewed as a ``quantized" water-filling algorithm. To support the sub-optimality of the proposed designs, we provide comprehensive analyses on the achievable mean square errors and their asymptotic expressions. Finally, numerical simulations verify that our proposed channel estimation designs can achieve the near-optimal performance and outperform existing approaches significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06806v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mingyao Cui, Zijian Zhang, Linglong Dai, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>EMF Mitigation via 5G and 6G MAC Scheduling</title>
      <link>https://arxiv.org/abs/2404.06830</link>
      <description>arXiv:2404.06830v1 Announce Type: cross 
Abstract: High antenna directivity allows for high throughput transmission but also increases the exposure to electromagnetic field (EMF) of the end-users. Health regulations impose limitations on the incident power density, that generate a negative impact on network performance. In this work we focus at the slot-by-slot operations of a cellular Medium Access Control (MAC) scheduler to constrain the short-term EMF exposure upon real-time resource allocation, minimizing the impacts on network performance. We assume that the long-term EMF exposure is controlled by a proper outer-loop technique, that is not the object of this paper. Due to the minimal computational complexity allowed in MAC scheduling, existing solutions allowing practical implementation are few and focused at sub-optimal approaches curbing radio resource allocation. Our contribution is the derivation of a computationally efficient water-filling solution to allocate power and - then - resources, with a feasible integration of the necessary algorithms in the operations of a 5G MAC scheduler. We finally evaluate our proposal versus the prior art approaches with system level simulations with realistic modeling of physical and MAC level cellular procedures. We conclude that our proposal can control EMF with considerable less impact on network performance, making it a standout candidate for 5G and future 6G MAC scheduler implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06830v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Silvio Mandelli, Lorenzo Maggi, Bill Zheng, Christophe Grangeat, Azra Zejnilagic</dc:creator>
    </item>
    <item>
      <title>SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography</title>
      <link>https://arxiv.org/abs/2404.06869</link>
      <description>arXiv:2404.06869v1 Announce Type: cross 
Abstract: Background: Sleep staging is a fundamental component in the diagnosis of sleep disorders and the management of sleep health. Traditionally, this analysis is conducted in clinical settings and involves a time-consuming scoring procedure. Recent data-driven algorithms for sleep staging, using the photoplethysmogram (PPG) time series, have shown high performance on local test sets but lower performance on external datasets due to data drift. Methods: This study aimed to develop a generalizable deep learning model for the task of four class (wake, light, deep, and rapid eye movement (REM)) sleep staging from raw PPG physiological time-series. Six sleep datasets, totaling 2,574 patients recordings, were used. In order to create a more generalizable representation, we developed and evaluated a deep learning model called SleepPPG-Net2, which employs a multi-source domain training approach.SleepPPG-Net2 was benchmarked against two state-of-the-art models. Results: SleepPPG-Net2 showed consistently higher performance over benchmark approaches, with generalization performance (Cohen's kappa) improving by up to 19%. Performance disparities were observed in relation to age, sex, and sleep apnea severity. Conclusion: SleepPPG-Net2 sets a new standard for staging sleep from raw PPG time-series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06869v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shirel Attia, Revital Shani Hershkovich, Alissa Tabakhov, Angeleene Ang, Sharon Haimov, Riva Tauman, Joachim A. Behar</dc:creator>
    </item>
    <item>
      <title>Joint Active And Passive IRS Aided Wireless Communication: Elements Allocation and Achievable Rate</title>
      <link>https://arxiv.org/abs/2404.06880</link>
      <description>arXiv:2404.06880v1 Announce Type: cross 
Abstract: Equipping reflecting elements at the active intelligent reflecting surface (AIRS) enhances signal amplification capability but meanwhile incurs non-negligible amplification noise, which thus challenges the determination of elements allocation for maximizing achievable rate in multi-cooperative AIRS and passive IRS (PIRS) jointly aided wireless communication system. To tackle this issue, we consider the downlink communication from a single-antenna transmitter (Tx) to a single-antenna receiver (Rx), which aided by a pair of AIRS and PIRS with two different deployment orders. Specifically, we target to determine the number of AIRS/PIRS elements over both transmission orders under given deployment budget for the achievable rate maximization. Our analysis illustrates that the PIRS should be allocated more elements than the AIRS for achieving optimized rate and linear signal-to-noise ratio (SNR) scaling orders are attained in both schemes. Simulation results are provided to evaluate the proposed algorithm and compare the rate performance of the AIRS and PIRS jointly aided wireless system with various benchmark systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06880v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoying Huang, Wen Chen, Qingqing Wu</dc:creator>
    </item>
    <item>
      <title>Are EEG Sequences Time Series? EEG Classification with Time Series Models and Joint Subject Training</title>
      <link>https://arxiv.org/abs/2404.06966</link>
      <description>arXiv:2404.06966v1 Announce Type: cross 
Abstract: As with most other data domains, EEG data analysis relies on rich domain-specific preprocessing. Beyond such preprocessing, machine learners would hope to deal with such data as with any other time series data. For EEG classification many models have been developed with layer types and architectures we typically do not see in time series classification. Furthermore, typically separate models for each individual subject are learned, not one model for all of them. In this paper, we systematically study the differences between EEG classification models and generic time series classification models. We describe three different model setups to deal with EEG data from different subjects, subject-specific models (most EEG literature), subject-agnostic models and subject-conditional models. In experiments on three datasets, we demonstrate that off-the-shelf time series classification models trained per subject perform close to EEG classification models, but that do not quite reach the performance of domain-specific modeling. Additionally, we combine time-series models with subject embeddings to train one joint subject-conditional classifier on all subjects. The resulting models are competitive with dedicated EEG models in 2 out of 3 datasets, even outperforming all EEG methods on one of them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06966v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Burchert, Thorben Werner, Vijaya Krishna Yalavarthi, Diego Coello de Portugal, Maximilian Stubbemann, Lars Schmidt-Thieme</dc:creator>
    </item>
    <item>
      <title>Learned Finite-Time Consensus for Distributed Optimization</title>
      <link>https://arxiv.org/abs/2404.07018</link>
      <description>arXiv:2404.07018v1 Announce Type: cross 
Abstract: Most algorithms for decentralized learning employ a consensus or diffusion mechanism to drive agents to a common solution of a global optimization problem. Generally this takes the form of linear averaging, at a rate of contraction determined by the mixing rate of the underlying network topology. For very sparse graphs this can yield a bottleneck, slowing down the convergence of the learning algorithm. We show that a sequence of matrices achieving finite-time consensus can be learned for unknown graph topologies in a decentralized manner by solving a constrained matrix factorization problem. We demonstrate numerically the benefit of the resulting scheme in both structured and unstructured graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07018v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Fainman, Stefan Vlaski</dc:creator>
    </item>
    <item>
      <title>On the Performance of IRS-Assisted SSK and RPM over Rician Fading Channels</title>
      <link>https://arxiv.org/abs/2404.07044</link>
      <description>arXiv:2404.07044v1 Announce Type: cross 
Abstract: This paper presents the index modulation, that is, the space-shift keying (SSK) and reflection phase modulation (RPM) schemes for intelligent reflecting surface (IRS)-assisted wireless network. IRS simultaneously reflects the incoming information signal from the base station and explicitly encodes the local information bits in the reflection phase shift of IRS elements. The phase shift of the IRS elements is employed according to local data from the RPM constellation. A joint detection using a maximum-likelihood (ML) decoder is performed for the SSK and RPM symbols over a realistic fading scenario modeled as the Rician fading channel. The pairwise error probability over Rician fading channels is derived and utilized to determine the average bit error rate. In addition, the ergodic capacity of the presented system is derived. The derived analytical results are verified and are in exact agreement with Monte-Carlo simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07044v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harsh Raj, Ugrasen Singh, B. R. Manoj</dc:creator>
    </item>
    <item>
      <title>A New Statistic for Testing Covariance Equality in High-Dimensional Gaussian Low-Rank Models</title>
      <link>https://arxiv.org/abs/2404.07100</link>
      <description>arXiv:2404.07100v1 Announce Type: cross 
Abstract: In this paper, we consider the problem of testing equality of the covariance matrices of L complex Gaussian multivariate time series of dimension $M$ . We study the special case where each of the L covariance matrices is modeled as a rank K perturbation of the identity matrix, corresponding to a signal plus noise model. A new test statistic based on the estimates of the eigenvalues of the different covariance matrices is proposed. In particular, we show that this statistic is consistent and with controlled type I error in the high-dimensional asymptotic regime where the sample sizes $N_1,\ldots,N_L$ of each time series and the dimension $M$ both converge to infinity at the same rate, while $K$ and $L$ are kept fixed. We also provide some simulations on synthetic and real data (SAR images) which demonstrate significant improvements over some classical methods such as the GLRT, or other alternative methods relevant for the high-dimensional regime and the low-rank model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07100v1</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2024.3382476</arxiv:DOI>
      <dc:creator>R\'emi Beisson, Pascal Vallet, Audrey Giremus, Guillaume Ginolhac</dc:creator>
    </item>
    <item>
      <title>Digital Over-the-Air Computation: Achieving High Reliability via Bit-Slicing</title>
      <link>https://arxiv.org/abs/2404.07121</link>
      <description>arXiv:2404.07121v1 Announce Type: cross 
Abstract: 6G mobile networks aim to realize ubiquitous intelligence at the network edge via distributed learning, sensing, and data analytics. Their common operation is to aggregate high-dimensional data, which causes a communication bottleneck that cannot be resolved using traditional orthogonal multi-access schemes. A promising solution, called over-the-air computation (AirComp), exploits channels' waveform superposition property to enable simultaneous access, thereby overcoming the bottleneck. Nevertheless, its reliance on uncoded linear analog modulation exposes data to perturbation by noise and interference. Hence, the traditional analog AirComp falls short of meeting the high-reliability requirement for 6G. Overcoming the limitation of analog AirComp motivates this work, which focuses on developing a framework for digital AirComp. The proposed framework features digital modulation of each data value, integrated with the bit-slicing technique to allocate its bits to multiple symbols, thereby increasing the AirComp reliability. To optimally detect the aggregated digital symbols, we derive the optimal maximum a posteriori detector that is shown to outperform the traditional maximum likelihood detector. Furthermore, a comparative performance analysis of digital AirComp with respect to its analog counterpart with repetition coding is conducted to quantify the practical signal-to-noise ratio (SNR) regime favoring the proposed scheme. On the other hand, digital AirComp is enhanced by further development to feature awareness of heterogeneous bit importance levels and its exploitation in channel adaptation. Lastly, simulation results demonstrate the achivability of substantial reliability improvement of digital AirComp over its analog counterpart given the same channel uses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07121v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Liu, Yi Gong, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Compressed Gradient Tracking for Decentralized Optimization Over General Directed Networks</title>
      <link>https://arxiv.org/abs/2106.07243</link>
      <description>arXiv:2106.07243v4 Announce Type: replace-cross 
Abstract: In this paper, we propose two communication efficient decentralized optimization algorithms over a general directed multi-agent network. The first algorithm, termed Compressed Push-Pull (CPP), combines the gradient tracking Push-Pull method with communication compression. We show that CPP is applicable to a general class of unbiased compression operators and achieves linear convergence rate for strongly convex and smooth objective functions. The second algorithm is a broadcast-like version of CPP (B-CPP), and it also achieves linear convergence rate under the same conditions on the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further reduce communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.07243v4</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2022.3160238</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, 70(2022), 1775-1787</arxiv:journal_reference>
      <dc:creator>Zhuoqing Song, Lei Shi, Shi Pu, Ming Yan</dc:creator>
    </item>
    <item>
      <title>A Federated Data Fusion-Based Prognostic Model for Applications with Multi-Stream Incomplete Signals</title>
      <link>https://arxiv.org/abs/2311.07474</link>
      <description>arXiv:2311.07474v2 Announce Type: replace-cross 
Abstract: Most prognostic methods require a decent amount of data for model training. In reality, however, the amount of historical data owned by a single organization might be small or not large enough to train a reliable prognostic model. To address this challenge, this article proposes a federated prognostic model that allows multiple users to jointly construct a failure time prediction model using their multi-stream, high-dimensional, and incomplete data while keeping each user's data local and confidential. The prognostic model first employs multivariate functional principal component analysis to fuse the multi-stream degradation signals. Then, the fused features coupled with the times-to-failure are utilized to build a (log)-location-scale regression model for failure prediction. To estimate parameters using distributed datasets and keep the data privacy of all participants, we propose a new federated algorithm for feature extraction. Numerical studies indicate that the performance of the proposed model is the same as that of classic non-federated prognostic models and is better than that of the models constructed by each user itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07474v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Madi Arabi, Xiaolei Fang</dc:creator>
    </item>
    <item>
      <title>Data-driven Semi-supervised Machine Learning with Surrogate Safety Measures for Abnormal Driving Behavior Detection</title>
      <link>https://arxiv.org/abs/2312.04610</link>
      <description>arXiv:2312.04610v2 Announce Type: replace-cross 
Abstract: Detecting abnormal driving behavior is critical for road traffic safety and the evaluation of drivers' behavior. With the advancement of machine learning (ML) algorithms and the accumulation of naturalistic driving data, many ML models have been adopted for abnormal driving behavior detection. Most existing ML-based detectors rely on (fully) supervised ML methods, which require substantial labeled data. However, ground truth labels are not always available in the real world, and labeling large amounts of data is tedious. Thus, there is a need to explore unsupervised or semi-supervised methods to make the anomaly detection process more feasible and efficient. To fill this research gap, this study analyzes large-scale real-world data revealing several abnormal driving behaviors (e.g., sudden acceleration, rapid lane-changing) and develops a Hierarchical Extreme Learning Machines (HELM) based semi-supervised ML method using partly labeled data to accurately detect the identified abnormal driving behaviors. Moreover, previous ML-based approaches predominantly utilize basic vehicle motion features (such as velocity and acceleration) to label and detect abnormal driving behaviors, while this study seeks to introduce Surrogate Safety Measures (SSMs) as the input features for ML models to improve the detection performance. Results from extensive experiments demonstrate the effectiveness of the proposed semi-supervised ML model with the introduced SSMs serving as important features. The proposed semi-supervised ML method outperforms other baseline semi-supervised or unsupervised methods regarding various metrics, e.g., delivering the best accuracy at 99.58% and the best F-1 measure at 0.9913. The ablation study further highlights the significance of SSMs for advancing detection performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04610v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>stat.OT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lanxin Zhang, Yongqi Dong, Haneen Farah, Arkady Zgonnikov, Bart van Arem</dc:creator>
    </item>
    <item>
      <title>Social Learning in Community Structured Graphs</title>
      <link>https://arxiv.org/abs/2312.12186</link>
      <description>arXiv:2312.12186v2 Announce Type: replace-cross 
Abstract: Traditional social learning frameworks consider environments with a homogeneous state, where each agent receives observations conditioned on that true state of nature. In this work, we relax this assumption and study the distributed hypothesis testing problem in a heterogeneous environment, where each agent can receive observations conditioned on their own personalized state of nature (or truth). We particularly focus on community structured networks, where each community admits their own true hypothesis. This scenario is common in various contexts, such as when sensors are spatially distributed, or when individuals in a social network have differing views or opinions. We show that the adaptive social learning strategy is a preferred choice for nonstationary environments, and allows each cluster to discover its own truth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12186v2</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Shumovskaia, Mert Kayaalp, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Chebyshev and The Fast Fourier Transform Methods for Signal Interpolation</title>
      <link>https://arxiv.org/abs/2404.00414</link>
      <description>arXiv:2404.00414v2 Announce Type: replace-cross 
Abstract: Approximation theorem is one of the most important aspects of numerical analysis that has evolved over the years with many different approaches. Some of the most popular approximation methods include the Lebesgue approximation theorem, the Weierstrass approximation, and the Fourier approximation theorem. The limitations associated with various approximation methods are too crucial to ignore, and thus, the nature of a specific dataset may require using a specific approximation method for such estimates. In this report, we shall delve into Chebyshev's polynomials interpolation in detail as an alternative approach to reconstructing signals and compare the reconstruction to that of the Fourier polynomials. We will also explore the advantages and limitations of the Chebyshev polynomials and discuss in detail their mathematical formulation and equivalence to the cosine function over a given interval [a, b].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00414v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ishmael N. Amartey</dc:creator>
    </item>
  </channel>
</rss>
