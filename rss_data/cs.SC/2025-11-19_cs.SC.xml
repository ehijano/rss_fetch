<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 02:42:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Structuring Definitions in Mathematical Libraries</title>
      <link>https://arxiv.org/abs/2509.10828</link>
      <description>arXiv:2509.10828v2 Announce Type: replace 
Abstract: Codifying mathematical theories in a proof assistant or computer algebra system is a challenging task, of which the most difficult part is, counterintuitively, structuring definitions. This results in a steep learning curve for new users and slow progress in formalizing even undergraduate level mathematics. There are many considerations one has to make, such as level of generality, readability, and ease of use in the type system, and there are typically multiple equivalent or related definitions from which to choose. Often, a definition that is ultimately selected for formalization is settled on after a lengthy trial and error process. This process involves testing potential definitions for usability by formalizing standard theorems about them, and weeding out the definitions that are unwieldy.
  Inclusion of a formal definition in a centralized community-run mathematical library is typically an indication that the definition is "good." For this reason, in this survey, we make some observations about what makes a definition "good," and examine several case studies of the refining process for definitions that have ultimately been added to the Lean Theorem Prover community-run mathematical library, mathlib. We observe that some of the difficulties are shared with the design of libraries for computer algebra systems, and give examples of related issues in that context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10828v2</guid>
      <category>cs.SC</category>
      <category>cs.LO</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alena Gusakov, Peter Nelson, Stephen Watt</dc:creator>
    </item>
    <item>
      <title>Fast polynomial computations with space constraints</title>
      <link>https://arxiv.org/abs/2511.11267</link>
      <description>arXiv:2511.11267v2 Announce Type: replace 
Abstract: The works presented in this habilitation concern the algorithmics of polynomials. This is a central topic in computer algebra, with numerous applications both within and outside the field - cryptography, error-correcting codes, etc. For many problems, extremely efficient algorithms have been developed since the 1960s. Here, we are interested in how this efficiency is affected when space constraints are introduced.
  The first part focuses on the time-space complexity of fundamental polynomial computations - multiplication, division, interpolation, ... While naive algorithms typically have constant space complexity, fast algorithms generally require linear space. We develop algorithms that are both time- and space-efficient. This leads us to discuss and refine definitions of space complexity for function computation.
  In the second part, the space constraints are put on the inputs and outputs. Algorithms for polynomials assume in general a dense representation for the polynomials, that is storing the full list of coefficients. In contrast, we work with sparse polynomials, in which most coefficients vanish. In particular, we describe the first quasi-linear algorithm for sparse interpolation, which plays a role analogous to the Fast Fourier Transform in the sparse settings. We also explore computationally hard problems concerning divisibility and factorization of sparse polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11267v2</guid>
      <category>cs.SC</category>
      <category>cs.CC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bruno Grenet</dc:creator>
    </item>
    <item>
      <title>Optimal Communication Unbalanced Private Set Union</title>
      <link>https://arxiv.org/abs/2402.16393</link>
      <description>arXiv:2402.16393v4 Announce Type: replace-cross 
Abstract: We present new two-party protocols for the Unbalanced Private Set Union (UPSU) problem. Here, the Sender holds a set of data points, and the Receiver holds another (possibly much larger) set, and they would like for the Receiver to learn the union of the two sets and nothing else. Furthermore, the Sender's computational cost, along with the communication complexity, should be smaller when the Sender has a smaller set. While the UPSU problem has numerous applications and has seen considerable recent attention in the literature, our protocols are the first where the Sender's computational cost and communication volume are linear in the size of the Sender's set only, and do not depend on the size of the Receiver's set. Our constructions combine linearly homomorphic encryption (LHE) with fully homomorphic encryption (FHE). The first construction uses multi-point polynomial evaluation (MEv) on FHE, and achieves optimal linear cost for the Sender, but has higher quadratic computational cost for the Receiver. In the second construction we explore another trade-off: the Receiver computes fast polynomial Euclidean remainder in FHE while the Sender computes a fast MEv, in LHE only. This reduces the Receiver's cost to quasi-linear, with a modest increase in the computational cost for the Sender. Preliminary experimental results using HElib indicate that, for example, a Sender holding 1000 elements can complete our first protocol using less than 2s of computation time and less than 10MB of communication volume, independently of the Receiver's set size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16393v4</guid>
      <category>cs.CR</category>
      <category>cs.SC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>23rd International Conference on Applied Cryptography and Network Security, Jun 2025, Munich, Germany. pp.107-135</arxiv:journal_reference>
      <dc:creator>Jean-Guillaume Dumas (CASC, UGA, LJK), Alexis Galan (CASC, UGA), Bruno Grenet (CASC), Aude Maignan (CASC), Daniel S. Roche</dc:creator>
    </item>
  </channel>
</rss>
