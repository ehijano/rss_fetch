<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Mar 2025 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Operational route planning under uncertainty for Demand Adaptive Systems</title>
      <link>https://arxiv.org/abs/2503.07812</link>
      <description>arXiv:2503.07812v1 Announce Type: new 
Abstract: With an increasing need for more flexible mobility services, we consider an operational problem arising in the planning of Demand Adaptive Systems (DAS). Motivated by the decision of whether to accept or reject passenger requests in real time in a DAS, we introduce the operational route planning problem of DASs. To this end, we propose an algorithmic framework that allows an operator to plan which passengers to serve in a DAS in real-time. To do so, we model the operational route planning problem as a Markov decision process (MDP) and utilize a rolling horizon approach to approximate the MDP via a two-stage stochastic program in each timestep to decide on the next action. Furthermore, we determine the deterministic equivalent of our approximation through sample-based approximation. This allows us to decompose the deterministic equivalent of our two-stage stochastic program into several full information planning problems, which can be solved in parallel efficiently. Additionally, we propose a consensus-based heuristic and a myopic approach. We perform extensive numerical studies based on real-world data provided to us by the public transportation provider of Munich, Germany. We show that our exact decomposition yields the best results in under five seconds, and our heuristic approach reduces the serial computation time by 17 - 57% compared to our exact decomposition, with a solution quality decline of less than one percent. From a managerial perspective, we show that by switching a fixed-line bus route to a DAS, an operator can increase profit by up to 49% and the number of served passengers by up to 35% while only increasing the travel distance of the bus by 14%. Furthermore, we show that an operator can reduce their cost per passenger by 43 - 51% by increasing route flexibility and that incentivizing passengers to walk slightly longer distances reduces the cost per passenger by 83-85%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07812v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedikt Lienkamp, Mike Hewitt, Axel Parmentier, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>Whiteness-based bilevel estimation of weighted TV parameter maps for image denoising</title>
      <link>https://arxiv.org/abs/2503.07814</link>
      <description>arXiv:2503.07814v1 Announce Type: new 
Abstract: We consider a bilevel optimisation strategy based on normalised residual whiteness loss for estimating the weighted total variation parameter maps for denoising images corrupted by additive white Gaussian noise. Compared to supervised and semi-supervised approaches relying on prior knowledge of (approximate) reference data and/or information on the noise magnitude, the proposal is fully unsupervised. To avoid noise overfitting an early stopping strategy is used, relying on simple statistics of optimal performances on a set of natural images. Numerical results comparing the supervised/unsupervised procedures for scalar/pixel-dependent \mbox{parameter maps are shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07814v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Monica Pragliola, Luca Calatroni, Alessandro Lanza</dc:creator>
    </item>
    <item>
      <title>Extension of Controllability Score to Infinite-Dimensional Systems</title>
      <link>https://arxiv.org/abs/2503.08011</link>
      <description>arXiv:2503.08011v1 Announce Type: new 
Abstract: Centrality analysis in dynamical network systems is essential for understanding system behavior. In finite-dimensional settings, controllability scores -- namely, the Volumetric Controllability Score (VCS) and the Average Energy Controllability Score (AECS) -- are defined as the unique solutions of specific optimization problems. In this work, we extend these concepts to infinite-dimensional systems by formulating analogous optimization problems. Moreover, we prove that these optimization problems have optimal solutions under weak assumptions, and that both VCS and AECS remain unique in the infinite-dimensional context under appropriate assumptions. The uniqueness of the controllability scores is essential to use them as a centrality measure, since it not only reflects the importance of each state in the dynamical network but also provides a consistent basis for interpretation and comparison across different researchers. Finally, we illustrate the behavior of VCS and AECS with a numerical experiment based on the heat equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08011v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuito Nakabe, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Observer-Based Output-Feedback Backstepping Stabilization of Continua of Hyperbolic PDEs and Application to Large-Scale $n+m$ Coupled Hyperbolic PDEs</title>
      <link>https://arxiv.org/abs/2503.08209</link>
      <description>arXiv:2503.08209v1 Announce Type: new 
Abstract: We develop a non-collocated, observer-based output-feedback law for a class of continua of linear hyperbolic PDE systems, which are viewed as the continuum version of $n+m$, general heterodirectional hyperbolic systems as $n\to\infty$. The design relies on the introduction of a novel, continuum PDE backstepping transformation, which enables the construction of a Lyapunov functional for the estimation error system. Stability under the observer-based output-feedback law is established by using the Lyapunov functional construction for the estimation error system and proving well-posedness of the complete closed-loop system, which allows utilization of the separation principle.
  Motivated by the fact that the continuum-based designs may provide computationally tractable control laws for large-scale, $n+m$ systems, we then utilize the control/observer kernels and the observer constructed for the continuum system to introduce an output-feedback control design for the original $n+m$ system. We establish exponential stability of the resulting closed-loop system, which consists of a mixed $n+m$-continuum PDE system (comprising the plant-observer dynamics), introducing a virtual continuum system with resets, which enables utilization of the continuum approximation property of the solutions of the $n+m$ system by its continuum counterpart (for large $n$). We illustrate the potential computational complexity/flexibility benefits of our approach via a numerical example of stabilization of a large-scale $n+m$ system, for which we employ the continuum observer-based controller, while the continuum-based stabilizing control/observer kernels can be computed in closed form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08209v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis</dc:creator>
    </item>
    <item>
      <title>Upper and Lower Bounds for a Class of Constrained Linear Time-Varying Games</title>
      <link>https://arxiv.org/abs/2503.08310</link>
      <description>arXiv:2503.08310v1 Announce Type: new 
Abstract: This paper develops an algorithm for upper- and lower-bounding the value function for a class of linear time-varying games subject to convex control sets. In particular, a two-player zero-sum differential game is considered where the respective players aim to minimise and maximise a convex terminal state cost. A collection of solutions of a single-player dynamical system subject to a trimmed control set is used to characterise a viscosity supersolution of a Hamilton-Jacobi (HJ) equation, which in turn yields an upper bound for the value function. Analogously, a collection of hyperplanes is used to characterise a viscosity subsolution of the HJ equation, which yields a lower bound. The computational complexity and memory requirement of the proposed algorithm scales with the number of solutions and hyperplanes that characterise the bounds, which is not explicitly tied to the number of system states. Thus, the algorithm is tractable for systems of moderately high dimension whilst preserving rigorous guarantees for optimal control and differential game applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08310v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Liu, Chris Manzie, Peter M. Dower</dc:creator>
    </item>
    <item>
      <title>A Dual Koopman Approach to Observer Design for Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2503.08345</link>
      <description>arXiv:2503.08345v1 Announce Type: new 
Abstract: The Koopman operator approach to the state estimation problem for nonlinear systems is a promising research area. The main goal of this paper is an attempt to provide a rigorous theoretical framework for this approach. In particular, the (linear) dual Koopman system is introduced and studied in an infinite dimensional context. Moreover, new concepts of observability and detectability are defined in the dual Koopman system, which are shown to be equivalent to the observability and detectability of the nonlinear system, respectively. The theoretical framework is applied to a class of holomorphic dynamics. For this class, a Luenberger-type observer is designed for the dual Koopman system via a spectral method, yielding an estimate of the state of the nonlinear system. A particular attention is given to the existence of an appropriate solution to the dual Koopman system and observer, which are defined in the Hardy space on the polydisc. Spectral observability and detectability conditions are derived in this setting, and the exponential convergence of the Koopman observer is shown. Finally, numerical experiments support the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08345v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Judica\"el Mohet, Alexandre Mauroy, Joseph J. Winkin</dc:creator>
    </item>
    <item>
      <title>Accelerated Distributed Optimization with Compression and Error Feedback</title>
      <link>https://arxiv.org/abs/2503.08427</link>
      <description>arXiv:2503.08427v1 Announce Type: new 
Abstract: Modern machine learning tasks often involve massive datasets and models, necessitating distributed optimization algorithms with reduced communication overhead. Communication compression, where clients transmit compressed updates to a central server, has emerged as a key technique to mitigate communication bottlenecks. However, the theoretical understanding of stochastic distributed optimization with contractive compression remains limited, particularly in conjunction with Nesterov acceleration -- a cornerstone for achieving faster convergence in optimization.
  In this paper, we propose a novel algorithm, ADEF (Accelerated Distributed Error Feedback), which integrates Nesterov acceleration, contractive compression, error feedback, and gradient difference compression. We prove that ADEF achieves the first accelerated convergence rate for stochastic distributed optimization with contractive compression in the general convex regime. Numerical experiments validate our theoretical findings and demonstrate the practical efficacy of ADEF in reducing communication costs while maintaining fast convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08427v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Jeremy Rack, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>A forward-reflected-anchored-backward splitting algorithm with double inertial effects for solving non-monotone inclusion problems</title>
      <link>https://arxiv.org/abs/2503.08432</link>
      <description>arXiv:2503.08432v1 Announce Type: new 
Abstract: In this paper, we study inclusion problems where the involved operators may not be monotone in the classical sense. Specifically, we assume the operators to be generalized monotone, a weaker notion than classical monotonicity. This allows us to extend the applicability of our results to a broader class of operators. We apply the two-step inertial forward-reflected-anchored-backward splitting algorithm proposed in \cite{CHIN} to these non-monotone inclusion problems. We establish the strong convergence of the sequence generated by the algorithm and demonstrate its applicability to other optimization problems, including Constrained Optimization Problems, Mixed Variational Inequalities, and Variational Inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08432v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Van Tran</dc:creator>
    </item>
    <item>
      <title>Progressive hedging for multi-stage stochastic lot sizing problems with setup carry-over under uncertain demand</title>
      <link>https://arxiv.org/abs/2503.08477</link>
      <description>arXiv:2503.08477v1 Announce Type: new 
Abstract: We investigate multi-stage demand uncertainty for the multi-item multi-echelon capacitated lot sizing problem with setup carry-over. Considering a multi-stage decision framework helps to quantify the benefits of being able to adapt decisions to newly available information. The drawback is that multi-stage stochastic optimization approaches lead to very challenging formulations. This is because they usually rely on scenario tree representations of the uncertainty, which grow exponentially in the number of decision stages. Thus, even for a moderate number of decision stages it becomes difficult to solve the problem by means of a compact optimization model. To address this issue, we propose a progressive hedging algorithm and we investigate and tune the crucial penalty parameter that influences the conflicting goals of fast convergence and solution quality. While low penalty parameters usually lead to high quality solutions, this comes at the cost of slow convergence. To tackle this problem, we adapt metaheuristic adjustment strategies to guide the algorithm towards a consensus more efficiently. Furthermore, we consider several options to compute the consensus solution. While averaging the subproblem decisions is a common choice, we also apply a majority voting procedure. We test different algorithm configurations and compare the results of progressive hedging to the solutions obtained by solving a compact optimization model on well-known benchmark instances. For several problem instances the progressive hedging algorithm converges to solutions within 1% of the cost of the compact model's solution, while requiring shorter runtimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08477v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Schlenkrich, Jean-Fran\c{c}ois Cordeau, Sophie N. Parragh</dc:creator>
    </item>
    <item>
      <title>A Communication-Efficient and Differentially-Private Distributed Generalized Nash Equilibrium Seeking Algorithm for Aggregative Games</title>
      <link>https://arxiv.org/abs/2503.08494</link>
      <description>arXiv:2503.08494v1 Announce Type: new 
Abstract: This paper studies the distributed generalized Nash equilibrium seeking problem for aggregative games with coupling constraints, where each player optimizes its strategy depending on its local cost function and the estimated strategy aggregation. The information transmission in distributed networks may go beyond bandwidth capacity and eventuate communication bottlenecks. Therefore, we propose a novel communication-efficient distributed generalized Nash equilibrium seeking algorithm, in which the communication efficiency is improved by event-triggered communication and information compression methods. The proposed algorithm saves the transmitted rounds and bits of communication simultaneously. Specifically, by developing precise step size conditions, the proposed algorithm ensures provable convergence, and is proven to achieve $(0,\delta)$-differential privacy with a stochastic quantization scheme. In the end, simulation results verify the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08494v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Zhao, Antai Xie, Yuchi Wu, Xinlei Yi, Xiaoqiang Ren</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of linearized $\ell_q$ penalty methods for nonconvex optimization with nonlinear equality constraints</title>
      <link>https://arxiv.org/abs/2503.08522</link>
      <description>arXiv:2503.08522v1 Announce Type: new 
Abstract: In this paper, we consider nonconvex optimization problems with nonlinear equality constraints. We assume that the objective function and the functional constraints are locally smooth. To solve this problem, we introduce a linearized $\ell_q$ penalty based method, where $q \in (1,2]$ is the parameter defining the norm used in the construction of the penalty function. Our method involves linearizing the objective function and functional constraints in a Gauss-Newton fashion at the current iteration in the penalty formulation and introduces a quadratic regularization. This approach yields an easily solvable subproblem, whose solution becomes the next iterate. By using a novel dynamic rule for the choice of the regularization parameter, we establish that the iterates of our method converge to an $\epsilon$-first-order solution in $\mathcal{O}(1/{\epsilon^{2+ (q-1)/q}})$ outer iterations. Finally, we put theory into practice and evaluate the performance of the proposed algorithm by making numerical comparisons with existing methods from literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08522v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lahcen El Bourkhissi, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>Faithful global convergence for the rescaled Consensus--Based Optimization</title>
      <link>https://arxiv.org/abs/2503.08578</link>
      <description>arXiv:2503.08578v1 Announce Type: new 
Abstract: We analyze the Consensus-Based Optimization (CBO) algorithm with a consensus point rescaled by a small fixed parameter $\kappa \in (0,1)$. Under minimal assumptions on the objective function and the initial data, we establish its unconditional convergence to the global minimizer. Our results hold in the asymptotic regime where both the time--horizon $t \to \infty$ and the inverse--temperature $\alpha \to \infty$, providing a rigorous theoretical foundation for the algorithm's global convergence. Furthermore, our findings extend to the case of multiple and non--discrete set of minimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08578v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Huang, Hicham Kouhkouh, Lukang Sun</dc:creator>
    </item>
    <item>
      <title>Regularized Federated Methods with Universal Guarantees for Simple Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2503.08634</link>
      <description>arXiv:2503.08634v1 Announce Type: new 
Abstract: We study a bilevel federated learning (FL) problem, where clients cooperatively seek to find among multiple optimal solutions of a primary distributed learning problem, a solution that minimizes a secondary distributed global loss function. This problem is motivated by model selection in over-parameterized machine learning, in that the outer-level objective is a suitably-defined regularizer and the inner-level objective is the training loss function. Despite recent progress in centralized settings, communication-efficient FL methods equipped with complexity guarantees for resolving this problem class are primarily absent. Motivated by this lacuna, we consider the setting where the inner-level objective is convex and the outer-level objective is either convex or strongly convex. We propose a universal regularized scheme and derive promising error bounds in terms of both the inner-level and outer-level loss functions. Leveraging this unifying theory, we then enable two existing FL methods to address the corresponding simple bilevel problem and derive novel communication complexity guarantees for each method. Additionally, we devise an FL method for addressing simple bilevel optimization problems with a nonconvex outer-level loss function. Through a two-loop scheme and by leveraging the universal theory, we derive new complexity bounds for the nonconvex setting. This appears to be the first time that federated simple bilevel optimization problems are provably addressed with guarantees. We validate the theoretical findings on EMNIST and CIFAR-10 datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08634v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadjavad Ebrahimi, Yuyang Qiu, Shisheng Cui, Farzad Yousefian</dc:creator>
    </item>
    <item>
      <title>Some commutation principles for optimization problems over transformation groups and semi-FTvN systems</title>
      <link>https://arxiv.org/abs/2503.08654</link>
      <description>arXiv:2503.08654v1 Announce Type: new 
Abstract: We introduce the concepts of commutativity relative to a transformation group and strong commutativity in the setting of a semi-FTvN system and show their appearance as optimality conditions in certain optimization problems. In the setting of a semi-FTvN system (in particular, in an FTvN system), we show that strong commutativity implies commutativity and observe that in the special case of Euclidean Jordan algebra, commutativity and strong commutativity concepts reduce, respectively, to those of operator and strong operator commutativity. We demonstrate that every complete hyperbolic polynomial induces a semi-FTvN system. By way of an application, we describe several commutation principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08654v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Seetharama Gowda, David Sossa</dc:creator>
    </item>
    <item>
      <title>An Improved Adaptive Orthogonal Basis Deflation Method for Multiple Solutions with Applications to Nonlinear Elliptic Equations in Varying Domains</title>
      <link>https://arxiv.org/abs/2503.07624</link>
      <description>arXiv:2503.07624v1 Announce Type: cross 
Abstract: Multiple solutions are common in various non-convex problems arising from industrial and scientific computing. Nonetheless, understanding the nontrivial solutions' qualitative properties seems limited, partially due to the lack of efficient and reliable numerical methods. In this paper, we design a dedicated numerical method to explore these nontrivial solutions further. We first design an improved adaptive orthogonal basis deflation method by combining the adaptive orthogonal basis method with a bisection-deflation algorithm. We then apply the proposed new method to study the impact of domain changes on multiple solutions of certain nonlinear elliptic equations. When the domain varies from a circular disk to an elliptical disk, the corresponding functional value changes dramatically for some particular solutions, which indicates that these nontrivial solutions in the circular domain may become unstable in the elliptical domain. Moreover, several theoretical results on multiple solutions in existing literature are verified. For the nonlinear Sine-Gordon equation with parameter $\lambda$, nontrivial solutions are found for $\lambda &gt; \lambda_2$, here $\lambda_2$ is the second eigenvalue of the corresponding linear eigenvalue problem. For the singularly perturbed Ginzburg-Landau equation, highly concentrated solutions are numerically found which suggests that their convergent limit is a delta function when the perturbation parameter goes to zero</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07624v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangyi Ye, Lin Li, Pengcheng Xie, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>Generalizations of Total Dual Integrality</title>
      <link>https://arxiv.org/abs/2503.07925</link>
      <description>arXiv:2503.07925v1 Announce Type: cross 
Abstract: We design new tools to study variants of Total Dual Integrality. As an application, we obtain a geometric characterization of Total Dual Integrality for the case where the associated polyhedron is non-degenerate. We also give sufficient conditions for a system to be Totally Dual Dyadic, and prove new special cases of Seymour's Dyadic conjecture on ideal clutters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07925v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bertrand Guenin, Levent Tun\c{c}el</dc:creator>
    </item>
    <item>
      <title>On Minimizing Phase Space Energies</title>
      <link>https://arxiv.org/abs/2503.07965</link>
      <description>arXiv:2503.07965v1 Announce Type: cross 
Abstract: A primary technical challenge for harnessing fusion energy is to control and extract energy from a non-thermal distribution of charged particles. The fact that phase space evolves by symplectomorphisms fundamentally limits how a distribution may be manipulated. While the constraint of phase-space volume preservation is well understood, other constraints remain to be fully appreciated. To better understand these constraints, we study the problem of extracting energy from a distribution of particles using area-preserving and symplectic linear maps. When a quadratic potential is imposed, we find that the maximal extractable energy can be computed as trace minimization problems. We solve these problems and show that the extractable energy under linear symplectomorphisms may be much smaller than the extractable energy under special linear maps. The method introduced in the present study enables an energy-based proof of the linear Gromov non-squeezing theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07965v1</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>physics.class-ph</category>
      <category>physics.plasm-ph</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Updike, Nicholas Bohlsen, Hong Qin, Nathaniel Fisch</dc:creator>
    </item>
    <item>
      <title>Dynamically optimal portfolios for monotone mean--variance preferences</title>
      <link>https://arxiv.org/abs/2503.08272</link>
      <description>arXiv:2503.08272v1 Announce Type: cross 
Abstract: Monotone mean-variance (MMV) utility is the minimal modification of the classical Markowitz utility that respects rational ordering of investment opportunities. This paper provides, for the first time, a complete characterization of optimal dynamic portfolio choice for the MMV utility in asset price models with independent returns. The task is performed under minimal assumptions, weaker than the existence of an equivalent martingale measure and with no restrictions on the moments of asset returns. We interpret the maximal MMV utility in terms of the monotone Sharpe ratio (MSR) and show that the global squared MSR arises as the nominal yield from continuously compounding at the rate equal to the maximal local squared MSR. The paper gives simple necessary and sufficient conditions for mean-variance (MV) efficient portfolios to be MMV efficient. Several illustrative examples contrasting the MV and MMV criteria are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08272v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ale\v{s} \v{C}ern\'y, Johannes Ruf, Martin Schweizer</dc:creator>
    </item>
    <item>
      <title>Nonlinear optimals and their role in sustaining turbulence in channel flow</title>
      <link>https://arxiv.org/abs/2503.08283</link>
      <description>arXiv:2503.08283v1 Announce Type: cross 
Abstract: We investigate the energy transfer from the mean profile to velocity fluctuations in channel flow by calculating nonlinear optimal disturbances,i.e. the initial condition of a given finite energy that achieves the highest possible energy growth during a given fixed time horizon. It is found that for a large range of time horizons and initial disturbance energies, the nonlinear optimal exhibits streak spacing and amplitude consistent with DNS at least at Re_tau = 180, which suggests that they isolate the relevant physical mechanisms that sustain turbulence. Moreover, the time horizon necessary for a nonlinear disturbance to outperform a linear optimal is consistent with previous DNS-based estimates using eddy turnover time, which offers a new perspective on how some turbulent time scales are determined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08283v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dario Klingenberg, Rich R. Kerswell</dc:creator>
    </item>
    <item>
      <title>DISTINGUISH Workflow: A New Paradigm of Dynamic Well Placement Using Generative Machine Learning</title>
      <link>https://arxiv.org/abs/2503.08509</link>
      <description>arXiv:2503.08509v1 Announce Type: cross 
Abstract: The real-time process of directional changes while drilling, known as geosteering, is crucial for hydrocarbon extraction and emerging directional drilling applications such as geothermal energy, civil infrastructure, and CO2 storage. The geo-energy industry seeks an automatic geosteering workflow that continually updates the subsurface uncertainties and captures the latest geological understanding given the most recent observations in real-time.
  We propose "DISTINGUISH": a real-time, AI-driven workflow designed to transform geosteering by integrating Generative Adversarial Networks (GANs) for geological parameterization, ensemble methods for model updating, and global discrete dynamic programming (DDP) optimization for complex decision-making during directional drilling operations. The DISTINGUISH framework relies on offline training of a GAN model to reproduce relevant geology realizations and a Forward Neural Network (FNN) to model Logging-While-Drilling (LWD) tools' response for a given geomodel.
  This paper introduces a first-of-its-kind workflow that progressively reduces GAN-geomodel uncertainty around and ahead of the drilling bit and adjusts the well plan accordingly. The workflow automatically integrates real-time LWD data with a DDP-based decision support system, enhancing predictive models of geology ahead of drilling and leading to better steering decisions. We present a simple yet representative benchmark case and document the performance target achieved by the DISTINGUISH workflow prototype. This benchmark will be a foundation for future methodological advancements and workflow refinements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08509v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.geo-ph</category>
      <category>stat.AP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Alyaev, Kristian Fossum, Hibat Errahmen Djecta, Jan Tveranger, Ahmed H. Elsheikh</dc:creator>
    </item>
    <item>
      <title>Dynamic Pricing and Matching for Two-Sided Queues</title>
      <link>https://arxiv.org/abs/1911.02213</link>
      <description>arXiv:1911.02213v4 Announce Type: replace 
Abstract: Motivated by applications from gig economy and online marketplaces, we study a two-sided queueing system under joint pricing and matching controls. The queueing system is modeled by a bipartite graph, where the vertices represent customer or server types and the edges represent compatible customer-server pairs. Both customers and servers sequentially arrive to the system and join separate queues according to their types. The arrival rates of different types depend on the prices set by the system operator and the expected waiting time. At any point in time, the system operator can choose certain customers to match with compatible servers. The objective is to maximize the long-run average profit for the system. We first propose a fluid approximation based pricing and max-weight matching policy, which achieves an $O(\sqrt{\eta})$ optimality rate when all the arrival rates are scaled by $\eta$. We further show that a two-price and max-weight matching policy achieves an improved $O(\eta^{1/3})$ optimality rate. Under a broad class of pricing policies, we prove that any matching policy has an optimality rate that is lower bounded by $\Omega(\eta^{1/3})$. Thus, the latter policy achieves the optimal rate with respect to $\eta$. We also demonstrate the advantage of max-weight matching with respect to the number of server and customer types $n$. Under a complete resource pooling condition, we show that max-weight matching achieves $O(\sqrt{n})$ and $O(n^{1/3})$ optimality rates for static and two-price policies, respectively, and the latter matches the lower bound $\Omega(n^{1/3})$. In comparison, the randomized matching policy may have an $\Omega(n)$ optimality rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.02213v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushil Mahavir Varma, Pornpawee Bumpensanti, Siva Theja Maguluri, He Wang</dc:creator>
    </item>
    <item>
      <title>Integral Quadratic Constraints on Linear Infinite-dimensional Systems for Robust Stability Analysis</title>
      <link>https://arxiv.org/abs/2003.06283</link>
      <description>arXiv:2003.06283v2 Announce Type: replace 
Abstract: This paper proposes a framework to assess the stability of an ordinary differential equation which is coupled to a 1D-partial differential equation (PDE). The stability theorem is based on a new result on Integral Quadratic Constraints (IQCs) and expressed in terms of two linear matrix inequalities with a moderate computational burden. The IQCs are not generated using dissipation inequalities involving the whole state of an infinite-dimensional system, but by using projection coefficients of the infinite-dimensional state. This permits to generalize our robustness result to many other PDEs. The proposed methodology is applied to a time-delay system and numerical results comparable to those in the literature are obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.06283v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IFAC WC 2020, Berlin</arxiv:journal_reference>
      <dc:creator>Barreau Matthieu, Scherer Carsten W., Gouaisbaut Frederic, Seuret Alexandre</dc:creator>
    </item>
    <item>
      <title>Energy matching in reduced passive and port-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2309.05778</link>
      <description>arXiv:2309.05778v2 Announce Type: replace 
Abstract: It is well known that any port-Hamiltonian (pH) system is passive, and conversely, any minimal and stable passive system has a pH representation. Nevertheless, this equivalence is only concerned with the input-output mapping but not with the Hamiltonian itself. Thus, we propose to view a pH system either as an enlarged dynamical system with the Hamiltonian as additional output or as two dynamical systems with the input-output and the Hamiltonian dynamic. Our first main result is a structure-preserving Kalman-like decomposition of the enlarged pH system that separates the controllable and zero-state observable parts. Moreover, for further approximations in the context of structure-preserving model-order reduction (MOR), we propose to search for a Hamiltonian in the reduced pH system that minimizes the $\mathcal{H}_2$-distance to the full-order Hamiltonian without altering the input-output dynamic, thus discussing a particular aspect of the corresponding multi-objective minimization problem corresponding to $\mathcal{H}_2$-optimal MOR for pH systems. We show that this optimization problem is uniquely solvable, can be recast as a standard semidefinite program, and present two numerical approaches for solving it. The results are illustrated with three academic examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05778v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Holicki, Jonas Nicodemus, Paul Schwerdtner, Benjamin Unger</dc:creator>
    </item>
    <item>
      <title>INVALS: A Forward Looking Inventory Allocation System</title>
      <link>https://arxiv.org/abs/2310.04305</link>
      <description>arXiv:2310.04305v2 Announce Type: replace 
Abstract: We design an Inventory Allocation System (INVALS) that, for each item-store combination, plans the quantity to be allocated from a warehouse that replenishes multiple stores using trailers, while respecting typical operational constraints. We formulate a linear objective function which, when maximized, determines the allocation plan by considering not only the immediate store needs, but also its future (forward) expected demand. This forward-looking allocation significantly improves the utilization of labor and trailers in the warehouse. To reduce overstocking, we adapt from our objective to prioritize allocating those items in excess which are sold faster at the stores, keeping the days of supply (DOS) to a minimum. For the proposed formulation, which is an instance of Mixed Integer Linear Programming (MILP), we present a scalable algorithm using the concepts of submodularity and optimal transport theory by: (i) sequentially adding trailers to stores based on maximum incremental gain, (ii) transforming the resultant linear program (LP) instance to an instance of capacity constrained optimal transport (COT), solvable using double entropic regularization and incurring the same computational complexity as the Sinkhorn algorithm. Compared against the planning engine that only allocates for immediate store needs, INVALS increases labor utilization by 34.70% and item occupancy in trailers by 37.08% on average. The DOS distribution is also skewed to the left, indicating that higher-demand items are allocated in excess, reducing the days they are stocked. We empirically observed that for ~90% of the replenishment cycles, the allocation results of INVALS are identical to the globally optimal MILP solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04305v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shiv Krishna Jaiswal, Karthik S. Gurumoorthy, Etika Agarwal, Shantala Manchenahally</dc:creator>
    </item>
    <item>
      <title>On finding optimal collective variables for complex systems by minimizing the deviation between effective and full dynamics</title>
      <link>https://arxiv.org/abs/2405.02001</link>
      <description>arXiv:2405.02001v2 Announce Type: replace 
Abstract: This paper is concerned with collective variables, or reaction coordinates, that map a discrete-in-time Markov process $X_n$ in $\mathbb{R}^d$ to a (much) smaller dimension $k \ll d$. We define the effective dynamics under a given collective variable map $\xi$ as the best Markovian representation of $X_n$ under $\xi$. The novelty of the paper is that it gives strict criteria for selecting optimal collective variables via the properties of the effective dynamics. In particular, we show that the transition density of the effective dynamics of the optimal collective variable solves a relative entropy minimization problem from certain family of densities to the transition density of $X_n$. We also show that many transfer operator-based data-driven numerical approaches essentially learn quantities of the effective dynamics. Furthermore, we obtain various error estimates for the effective dynamics in approximating dominant timescales / eigenvalues and transition rates of the original process $X_n$ and how optimal collective variables minimize these errors. Our results contribute to the development of theoretical tools for the understanding of complex dynamical systems, e.g. molecular kinetics, on large timescales. These results shed light on the relations among existing data-driven numerical approaches for identifying good collective variables, and they also motivate the development of new methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02001v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Zhang, Christof Sch\"utte</dc:creator>
    </item>
    <item>
      <title>Multilinear Extensions in Submodular Optimization for Optimal Sensor Scheduling in Nonlinear Networks</title>
      <link>https://arxiv.org/abs/2408.03833</link>
      <description>arXiv:2408.03833v2 Announce Type: replace 
Abstract: Optimal sensing nodes selection (SNS) in dynamic systems is a combinatorial optimization problem that has been thoroughly studied in the recent literature. This problem can be formulated within the context of set optimization. For high-dimensional nonlinear systems, the problem is extremely difficult to solve. It scales poorly too. Current literature poses combinatorial submodular set optimization problems via maximizing observability performance metrics subject to matroid constraints. Such an approach is typically solved using greedy algorithms that require lower computational effort yet often yield sub-optimal solutions. In this paper, we address the SNS problem for nonlinear dynamical networks using a variational form of the system dynamics, that basically perturb the system physics. As a result, we show that the observability performance metrics under such system representation are indeed submodular. The optimal problem is then solved using the multilinear continuous extension. This extension offers a computationally scalable and approximate continuous relaxation with a performance guarantee. The effectiveness of the extended submodular program is studied and compared to greedy algorithms. We demonstrate the proposed set optimization formulation for SNS on nonlinear natural gas combustion networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03833v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamad H. Kazma, Ahmad F. Taha</dc:creator>
    </item>
    <item>
      <title>Single-loop methods for bilevel parameter learning in inverse imaging</title>
      <link>https://arxiv.org/abs/2408.08123</link>
      <description>arXiv:2408.08123v2 Announce Type: replace 
Abstract: Bilevel optimisation is used in inverse problems for hyperparameter learning and experimental design. For instance, it can be used to find optimal regularisation parameters and forward operators, based on a set of training pairs. However, computationally, the process is costly. To reduce this cost, recently in bilevel optimisation research, especially as applied to machine learning, so-called single-loop approaches have been introduced. On each step of an outer optimisation method, such methods only take a single gradient descent step towards the solution of the inner problem. In this paper, we flexibilise the inner algorithm, to allow for methods more applicable to difficult inverse problems with nonsmooth regularisation, including primal-dual proximal splitting (PDPS). Moreover, as we have recently shown, significant performance improvements can be obtained in PDE-constrained optimisation by interweaving the steps of conventional iterative solvers (Jacobi, Gauss-Seidel, conjugate gradients) for both the PDE and its adjoint, with the steps of the optimisation method. In this paper we demonstrate how the adjoint equation in bilevel problems can also benefit from such interweaving with conventional linear system solvers. We demonstrate the performance of our proposed methods on learning the deconvolution kernel for image deblurring, and the subsampling operator for magnetic resonance imaging (MRI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08123v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ensio Suonper\"a, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>A Parallel-in-Time Newton's Method for Nonlinear Model Predictive Control</title>
      <link>https://arxiv.org/abs/2409.20027</link>
      <description>arXiv:2409.20027v3 Announce Type: replace 
Abstract: Model predictive control (MPC) is a powerful framework for optimal control of dynamical systems. However, MPC solvers suffer from a high computational burden that restricts their application to systems with low sampling frequency. This issue is further amplified in nonlinear and constrained systems that require nesting MPC solvers within iterative procedures. In this paper, we address these issues by developing parallel-in-time algorithms for constrained nonlinear optimization problems that take advantage of massively parallel hardware to achieve logarithmic computational time scaling over the planning horizon. We develop time-parallel second-order solvers based on interior point methods and the alternating direction method of multipliers, leveraging fast convergence and lower computational cost per iteration. The parallelization is based on a reformulation of the subproblems in terms of associative operations that can be parallelized using the associative scan algorithm. We validate our approach on numerical examples of nonlinear and constrained dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20027v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Casian Iacob, Hany Abdulsamad, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>Exponential Convergence of Augmented Primal-dual Gradient Algorithms for Partially Strongly Convex Functions</title>
      <link>https://arxiv.org/abs/2410.02192</link>
      <description>arXiv:2410.02192v3 Announce Type: replace 
Abstract: We show that the augmented primal-dual gradient algorithms can achieve global exponential convergence with partially strongly convex functions. In particular, the objective function only needs to be strongly convex in the subspace satisfying the equality constraint and can be generally convex elsewhere, provided the global Lipschitz condition for the gradient is satisfied. This condition implies that states outside the equality subspace will converge towards it exponentially fast. The analysis is then applied to distributed optimization, where the partially strong convexity can be relaxed to the restricted secant inequality condition, which is not necessarily convex. This work unifies global exponential convergence results for some existing centralized and distributed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02192v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Online Control-Informed Learning</title>
      <link>https://arxiv.org/abs/2410.03924</link>
      <description>arXiv:2410.03924v2 Announce Type: replace 
Abstract: This paper proposes an Online Control-Informed Learning (OCIL) framework, which employs the well-established optimal control and state estimation techniques in the field of control to solve a broad class of learning tasks in an online fashion. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in an online fashion, enabling it to complete designated learning or control tasks. The proposed method also improves the robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03924v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zihao Liang, Tianyu Zhou, Zehui Lu, Shaoshuai Mou</dc:creator>
    </item>
    <item>
      <title>Time-reversal solution of BSDEs in stochastic optimal control: a linear quadratic study</title>
      <link>https://arxiv.org/abs/2410.04615</link>
      <description>arXiv:2410.04615v2 Announce Type: replace 
Abstract: This paper addresses the numerical solution of backward stochastic differential equations (BSDEs) arising in stochastic optimal control. Specifically, we investigate two BSDEs: one derived from the Hamilton-Jacobi-Bellman equation and the other from the stochastic maximum principle. For both formulations, we analyze and compare two numerical methods. The first utilizes the least-squares Monte-Carlo (LSMC) approach for approximating conditional expectations, while the second leverages a time-reversal (TR) of diffusion processes. Although both methods extend to nonlinear settings, our focus is on the linear-quadratic case, where analytical solutions provide a benchmark. Numerical results demonstrate the superior accuracy and efficiency of the TR approach across both BSDE representations, highlighting its potential for broader applications in stochastic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04615v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhang Mei, Amirhossein Taghvaei</dc:creator>
    </item>
    <item>
      <title>Beyond Discretization: Learning the Optimal Solution Path</title>
      <link>https://arxiv.org/abs/2410.14885</link>
      <description>arXiv:2410.14885v3 Announce Type: replace 
Abstract: Many applications require minimizing a family of optimization problems indexed by some hyperparameter $\lambda \in \Lambda$ to obtain an entire solution path. Traditional approaches proceed by discretizing $\Lambda$ and solving a series of optimization problems. We propose an alternative approach that parameterizes the solution path with a set of basis functions and solves a \emph{single} stochastic optimization problem to learn the entire solution path. Our method offers substantial complexity improvements over discretization. When using constant-step size SGD, the uniform error of our learned solution path relative to the true path exhibits linear convergence to a constant related to the expressiveness of the basis. When the true solution path lies in the span of the basis, this constant is zero. We also prove stronger results for special cases common in machine learning: When $\lambda \in [-1, 1]$ and the solution path is $\nu$-times differentiable, constant step-size SGD learns a path with $\epsilon$ uniform error after at most $O(\epsilon^{\frac{1}{1-\nu}} \log(1/\epsilon))$ iterations, and when the solution path is analytic, it only requires $O\left(\log^2(1/\epsilon)\log\log(1/\epsilon)\right)$. By comparison, the best-known discretization schemes in these settings require at least $O(\epsilon^{-1/2})$ discretization points (and even more gradient calls). Finally, we propose an adaptive variant of our method that sequentially adds basis functions and demonstrates strong numerical performance through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14885v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiran Dong, Paul Grigas, Vishal Gupta</dc:creator>
    </item>
    <item>
      <title>ItsOPT: An inexact two-level smoothing framework for nonconvex optimization via high-order Moreau envelope</title>
      <link>https://arxiv.org/abs/2410.19928</link>
      <description>arXiv:2410.19928v4 Announce Type: replace 
Abstract: This paper introduces ItsOPT, an inexact two-level smoothing optimization framework designed to find first-order critical points of nonsmooth and nonconvex functions. The framework involves two levels of methodologies: at the upper level, a zero-, first-, or second-order method will be tailored to minimize a smooth approximation; at the lower level, the high-order proximal auxiliary problems will be solved inexactly, generating an inexact oracle for the smooth function. As a smoothing technique, we here introduce the high-order Moreau envelope (HOME) and study its fundamental features under standard assumptions. Next, introducing a boosted high-order proximal-point algorithm (Boosted HiPPA) at the upper level using the inexact oracle from the lower level leads to an instance of ItsOPT. Global convergence rates are established under the Kurdyka-{\L}ojasiewicz (KL) property of the cost and envelope functions, along with some reasonable conditions for the accuracy of the proximal terms. surprisingly, for any KL exponent $\theta\in (0,1)$ of the original cost, setting the regularization order $p=\frac{1}{1-\theta}$ ensures that Boosted HiPPA converges linearly to a proximal fixed point, which is the first algorithm with this property for KL functions. Preliminary numerical experiments on a robust low-rank matrix recovery problem indicate a promising performance of the proposed algorithm, validating our theoretical foundations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19928v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Kabgani, Masoud Ahookhosh</dc:creator>
    </item>
    <item>
      <title>On the required number of electrodes for uniqueness and convex reformulation in an inverse coefficient problem</title>
      <link>https://arxiv.org/abs/2411.00482</link>
      <description>arXiv:2411.00482v2 Announce Type: replace 
Abstract: We introduce a computer-assisted proof for the required number of electrodes for uniqueness and global reconstruction for the inverse Robin transmission problem, where the corrosion function on the boundary of an interior object is to be determined from electrode current-voltage measurements. We consider the shunt electrode model where, in contrast to the standard Neumann boundary condition, the applied electrical current is only partially known. The aim is to determine the corrosion coefficient with a finite number of measurements.
  In this paper, we present a numerically verifiable criterion that ensures unique solvability of the inverse problem, given a desired resolution. This allows us to explicitly determine the required number and position of the electrodes. Furthermore, we will present an error estimate for noisy data. By rewriting the problem as a convex optimization problem, our aim is to develop a globally convergent reconstruction algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00482v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrej Brojatsch, Bastian Harrach</dc:creator>
    </item>
    <item>
      <title>Correction to: A Lagrangian dual method for two-stage robust optimization with binary uncertainties</title>
      <link>https://arxiv.org/abs/2411.04307</link>
      <description>arXiv:2411.04307v2 Announce Type: replace 
Abstract: We provide a correction to the sufficient conditions under which closed-form expressions for the optimal Lagrange multiplier are provided in arXiv:2112.13138 [math.OC]. We first present a simple counterexample where the original conditions are insufficient, highlight where the original proof fails, and then provide modified conditions along with a correct proof of their validity. Finally, although the original paper discusses modifications to their method for problems that may not satisfy any sufficient conditions, we substantiate that discussion along two directions. We first show that computing an optimal Lagrange multiplier can still be done in polynomial time. We then provide complete and correct versions of the corresponding Benders and column-and-constraint generation algorithms in which the original method is used. We also discuss the implications of our findings on computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04307v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Lefebvre, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Bilevel Learning with Inexact Stochastic Gradients</title>
      <link>https://arxiv.org/abs/2412.12049</link>
      <description>arXiv:2412.12049v2 Announce Type: replace 
Abstract: Bilevel learning has gained prominence in machine learning, inverse problems, and imaging applications, including hyperparameter optimization, learning data-adaptive regularizers, and optimizing forward operators. The large-scale nature of these problems has led to the development of inexact and computationally efficient methods. Existing adaptive methods predominantly rely on deterministic formulations, while stochastic approaches often adopt a doubly-stochastic framework with impractical variance assumptions, enforces a fixed number of lower-level iterations, and requires extensive tuning. In this work, we focus on bilevel learning with strongly convex lower-level problems and a nonconvex sum-of-functions in the upper-level. Stochasticity arises from data sampling in the upper-level which leads to inexact stochastic hypergradients. We establish their connection to state-of-the-art stochastic optimization theory for nonconvex objectives. Furthermore, we prove the convergence of inexact stochastic bilevel optimization under mild assumptions. Our empirical results highlight significant speed-ups and improved generalization in imaging tasks such as image denoising and deblurring in comparison with adaptive deterministic bilevel methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12049v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Fast Inexact Bilevel Optimization for Analytical Deep Image Priors</title>
      <link>https://arxiv.org/abs/2502.09758</link>
      <description>arXiv:2502.09758v2 Announce Type: replace 
Abstract: The analytical deep image prior (ADP) introduced by Dittmer et al. (2020) establishes a link between deep image priors and classical regularization theory via bilevel optimization. While this is an elegant construction, it involves expensive computations if the lower-level problem is to be solved accurately. To overcome this issue, we propose to use adaptive inexact bilevel optimization to solve ADP problems. We discuss an extension of a recent inexact bilevel method called the method of adaptive inexact descent of Salehi et al.(2024) to an infinite-dimensional setting required by the ADP framework. In our numerical experiments we demonstrate that the computational speed-up achieved by adaptive inexact bilevel optimization allows one to use ADP on larger-scale problems than in the previous literature, e.g. in deblurring of 2D color images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09758v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.NA</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Tatiana A. Bubba, Yury Korolev</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Linear Functionals of Online SGD in High-dimensional Linear Regression</title>
      <link>https://arxiv.org/abs/2302.09727</link>
      <description>arXiv:2302.09727v3 Announce Type: replace-cross 
Abstract: Stochastic gradient descent (SGD) has emerged as the quintessential method in a data scientist's toolbox. Using SGD for high-stakes applications requires, however, careful quantification of the associated uncertainty. Towards that end, in this work, we establish a high-dimensional Central Limit Theorem (CLT) for linear functionals of online SGD iterates for overparametrized least-squares regression with non-isotropic Gaussian inputs. We first show that a bias-corrected CLT holds when the number of iterations of the online SGD, $t$, grows sub-linearly in the dimensionality, $d$. In order to use the developed result in practice, we further develop an online approach for estimating the variance term appearing in the CLT, and establish high-probability bounds for the developed online estimator. Together with the CLT result, this provides a fully online and data-driven way to numerically construct confidence intervals. This enables practical high-dimensional algorithmic inference with SGD and to the best of our knowledge, is the first such result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09727v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bhavya Agrawalla, Krishnakumar Balasubramanian, Promit Ghosal</dc:creator>
    </item>
    <item>
      <title>On real and observable rational realizations of input-output equations</title>
      <link>https://arxiv.org/abs/2303.16799</link>
      <description>arXiv:2303.16799v3 Announce Type: replace-cross 
Abstract: Given a single (differential-algebraic) input-output equation, we present a method for finding different representations of the associated system in the form of rational realizations; these are dynamical systems with rational right-hand sides. It has been shown that in the case where the input-output equation is of order one, rational realizations can be computed, if they exist. In this work, we focus first on the existence and actual computation of the so-called observable rational realizations, and secondly on rational realizations with real coefficients. The study of observable realizations allows to find every rational realization of a given first order input-output equation, and the necessary field extensions in this process. We show that for first order input-output equations the existence of a rational realization is equivalent to the existence of an observable rational realization. Moreover, we give a criterion to decide the existence of real rational realizations. The computation of observable and real realizations of first order input-output equations is fully algorithmic. We also present partial results for the case of higher order input-output equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16799v3</guid>
      <category>cs.SC</category>
      <category>math.AG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2025.106059</arxiv:DOI>
      <arxiv:journal_reference>Systems &amp; Control Letters, 198 (2025): 106059</arxiv:journal_reference>
      <dc:creator>Sebastian Falkensteiner, Dmitrii Pavlov, Rafael Sendra</dc:creator>
    </item>
    <item>
      <title>Does SGD really happen in tiny subspaces?</title>
      <link>https://arxiv.org/abs/2405.16002</link>
      <description>arXiv:2405.16002v3 Announce Type: replace-cross 
Abstract: Understanding the training dynamics of deep neural networks is challenging due to their high-dimensional nature and intricate loss landscapes. Recent studies have revealed that, along the training trajectory, the gradient approximately aligns with a low-rank top eigenspace of the training loss Hessian, referred to as the dominant subspace. Given this alignment, this paper explores whether neural networks can be trained within the dominant subspace, which, if feasible, could lead to more efficient training methods. Our primary observation is that when the SGD update is projected onto the dominant subspace, the training loss does not decrease further. This suggests that the observed alignment between the gradient and the dominant subspace is spurious. Surprisingly, projecting out the dominant subspace proves to be just as effective as the original update, despite removing the majority of the original update component. We observe similar behavior across practical setups, including the large learning rate regime (also known as Edge of Stability), Sharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the main causes and implications of this spurious alignment, shedding light on the dynamics of neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16002v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minhak Song, Kwangjun Ahn, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>AdaFisher: Adaptive Second Order Optimization via Fisher Information</title>
      <link>https://arxiv.org/abs/2405.16397</link>
      <description>arXiv:2405.16397v3 Announce Type: replace-cross 
Abstract: First-order optimization methods are currently the mainstream in training deep neural networks (DNNs). Optimizers like Adam incorporate limited curvature information by employing the diagonal matrix preconditioning of the stochastic gradient during the training. Despite their widespread, second-order optimization algorithms exhibit superior convergence properties compared to their first-order counterparts e.g. Adam and SGD. However, their practicality in training DNNs is still limited due to increased per-iteration computations compared to the first-order methods. We present \emph{AdaFisher}--an adaptive second-order optimizer that leverages a \emph{diagonal block-Kronecker} approximation of the Fisher information matrix for adaptive gradient preconditioning. AdaFisher aims to bridge the gap between enhanced \emph{convergence/generalization} capabilities and computational efficiency in second-order optimization framework for training DNNs. Despite the slow pace of second-order optimizers, we showcase that AdaFisher can be reliably adopted for image classification, language modeling and stands out for its stability and robustness in hyper-parameter tuning. We demonstrate that AdaFisher \textbf{outperforms the SOTA optimizers} in terms of both accuracy and convergence speed. Code is available from https://github.com/AtlasAnalyticsLab/AdaFisher.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16397v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Martins Gomes, Yanlei Zhang, Eugene Belilovsky, Guy Wolf, Mahdi S. Hosseini</dc:creator>
    </item>
    <item>
      <title>Efficient Trajectory Inference in Wasserstein Space Using Consecutive Averaging</title>
      <link>https://arxiv.org/abs/2405.19679</link>
      <description>arXiv:2405.19679v2 Announce Type: replace-cross 
Abstract: Capturing data from dynamic processes through cross-sectional measurements is seen in many fields, such as computational biology. Trajectory inference deals with the challenge of reconstructing continuous processes from such observations. In this work, we propose methods for B-spline approximation and interpolation of point clouds through consecutive averaging that is intrinsic to the Wasserstein space. Combining subdivision schemes with optimal transport-based geodesic, our methods carry out trajectory inference at a chosen level of precision and smoothness, and can automatically handle scenarios where particles undergo division over time. We prove linear convergence rates and rigorously evaluate our method on cell data characterized by bifurcations, merges, and trajectory splitting scenarios like $supercells$, comparing its performance against state-of-the-art trajectory inference and interpolation methods. The results not only underscore the effectiveness of our method in inferring trajectories but also highlight the benefit of performing interpolation and approximation that respect the inherent geometric properties of the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19679v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amartya Banerjee, Harlin Lee, Nir Sharon, Caroline Moosm\"uller</dc:creator>
    </item>
    <item>
      <title>A nonlocal approximation of the area in codimension two</title>
      <link>https://arxiv.org/abs/2406.13696</link>
      <description>arXiv:2406.13696v2 Announce Type: replace-cross 
Abstract: For $s\in (0,1)$ we introduce a notion of fractional $s$-mass on $(n-2)$-dimensional closed, orientable surfaces in $\R^n$. Moreover, we prove its $\Gamma$-convergence, with respect to the flat topology, and pointwise convergence to the $(n-2)$-dimensional area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13696v2</guid>
      <category>math.DG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Caselli, Mattia Freguglia, Nicola Picenni</dc:creator>
    </item>
    <item>
      <title>Non-commutative optimization problems with differential constraints</title>
      <link>https://arxiv.org/abs/2408.02572</link>
      <description>arXiv:2408.02572v2 Announce Type: replace-cross 
Abstract: Non-commutative polynomial optimization (NPO) problems seek to minimize the state average of a polynomial of some operator variables, subject to polynomial constraints, over all states and operators, as well as the Hilbert spaces where those might be defined. Many of these problems are known to admit a complete hierarchy of semidefinite programming (SDP) relaxations. In this work, we consider a variant of NPO problems where a subset of the operator variables satisfies a system of ordinary differential equations. We find that, under mild conditions of operator boundedness, for every such problem one can construct a standard NPO problem with the same solution. This allows us to define a complete hierarchy of SDPs to tackle the original differential problem. We apply this method to bound averages of local observables in quantum spin systems subject to a Hamiltonian evolution (i.e., a quench). We find that, even in the thermodynamic limit of infinitely many sites, low levels of the hierarchy provide very good approximations for reasonably long evolution times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02572v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateus Ara\'ujo, Andrew J. P. Garner, Miguel Navascues</dc:creator>
    </item>
    <item>
      <title>Statistical and Geometrical properties of regularized Kernel Kullback-Leibler divergence</title>
      <link>https://arxiv.org/abs/2408.16543</link>
      <description>arXiv:2408.16543v2 Announce Type: replace-cross 
Abstract: In this paper, we study the statistical and geometrical properties of the Kullback-Leibler divergence with kernel covariance operators (KKL) introduced by Bach [2022]. Unlike the classical Kullback-Leibler (KL) divergence that involves density ratios, the KKL compares probability distributions through covariance operators (embeddings) in a reproducible kernel Hilbert space (RKHS), and compute the Kullback-Leibler quantum divergence. This novel divergence hence shares parallel but different aspects with both the standard Kullback-Leibler between probability distributions and kernel embeddings metrics such as the maximum mean discrepancy. A limitation faced with the original KKL divergence is its inability to be defined for distributions with disjoint supports. To solve this problem, we propose in this paper a regularised variant that guarantees that the divergence is well defined for all distributions. We derive bounds that quantify the deviation of the regularised KKL to the original one, as well as finite-sample bounds. In addition, we provide a closed-form expression for the regularised KKL, specifically applicable when the distributions consist of finite sets of points, which makes it implementable. Furthermore, we derive a Wasserstein gradient descent scheme of the KKL divergence in the case of discrete distributions, and study empirically its properties to transport a set of points to a target distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16543v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ementine Chazal, Anna Korba, Francis Bach</dc:creator>
    </item>
    <item>
      <title>A Quantum Optimization Algorithm for Optimal Electric Vehicle Charging Station Placement for Intercity Trips</title>
      <link>https://arxiv.org/abs/2410.16231</link>
      <description>arXiv:2410.16231v2 Announce Type: replace-cross 
Abstract: Electric vehicles (EVs) play a significant role in enhancing the sustainability of transportation systems. However, their widespread adoption is hindered by inadequate public charging infrastructure, particularly to support long-distance travel. Identifying optimal charging station locations in large transportation networks presents a well-known NP-hard combinatorial optimization problem, as the search space grows exponentially with the number of potential charging station locations. This paper introduces a quantum search-based optimization algorithm designed to enhance the efficiency of solving this NP-hard problem for transportation networks. By leveraging quantum parallelism, amplitude amplification, and quantum phase estimation as a subroutine, the optimal solution is identified with a quadratic improvement in complexity compared to classical exact methods, such as branch and bound. The detailed design and complexity of a resource-efficient quantum circuit are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16231v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tina Radvand, Alireza Talebpour, Homa Khosravian</dc:creator>
    </item>
    <item>
      <title>A finite element scheme for an optimal control problem on steady Navier-Stokes-Brinkman equations</title>
      <link>https://arxiv.org/abs/2502.09336</link>
      <description>arXiv:2502.09336v3 Announce Type: replace-cross 
Abstract: This paper presents a rigorous finite element framework for solving an optimal control problem governed by the steady Navier-Stokes-Brinkman equations, focusing on identifying a scalar permeability parameter $\gamma$ from local velocity observations. Three different finite element discretization schemes are proposed, and a priori error estimates are proven under appropriate regularity assumptions for each one. A key contribution of this paper is the development of residual-based a posteriori error estimators for both fully discrete and semi-discrete schemes, guiding adaptive mesh refinement to achieve comparable accuracy with fewer degrees of freedom. The method of manufactured solutions is used for numerical experiments to validate the theoretical findings, to demonstrate optimal convergence rates and the effectivity index is evaluated to measure their reliability. The framework offers insights into flow control mechanisms and paving the way for extensions to time-dependent, stochastic, or multiphysics problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09336v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.34425.79200</arxiv:DOI>
      <dc:creator>Jorge Aguayo Araneda, Julie Merten</dc:creator>
    </item>
    <item>
      <title>Efficient Ptychography Reconstruction using the Hessian operator</title>
      <link>https://arxiv.org/abs/2502.10755</link>
      <description>arXiv:2502.10755v2 Announce Type: replace-cross 
Abstract: X-ray ptychography is a powerful and robust coherent imaging method providing access to the complex object and probe (illumination). Ptychography reconstruction is typically performed using first-order methods due to their computational efficiency. Higher-order methods, while potentially more accurate, are often prohibitively expensive in terms of computation. In this study, we present a mathematical framework for reconstruction using second-order information, derived from an efficient computation of the bilinear Hessian and Hessian operator. The formulation is provided for Gaussian based models, enabling the simultaneous reconstruction of the object, probe, and object positions. Synthetic data tests, along with experimental near-field ptychography data processing, demonstrate a ten-fold reduction in computation time compared to first-order methods. The derived formulas for computing the Hessians, along with the strategies for incorporating them into optimization schemes, are well-structured and easily adaptable to various ptychography problem formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10755v2</guid>
      <category>physics.optics</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcus Carlsson, Herwig Wendt, Peter Cloetens, Viktor Nikitin</dc:creator>
    </item>
    <item>
      <title>Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards based Co-constructive Approach</title>
      <link>https://arxiv.org/abs/2503.01413</link>
      <description>arXiv:2503.01413v2 Announce Type: replace-cross 
Abstract: Since its inception, Fuzzy Set has been widely used to handle uncertainty and imprecision in decision-making. However, conventional fuzzy sets, often referred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher levels of uncertainty, particularly when decision-makers (DMs) express hesitation or ambiguity in membership degree. To address this, Interval Type-2 Fuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in membership degree allocation, which enhanced flexibility in modelling subjective judgments. Despite their advantages, existing IT2FS construction methods often lack active involvement from DMs and that limits the interpretability and effectiveness of decision models. This study proposes a socio-technical co-constructive approach for developing IT2FS models of linguistic terms by facilitating the active involvement of DMs in preference elicitation and its application in multicriteria decision-making (MCDM) problems. Our methodology is structured in two phases. The first phase involves an interactive process between the DM and the decision analyst, in which a modified version of Deck-of-Cards (DoC) method is proposed to construct T1FS membership functions on a ratio scale. We then extend this method to incorporate ambiguity in subjective judgment and that resulted in an IT2FS model that better captures uncertainty in DM's linguistic assessments. The second phase formalizes the constructed IT2FS model for application in MCDM by defining an appropriate mathematical representation of such information, aggregation rules, and an admissible ordering principle. The proposed framework enhances the reliability and effectiveness of fuzzy decision-making not only by accurately representing DM's personalized semantics of linguistic information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01413v2</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bapi Dutta, Diego Garc\'ia-Zamora, Jos\'e Rui Figueira, Luis Mart\'inez</dc:creator>
    </item>
  </channel>
</rss>
