<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Aug 2025 04:01:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>SAGE: A Set-based Adaptive Gradient Estimator</title>
      <link>https://arxiv.org/abs/2508.19400</link>
      <description>arXiv:2508.19400v1 Announce Type: new 
Abstract: A new paradigm to estimate the gradient of a black-box scalar function is introduced, considering it as a member of a set of admissible gradients that are computed using existing function samples. Results on gradient estimate accuracy, derived from a multivariate Taylor series analysis, are used to express the set of admissible gradients through linear inequalities. An approach to refine this gradient estimate set to a desired precision is proposed as well, using an adaptive sampling approach. The resulting framework allows one to estimate gradients from data sets affected by noise with finite bounds, to provide the theoretical best attainable gradient estimate accuracy, and the optimal sampling distance from the point of interest to achieve the best refinement of the gradient set estimates. Using these results, a new algorithm is proposed, named Set-based Adaptive Gradient Estimator (SAGE), which features both sample efficiency and robustness to noise. The performance of SAGE are demonstrated by comparing it with commonly-used and latest gradient estimators from literature and practice, in the context of numerical optimization with a first-order method. The results of an extensive statistical test show that SAGE performs competitively when faced with noiseless data, and emerges as the best method when faced with high noise bounds where other gradient estimators result in large errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19400v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Sabug Jr., Fredy Ruiz, Lorenzo Fagiano</dc:creator>
    </item>
    <item>
      <title>Optimal Control of ODE Car-Following Models: Applications to Mixed-Autonomy Platoon Control via Coupled Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2508.19417</link>
      <description>arXiv:2508.19417v1 Announce Type: new 
Abstract: In this paper, we study the optimal control of a mixed-autonomy platoon driving on a single lane to smooth traffic flow. The platoon consists of autonomous vehicles, whose acceleration is controlled, and human-driven vehicles, whose behavior is described using a microscopic car-following model. We formulate the optimal control problem where the dynamics of the platoon are describing through a system of non-linear ODEs, with explicit constraints on both the state and the control variables. Theoretically, we analyze the well-posedness of the system dynamics under a reasonable set of admissible controls and establish the existence of minimizers for the optimal control problem. To solve the problem numerically, we propose a gradient descent-based algorithm that leverages the adjoint method, along with a penalty approach to handle state constraints. We demonstrate the effectiveness of the proposed numerical scheme through several experiments, exploring various scenarios with different penetration rates and distributions of controlled vehicles within the platoon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19417v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arwa Alanqary, Alexandre M. Bayen, Xiaoqian Gong, Anish Gollakota, Alexander Keimer, Ashish Pandian</dc:creator>
    </item>
    <item>
      <title>Spatial-temporal risk field-based coupled dynamic-static driving risk assessment and trajectory planning in weaving segments</title>
      <link>https://arxiv.org/abs/2508.19513</link>
      <description>arXiv:2508.19513v1 Announce Type: new 
Abstract: In this paper, we first propose a spatial-temporal coupled risk assessment paradigm by constructing a three-dimensional spatial-temporal risk field (STRF). Specifically, we introduce spatial-temporal distances to quantify the impact of future trajectories of dynamic obstacles. We also incorporate a geometrically configured specialized field for the weaving segment to constrain vehicle movement directionally. To enhance the STRF's accuracy, we further developed a parameter calibration method using real-world aerial video data, leveraging YOLO-based machine vision and dynamic risk balance theory. A comparative analysis with the traditional risk field demonstrates the STRF's superior situational awareness of anticipatory risk. Building on these results, we final design a STRF-based CAV trajectory planning method in weaving segments. We integrate spatial-temporal risk occupancy maps, dynamic iterative sampling, and quadratic programming to enhance safety, comfort, and efficiency. By incorporating both dynamic and static risk factors during the sampling phase, our method ensures robust safety performance. Additionally, the proposed method simultaneously optimizes path and speed using a parallel computing approach, reducing computation time. Real-world cases show that, compared to the dynamic planning + quadratic programming schemes, and real human driving trajectories, our method significantly improves safety, reduces lane-change completion time, and minimizes speed fluctuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19513v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guodong Ma, Baofeng Sun, Hongchao Liang, Wenyu Yang, Huxing Zhou</dc:creator>
    </item>
    <item>
      <title>Discounted LQR: stabilizing (near-)optimal state-feedback laws</title>
      <link>https://arxiv.org/abs/2508.19599</link>
      <description>arXiv:2508.19599v1 Announce Type: new 
Abstract: We study deterministic, discrete linear time-invariant systems with infinite-horizon discounted quadratic cost. It is well-known that standard stabilizability and detectability properties are not enough in general to conclude stability properties for the system in closed-loop with the optimal controller when the discount factor is small. In this context, we first review some of the stability conditions based on the optimal value function found in the learning and control literature and highlight their conservatism. We then propose novel (necessary and) sufficient conditions, still based on the optimal value function, under which stability of the origin for the optimal closed-loop system is guaranteed. Afterwards, we focus on the scenario where the optimal feedback law is not stabilizing because of the discount factor and the goal is to design an alternative stabilizing near-optimal static state-feedback law. We present both linear matrix inequality-based conditions and a variant of policy iteration to construct such stabilizing near-optimal controllers. The methods are illustrated via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19599v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan de Brusse, Jamal Daafouz, Mathieu Granzotto, Romain Postoyan, Dragan Nesic</dc:creator>
    </item>
    <item>
      <title>Simple Stepsize for Quasi-Newton Methods with Global Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2508.19712</link>
      <description>arXiv:2508.19712v1 Announce Type: new 
Abstract: Quasi-Newton methods are widely used for solving convex optimization problems due to their ease of implementation, practical efficiency, and strong local convergence guarantees. However, their global convergence is typically established only under specific line search strategies and the assumption of strong convexity. In this work, we extend the theoretical understanding of Quasi-Newton methods by introducing a simple stepsize schedule that guarantees a global convergence rate of ${O}(1/k)$ for the convex functions. Furthermore, we show that when the inexactness of the Hessian approximation is controlled within a prescribed relative accuracy, the method attains an accelerated convergence rate of ${O}(1/k^2)$ -- matching the best-known rates of both Nesterov's accelerated gradient method and cubically regularized Newton methods. We validate our theoretical findings through empirical comparisons, demonstrating clear improvements over standard Quasi-Newton baselines. To further enhance robustness, we develop an adaptive variant that adjusts to the function's curvature while retaining the global convergence guarantees of the non-adaptive algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19712v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artem Agafonov, Vladislav Ryspayev, Samuel Horv\'ath, Alexander Gasnikov, Martin Tak\'a\v{c}, Slavomir Hanzely</dc:creator>
    </item>
    <item>
      <title>A Framework for Energy Management Modelling in Hubs for Circularity</title>
      <link>https://arxiv.org/abs/2508.19765</link>
      <description>arXiv:2508.19765v1 Announce Type: new 
Abstract: The concept Hubs for Circularity (H4C) represents integrated systems that combine efficient use of clean energy and circular economy to enhance resource efficiency within a region. H4C benefit from the geographical proximity of different industries within industrial zones and the surrounding urban and rural areas, allowing them to share resources, technology, and infrastructure. They reduce the use of virgin resources through Industrial Symbiosis (IS), where one company uses waste of another company as resource. Energy management is crucial in H4C, as these systems often integrate renewable energy sources, involve energy-intensive industries, include numerous energy consumers, and may rely on energy-based industrial symbiosis exchanges.
  This study presents a modelling framework for energy management in H4C, developed through a systematic literature review of related systems including energy-based IS. The framework provides a guideline for researchers and practitioners on which modelling aspects to consider when optimising the energy flows within a hub. We argue that effective energy management in H4C requires combining conventional modelling aspects - such as objective functions, uncertainty, operational flexibility, and market participation - with IS-specific factors like the type of symbiosis, the degree of information sharing, and collaboration structures. In H4C with extensive IS, decentralised resource and energy exchanges often lead to similarly decentralised information flows and decision-making. Yet, our review shows a persistent reliance on centralised model structures, suggesting a path dependency rooted in traditional energy optimisation approaches. This highlights the need for models that better align with the distributed and collaborative nature of H4C systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19765v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias L{\o}vebakke Nielsen, Daniela Guericke, Alessio Trivella, Devrim Murat Yazan</dc:creator>
    </item>
    <item>
      <title>Robust Data-Driven Quasiconcave Optimization</title>
      <link>https://arxiv.org/abs/2508.19787</link>
      <description>arXiv:2508.19787v1 Announce Type: new 
Abstract: We investigate a data-driven quasiconcave maximization problem where information about the objective function is limited to a finite sample of data points. We begin by defining an ambiguity set for admissible objective functions based on available partial information about the objective. This ambiguity set consists of those quasiconcave functions that majorize a given data sample, and that satisfy additional functional properties (monotonicity, Lipschitz continuity, and permutation invariance). We then formulate a robust optimization (RO) problem which maximizes the worst-case objective function over this ambiguity set. Based on the quasiconcave structure in this problem, we explicitly construct the upper level sets of the worst-case objective at all levels. We can then solve the resulting RO problem efficiently by doing binary search over the upper level sets and solving a logarithmic number of convex feasibility problems. This numerical approach differs from traditional subgradient descent and support function based methods for this problem class. While these methods can be applied in our setting, the binary search method displays superb finite convergence to the global optimum, whereas the others do not. This is primarily because binary search fully exploits the specific structure of the worst-case quasiconcave objective, which leads to an explicit and general convergence rate in terms of the number of convex optimization problems to be solved. Our numerical experiments on a Cobb-Douglas production efficiency problem demonstrate the tractability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19787v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Wu, William B. Haskell, Wenjie Huang, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Robust Paths: Geometry and Computation</title>
      <link>https://arxiv.org/abs/2508.20039</link>
      <description>arXiv:2508.20039v1 Announce Type: new 
Abstract: Applying robust optimization often requires selecting an appropriate uncertainty set both in shape and size, a choice that directly affects the trade-off between average-case and worst-case performances. In practice, this calibration is usually done via trial-and-error: solving the robust optimization problem many times with different uncertainty set shapes and sizes, and examining their performance trade-off. This process is computationally expensive and ad hoc. In this work, we take a principled approach to study this issue for robust optimization problems with linear objective functions, convex feasible regions, and convex uncertainty sets. We introduce and study what we define as the robust path: a set of robust solutions obtained by varying the uncertainty set's parameters. Our central geometric insight is that a robust path can be characterized as a Bregman projection of a curve (whose geometry is defined by the uncertainty set) onto the feasible region. This leads to a surprising discovery that the robust path can be approximated via the trajectories of standard optimization algorithms, such as the proximal point method, of the deterministic counterpart problem. We give a sharp approximation error bound and show it depends on the geometry of the feasible region and the uncertainty set. We also illustrate two special cases where the approximation error is zero: the feasible region is polyhedrally monotone (e.g., a simplex feasible region under an ellipsoidal uncertainty set), or the feasible region and the uncertainty set follow a dual relationship. We demonstrate the practical impact of this approach in two settings: portfolio optimization and adversarial deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20039v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hao Hao, Peter Zhang</dc:creator>
    </item>
    <item>
      <title>Nagumo-Type Characterization of Forward Invariance for Constrained Systems</title>
      <link>https://arxiv.org/abs/2508.20045</link>
      <description>arXiv:2508.20045v1 Announce Type: new 
Abstract: This paper proposes a Nagumo-type invariance condition for differential inclusions defined on closed constraint sets. More specifically, given a closed set to render forward invariant, the proposed condition restricts the system's dynamics, assumed to be locally Lipschitz, on the boundary of the set restricted to the interior of the constraint set. In particular, when the boundary of the set is entirely within the interior of the constraint set, the proposed condition reduces to the well-known Nagumo condition, known to be necessary and sufficient for forward invariance in this case. This being said, the proposed condition is only necessary in the general setting. As a result, we provide a set of additional assumptions relating the constrained system to the set to render forward invariant, and restricting to the geometry at the intersection between the two sets, so that the equivalence holds. The importance of the proposed assumptions is illustrated via examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20045v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olayo Reynaud, Mohamed Maghenem, Adnane Saoud, Sadek Belamfedel Alaoui, Ahmad Hably</dc:creator>
    </item>
    <item>
      <title>Moment Constrained Optimal Transport for Thermostatically Controlled Loads</title>
      <link>https://arxiv.org/abs/2508.20059</link>
      <description>arXiv:2508.20059v1 Announce Type: new 
Abstract: Controlling large populations of thermostatically controlled loads (TCLs), such as water heaters, poses significant challenges due to the need to balance global constraints (e.g., grid stability) with individual requirements (e.g., physical limits and quality of service). In this work, we introduce a novel framework based on Moment Constrained Optimal Transport (MCOT) for distributed control of TCLs. By formulating the control problem as an optimal transport problem with moment constraints, our approach integrates global consumption constraints and physical feasibility conditions into the control design. This problem with high (or infinite) dimensionality can be reduced to a much lower finite-dimensional problem. The structure of this problem allows for computing the gradient with Monte Carlo methods by generating trajectories of TCLs. Contrary to all previous work, in our MCOT framework, it is possible to choose the sampling law, which considerably speeds up the calculations. This algorithm mitigates the need for extensive state-space discretization and significantly reduces computational complexity compared to existing methods. Numerical experiments in a water heater case study demonstrate that our MCOT-based method effectively coordinates TCLs under various constraints. We further extend our approach to an online setting, illustrating its practical applicability on simulated data from the SMACH (Multi-agent Simulation of Human Activity in the Household) platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20059v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Le Corre, Julien Cardinal, Ana Bu\v{s}i\'c</dc:creator>
    </item>
    <item>
      <title>A Partially Derivative-Free Proximal Method for Composite Multiobjective Optimization in the H\"older Setting</title>
      <link>https://arxiv.org/abs/2508.20071</link>
      <description>arXiv:2508.20071v1 Announce Type: new 
Abstract: This paper presents an algorithm for solving multiobjective optimization problems involving composite functions, where we minimize a quadratic model that approximates $F(x) - F(x^k)$ and that can be derivative-free. We establish theoretical assumptions about the component functions of the composition and provide comprehensive convergence and complexity analysis. Specifically, we prove that the proposed method converges to a weakly $\varepsilon$-approximate Pareto point in at most $\mathcal{O}\left(\varepsilon^{-\frac{\beta+1}{\beta}}\right)$ iterations, where $\beta$ denotes the H\"{o}lder exponent of the gradient. The algorithm incorporates gradient approximations and a scaling matrix $B_k$ to achieve an optimal balance between computational accuracy and efficiency. Numerical experiments on robust biobjective instances with Lipschitz and H\"{o}lder-gradient components illustrate the method's behavior. In these tests, the proposed approach was able to approximate the Pareto front under different levels of uncertainty and consistently recovered distinct solutions, even in challenging cases where the objectives have only H\"{o}lder continuous gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20071v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V. S. Amaral, P. B. Assun\c{c}\~ao, D. R. Souza</dc:creator>
    </item>
    <item>
      <title>Set-membership identification of continuous-time MIMO systems via Tustin discretization</title>
      <link>https://arxiv.org/abs/2508.19348</link>
      <description>arXiv:2508.19348v1 Announce Type: cross 
Abstract: In this paper, we deal with the identification of continuous-time systems from sampled data corrupted by unknown but bounded errors. A significant challenge in continuous-time identification is the estimation of the input and output data derivatives. In this paper, we propose a novel method based on set-membership techniques and Tustin discretization, which overcomes the derivative measurement problem and the presence of bounded errors affecting all the measured signals. First, we derive the proposed method and prove that it becomes an affordable polynomial optimization problem. Then, we present some numerical results based on simulation and experimental data to explore the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19348v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vito Cerone, Sophie M. Fosson, Simone Pirrera, Diego Regruto</dc:creator>
    </item>
    <item>
      <title>Exploiting nonlinear incoherent image formation through linear volume metaoptics for inference</title>
      <link>https://arxiv.org/abs/2508.19436</link>
      <description>arXiv:2508.19436v1 Announce Type: cross 
Abstract: We showed that a 2D depth map representing an incoherent 3D opaque scene is directly encoded in the response function of an imaging optics. As a result, the optics creates an image that depends nonlinearly on the depth map. Furthermore, strong spatio-spectral dispersions in volume metaoptics can be engineered to create a complex image in response to a depth map. We hypothesize that this complexity will allow the linear volume metaoptics to nonlinearly sense and process 3D opaque scenes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19436v1</guid>
      <category>physics.optics</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Zhang, Arvin Keshvari, Ata Shakeri, Zin Lin</dc:creator>
    </item>
    <item>
      <title>Controllability of a One-Dimensional Dynamic Debonding Model</title>
      <link>https://arxiv.org/abs/2508.19755</link>
      <description>arXiv:2508.19755v1 Announce Type: cross 
Abstract: We investigate a one-dimensional dynamic debonding model, introduced by Freund (1990), in which the wave equation is coupled with a Griffith criterion governing the propagation of the fracture. In particular, we study the boundary controllability of the system to a prescribed target state. Our main results provide precise characterizations of the reachable target states, in both \( C^{ 0, 1 } \) and \( C^1 \) regularity settings, and construct exact controls toward these target states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19755v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola De Nitti, Arick Shao</dc:creator>
    </item>
    <item>
      <title>From Optimization to Control: Quasi Policy Iteration</title>
      <link>https://arxiv.org/abs/2311.11166</link>
      <description>arXiv:2311.11166v3 Announce Type: replace 
Abstract: Recent control algorithms for Markov decision processes (MDPs) have been designed using an implicit analogy with well-established optimization algorithms. In this paper, we adopt the quasi-Newton method (QNM) from convex optimization to introduce a novel control algorithm coined as quasi-policy iteration (QPI). In particular, QPI is based on a novel approximation of the ``Hessian'' matrix in the policy iteration algorithm, which exploits two linear structural constraints specific to MDPs and allows for the incorporation of prior information on the transition probability kernel. While the proposed algorithm has the same computational complexity as value iteration, it exhibits an empirical convergence behavior similar to that of QNM with a low sensitivity to the discount factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11166v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Amin Sharifi Kolarijani, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Exploiting Symmetries in Optimal Quantum Circuit Design</title>
      <link>https://arxiv.org/abs/2401.08262</link>
      <description>arXiv:2401.08262v2 Announce Type: replace 
Abstract: A physical limitation in quantum circuit design is the fact that gates in a quantum system can only act on qubits that are physically adjacent in the architecture. To overcome this problem, SWAP gates need to be inserted to make the circuit physically realizable. The nearest neighbour compliance problem (NNCP) asks for an optimal embedding of qubits in a given architecture such that the total number of SWAP gates to be inserted is minimized. In this paper we study the NNCP on general quantum architectures. Building upon an existing linear programming formulation, we show how the model can be reduced by exploiting the symmetries of the graph underlying the formulation. The resulting model is equivalent to a generalized network flow problem and follows from an in-depth analysis of the automorphism group of specific Cayley graphs. As a byproduct of our approach, we show that the NNCP is polynomial time solvable for several classes of symmetric quantum architectures. Numerical tests on various architectures indicate that the reduction in the number of variables and constraints is on average at least 90%. In particular, NNCP instances on the star architecture can be solved for quantum circuits up to 100 qubits and more than 1000 quantum gates within a very short computation time. These results are far beyond the computational capacity when solving the instances without the exploitation of symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08262v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank de Meijer, Dion Gijswijt, Renata Sotirov</dc:creator>
    </item>
    <item>
      <title>Analysis and Synthesis Denoisers for Forward-Backward Plug-and-Play Algorithms</title>
      <link>https://arxiv.org/abs/2411.13276</link>
      <description>arXiv:2411.13276v3 Announce Type: replace 
Abstract: In this work we study the behavior of the forward-backward (FB) algorithm when the proximity operator is replaced by a sub-iterative procedure to approximate a Gaussian denoiser, in a Plug-and-Play (PnP) fashion. In particular, we consider both analysis and synthesis Gaussian denoisers within a dictionary framework, obtained by unrolling dual-FB iterations or FB iterations, respectively. We analyze the associated minimization problems as well as the asymptotic behavior of the resulting FB-PnP iterations. In particular, we show that the synthesis Gaussian denoising problem can be viewed as a proximity operator. For each case, analysis and synthesis, we show that the FB-PnP algorithms solve the same problem whether we use only one or an infinite number of sub-iteration to solve the denoising problem at each iteration. To this aim, we show that each "one sub-iteration" strategy within the FB-PnP can be interpreted as a primal-dual algorithm when a warm-restart strategy is used. We further present similar results when using a Moreau-Yosida smoothing of the global problem, for an arbitrary number of sub-iterations. Finally, we provide numerical simulations to illustrate our theoretical results. In particular we first consider a toy compressive sensing example, as well as an image restoration problem in a deep dictionary framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13276v3</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthieu Kowalski, Beno\^it Mal\'ezieux, Thomas Moreau, Audrey Repetti</dc:creator>
    </item>
    <item>
      <title>Benchmarking Diffusion Annealing-Based Bayesian Inverse Problem Solvers</title>
      <link>https://arxiv.org/abs/2503.03007</link>
      <description>arXiv:2503.03007v2 Announce Type: replace 
Abstract: In recent years, the ascendance of diffusion modeling as a state-of-the-art generative modeling approach has spurred significant interest in their use as priors in Bayesian inverse problems. However, it is unclear how to optimally integrate a diffusion model trained on the prior distribution with a given likelihood function to obtain posterior samples. While algorithms developed for this purpose can produce high-quality, diverse point estimates of the unknown parameters of interest, they are often tested on problems where the prior distribution is analytically unknown, making it difficult to assess their performance in providing rigorous uncertainty quantification. Motivated by this challenge, this work introduces three benchmark problems for evaluating the performance of diffusion model based samplers. The benchmark problems, which are inspired by problems in image inpainting, x-ray tomography, and phase retrieval, have a posterior density that is analytically known. In this setting, approximate ground-truth posterior samples can be obtained, enabling principled evaluation of the performance of posterior sampling algorithms. This work also introduces a general framework for diffusion model based posterior sampling, Bayesian Inverse Problem Solvers through Diffusion Annealing (BIPSDA). This framework unifies several recently proposed diffusion-model-based posterior sampling algorithms and contains novel algorithms that can be realized through flexible combinations of design choices. We tested the performance of a set of BIPSDA algorithms, including previously proposed state-of-the-art approaches, on the proposed benchmark problems. The results provide insight into the strengths and limitations of existing diffusion-model based posterior samplers, while the benchmark problems provide a testing ground for future algorithmic developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03007v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/OJSP.2025.3597867</arxiv:DOI>
      <arxiv:journal_reference>IEEE Open J. Signal Process. 6 (2025) 975-991</arxiv:journal_reference>
      <dc:creator>Evan Scope Crafts, Umberto Villa</dc:creator>
    </item>
    <item>
      <title>Accelerating High-Capacity Ridepooling in Robo-Taxi Systems</title>
      <link>https://arxiv.org/abs/2505.07776</link>
      <description>arXiv:2505.07776v3 Announce Type: replace 
Abstract: Rapid urbanization has increased demand for customized urban mobility, making on-demand services and robo-taxis central to future transportation. The efficiency of these systems hinges on real-time fleet coordination algorithms. This work accelerates the state-of-the-art high-capacity ridepooling framework by identifying its computational bottlenecks and introducing two complementary strategies: (i) a data-driven feasibility predictor that filters low-potential trips, and (ii) a graph-partitioning scheme that enables parallelizable trip generation. Using real-world Manhattan demand data, we show that the acceleration algorithms reduce the optimality gap by up to 27% under real-time constraints and cut empty travel time by up to 5%. These improvements translate into tangible economic and environmental benefits, advancing the scalability of high-capacity robo-taxi operations in dense urban settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07776v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinling Li, Daniele Gammelli, Alex Wallar, Jinhua Zhao, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>Greedy Matching in Optimal Transport with concave cost</title>
      <link>https://arxiv.org/abs/2307.03140</link>
      <description>arXiv:2307.03140v2 Announce Type: replace-cross 
Abstract: We consider the optimal transport problem between a set of $n$ red points and a set of $n$ blue points subject to a concave cost function such as $c(x,y) = \|x-y\|^{p}$ for $0&lt; p &lt; 1$. Our focus is on a particularly simple matching algorithm: match the closest red and blue point, remove them both and repeat. We prove that it provides good results in any metric space $(X,d)$ when the cost function is $c(x,y) = d(x,y)^{p}$ with $0 &lt; p &lt; 1/2$. Empirically, the algorithm produces results that are remarkably close to optimal -- especially as the cost function gets more concave; this suggests that greedy matching may be a good toy model for Optimal Transport for very concave transport cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03140v2</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Ottolini, Stefan Steinerberger</dc:creator>
    </item>
    <item>
      <title>Secure Set-based State Estimation for Safety-Critical Applications under Adversarial Attacks on Sensors</title>
      <link>https://arxiv.org/abs/2309.05075</link>
      <description>arXiv:2309.05075v3 Announce Type: replace-cross 
Abstract: Set-based state estimation provides guaranteed state inclusion certificates that are crucial for the safety verification of dynamical systems. However, when system sensors are subject to cyberattacks, maintaining both safety and security guarantees becomes a fundamental challenge that existing point-based secure state estimation methods cannot adequately address due to their inherent inability to provide state inclusion certificates. This paper introduces a novel approach that simultaneously ensures safety guarantees through guaranteed state inclusion and security guarantees against sensor attacks, without imposing conservative restrictions on system operation. We propose a Secure Set-based State Estimation (S3E) algorithm that maintains the true system state within the estimated set under sensor attacks, provided the initialization set contains the initial state and the system remains observable from the uncompromised sensor subset. The algorithm gives the estimated set as a collection of constrained zonotopes (agreement sets), which can be employed as robust certificates for verifying whether the system adheres to safety constraints. Furthermore, we demonstrate that the estimated set remains unaffected by attack signals of sufficiently large magnitude and also establish sufficient conditions for attack detection, identification, and filtering. This compels the attacker to only inject signals of small magnitudes to evade detection, thus preserving the accuracy of the estimated set. To address the computational complexity of the algorithm, we offer several strategies for complexity-performance trade-offs. The efficacy of the proposed algorithm is illustrated through several examples, including its application to a three-story building model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05075v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Umar B. Niazi, Michelle S. Chong, Amr Alanwar, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Conditional Wasserstein Distances with Applications in Bayesian OT Flow Matching</title>
      <link>https://arxiv.org/abs/2403.18705</link>
      <description>arXiv:2403.18705v3 Announce Type: replace-cross 
Abstract: In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback--Leibler divergence, this is in general not hold true for the Wasserstein distance. In this paper, we introduce a conditional Wasserstein distance via a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. Interestingly, the dual formulation of the conditional Wasserstein-1 flow resembles losses in the conditional Wasserstein GAN literature in a quite natural way. We derive theoretical properties of the conditional Wasserstein distance, characterize the corresponding geodesics and velocity fields as well as the flow ODEs. Subsequently, we propose to approximate the velocity fields by relaxing the conditional Wasserstein distance. Based on this, we propose an extension of OT Flow Matching for solving Bayesian inverse problems and demonstrate its numerical advantages on an inverse problem and class-conditional image generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18705v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannis Chemseddine, Paul Hagemann, Gabriele Steidl, Christian Wald</dc:creator>
    </item>
    <item>
      <title>Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence</title>
      <link>https://arxiv.org/abs/2412.18164</link>
      <description>arXiv:2412.18164v3 Announce Type: replace-cross 
Abstract: Diffusion models have emerged as powerful tools for generative modeling, demonstrating exceptional capability in capturing target data distributions from large datasets. However, fine-tuning these massive models for specific downstream tasks, constraints, and human preferences remains a critical challenge. While recent advances have leveraged reinforcement learning algorithms to tackle this problem, much of the progress has been empirical, with limited theoretical understanding. To bridge this gap, we propose a stochastic control framework for fine-tuning diffusion models. Building on denoising diffusion probabilistic models as the pre-trained reference dynamics, our approach integrates linear dynamics control with Kullback-Leibler regularization. We establish the well-posedness and regularity of the stochastic control problem and develop a policy iteration algorithm (PI-FT) for numerical solution. We show that PI-FT achieves global convergence at a linear rate. Unlike existing work that assumes regularities throughout training, we prove that the control and value sequences generated by the algorithm maintain the regularity. Additionally, we explore extensions of our framework to parametric settings and continuous-time formulations, and demonstrate the practical effectiveness of the proposed PI-FT algorithm through numerical experiments. Our code is available at https://github.com/yinbinhan/fine-tuning-of-diffusion-models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18164v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Forty-Second International Conference on Machine Learning 2025</arxiv:journal_reference>
      <dc:creator>Yinbin Han, Meisam Razaviyayn, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>PAC Learnability of Scenario Decision-Making Algorithms: Necessary Conditions and Sufficient Conditions</title>
      <link>https://arxiv.org/abs/2501.08887</link>
      <description>arXiv:2501.08887v2 Announce Type: replace-cross 
Abstract: We investigate the Probably Approximately Correct (PAC) property of scenario decision algorithms, which refers to their ability to produce decisions with an arbitrarily low risk of violating unknown safety constraints, provided a sufficient number of realizations of these constraints are sampled. While several PAC sufficient conditions for such algorithms exist in the literature -- such as the finiteness of the VC dimension of their associated classifiers, or the existence of a compression scheme -- it remains unclear whether these conditions are also necessary. In this work, we demonstrate through counterexamples that these conditions are not necessary in general. These findings stand in contrast to binary classification learning, where analogous conditions are both sufficient and necessary for a family of classifiers to be PAC. Furthermore, we extend our analysis to stable scenario decision algorithms, a broad class that includes practical methods like scenario optimization. Even under this additional assumption, we show that the aforementioned conditions remain unnecessary. Furthermore, we introduce a novel quantity, called the dVC dimension, which serves as an analogue to the VC dimension for scenario decision algorithms. We prove that the finiteness of this dimension is a PAC necessary condition for scenario decision algorithms. This allows to (i) guide algorithm users and designers to recognize algorithms that are not PAC, and (ii) contribute to a comprehensive characterization of PAC scenario decision algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08887v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume O. Berger, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>Ranking matters: Does the new format select the best teams for the knockout phase in the UEFA Champions League?</title>
      <link>https://arxiv.org/abs/2503.13569</link>
      <description>arXiv:2503.13569v2 Announce Type: replace-cross 
Abstract: Starting in the 2024/25 season, the Union of European Football Associations (UEFA) has fundamentally changed the format of its club competitions: the group stage has been replaced by a league phase played by 36 teams in an incomplete round robin format. This makes ranking the teams based on their results challenging because teams play against different sets of opponents, whose strengths vary. In this research note, we apply several well-known ranking methods for incomplete round robin tournaments to the 2024/25 UEFA Champions League league phase in order to check the robustness of the official ranking, as well as to call the attention of organizers to the non-trivial issue of ranking in these competitions. Our results show that it is doubtful whether the currently used point-based system provides the best ranking of the teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13569v2</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, Karel Devriesere, Dries Goossens, Andr\'as Gyimesi, Roel Lambers, Frits Spieksma</dc:creator>
    </item>
    <item>
      <title>Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2506.22971</link>
      <description>arXiv:2506.22971v3 Announce Type: replace-cross 
Abstract: This paper introduces a two-timescale hierarchical decentralized control architecture for Cyber-Physical Systems (CPS). The system consists of a global controller (GC), and N local controllers (LCs). The GC operates at a slower timescale, imposing budget constraints on the actions of LCs, which function at a faster timescale. Applications can be found in energy grid planning, wildfire management, and other decentralized resource allocation problems. We propose and analyze two optimization frameworks for this setting: COpt and FOpt. In COpt, both GC and LCs together optimize infinite-horizon discounted rewards, while in FOpt the LCs optimize finite-horizon episodic rewards, and the GC optimizes infinite-horizon rewards. Although both frameworks share identical reward functions, their differing horizons can lead to different optimal policies. In particular, FOpt grants greater autonomy to LCs by allowing their policies to be determined only by local objectives, unlike COpt. To our knowledge, these frameworks have not been studied in the literature. We establish the formulations, prove the existence of optimal policies, and prove the convergence of their value iteration algorithms. We further show that COpt always achieves a higher value function than FOpt and derive explicit bounds on their difference. Finally, we establish a set of sufficient structural conditions under which the two frameworks become equivalent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22971v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kesav Kaza, Ramachandran Anantharaman, Rahul Meshram</dc:creator>
    </item>
  </channel>
</rss>
