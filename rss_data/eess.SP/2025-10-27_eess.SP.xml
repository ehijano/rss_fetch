<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Oct 2025 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Automated Tinnitus Detection Through Dual-Modality Neuroimaging: EEG Microstate Analysis and Resting-State fMRI Classification Using Deep Learning</title>
      <link>https://arxiv.org/abs/2510.21748</link>
      <description>arXiv:2510.21748v1 Announce Type: new 
Abstract: Objective: Tinnitus affects 10-15% of the population yet lacks objective diagnostic biomarkers. This study applied machine learning to EEG and fMRI data to identify neural signatures distinguishing tinnitus patients from healthy controls. Methods: Two datasets were analyzed: 64-channel EEG recordings from 80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38 participants (19 tinnitus, 19 controls). EEG analysis extracted microstate features across four to seven clustering states and five frequency bands, producing 440 features per subject. Global Field Power signals were also transformed into wavelet images for deep learning. fMRI data were analyzed using slice-wise convolutional neural networks and hybrid models combining pre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest, and SVM classifiers. Model performance was evaluated using 5-fold cross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC. Results: EEG microstate analysis revealed altered network dynamics in tinnitus, particularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs tinnitus: 43.81, p &lt; 0.001) and diminished alpha coverage. Tree-based classifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed EEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively. fMRI analysis identified 12 high-performing axial slices (&gt;=90% accuracy), with slice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95% +/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural biomarkers for tinnitus classification. Tree-based and hybrid models demonstrated superior performance, highlighting tinnitus as a multi-network disorder requiring multimodal analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21748v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiana Kiashemshaki, Sina Samieirad, Sarvenaz Erfani, Aryan Jalaeianbanayan, Nasibeh Asadi Isakan, Hossein Najafzadeh</dc:creator>
    </item>
    <item>
      <title>Monitoring Real-Time ECG Signals on Mobile Systems</title>
      <link>https://arxiv.org/abs/2510.21789</link>
      <description>arXiv:2510.21789v1 Announce Type: new 
Abstract: This study focuses on the connection of a development kit that enables real-time monitoring of electrocardiogram (ECG) signals using a mobile system. A software developed on the Visual Studio .NET platform reads real-time ECG signals from the human body through non invasive methods and displays them graphically on the mobile system. ECG electrodes placed on specific areas of the body using the method known as Einthoven's triangle. Subsequently, the software initiates data flow through the serial port, and these data displayed as signal values on the mobile device's screen via a graphical interface. When the monitored ECG signals fall below a certain threshold or reach a critical value, the system provides feedback with an alert based on medical data. The developed system is fully portable. Additionally, the implemented system has the potential to form the basis for a multi-purpose system in the future, such as online patient monitoring, patient location tracking, and even initial intervention using the defibrillation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21789v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beyazit Bestami Yuksel</dc:creator>
    </item>
    <item>
      <title>Adaptive Split-MMD Training for Small-Sample Cross-Dataset P300 EEG Classification</title>
      <link>https://arxiv.org/abs/2510.21969</link>
      <description>arXiv:2510.21969v1 Announce Type: new 
Abstract: Detecting single-trial P300 from EEG is difficult when only a few labeled trials are available. When attempting to boost a small target set with a large source dataset through transfer learning, cross-dataset shift arises. To address this challenge, we study transfer between two public visual-oddball ERP datasets using five shared electrodes (Fz, Pz, P3, P4, Oz) under a strict small-sample regime (target: 10 trials/subject; source: 80 trials/subject). We introduce Adaptive Split Maximum Mean Discrepancy Training (AS-MMD), which combines (i) a target-weighted loss with warm-up tied to the square root of the source/target size ratio, (ii) Split Batch Normalization (Split-BN) with shared affine parameters and per-domain running statistics, and (iii) a parameter-free logit-level Radial Basis Function kernel Maximum Mean Discrepancy (RBF-MMD) term using the median-bandwidth heuristic. Implemented on an EEG Conformer, AS-MMD is backbone-agnostic and leaves the inference-time model unchanged. Across both transfer directions, it outperforms target-only and pooled training (Active Visual Oddball: accuracy/AUC 0.66/0.74; ERP CORE P3: 0.61/0.65), with gains over pooling significant under corrected paired t-tests. Ablations attribute improvements to all three components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21969v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiyu Chen, Arnaud Delorme</dc:creator>
    </item>
    <item>
      <title>Experimental Demonstration of Multi-Object Tracking in Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2510.22180</link>
      <description>arXiv:2510.22180v1 Announce Type: new 
Abstract: For a wide range of envisioned integrated sensing and communication (ISAC) use cases, it is necessary to incorporate tracking techniques into cellular communication systems. While numerous multi-object tracking algorithms exist, they have not yet been applied to real-world ISAC, with its challenges such as clutter and non-optimal hardware. In this work, we showcase multi-object tracking based on the probability hypothesis density (PHD) filter in the range and Doppler speed domain. The measurements are taken with a 5G compliant ISAC proof-of-concept in a real factory environment, where the pedestrian-like objects are generated by a radar object emulator. We detail the complete pipeline, from measurement acquisition to evaluation, with a focus on the post-processing of the raw captured data and the tracking itself. Our end-to-end evaluation and comparison to simulations show good multi-object tracking performance with mean absolute error &lt;1.5m and detection rates &gt;91% for realistic but challenging scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22180v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maximilian Bauhofer, Marcus Henninger, Meik Kottkamp, Lucas Giroto, Philip Grill, Alexander Felix, Thorsten Wild, Stephan ten Brink, Silvio Mandelli</dc:creator>
    </item>
    <item>
      <title>Angular Estimation Comparison with ISAC PoC</title>
      <link>https://arxiv.org/abs/2510.22297</link>
      <description>arXiv:2510.22297v1 Announce Type: new 
Abstract: The introduction of Integrated Sensing and Communications (ISAC) in cellular systems is not expected to result in a shift away from the popular choice of cost- and energy-efficient analog or hybrid beamforming structures. However, this comes at the cost of limiting the angular capabilities to a confined space per acquisitions. Thus, as a prerequisite for the successful implementation of numerous ISAC use cases, the need for an optimal angular estimation of targets and their separation based on the minimal number of angular samples arises.
  In this work, different approaches for angular estimation based on a minimal, DFT-based set of angular samples are evaluated. The samples are acquired through sweeping multiple beams of an ISAC proof of concept (PoC) in the industrial scenario of the ARENA2036. The study's findings indicate that interpolation approaches are more effective for generalizing across different types of angular scenarios. While the orthogonal matching pursuit (OMP) approach exhibits the most accurate estimation for a single, strong and clearly discriminable target, the DFT-based interpolation approach demonstrates the best overall estimation performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22297v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Felix, Rudolf Hoffmann, Marcus Henninger, Stephan ten Brink, Silvio Mandelli</dc:creator>
    </item>
    <item>
      <title>Data-driven, Wavelet-based Identification and Reduced-order Modeling of Linear Systems with Closely Spaced Modes</title>
      <link>https://arxiv.org/abs/2510.22406</link>
      <description>arXiv:2510.22406v1 Announce Type: new 
Abstract: This work presents a purely data-driven, wavelet-based framework for modal identification and reduced-order modeling of mechanical systems with assumed linear dynamics characterized by closely spaced modes with classical or non-classical damping distribution. Traditional Fourier-based methods often fail to reliably identify closely spaced modes or accurately capture modal interactions and complexities. To address these limitations, we propose a methodology leveraging the enhanced time -frequency resolution capabilities of the continuous wavelet transform (CWT). By selecting appropriate harmonic regions within the wavelet spectra, we effectively isolate modes, and then invert them back in the temporal domain by applying the inverse CWT (ICWT). In this way we reconstruct the corresponding modal dynamics in the time domain. Using the Hilbert transform, instantaneous phases are extracted for each identified mode, enabling the introduction of a complexified modal matrix which robustly characterizes the system's modal properties, even under challenging perturbations such as noise and uncertainties due to modal interference and unmodeled effects. The identified modal parameters are utilized to reconstruct the frequency response functions (FRFs) of the system and to develop a reduced-order model (ROM) that captures accurately the system's dominant dynamical behavior valid in a specified frequency range.. Validation of the methodology is conducted both with a numerical non-classical damping and an experimental testbed representing a model of an airplane structure. Results demonstrate the effectiveness of the proposed approach in resolving intricate modal interactions and accurately reproducing the dynamic response of complex structural systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22406v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anargyros Michaloliakos, Benjamin J. Chang, Lawrence A. Bergman, Alexander F. Vakakis</dc:creator>
    </item>
    <item>
      <title>Genetic Optimization of a Software-Defined GNSS Receiver</title>
      <link>https://arxiv.org/abs/2510.22417</link>
      <description>arXiv:2510.22417v1 Announce Type: new 
Abstract: Commercial off-the-shelf (COTS) Global Navigation Satellite System (GNSS) receivers face significant limitations under high-dynamic conditions, particularly in high-acceleration environments such as those experienced by launch vehicles. These performance degradations, often observed as discontinuities in the navigation solution, arise from the inability of traditional tracking loop bandwidths to cope with rapid variations in synchronization parameters. Software-Defined Radio (SDR) receivers overcome these constraints by enabling flexible reconfiguration of tracking loops; however, manual tuning involves a complex, multidimensional search and seldom ensures optimal performance. This work introduces a genetic algorithm-based optimization framework that autonomously explores the receiver configuration space to determine optimal loop parameters for phase, frequency, and delay tracking. The approach is validated within an SDR environment using realistically simulated GPS L1 signals for three representative dynamic regimes -guided rocket flight, Low Earth Orbit (LEO) satellite, and static receiver-processed with the open-source GNSS-SDR architecture. Results demonstrate that evolutionary optimization enables SDR receivers to maintain robust and accurate Position, Velocity, and Time (PVT) solutions across diverse dynamic conditions. The optimized configurations yielded maximum position and velocity errors of approximately 6 m and 0.08 m/s for the static case, 12 m and 2.5 m/s for the rocket case, and 5 m and 0.2 m/s for the LEO case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22417v1</guid>
      <category>eess.SP</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Laura Train, Rodrigo Castellanos, Miguel G\'omez-L\'opez</dc:creator>
    </item>
    <item>
      <title>Data-driven Exponential Framing for Pulsive Temporal Patterns without Repetition or Singularity</title>
      <link>https://arxiv.org/abs/2510.22472</link>
      <description>arXiv:2510.22472v1 Announce Type: new 
Abstract: Extracting pulsive temporal patterns from a small dataset without their repetition or singularity shows significant importance in manufacturing applications but does not sufficiently attract scientific attention. We propose to quantify how long temporal patterns appear without relying on their repetition or singularity, enabling to extract such temporal patterns from a small dataset. Inspired by the celebrated time delay embedding and data-driven Hankel matrix analysis, we introduce a linear dynamical system model on the time-delay coordinates behind the data to derive the discrete-time bases each of which has a distinct exponential decay constant. The derived bases are fitted onto subsequences that are extracted with a sliding window in order to quantify how long patterns are dominant in the set of subsequences. We call the quantification method Data-driven Exponential Framing (DEF). A toy model-based experiment shows that DEF can identify multiple patterns with distinct lengths. DEF is also applied to electric current measurement on a punching machine, showing its possibility to extract multiple patterns from real-world oscillatory data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22472v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohei Kono, Yoshiyuki Tajima</dc:creator>
    </item>
    <item>
      <title>Large-Model AI for Near Field Beam Prediction: A CNN-GPT2 Framework for 6G XL-MIMO</title>
      <link>https://arxiv.org/abs/2510.22557</link>
      <description>arXiv:2510.22557v1 Announce Type: new 
Abstract: The emergence of extremely large-scale antenna arrays (ELAA) in millimeter-wave (mmWave) communications, particularly in high-mobility scenarios, highlights the importance of near-field beam prediction. Unlike the conventional far-field assumption, near-field beam prediction requires codebooks that jointly sample the angular and distance domains, which leads to a dramatic increase in pilot overhead. Moreover, unlike the far- field case where the optimal beam evolution is temporally smooth, the optimal near-field beam index exhibits abrupt and nonlinear dynamics due to its joint dependence on user angle and distance, posing significant challenges for temporal modeling. To address these challenges, we propose a novel Convolutional Neural Network-Generative Pre-trained Transformer 2 (CNN-GPT2) based near-field beam prediction framework. Specifically, an uplink pilot transmission strategy is designed to enable efficient channel probing through widebeam analog precoding and frequency-varying digital precoding. The received pilot signals are preprocessed and passed through a CNN-based feature extractor, followed by a GPT-2 model that captures temporal dependencies across multiple frames and directly predicts the near-field beam index in an end-to-end manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22557v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Liu, Cunhua Pan, Hong Ren, Wei Zhang, Cheng-Xiang Wang, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Parametric Channel Estimation and Design for Active-RIS-Assisted Communications</title>
      <link>https://arxiv.org/abs/2510.22621</link>
      <description>arXiv:2510.22621v1 Announce Type: new 
Abstract: Reconfigurable Intelligent Surface (RIS) technology has emerged as a key enabler for future wireless communications. However, its potential is constrained by the difficulty of acquiring accurate user-to-RIS channel state information (CSI), due to the cascaded channel structure and the high pilot overhead of non-parametric methods. Unlike a passive RIS, where the reflected signal suffers from multiplicative path loss, an active RIS amplifies the signal, improving its practicality in real deployments. In this letter, we propose a parametric channel estimation method tailored for active RISs. The proposed approach integrates an active RIS model with an adaptive Maximum Likelihood Estimator (MLE) to recover the main channel parameters using a minimal number of pilots. To further enhance performance, an adaptive active RIS configuration strategy is employed, which refines the beam direction based on an initial user location estimate. Moreover, an orthogonal angle-pair codebook is used instead of the conventional Discrete Fourier Transform (DFT) codebook, significantly reducing the codebook size and ensuring reliable operation for both far-field and near-field users. Extensive simulations demonstrate that the proposed method achieves near-optimal performance with very few pilots compared to non-parametric approaches. Its performance is also benchmarked against that of a traditional passive RIS under the same total power budget to ensure fairness. Results show that active RIS yields higher spectral efficiency (SE) by eliminating the multiplicative fading inherent in passive RISs and allocating more resources to data transmission</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22621v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md. Shahriar Sadid, Ali A. Nasir, Saad Al-Ahmadi, Samir Al-Ghadhban</dc:creator>
    </item>
    <item>
      <title>Enhancing WiFi CSI Fingerprinting: A Deep Auxiliary Learning Approach</title>
      <link>https://arxiv.org/abs/2510.22731</link>
      <description>arXiv:2510.22731v1 Announce Type: new 
Abstract: Radio frequency (RF) fingerprinting techniques provide a promising supplement to cryptography-based approaches but rely on dedicated equipment to capture in-phase and quadrature (IQ) samples, hindering their wide adoption. Recent advances advocate easily obtainable channel state information (CSI) by commercial WiFi devices for lightweight RF fingerprinting, while falling short in addressing the challenges of coarse granularity of CSI measurements in an open-world setting. In this paper, we propose CSI2Q, a novel CSI fingerprinting system that achieves comparable performance to IQ-based approaches. Instead of extracting fingerprints directly from raw CSI measurements, CSI2Q first transforms frequency-domain CSI measurements into time-domain signals that share the same feature space with IQ samples. Then, we employ a deep auxiliary learning strategy to transfer useful knowledge from an IQ fingerprinting model to the CSI counterpart. Finally, the trained CSI model is combined with an OpenMax function to estimate the likelihood of unknown ones. We evaluate CSI2Q on one synthetic CSI dataset involving 85 devices and two real CSI datasets, including 10 and 25 WiFi routers, respectively. Our system achieves accuracy increases of at least 16% on the synthetic CSI dataset, 20% on the in-lab CSI dataset, and 17% on the in-the-wild CSI dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22731v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2025.3625062</arxiv:DOI>
      <dc:creator>Yong Huang, Wenjing Wang, Dalong Zhang, Junjie Wang, Chen Chen, Yan Cao, Wei Wang</dc:creator>
    </item>
    <item>
      <title>Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2510.22772</link>
      <description>arXiv:2510.22772v1 Announce Type: new 
Abstract: Radar-based human activity recognition (HAR) is attractive for unobtrusive and privacy-preserving monitoring, yet many CNN/RNN solutions remain too heavy for edge deployment, and even lightweight ViT/SSM variants often exceed practical compute and memory budgets. We introduce Neural-HAR, a dimension-gated CNN accelerator tailored for real-time radar HAR on resource-constrained platforms. At its core is GateCNN, a parameter-efficient Doppler-temporal network that (i) embeds Doppler vectors to emphasize frequency evolution over time and (ii) applies dual-path gated convolutions that modulate Doppler-aware content features with temporal gates, complemented by a residual path for stable training. On the University of Glasgow UoG2020 continuous radar dataset, GateCNN attains 86.4% accuracy with only 2.7k parameters and 0.28M FLOPs per inference, comparable to CNN-BiGRU at a fraction of the complexity. Our FPGA prototype on Xilinx Zynq-7000 Z-7007S reaches 107.5 $\mu$s latency and 15 mW dynamic power using LUT-based ROM and distributed RAM only (zero DSP/BRAM), demonstrating real-time, energy-efficient edge inference. Code and HLS conversion scripts are available at https://github.com/lab-emi/AIRHAR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22772v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhuo Wu, Francesco Fioranelli, Chang Gao</dc:creator>
    </item>
    <item>
      <title>Rmd: Robust Modal Decomposition with Constrained Bandwidth</title>
      <link>https://arxiv.org/abs/2510.22895</link>
      <description>arXiv:2510.22895v1 Announce Type: new 
Abstract: Modal decomposition techniques, such as Empirical Mode Decomposition (EMD), Variational Mode Decomposition (VMD), and Singular Spectrum Analysis (SSA), have advanced time-frequency signal analysis since the early 21st century. These methods are generally classified into two categories: numerical optimization-based methods (EMD, VMD) and spectral decomposition methods (SSA) that consider the physical meaning of signals. The former can produce spurious modes due to the lack of physical constraints, while the latter is more sensitive to noise and struggles with nonlinear signals. Despite continuous improvements in these methods, a modal decomposition approach that effectively combines the strengths of both categories remains elusive. This paper thus proposes a Robust Modal Decomposition (RMD) method with constrained bandwidth, which preserves the intrinsic structure of the signal by mapping the time series into its trajectory-GRAM matrix in phase space. Moreover, the method incorporates bandwidth constraints during the decomposition process, enhancing noise resistance. Extensive experiments on synthetic and real-world datasets, including millimeter-wave radar echoes, electrocardiogram (ECG), phonocardiogram (PCG), and bearing fault detection data, demonstrate the method's effectiveness and versatility. All code and dataset samples are available on GitHub: https://github.com/Einstein-sworder/RMD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22895v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wang Hao, Kuang Zhang, Hou Chengyu, Yang Yifan, Tan Chenxing, Fu Weifeng</dc:creator>
    </item>
    <item>
      <title>Clinic-Oriented Feasibility of a Sensor-Fused Wearable for Upper-Limb Function</title>
      <link>https://arxiv.org/abs/2510.22913</link>
      <description>arXiv:2510.22913v1 Announce Type: new 
Abstract: Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of daily living (ADL) and reduce adherence to home rehabilitation. Objective: To assess technical feasibility and clinician-relevant signals of a sensor-fused wearable targeting the triceps brachii and extensor pollicis brevis. Methods: A lightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and flex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and a safety-bounded assist policy (angle/torque/jerk limits; stall/time-out). Healthy adults (n = 12) performed three ADL-like tasks. Primary outcomes: Tremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$). Secondary: EMG median-frequency slope (fatigue trend), closed-loop latency, session completion, and device-related adverse events. Analyses used subject-level paired medians with BCa 95\% CIs; exact Wilcoxon $p$-values are reported in the Results. Results: Assistance was associated with lower tremor prominence and improved task throughput: TI decreased by $-0.092$ (95\% CI [$-0.102$, $-0.079$]), ROM increased by $+12.65\%$ (95\% CI [$+8.43$, $+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\% CI [$+2.61$, $+3.35$]). Median on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were completed with no device-related adverse events. Conclusions: Multimodal sensing with low-latency, safety-bounded assistance produced improved movement quality (TI $\downarrow$) and throughput (ROM, Reps $\uparrow$) in a pilot technical-feasibility setting, supporting progression to IRB-approved patient studies. Trial registration: Not applicable (pilot non-clinical).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22913v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanyanee Srichaisak, Arissa Ieochai, Aueaphum Aueawattthanaphisut</dc:creator>
    </item>
    <item>
      <title>Intelligent Multimodal Multi-Sensor Fusion-Based UAV Identification, Localization, and Countermeasures for Safeguarding Low-Altitude Economy</title>
      <link>https://arxiv.org/abs/2510.22947</link>
      <description>arXiv:2510.22947v1 Announce Type: new 
Abstract: The development of the low-altitude economy has led to a growing prominence of uncrewed aerial vehicle (UAV) safety management issues. Therefore, accurate identification, real-time localization, and effective countermeasures have become core challenges in airspace security assurance. This paper introduces an integrated UAV management and control system based on deep learning, which integrates multimodal multi-sensor fusion perception, precise positioning, and collaborative countermeasures. By incorporating deep learning methods, the system combines radio frequency (RF) spectral feature analysis, radar detection, electro-optical identification, and other methods at the detection level to achieve the identification and classification of UAVs. At the localization level, the system relies on multi-sensor data fusion and the air-space-ground integrated communication network to conduct real-time tracking and prediction of UAV flight status, providing support for early warning and decision-making. At the countermeasure level, it adopts comprehensive measures that integrate ``soft kill'' and ``hard kill'', including technologies such as electromagnetic signal jamming, navigation spoofing, and physical interception, to form a closed-loop management and control process from early warning to final disposal, which significantly enhances the response efficiency and disposal accuracy of low-altitude UAV management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22947v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Tao, Zhen Gao, Fangquan Ye, Jingbo Xu, Tao Song, Weidong Li, Yu Su, Lu Peng, Xiaomei Wu, Tong Qin, Zhongxiang Li, Dezhi Zheng</dc:creator>
    </item>
    <item>
      <title>PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming</title>
      <link>https://arxiv.org/abs/2510.22948</link>
      <description>arXiv:2510.22948v1 Announce Type: new 
Abstract: A pinching-antenna system (PASS)-enhanced mobile edge computing (MEC) architecture is investigated to improve the task offloading efficiency and latency performance in dynamic wireless environments. By leveraging dielectric waveguides and flexibly adjustable pinching antennas, PASS establishes short-distance line-of-sight (LoS) links while effectively mitigating the significant path loss and potential signal blockage, making it a promising solution for high-frequency MEC systems. We formulate a network latency minimization problem to joint optimize uplink PASS beamforming and task offloading. The resulting problem is modeled as a Markov decision process (MDP) and solved via the deep reinforcement learning (DRL) method. To address the instability introduced by the $\max$ operator in the objective function, we propose a load balancing-aware proximal policy optimization (LBPPO) algorithm. LBPPO incorporates both node-level and waveguide-level load balancing information into the policy design, maintaining computational and transmission delay equilibrium, respectively. Simulation results demonstrate that the proposed PASS-enhanced MEC with adaptive uplink PASS beamforming exhibit stronger convergence capability than fixed-PA baselines and conventional MIMO-assisted MEC, especially in scenarios with a large number of UEs or high transmit power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22948v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoming Hu, Ruikang Zhong, Xidong Mu, Dengao Li, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Planning Oriented Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2510.23021</link>
      <description>arXiv:2510.23021v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) enables simultaneous localization, environment perception, and data exchange for connected autonomous vehicles. However, most existing ISAC designs prioritize sensing accuracy and communication throughput, treating all targets uniformly and overlooking the impact of critical obstacles on motion efficiency. To overcome this limitation, we propose a planning-oriented ISAC (PISAC) framework that reduces the sensing uncertainty of planning-bottleneck obstacles and expands the safe navigable path for the ego-vehicle, thereby bridging the gap between physical-layer optimization and motion-level planning. The core of PISAC lies in deriving a closed-form safety bound that explicitly links ISAC transmit power to sensing uncertainty, based on the Cram\'er-Rao Bound and occupancy inflation principles. Using this model, we formulate a bilevel power allocation and motion planning (PAMP) problem, where the inner layer optimizes the ISAC beam power distribution and the outer layer computes a collision-free trajectory under uncertainty-aware safety constraints. Comprehensive simulations in high-fidelity urban driving environments demonstrate that PISAC achieves up to 40% higher success rates and over 5% shorter traversal times than existing ISAC-based and communication-oriented benchmarks, validating its effectiveness in enhancing both safety and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23021v1</guid>
      <category>eess.SP</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xibin Jin, Guoliang Li, Shuai Wang, Fan Liu, Miaowen Wen, Huseyin Arslan, Derrick Wing Kwan Ng, Chengzhong Xu</dc:creator>
    </item>
    <item>
      <title>HAPS-ISAC for 6G: Architecture, Design Trade-offs, and a Practical Roadmap</title>
      <link>https://arxiv.org/abs/2510.23147</link>
      <description>arXiv:2510.23147v1 Announce Type: new 
Abstract: To meet the ambitious goals of next-generation 6G networks, including ultra-high data rates and ubiquitous coverage, we propose a novel high-altitude platform station (HAPS)-based integrated sensing and communication (ISAC) architecture. Operating in the stratosphere, the HAPS functions as both a powerful communication hub and an advanced environmental sensor. Combined with a fleet of cooperative uncrewed aerial vehicles (UAVs), this dual-purpose system forms a scalable and intelligent 3D network. Simulation results indicate that this approach significantly boosts network performance, improves sensing accuracy, and ensures a fairer service distribution across users, outperforming conventional UAV-only baselines. We conclude by outlining the prospective applications and a deployment roadmap for this technology for smart cities and other large-scale environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23147v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parisa Kanani, Mohammad Javad Omidi, Mahmoud Modarres-Hashemi, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Approaching Domain Generalization with Embeddings for Robust Discrimination and Recognition of RF Communication Signals</title>
      <link>https://arxiv.org/abs/2510.23186</link>
      <description>arXiv:2510.23186v1 Announce Type: new 
Abstract: Radio frequency (RF) signal recognition plays a critical role in modern wireless communication and security applications. Deep learning-based approaches have achieved strong performance but typically rely heavily on extensive training data and often fail to generalize to unseen signals. In this paper, we propose a method to learn discriminative embeddings without relying on real-world RF signal recordings by training on signals of synthetic wireless protocols. We validate the approach on a dataset of real RF signals and show that the learned embeddings capture features enabling accurate discrimination of previously unseen real-world signals, highlighting its potential for robust RF signal classification and anomaly detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23186v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Henneke, Frank Kurth</dc:creator>
    </item>
    <item>
      <title>Uplink SCMA-empowered Uncoordinated Random Access for Future mMTC</title>
      <link>https://arxiv.org/abs/2510.23355</link>
      <description>arXiv:2510.23355v1 Announce Type: new 
Abstract: In this paper, a novel uncoordinated random access (URA) protocol is presented to address the pressing demand for massive connectivity with low access latency in future massive machine type communication (mMTC) scenarios. The proposed URA scheme integrates the classical slotted ALOHA (S-ALOHA) protocol with sparse code multiple access (SCMA) technique, referred to as SCMA-empowered URA. Specifically, active users randomly choose an SCMA codebook to access the communication network in an arbitrary time slot whenever they want without scheduling. However, due to the lack of central coordination in the proposed URA scheme, SCMA codebook collisions become inevitable, making decoding challenging and leading to increased access failures. To cope with the decoding issue, an interference-canceling (IC) first decoding strategy is proposed at the access point (AP), which can partially tackles collision problems, contributing to a higher system throughput. Taking the proposed IC-first decoding strategy into account, a closed-form theoretical expression of the throughput is derived. Moreover, to alleviate the throughput degradation under the congested user traffic, a user barring mechanism is introduced to manage the traffic load. Firstly, a closed-form expression of idle codebook probability is developed to help indicate the system state, i.e., congested or not. Then, in addition to the estimated real-time load, the AP adaptively adjusts the access probability and redistributes the actual access load. Finally, simulation results demonstrate that the proposed SCMA-empowered URA scheme enjoys higher maximum throughput, compared to the conventional orthogonal multiple access (OMA) based URA scheme. Moreover, the accuracy of the presented theoretical analysis and the effectiveness of the user barring mechanism are verified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23355v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pengyu Gao, Qu Luo, Jing Zhu, Gaojie Chen, Pei Xiao, Chuan Heng Foh</dc:creator>
    </item>
    <item>
      <title>Randomized Space-Time Coded Stacked Intelligent Metasurfaces for Massive Multiuser Downlink Connectivity</title>
      <link>https://arxiv.org/abs/2510.23440</link>
      <description>arXiv:2510.23440v1 Announce Type: new 
Abstract: Stacked intelligent metasurfaces (SIMs) represent a key enabler for next-generation wireless networks, offering beamforming gains while significantly reducing radio-frequency chain requirements. In conventional space-only SIM architectures, the rate of reconfigurability of the SIM is equal to the inverse of the channel coherence time. This paper investigates a novel beamforming strategy for massive downlink connectivity using a randomized space-time (ST) coded SIM. In addition to conventional space-only metasurface layers, the proposed design integrates a ST metasurface layer at the input stage of the SIM that introduces random time variations over each channel coherence time interval. These artificial time variations enable opportunistic user scheduling and exploitation of multiuser diversity under slow channel dynamics. To mitigate the prohibitive overhead associated with full channel state information at the transmitter (CSIT), we propose a partial-CSIT-based beamforming scheme that leverages randomized steering vectors and limited user-side feedback based on signal quality measurements. Numerical results demonstrate that the proposed ST-SIM architecture achieves satisfactory sum-rate performance while significantly reducing CSIT acquisition and feedback overhead, thereby enabling scalable downlink connectivity in dense networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23440v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donatella Darsena, Ivan Iudice, Vincenzo Galdi, Francesco Verde</dc:creator>
    </item>
    <item>
      <title>Joint Uplink and Downlink Resource Allocation and Antenna Activation for Pinching Antenna Systems</title>
      <link>https://arxiv.org/abs/2510.23467</link>
      <description>arXiv:2510.23467v1 Announce Type: new 
Abstract: In this paper, we explore a novel joint uplink and downlink framework utilizing a pinching antenna system (PASS). We consider two waveguides, one dedicated to transmission and one to reception, and both of them are connected to a base station (BS). Each type of waveguide consists of several pinching antennas (PAs) in some preconfigured positions. In this framework, we assume the BS can serve downlink and uplink user equipments (UEs) at the same time using the same spectrum resources through the presented PASS. In this aspect, we formulate a sum rate optimization problem that jointly optimizes the antenna activation factor, the BS transmit power, and the UE's transmit power, subject to power budget constraints for the BS and the UEs, as well as minimum rate requirements for the UEs. The formulated problem is highly non-convex and difficult to solve directly. Hence, we divide the main problem into two sub-problems: the antenna activation sub-problem and the power allocation sub-problem. Then, we solve the antenna activation problem utilizing a distance and spatial correlation-based algorithm. Meanwhile, the resource allocation problem is solved using a successive convex approximation (SCA)-based algorithm. Numerical results show that our proposed framework can achieve around 60-90\% performance gains over its time division duplex (TDD) where the uplink and downlink transmissions are served in different orthogonal time slots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23467v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreya Khisa, Ali Amhaz, Mohamed Elhattab, Chadi Assi, Sanaa Sharafeddine</dc:creator>
    </item>
    <item>
      <title>K-DAREK: Distance Aware Error for Kurkova Kolmogorov Networks</title>
      <link>https://arxiv.org/abs/2510.22021</link>
      <description>arXiv:2510.22021v1 Announce Type: cross 
Abstract: Neural networks are parametric and powerful tools for function approximation, and the choice of architecture heavily influences their interpretability, efficiency, and generalization. In contrast, Gaussian processes (GPs) are nonparametric probabilistic models that define distributions over functions using a kernel to capture correlations among data points. However, these models become computationally expensive for large-scale problems, as they require inverting a large covariance matrix. Kolmogorov- Arnold networks (KANs), semi-parametric neural architectures, have emerged as a prominent approach for modeling complex functions with structured and efficient representations through spline layers. Kurkova Kolmogorov-Arnold networks (KKANs) extend this idea by reducing the number of spline layers in KAN and replacing them with Chebyshev layers and multi-layer perceptrons, thereby mapping inputs into higher-dimensional spaces before applying spline-based transformations. Compared to KANs, KKANs perform more stable convergence during training, making them a strong architecture for estimating operators and system modeling in dynamical systems. By enhancing the KKAN architecture, we develop a novel learning algorithm, distance-aware error for Kurkova-Kolmogorov networks (K-DAREK), for efficient and interpretable function approximation with uncertainty quantification. Our approach establishes robust error bounds that are distance-aware; this means they reflect the proximity of a test point to its nearest training points. Through case studies on a safe control task, we demonstrate that K-DAREK is about four times faster and ten times higher computationally efficiency than Ensemble of KANs, 8.6 times more scalable than GP by increasing the data size, and 50% safer than our previous work distance-aware error for Kolmogorov networks (DAREK).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22021v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Ataei, Vikas Dhiman, Mohammad Javad Khojasteh</dc:creator>
    </item>
    <item>
      <title>Frequency-Spatial Interaction Driven Network for Low-Light Image Enhancement</title>
      <link>https://arxiv.org/abs/2510.22154</link>
      <description>arXiv:2510.22154v1 Announce Type: cross 
Abstract: Low-light image enhancement (LLIE) aims at improving the perception or interpretability of an image captured in an environment with poor illumination. With the advent of deep learning, the LLIE technique has achieved significant breakthroughs. However, existing LLIE methods either ignore the important role of frequency domain information or fail to effectively promote the propagation and flow of information, limiting the LLIE performance. In this paper, we develop a novel frequency-spatial interaction-driven network (FSIDNet) for LLIE based on two-stage architecture. To be specific, the first stage is designed to restore the amplitude of low-light images to improve the lightness, and the second stage devotes to restore phase information to refine fine-grained structures. Considering that Frequency domain and spatial domain information are complementary and both favorable for LLIE, we further develop two frequency-spatial interaction blocks which mutually amalgamate the complementary spatial and frequency information to enhance the capability of the model. In addition, we construct the Information Exchange Module (IEM) to associate two stages by adequately incorporating cross-stage and cross-scale features to effectively promote the propagation and flow of information in the two-stage network structure. Finally, we conduct experiments on several widely used benchmark datasets (i.e., LOL-Real, LSRW-Huawei, etc.), which demonstrate that our method achieves the excellent performance in terms of visual results and quantitative metrics while preserving good model efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22154v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunhong Tao, Wenbing Tao, Xiang Xiang</dc:creator>
    </item>
    <item>
      <title>Robust MIMO Channel Estimation Using Energy-Based Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2510.22230</link>
      <description>arXiv:2510.22230v1 Announce Type: cross 
Abstract: Channel estimation for massive multiple-input multiple-output (MIMO) systems is fundamentally constrained by excessive pilot overhead and high estimation latency. To overcome these obstacles, recent studies have leveraged deep generative networks to capture the prior distribution of wireless channels. In this paper, we propose a novel estimation framework that integrates an energy-based generative diffusion model (DM) with the Metropolis-Hastings (MH) principle. By reparameterizing the diffusion process with an incorporated energy function, the framework explicitly estimates the unnormalized log-prior, while MH corrections refine the sampling trajectory, mitigate deviations, and enhance robustness, ultimately enabling accurate posterior sampling for high-fidelity channel estimation. Numerical results reveal that the proposed approach significantly improves estimation accuracy compared with conventional parameterized DMs and other baseline methods, particularly in cases with limited pilot overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22230v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqi Diao, Xingyu Zhou, Le Liang, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Tuned for Creativity? Graph-Theoretical Mapping of Resting-State EEG Reveals Neural Signatures of Creativity</title>
      <link>https://arxiv.org/abs/2510.22364</link>
      <description>arXiv:2510.22364v1 Announce Type: cross 
Abstract: Understanding how creativity is represented in the brain's intrinsic functional architecture remains a central challenge in cognitive neuroscience. While resting-state fMRI studies have revealed large-scale network correlates of creative potential, electroencephalography (EEG) offers a temporally precise and scalable approach to capture the fast oscillatory dynamics that underlie spontaneous neural organization. In this study, we used a data-driven network approach to examine whether resting-state EEG connectivity patterns differentiate individuals according to their creative abilities. Creativity was evaluated by: The Inventory of Creative Activities and Achievements (ICAA), The Divergent Association Task (DAT), The Matchstick Arithmetic Puzzles Task (MAPT) and Self-rating (SR) of creative ability in 30 healthy young adults. Graph-theoretical analyses were applied to functional connectivity matrices and clustered based on graph similarity. Two distinct participant clusters emerged, differing systematically across multiple dimensions of creativity. Cluster 1, characterized by consistently higher performance across multiple creativity variables (ICAA, DAT, MAPT and SR), showed broad alpha-band hypoconnectivity, relatively preserved left frontal connectivity and greater network modularity. Cluster 0, associated with lower creativity scores, exhibited stronger overall connectivity strength, reduced modularity and higher local clustering. These findings suggest that resting-state EEG connectivity patterns can index stable cognitive traits such as creativity. More broadly, they point to an intrinsic neural signature of adaptive brain function marked by efficient yet flexible network organization that may support creative and adaptive cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22364v1</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samir Damji, Simrut Kurry, Shazia'Ayn Babul, Joydeep Bhattacharya, Naznin Virji-Babul</dc:creator>
    </item>
    <item>
      <title>HyBeam: Hybrid Microphone-Beamforming Array-Agnostic Speech Enhancement for Wearables</title>
      <link>https://arxiv.org/abs/2510.22637</link>
      <description>arXiv:2510.22637v1 Announce Type: cross 
Abstract: Speech enhancement is a fundamental challenge in signal processing, particularly when robustness is required across diverse acoustic conditions and microphone setups. Deep learning methods have been successful for speech enhancement, but often assume fixed array geometries, limiting their use in mobile, embedded, and wearable devices. Existing array-agnostic approaches typically rely on either raw microphone signals or beamformer outputs, but both have drawbacks under changing geometries. We introduce HyBeam, a hybrid framework that uses raw microphone signals at low frequencies and beamformer signals at higher frequencies, exploiting their complementary strengths while remaining highly array-agnostic. Simulations across diverse rooms and wearable array configurations demonstrate that HyBeam consistently surpasses microphone-only and beamformer-only baselines in PESQ, STOI, and SI-SDR. A bandwise analysis shows that the hybrid approach leverages beamformer directivity at high frequencies and microphone cues at low frequencies, outperforming either method alone across all bands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22637v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Bar Ilan (School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel), Boaz Rafaely (School of Electrical and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva, Israel), Vladimir Tourbabin (Reality Labs Research, Meta, Redmond, WA, USA)</dc:creator>
    </item>
    <item>
      <title>Numerical Spectrum Linking: Identification of Governing PDE via Koopman-Chebyshev Approximation</title>
      <link>https://arxiv.org/abs/2510.23078</link>
      <description>arXiv:2510.23078v1 Announce Type: cross 
Abstract: A numerical framework is proposed for identifying partial differential equations (PDEs) governing dynamical systems directly from their observation data using Chebyshev polynomial approximation. In contrast to data-driven approaches such as dynamic mode decomposition (DMD), which approximate the Koopman operator without a clear connection to differential operators, the proposed method constructs finite-dimensional Koopman matrices by projecting the dynamics onto a Chebyshev basis, thereby capturing both differential and nonlinear terms. This establishes a numerical link between the Koopman and differential operators. Numerical experiments on benchmark dynamical systems confirm the accuracy and efficiency of the approach, underscoring its potential for interpretable operator learning. The framework also lays a foundation for future integration with symbolic regression, enabling the construction of explicit mathematical models directly from data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23078v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Phonepaserth Sisaykeo, Shogo Muramatsu</dc:creator>
    </item>
    <item>
      <title>Grassmanian Interpolation of Low-Pass Graph Filters: Theory and Applications</title>
      <link>https://arxiv.org/abs/2510.23235</link>
      <description>arXiv:2510.23235v1 Announce Type: cross 
Abstract: Low-pass graph filters are fundamental for signal processing on graphs and other non-Euclidean domains. However, the computation of such filters for parametric graph families can be prohibitively expensive as computation of the corresponding low-frequency subspaces, requires the repeated solution of an eigenvalue problem. We suggest a novel algorithm of low-pass graph filter interpolation based on Riemannian interpolation in normal coordinates on the Grassmann manifold. We derive an error bound estimate for the subspace interpolation and suggest two possible applications for induced parametric graph families. First, we argue that the temporal evolution of the node features may be translated to the evolving graph topology via a similarity correction to adjust the homophily degree of the network. Second, we suggest a dot product graph family induced by a given static graph which allows to infer improved message passing scheme for node classification facilitated by the filter interpolation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23235v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Savostianov, Michael T. Schaub, Benjamin Stamm</dc:creator>
    </item>
    <item>
      <title>Quality-controlled registration of urban MLS point clouds reducing drift effects by adaptive fragmentation</title>
      <link>https://arxiv.org/abs/2510.23416</link>
      <description>arXiv:2510.23416v1 Announce Type: cross 
Abstract: This study presents a novel workflow designed to efficiently and accurately register large-scale mobile laser scanning (MLS) point clouds to a target model point cloud in urban street scenarios. This workflow specifically targets the complexities inherent in urban environments and adeptly addresses the challenges of integrating point clouds that vary in density, noise characteristics, and occlusion scenarios, which are common in bustling city centers. Two methodological advancements are introduced. First, the proposed Semi-sphere Check (SSC) preprocessing technique optimally fragments MLS trajectory data by identifying mutually orthogonal planar surfaces. This step reduces the impact of MLS drift on the accuracy of the entire point cloud registration, while ensuring sufficient geometric features within each fragment to avoid local minima. Second, we propose Planar Voxel-based Generalized Iterative Closest Point (PV-GICP), a fine registration method that selectively utilizes planar surfaces within voxel partitions. This pre-process strategy not only improves registration accuracy but also reduces computation time by more than 50% compared to conventional point-to-plane ICP methods. Experiments on real-world datasets from Munich's inner city demonstrate that our workflow achieves sub-0.01 m average registration accuracy while significantly shortening processing times. The results underscore the potential of the proposed methods to advance automated 3D urban modeling and updating, with direct applications in urban planning, infrastructure management, and dynamic city monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23416v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Antonio Ortiz Rincon, Yihui Yang, Christoph Holst</dc:creator>
    </item>
    <item>
      <title>Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems</title>
      <link>https://arxiv.org/abs/2510.23503</link>
      <description>arXiv:2510.23503v1 Announce Type: cross 
Abstract: Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely inference tasks while operating with limited on-board computing and energy resources. In this paper, we investigate the problem of collaborative inference in wireless edge networks, where energy-constrained edge devices aim to complete inference tasks within given deadlines. These tasks are carried out using neural networks, and the edge device seeks to optimize inference performance under energy and delay constraints. The inference process can be split between the edge device and an edge server, thereby achieving collaborative inference over wireless networks. We formulate an inference utility optimization problem subject to energy and delay constraints, and propose a novel solution called Bayes-Split-Edge, which leverages Bayesian optimization for collaborative split inference over wireless edge networks. Our solution jointly optimizes the transmission power and the neural network split point. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition function that balances inference task utility, sample efficiency, and constraint violation penalties. We evaluate our approach using the VGG19 model on the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world mMobile wireless channel datasets. Numerical results demonstrate that Bayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to standard Bayesian optimization and achieves near-linear convergence. It also outperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and Proximal Policy Optimization (PPO), while matching exhaustive search performance under tight constraints. These results confirm that the proposed framework provides a sample-efficient solution requiring maximum 20 function evaluations and constraint-aware optimization for wireless split inference in edge computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23503v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatemeh Zahra Safaeipour, Jacob Chakareski, Morteza Hashemi</dc:creator>
    </item>
    <item>
      <title>Efficient Localization of Directional RF Emitters via Iterated Beampattern Analysis</title>
      <link>https://arxiv.org/abs/2411.04364</link>
      <description>arXiv:2411.04364v3 Announce Type: replace 
Abstract: The localization of directional RF emitters presents significant challenges for electronic warfare applications. Traditional localization methods, designed for omnidirectional emitters, experience degraded performance when applied to directional sources due to pronounced received signal strength (RSS) modulations introduced by directive beampatterns. This paper presents a robust direct position determination (DPD) approach that jointly estimates emitter position and beampattern parameters by incorporating RSS modulation from both path attenuation and directional gain alongside angle of arrival (AOA) and time difference of arrival (TDOA) information. To address the computational challenge of joint optimization over position and beampattern parameters, we develop an alternating maximization algorithm that decomposes the four-dimensional search into efficient iterative two-dimensional optimizations using a generalized beampattern model. Cramer-Rao Lower Bound (CRLB) analysis establishes theoretical performance limits, and numerical simulations demonstrate substantial improvements over conventional methods. At -10 dB SNR, the proposed approach achieves 49% to 61% error reduction compared to AOA-TDOA baselines, with performance approaching the CRLB above -10 dB. The algorithm converges rapidly, requiring 3 to 4 iterations on average, and exhibits robustness to beampattern model mismatch. A contrast-expanded half-power uncertainty metric is introduced to quantify localization confidence, revealing that the proposed method produces concentrated unimodal likelihood surfaces while conventional approaches generate spurious peaks. Sensitivity analysis demonstrates that optimal performance occurs when receivers are positioned at beampattern main lobe edges where RSS gradients are maximized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04364v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fraser Williams, Akila Pemasiri, Dhammika Jayalath, Terry Martin, Clinton Fookes</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Feature Compression for Multimodal Understanding via Device-Edge Co-Inference</title>
      <link>https://arxiv.org/abs/2503.12926</link>
      <description>arXiv:2503.12926v3 Announce Type: replace 
Abstract: With the rapid development of large multimodal models (LMMs), multimodal understanding applications are emerging. As most LMM inference requests originate from edge devices with limited computational capabilities, the predominant inference pipeline involves directly forwarding the input data to an edge server which handles all computations. However, this approach introduces high transmission latency due to limited uplink bandwidth of edge devices and significant computation latency caused by the prohibitive number of visual tokens, thus hindering delay-sensitive tasks and degrading user experience. To address this challenge, we propose a task-oriented feature compression (TOFC) method for multimodal understanding in a device-edge co-inference framework, where visual features are merged by clustering and encoded by a learnable and selective entropy model before feature projection. Specifically, we employ density peaks clustering based on K nearest neighbors to reduce the number of visual features, thereby minimizing both data transmission and computational complexity. Subsequently, a learnable entropy model with hyperprior is utilized to encode and decode merged features, further reducing transmission overhead. To enhance compression efficiency, multiple entropy models are adaptively selected based on the characteristics of the visual features, enabling a more accurate estimation of the probability distribution. Comprehensive experiments on seven visual question answering benchmarks validate the effectiveness of the proposed TOFC method. Results show that TOFC achieves up to 52% reduction in data transmission overhead and 63% reduction in system latency while maintaining identical task performance, compared with neural compression ELIC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12926v3</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Yuan, Zhening Liu, Jiashu Lv, Jiawei Shao, Yufei Jiang, Jun Zhang, Xuelong Li</dc:creator>
    </item>
    <item>
      <title>PhySense: Sensor Placement Optimization for Accurate Physics Sensing</title>
      <link>https://arxiv.org/abs/2505.18190</link>
      <description>arXiv:2505.18190v3 Announce Type: replace 
Abstract: Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18190v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuezhou Ma, Haixu Wu, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization</title>
      <link>https://arxiv.org/abs/2506.00011</link>
      <description>arXiv:2506.00011v2 Announce Type: replace 
Abstract: Federated fine-tuning of large language models (LLMs) over bandwidth-limited 6G links must meet strict round-time and energy budgets. Analog over-the-air (OTA) aggregation reduces uplink cost but is sensitive to fading and interference, which distort the aggregated gradient. We consider a two-phase workflow (centralized pre-training followed by federated fine-tuning) where the base station uses a movable-antenna (MA) array. In each round, MA element positions and the receive/transmit beamformers are adjusted under minimum-spacing constraints to reshape the channel and improve OTA aggregation without increasing user transmit power. We formulate a mixed-integer, nonconvex resource-allocation problem that jointly selects clients and optimizes the number of global rounds, CPU frequencies, mini-batch sizes, MA positions, and analog weights under end-to-end latency and energy limits. A successive convex approximation-penalty dual decomposition (SCA-PDD) routine alternates convex updates with oblique-manifold beamforming and spacing-aware MA placement. Experiments on OpenLLaMA-v2 (3B) with LoRA and 4-bit quantization on Alpaca and Dolly (10 clients) attain round-30 validation perplexities as low as 2.94 (Alpaca, K=1) and 4.62 (Dolly, K=1). Relative to the strongest non-MA baseline at the same concurrency, this corresponds to 17.4 percent (Alpaca, K=1) and 54.4 percent (Dolly, K=1) lower perplexity; at K=2 the reductions are 14.2 percent (Alpaca) and 13.7 percent (Dolly). Participation fairness also improves across all uplink concurrencies K in {1,2,4,8}, with the largest margins when fewer clients transmit per round.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00011v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Zhao, Yue Xiu, Chengxiao Dai, Ning Wei, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Enabling Scalable Distributed Beamforming via Networked LEO Satellites Towards 6G</title>
      <link>https://arxiv.org/abs/2506.01382</link>
      <description>arXiv:2506.01382v2 Announce Type: replace 
Abstract: In this paper, we propose scalable distributed beamforming schemes over low Earth orbit (LEO) satellite networks that rely solely on statistical channel state information for downlink orthogonal frequency division multiplexing systems. We begin by introducing the system model and presenting a pragmatic yet effective analog beamformer and user-scheduling design. We then derive a closed-form lower bound on the ergodic sum rate, based on the hardening bound, for the digital beamformer design. Next, we formulate a per-satellite power-constrained sum-rate maximization problem, whose centralized solution, obtained via the weighted minimum mean squared error (WMMSE) framework, establishes performance limits and motivates decentralized strategies. We subsequently introduce two decentralized optimization schemes, based on approximating the hardening bound and decentralizing the WMMSE framework, for representative inter-satellite link topologies. In the Ring scheme, satellites update beamformers locally and exchange intermediate parameters sequentially. In the Star scheme, edge satellites update beamformers locally and in parallel, achieving consensus on intermediate parameters at a central satellite using a penalty-dual decomposition framework. Extensive simulations demonstrate that our distributed designs achieve near-centralized performance with superior scalability, substantially outperforming simple closed-form beamformers and single-satellite baselines in sum rate. Additionally, the delay-overhead trade-off between the two topologies is revealed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01382v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Zhang, Tareq Y. Al-Naffouri</dc:creator>
    </item>
    <item>
      <title>A Novel Spreading-Factor-Index-Aided LoRa Scheme: Design and Performance Analysis</title>
      <link>https://arxiv.org/abs/2506.06758</link>
      <description>arXiv:2506.06758v2 Announce Type: replace 
Abstract: LoRa is a widely recognized modulation technology in the field of low power wide area networks (LPWANs). However, the data rate of LoRa is too low to satisfy the requirements of Internet of Things applications. To address this issue, we propose a novel high-data-rate LoRa scheme based on the spreading factor index (SFI). In the proposed SFI-LoRa scheme, the starting frequency bin of a chirp signal is used to transmit information bits, while the combinations of spreading factors are exploited as a set of indices to convey additional information bits. Moreover, the theoretical symbol error rate, data rate, transmission throughput, complexity and energy efficiency of the proposed SFI-LoRa scheme are carefully analyzed. Simulation results not only verify the accuracy of our theoretical analysis, but also demonstrate that the proposed SFI-LoRa scheme can improve the transmission throughput of existing LoRa schemes without sacrificing the BER performance over additive white Gaussian noise, Rayleigh fading, and multipath flat-fading channels. Therefore, the proposed SFI-LoRa scheme is a potential solution for applications requiring a high data rate in the LPWAN domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06758v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Zeng, Huan Ma, Yi Fang, Pingping Chen, Wenkun Wen, Tierui Min</dc:creator>
    </item>
    <item>
      <title>Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation</title>
      <link>https://arxiv.org/abs/2506.21208</link>
      <description>arXiv:2506.21208v2 Announce Type: replace 
Abstract: Deep neural networks (DNNs) have widespread applications for optimizing resource allocation. Yet, their performance is vulnerable to distribution shifts between training and test data, say wireless channels. In this paper, we resort to adversarial training (AT) for enhancing out-of-distribution (OOD) generalizability of DNNs trained in unsupervised manner. We reformulate AT problem to reflect the OOD degradation, and propose a one-step gradient ascent algorithm to solve the AT problem for training DNNs. The proposed method is evaluated by optimizing hybrid precoding. Simulation results showcase the enhanced OOD performance of multiple kinds of DNNs, with approximately 5\(\sim\)20\% improvement, across various channel distributions, even when the samples only from a single distribution (e.g., Rayleigh fading) are used for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21208v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengjie Liu, Chenyang Yang</dc:creator>
    </item>
    <item>
      <title>Affine Frequency Division Multiplexing (AFDM) for 6G: Properties, Features, and Challenges</title>
      <link>https://arxiv.org/abs/2507.21704</link>
      <description>arXiv:2507.21704v2 Announce Type: replace 
Abstract: Affine frequency division multiplexing (AFDM) is an emerging waveform candidate for future sixth generation (6G) systems offering a range of promising features, such as enhanced robustness in heterogeneous and high-mobility environments, as well as inherent suitability for integrated sensing and communications (ISAC) applications. In addition, unlike other candidates such as orthogonal time-frequency space (OTFS) modulation, AFDM provides several unique advantages that strengthen its relevance to practical deployment and standardization in 6G. Notably, as a natural generalization of orthogonal frequency division multiplexing (OFDM), strong backward compatibility with existing conventional systems is guaranteed, while also offering novel possibilities in waveform design, for example to enable physical-layer security through its inherent chirp parametrization. In all, this article provides an overview of AFDM, emphasizing its suitability as a candidate waveform for 6G standardization. First, we provide a concise introduction to the fundamental properties and unique characteristics of AFDM, followed by highlights of its advantageous features, and finally a discussion of its potential and challenges in 6G standardization efforts and representative requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21704v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyeon Seok Rou, Kuranage Roche Rayan Ranasinghe, Vincent Savaux, Giuseppe Thadeu Freitas de Abreu, David Gonz\'alez G., Christos Masouros</dc:creator>
    </item>
    <item>
      <title>Developing an Open-Source Framework for Quantitative Simulation of Blood Flow and Tissue Motion for Ultrafast Doppler Ultrasound</title>
      <link>https://arxiv.org/abs/2509.05464</link>
      <description>arXiv:2509.05464v3 Announce Type: replace 
Abstract: Ultrafast power Doppler imaging (uPDI) has become a powerful tool for both research and clinical applications. However, existing simulation tools are insufficient for generating quantitatively accurate three-dimensional (3D) flow fields with tissue motion mimicking in vivo conditions. In this study, we present an open-source framework, named 3D-Fully Quantitative Flow (3D-FQFlow), to provide quantitative modeling of 3D vascular hemodynamics with physiologically realistic tissue motion for uPDI. The framework can perform quantitative modeling of both hemodynamics and tissue motion for either user-defined or clinical-derived vasculatures. Besides, it also integrates a GPU-accelerated image processing and reconstruction module. We demonstrate the performance of 3D-FQFlow using both synthetic vascular structures and clinical datasets. This framework could provide essential ground-truth simulation models to support the development, validation, and benchmarking of uPDI techniques. The source code is freely available online athttps://github.com/FortuneOU/3D-FQFlow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05464v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Fu, Changhui Li</dc:creator>
    </item>
    <item>
      <title>Multi-Rate Task-Oriented Communication for Multi-Edge Cooperative Inference</title>
      <link>https://arxiv.org/abs/2510.19360</link>
      <description>arXiv:2510.19360v2 Announce Type: replace 
Abstract: The integration of artificial intelligence (AI) with the Internet of Things (IoT) enables task-oriented communication for multi-edge cooperative inference system, where edge devices transmit extracted features of local sensory data to an edge server to perform AI-driven tasks. However, the privacy concerns and limited communication bandwidth pose fundamental challenges, since simultaneous transmission of extracted features with a single fixed compression ratio from all devices leads to severe inefficiency in communication resource utilization. To address this challenge, we propose a framework that dynamically adjusts the code rate in feature extraction based on its importance to the downstream inference task by adopting a rate-adaptive quantization (RAQ) scheme. Furthermore, to select the code rate for each edge device under limited bandwidth constraint, a dynamic programming (DP) approach is leveraged to allocate the code rate across discrete code rate options. Experiments on multi-view datasets demonstrate that the proposed frameworks significantly outperform the frameworks using fixed-rate quantization, achieving a favorable balance between communication efficiency and inference performance under limited bandwidth conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19360v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongwon Kim, Jiwan Seo, Joonhyuk Kang</dc:creator>
    </item>
    <item>
      <title>UCINet0: A Machine Learning based Receiver for 5G NR PUCCH Format 0</title>
      <link>https://arxiv.org/abs/2404.15243</link>
      <description>arXiv:2404.15243v2 Announce Type: replace-cross 
Abstract: Accurate decoding of Uplink Control Information (UCI) on the Physical Uplink Control Channel (PUCCH) is essential for enabling 5G wireless links. This paper explores an AI/ML-based receiver design for PUCCH Format 0. Format 0 signaling encodes the UCI content within the phase of a known base waveform and even supports multiplexing of up to 12 users within the same time-frequency resources. The proposed neural network classifier, which we term UCINet0, is capable of predicting when no user is transmitting on the PUCCH, as well as decoding the UCI content for any number of multiplexed users (up to 12). The test results with simulated, hardware-captured (lab) and field datasets show that the UCINet0 model outperforms conventional correlation-based decoders across all SNR ranges and multiple fading scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15243v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeeva Keshav Sattianarayanin, Anil Kumar Yerrapragada, Radha Krishna Ganti</dc:creator>
    </item>
    <item>
      <title>R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models</title>
      <link>https://arxiv.org/abs/2407.11654</link>
      <description>arXiv:2407.11654v3 Announce Type: replace-cross 
Abstract: Split federated learning (SFL) is a compute-efficient paradigm in distributed machine learning (ML), where components of large ML models are outsourced to remote servers. A significant challenge in SFL, particularly when deployed over wireless channels, is the susceptibility of transmitted model parameters to adversarial jamming that could jeopardize the learning process. This is particularly pronounced for embedding parameters in large language models (LLMs) and vision language models (VLMs), which are learned feature vectors essential for domain understanding. In this paper, rigorous insights are provided into the influence of jamming embeddings in SFL by deriving an expression for the ML training loss divergence and showing that it is upper-bounded by the mean squared error (MSE). Based on this analysis, a physical layer framework is developed for resilient SFL with LLMs (R-SFLLM) over wireless networks. R-SFLLM leverages wireless sensing data to gather information on the jamming directions-of-arrival (DoAs) for the purpose of devising a novel, sensing-assisted anti-jamming strategy while jointly optimizing beamforming, user scheduling, and resource allocation. Extensive experiments using both LLMs and VLMs demonstrate R-SFLLM's effectiveness, achieving close-to-baseline performance across various natural language processing (NLP) and computer vision (CV) tasks, datasets, and modalities. The proposed methodology further introduces an adversarial training component, where controlled noise exposure significantly enhances the model's resilience to perturbed parameters during training. The results show that more noise-sensitive models, such as RoBERTa, benefit from this feature, especially when resource allocation is unfair. It is also shown that worst-case jamming in particular translates into worst-case model outcomes, thereby necessitating the need for jamming-resilient SFL protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11654v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIFS.2025.3594107</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Information Forensics and Security (Volume: 20), 2025</arxiv:journal_reference>
      <dc:creator>Aladin Djuhera, Vlad C. Andrei, Xinyang Li, Ullrich J. M\"onich, Holger Boche, Walid Saad</dc:creator>
    </item>
    <item>
      <title>DeepVigor+: Scalable and Accurate Semi-Analytical Fault Resilience Analysis for Deep Neural Network</title>
      <link>https://arxiv.org/abs/2410.15742</link>
      <description>arXiv:2410.15742v2 Announce Type: replace-cross 
Abstract: The growing exploitation of Machine Learning (ML) in safety-critical applications necessitates rigorous safety analysis. Hardware reliability assessment is a major concern with respect to measuring the level of safety in ML-based systems. Quantifying the reliability of emerging ML models, including Convolutional Neural Networks (CNNs), is highly complex due to their enormous size in terms of the number of parameters and computations. Conventionally, Fault Injection (FI) is applied to perform a reliability measurement. However, performing FI on modern-day CNNs is prohibitively time-consuming if an acceptable confidence level is to be achieved. To speed up FI for large CNNs, statistical FI (SFI) has been proposed, but its runtimes are still considerably long.
  In this work, we introduce DeepVigor+, a scalable, fast, and accurate semi-analytical method as an efficient alternative for reliability measurement in CNNs. DeepVigor+ implements a fault propagation analysis model and attempts to acquire Vulnerability Factors (VFs) as reliability metrics in an optimal way. The results indicate that DeepVigor+ obtains VFs for CNN models with an error less than $1\%$, i.e., the objective in SFI, but with $14.9$ up to $26.9$ times fewer simulations than the best-known state-of-the-art SFI. DeepVigor+ enables an accurate reliability analysis for large and deep CNNs within a few minutes, rather than achieving the same results in days or weeks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15742v2</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohammad Hasan Ahmadilivani, Jaan Raik, Masoud Daneshtalab, Maksim Jenihhin</dc:creator>
    </item>
    <item>
      <title>Global Optimal Closed-Form Solutions for Intelligent Surfaces With Mutual Coupling: Is Mutual Coupling Detrimental or Beneficial?</title>
      <link>https://arxiv.org/abs/2411.04949</link>
      <description>arXiv:2411.04949v2 Announce Type: replace-cross 
Abstract: Reconfigurable Intelligent Surface (RIS) is a breakthrough technology enabling the dynamic control of the propagation environment in wireless communications through programmable surfaces. To improve the flexibility of conventional diagonal RIS (D-RIS), beyond diagonal RIS (BD-RIS) has emerged as a family of more general RIS architectures. However, D-RIS and BD-RIS have been commonly explored neglecting mutual coupling effects, while the global optimization of RIS with mutual coupling, its performance limits, and scaling laws remain unexplored. This study addresses these gaps by deriving global optimal closed-form solutions for BD-RIS with mutual coupling to maximize the channel gain, specifically fully- and tree-connected RISs. Besides, we provide the expression of the maximum channel gain achievable in the presence of mutual coupling and its scaling law in closed form. By using the derived scaling laws, we analytically prove that mutual coupling increases the channel gain on average under Rayleigh fading channels. Our theoretical analysis, confirmed by numerical simulations, shows that both fully- and tree-connected RISs with mutual coupling achieve the same channel gain upper bound when optimized with the proposed global optimal solutions. Furthermore, we observe that a mutual coupling-unaware optimization of RIS can cause a channel gain degradation of up to 5 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04949v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Hongyu Li, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Physics-Compliant Modeling and Scaling Laws of Multi-RIS Aided MIMO Systems</title>
      <link>https://arxiv.org/abs/2411.06309</link>
      <description>arXiv:2411.06309v2 Announce Type: replace-cross 
Abstract: Reconfigurable intelligent surface (RIS) enables the control of wireless channels to improve coverage. To further extend coverage, multi-RIS aided systems have been explored, where multiple RISs steer the signal via a multi-hop path. However, deriving a physics-compliant channel model for multi-RIS aided systems is still an open problem. In this study, we fill this gap by modeling multi-RIS aided systems through multiport network theory, and deriving a channel model accounting for impedance mismatch, mutual coupling, and structural scattering. The derived physics-compliant model differs from the model widely used in literature, which omits the RIS structural scattering. To quantify this difference, we derive the channel gain scaling laws of the two models under line-of-sight (LoS) and multipath channels. Theoretical insights, validated by numerical results, show an important discrepancy between the physics-compliant and the widely used models, increasing with the number of RISs and multipath richness. In a multi-hop system aided by four 128-element RISs with multipath channels, optimizing the RISs using the widely used model and applying their solutions to the physics-compliant model achieves only 7% of the maximum channel gain. This highlights how severely mismatched channel models can be, calling for more accurate models in communication theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06309v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Gabriele Gradoni, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>DERD-Net: Learning Depth from Event-based Ray Densities</title>
      <link>https://arxiv.org/abs/2504.15863</link>
      <description>arXiv:2504.15863v2 Announce Type: replace-cross 
Abstract: Event cameras offer a promising avenue for multi-view stereo depth estimation and Simultaneous Localization And Mapping (SLAM) due to their ability to detect blur-free 3D edges at high-speed and over broad illumination conditions. However, traditional deep learning frameworks designed for conventional cameras struggle with the asynchronous, stream-like nature of event data, as their architectures are optimized for discrete, image-like inputs. We propose a scalable, flexible and adaptable framework for pixel-wise depth estimation with event cameras in both monocular and stereo setups. The 3D scene structure is encoded into disparity space images (DSIs), representing spatial densities of rays obtained by back-projecting events into space via known camera poses. Our neural network processes local subregions of the DSIs combining 3D convolutions and a recurrent structure to recognize valuable patterns for depth prediction. Local processing enables fast inference with full parallelization and ensures constant ultra-low model complexity and memory costs, regardless of camera resolution. Experiments on standard benchmarks (MVSEC and DSEC datasets) demonstrate unprecedented effectiveness: (i) using purely monocular data, our method achieves comparable results to existing stereo methods; (ii) when applied to stereo data, it strongly outperforms all state-of-the-art (SOTA) approaches, reducing the mean absolute error by at least 42%; (iii) our method also allows for increases in depth completeness by more than 3-fold while still yielding a reduction in median absolute error of at least 30%. Given its remarkable performance and effective processing of event-data, our framework holds strong potential to become a standard approach for using deep learning for event-based depth estimation and SLAM. Project page: https://github.com/tub-rip/DERD-Net</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15863v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Diego Hitzges, Suman Ghosh, Guillermo Gallego</dc:creator>
    </item>
    <item>
      <title>An Information-Theoretic Framework for Receiver Quantization in Communication</title>
      <link>https://arxiv.org/abs/2505.12258</link>
      <description>arXiv:2505.12258v2 Announce Type: replace-cross 
Abstract: We investigate information-theoretic limits and design of communication under receiver quantization. Unlike most existing studies, this work is more focused on the impact of resolution reduction from high to low. We consider a standard transceiver architecture, which includes i.i.d. complex Gaussian codebook at the transmitter, and a symmetric quantizer cascaded with a nearest neighbor decoder at the receiver. Employing the generalized mutual information (GMI), an achievable rate under general quantization rules is obtained in an analytical form, which shows that the rate loss due to quantization is $\log\left(1+\gamma\mathsf{SNR}\right)$, where $\gamma$ is determined by thresholds and levels of the quantizer. Based on this result, the performance under uniform receiver quantization is analyzed comprehensively. We show that the front-end gain control, which determines the loading factor of quantization, has an increasing impact on performance as the resolution decreases. In particular, we prove that the unique loading factor that minimizes the MSE also maximizes the GMI, and the corresponding irreducible rate loss is given by $\log\left(1+\mathsf {mmse}\cdot\mathsf{SNR}\right)$, where mmse is the minimum MSE normalized by the variance of quantizer input, and is equal to the minimum of $\gamma$. A geometrical interpretation for the optimal uniform quantization at the receiver is further established. Moreover, by asymptotic analysis, we characterize the impact of biased gain control, showing how small rate losses decay to zero and providing rate approximations under large bias. From asymptotic expressions of the optimal loading factor and mmse, approximations and several per-bit rules for performance are also provided. Finally we discuss more types of receiver quantization and show that the consistency between achievable rate maximization and MSE minimization does not hold in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12258v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jing Zhou, Shuqin Pang, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Cooperative NOMA Meets Emerging Technologies: A Survey for Next-Generation Wireless Networks</title>
      <link>https://arxiv.org/abs/2505.16327</link>
      <description>arXiv:2505.16327v2 Announce Type: replace-cross 
Abstract: The emerging demands of sixth-generation wireless networks, such as ultra-connectivity, native intelligence, and cross-domain convergence, are bringing renewed focus to cooperative non-orthogonal multiple access (C-NOMA) as a fundamental enabler of scalable, efficient, and intelligent communication systems. C-NOMA builds on the core benefits of NOMA by leveraging user cooperation and relay strategies to enhance spectral efficiency, coverage, and energy performance. This article presents a unified and forward-looking survey on the integration of C-NOMA with key enabling technologies, including radio frequency energy harvesting, cognitive radio networks, reconfigurable intelligent surfaces, space-air-ground integrated networks, and integrated sensing and communication-assisted semantic communication. Foundational principles and relaying protocols are first introduced to establish the technical relevance of C-NOMA. Then, a focused investigation is conducted into protocol-level synergies, architectural models, and deployment strategies across these technologies. Beyond integration, this article emphasizes the orchestration of C-NOMA across future application domains such as digital twins, extended reality, and e-health. In addition, it provides an extensive and in-depth review of recent literature, categorized by relaying schemes, system models, performance metrics, and optimization paradigms, including model-based, heuristic, and AI-driven approaches. Finally, open challenges and future research directions are outlined, spanning standardization, security, and cross-layer design, positioning C-NOMA as a key pillar of intelligent next-generation network architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16327v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud M. Salim, Suhail I. Al-Dharrab, Daniel Benevides Da Costa, Ali H. Muqaibel</dc:creator>
    </item>
    <item>
      <title>On the Stability of Graph Convolutional Neural Networks: A Probabilistic Perspective</title>
      <link>https://arxiv.org/abs/2506.01213</link>
      <description>arXiv:2506.01213v4 Announce Type: replace-cross 
Abstract: Graph convolutional neural networks (GCNNs) have emerged as powerful tools for analyzing graph-structured data, achieving remarkable success across diverse applications. However, the theoretical understanding of the stability of these models, i.e., their sensitivity to small changes in the graph structure, remains in rather limited settings, hampering the development and deployment of robust and trustworthy models in practice. To fill this gap, we study how perturbations in the graph topology affect GCNN outputs and propose a novel formulation for analyzing model stability. Unlike prior studies that focus only on worst-case perturbations, our distribution-aware formulation characterizes output perturbations across a broad range of input data. This way, our framework enables, for the first time, a probabilistic perspective on the interplay between the statistical properties of the node data and perturbations in the graph topology. We conduct extensive experiments to validate our theoretical findings and demonstrate their benefits over existing baselines, in terms of both representation stability and adversarial attacks on downstream tasks. Our results demonstrate the practical significance of the proposed formulation and highlight the importance of incorporating data distribution into stability analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01213v4</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Zhang, Henry Kenlay, Li Zhang, Mihai Cucuringu, Xiaowen Dong</dc:creator>
    </item>
    <item>
      <title>DASPack: Controlled Data Compression for Distributed Acoustic Sensing</title>
      <link>https://arxiv.org/abs/2507.16390</link>
      <description>arXiv:2507.16390v2 Announce Type: replace-cross 
Abstract: We present DASPack, a high-performance, open-source compression tool specifically designed for distributed acoustic sensing (DAS) data. As DAS becomes a key technology for real-time, high-density, and long-range monitoring in fields such as geophysics, infrastructure surveillance, and environmental sensing, the volume of collected data is rapidly increasing. Large-scale DAS deployments already generate hundreds of terabytes and are expected to increase in the coming years, making long-term storage a major challenge. Despite this urgent need, few compression methods have proven to be both practical and scalable in real-world scenarios. DASPack is a fully operational solution that consistently outperforms existing techniques for DAS data. It enables both controlled lossy and lossless compression by allowing users to choose the maximum absolute difference per datum between the original and compressed data. The compression pipeline combines wavelet transforms, linear predictive coding, and entropy coding to optimise efficiency. Our method achieves up to 3x file size reductions for strain and strain rate data in lossless mode across diverse datasets. In lossy mode, compression improves to 6x with near-perfect signal fidelity, and up to 10x is reached with acceptable signal degradation. It delivers fast throughput (100-200 MB/s using a single-thread and up to 750 MB/s using 8-threads), enabling real-time deployment even under high data rates. We validated its performance on 15 datasets from a variety of acquisition environments, demonstrating its speed, robustness, and broad applicability. DASPack provides a practical foundation for long-term, sustainable DAS data management in large-scale monitoring networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16390v2</guid>
      <category>physics.geo-ph</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/gji/ggaf397</arxiv:DOI>
      <dc:creator>Aleix Segui, Arantza Ugalde, Andreas Fichtner, Sergi Ventosa, Josep Ramon Morros</dc:creator>
    </item>
    <item>
      <title>Time-Resolved EEG Decoding of Semantic Processing Reveals Altered Neural Dynamics in Depression and Suicidality</title>
      <link>https://arxiv.org/abs/2507.22313</link>
      <description>arXiv:2507.22313v2 Announce Type: replace-cross 
Abstract: Depression and suicidality affect cognitive and emotional processes, yet objective, task-evoked neural readouts of mental health remain limited. We investigated the spatiotemporal dynamics of affective semantic processing using multivariate decoding of time-resolved, 64-channel electroencephalography (EEG). Participants (N=137) performed a sentence-evaluation task with emotionally salient, self-referential statements. We identified robust neural signatures of semantic processing, with peak decoding accuracy between 300-600 ms -- a window associated with rapid, stimulus-driven semantic evaluation and conflict monitoring. Relative to healthy controls, individuals with depression and suicidal ideation showed earlier onset, longer duration, and greater amplitude decoding responses, along with broader cross-temporal generalization and enhanced contributions from frontocentral and parietotemporal components. These findings suggest altered sensitivity and impaired disengagement from emotionally salient content in the clinical groups, advancing our understanding of the neurocognitive basis of mental health and establishing a compact and interpretable EEG-based index of semantic-evaluation dynamics with potential diagnostic relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22313v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Woojae Jeong, Aditya Kommineni, Kleanthis Avramidis, Colin McDaniel, Donald Berry, Myzelle Hughes, Thomas McGee, Elsi Kaiser, Dani Byrd, Assal Habibi, B. Rael Cahn, Idan A. Blank, Kristina Lerman, Dimitrios Pantazis, Sudarsana R. Kadiri, Takfarinas Medani, Shrikanth Narayanan, Richard M. Leahy</dc:creator>
    </item>
    <item>
      <title>Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices</title>
      <link>https://arxiv.org/abs/2510.05109</link>
      <description>arXiv:2510.05109v2 Announce Type: replace-cross 
Abstract: Large Multimodal Models (LMMs) are inherently modular, consisting of vision and audio encoders, projectors, and large language models. Yet, they are almost always executed monolithically, which underutilizes the heterogeneous accelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end latency. In this paper, we present NANOMIND, a hardware--software co-design inference framework for Large Multimodal Models (LMMs) that breaks large models into modular ``bricks'' (vision, language, audio, etc.) and maps each to its ideal accelerator. The key insight is that large models can be broken into modular components and scheduled to run on the most appropriate compute units. It performs module-level dynamic offloading across accelerators on unified-memory SoCs. By combining customized hardware design, system-level scheduling, and optimized low-bit computation kernels, we demonstrate our framework with a compact, battery-powered device capable of running LMMs entirely on device. This prototype functions as a self-contained intelligent assistant that requires no network connectivity, while achieving higher throughput and superior power efficiency under strict resource constraints. The design further bypasses CPU bottlenecks and reduces redundant memory usage through token-aware buffer management and module-level coordination. Our system outperforms existing implementations in resource efficiency, cutting energy consumption by 42.3\% and GPU memory usage by 11.2\%. This enables a battery-powered device to run LLaVA-OneVision with a camera for nearly half a day and LLaMA-3-8B for voice interactions up to almost 20.8 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05109v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yilong Li, Shuai Zhang, Yijing Zeng, Hao Zhang, Xinmiao Xiong, Jingyu Liu, Pan Hu, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>Exploiting Non-Diffracting Beams for Resilient Near-Field Millimeter-Wave Communications A Quantitative Roadmap</title>
      <link>https://arxiv.org/abs/2510.14858</link>
      <description>arXiv:2510.14858v2 Announce Type: replace-cross 
Abstract: Non diffracting (ND) beams are often cited as a promising solution to mitigate blockage in millimeter wave (mmWave) systems. However, a quantitative answer to the fundamental question, under what specific conditions do ND beams actually outperform conventional pencil beams, has remained elusive, especially in the emerging context of near-field communications. This paper provides the first systematic answer by mapping the performance advantage regimes of ND beams for blockage-resilient near-field links. We propose a unified holographic generator that synthesizes various structured beams (e.g., Bessel, Mathieu) under the physical constraints of a planar phased array, ensuring a fair comparison against a boresight baseline with identical EIRP and aperture. Through extensive, unbiased Monte Carlo simulations, we construct advantage regime maps that delineate the specific regions where ND beams offer a tangible link-level gain. Our key finding is that the advantage of ND beams is a powerful but conditional near field phenomenon. While offering a positive average gain, its performance is highly variable, with a 60-70% probability of outperforming the baseline in its optimal range. Crucially, this performance is strongly modulated by the obstacle's geometry, revealing a significant weakness against large blockers. These findings provide not just a practical roadmap for judiciously employing ND beams but also a clear motivation for future work in environment-aware, adaptively shaped structured beams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14858v2</guid>
      <category>physics.optics</category>
      <category>eess.SP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifeng Qin, Jing Chen, Zhi Hao Jiang, Zhining Chen, Yongming Huang</dc:creator>
    </item>
  </channel>
</rss>
