<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 04:02:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Matrix nearness problems and eigenvalue optimization</title>
      <link>https://arxiv.org/abs/2503.14750</link>
      <description>arXiv:2503.14750v1 Announce Type: new 
Abstract: This book is about solving matrix nearness problems that are related to eigenvalues or singular values or pseudospectra. These problems arise in great diversity in various fields, be they related to dynamics, as in questions of robust stability and robust control, or related to graphs, as in questions of clustering and ranking. Algorithms for such problems work with matrix perturbations that drive eigenvalues or singular values or Rayleigh quotients to desired locations.
  Remarkably, the optimal perturbation matrices are typically of rank one or are projections of rank-1 matrices onto a linear structure, e.g. a prescribed sparsity pattern. In the approach worked out here, these optimal rank-1 perturbations will be determined in a two-level iteration: In the inner iteration, an eigenvalue optimization problem for a fixed perturbation size is to be solved via gradient-based rank-1 matrix differential equations. This amounts to numerically driving a rank-1 matrix, which is represented by two vectors, into a stationary point, mostly starting nearby. The outer iteration determines the optimal perturbation size by solving a scalar nonlinear equation.
  A wide variety of matrix nearness problems, as outlined in the introductory Chapter I, will be tackled in Chapters II to VIII by such an approach and its nontrivial extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14750v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicola Guglielmi, Christian Lubich</dc:creator>
    </item>
    <item>
      <title>A shape-optimization approach for inverse diffusion problems by single boundary measurement</title>
      <link>https://arxiv.org/abs/2503.14764</link>
      <description>arXiv:2503.14764v1 Announce Type: new 
Abstract: This paper explores the reconstruction of a space-dependent parameter in inverse diffusion problems, proposing a shape-optimization-based approach. The main objective is to recover the absorption coefficient from a single boundary measurement. While conventional gradient-based methods rely on the Fr\'{e}chet derivative of a cost functional with respect to the unknown parameter, we also utilize its shape derivative with respect to the unknown boundary interface for recovery. This non-conventional approach addresses the problem of parameter recovery from a single measurement, which represents the key innovation of this work. Various numerical experiments, conducted in both two and three spatial dimensions, demonstrate the effectiveness of the proposed method, even for complex, non-convex boundary interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14764v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manabu Machida, Hirofumi Notsu, Julius Fergy Tiongson Rabago</dc:creator>
    </item>
    <item>
      <title>A PINN-enriched finite element method for linear elliptic problems</title>
      <link>https://arxiv.org/abs/2503.14913</link>
      <description>arXiv:2503.14913v1 Announce Type: new 
Abstract: In this paper, we propose a hybrid method that combines finite element method (FEM) and physics-informed neural network (PINN) for solving linear elliptic problems. This method contains three steps: (1) train a PINN and obtain an approximate solution $u_{\theta}$; (2) enrich the finite element space with $u_{\theta}$; (3) obtain the final solution by FEM in the enriched space. In the second step, the enriched space is constructed by addition $v + u_{\theta}$ or multiplication $v \cdot u_{\theta}$, where $v$ belongs to the standard finite element space. We conduct the convergence analysis for the proposed method. Compared to the standard FEM, the same convergence order is obtained and higher accuracy can be achieved when solution derivatives are well approximated in PINN. Numerical examples from one dimension to three dimensions verify these theoretical results. For some examples, the accuracy of the proposed method can be reduced by a couple of orders of magnitude compared to the standard FEM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14913v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Chen, Yixin Luo, Jingrun Chen</dc:creator>
    </item>
    <item>
      <title>Image Restoration Models with Optimal Transport and Total Variation Regularization</title>
      <link>https://arxiv.org/abs/2503.14947</link>
      <description>arXiv:2503.14947v1 Announce Type: new 
Abstract: In this paper, we propose image restoration models using optimal transport (OT) and total variation regularization. We present theoretical results of the proposed models based on the relations between the dual Lipschitz norm from OT and the G-norm introduced by Yves Meyer. We design a numerical method based on the Primal-Dual Hybrid Gradient (PDHG) algorithm for the Wasserstain distance and the augmented Lagrangian method (ALM) for the total variation, and the convergence analysis of the proposed numerical method is established. We also consider replacing the total variation in our model by one of its modifications developed in \cite{zhu}, with the aim of suppressing the stair-casing effect and preserving image contrasts. Numerical experiments demonstrate the features of the proposed models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14947v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijia Huang, Zhongyi Huang, Wenli Yang, Wei Zhu</dc:creator>
    </item>
    <item>
      <title>Control, Optimal Transport and Neural Differential Equations in Supervised Learning</title>
      <link>https://arxiv.org/abs/2503.15105</link>
      <description>arXiv:2503.15105v1 Announce Type: new 
Abstract: From the perspective of control theory, neural differential equations (neural ODEs) have become an important tool for supervised learning. In the fundamental work of Ruiz-Balet and Zuazua (SIAM REVIEW 2023), the authors pose an open problem regarding the connection between control theory, optimal transport theory, and neural differential equations. More precisely, they inquire how one can quantify the closeness of the optimal flows in neural transport equations to the true dynamic optimal transport. In this work, we propose a construction of neural differential equations that converge to the true dynamic optimal transport in the limit, providing a significant step in solving the formerly mentioned open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15105v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh-Nhat Phung, Minh-Binh Tran</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of SPH method on irregular particle distributions for the Poisson equation</title>
      <link>https://arxiv.org/abs/2503.15188</link>
      <description>arXiv:2503.15188v1 Announce Type: new 
Abstract: The accuracy of particle approximation in Smoothed Particle Hydrodynamics (SPH) method decreases due to irregular particle distributions, especially for second-order derivatives. This study aims to enhance the accuracy of SPH method and analyze its convergence with irregular particle distributions. By establishing regularity conditions for particle distributions, we ensure that the local truncation error of traditional SPH formulations, including first and second derivatives, achieves second-order accuracy. Our proposed method, the volume reconstruction SPH method, guarantees these regularity conditions while preserving the discrete maximum principle. Benefiting from the discrete maximum principle, we conduct a rigorous global error analysis in the $L^\infty$-norm for the Poisson equation with variable coefficients, achieving second-order convergence. Numerical examples are presented to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15188v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhonghua Qiao, Yifan Wei</dc:creator>
    </item>
    <item>
      <title>A Lie algebra view of matrix splittings</title>
      <link>https://arxiv.org/abs/2503.15258</link>
      <description>arXiv:2503.15258v1 Announce Type: new 
Abstract: In this paper we use some basic facts from the theory of (matrix) Lie groups and algebras to show that many of the classical matrix splittings used to construct stationary iterative methods and preconditioniers for Krylov subspace methods can be interpreted as linearizations of matrix factorizations. Moreover, we show that new matrix splittings are obtained when we specialize these splittings to some of the classical matrix groups and their Lie and Jordan algebras. As an example, we derive structured generalizations of the HSS (Hermitian/skew-Hermitian) iteration, and provide sufficient conditions for their convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15258v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Benzi, Milo Viviani</dc:creator>
    </item>
    <item>
      <title>A High Order IMEX Method for Generalized Korteweg de-Vries Equations</title>
      <link>https://arxiv.org/abs/2503.15397</link>
      <description>arXiv:2503.15397v1 Announce Type: new 
Abstract: In this paper, we introduce a high order space-time approximation of generalized Korteweg de-Vries equations. More specifically, the method uses continuous $H^1$-conforming finite elements for the spatial approximation and implicit-explicit methods for the temporal approximation. The method is high order in both space, provably stable, and mass-conservative. The scheme is formulated, its properties are proven, and numerical simulations are provided to illustrate the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15397v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seth Gerberding</dc:creator>
    </item>
    <item>
      <title>A discontinuity-capturing neural network with categorical embedding and its application to anisotropic elliptic interface problems</title>
      <link>https://arxiv.org/abs/2503.15441</link>
      <description>arXiv:2503.15441v1 Announce Type: new 
Abstract: In this paper, we propose a discontinuity-capturing shallow neural network with categorical embedding to represent piecewise smooth functions. The network comprises three hidden layers, a discontinuity-capturing layer, a categorical embedding layer, and a fully-connected layer. Under such a design, we show that a piecewise smooth function, even with a large number of pieces, can be approximated by a single neural network with high prediction accuracy. We then leverage the proposed network model to solve anisotropic elliptic interface problems. The network is trained by minimizing the mean squared error loss of the system. Our results show that, despite its simple and shallow structure, the proposed neural network model exhibits comparable efficiency and accuracy to traditional grid-based numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15441v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei-Fan Hu, Te-Sheng Lin, Ming-Chih Lai</dc:creator>
    </item>
    <item>
      <title>Acceptance or Rejection of Lots while Minimizing and Controlling Type I and Type II Errors</title>
      <link>https://arxiv.org/abs/2503.14514</link>
      <description>arXiv:2503.14514v1 Announce Type: cross 
Abstract: The double hypothesis test (DHT) is a test that allows controlling Type I (producer) and Type II (consumer) errors. It is possible to say whether the batch has a defect rate, p, between 1.5 and 2%, or between 2 and 5%, or between 5 and 10%, and so on, until finding a required value for this probability. Using the two probabilities side by side, the Type I error for the lower probability distribution and the Type II error for the higher probability distribution, both can be controlled and minimized. It can be applied in the development or manufacturing process of a batch of components, or in the case of purchasing from a supplier, when the percentage of defects (p) is unknown, considering the technology and/or process available to obtain them. The power of the test is amplified by the joint application of the Limit of Successive Failures (LSF) related to the Renewal Theory. To enable the choice of the most appropriate algorithm for each application. Four distributions are proposed for the Bernoulli event sequence, including their computational efforts: Binomial, Binomial approximated by Poisson, and Binomial approximated by Gaussian (with two variants). Fuzzy logic rules are also applied to facilitate decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14514v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edson Luiz Ursini, Elaine Cristina Catapani Poletti, Loreno Menezes da Silveira, Jos\'e Roberto Emiliano Leite</dc:creator>
    </item>
    <item>
      <title>Inferring diffusivity from killed diffusion</title>
      <link>https://arxiv.org/abs/2503.14978</link>
      <description>arXiv:2503.14978v1 Announce Type: cross 
Abstract: We consider diffusion of independent molecules in an insulated Euclidean domain with unknown diffusivity parameter. At a random time and position, the molecules may bind and stop diffusing in dependence of a given `binding potential'. The binding process can be modeled by an additive random functional corresponding to the canonical construction of a `killed' diffusion Markov process. We study the problem of conducting inference on the infinite-dimensional diffusion parameter from a histogram plot of the `killing' positions of the process. We show first that these positions follow a Poisson point process whose intensity measure is determined by the solution of a certain Schr\"odinger equation. The inference problem can then be re-cast as a non-linear inverse problem for this PDE, which we show to be consistently solvable in a Bayesian way under natural conditions on the initial state of the diffusion, provided the binding potential is not too `aggressive'. In the course of our proofs we obtain novel posterior contraction rate results for high-dimensional Poisson count data that are of independent interest. A numerical illustration of the algorithm by standard MCMC methods is also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14978v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Nickl, Fanny Seizilles</dc:creator>
    </item>
    <item>
      <title>Analytic adjoint solution for incompressible potential flows</title>
      <link>https://arxiv.org/abs/2503.15121</link>
      <description>arXiv:2503.15121v1 Announce Type: cross 
Abstract: We obtain the analytic adjoint solution for two-dimensional (2D) incompressible potential flow for a cost function measuring aerodynamic force using the connection of the adjoint approach to Green's functions and also by establishing and exploiting its relation to the adjoint incompressible Euler equations. By comparison with the analytic solution, it is shown that the naive approach based on solving Laplace's equation for the adjoint variables can be ill-defined. The analysis of the boundary behavior of the analytic solution is used to discuss the proper formulation of the adjoint problem as well as the mechanism for incorporating the Kutta condition in the adjoint formulation</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15121v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Carlos Lozano, Jorge Ponsin</dc:creator>
    </item>
    <item>
      <title>A Spectral Approach to Optimal Control of the Fokker-Planck Equation</title>
      <link>https://arxiv.org/abs/2503.15125</link>
      <description>arXiv:2503.15125v1 Announce Type: cross 
Abstract: In this paper, we present a spectral optimal control framework for Fokker-Planck equations based on the standard ground state transformation that maps the Fokker-Planck operator to a Schrodinger operator. Our primary objective is to accelerate convergence toward the (unique) steady state. To fulfill this objective, a gradient-based iterative algorithm with Pontryagin's maximum principle and Barzilai-Borwein update is developed to compute time-dependent controls. Numerical experiments on two-dimensional ill-conditioned normal distributions and double-well potentials demonstrate that our approach effectively targets slow-decaying modes, thus increasing the spectral gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15125v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Kalise, Lucas M. Moschen, Grigorios A. Pavliotis, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Computation of Miura surfaces with gradient Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2209.05567</link>
      <description>arXiv:2209.05567v5 Announce Type: replace 
Abstract: Miura surfaces are the solutions of a constrained nonlinear elliptic system of equations. This system is derived by homogenization from the Miura fold, which is a type of origami fold with multiple applications in engineering. A previous inquiry, gave suboptimal conditions for existence of solutions and proposed an $H^2$-conformal finite element method to approximate them. In this paper, the existence of Miura surfaces is studied using a gradient formulation. It is also proved that, under some hypotheses, the constraints propagate from the boundary to the interior of the domain. Then, a numerical method based on a stabilized least-square formulation, conforming finite elements and a Newton method is introduced to approximate Miura surfaces. The numerical method is proved to converge and numerical tests are performed to demonstrate its robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.05567v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederic Marazzato</dc:creator>
    </item>
    <item>
      <title>An Adaptive Parallel Arc-Length Method</title>
      <link>https://arxiv.org/abs/2303.01075</link>
      <description>arXiv:2303.01075v2 Announce Type: replace 
Abstract: Parallel computing is omnipresent in today's scientific computer landscape, starting at multicore processors in desktop computers up to massively parallel clusters. While domain decomposition methods have a long tradition in computational mechanics to decompose spatial problems into multiple subproblems that can be solved in parallel, advancing solution schemes for dynamics or quasi-statics are inherently serial processes. For quasi-static simulations, however, there is no accumulating 'time' discretization error, hence an alternative approach is required. In this paper, we present an Adaptive Parallel Arc-Length Method (APALM). By using a domain parametrization of the arc-length instead of time, the multi-level error for the arc-length parametrization is formed by the load parameter and the solution norm. By applying local refinements in the arc-length parameter, the APALM refines solutions where the non-linearity in the load-response space is maximal. The concept is easily extended for bifurcation problems. The performance of the method is demonstrated using isogeometric Kirchhoff-Love shells on problems with snap-through and pitch-fork instabilities. It can be concluded that the adaptivity of the method works as expected and that a relatively coarse approximation of the serial initialization can already be used to produce a good approximation in parallel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01075v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compstruc.2024.107300</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Structures 296 (2024): 107300</arxiv:journal_reference>
      <dc:creator>H. M. Verhelst, J. H. Den Besten, M. M\"oller</dc:creator>
    </item>
    <item>
      <title>Goal-Adaptive Meshing of Isogeometric Kirchhoff-Love Shells</title>
      <link>https://arxiv.org/abs/2307.08356</link>
      <description>arXiv:2307.08356v2 Announce Type: replace 
Abstract: Mesh adaptivity is a technique to provide detail in numerical solutions without the need to refine the mesh over the whole domain. Mesh adaptivity in isogeometric analysis can be driven by Truncated Hierarchical B-splines (THB-splines) which add degrees of freedom locally based on finer B-spline bases. Labeling of elements for refinement is typically done using residual-based error estimators. In this paper, an adaptive meshing workflow for isogeometric Kirchhoff-Love shell analysis is developed. This framework includes THB-splines, mesh admissibility for combined refinement and coarsening and the Dual-Weighted Residual (DWR) method for computing element-wise error contributions. The DWR can be used in several structural analysis problems, allowing the user to specify a goal quantity of interest which is used to mark elements and refine the mesh. This goal functional can involve, for example, displacements, stresses, eigenfrequencies etc. The proposed framework is evaluated through a set of different benchmark problems, including modal analysis, buckling analysis and non-linear snap-through and bifurcation problems, showing high accuracy of the DWR estimator and efficient allocation of degrees of freedom for advanced shell computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08356v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00366-024-01958-4</arxiv:DOI>
      <arxiv:journal_reference>Engineering with Computers (2024): 1-28</arxiv:journal_reference>
      <dc:creator>H. M. Verhelst, A. Mantzaflaris, M. M\"oller, J. H. Den Besten</dc:creator>
    </item>
    <item>
      <title>Ergodic Estimations for Toeplitz Sequences Generated by a Symbol</title>
      <link>https://arxiv.org/abs/2308.07281</link>
      <description>arXiv:2308.07281v4 Announce Type: replace 
Abstract: We analyse the convergence of the ergodic formula for Toeplitz matrix-sequences generated by a symbol and we produce explicit bounds depending on the size of the matrix, the regularity of the symbol and the regularity of the test function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07281v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Barbarino</dc:creator>
    </item>
    <item>
      <title>A comparison of smooth basis constructions for isogeometric analysis</title>
      <link>https://arxiv.org/abs/2309.04405</link>
      <description>arXiv:2309.04405v2 Announce Type: replace 
Abstract: In order to perform isogeometric analysis with increased smoothness on complex domains, trimming, variational coupling or unstructured spline methods can be used. The latter two classes of methods require a multi-patch segmentation of the domain, and provide continuous bases along patch interfaces. In the context of shell modeling, variational methods are widely used, whereas the application of unstructured spline methods on shell problems is rather scarce. In this paper, we therefore provide a qualitative and a quantitative comparison of a selection of unstructured spline constructions, in particular the D-Patch, Almost-$C^1$, Analysis-Suitable $G^1$ and the Approximate $C^1$ constructions. Using this comparison, we aim to provide insight into the selection of methods for practical problems, as well as directions for future research. In the qualitative comparison, the properties of each method are evaluated and compared. In the quantitative comparison, a selection of numerical examples is used to highlight different advantages and disadvantages of each method. In the latter, comparison with weak coupling methods such as Nitsche's method or penalty methods is made as well. In brief, it is concluded that the Approximate $C^1$ and Analysis-Suitable $G^1$ converge optimally in the analysis of a bi-harmonic problem, without the need of special refinement procedures. Furthermore, these methods provide accurate stress fields. On the other hand, the Almost-$C^1$ and D-Patch provide relatively easy construction on complex geometries. The Almost-$C^1$ method does not have limitations on the valence of boundary vertices, unlike the D-Patch, but is only applicable to biquadratic local bases. Following from these conclusions, future research directions are proposed, for example towards making the Approximate $C^1$ and Analysis-Suitable $G^1$ applicable to more complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04405v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2023.116659</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering 419 (2024): 116659</arxiv:journal_reference>
      <dc:creator>H. M. Verhelst, P. Weinm\"uller, A. Mantzaflaris, T. Takacs, D. Toshniwal</dc:creator>
    </item>
    <item>
      <title>The sharpness condition for constructing a finite element from a superspline</title>
      <link>https://arxiv.org/abs/2407.03680</link>
      <description>arXiv:2407.03680v2 Announce Type: replace 
Abstract: This paper addresses sharpness conditions for constructing $C^r$ conforming finite element spaces from a superspline spaces on general simplicial triangulations. We introduce the concept of extendability for the pre-element spaces, which encompasses both the superspline spaces and the finite element spaces. By examining the extendability condition for both types of spaces, we provide an answer to the conditions regarding the construction. A corollary of our results is that constructing $C^r$ conforming elements in $d$ dimensions generally requires an extra $C^{2^{s}r}$ continuity on $s$-codimensional simplices, and the polynomial degree is at least $(2^d r + 1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03680v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Hu, Ting Lin, Qingyu Wu, Beihui Yuan</dc:creator>
    </item>
    <item>
      <title>Optimizing Variational Physics-Informed Neural Networks Using Least Squares</title>
      <link>https://arxiv.org/abs/2407.20417</link>
      <description>arXiv:2407.20417v3 Announce Type: replace 
Abstract: Variational Physics-Informed Neural Networks often suffer from poor convergence when using stochastic gradient-descent-based optimizers. By introducing a Least Squares solver for the weights of the last layer of the neural network, we improve the convergence of the loss during training in most practical scenarios. This work analyzes the computational cost of the resulting hybrid Least-Squares/Gradient-Descent optimizer and explains how to implement it efficiently. In particular, we show that a traditional implementation based on backward-mode automatic differentiation leads to a prohibitively expensive algorithm. To remedy this, we propose using either forward-mode automatic differentiation or an ultraweak-type scheme that avoids the differentiation of trial functions in the discrete weak formulation. The proposed alternatives are up to one hundred times faster than the traditional one, recovering a computational cost-per-iteration similar to that of a conventional gradient-descent-based optimizer alone. To support our analysis, we derive computational estimates and conduct numerical experiments in one- and two-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20417v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.camwa.2025.02.022</arxiv:DOI>
      <dc:creator>Carlos Uriarte, Manuela Bastidas, David Pardo, Jamie M. Taylor, Sergio Rojas</dc:creator>
    </item>
    <item>
      <title>An efficient particle locating method on unstructured meshes in two and three dimensions based on patch searching</title>
      <link>https://arxiv.org/abs/2408.07959</link>
      <description>arXiv:2408.07959v2 Announce Type: replace 
Abstract: We present a particle locating method for unstructured meshes in two and three dimensions. Our algorithm is based on a patch searching process, and includes two steps. We first locate the given point to a patch near a vertex, and then the host element is determined within the patch domain. Here, the patch near a vertex is the domain of elements around this vertex. We prove that in the first step the patch can be rapidly identified by constructing an auxiliary Cartesian grid with a prescribed resolution. Then, the second step can be converted into a searching problem, which can be easily solved by searching algorithms. Only coordinates to particles are required in our method. We conduct a series of numerical tests in two and three dimensions to illustrate the robustness and efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07959v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Chen, Fanyi Yang</dc:creator>
    </item>
    <item>
      <title>A Wrinkling Model for General Hyperelastic Materials based on Tension Field Theory</title>
      <link>https://arxiv.org/abs/2410.16990</link>
      <description>arXiv:2410.16990v3 Announce Type: replace 
Abstract: Wrinkling is the phenomenon of out-of-plane deformation patterns in thin walled structures, as a result of a local compressive (internal) loads in combination with a large membrane stiffness and a small but non-zero bending stiffness. Numerical modelling typically involves thin shell formulations. As the mesh resolution depends on the wrinkle wave lengths, the analysis can become computationally expensive for shorter ones. Implicitly modeling the wrinkles using a modified kinematic or constitutive relationship based on a taut, slack or wrinkled state derived from a so-called tension field, a simplification is introduced in order to reduce computational efforts. However, this model was restricted to linear elastic material models in previous works. Aiming to develop an implicit isogeometric wrinkling model for large strain and hyperelastic material applications, a modified deformation gradient has been assumed, which can be used for any strain energy density formulation. The model is an extension of a previously published model for linear elastic material behaviour and is generalized to other types of discretisation as well. The extension for hyperelastic materials requires the derivative of the material tensor, which can be computed numerically or derived analytically. The presented model relies on a combination of dynamic relaxation and a Newton-Raphson solver, because of divergence in early Newton-Raphson iterations as a result of a changing tension field, which is not included in the stress tensor variation. Using four benchmarks, the model performance is evaluated. Convergence with the expected order for Newton-Raphson iterations has been observed, provided a fixed tension field. The model accurately approximates the mean surface of a wrinkled membrane with a reduced number of degrees of freedom in comparison to a shell solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16990v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>H. M. Verhelst, M. M\"oller, J. H. Den Besten</dc:creator>
    </item>
    <item>
      <title>Exploiting Inexact Computations in Multilevel Sampling Methods</title>
      <link>https://arxiv.org/abs/2503.05533</link>
      <description>arXiv:2503.05533v2 Announce Type: replace 
Abstract: Multilevel sampling methods, such as multilevel and multifidelity Monte Carlo, multilevel stochastic collocation, or delayed acceptance Markov chain Monte Carlo, have become standard uncertainty quantification tools for a wide class of forward and inverse problems. The underlying idea is to achieve faster convergence by leveraging a hierarchy of models, such as partial differential equation (PDE) or stochastic differential equation (SDE) discretisations with increasing accuracy. By optimally redistributing work among the levels, multilevel methods can achieve significant performance improvement compared to single level methods working with one high-fidelity model. Intuitively, approximate solutions on coarser levels can tolerate large computational error without affecting the overall accuracy. We show how this can be used in high-performance computing applications to obtain a significant performance gain.
  As a use case, we analyse the computational error in the standard multilevel Monte Carlo method and formulate an adaptive algorithm which determines a minimum required computational accuracy on each level of discretisation. We show two examples of how the inexactness can be converted into actual gains using an elliptic PDE with lognormal random coefficients. Using a low precision sparse direct solver combined with iterative refinement results in a simulated gain in memory references of up to $3.5\times$ compared to the reference double precision solver; while using a MINRES iterative solver, a practical speedup of up to $1.5\times$ in terms of FLOPs is achieved. These results provide a step in the direction of energy-aware scientific computing, with significant potential for energy savings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05533v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josef Mart\'inek, Erin Carson, Robert Scheichl</dc:creator>
    </item>
    <item>
      <title>Investigation of the piston effect in supercritical fluids via a reversible--irreversible vector field splitting-based explicit time integration scheme</title>
      <link>https://arxiv.org/abs/2503.07449</link>
      <description>arXiv:2503.07449v2 Announce Type: replace 
Abstract: In the vicinity of the liquid--vapor critical point, supercritical fluids behave strongly compressibly and, in parallel, thermophysical properties have strong state dependence. These lead to various peculiar phenomena, one of which being the piston effect where a sudden heating induces a mechanical pulse. The coupling between thermal and mechanical processes, in the linear approximation, yields a non-trivially rich thermoacoustics. The numerous applications of supercritical fluids raise the need for reliable yet fast and efficient numerical solution for thermoacoustic time and space dependence in this sensitive domain. Here, we present a second-order accurate, fully explicit staggered space-time grid finite difference method for such coupled linear thermoacoustic problems. Time integration is based on the splitting of the state space vector field representing the interactions that affect the dynamics into reversible and irreversible parts, which splitting procedure leads to decoupled wave and heat equations. The former is a hyperbolic partial differential equation, while the latter is a parabolic one, therefore, different time integration algorithms must be amalgamated to obtain a reliable, dispersion error-free, and dissipation error-free numerical solution. Finally, the thermoacoustic approximation of the supercritical piston effect is investigated via the developed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07449v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Don\'at M. Tak\'acs, Tam\'as F\"ul\"op, R\'obert Kov\'acs, M\'aty\'as Sz\"ucs</dc:creator>
    </item>
    <item>
      <title>Conditional Stability of the Euler Method on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2503.09434</link>
      <description>arXiv:2503.09434v2 Announce Type: replace 
Abstract: We derive nonlinear stability results for numerical integrators on Riemannian manifolds, by imposing conditions on the ODE vector field and the step size that makes the numerical solution non-expansive whenever the exact solution is non-expansive over the same time step. Our model case is a geodesic version of the explicit Euler method. Precise bounds are obtained in the case of Riemannian manifolds of constant sectional curvature. The approach is based on a cocoercivity property of the vector field adapted to manifolds from Euclidean space. It allows us to compare the new results to the corresponding well-known results in flat spaces, and in general we find that a non-zero curvature will deteriorate the stability region of the geodesic Euler method. The step size bounds depend on the distance traveled over a step from the initial point. Numerical examples for spheres and hyperbolic 2-space confirm that the bounds are tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09434v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Ghirardelli, Brynjulf Owren, Elena Celledoni</dc:creator>
    </item>
    <item>
      <title>Optimal Estimation and Uncertainty Quantification for Stochastic Inverse Problems via Variational Bayesian Methods</title>
      <link>https://arxiv.org/abs/2503.10199</link>
      <description>arXiv:2503.10199v4 Announce Type: replace 
Abstract: The Bayesian inversion method demonstrates significant potential for solving inverse problems, enabling both point estimation and uncertainty quantification. However, Bayesian maximum a posteriori (MAP) estimation may become unstable when handling data from diverse distributions (e.g., solutions of stochastic partial differential equations (SPDEs)). Additionally, Monte Carlo sampling methods are computationally expensive. To address these challenges, we propose a novel two-stage optimization method based on optimal control theory and variational Bayesian methods. This method not only achieves stable solutions for stochastic inverse problems but also efficiently quantifies the uncertainty of the solutions. In the first stage, we introduce a new weighting formulation to ensure the stability of the Bayesian MAP estimation. In the second stage, we derive the necessary condition to efficiently quantify the uncertainty of the solutions, by combining the new weighting formula with variational inference. Furthermore, we establish an error estimation theorem that relates the exact solution to the optimally estimated solution under different amounts of observed data. Finally, the efficiency of the proposed method is demonstrated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10199v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruibiao Song, Liying Zhang</dc:creator>
    </item>
    <item>
      <title>An inexact infeasible arc-search interior-point method for linear optimization</title>
      <link>https://arxiv.org/abs/2403.18155</link>
      <description>arXiv:2403.18155v3 Announce Type: replace-cross 
Abstract: Arc-search interior-point methods (IPMs) are a class of IPMs that utilize an ellipsoidal arc to approximate the central path. On the other hand, inexact IPMs solve the linear
  equation system for the search direction inexactly at each iteration. In this paper, we propose an inexact infeasible arc-search interior-point method. We establish that the
  proposed method is a polynomial-time algorithm and we show that its iteration complexity is lower than an inexact infeasible line-search IPM. We conducted numerical experiments with benchmark problems from NETLIB. The numerical results demonstrate that the proposed method can reduce the number of iterations and the computation time compared to an existing inexact line-search IPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18155v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Einosuke Iida, Makoto Yamashita</dc:creator>
    </item>
    <item>
      <title>ANaGRAM: A Natural Gradient Relative to Adapted Model for efficient PINNs learning</title>
      <link>https://arxiv.org/abs/2412.10782</link>
      <description>arXiv:2412.10782v2 Announce Type: replace-cross 
Abstract: In the recent years, Physics Informed Neural Networks (PINNs) have received strong interest as a method to solve PDE driven systems, in particular for data assimilation purpose. This method is still in its infancy, with many shortcomings and failures that remain not properly understood. In this paper we propose a natural gradient approach to PINNs which contributes to speed-up and improve the accuracy of the training. Based on an in depth analysis of the differential geometric structures of the problem, we come up with two distinct contributions: (i) a new natural gradient algorithm that scales as $\min(P^2S, S^2P)$, where $P$ is the number of parameters, and $S$ the batch size; (ii) a mathematically principled reformulation of the PINNs problem that allows the extension of natural gradient to it, with proved connections to Green's function theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10782v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of ICLR 2025</arxiv:journal_reference>
      <dc:creator>Nilo Schwencke, Cyril Furtlehner</dc:creator>
    </item>
  </channel>
</rss>
