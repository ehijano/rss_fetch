<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Dec 2025 05:02:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Do you precondition on the left or on the right?</title>
      <link>https://arxiv.org/abs/2512.05160</link>
      <description>arXiv:2512.05160v1 Announce Type: new 
Abstract: This work is a follow-up to a poster that was presented at the DD29 conference. Participants were asked the question: ``Do you precondition on the left or on the right?''. Here we report on the results of this social experiment. We also provide context on left, right and split preconditioning, share our literature review on the topic, and analyze some of the finer points. Two examples illustrate that convergence bounds can sometimes lead to misleading conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05160v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Spillane (CMAP), Pierre Matalon (CMAP), Daniel B Szyld</dc:creator>
    </item>
    <item>
      <title>Calculation of Univariate Pade Approximants for solutions of the Michaelis-Menten equation with first order input using the Tau method</title>
      <link>https://arxiv.org/abs/2512.05258</link>
      <description>arXiv:2512.05258v1 Announce Type: new 
Abstract: In this paper the Jacobi formula is used to recursively generate (diagonal) univariate Pade approximants using the Tau method for solutions Michaelis-Menten equation with first order input. In the algorithm the Jacobi coefficients and error terms in the Tau method are postulated to have a particular form, and this form is maintained by specific patterns of cancellations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05258v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gareth Hegarty</dc:creator>
    </item>
    <item>
      <title>Stability analysis of very high order minimization-based and Taylor-based embedded boundary treatments of discontinuous Galerkin for hyperbolic equations</title>
      <link>https://arxiv.org/abs/2512.05278</link>
      <description>arXiv:2512.05278v1 Announce Type: new 
Abstract: In this paper, we present a stability analysis of very high order embedded boundary methods, specifically the Reconstruction for Off-site Data (ROD) and Shifted Boundary (SB) methods, coupled with a discontinuous Galerkin discretization for the linear advection equation. In unfitted configurations, these methods impose consistent modified boundary conditions on the computational boundary. Due to the high algebraic complexity of very high order schemes, the stability is studied by visualizing the eigenspectrum of the discretized operators. A recent study on the SB method demonstrated that its Taylor expansion can be formulated as a direct polynomial correction. In this work, we prove that the ROD minimization problem admits an analogous polynomial correction. This unified perspective provides significant benefits: algorithmically, it greatly simplifies the implementation of ROD by eliminating the need for linear system inversions at each iteration; mathematically, it enables a rigorous stability study. For completeness, a side-by-side stability analysis of the ROD and SB methods is presented for polynomials up to degree 6. Furthermore, due to the stability restrictions of embedded methods for hyperbolic problems, a coupling with both explicit and implicit time integration is investigated. A set of numerical experiments confirms the findings of the stability study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05278v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mirco Ciallella</dc:creator>
    </item>
    <item>
      <title>Randomized Algorithms for Low-Rank Matrix and Tensor Decompositions</title>
      <link>https://arxiv.org/abs/2512.05286</link>
      <description>arXiv:2512.05286v1 Announce Type: new 
Abstract: This paper surveys randomized algorithms in numerical linear algebra for low-rank decompositions of matrices and tensors. The survey begins with a review of classical matrix algorithms that can be accelerated by randomized dimensionality reduction, such as the singular value decomposition (SVD) or interpolative (ID) and CUR decompositions. Recent advances in randomized dimensionality reduction are discussed, including new methods of fast matrix sketching and sampling techniques, which are incorporated into classical matrix algorithms for fast low-rank matrix approximations. The extension of randomized matrix algorithms to tensors is then explored for several low-rank tensor decompositions in the CP and Tucker formats, including the higher-order SVD, ID, and CUR decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05286v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine J. Pearce, Per-Gunnar Martinsson</dc:creator>
    </item>
    <item>
      <title>A new class of general linear method with inherent quadratic stability for solving stiff differential systems</title>
      <link>https://arxiv.org/abs/2512.05486</link>
      <description>arXiv:2512.05486v1 Announce Type: new 
Abstract: This article proposes a new class of general linear method with $p=q$ and $r=s=p+1$. The construction of the present method is carried out using order conditions and error minimization subject to $A$- stability constraints. The proposed time integration schemes are $A$- and $L$-stable general linear methods (GLMs) equipped with inherent quadratic stability (IQS) criteria. We construct implicit GLMs of orders up to four with $p = q$ and $s = r$ along with the Nordsieck input vector assumption. Further, we test these schemes on three real-world problems: the van der Pol oscillator and two partial differential equations consisting of diffusion (Burgers' equation and the Gray-Scott model), and numerical results are presented. Computational results confirm that our proposed schemes are competitive with the existing GLMs and can be recognized as an alternative time integration scheme. We demonstrate the order of accuracy and convergence for the proposed schemes through observed order computation and error versus step size plots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05486v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sakshi Gautam, Ram K. Pandey</dc:creator>
    </item>
    <item>
      <title>Long-time stability analysis of an explicit exponential Runge-Kutta scheme for Cahn-Hilliard equations</title>
      <link>https://arxiv.org/abs/2512.05608</link>
      <description>arXiv:2512.05608v1 Announce Type: new 
Abstract: In this paper, we present a comprehensive long-time stability analysis of a second-order explicit exponential Runge--Kutta (ERK2) method for the Cahn--Hilliard (CH) equation. By employing Fourier spectral collocation in space and a two-stage ERK2 scheme in time, we construct a fully discrete numerical method that preserves the original energy dissipation property. The uniform-in-time boundedness of the numerical solution is rigorously proven in the discrete $H^1$ and $H^2$ norms under a mild time-step condition, and an $\ell^\infty$ bound is derived via a discrete Sobolev embedding. These results remove the typical boundedness assumption required in previous energy-stability analyses, thereby establishing unconditional energy dissipation for the fully discrete scheme. Building on this uniform boundedness, we derive an optimal-order error estimate in the $\ell^2$ norm. The analytical framework developed herein is general and can be extended to higher-order exponential integrators for a broader class of phase-field models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05608v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Guo</dc:creator>
    </item>
    <item>
      <title>Divergence-free decoupled finite element methods for incompressible flow problems</title>
      <link>https://arxiv.org/abs/2512.05642</link>
      <description>arXiv:2512.05642v1 Announce Type: new 
Abstract: Incompressible flows are modeled by a coupled system of partial differential equations for velocity and pressure, Starting from a divergence-free mixed method proposed in [John, Li, Merdon and Rui, Math. Models Methods Appl. Sci. 34(05):919--949, 2024], this paper proposes $\vecb{H}(\mathrm{div})$-conforming finite element methods which decouple the velocity and pressure by constructing divergence-free basis functions. Algorithmic issues like the computation of this basis and the imposition of non-homogeneous Dirichlet boundary conditions are discussed. Numerical studies at two- and three-dimensional Stokes problems compare the efficiency of the proposed methods with methods from the above mentioned paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05642v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Volker John, Xu Li, Christian Merdon</dc:creator>
    </item>
    <item>
      <title>Inexact Uzawa-Double Deep Ritz Method for Weak Adversarial Neural Networks</title>
      <link>https://arxiv.org/abs/2512.05673</link>
      <description>arXiv:2512.05673v1 Announce Type: new 
Abstract: The emergence of deep learning has stimulated a new class of PDE solvers in which the unknown solution is represented by a neural network. Within this framework, residual minimization in dual norms -- central to weak adversarial neural network approaches -- naturally leads to saddle-point problems whose stability depends on the underlying iterative scheme. Motivated by this structure, we develop an inexact Uzawa methodology in which both trial and test functions are represented by neural networks and updated only approximately. We introduce the Uzawa Deep Double Ritz method, a mesh-free deep PDE solver equipped with a continuous level convergence showing that the overall iteration remains stable and convergent provided the inexact inner updates move in the correct descent direction. Numerical experiments validate the theoretical findings and demonstrate the practical robustness and accuracy of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05673v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emin Benny-Chacko, Ignacio Brevis, Luis Espath, Kristoffer G. van der Zee</dc:creator>
    </item>
    <item>
      <title>Optimal Time-Adaptivity for Parabolic Problems with applications to Model Order Reduction</title>
      <link>https://arxiv.org/abs/2512.05676</link>
      <description>arXiv:2512.05676v1 Announce Type: new 
Abstract: Since the first optimality proofs for adaptive mesh refinement algorithms in the early 2000s, the theory of optimal mesh refinement for PDEs was inherently limited to stationary problems. The reason for this is that time-dependent problems usually do not exhibit the necessary coercive structure that is used in optimality proofs to show a certain quasi-orthogonality, which is crucial for the theory. Recently, by using a new equivalence between quasi-orthogonality and inf-sup stability of the underlying problem, it was shown that an adaptive Crank-Nicolson scheme for the heat equation is optimal under a severe step size restriction. In this work, we use this new approach towards quasi-orthogonality together with a Radau IIA method that combines the advantages of the Crank-Nicolson and implicit Euler schemes. We obtain the first adaptive time stepping method for non-stationary PDEs that is provably rate optimal with respect to number of time steps vs. approximation error. Together with a reduced basis method that leverages the Laplace transform for building tailored subspaces of reduced dimension, we obtain a very efficient method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05676v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Feischl, Fernando Henr\'iquez, David Niederkofler</dc:creator>
    </item>
    <item>
      <title>Interpretation of a Discrete de Rham method as a Finite Element System</title>
      <link>https://arxiv.org/abs/2512.05912</link>
      <description>arXiv:2512.05912v1 Announce Type: new 
Abstract: We show that the DDR method can be interpreted as defining a computable consistent discrete $\mathrm{L}^2$ product on a conforming FES defined by PDEs. Without modifying the numerical method itself, this point of view provides an alternative approach to the analysis. The conformity and consistency properties we prove are stronger than those previously shown. We can also recover some of the other results that have been proved about DDR, from those that have already been proved, in principle, in the general context of FES. We also bring VEM, the Virtual Element Method, into the discussion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05912v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Snorre H. Christiansen, Francesca Rapetti</dc:creator>
    </item>
    <item>
      <title>A Discontinuous Galerkin Consistent Splitting Method for the Incompressible Navier-Stokes Equations</title>
      <link>https://arxiv.org/abs/2512.05919</link>
      <description>arXiv:2512.05919v1 Announce Type: new 
Abstract: This work presents the discontinuous Galerkin discretization of the consistent splitting scheme proposed by Liu [J. Liu, J. Comp. Phys., 228(19), 2009]. The method enforces the divergence-free constraint implicitly, removing velocity--pressure compatibility conditions and eliminating pressure boundary layers. Consistent boundary conditions are imposed, also for settings with open and traction boundaries. Hence, accuracy in time is no longer limited by a splitting error.
  The symmetric interior penalty Galerkin method is used for second spatial derivatives. The convective term is treated in a semi-implicit manner, which relaxes the CFL restriction of explicit schemes while avoiding the need to solve nonlinear systems required by fully implicit formulations. For improved mass conservation, Leray projection is combined with divergence and normal continuity penalty terms.
  By selecting appropriate fluxes for both the divergence of the velocity field and the divergence of the convective operator, the consistent pressure boundary condition can be shown to reduce to contributions arising solely from the acceleration and the viscous term for the $L^2$ discretization. Per time step, the decoupled nature of the scheme with respect to the velocity and pressure fields leads to a single pressure Poisson equation followed by a single vector-valued convection-diffusion-reaction equation. We verify optimal convergence rates of the method in both space and time and demonstrate compatibility with higher-order time integration schemes. A series of numerical experiments, including the two-dimensional flow around a cylinder benchmark and the three-dimensional Taylor--Green vortex problem, verify the applicability to practically relevant flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05919v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Still, Natalia Nebulishvili, Richard Schussnig, Katharina Kormann, Martin Kronbichler</dc:creator>
    </item>
    <item>
      <title>Qualitative and Quantitative Analysis of Riemannian Optimization Methods for Ground States of Rotating Multicomponent Bose-Einstein Condensates</title>
      <link>https://arxiv.org/abs/2512.05939</link>
      <description>arXiv:2512.05939v1 Announce Type: new 
Abstract: We develop and analyze Riemannian optimization methods for computing ground states of rotating multicomponent Bose-Einstein condensates, defined as minimizers of the Gross-Pitaevskii energy functional. To resolve the non-uniqueness of ground states induced by phase invariance, we work on a quotient manifold endowed with a general Riemannian metric. By introducing an auxiliary phase-aligned iteration and employing fixed-point convergence theory, we establish a unified local convergence framework for Riemannian gradient descent methods and derive explicit convergence rates. Specializing this framework to two metrics tailored to the energy landscape, we study the energy-adaptive and Lagrangian-based Riemannian gradient descent methods. While monotone energy decay and global convergence are established only for the former, a quantified local convergence analysis is provided for both methods. Numerical experiments confirm the theoretical results and demonstrate that the Lagrangian-based method, which incorporates second-order information on the energy functional and mass constraints, achieves faster local convergence than the energy-adaptive scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05939v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hermann, Tatjana Stykel, Mahima Yadav</dc:creator>
    </item>
    <item>
      <title>CFO: Learning Continuous-Time PDE Dynamics via Flow-Matched Neural Operators</title>
      <link>https://arxiv.org/abs/2512.05297</link>
      <description>arXiv:2512.05297v1 Announce Type: cross 
Abstract: Neural operator surrogates for time-dependent partial differential equations (PDEs) conventionally employ autoregressive prediction schemes, which accumulate error over long rollouts and require uniform temporal discretization. We introduce the Continuous Flow Operator (CFO), a framework that learns continuous-time PDE dynamics without the computational burden of standard continuous approaches, e.g., neural ODE. The key insight is repurposing flow matching to directly learn the right-hand side of PDEs without backpropagating through ODE solvers. CFO fits temporal splines to trajectory data, using finite-difference estimates of time derivatives at knots to construct probability paths whose velocities closely approximate the true PDE dynamics. A neural operator is then trained via flow matching to predict these analytic velocity fields. This approach is inherently time-resolution invariant: training accepts trajectories sampled on arbitrary, non-uniform time grids while inference queries solutions at any temporal resolution through ODE integration. Across four benchmarks (Lorenz, 1D Burgers, 2D diffusion-reaction, 2D shallow water), CFO demonstrates superior long-horizon stability and remarkable data efficiency. CFO trained on only 25% of irregularly subsampled time points outperforms autoregressive baselines trained on complete data, with relative error reductions up to 87%. Despite requiring numerical integration at inference, CFO achieves competitive efficiency, outperforming autoregressive baselines using only 50% of their function evaluations, while uniquely enabling reverse-time inference and arbitrary temporal querying.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05297v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xianglong Hou, Xinquan Huang, Paris Perdikaris</dc:creator>
    </item>
    <item>
      <title>Convolution-FFT for option pricing in the Heston model</title>
      <link>https://arxiv.org/abs/2512.05326</link>
      <description>arXiv:2512.05326v1 Announce Type: cross 
Abstract: We propose a convolution-FFT method for pricing European options under the Heston model that leverages a continuously differentiable representation of the joint characteristic function. Unlike existing Fourier-based methods that rely on branch-cut adjustments or empirically tuned damping parameters, our approach yields a stable integrand even under large frequency oscillations. Crucially, we derive fully analytical error bounds that quantify both truncation error and discretization error in terms of model parameters and grid settings. To the best of our knowledge, this is the first work to provide such explicit, closed-form error estimates for an FFT-based convolution method specialized to the Heston model. Numerical experiments confirm the theoretical rates and illustrate robust, high-accuracy option pricing at modest computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05326v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.PR</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Gao, Cody Hyndman</dc:creator>
    </item>
    <item>
      <title>OpenSQP: A Reconfigurable Open-Source SQP Algorithm in Python for Nonlinear Optimization</title>
      <link>https://arxiv.org/abs/2512.05392</link>
      <description>arXiv:2512.05392v1 Announce Type: cross 
Abstract: Sequential quadratic programming (SQP) methods have been remarkably successful in solving a broad range of nonlinear optimization problems. These methods iteratively construct and solve quadratic programming (QP) subproblems to compute directions that converge to a local minimum. While numerous open-source and commercial SQP algorithms are available, their implementations lack the transparency and modularity necessary to adapt and fine-tune them for specific applications or to swap out different modules to create a new optimizer. To address this gap, we present OpenSQP, a modular and reconfigurable SQP algorithm implemented in Python that achieves robust performance comparable to leading algorithms. We implement OpenSQP in a manner that allows users to easily modify or replace components such as merit functions, line search procedures, Hessian approximations, and QP solvers. This flexibility enables the creation of tailored variants of the algorithm for specific needs. To demonstrate reliability, we present numerical results using the standard configuration of OpenSQP that employs a smooth augmented Lagrangian merit function for the line search and a quasi-Newton BFGS method for approximating the Hessians. We benchmark this configuration on a comprehensive set of problems from the CUTEst test suite. The results demonstrate performance that is competitive with proven nonlinear optimization algorithms such as SLSQP, SNOPT, and IPOPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05392v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anugrah Jo Joshy, John T. Hwang</dc:creator>
    </item>
    <item>
      <title>Stochastic Zeroth-Order Method for Computing Generalized Rayleigh Quotients</title>
      <link>https://arxiv.org/abs/2512.05520</link>
      <description>arXiv:2512.05520v1 Announce Type: cross 
Abstract: The maximization of the (generalized) Rayleigh quotient is a central problem in numerical linear algebra. Conventional algorithms for its computation typically rely on matrix-adjoint products, making them sensitive to errors arising from adjoint mismatches. To address this issue, we introduce a stochastic zeroth-order Riemannian algorithm that maximizes the generalized Rayleigh quotient without requiring adjoint or matrix inverse computations. We provide theoretical convergence guarantees showing that the iterates converge to the set of global maximizers of the (generalized) Rayleigh quotient at a sublinear rate with probability one. Our theoretical results are supported by numerical experiments, which demonstrate the excellent performance of the proposed method compared to state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05520v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Bresch, Oleh Melnyk, Martin Schoen, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>Taylor Approximation Variance Reduction for Approximation Errors in PDE-constrained Bayesian Inverse Problems</title>
      <link>https://arxiv.org/abs/2512.05723</link>
      <description>arXiv:2512.05723v1 Announce Type: cross 
Abstract: In numerous applications, surrogate models are used as a replacement for accurate parameter-to-observable mappings when solving large-scale inverse problems governed by partial differential equations (PDEs). The surrogate model may be a computationally cheaper alternative to the accurate parameter-to-observable mappings and/or may ignore additional unknowns or sources of uncertainty. The Bayesian approximation error (BAE) approach provides a means to account for the induced uncertainties and approximation errors (between the accurate parameter-to-observable mapping and the surrogate). The statistics of these errors are in general unknown a priori, and are thus calculated using Monte Carlo sampling. Although the sampling is typically carried out offline the process can still represent a computational bottleneck. In this work, we develop a scalable computational approach for reducing the costs associated with the sampling stage of the BAE approach. Specifically, we consider the Taylor expansion of the accurate and surrogate forward models with respect to the uncertain parameter fields either as a control variate for variance reduction or as a means to efficiently approximate the mean and covariance of the approximation errors. We propose efficient methods for evaluating the expressions for the mean and covariance of the Taylor approximations based on linear(-ized) PDE solves. Furthermore, the proposed approach is independent of the dimension of the uncertain parameter, depending instead on the intrinsic dimension of the data, ensuring scalability to high-dimensional problems. The potential benefits of the proposed approach are demonstrated for two high-dimensional inverse problems governed by PDE examples, namely for the estimation of a distributed Robin boundary coefficient in a linear diffusion problem, and for a coefficient estimation problem governed by a nonlinear diffusion problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05723v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruanui Nicholson, Radoslav Vuchkov, Umberto Villa, Noemi Petra</dc:creator>
    </item>
    <item>
      <title>Concrete examples of the rate of convergence of Chernoff approximations: numerical results for the heat semigroup and open questions on them (with appendix: full list of pictures and Python code)</title>
      <link>https://arxiv.org/abs/2301.05284</link>
      <description>arXiv:2301.05284v4 Announce Type: replace 
Abstract: The article is devoted to the construction of examples that illustrate (using computer calculations) the rate of convergence of Chernoff approximations to the solution of the Cauchy problem for the heat equation. We are interested in the Chernoff theorem in general and select the heat semigroup as a model case because this semigroup (and solutions of the heat equations) are known, so it is easy to measure the distance between the exact solution and its Chernoff approximations. Two Chernoff functions (of the first and second order of Chernoff tangency to the generator of the heat semigroup, i.e. to the operator of taking the second derivative) and several initial conditions of different smoothness are considered. From the numerically plotted graphs, visually, it is determined that the approximations are close to the solution. For each of the two Chernoff functions, for several initial conditions of different smoothness and for approximation numbers up to 11 inclusive, the error (i.e. the supremum of the absolute value of the difference between the exact solution and the approximating function) corresponding to each approximation was numerically found. As it turned out, in all the cases studied, the dependence of the error on the number of the approximation has an approximately power-law form (we call this power the order of convergence). This follows from the fact that, as we discovered, the dependence of the logarithm of the error on the logarithm of the approximation number is approximately linear. Using the considered family of initial conditions, an empirical dependence of the order of convergence on the smoothness class of the initial condition is found. The orders of convergence for all the initial conditions studied are collected in a table.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05284v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>K. A. Katalova (Dragunova), N. Nikbakht, I. D. Remizov</dc:creator>
    </item>
    <item>
      <title>pETNNs: Partial Evolutionary Tensor Neural Networks for Solving Time-dependent Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2403.06084</link>
      <description>arXiv:2403.06084v3 Announce Type: replace 
Abstract: We present the partial evolutionary tensor neural networks (pETNNs), a novel framework for solving time-dependent partial differential equations with high accuracy and capable of handling high-dimensional problems. Our architecture incorporates tensor neural networks and evolutionary parametric approximation. A posterior error bounded is proposed to support the extrapolation capabilities. In the numerical implementations, we adopt a partial update strategy to achieve a significant reduction in computational cost while maintaining precision and robustness. Notably, as a low-rank approximation method of complex dynamical systems, pETNNs enhance the accuracy of evolutionary deep neural networks and empower computational abilities to address high-dimensional problems. Numerical experiments demonstrate the superior performance of the pETNNs in solving time-dependent complex equations, including the incompressible Navier-Stokes equations, high-dimensional heat equations, high-dimensional transport equations, and dispersive equations of higher-order derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06084v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4208/csiam-am.SO-2024-0048</arxiv:DOI>
      <dc:creator>Tunan Kao, He Zhang, Lei Zhang, Jin Zhao</dc:creator>
    </item>
    <item>
      <title>Convergent analysis of algebraic multigrid method with data-driven parameter learning for non-selfadjoint elliptic problems</title>
      <link>https://arxiv.org/abs/2410.23681</link>
      <description>arXiv:2410.23681v3 Announce Type: replace 
Abstract: In this paper, we apply the practical GADI-HS iteration as a smoother in algebraic multigrid (AMG) method for solving second-order non-selfadjoint elliptic problem. Additionally, we prove the convergence of the derived algorithm and introduce a data-driven parameter learing method called Gaussian process regression (GPR) to predict optimal parameters. Numerical experimental results show that using GPR to predict parameters can save a significant amount of time cost and approach the optimal parameters accurately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23681v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Zhang, Junyue Luo</dc:creator>
    </item>
    <item>
      <title>Multi- and Infinite-variate Integration and $L^2$-Approximation on Hilbert Spaces with Gaussian Kernels</title>
      <link>https://arxiv.org/abs/2412.05368</link>
      <description>arXiv:2412.05368v2 Announce Type: replace 
Abstract: We study integration and $L^2$-approximation in the worst-case setting for deterministic linear algorithms based on function evaluations. The underlying function space is a reproducing kernel Hilbert space with a Gaussian kernel of tensor product form. In the infinite-variate case, for both computational problems, we establish matching upper and lower bounds for the polynomial convergence rate of the $n$-th minimal error. In the multivariate case, we improve several tractability results for the integration problem. For the proofs, we establish the following transference result together with an explicit construction: Each of the computational problems on a space with a Gaussian kernel is equivalent on the level of algorithms to the same problem on a Hermite space with suitable parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05368v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Gnewuch, Klaus Ritter, Robin R\"u{\ss}mann</dc:creator>
    </item>
    <item>
      <title>Image resizing by neural network operators and their convergence rate with respect to the $L^p$-norm and the dissimilarity index defined through the continuous SSIM</title>
      <link>https://arxiv.org/abs/2501.14857</link>
      <description>arXiv:2501.14857v2 Announce Type: replace 
Abstract: In literature, several algorithms for imaging based on interpolation or approximation methods are available. The implementation of theoretical processes highlighted the necessity of providing theoretical frameworks for the convergence and error estimate analysis to support the experimental setups. In this paper, we establish new techniques for deriving quantitative estimates for the order of approximation for multivariate linear operators of the pointwise-type, with respect to the $L^p$-norm and to the so-called dissimilarity index defined through the continuous SSIM. In particular, we consider a family of approximation operators known as neural network (NN) operators, that have been widely studied in the last years in view of their connection with the theory of artificial neural networks. For these operators, we first establish sharp estimates in case of $C^1$ and piecewise (everywhere defined) $C^1$-functions. Then, the case of functions modeling digital images is considered, and specific quantitative estimates are achieved, including those with respect to the mentioned dissimilarity index. Moreover, the above analysis has also been extended to $L^p$-spaces, using a new constructive technique, in which the multivariate averaged modulus of smoothness has been employed. Finally, numerical experiments of image resizing have been given to support the theoretical results. The accuracy of the proposed algorithm has been evaluated through similarity indexes such as SSIM, likelihood index (S-index) and PSNR, and compared with other rescaling methods, including bilinear, bicubic, and upscaling-de la Vall\'ee-Poussin interpolation (u-VPI). Numerical simulations show the effectiveness of the proposed method for image processing tasks, particularly in terms of the aforementioned SSIM, and are consistent with the provided theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14857v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Costarelli, Mariarosaria Natale, Michele Piconi</dc:creator>
    </item>
    <item>
      <title>Discrete Superconvergence Analysis for Quantum Magnus Algorithms of Unbounded Hamiltonian Simulation</title>
      <link>https://arxiv.org/abs/2502.20255</link>
      <description>arXiv:2502.20255v2 Announce Type: replace 
Abstract: Motivated by various applications, unbounded Hamiltonian simulation has recently garnered great attention. Quantum Magnus algorithms, designed to achieve commutator scaling for time-dependent Hamiltonian simulation, have been found to be particularly efficient for such applications. When applied to unbounded Hamiltonian simulation in the interaction picture, they exhibit an unexpected superconvergence phenomenon. However, existing proofs are limited to the spatially continuous setting and do not extend to discrete spatial discretizations. In this work, we provide the first superconvergence estimate in the fully discrete setting with a finite number of spatial discretization points $N$, and show that it holds with an error constant uniform in $N$. The proof is based on the two-parameter symbol class, which, to our knowledge, is applied for the first time in algorithm analysis. The key idea is to establish a semiclassical framework by identifying two parameters through the discretization number and the time step size rescaled by the operator norm, such that the semiclassical uniformity guarantees the uniformity of both. This approach may have broader applications in numerical analysis beyond the specific context of this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20255v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>quant-ph</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yonah Borns-Weil, Di Fang, Jiaqi Zhang</dc:creator>
    </item>
    <item>
      <title>The Linearized Vlasov-Maxwell System as a Hamiltonian System</title>
      <link>https://arxiv.org/abs/2504.04929</link>
      <description>arXiv:2504.04929v2 Announce Type: replace 
Abstract: We present a Hamiltonian formulation for the linearized Vlasov-Maxwell system with a Maxwellian background distribution function. We discuss the geometric properties of the model at the continuous level, and how to discretize the model in the GEMPIC framework [1]. This method allows us to preserve the structure of the system at the semi-discrete level. To integrate the model in time, we employ a Poisson splitting and discuss how to integrate each subsystem separately. We test the model against the direct delta-f method, which is the non-geometric pendant of our model. The first test case is the weak Landau damping, where our model exhibits the same physical properties for short simulations, but enjoys better long-time stability and energy conservation due to its geometric construction. These advantages becomes even more pronounced for the simulation of Bernstein waves, our second test case, where the noise in the direct delta-f method washes out all features of the dispersion relation whereas our model is able to reproduce the full spectrum correctly. The model is implemented in the open-source Python library STRUPHY [2], [3].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04929v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.5205875</arxiv:DOI>
      <dc:creator>Dominik Bell, Martin Campos Pinto, Stefan Possanner, Eric Sonnendr\"ucker</dc:creator>
    </item>
    <item>
      <title>Operator learning meets inverse problems: A probabilistic perspective</title>
      <link>https://arxiv.org/abs/2508.20207</link>
      <description>arXiv:2508.20207v2 Announce Type: replace 
Abstract: Operator learning offers a robust framework for approximating mappings between infinite-dimensional function spaces. It has also become a powerful tool for solving inverse problems in the computational sciences. This chapter surveys methodological and theoretical developments at the intersection of operator learning and inverse problems. It begins by summarizing the probabilistic and deterministic approaches to inverse problems, and pays special attention to emerging measure-centric formulations that treat observed data or unknown parameters as probability distributions. The discussion then turns to operator learning by covering essential components such as data generation, loss functions, and widely used architectures for representing function-to-function maps. The core of the chapter centers on the end-to-end inverse operator learning paradigm, which aims to directly map observed data to the solution of the inverse problem without requiring explicit knowledge of the forward map. It highlights the unique challenge that noise plays in this data-driven inversion setting, presents structure-aware architectures for both point predictions and posterior estimates, and surveys relevant theory for linear and nonlinear inverse problems. The chapter also discusses the estimation of priors and regularizers, where operator learning is used more selectively within classical inversion algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20207v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas H. Nelsen, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>The Conjugate Function Method for Surfaces with Elaborate Topological Types</title>
      <link>https://arxiv.org/abs/2509.01978</link>
      <description>arXiv:2509.01978v2 Announce Type: replace 
Abstract: The conjugate function method is an algorithm for numerical computation of conformal mappings for simply and multiply connected domains on surfaces. In this paper the conjugate function method, earlier used for simply connected domains, is generalized and refined to achieve the same level of accuracy on multiply connected planar domains and Riemann surfaces. The main challenge is the accurate and efficient construction of boundary values for the conjugate problem on multiply connected domains. The method relies on high-order finite element methods which allow for highly accurate computations of mappings on surfaces, including domains of complex boundary geometry containing strong singularities and cusps. We also derive the reciprocal error estimate for the multiply connected case. The efficacy of the proposed method is illustrated via an extensive set of numerical experiments with error estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01978v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <category>math.DG</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Hakula, A. Rasila, Y. Zheng</dc:creator>
    </item>
    <item>
      <title>Algorithm for constructing optimal explicit finite-difference formulas in the Hilbert space</title>
      <link>https://arxiv.org/abs/2510.06643</link>
      <description>arXiv:2510.06643v2 Announce Type: replace 
Abstract: This work presents problems of constructing finite-difference formulas in the Hilbert space, i.e., setting problems of constructing finite-difference formulas using functional methods. The work presents a functional statement of the problem of optimizing finite-difference formulas in the space $W_{2}^{\left(m,m-1\right)} \left(0,1\right)$. Here, representations of optimal coefficients of explicit finite-difference formulas of the Adams type on classes $W_{2}^{\left(m,m-1\right)} \left(0,1\right)$ for any $m\ge 3$ will be found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06643v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. S. Karimov, D. D. Atoev</dc:creator>
    </item>
    <item>
      <title>Unconditionally stable Gauge-Uzawa finite element schemes for the chemo-repulsion-Navier-Stokes system</title>
      <link>https://arxiv.org/abs/2510.27026</link>
      <description>arXiv:2510.27026v2 Announce Type: replace 
Abstract: This paper investigates a Gauge-Uzawa finite element method (GU-FEM) for the two-dimensional chemo-repulsion-Navier-Stokes (CRNS) system. The proposed approach establishes a fully discrete projection framework that integrates the advantages of both canonical and Uzawa-type formulations while preserving variational consistency. The method possesses two notable advantages: (1) it requires no initial pressure value; (2) it avoids artificial pressure boundary conditions and thus reduces computational cost. Furthermore, the scheme is shown to be unconditionally energy stable, and we establish unique solvability together with optimal error estimates for cell density, chemical concentration, and fluid velocity. Finally, several numerical experiments are provided to validate the accuracy, stability, and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27026v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyang Li, Ping Lin, Haibiao Zheng</dc:creator>
    </item>
    <item>
      <title>Convergence of a Sequential Monte Carlo algorithm towards multimodal distributions on Rd</title>
      <link>https://arxiv.org/abs/2511.22564</link>
      <description>arXiv:2511.22564v3 Announce Type: replace-cross 
Abstract: In an earlier joint work, we studied a sequential Monte Carlo algorithm to sample from the Gibbs measure supported on torus with a non-convex energy function at a low temperature, where we proved that the time complexity of the algorithm is polynomial in the inverse temperature. However, the analysis in that torus setting relied crucially on compactness and does not directly extend to unbounded domains. This work introduces a new approach that resolves this issue and establishes a similar result for sampling from Gibbs measures supported on Rd. In particular, our main result shows that for double-well energy with equal well depths, the time complexity scales as seventh power of the inverse temperature, and quadratically in both the inverse allowed absolute error and probability error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22564v3</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiyu Han</dc:creator>
    </item>
  </channel>
</rss>
