<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.geo-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.geo-ph</link>
    <description>physics.geo-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.geo-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Dec 2025 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Gutenberg-Richter-like relations in physical systems</title>
      <link>https://arxiv.org/abs/2512.17615</link>
      <description>arXiv:2512.17615v1 Announce Type: cross 
Abstract: We analyze regional earthquake energy statistics from the Southern California and Japan seismic catalogs and find scale-invariant energy distributions characterized by an exponent $\tau \simeq 1.67$. To quantify how closely scale-invariant dynamics with different exponent values resemble real earthquakes, we generate synthetic energy distributions over a wide range of $\tau$ under conditions of constant activity. Earthquake-like behavior, in a broad sense, is obtained for $1.5 \leqslant \tau &lt; 2.0$. When energy variations are further restricted to be within a factor of ten relative to real earthquakes, the admissible range narrows to $1.58 \leqslant \tau \leqslant 1.76$. We identify the physical mechanisms governing the dynamics in the different regimes: fault dynamics characterized by a balance between slow energy accumulation and release through scale-free events in the earthquake-like regime; externally supplied energy relative to a slowly driven fault for $\tau &lt; 1.5$; and dominance of small events in the energy budget for $\tau &gt; 2$</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17615v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Duplat, G. Varas, O. Ramos</dc:creator>
    </item>
    <item>
      <title>What is glacier sliding</title>
      <link>https://arxiv.org/abs/2407.13577</link>
      <description>arXiv:2407.13577v4 Announce Type: replace 
Abstract: Glacier and ice-sheet motion is fundamental to glaciology. However, we still lack a consensus for the optimal way to relate basal velocity to basal traction for large-scale glacier and ice-sheet models (the 'sliding relationship'). Typically, a single tunable coefficient loosely connected to one or a limited number of physical processes is varied spatially to reconcile model output with observations. Yet, process-agnostic studies indicate that the suitability of a given sliding relationship depends on the setting. Here, we suggest that this arises from myriad overlapping setting- and scale-dependent sliding sub-processes, including complicated near-basal stress states not captured by large-scale models, reviewed here as comprising a basal 'sliding layer'. A corresponding 'bulk layer' then accounts for ice deformation only minimally influenced by bed properties. We provide a framework for incorporating arbitrarily many sub-processes within a given region -- separated into normal ('form drag') and tangential ('slip') resistance at the ice-bed interface, stressing that the maximum scale of cavitation is an important contributor to the division between the two. Under reasonable assumptions, our framework implies that sliding relationships should fall within a sum of regularised-Coulomb and power-law components, with a rough-smooth distinction proving more consequential in dictating sliding behaviour than a traditional hard-soft transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13577v4</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Law, David Chandler, Phillip Voigt, Ivan Utkin, Andreas Born</dc:creator>
    </item>
    <item>
      <title>Non-parametric kernel density estimation of magnitude distribution for the analysis of seismic hazard posed by anthropogenic seismicity</title>
      <link>https://arxiv.org/abs/2503.04393</link>
      <description>arXiv:2503.04393v2 Announce Type: replace 
Abstract: Frequent significant deviations of the observed magnitude distribution of anthropogenic seismicity from the Gutenberg-Richter relation require alternative estimation methods for probabilistic seismic hazard assessments. We evaluate five nonparametric kernel density estimation (KDE) methods on simulated samples drawn from four magnitude distribution models: the exponential, concave and convex bi-exponential, and exponential-Gaussian distributions. The latter three represent deviations from the Gutenberg-Richter relation due to the finite thickness of the seismogenic crust and the effect of characteristic earthquakes. The assumed deviations from exponentiality are never more than those met in practice. The studied KDE methods include Silverman's and Scott's rules with Abramson's bandwidth adaptation, two diffusion-based methods (ISJ and diffKDE), and adaptiveKDE, which formulates the bandwidth estimation as an optimization problem. We assess their performance for magnitudes from 2 to 6 with sample sizes of 400 to 5000, using the mean integrated square error (MISE) over 100,000 simulations. Their suitability in hazard assessments is illustrated by the mean of the mean return period (MRP) for a sample size of 1000. Among the tested methods, diffKDE provides the most accurate cumulative distribution function estimates for larger magnitudes. Even when the data is drawn from an exponential distribution, diffKDE performs comparably to maximum likelihood estimation when the sample size is at least 1000. Given that anthropogenic seismicity often deviates from the exponential model, we recommend using diffKDE for probabilistic seismic hazard assessments whenever a sufficient sample size is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04393v2</guid>
      <category>physics.geo-ph</category>
      <category>stat.AP</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11600-025-01762-8</arxiv:DOI>
      <dc:creator>Francis Tong, Stanis{\l}aw Lasocki, Beata Orlecka-Sikora</dc:creator>
    </item>
  </channel>
</rss>
