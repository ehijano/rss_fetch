<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2024 05:03:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Unifying Theory of Aging and Mortality</title>
      <link>https://arxiv.org/abs/2412.12815</link>
      <description>arXiv:2412.12815v1 Announce Type: new 
Abstract: In this paper, we advance the network theory of aging and mortality by developing a causal mathematical model for the mortality rate. First, we show that in large networks, where health deficits accumulate at nodes representing health indicators, the modeling of network evolution with Poisson processes is universal and can be derived from fundamental principles. Second, with the help of two simplifying approximations, which we refer to as mean-field assumption and homogeneity assumption, we provide an analytical derivation of Gompertz law under generic and biologically relevant conditions. We identify the parameters in Gompertz law as a function of the parameters driving the evolution of the network, and illustrate our computations with simulations and analytic approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12815v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentin Flietner, Bernd Heidergott, Frank den Hollander, Ines Lindner, Azadeh Parvaneh, Holger Strulik</dc:creator>
    </item>
    <item>
      <title>InterPLM: Discovering Interpretable Features in Protein Language Models via Sparse Autoencoders</title>
      <link>https://arxiv.org/abs/2412.12101</link>
      <description>arXiv:2412.12101v1 Announce Type: cross 
Abstract: Protein language models (PLMs) have demonstrated remarkable success in protein modeling and design, yet their internal mechanisms for predicting structure and function remain poorly understood. Here we present a systematic approach to extract and analyze interpretable features from PLMs using sparse autoencoders (SAEs). By training SAEs on embeddings from the PLM ESM-2, we identify up to 2,548 human-interpretable latent features per layer that strongly correlate with up to 143 known biological concepts such as binding sites, structural motifs, and functional domains. In contrast, examining individual neurons in ESM-2 reveals up to 46 neurons per layer with clear conceptual alignment across 15 known concepts, suggesting that PLMs represent most concepts in superposition. Beyond capturing known annotations, we show that ESM-2 learns coherent concepts that do not map onto existing annotations and propose a pipeline using language models to automatically interpret novel latent features learned by the SAEs. As practical applications, we demonstrate how these latent features can fill in missing annotations in protein databases and enable targeted steering of protein sequence generation. Our results demonstrate that PLMs encode rich, interpretable representations of protein biology and we propose a systematic framework to extract and analyze these latent features. In the process, we recover both known biology and potentially new protein motifs. As community resources, we introduce InterPLM (interPLM.ai), an interactive visualization platform for exploring and analyzing learned PLM features, and release code for training and analysis at github.com/ElanaPearl/interPLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12101v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elana Simon, James Zou</dc:creator>
    </item>
    <item>
      <title>Using machine learning to inform harvest control rule design in complex fishery settings</title>
      <link>https://arxiv.org/abs/2412.12400</link>
      <description>arXiv:2412.12400v1 Announce Type: cross 
Abstract: In fishery science, harvest management of size-structured stochastic populations is a long-standing and difficult problem. Rectilinear precautionary policies based on biomass and harvesting reference points have now become a standard approach to this problem. While these standard feedback policies are adapted from analytical or dynamic programming solutions assuming relatively simple ecological dynamics, they are often applied to more complicated ecological settings in the real world. In this paper we explore the problem of designing harvest control rules for partially observed, age-structured, spasmodic fish populations using tools from reinforcement learning (RL) and Bayesian optimization. Our focus is on the case of Walleye fisheries in Alberta, Canada, whose highly variable recruitment dynamics have perplexed managers and ecologists. We optimized and evaluated policies using several complementary performance metrics. The main questions we addressed were: 1. How do standard policies based on reference points perform relative to numerically optimized policies? 2. Can an observation of mean fish weight, in addition to stock biomass, aid policy decisions?</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12400v1</guid>
      <category>q-bio.PE</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Montealegre-Mora, Carl Boettiger, Carl J. Walters, Christopher L. Cahill</dc:creator>
    </item>
    <item>
      <title>Does the random nature of cell-virus interactions during in vitro infections affect TCID$_{50}$ measurements and parameter estimation by mathematical models?</title>
      <link>https://arxiv.org/abs/2412.12960</link>
      <description>arXiv:2412.12960v1 Announce Type: cross 
Abstract: Endpoint dilution (TCID50) assays cannot count the number of infectious virions (IVs), and instead are limited to counting the number of Specific INfections caused by the sample (SIN). The latter depends not only on whether virions are infectious, but also on the cells and the experimental conditions under which they interact. These interactions are random and controlled by parameters such as the rates at which IVs lose infectivity, enter cells, or fail to replicate following cell entry. Here, stochastic TCID50 assays are simulated to determine how the random number of infected wells relates to the parameters and the number of IVs in a sample. We introduce a new parameter estimation method based on the likelihood of observing a given TCID50 assay outcome given the model-predicted number of IVs in the sample. We then successively evaluate how parameter estimates are affected by the use of: 1) the new likelihood function vs the typical assumption of Gaussian-distributed measurement errors; 2) IV vs SIN units to express virus in the model; and 3) a stochastic vs an ODE model to simulate the course of a virus infection. Unlike previous methods, the new likelihood correctly handles measurements beyond the detection limits, and results in non-Gaussian distributions. Expressing virus using IV units makes it possible to impose physical constraints (e.g. one IV cannot infect more than one cell), and yields more biologically useful parameters (e.g. mutation emergence likelihood depends on the number of IVs, not SIN, produced). Using a stochastic rather than an ODE model we show that the variability observed between replicate in vitro virus infections is consistent with the level of stochasticity introduced by the TCID50 assay, which can be reduced through better assay design. The framework introduced herein offers several important improvements over current methods and should be widely adopted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12960v1</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Quirouette, Risavarshni Thevakumaran, Kyosuke Adachi, Catherine A. A. Beauchemin</dc:creator>
    </item>
  </channel>
</rss>
