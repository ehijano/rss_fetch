<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 02:36:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Phospho-Proteomics Method Optimization and Application to Stimulated Jurkat Cells</title>
      <link>https://arxiv.org/abs/2511.02932</link>
      <description>arXiv:2511.02932v1 Announce Type: new 
Abstract: In clinical proteomics, available input is often limited. In addition, phospho-proteomics is of particular interest since the dysregulation of these post-translational modifications (PTMs) has been implicated in various diseases such as cancer. We therefore assessed the feasibility of low input phospho-proteomics via phospho-bulk titration and low-input starting material. We found that there was identification of more phospho-peptides through phospho-bulk titration because of sample loss during preparation of low input starting material. Additionally, we explored various lysis buffers and boiling times for efficiency of decrosslinking formalin-fixed cells since cells and tissues are often fixed for preservation and sorting via FACS. We found that boiling in 0.05M Tris pH 7.6 with 5% SDS for 60 min yielded the highest number of phospho-peptides. Lastly, we applied Evotips Pure and phospho-bulk titration to treated Jurkat cells and identified 7 phospho-sites involved in T-cell stimulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02932v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.GN</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Teresia Ndungu, Jana Zecha, Lisa Cazares, Sonja Hess</dc:creator>
    </item>
    <item>
      <title>Novel reaction-diffusion PDE model for fingerprint-like pattern emergence via the Schnakenberg mechanism</title>
      <link>https://arxiv.org/abs/2511.03096</link>
      <description>arXiv:2511.03096v1 Announce Type: new 
Abstract: Fingerprint analysis and fingerprint identification have been the most widely used tools for human identification. To this day, various models have been proposed to explain how fingerprints are formed, ranging from the fibroblast model, which focuses on cell-collagen interactions, to the buckling of thin layers model, both yielding significant results. In this work, we present a reaction-diffusion model of Schnakenberg type, featuring an anisotropic diffusion matrix that follows the ridge orientations supplied by other traditional fingerprint-generation models, and notably yet allows minutiae -- i.e. characteristic microstructures embedded in fingerprints -- to emerge. The statistical analysis of the minutiae distribution in a randomly generated fingerprint collection is consistent with observations in real fingerprints. The model can numerically generate fingerprint-like patterns corresponding to the four basic classifications -- arches, ulnar loops, radial loops, and whorls -- as well as a variety of derived forms. The generated patterns emerge on a convex domain that mimics the geometry of a fingertip, exhibiting the diverse types of minutiae typically analyzed in fingerprint identification and showing strong agreement with those observed in human fingerprints. This model also provides insight into how levels of certainty in human identification can be achieved when based on minutiae positions. All the algorithms are implemented in an open source software named GenCHSin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03096v1</guid>
      <category>q-bio.QM</category>
      <category>nlin.PS</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabi\'an Sep\'ulveda-Soto, Lucia Soto-Barrios, Carlos Rom\'an, Axel Osses</dc:creator>
    </item>
    <item>
      <title>FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation</title>
      <link>https://arxiv.org/abs/2511.03113</link>
      <description>arXiv:2511.03113v1 Announce Type: cross 
Abstract: Computational antibody design holds immense promise for therapeutic discovery, yet existing generative models are fundamentally limited by two core challenges: (i) a lack of dynamical consistency, which yields physically implausible structures, and (ii) poor generalization due to data scarcity and structural bias. We introduce FP-AbDiff, the first antibody generator to enforce Fokker-Planck Equation (FPE) physics along the entire generative trajectory. Our method minimizes a novel FPE residual loss over the mixed manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising scores to assemble into a globally coherent probability flow. This physics-informed regularizer is synergistically integrated with deep biological priors within a state-of-the-art SE(3)-equivariant diffusion framework. Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25% improvement over the previous state-of-the-art model, AbX, and the highest reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored in the more challenging six-CDR co-design task, where our model delivers consistently superior geometric precision, cutting the average full-chain Root Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By aligning generative dynamics with physical laws, FP-AbDiff enhances robustness and generalizability, establishing a principled approach for physically faithful and functionally viable antibody design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03113v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiameng Chen, Yida Xiong, Kun Li, Hongzhi Zhang, Xiantao Cai, Wenbin Hu, Jia Wu</dc:creator>
    </item>
    <item>
      <title>Morpho-Genomic Deep Learning for Ovarian Cancer Subtype and Gene Mutation Prediction from Histopathology</title>
      <link>https://arxiv.org/abs/2511.03365</link>
      <description>arXiv:2511.03365v1 Announce Type: cross 
Abstract: Ovarian cancer remains one of the most lethal gynecological malignancies, largely due to late diagnosis and extensive heterogeneity across subtypes. Current diagnostic methods are limited in their ability to reveal underlying genomic variations essential for precision oncology. This study introduces a novel hybrid deep learning pipeline that integrates quantitative nuclear morphometry with deep convolutional image features to perform ovarian cancer subtype classification and gene mutation inference directly from Hematoxylin and Eosin (H&amp;E) histopathological images. Using $\sim45,000$ image patches sourced from The Cancer Genome Atlas (TCGA) and public datasets, a fusion model combining a ResNet-50 Convolutional Neural Network (CNN) encoder and a Vision Transformer (ViT) was developed. This model successfully captured both local morphological texture and global tissue context. The pipeline achieved a robust overall subtype classification accuracy of $84.2\%$ (Macro AUC of $0.87 \pm 0.03$). Crucially, the model demonstrated the capacity for gene mutation inference with moderate-to-high accuracy: $AUC_{TP53} = 0.82 \pm 0.02$, $AUC_{BRCA1} = 0.76 \pm 0.04$, and $AUC_{ARID1A} = 0.73 \pm 0.05$. Feature importance analysis established direct quantitative links, revealing that nuclear solidity and eccentricity were the dominant predictors for TP53 mutation. These findings validate that quantifiable histological phenotypes encode measurable genomic signals, paving the way for cost-effective, precision histopathology in ovarian cancer triage and diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03365v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriela Fernandes</dc:creator>
    </item>
    <item>
      <title>Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in Brain Gliomas</title>
      <link>https://arxiv.org/abs/2511.03376</link>
      <description>arXiv:2511.03376v1 Announce Type: cross 
Abstract: We present a framework that combines Large Language Models with computational image analytics for non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. For each subject, coregistered multi-parametric MRI scans and multi-class tumor segmentation maps were processed to extract interpretable semantic (visual) attributes and quantitative features, serialized in a standardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning. We evaluated this framework on six publicly available datasets (N = 1427) and results showcased high accuracy and balanced classification performance across heterogeneous cohorts, even in the absence of manual annotations. GPT 5 outperformed GPT 4o in context-driven phenotype interpretation. Volumetric features emerged as the most important predictors, supplemented by subtype-specific imaging markers and clinical information. Our results demonstrate the potential of integrating LLM-based reasoning with computational image analytics for precise, non-invasive tumor genotyping, advancing diagnostic strategies in neuro-oncology. The code is available at https://github.com/ATPLab-LUMS/CIM-LLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03376v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Syed Muqeem Mahmood, Hassan Mohy-ud-Din</dc:creator>
    </item>
    <item>
      <title>Reliability Assessment Framework Based on Feature Separability for Pathological Cell Image Classification under Prior Bias</title>
      <link>https://arxiv.org/abs/2511.01953</link>
      <description>arXiv:2511.01953v2 Announce Type: replace 
Abstract: Background and objective: Prior probability shift between training and deployment datasets challenges deep learning-based medical image classification. Standard correction methods reweight posterior probabilities to adjust prior bias, yet their benefit is inconsistent. We developed a reliability framework identifying when prior correction helps or harms performance in pathological cell image analysis. Methods: We analyzed 303 colorectal cancer specimens with CD103/CD8 immunostaining, yielding 185,432 annotated cell images across 16 cell types. ResNet models were trained under varying bias ratios (1.1-20$\times$). Feature separability was quantified using cosine similarity-based likelihood quality scores, reflecting intra- versus inter-class distinctions in learned feature spaces. Multiple linear regression, ANOVA, and generalized additive models (GAMs) evaluated associations among feature separability, prior bias, sample adequacy, and F1 performance. Results: Feature separability dominated performance ($\beta = 1.650$, $p &lt; 0.001$), showing 412-fold stronger impact than prior bias ($\beta = 0.004$, $p = 0.018$). GAM analysis showed strong predictive power ($R^2 = 0.876$) with mostly linear trends. A quality threshold of 0.294 effectively identified cases requiring correction (AUC = 0.610). Cell types scoring $&gt;0.5$ were robust without correction, whereas those $&lt;0.3$ consistently required adjustment. Conclusion: Feature extraction quality, not bias magnitude, governs correction benefit. The proposed framework provides quantitative guidance for selective correction, enabling efficient deployment and reliable diagnostic AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01953v2</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takaaki Tachibana, Toru Nagasaka, Yukari Adachi, Hiroki Kagiyama, Ryota Ito, Mitsugu Fujita, Kimihiro Yamashita, Yoshihiro Kakeji</dc:creator>
    </item>
    <item>
      <title>Individualizing Glioma Radiotherapy Planning by Optimization of Data and Physics-Informed Discrete Loss</title>
      <link>https://arxiv.org/abs/2312.05063</link>
      <description>arXiv:2312.05063v4 Announce Type: replace-cross 
Abstract: Brain tumor growth is unique to each glioma patient and extends beyond what is visible in imaging scans, infiltrating surrounding brain tissue. Understanding these hidden patient-specific progressions is essential for effective therapies. Current treatment plans for brain tumors, such as radiotherapy, typically involve delineating a uniform margin around the visible tumor on pre-treatment scans to target this invisible tumor growth. This "one size fits all" approach is derived from population studies and often fails to account for the nuances of individual patient conditions. We present the GliODIL framework, which infers the full spatial distribution of tumor cell concentration from available multi-modal imaging, leveraging a Fisher-Kolmogorov type physics model to describe tumor growth. This is achieved through the newly introduced method of Optimizing the Discrete Loss, where both data and physics-based constraints are softly assimilated into the solution. Our test dataset comprises 152 glioblastoma patients with pre-treatment imaging and post-treatment follow-ups for tumor recurrence monitoring. By blending data-driven techniques with physics-based constraints, GliODIL enhances recurrence prediction in radiotherapy planning, challenging traditional uniform margins and strict adherence to the Fisher-Kolmogorov partial differential equation model, which is adapted for complex cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05063v4</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michal Balcerak, Jonas Weidner, Petr Karnakov, Ivan Ezhov, Sergey Litvinov, Petros Koumoutsakos, Tamaz Amiranashvili, Ray Zirui Zhang, John S. Lowengrub, Bene Wiestler, Bjoern Menze</dc:creator>
    </item>
    <item>
      <title>Optical turbulence retrieval of heterogeneous media</title>
      <link>https://arxiv.org/abs/2506.13204</link>
      <description>arXiv:2506.13204v2 Announce Type: replace-cross 
Abstract: The transport of intensity equation (TIE) has revolutionized phase retrieval in optical microscopy, yet its application to complex media with absorption/scattering remains challenging. Here, we present a coupled TIE-TPE (transport of phase equation) framework derived directly from the paraxial wave equation with complex optical potential. By decomposing the refractive index field into a spatially uniform mean field and local fluctuation field, our approach enables simultaneous reconstruction of refractive-index fluctuations and attenuation coefficients without linearization assumptions. We establish reconstruction validity bounds that define the measurable parameter region where reconstruction remains physically consistent. Experimental demonstration with microlens arrays and HeLa cells shows robust recovery of optical properties even in the transparent-limit regime where attenuation signals approach detection thresholds. Furthermore, we provide the first experimental verification of attenuation symmetry -- a fundamental property of wave propagation that characterizes reciprocity in light-matter interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13204v2</guid>
      <category>physics.optics</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masaki Watabe, Joe Sakamoto, Hideaki Yoshimura, Tomomi Nemoto, Kazunari Kaizu</dc:creator>
    </item>
    <item>
      <title>Learning noisy tissue dynamics across time scales</title>
      <link>https://arxiv.org/abs/2510.19090</link>
      <description>arXiv:2510.19090v2 Announce Type: replace-cross 
Abstract: Tissue dynamics play a crucial role in biological processes ranging from inflammation to morphogenesis. However, these noisy multicellular dynamics are notoriously hard to predict. Here, we introduce a biomimetic machine learning framework capable of inferring noisy multicellular dynamics directly from experimental movies. This generative model combines graph neural networks, normalizing flows and WaveNet algorithms to represent tissues as neural stochastic differential equations where cells are edges of an evolving graph. Cell interactions are encoded in a dual signaling graph capable of handling signaling cascades. The dual graph architecture of our neural networks reflects the architecture of the underlying biological tissues, substantially reducing the amount of data needed for training, compared to convolutional or fully-connected neural networks. Taking epithelial tissue experiments as a case study, we show that our model not only captures stochastic cell motion but also predicts the evolution of cell states in their division cycle. Finally, we demonstrate that our method can accurately generate the experimental dynamics of developmental systems, such as the fly wing, and cell signaling processes mediated by stochastic ERK waves, paving the way for its use as a digital twin in bioengineering and clinical contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19090v2</guid>
      <category>cond-mat.soft</category>
      <category>cs.LG</category>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Han, John Devany, Michel Fruchart, Margaret L. Gardel, Vincenzo Vitelli</dc:creator>
    </item>
  </channel>
</rss>
