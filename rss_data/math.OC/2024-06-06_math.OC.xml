<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Jun 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quantum-Inspired Mean Field Probabilistic Model for Combinatorial Optimization Problems</title>
      <link>https://arxiv.org/abs/2406.03502</link>
      <description>arXiv:2406.03502v1 Announce Type: new 
Abstract: Combinatorial optimization problems are pivotal across many fields. Among these, Quadratic Unconstrained Binary Optimization (QUBO) problems, central to fields like portfolio optimization, network design, and computational biology, are NP-hard and require exponential computational resources. To address these challenges, we develop a novel Quantum-Inspired Mean Field (QIMF) probabilistic model that approximates solutions to QUBO problems with enhanced accuracy and efficiency. The QIMF model draws inspiration from quantum measurement principles and leverages the mean field probabilistic model. We incorporate a measurement grouping technique and an amplitude-based shot allocation strategy, both critical for optimizing cost functions with a polynomial speedup over traditional methods. Our extensive empirical studies demonstrate significant improvements in solution evaluation for large-scale problems of portfolio selection, the weighted maxcut problem, and the Ising model. Specifically, using S&amp;P 500 data from 2022 and 2023, QIMF improves cost values by 152.8% and 12.5%, respectively, compared to the state-of-the-art baselines. Furthermore, when evaluated on increasingly larger datasets for QUBO problems, QIMF's scalability demonstrates its potential for large-scale QUBO challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03502v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Huang, Siyuan Jin, Yichi Zhang, Ling Pan, Qiming Shao</dc:creator>
    </item>
    <item>
      <title>A New Branch-and-Bound Pruning Framework for $\ell_0$-Regularized Problems</title>
      <link>https://arxiv.org/abs/2406.03504</link>
      <description>arXiv:2406.03504v1 Announce Type: new 
Abstract: We consider the resolution of learning problems involving $\ell_0$-regularization via Branch-and-Bound (BnB) algorithms. These methods explore regions of the feasible space of the problem and check whether they do not contain solutions through "pruning tests". In standard implementations, evaluating a pruning test requires to solve a convex optimization problem, which may result in computational bottlenecks. In this paper, we present an alternative to implement pruning tests for some generic family of $\ell_0$-regularized problems. Our proposed procedure allows the simultaneous assessment of several regions and can be embedded in standard BnB implementations with a negligible computational overhead. We show through numerical simulations that our pruning strategy can improve the solving time of BnB procedures by several orders of magnitude for typical problems encountered in machine-learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03504v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theo Guyard, C\'edric Herzet, Cl\'ement Elvira, Ay\c{s}e-Nur Arslan</dc:creator>
    </item>
    <item>
      <title>Learning in Spatial Branching: Limitations of Strong Branching Imitation</title>
      <link>https://arxiv.org/abs/2406.03626</link>
      <description>arXiv:2406.03626v1 Announce Type: new 
Abstract: Over the last few years, there has been a surge in the use of learning techniques to improve the performance of optimization algorithms. In particular, the learning of branching rules in mixed integer linear programming has received a lot of attention, with most methodologies based on strong branching imitation. Recently, some advances have been made as well in the context of nonlinear programming, with some methodologies focusing on learning to select the best branching rule among a predefined set of rules leading to promising results. In this paper we explore, in the nonlinear setting, the limits on the improvements that might be achieved by the above two approaches: learning to select the best variable (strong branching) and learning to select the best rule (rule selection).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03626v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brais Gonz\'alez-Rodr\'iguez, Ignacio G\'omez-Casares, Bissan Ghaddar, Julio Gonz\'alez-D\'iaz, Beatriz Pateiro-L\'opez</dc:creator>
    </item>
    <item>
      <title>Collision Avoidance Maneuvers Optimization in the Presence of Multiple Encounters</title>
      <link>https://arxiv.org/abs/2406.03654</link>
      <description>arXiv:2406.03654v1 Announce Type: new 
Abstract: The optimization of fuel-optimal low-thrust collision avoidance maneuvers (CAMs) in scenarios involving multiple encounters between spacecraft is addressed. The optimization's objective is the minimization of the total fuel consumption while respecting constraints on the total probability of collision. The solution methodology combines sequential convex programming, second-order cone programming, and differential algebra to approximate the non-convex optimal control problem progressively. A Gaussian mixture model method is used to propagate the initial covariance matrix of the secondary spacecraft, allowing us to split it into multiple mixands that can be treated as different objects. This leads to an accurate propagation of the uncertainties. No theoretical guarantee is given for the convergence of the method to the global optimum of the original optimal control problem. Nonetheless, good performance is demonstrated through case studies involving multiple short- and long-term encounters, showcasing the generation of fuel-efficient CAMs while respecting operational constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03654v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeno Pavanello, Laura Pirovano, Roberto Armellin, Andrea De Vittori, Pierluigi Di Lizia</dc:creator>
    </item>
    <item>
      <title>AMPIC: Adaptive Model Predictive Ising Controller for large-scale urban traffic signals</title>
      <link>https://arxiv.org/abs/2406.03690</link>
      <description>arXiv:2406.03690v1 Announce Type: new 
Abstract: Realizing smooth traffic flow is important for achieving carbon neutrality. Adaptive traffic signal control, which considers traffic conditions, has thus attracted attention. However, it is difficult to ensure optimal vehicle flow throughout a large city using existing control methods because of their heavy computational load. Here, we propose a control method called AMPIC (Adaptive Model Predictive Ising Controller) that guarantees both scalability and optimality. The proposed method employs model predictive control to solve an optimal control problem at each control interval with explicit consideration of a predictive model of vehicle flow. This optimal control problem is transformed into a combinatorial optimization problem with binary variables that is equivalent to the so-called Ising problem. This transformation allows us to use an Ising solver, which has been widely studied and is expected to have fast and efficient optimization performance. We performed numerical experiments using a microscopic traffic simulator for a realistic city road network. The results show that AMPIC enables faster vehicle cruising speed with less waiting time than that achieved by classical control methods, resulting in lower CO2 emissions. The model predictive approach with a long prediction horizon thus effectively improves control performance. Systematic parametric studies on model cities indicate that the proposed method realizes smoother traffic flows for large city road networks. Among Ising solvers, D-Wave's quantum annealing is shown to find near-optimal solutions at a reasonable computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03690v1</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daisuke Inoue, Hiroshi Yamashita, Kazuyuki Aihara, Hiroaki Yoshida</dc:creator>
    </item>
    <item>
      <title>Self-dual polyhedra and polarity</title>
      <link>https://arxiv.org/abs/2406.03698</link>
      <description>arXiv:2406.03698v1 Announce Type: new 
Abstract: Every polyhedron can be described by an H-representation H(P) consisting of half spaces or equivalently by a V-representation V(P) as the convex hull of a set of vertices and extreme rays. By a suitable encoding we can define a polyhedron Q by setting H(Q)=V(P). We call P self-dual if V(Q) is isomorphic to H(P). It is well known and often stated that polytopes that contain the origin in their interior and pointed polyhedral cones are self-dual. It seems to be less well known that, more generally, a polyhedron is self-dual if and only if it contains the origin. We show this by using Minkowski's bipolar equation and discuss its application to the H/V conversion problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03698v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Avis</dc:creator>
    </item>
    <item>
      <title>Mean-variance portfolio selection in jump-diffusion model under no-shorting constraint: A viscosity solution approach</title>
      <link>https://arxiv.org/abs/2406.03709</link>
      <description>arXiv:2406.03709v1 Announce Type: new 
Abstract: This paper concerns a continuous time mean-variance (MV) portfolio selection problem in a jump-diffusion financial model with no-shorting trading constraint. The problem is reduced to two subproblems: solving a stochastic linear-quadratic (LQ) control problem under control constraint, and finding a maximal point of a real function. Based on a two-dimensional fully coupled ordinary differential equation (ODE), we construct an explicit viscosity solution to the Hamilton-Jacobi-Bellman equation of the constrained LQ problem. Together with the Meyer-It\^o formula and a verification procedure, we obtain the optimal feedback controls of the constrained LQ problem and the original MV problem, which corrects the flawed results in some existing literatures. In addition, closed-form efficient portfolio and efficient frontier are derived. In the end, we present several examples where the two-dimensional ODE is decoupled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03709v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaomin Shi, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Methods for the Cost-Constrained LQR: Strong Duality and Global Convergence</title>
      <link>https://arxiv.org/abs/2406.03734</link>
      <description>arXiv:2406.03734v1 Announce Type: new 
Abstract: In safety-critical applications, reinforcement learning (RL) needs to consider safety constraints. However, theoretical understandings of constrained RL for continuous control are largely absent. As a case study, this paper presents a cost-constrained LQR formulation, where a number of LQR costs with user-defined penalty matrices are subject to constraints. To solve it, we propose a policy gradient primal-dual method to find an optimal state feedback gain. Despite the non-convexity of the cost-constrained LQR problem, we provide a constructive proof for strong duality and a geometric interpretation of an optimal multiplier set. By proving that the concave dual function is Lipschitz smooth, we further provide convergence guarantees for the PG primal-dual method. Finally, we perform simulations to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03734v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Keyou You</dc:creator>
    </item>
    <item>
      <title>Projection-Free Variance Reduction Methods for Stochastic Constrained Multi-Level Compositional Optimization</title>
      <link>https://arxiv.org/abs/2406.03787</link>
      <description>arXiv:2406.03787v1 Announce Type: new 
Abstract: This paper investigates projection-free algorithms for stochastic constrained multi-level optimization. In this context, the objective function is a nested composition of several smooth functions, and the decision set is closed and convex. Existing projection-free algorithms for solving this problem suffer from two limitations: 1) they solely focus on the gradient mapping criterion and fail to match the optimal sample complexities in unconstrained settings; 2) their analysis is exclusively applicable to non-convex functions, without considering convex and strongly convex objectives. To address these issues, we introduce novel projection-free variance reduction algorithms and analyze their complexities under different criteria. For gradient mapping, our complexities improve existing results and match the optimal rates for unconstrained problems. For the widely-used Frank-Wolfe gap criterion, we provide theoretical guarantees that align with those for single-level problems. Additionally, by using a stage-wise adaptation, we further obtain complexities for convex and strongly convex functions. Finally, numerical experiments on different tasks demonstrate the effectiveness of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03787v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Sifan Yang, Wenhao Yang, Yibo Wang, Yuanyu Wan, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Recognizing weighted means in geodesic spaces</title>
      <link>https://arxiv.org/abs/2406.03913</link>
      <description>arXiv:2406.03913v1 Announce Type: new 
Abstract: Geodesic metric spaces support a variety of averaging constructions for given finite sets. Computing such averages has generated extensive interest in diverse disciplines. Here we consider the inverse problem of recognizing computationally whether or not a given point is such an average, exactly or approximately. In nonpositively curved spaces, several averaging notions, including the usual weighted barycenter, produce the same "mean set". In such spaces, at points where the tangent cone is a Euclidean space, the recognition problem reduces to Euclidean projection onto a polytope. Hadamard manifolds comprise one example. Another consists of CAT(0) cubical complexes, at relative-interior points: the recognition problem is harder for general points, but we present an efficient semidefinite-programming-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03913v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Goodwin, Adrian S. Lewis, Genaro Lopez-Acedo, Adriana Nicolae</dc:creator>
    </item>
    <item>
      <title>Model order reduction for discrete time-delay systems with inhomogeneous initial conditions</title>
      <link>https://arxiv.org/abs/2406.03967</link>
      <description>arXiv:2406.03967v1 Announce Type: new 
Abstract: We propose two kinds of model order reduction methods for discrete time-delay systems with inhomogeneous initial conditions. The peculiar properties of discrete Walsh functions are directly utilized to compute the Walsh coefficients of the systems, and the projection matrix is defined properly to generate reduced models by taking into account the non-zero initial conditions. It is shown that reduced models can preserve some Walsh coefficients of the expansion of the original systems. Further, the superposition principle is exploited to achieve a decomposition of the original systems, and a new definition of Gramians is proposed by combining the individual Gramians of each subsystem. As a result, the balanced truncation method is applied to systems with inhomogeneous initial conditions. We also provide a low-rank approximation to Gramians based on the discrete Laguerre polynomials, which enables an efficient execution of our approach. Numerical examples confirm the feasibility and effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03967v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolong Wang, Kejia Xu</dc:creator>
    </item>
    <item>
      <title>Benign Nonconvex Landscapes in Optimal and Robust Control, Part II: Extended Convex Lifting</title>
      <link>https://arxiv.org/abs/2406.04001</link>
      <description>arXiv:2406.04001v1 Announce Type: new 
Abstract: Many optimal and robust control problems are nonconvex and potentially nonsmooth in their policy optimization forms. In Part II of this paper, we introduce a new and unified Extended Convex Lifting (ECL) framework to reveal hidden convexity in classical optimal and robust control problems from a modern optimization perspective. Our ECL offers a bridge between nonconvex policy optimization and convex reformulations, enabling convex analysis for nonconvex problems. Despite non-convexity and non-smoothness, the existence of an ECL not only reveals that minimizing the original function is equivalent to a convex problem but also certifies a class of first-order non-degenerate stationary points to be globally optimal. Therefore, no spurious stationarity exists in the set of non-degenerate policies. This ECL framework can cover many benchmark control problems, including state feedback linear quadratic regulator (LQR), dynamic output feedback linear quadratic Gaussian (LQG) control, and $\mathcal{H}_\infty$ robust control. ECL can also handle a class of distributed control problems when the notion of quadratic invariance (QI) holds. We further show that all static stabilizing policies are non-degenerate for state feedback LQR and $\mathcal{H}_\infty$ control under standard assumptions. We believe that the new ECL framework may be of independent interest for analyzing nonconvex problems beyond control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04001v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Zheng, Chih-Fan Pai, Yujie Tang</dc:creator>
    </item>
    <item>
      <title>Stochastic Polyak Step-sizes and Momentum: Convergence Guarantees and Practical Performance</title>
      <link>https://arxiv.org/abs/2406.04142</link>
      <description>arXiv:2406.04142v1 Announce Type: new 
Abstract: Stochastic gradient descent with momentum, also known as Stochastic Heavy Ball method (SHB), is one of the most popular algorithms for solving large-scale stochastic optimization problems in various machine learning tasks. In practical scenarios, tuning the step-size and momentum parameters of the method is a prohibitively expensive and time-consuming process. In this work, inspired by the recent advantages of stochastic Polyak step-size in the performance of stochastic gradient descent (SGD), we propose and explore new Polyak-type variants suitable for the update rule of the SHB method. In particular, using the Iterate Moving Average (IMA) viewpoint of SHB, we propose and analyze three novel step-size selections: MomSPS$_{\max}$, MomDecSPS, and MomAdaSPS. For MomSPS$_{\max}$, we provide convergence guarantees for SHB to a neighborhood of the solution for convex and smooth problems (without assuming interpolation). If interpolation is also satisfied, then using MomSPS$_{\max}$, SHB converges to the true solution at a fast rate matching the deterministic HB. The other two variants, MomDecSPS and MomAdaSPS, are the first adaptive step-sizes for SHB that guarantee convergence to the exact minimizer without prior knowledge of the problem parameters and without assuming interpolation. The convergence analysis of SHB is tight and obtains the convergence guarantees of SGD with stochastic Polyak step-sizes as a special case. We supplement our analysis with experiments that validate the theory and demonstrate the effectiveness and robustness of the new algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04142v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Oikonomou, Nicolas Loizou</dc:creator>
    </item>
    <item>
      <title>Essentially Sharp Estimates on the Entropy Regularization Error in Discrete Discounted Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04163</link>
      <description>arXiv:2406.04163v1 Announce Type: new 
Abstract: We study the error introduced by entropy regularization of infinite-horizon discrete discounted Markov decision processes. We show that this error decreases exponentially in the inverse regularization strength both in a weighted KL-divergence and in value with a problem-specific exponent. We provide a lower bound matching our upper bound up to a polynomial factor. Our proof relies on the correspondence of the solutions of entropy-regularized Markov decision processes with gradient flows of the unregularized reward with respect to a Riemannian metric common in natural policy gradient methods. Further, this correspondence allows us to identify the limit of the gradient flow as the generalized maximum entropy optimal policy, thereby characterizing the implicit bias of the Kakade gradient flow which corresponds to a time-continuous version of the natural policy gradient method. We use this to show that for entropy-regularized natural policy gradient methods the overall error decays exponentially in the square root of the number of iterations improving existing sublinear guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04163v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes M\"uller, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Numerical Optimization Study of a Constrained Hypersonic Reentry Vehicle</title>
      <link>https://arxiv.org/abs/2406.04185</link>
      <description>arXiv:2406.04185v1 Announce Type: new 
Abstract: The trajectory optimization of the atmospheric entry of a reusable launch vehicle is studied. The objective is to maximize the crossrange of the vehicle subject to two control-inequality path constraints, two state-inequality path constraints, and one mixed state-and-control inequality path constraint. In order to determine the complex switching structure in the activity of the path constraints, a recently developed method for solving state-path constrained optimal control problems is used. This recently developed method is designed to algorithmically locate the points of activation and deactivation in the path constraints and partition the domain of the independent variable into subdomains based on these activation and deactivation points. Additionally, in a domain where a state-inequality path constraint is found to be active, the method algorithmically determines and enforces the additional necessary conditions that apply on the constrained arc. A multiple-domain formulation of Legendre-Gauss-Radau direct collocation is then employed to transcribe the optimal control problem into a large sparse nonlinear programming problem. Two studies are performed which analyze a variety of problem formulations of the hypersonic reusable launch vehicle. Key features of the constrained trajectories are presented, and the method used is shown to obtain highly accurate solutions with minimal user intervention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04185v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cale A. Byczkowski, Anil V. Rao</dc:creator>
    </item>
    <item>
      <title>Why Study the Spherical Convexity of Non-Homogeneous Quadratic Functions, and What Makes It Surprising?</title>
      <link>https://arxiv.org/abs/2406.04205</link>
      <description>arXiv:2406.04205v1 Announce Type: new 
Abstract: This paper presents necessary, sufficient, and equivalent conditions for the spherical convexity of non-homogeneous quadratic functions. In addition to motivating this study and identifying useful criteria for determining whether such functions are spherically convex, we discovered surprising properties that distinguish spherically convex quadratic functions from their geodesically convex counterparts in both hyperbolic and Euclidean spaces. Since spherically convex functions over the entire sphere are constant, we restricted our focus to proper spherically convex subsets of the sphere. Although most of our results pertain to non-homogeneous quadratic functions on the spherically convex set of unit vectors with positive coordinates, we also present findings for more general spherically convex sets. Beyond the general non-homogeneous quadratic functions, we consider explicit special cases where the matrix in the function's definition is of a specific type, such as positive, diagonal, and Z-matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04205v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Bolton, S. Z. N\'emeth</dc:creator>
    </item>
    <item>
      <title>Policy Optimization in Control: Geometry and Algorithmic Implications</title>
      <link>https://arxiv.org/abs/2406.04243</link>
      <description>arXiv:2406.04243v1 Announce Type: new 
Abstract: This survey explores the geometric perspective on policy optimization within the realm of feedback control systems, emphasizing the intrinsic relationship between control design and optimization. By adopting a geometric viewpoint, we aim to provide a nuanced understanding of how various ``complete parameterization'' -- referring to the policy parameters together with its Riemannian geometry -- of control design problems, influence stability and performance of local search algorithms. The paper is structured to address key themes such as policy parameterization, the topology and geometry of stabilizing policies, and their implications for various (non-convex) dynamic performance measures. We focus on a few iconic control design problems, including the Linear Quadratic Regulator (LQR), Linear Quadratic Gaussian (LQG) control, and $\mathcal{H}_\infty$ control. In particular, we first discuss the topology and Riemannian geometry of stabilizing policies, distinguishing between their static and dynamic realizations. Expanding on this geometric perspective, we then explore structural properties of the aforementioned performance measures and their interplay with the geometry of stabilizing policies in presence of policy constraints; along the way, we address issues such as spurious stationary points, symmetries of dynamic feedback policies, and (non-)smoothness of the corresponding performance measures. We conclude the survey with algorithmic implications of policy optimization in feedback design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04243v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shahriar Talebi, Yang Zheng, Spencer Kraisler, Na Li, Mehran Mesbahi</dc:creator>
    </item>
    <item>
      <title>A Simple Learning-Augmented Algorithm for Online Packing with Concave Objectives</title>
      <link>https://arxiv.org/abs/2406.03574</link>
      <description>arXiv:2406.03574v1 Announce Type: cross 
Abstract: Learning-augmented algorithms has been extensively studied recently in the computer-science community, due to the potential of using machine learning predictions in order to improve the performance of algorithms. Predictions are especially useful for online algorithms making irrevocable decisions without knowledge of the future. Such learning-augmented algorithms aim to overcome the limitations of classical online algorithms when the predictions are accurate, and still perform comparably when the predictions are inaccurate.
  A common approach is to adapt existing online algorithms to the particular advice notion employed, which often involves understanding previous sophisticated algorithms and their analyses. However, ideally, one would simply use previous online solutions in a black-box fashion, without much loss in the approximation guarantees. Such clean solutions that avoid opening up black-boxes are often rare, and may be even missed the first time around. For example, Grigorescu et al. (NeurIPS 22) proposed a learning-augmented algorithms for online covering linear programs, but it later turned out that their results can be subsumed by a natural approach that switches between the advice and an online algorithm given as a black-box, as noted in their paper.
  In this work, we introduce and analyze a simple learning-augmented algorithm for online packing problems with linear constraints and concave objectives. We exhibit several direct applications of our framework including online packing linear programming, knapsack, resource management benefit, throughput maximization, and network utility maximization. We further raise the problem of understanding necessary and sufficient conditions for when such simple black-box solutions may be optimal. We believe this is an important direction of research that would unify many ad-hoc approaches from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03574v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Grigorescu, Young-San Lin, Maoyuan Song</dc:creator>
    </item>
    <item>
      <title>Private Online Learning via Lazy Algorithms</title>
      <link>https://arxiv.org/abs/2406.03620</link>
      <description>arXiv:2406.03620v1 Announce Type: cross 
Abstract: We study the problem of private online learning, specifically, online prediction from experts (OPE) and online convex optimization (OCO). We propose a new transformation that transforms lazy online learning algorithms into private algorithms. We apply our transformation for differentially private OPE and OCO using existing lazy algorithms for these problems. Our final algorithms obtain regret, which significantly improves the regret in the high privacy regime $\varepsilon \ll 1$, obtaining $\sqrt{T \log d} + T^{1/3} \log(d)/\varepsilon^{2/3}$ for DP-OPE and $\sqrt{T} + T^{1/3} \sqrt{d}/\varepsilon^{2/3}$ for DP-OCO. We also complement our results with a lower bound for DP-OPE, showing that these rates are optimal for a natural family of low-switching private algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03620v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Asi, Tomer Koren, Daogao Liu, Kunal Talwar</dc:creator>
    </item>
    <item>
      <title>On Exponential Convergence of Random Variables</title>
      <link>https://arxiv.org/abs/2406.03644</link>
      <description>arXiv:2406.03644v1 Announce Type: cross 
Abstract: Given the discrete time sequence of nonnegative random variables, general dependencies between the exponential convergence of the expectations, exponential convergence of the trajectories and the convergence of the corresponding expected hitting times are analysed . The applications are presented: the general results are applied to the areas of optimization, control and estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03644v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawid Tar{\l}owski</dc:creator>
    </item>
    <item>
      <title>Discrete error dynamics of mini-batch gradient descent for least squares regression</title>
      <link>https://arxiv.org/abs/2406.03696</link>
      <description>arXiv:2406.03696v1 Announce Type: cross 
Abstract: We study the discrete dynamics of mini-batch gradient descent for least squares regression when sampling without replacement. We show that the dynamics and generalization error of mini-batch gradient descent depends on a sample cross-covariance matrix $Z$ between the original features $X$ and a set of new features $\widetilde{X}$, in which each feature is modified by the mini-batches that appear before it during the learning process in an averaged way. Using this representation, we rigorously establish that the dynamics of mini-batch and full-batch gradient descent agree up to leading order with respect to the step size using the linear scaling rule. We also study discretization effects that a continuous-time gradient flow analysis cannot detect, and show that mini-batch gradient descent converges to a step-size dependent solution, in contrast with full-batch gradient descent. Finally, we investigate the effects of batching, assuming a random matrix model, by using tools from free probability theory to numerically compute the spectrum of $Z$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03696v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackie Lok, Rishi Sonthalia, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Maximum Likelihood Identification of Uncontrollable Linear Time-Invariant Models for Offset-Free Control</title>
      <link>https://arxiv.org/abs/2406.03760</link>
      <description>arXiv:2406.03760v1 Announce Type: cross 
Abstract: Maximum likelihood identification of linear time-invariant models is a difficult problem because it is, in general, a nonlinear semidefinite program, with semidefinite covariance matrix arguments and semidefinite filter stability constraints. To enforce filter stability, we establish a general theory of closed constraints on the system eigenvalues using LMI regions. To solve the identification problem, we employ a Cholesky factorization method that reduces the semidefinite program to a standard nonlinear program. Finally, we apply the identification algorithm to a class of linear plant and disturbance models commonly used in offset-free model predictive control applications. Specifically, we consider models that are structured with uncontrollable, integrating disturbance states. We solve this disturbance modeling problem, and validate the resulting controller and estimator performance, in two real-world case studies: first, a low-cost benchmark temperature control laboratory, and second, an industrial-scale chemical reactor at Eastman Chemical's Kingsport plant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03760v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven J. Kuntz, James B. Rawlings</dc:creator>
    </item>
    <item>
      <title>Positive definiteness of fourth order three dimensional symmetric tensors</title>
      <link>https://arxiv.org/abs/2406.04010</link>
      <description>arXiv:2406.04010v1 Announce Type: cross 
Abstract: For a 4th order 3-dimensional symmetric tensor with its entries $1$ or $-1$, we show the analytic sufficient and necessary conditions of its positive definiteness. By applying these conclusions, several strict inequalities is bulit for ternary quartic homogeneous polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04010v1</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Bisimulation Metrics are Optimal Transport Distances, and Can be Computed Efficiently</title>
      <link>https://arxiv.org/abs/2406.04056</link>
      <description>arXiv:2406.04056v1 Announce Type: cross 
Abstract: We propose a new framework for formulating optimal transport distances between Markov chains. Previously known formulations studied couplings between the entire joint distribution induced by the chains, and derived solutions via a reduction to dynamic programming (DP) in an appropriately defined Markov decision process. This formulation has, however, not led to particularly efficient algorithms so far, since computing the associated DP operators requires fully solving a static optimal transport problem, and these operators need to be applied numerous times during the overall optimization process. In this work, we develop an alternative perspective by considering couplings between a flattened version of the joint distributions that we call discounted occupancy couplings, and show that calculating optimal transport distances in the full space of joint distributions can be equivalently formulated as solving a linear program (LP) in this reduced space. This LP formulation allows us to port several algorithmic ideas from other areas of optimal transport theory. In particular, our formulation makes it possible to introduce an appropriate notion of entropy regularization into the optimization problem, which in turn enables us to directly calculate optimal transport distances via a Sinkhorn-like method we call Sinkhorn Value Iteration (SVI). We show both theoretically and empirically that this method converges quickly to an optimal coupling, essentially at the same computational cost of running vanilla Sinkhorn in each pair of states. Along the way, we point out that our optimal transport distance exactly matches the common notion of bisimulation metrics between Markov chains, and thus our results also apply to computing such metrics, and in fact our algorithm turns out to be significantly more efficient than the best known methods developed so far for this purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04056v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio Calo, Anders Jonsson, Gergely Neu, Ludovic Schwartz, Javier Segovia</dc:creator>
    </item>
    <item>
      <title>Symplectic Methods in Deep Learning</title>
      <link>https://arxiv.org/abs/2406.04104</link>
      <description>arXiv:2406.04104v1 Announce Type: cross 
Abstract: Deep learning is widely used in tasks including image recognition and generation, in learning dynamical systems from data and many more. It is important to construct learning architectures with theoretical guarantees to permit safety in the applications. There has been considerable progress in this direction lately. In particular, symplectic networks were shown to have the non vanishing gradient property, essential for numerical stability. On the other hand, architectures based on higher order numerical methods were shown to be efficient in many tasks where the learned function has an underlying dynamical structure. In this work we construct symplectic networks based on higher order explicit methods with non vanishing gradient property and test their efficiency on various examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04104v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sofya Maslovskaya, Sina Ober-Bl\"obaum</dc:creator>
    </item>
    <item>
      <title>An overview of systems-theoretic guarantees in data-driven model predictive control</title>
      <link>https://arxiv.org/abs/2406.04130</link>
      <description>arXiv:2406.04130v1 Announce Type: cross 
Abstract: The development of control methods based on data has seen a surge of interest in recent years. When applying data-driven controllers in real-world applications, providing theoretical guarantees for the closed-loop system is of crucial importance to ensure reliable operation. In this review, we provide an overview of data-driven model predictive control (MPC) methods for controlling unknown systems with guarantees on systems-theoretic properties such as stability, robustness, and constraint satisfaction. The considered approaches rely on the Fundamental Lemma from behavioral theory in order to predict input-output trajectories directly from data. We cover various setups, ranging from linear systems and noise-free data to more realistic formulations with noise and nonlinearities, and we provide an overview of different techniques to ensure guarantees for the closed-loop system. Moreover, we discuss avenues for future research that may further improve the theoretical understanding and practical applicability of data-driven MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04130v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Berberich, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Towards Principled Superhuman AI for Multiplayer Symmetric Games</title>
      <link>https://arxiv.org/abs/2406.04201</link>
      <description>arXiv:2406.04201v1 Announce Type: cross 
Abstract: Multiplayer games, when the number of players exceeds two, present unique challenges that fundamentally distinguish them from the extensively studied two-player zero-sum games. These challenges arise from the non-uniqueness of equilibria and the risk of agents performing highly suboptimally when adopting equilibrium strategies. While a line of recent works developed learning systems successfully achieving human-level or even superhuman performance in popular multiplayer games such as Mahjong, Poker, and Diplomacy, two critical questions remain unaddressed: (1) What is the correct solution concept that AI agents should find? and (2) What is the general algorithmic framework that provably solves all games within this class? This paper takes the first step towards solving these unique challenges of multiplayer games by provably addressing both questions in multiplayer symmetric normal-form games. We also demonstrate that many meta-algorithms developed in prior practical systems for multiplayer games can fail to achieve even the basic goal of obtaining agent's equal share of the total reward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04201v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Ge, Yuanhao Wang, Wenzhe Li, Chi Jin</dc:creator>
    </item>
    <item>
      <title>Explicit Steady-State Approximations for Parallel Server Systems with Heterogeneous Servers</title>
      <link>https://arxiv.org/abs/2406.04203</link>
      <description>arXiv:2406.04203v1 Announce Type: cross 
Abstract: The weighted-workload-task-allocation (WWTA) load-balancing policy is known to be throughput optimal for parallel server systems with heterogeneous servers. This work concerns the heavy traffic approximation of steady-state performance for parallel server systems operating under WWTA policy. Under a relaxed complete-resource-pooling condition, we prove that WWTA achieves a "strong form" of state-space collapse in heavy traffic and that the scaled workload for each server converges in distribution to an exponential random variable, whose parameter is explicitly given by system primitives. Various steady-state performance measures are shown to be approximated from this exponential random variable. Instead of proving a stochastic process limit followed by an interchange of limits - a method that dominates the literature, our method works directly with a pre-limit basic adjoint relationship (BAR) that characterizes the stationary distribution of each pre-limit system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04203v1</guid>
      <category>math.PR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. G. Dai, Yaosheng Xu</dc:creator>
    </item>
    <item>
      <title>Linearized optimal transport on manifolds</title>
      <link>https://arxiv.org/abs/2303.13901</link>
      <description>arXiv:2303.13901v2 Announce Type: replace 
Abstract: Optimal transport is a geometrically intuitive, robust and flexible metric for sample comparison in data analysis and machine learning. Its formal Riemannian structure allows for a local linearization via a tangent space approximation. This in turn leads to a reduction of computational complexity and simplifies combination with other methods that require a linear structure. Recently this approach has been extended to the unbalanced Hellinger--Kantorovich (HK) distance. In this article we further extend the framework in various ways, including measures on manifolds, the spherical HK distance, a study of the consistency of discretization via the barycentric projection, and the continuity properties of the logarithmic map for the HK distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13901v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Sarrazin, Bernhard Schmitzer</dc:creator>
    </item>
    <item>
      <title>Platform Design in Curated Dating Markets</title>
      <link>https://arxiv.org/abs/2308.02584</link>
      <description>arXiv:2308.02584v4 Announce Type: replace 
Abstract: Motivated by online dating apps, we study how to select subset of profiles to show to each user in each period in a two-sided matching platform. Users on each side observe the profiles set by the platform and decide which of them to like. A match occurs if and only if two users mutually like each other, potentially in different periods. The goal of the platform is to maximize the total expected number of matches. We study different platform designs, varying (i) how users interact with each other, i.e., whether one or both sides of the market can initiate an interaction, and (ii) the timing of matches, i.e., whether the platform allows non-sequential matches in addition to sequential ones. We focus on the case with two periods and study the performance of different approaches. First, we show that algorithms that exploit the submodularity of the problem and properties of its feasible region can achieve constant factor approximation guarantees that depend on the platform design, ranging from $1-1/e$ to $1/3$. Finally, we show that the Dating Heuristic (DH) (Rios et al., 2023), which is commonly used and achieves good performance in practice, provides an approximation guarantee of $1-1/e$ for all platform designs. We show theoretically and empirically that the performance of the DH is robust to the platform design. Our simulation results -- using real data from our industry partner -- also show that platforms using a one-directional design should initiate interactions with the side that leads to the smallest expected backlog per profile displayed, balancing size and selectivity. Moreover, we find that a one-directional design can lead to at least half of the matches obtained with a two-directional design. Finally, our results show that avoiding non-sequential matches has no sizable effect, regardless of the platform design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02584v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ignacio Rios, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>A New Spectral Conjugate Subgradient Method with Application in Computed Tomography Image Reconstruction</title>
      <link>https://arxiv.org/abs/2309.15266</link>
      <description>arXiv:2309.15266v2 Announce Type: replace 
Abstract: A new spectral conjugate subgradient method is presented to solve nonsmooth unconstrained optimization problems. The method combines the spectral conjugate gradient method for smooth problems with the spectral subgradient method for nonsmooth problems. We study the effect of two different choices of line search, as well as three formulas for determining the conjugate directions. In addition to numerical experiments with standard nonsmooth test problems, we also apply the method to several image reconstruction problems in computed tomography, using total variation regularization. Performance profiles are used to compare the performance of the algorithm using different line search strategies and conjugate directions to that of the original spectral subgradient method. Our results show that the spectral conjugate subgradient algorithm outperforms the original spectral subgradient method, and that the use of the Polak-Ribiere formula for conjugate directions provides the best and most robust performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15266v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milagros Loreto, Thomas Humphries, Chella Raghavan, Kenneth Wu, Sam Kwak</dc:creator>
    </item>
    <item>
      <title>Vehicle Routing Problem for Urban and Grey Zones Considering Heterogeneous Fleets and Carpooling</title>
      <link>https://arxiv.org/abs/2312.00905</link>
      <description>arXiv:2312.00905v2 Announce Type: replace 
Abstract: The conveyance of employees holds paramount significance for expansive corporations. Employees typically commute to their workplaces either via personal vehicles or through public transit. In this research endeavor, our role is that of a third-party entity entrusted with orchestrating the transportation of employees whose place of employment is situated within the grey zone. This zone exclusively permits the ingress of electric/hybrid vehicles and buses. We advocate for employees to adopt carpooling and furnish bus services for those who abstain from it. The primary objective of this research is to curtail the quantity of vehicles leased by the third-party entity, promote carpooling among employees, amplify employee contentment, and mitigate environmental degradation stemming from vehicular gasoline consumption. To decipher the model delineated in this study, the epsilon constraint method is proffered for petite-scale instances, while NSGA-II is introduced as a potent meta-heuristic technique tailored for large-scale scenarios. Computational trials corroborate that the models posited can be efficaciously harnessed by enterprises to pare down transportation expenditures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00905v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Keshvarinia, S. M. J. Mirzapour Al-e-hashem, R. Shahin, A. Farsi, M. Kiaghadi</dc:creator>
    </item>
    <item>
      <title>Higher-order Riemannian splines and the interpolation problem: an approach of gradient flows</title>
      <link>https://arxiv.org/abs/2312.10513</link>
      <description>arXiv:2312.10513v4 Announce Type: replace 
Abstract: In this paper, we resolve problems of spline interpolation, regardless of whether least-squares fitting is incorporated, on smooth Riemannian manifolds. Our approach leverages the concept of gradient flows for successively connected curves or networks, offering a fresh perspective on addressing such challenges. Notably, this method extends to the problem of spline interpolation on Lie groups, commonly encountered in mechanical optimal control theory formulations, thus contributing to both geometric control theory and statistical shape data analysis. We rigorously establish the existence of global solutions in H\"{o}lder spaces for the gradient flow, with the asymptotic limits of these solutions confirming the existence to the problem of spline interpolation. This comprehensive solution underscores the constructive nature of our proof, hinting at potential numerical schemes for discovering solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10513v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chun-Chi Lin, Dung The Tran</dc:creator>
    </item>
    <item>
      <title>Relationships Between Necessary Conditions for Feedback Stabilizability</title>
      <link>https://arxiv.org/abs/2312.16752</link>
      <description>arXiv:2312.16752v2 Announce Type: replace 
Abstract: The author's extensions of Brockett's and Coron's necessary conditions for stabilizability are shown to be independent in the fiber bundle picture of control, but the latter is shown to be stronger in the vector bundle picture if the state space is orientable and the Cech-Euler characteristic of the set to be stabilized is nonzero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16752v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AT</category>
      <category>math.DG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew D. Kvalheim</dc:creator>
    </item>
    <item>
      <title>Extended Formulations for Binary Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2401.03942</link>
      <description>arXiv:2401.03942v3 Announce Type: replace 
Abstract: Extended formulations are an important tool in polyhedral combinatorics. Many combinatorial optimization problems require an exponential number of inequalities when modeled as a linear program in the natural space of variables. However, by adding artificial variables, one can often find a small linear formulation, i.e., one containing a polynomial number of variables and constraints, such that the projection to the original space of variables yields a perfect linear formulation. Motivated by binary optimal control problems with switching constraints, we show that a similar approach can be useful also for optimization problems in function space, in order to model the closed convex hull of feasible controls in a compact way. More specifically, we present small extended formulations for switches with bounded variation and for dwell-time constraints. For general linear switching point constraints, we devise an extended model linearizing the problem, but show that a small extended formulation that is compatible with discretization cannot exist unless P=NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03942v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Buchheim</dc:creator>
    </item>
    <item>
      <title>B-ary Tree Push-Pull Method is Provably Efficient for Distributed Learning on Heterogeneous Data</title>
      <link>https://arxiv.org/abs/2404.05454</link>
      <description>arXiv:2404.05454v2 Announce Type: replace 
Abstract: This paper considers the distributed learning problem where a group of agents cooperatively minimizes the summation of their local cost functions based on peer-to-peer communication. Particularly, we propose a highly efficient algorithm, termed ``B-ary Tree Push-Pull'' (BTPP), that employs two B-ary spanning trees for distributing the information related to the parameters and stochastic gradients across the network. The simple method is efficient in communication since each agent interacts with at most $(B+1)$ neighbors per iteration. More importantly, BTPP achieves linear speedup for smooth nonconvex objective functions with only $\tilde{O}(n)$ transient iterations, significantly outperforming the state-of-the-art results to the best of our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05454v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runze You, Shi Pu</dc:creator>
    </item>
    <item>
      <title>Learned Finite-Time Consensus for Distributed Optimization</title>
      <link>https://arxiv.org/abs/2404.07018</link>
      <description>arXiv:2404.07018v2 Announce Type: replace 
Abstract: Most algorithms for decentralized learning employ a consensus or diffusion mechanism to drive agents to a common solution of a global optimization problem. Generally this takes the form of linear averaging, at a rate of contraction determined by the mixing rate of the underlying network topology. For very sparse graphs this can yield a bottleneck, slowing down the convergence of the learning algorithm. We show that a sequence of matrices achieving finite-time consensus can be learned for unknown graph topologies in a decentralized manner by solving a constrained matrix factorization problem. We demonstrate numerically the benefit of the resulting scheme in both structured and unstructured graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07018v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Fainman, Stefan Vlaski</dc:creator>
    </item>
    <item>
      <title>MIP-DD: A Delta Debugger for Mixed Integer Programming Solvers</title>
      <link>https://arxiv.org/abs/2405.19770</link>
      <description>arXiv:2405.19770v3 Announce Type: replace 
Abstract: The recent performance improvements in mixed-integer programming (MIP) went along with a significantly increased complexity of the codes of MIP solvers, which poses challenges in fixing implementation errors. In this paper, we introduce MIP-DD, a solver-independent tool, which is, to the best of our knowledge, the first open-source delta debugger for MIP. Delta debugging is a hypothesis-trial-result approach to isolate the cause of a solver failure. MIP-DD simplifies MIP instances while maintaining the undesired behavior and already supported and motivated fixes for many bugs in the SCIP releases 8.0.4, 8.1.0, and 9.0.0. This translates to an increase of approximately 71.% more bugfixes than in the same time period before and including some fixes of long-known issues. As we highlight in selected case studies, instances triggering fundamental bugs in SCIP can typically be reduced to a few variables and constraints in less than an hour. This makes it significantly easier to manually trace and check the solution process on the resulting simplified instances. A promising future application of MIP-DD is the analysis of performance bottlenecks, which could very well benefit from simple adversarial instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19770v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Hoen, Dominik Kamp, Ambros Gleixner</dc:creator>
    </item>
    <item>
      <title>Entropy annealing for policy mirror descent in continuous time and space</title>
      <link>https://arxiv.org/abs/2405.20250</link>
      <description>arXiv:2405.20250v2 Announce Type: replace 
Abstract: Entropy regularization has been extensively used in policy optimization algorithms to regularize the optimization landscape and accelerate convergence; however, it comes at the cost of introducing an additional regularization bias. This work quantifies the impact of entropy regularization on the convergence of policy gradient methods for stochastic exit time control problems. We analyze a continuous-time policy mirror descent dynamics, which updates the policy based on the gradient of an entropy-regularized value function and adjusts the strength of entropy regularization as the algorithm progresses. We prove that with a fixed entropy level, the dynamics converges exponentially to the optimal solution of the regularized problem. We further show that when the entropy level decays at suitable polynomial rates, the annealed flow converges to the solution of the unregularized problem at a rate of $\mathcal O(1/S)$ for discrete action spaces and, under suitable conditions, at a rate of $\mathcal O(1/\sqrt{S})$ for general action spaces, with $S$ being the gradient flow time. This paper explains how entropy regularization improves policy optimization, even with the true gradient, from the perspective of convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20250v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deven Sethi, David \v{S}i\v{s}ka, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Optimisation of time-ordered processes in the finite and asymptotic regime</title>
      <link>https://arxiv.org/abs/2302.02918</link>
      <description>arXiv:2302.02918v2 Announce Type: replace-cross 
Abstract: Many problems in quantum information theory can be formulated as optimizations over the sequential outcomes of dynamical systems subject to unpredictable external influences. Such problems include many-body entanglement detection through adaptive measurements, computing the maximum average score of a preparation game over a continuous set of target states and limiting the behavior of a (quantum) finite-state automaton. In this work, we introduce tractable relaxations of this class of optimization problems. To illustrate their performance, we use them to: (a) compute the probability that a finite-state automaton outputs a given sequence of bits; (b) develop a new many-body entanglement detection protocol; (c) let the computer invent an adaptive protocol for magic state detection. As we further show, the maximum score of a sequential problem in the limit of infinitely many time steps is in general incomputable. Nonetheless, we provide general heuristics to bound this quantity and show that they provide useful estimates in relevant scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.02918v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PRXQuantum.5.020351</arxiv:DOI>
      <arxiv:journal_reference>PRX Quantum 5, 020351 (2024)</arxiv:journal_reference>
      <dc:creator>Mirjam Weilenmann, Costantino Budroni, Miguel Navascues</dc:creator>
    </item>
    <item>
      <title>Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning</title>
      <link>https://arxiv.org/abs/2306.04815</link>
      <description>arXiv:2306.04815v3 Announce Type: replace-cross 
Abstract: In this paper, we first present an explanation regarding the common occurrence of spikes in the training loss when neural networks are trained with stochastic gradient descent (SGD). We provide evidence that the spikes in the training loss of SGD are "catapults", an optimization phenomenon originally observed in GD with large learning rates in [Lewkowycz et al. 2020]. We empirically show that these catapults occur in a low-dimensional subspace spanned by the top eigenvectors of the tangent kernel, for both GD and SGD. Second, we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04815v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Libin Zhu, Chaoyue Liu, Adityanarayanan Radhakrishnan, Mikhail Belkin</dc:creator>
    </item>
    <item>
      <title>Langevin dynamics for the probability of Markov jumping processes</title>
      <link>https://arxiv.org/abs/2307.00678</link>
      <description>arXiv:2307.00678v3 Announce Type: replace-cross 
Abstract: We study gradient drift-diffusion processes on a probability simplex set with finite state Wasserstein metrics, namely the Wasserstein common noise. A fact is that the Kolmogorov transition equation of finite reversible Markov jump processes forms the gradient flow of entropy in finite state Wasserstein space. This paper proposes to perturb finite state Markov jump processes with Wasserstein common noises and formulate stochastic reversible Markov jumping processes. We also define a Wasserstein Q-matrix for this stochastic Markov jumping process. We then derive the functional Fokker-Planck equation in probability simplex, whose stationary distribution is a Gibbs distribution of entropy functional in a simplex set. Finally, we present several examples of Wasserstein drift-diffusion processes on a two-point state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00678v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuchen Li</dc:creator>
    </item>
    <item>
      <title>DPZero: Private Fine-Tuning of Language Models without Backpropagation</title>
      <link>https://arxiv.org/abs/2310.09639</link>
      <description>arXiv:2310.09639v3 Announce Type: replace-cross 
Abstract: The widespread practice of fine-tuning large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continues to grow, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize training data, it is important to protect potentially sensitive information in the fine-tuning data from being regurgitated. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differentially private gradient descent suffers more as model size grows. To bridge this gap, we introduce DPZero, a novel private zeroth-order algorithm with nearly dimension-independent rates. The memory efficiency of DPZero is demonstrated in privately fine-tuning RoBERTa and OPT on several downstream tasks. Our code is available at https://github.com/Liang137/DPZero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09639v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil, Sewoong Oh, Niao He</dc:creator>
    </item>
    <item>
      <title>Compressed and Sparse Models for Non-Convex Decentralized Learning</title>
      <link>https://arxiv.org/abs/2311.05760</link>
      <description>arXiv:2311.05760v2 Announce Type: replace-cross 
Abstract: Recent research highlights frequent model communication as a significant bottleneck to the efficiency of decentralized machine learning (ML), especially for large-scale and over-parameterized neural networks (NNs). To address this, we present Malcom-PSGD, a novel decentralized ML algorithm that combines gradient compression techniques with model sparsification. We promote model sparsity by adding $\ell_1$ regularization to the objective and present a decentralized proximal SGD method for training. Our approach employs vector source coding and dithering-based quantization for the compressed gradient communication of sparsified models. Our analysis demonstrates that Malcom-PSGD achieves a convergence rate of $\mathcal{O}(1/\sqrt{t})$ with respect to the iterations $t$, assuming a constant consensus and learning rate. This result is supported by our proof for the convergence of non-convex compressed Proximal SGD methods. Additionally, we conduct a bit analysis, providing a closed-form expression for the communication costs associated with Malcom-PSGD. Numerical results verify our theoretical findings and demonstrate that our method reduces communication costs by approximately $75\%$ when compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05760v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Campbell, Hang Liu, Leah Woldemariam, Anna Scaglione</dc:creator>
    </item>
    <item>
      <title>Convex Relaxations of ReLU Neural Networks Approximate Global Optima in Polynomial Time</title>
      <link>https://arxiv.org/abs/2402.03625</link>
      <description>arXiv:2402.03625v2 Announce Type: replace-cross 
Abstract: In this paper, we study the optimality gap between two-layer ReLU networks regularized with weight decay and their convex relaxations. We show that when the training data is random, the relative optimality gap between the original problem and its relaxation can be bounded by a factor of O(log n^0.5), where n is the number of training samples. A simple application leads to a tractable polynomial-time algorithm that is guaranteed to solve the original non-convex problem up to a logarithmic factor. Moreover, under mild assumptions, we show that local gradient methods converge to a point with low training loss with high probability. Our result is an exponential improvement compared to existing results and sheds new light on understanding why local gradient methods work well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03625v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sungyoon Kim, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Variational Learning is Effective for Large Deep Networks</title>
      <link>https://arxiv.org/abs/2402.17641</link>
      <description>arXiv:2402.17641v2 Announce Type: replace-cross 
Abstract: We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton (IVON) consistently matches or outperforms Adam for training large networks such as GPT-2 and ResNets from scratch. IVON's computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of IVON where we improve finetuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence that variational learning is effective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17641v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuesong Shen, Nico Daheim, Bai Cong, Peter Nickl, Gian Maria Marconi, Clement Bazan, Rio Yokota, Iryna Gurevych, Daniel Cremers, Mohammad Emtiyaz Khan, Thomas M\"ollenhoff</dc:creator>
    </item>
    <item>
      <title>Subhomogeneous Deep Equilibrium Models</title>
      <link>https://arxiv.org/abs/2403.00720</link>
      <description>arXiv:2403.00720v2 Announce Type: replace-cross 
Abstract: Implicit-depth neural networks have grown as powerful alternatives to traditional networks in various applications in recent years. However, these models often lack guarantees of existence and uniqueness, raising stability, performance, and reproducibility issues. In this paper, we present a new analysis of the existence and uniqueness of fixed points for implicit-depth neural networks based on the concept of subhomogeneous operators and the nonlinear Perron-Frobenius theory. Compared to previous similar analyses, our theory allows for weaker assumptions on the parameter matrices, thus yielding a more flexible framework for well-defined implicit networks. We illustrate the performance of the resulting subhomogeneous networks on feedforward, convolutional, and graph neural network examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00720v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pietro Sittoni, Francesco Tudisco</dc:creator>
    </item>
    <item>
      <title>On the Last-Iterate Convergence of Shuffling Gradient Methods</title>
      <link>https://arxiv.org/abs/2403.07723</link>
      <description>arXiv:2403.07723v3 Announce Type: replace-cross 
Abstract: Shuffling gradient methods are widely used in modern machine learning tasks and include three popular implementations: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understood for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove the first last-iterate convergence rates for shuffling gradient methods with respect to the objective value even without strong convexity. Our new results either (nearly) match the existing last-iterate lower bounds or are as fast as the previous best upper bounds for the average iterate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07723v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Parameter-Adaptive Approximate MPC: Tuning Neural-Network Controllers without Retraining</title>
      <link>https://arxiv.org/abs/2404.05835</link>
      <description>arXiv:2404.05835v2 Announce Type: replace-cross 
Abstract: Model Predictive Control (MPC) is a method to control nonlinear systems with guaranteed stability and constraint satisfaction but suffers from high computation times. Approximate MPC (AMPC) with neural networks (NNs) has emerged to address this limitation, enabling deployment on resource-constrained embedded systems. However, when tuning AMPCs for real-world systems, large datasets need to be regenerated and the NN needs to be retrained at every tuning step. This work introduces a novel, parameter-adaptive AMPC architecture capable of online tuning without recomputing large datasets and retraining. By incorporating local sensitivities of nonlinear programs, the proposed method not only mimics optimal MPC inputs but also adjusts to known changes in physical parameters of the model using linear predictions while still guaranteeing stability. We showcase the effectiveness of parameter-adaptive AMPC by controlling the swing-ups of two different real cartpole systems with a severely resource-constrained microcontroller (MCU). We use the same NN across both system instances that have different parameters. This work not only represents the first experimental demonstration of AMPC for fast-moving systems on low-cost MCUs to the best of our knowledge, but also showcases generalization across system instances and variations through our parameter-adaptation method. Taken together, these contributions represent a marked step toward the practical application of AMPC in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05835v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Hose, Alexander Gr\"afe, Sebastian Trimpe</dc:creator>
    </item>
    <item>
      <title>Online Control in Population Dynamics</title>
      <link>https://arxiv.org/abs/2406.01799</link>
      <description>arXiv:2406.01799v2 Announce Type: replace-cross 
Abstract: The study of population dynamics originated with early sociological works but has since extended into many fields, including biology, epidemiology, evolutionary game theory, and economics. Most studies on population dynamics focus on the problem of prediction rather than control. Existing mathematical models for control in population dynamics are often restricted to specific, noise-free dynamics, while real-world population changes can be complex and adversarial.
  To address this gap, we propose a new framework based on the paradigm of online control. We first characterize a set of linear dynamical systems that can naturally model evolving populations. We then give an efficient gradient-based controller for these systems, with near-optimal regret bounds with respect to a broad class of linear policies. Our empirical evaluations demonstrate the effectiveness of the proposed algorithm for control in population dynamics even for non-linear models such as SIR and replicator dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01799v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Golowich, Elad Hazan, Zhou Lu, Dhruv Rohatgi, Y. Jennifer Sun</dc:creator>
    </item>
    <item>
      <title>PDHG-Unrolled Learning-to-Optimize Method for Large-Scale Linear Programming</title>
      <link>https://arxiv.org/abs/2406.01908</link>
      <description>arXiv:2406.01908v2 Announce Type: replace-cross 
Abstract: Solving large-scale linear programming (LP) problems is an important task in various areas such as communication networks, power systems, finance and logistics. Recently, two distinct approaches have emerged to expedite LP solving: (i) First-order methods (FOMs); (ii) Learning to optimize (L2O). In this work, we propose an FOM-unrolled neural network (NN) called PDHG-Net, and propose a two-stage L2O method to solve large-scale LP problems. The new architecture PDHG-Net is designed by unrolling the recently emerged PDHG method into a neural network, combined with channel-expansion techniques borrowed from graph neural networks. We prove that the proposed PDHG-Net can recover PDHG algorithm, thus can approximate optimal solutions of LP instances with a polynomial number of neurons. We propose a two-stage inference approach: first use PDHG-Net to generate an approximate solution, and then apply PDHG algorithm to further improve the solution. Experiments show that our approach can significantly accelerate LP solving, achieving up to a 3$\times$ speedup compared to FOMs for large-scale LP problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01908v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingheng Li, Linxin Yang, Yupeng Chen, Senmiao Wang, Qian Chen, Haitao Mao, Yao Ma, Akang Wang, Tian Ding, Jiliang Tang, Ruoyu Sun</dc:creator>
    </item>
    <item>
      <title>Graph Convolutional Branch and Bound</title>
      <link>https://arxiv.org/abs/2406.03099</link>
      <description>arXiv:2406.03099v2 Announce Type: replace-cross 
Abstract: This article demonstrates the effectiveness of employing a deep learning model in an optimization pipeline. Specifically, in a generic exact algorithm for a NP problem, multiple heuristic criteria are usually used to guide the search of the optimum within the set of all feasible solutions. In this context, neural networks can be leveraged to rapidly acquire valuable information, enabling the identification of a more expedient path in this vast space. So, after the explanation of the tackled traveling salesman problem, the implemented branch and bound for its classical resolution is described. This algorithm is then compared with its hybrid version termed "graph convolutional branch and bound" that integrates the previous branch and bound with a graph convolutional neural network. The empirical results obtained highlight the efficacy of this approach, leading to conclusive findings and suggesting potential directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03099v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Sciandra, Roberto Esposito, Andrea Cesare Grosso, Laura Sacerdote, Cristina Zucca</dc:creator>
    </item>
  </channel>
</rss>
