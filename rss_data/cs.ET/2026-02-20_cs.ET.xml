<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Feb 2026 05:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Construction-Phase Digital Twin Framework for Quality Assurance and Decision Support in Civil Infrastructure Projects</title>
      <link>https://arxiv.org/abs/2602.16748</link>
      <description>arXiv:2602.16748v1 Announce Type: cross 
Abstract: Quality assurance (QA) during construction often relies on inspection records and laboratory test results that become available days or weeks after work is completed. On large highway and bridge projects, this delay limits early intervention and increases the risk of rework, schedule impacts, and fragmented documentation. This study presents a construction-phase digital twin framework designed to support element-level QA and readiness-based decision making during active construction. The framework links inspection records, material production and placement data, early-age sensing, and predictive strength models to individual construction elements. By integrating these data streams, the system represents the evolving quality state of each element and supports structured release or hold decisions before standard-age test results are available. The approach does not replace established inspection and testing procedures. Instead, it supplements existing workflows by improving traceability and enabling earlier, data-informed quality assessments. Practical considerations related to data integration, contractual constraints, and implementation challenges are also discussed. The proposed framework provides a structured pathway for transitioning construction QA from delayed, document-driven review toward proactive, element-level decision support during construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16748v1</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Asiful Islam, Shanto Jouerder, Md Sabit As Sami, Afia Jahin Prema</dc:creator>
    </item>
    <item>
      <title>DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs</title>
      <link>https://arxiv.org/abs/2602.16935</link>
      <description>arXiv:2602.16935v1 Announce Type: cross 
Abstract: While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a "Safety Gap" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed malicious intent across turn boundaries to bypass stateless filters. We introduce DeepContext, a stateful monitoring framework designed to map the temporal trajectory of user intent. DeepContext discards the isolated evaluation model in favor of a Recurrent Neural Network (RNN) architecture that ingests a sequence of fine-tuned turn-level embeddings. By propagating a hidden state across the conversation, DeepContext captures the incremental accumulation of risk that stateless models overlook. Our evaluation demonstrates that DeepContext significantly outperforms existing baselines in multi-turn jailbreak detection, achieving a state-of-the-art F1 score of 0.84, which represents a substantial improvement over both hyperscaler cloud-provider guardrails and leading open-weight models such as Llama-Prompt-Guard-2 (0.67) and Granite-Guardian (0.67). Furthermore, DeepContext maintains a sub-20ms inference overhead on a T4 GPU, ensuring viability for real-time applications. These results suggest that modeling the sequential evolution of intent is a more effective and computationally efficient alternative to deploying massive, stateless models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16935v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Albrethsen, Yash Datta, Kunal Kumar, Sharath Rajasekar</dc:creator>
    </item>
    <item>
      <title>Resource Allocation for STAR-RIS-enhanced Metaverse Systems with Augmented Reality</title>
      <link>https://arxiv.org/abs/2602.17123</link>
      <description>arXiv:2602.17123v1 Announce Type: cross 
Abstract: Augmented reality (AR)-enabled Metaverse is a promising technique to provide immersive service experience for mobile users. However, the limited network resources and unpredictable wireless propagation environments are key design bottlenecks of AR-enabled Metaverse systems. Therefore, this paper presents a resource management framework for simultaneously transmitting and reflecting RIS (STAR-RIS)-assisted AR-enabled Metaverse, where the STAR-RIS is configured to improve the communication efficiency between AR users and the Metaverse server located at the base station (BS). Moreover, we formulate a service latency minimization problem via jointly optimizing the computation resource allocation of the BS, coefficient matrix of the STAR-RIS, central processing unit (CPU) frequency and transmit power of the AR users. To tackle the non-convex problem, we utilize an approximate method to transform it to a tractable form, and decouple the multi-dimensional variables via the alternating optimization method. Particularly, the optimal coefficient matrix is obtained by a penalty function-based method with proved convergence, the CPU frequencies of AR users are derived as the closed-form solution, and the transmit power of AR users and computation resource allocation of the BS are obtained by the Lagrange duality method and convex optimization theory. Finally, simulation results demonstrates that the proposed method achieves remarkable latency reduction than several benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17123v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sun Mao, Lei Liu, Kun Yang, F. Richard Yu, Duist Niyato, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Device-Centric ISAC for Exposure Control via Opportunistic Virtual Aperture Sensing</title>
      <link>https://arxiv.org/abs/2602.17609</link>
      <description>arXiv:2602.17609v1 Announce Type: cross 
Abstract: Regulatory limits on Maximum Permissible Exposure (MPE) require handheld devices to reduce transmit power when operated near the user's body. Current proximity sensors provide only binary detection, triggering conservative power back-off that degrades link quality. If the device could measure its distance from the body, transmit power could be adjusted proportionally, improving throughput while maintaining compliance. This paper develops a device-centric integrated sensing and communication (ISAC) method for the device to measure this distance. The uplink communication waveform is exploited for sensing, and the natural motion of the user's hand creates a virtual aperture that provides the angular resolution necessary for localization. Virtual aperture processing requires precise knowledge of the device trajectory, which in this scenario is opportunistic and unknown. One can exploit onboard inertial sensors to estimate the device trajectory; however, the inertial sensors accuracy is not sufficient. To address this, we develop an autofocus algorithm based on extended Kalman filtering that jointly tracks the trajectory and compensates residual errors using phase observations from strong scatterers. The Bayesian Cram\'er-Rao bound for localization is derived under correlated inertial errors. Numerical results at 28GHz demonstrate centimeter-level accuracy with realistic sensor parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17609v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marouan Mizmizi, Zhibin Yu, Guanglong Du, Umberto Spagnolini</dc:creator>
    </item>
    <item>
      <title>Laser interferometry as a robust neuromorphic platform for machine learning</title>
      <link>https://arxiv.org/abs/2601.18047</link>
      <description>arXiv:2601.18047v3 Announce Type: replace-cross 
Abstract: We present a method for implementing an optical neural network using only linear optical resources, namely field displacement and interferometry applied to coherent states of light. The nonlinearity required for learning in a neural network is realized via an encoding of the input into phase shifts allowing for far more straightforward experimental implementation compared to previous proposals for, and demonstrations of, $\textit{in situ}$ inference. Beyond $\textit{in situ}$ inference, the method enables $\textit{in situ}$ training by utilizing established techniques like parameter shift rules or physical backpropagation to extract gradients directly from measurements of the linear optical circuit. We also investigate the effect of photon losses and find the model to be very resilient to these.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18047v3</guid>
      <category>physics.optics</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 20 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amanuel Anteneh, Kyungeun Kim, J. M. Schwarz, Israel Klich, Olivier Pfister</dc:creator>
    </item>
  </channel>
</rss>
