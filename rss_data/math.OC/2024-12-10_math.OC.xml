<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2024 05:01:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Use of Differential Equations With Variable Coefficients to Describe the Motions of Nonlinear Electromechanical Systems</title>
      <link>https://arxiv.org/abs/2412.05294</link>
      <description>arXiv:2412.05294v1 Announce Type: new 
Abstract: Due to the processes that occur during the functioning of modern electromechanical systems, these systems can be considered complex nonlinear dynamic systems from the point of view of the theory of dynamic systems. The movement of such systems is completely determined by external influences acting on the EMS, their parameters, and initial operating conditions. The above-mentioned factors complicate the study of electromechanical systems and, in the general case, make it impossible to use classical methods of analyzing the dynamics of the EMS since the latter neglect the features of nonlinear systems and describe their dynamics using ordinary linear differential equations with constant coefficients. At the same time, many methods and approaches have been developed in control theory for analyzing stability and synthesizing motion trajectories based on linear differential equations. Therefore, an important task arises to create mathematical models of nonlinear EMS that consider the peculiarities of their motion but have a form similar to linear models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05294v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roman Voliansky</dc:creator>
    </item>
    <item>
      <title>Residual growth control for general maps and an approximate inverse function result</title>
      <link>https://arxiv.org/abs/2412.05324</link>
      <description>arXiv:2412.05324v1 Announce Type: new 
Abstract: The need to control the residual of a potentially nonlinear function $\mathcal{F}$ arises in several situations in mathematics. For example, computing the zeros of a given map, or the reduction of some cost function during an optimization process are such situations. In this note, we discuss the existence of a curve $t\mapsto x(t)$ in the domain of the nonlinear map $\mathcal{F}$ leading from some initial value $x_0$ to a value $u$ such that we are able to control the residual $\mathcal{F}(x(t))$ based on the value $\mathcal{F}(x_0)$. More precisely, we slightly extend an existing result from J.W. Neuberger by proving the existence of such a curve, assuming that the directional derivative of $\mathcal{F}$ can be represented by $x \mapsto \mathcal{A}(x)\mathcal{F}(x_0)$, where $\mathcal{A}$ is a suitable defined operator. The presented approach covers, in case of $\mathcal{A}(x) = -\mathsf{Id}$, some well known results from the theory of so-called continuous Newton methods. Moreover, based on the presented results, we discover an approximate inverse function result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05324v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Amrein</dc:creator>
    </item>
    <item>
      <title>Controllability and observability of tempered fractional differential systems</title>
      <link>https://arxiv.org/abs/2412.05349</link>
      <description>arXiv:2412.05349v1 Announce Type: new 
Abstract: We study controllability and observability concepts of tempered fractional linear systems in the Caputo sense. First, we formulate a solution for the class of tempered systems under investigation by means of the Laplace transform method. Then, we derive necessary and sufficient conditions for the controllability, as well as for the observability, in terms of the Gramian controllability matrix and the Gramian observability matrix, respectively. Moreover, we establish the Kalman criteria that allows one to check easily the controllability and the observability for tempered fractional systems. Applications to the fractional Chua's circuit and Chua--Hartley's oscillator models are provided to illustrate the theoretical results developed in this manuscript.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05349v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cnsns.2024.108501</arxiv:DOI>
      <dc:creator>Ilyasse Lamrani, Hanaa Zitane, Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Accelerating Proximal Gradient Descent via Silver Stepsizes</title>
      <link>https://arxiv.org/abs/2412.05497</link>
      <description>arXiv:2412.05497v1 Announce Type: new 
Abstract: Surprisingly, recent work has shown that gradient descent can be accelerated without using momentum -- just by judiciously choosing stepsizes. An open question raised by several papers is whether this phenomenon of stepsize-based acceleration holds more generally for constrained and/or composite convex optimization via projected and/or proximal versions of gradient descent. We answer this in the affirmative by proving that the silver stepsize schedule yields analogously accelerated rates in these settings. These rates are conjectured to be asymptotically optimal among all stepsize schedules, and match the silver convergence rate of vanilla gradient descent (Altschuler and Parrilo, 2023), namely $O(\varepsilon^{- \log_{\rho} 2})$ for smooth convex optimization and $O(\kappa^{\log_\rho 2} \log \frac{1}{\varepsilon})$ under strong convexity, where $\varepsilon$ is the precision, $\kappa$ is the condition number, and $\rho = 1 + \sqrt{2}$ is the silver ratio. The key technical insight is the combination of recursive gluing -- the technique underlying all analyses of gradient descent accelerated with time-varying stepsizes -- with a certain Laplacian-structured sum-of-squares certificate for the analysis of proximal point updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05497v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinho Bok, Jason M. Altschuler</dc:creator>
    </item>
    <item>
      <title>Solving a global optimal problem requires only two-armed slot machine</title>
      <link>https://arxiv.org/abs/2412.05604</link>
      <description>arXiv:2412.05604v1 Announce Type: new 
Abstract: For a general purpose optimization problem over a finite rectangle region, this paper pioneers a unified slot machine framework for global optimization by transforming the search for global optimizer(s) to the optimal strategy formulation of a bandit process in infinite policy sets and proves that two-armed bandit is enough. By leveraging the strategic bandit process-driven optimization framework, we introduce a new {\bf S}trategic {\bf M}onte {\bf C}arlo {\bf O}ptimization (SMCO) algorithm that coordinate-wisely generates points from multiple paired distributions and can be implemented parallel for high-dimensional continuous functions. Our SMCO algorithm, equipped with tree search that broadens the optimal policy search space of slot machine for attaining the global optimizer(s) of a multi-modal function, facilitates fast learning via trial and error. We provide a strategic law of large numbers for nonlinear expectations in bandit settings, and establish that our SMCO algorithm converges to global optimizer(s) almost surely. Unlike the standard gradient descent ascent (GDA) that uses a one-leg walk to climb the mountain and is sensitive to starting points and step sizes, our SMCO algorithm takes a two-leg walk to the peak by using the two-sided sampling from the paired distributions and is not sensitive to initial point selection or step size constraints. Numerical studies demonstrate that the new SMCO algorithm outperforms GDA, particle swarm optimization and simulated annealing in both convergence accuracy and speed. Our SMCO algorithm should be extremely useful for finding optimal tuning parameters in many large scale complex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05604v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Zengjing Chen, Xiaodong Yan, Guodong Zhang, Yu Zhang</dc:creator>
    </item>
    <item>
      <title>Alternative theorem for sequences of functions and applications to optimisation</title>
      <link>https://arxiv.org/abs/2412.05614</link>
      <description>arXiv:2412.05614v1 Announce Type: new 
Abstract: We present a new alternative theorems for sequences of functions. As applications, we extend recent results in the literature related to first-order necessary conditions for optimality problems. Our contributions involve extending well-known results, previously established for a finite number of inequality constraints to a countable number of inequality constraints. This extension is achieved using the Dini differentiability concept which is more general than Fr\'echet or G\^ateaux differentiability. We will illustrate our results by giving examples of optimisation problems with a finite or countable number of inequality constraints where the functions are not Gateaux-differentiable but only upper Dini-differentiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05614v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Bachir, Rongzhen Lyu</dc:creator>
    </item>
    <item>
      <title>Neural Embedded Mixed-Integer Optimization for Location-Routing Problems</title>
      <link>https://arxiv.org/abs/2412.05665</link>
      <description>arXiv:2412.05665v1 Announce Type: new 
Abstract: We present a novel framework that combines machine learning with mixed-integer optimization to solve the Capacitated Location-Routing Problem (CLRP). The CLRP is a classical yet NP-hard problem that integrates strategic facility location with operational vehicle routing decisions, aiming to simultaneously minimize both fixed and variable costs. The proposed method first trains a permutationally invariant neural network that approximates the vehicle routing cost for serving any arbitrary subset of customers by any candidate facility. The trained neural network is then used as a surrogate within a mixed-integer optimization problem, which is reformulated and solved using off-the-shelf solvers. The framework is simple, scalable, and requires no routing-specific knowledge or parameter tuning. Computational experiments on large-scale benchmark instances confirm the effectiveness of our approach. Using only 10,000 training samples generated by an off-the-shelf vehicle routing heuristic and a one-time training cost of approximately 2 wall-clock hours, the method provides location-allocation decisions that are within 1% of the best-known solutions for large problems in less than 5 seconds on average. The findings suggest that the neural-embedded framework can be a viable method for tackling integrated location and routing problems at scale. Our code and data are publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05665v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Waquar Kaleem, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Local Linear Convergence of Infeasible Optimization with Orthogonal Constraints</title>
      <link>https://arxiv.org/abs/2412.05689</link>
      <description>arXiv:2412.05689v1 Announce Type: new 
Abstract: Many classical and modern machine learning algorithms require solving optimization tasks under orthogonality constraints. Solving these tasks with feasible methods requires a gradient descent update followed by a retraction operation on the Stiefel manifold, which can be computationally expensive. Recently, an infeasible retraction-free approach, termed the landing algorithm, was proposed as an efficient alternative. Motivated by the common occurrence of orthogonality constraints in tasks such as principle component analysis and training of deep neural networks, this paper studies the landing algorithm and establishes a novel linear convergence rate for smooth non-convex functions using only a local Riemannian P{\L} condition. Numerical experiments demonstrate that the landing algorithm performs on par with the state-of-the-art retraction-based methods with substantially reduced computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05689v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youbang Sun, Shixiang Chen, Alfredo Garcia, Shahin Shahrampour</dc:creator>
    </item>
    <item>
      <title>An Inexact Boosted Difference of Convex Algorithm for Nondifferentiable Functions</title>
      <link>https://arxiv.org/abs/2412.05697</link>
      <description>arXiv:2412.05697v1 Announce Type: new 
Abstract: In this paper, we introduce an inexact approach to the Boosted Difference of Convex Functions Algorithm (BDCA) for solving nonconvex and nondifferentiable problems involving the difference of two convex functions (DC functions). Specifically, when the first DC component is differentiable and the second may be nondifferentiable, BDCA utilizes the solution from the subproblem of the DC Algorithm (DCA) to define a descent direction for the objective function. A monotone linesearch is then performed to find a new point that improves the objective function relative to the subproblem solution. This approach enhances the performance of DCA. However, if the first DC component is nondifferentiable, the BDCA direction may become an ascent direction, rendering the monotone linesearch ineffective. To address this, we propose an Inexact nonmonotone Boosted Difference of Convex Algorithm (InmBDCA). This algorithm incorporates two main features of inexactness: First, the subproblem therein is solved approximately allowing us for a controlled relative error tolerance in defining the linesearch direction. Second, an inexact nonmonotone linesearch scheme is used to determine the step size for the next iteration. Under suitable assumptions, we demonstrate that InmBDCA is well-defined, with any accumulation point of the sequence generated by InmBDCA being a critical point of the problem. We also provide iteration-complexity bounds for the algorithm. Numerical experiments show that InmBDCA outperforms both the nonsmooth BDCA (nmBDCA) and the monotone version of DCA in practical scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05697v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orizon P. Ferreira, Boris S. Mordukhovich, Wilkreffy M. S. Santos, Jo\~ao Carlos O. Souza</dc:creator>
    </item>
    <item>
      <title>Acceleration by Random Stepsizes: Hedging, Equalization, and the Arcsine Stepsize Schedule</title>
      <link>https://arxiv.org/abs/2412.05790</link>
      <description>arXiv:2412.05790v1 Announce Type: new 
Abstract: We show that for separable convex optimization, random stepsizes fully accelerate Gradient Descent. Specifically, using inverse stepsizes i.i.d. from the Arcsine distribution improves the iteration complexity from $O(k)$ to $O(k^{1/2})$, where $k$ is the condition number. No momentum or other algorithmic modifications are required. This result is incomparable to the (deterministic) Silver Stepsize Schedule which does not require separability but only achieves partial acceleration $O(k^{\log_{1+\sqrt{2}} 2}) \approx O(k^{0.78})$. Our starting point is a conceptual connection to potential theory: the variational characterization for the distribution of stepsizes with fastest convergence rate mirrors the variational characterization for the distribution of charged particles with minimal logarithmic potential energy. The Arcsine distribution solves both variational characterizations due to a remarkable "equalization property" which in the physical context amounts to a constant potential over space, and in the optimization context amounts to an identical convergence rate over all quadratic functions. A key technical insight is that martingale arguments extend this phenomenon to all separable convex functions. We interpret this equalization as an extreme form of hedging: by using this random distribution over stepsizes, Gradient Descent converges at exactly the same rate for all functions in the function class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05790v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason M. Altschuler, Pablo A. Parrilo</dc:creator>
    </item>
    <item>
      <title>Block Coordinate Descent Methods for Structured Nonconvex Optimization with Nonseparable Constraints: Optimality Conditions and Global Convergence</title>
      <link>https://arxiv.org/abs/2412.05918</link>
      <description>arXiv:2412.05918v1 Announce Type: new 
Abstract: Coordinate descent algorithms are widely used in machine learning and large-scale data analysis due to their strong optimality guarantees and impressive empirical performance in solving non-convex problems. In this work, we introduce Block Coordinate Descent (BCD) method for structured nonconvex optimization with nonseparable constraints. Unlike traditional large-scale Coordinate Descent (CD) approaches, we do not assume the constraints are separable. Instead, we account for the possibility of nonlinear coupling among them. By leveraging the inherent problem structure, we propose new CD methods to tackle this specific challenge. Under the relatively mild condition of locally bounded non-convexity, we demonstrate that achieving coordinate-wise stationary points offer a stronger optimality criterion compared to standard critical points. Furthermore, under the Luo-Tseng error bound conditions, our BCD methods exhibit Q-linear convergence to coordinate-wise stationary points or critical points. To demonstrate the practical utility of our methods, we apply them to various machine learning and signal processing models. We also provide the geometry analysis for the models. Experiments on real-world data consistently demonstrate the superior objective values of our approaches compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05918v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhijie Yuan, Ganzhao Yuan, Lei Sun</dc:creator>
    </item>
    <item>
      <title>Strong Convergence of Relaxed Inertial Inexact Progressive Hedging Algorithm for Multi-stage Stochastic Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2412.05928</link>
      <description>arXiv:2412.05928v1 Announce Type: new 
Abstract: A Halpern-type relaxed inertial inexact progressive hedging algorithm (PHA) is proposed for solving multi-stage stochastic variational inequalities in general probability spaces. The subproblems in this algorithm are allowed to be calculated inexactly. It is found that the Halpern-type relaxed inertial inexact PHA is closely related to the Halpern-type relaxed inertial inexact proximal point algorithm (PPA). The strong convergence of the Halpern-type relaxed inertial inexact PHA is proved under appropriate conditions. Some numerical examples are given to indicate that the over-relaxed parameter and the inertial term can accelerate the convergence of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05928v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxin Chen, Zunjie Huang, Haisen Zhang</dc:creator>
    </item>
    <item>
      <title>Inertial primal-dual dynamics with Hessian-driven damping and Tikhonov regularization for convex-concave bilinear saddle point problems</title>
      <link>https://arxiv.org/abs/2412.05931</link>
      <description>arXiv:2412.05931v1 Announce Type: new 
Abstract: This paper deals with a second-order primal-dual dynamical system with Hessian-driven damping and Tikhonov regularization terms in connection with a convex-concave bilinear saddle point problem. We first obtain a fast convergence rate of the primal-dual gap along the trajectory generated by the dynamical system, and provide some integral estimates. Then, based on the setting of the parameters involved, we demonstrate that both the convergence rate of the primal-dual gap and the strong convergence of the trajectory can be achieved simultaneously. Furthermore, we evaluate the performance of the proposed system using two numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05931v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangkai Sun, Liang He, Xianjun Long</dc:creator>
    </item>
    <item>
      <title>A Newton-Like Dynamical System for Nonsmooth and Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2412.05952</link>
      <description>arXiv:2412.05952v1 Announce Type: new 
Abstract: This work investigates a dynamical system functioning as a nonsmooth adaptation of the continuous Newton method, aimed at minimizing the sum of a primal lower-regular and a locally Lipschitz function, both potentially nonsmooth. The classical Newton method's second-order information is extended by incorporating the graphical derivative of a locally Lipschitz mapping. Specifically, we analyze the existence and uniqueness of solutions, along with the asymptotic behavior of the system's trajectories. Conditions for convergence and respective convergence rates are established under two distinct scenarios: strong metric subregularity and satisfaction of the Kurdyka-Lojasiewicz inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05952v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Guillermo Garrido, Pedro P\'erez-Aros, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>On the role of semismoothness in the implicit programming approach to selected nonsmooth optimization problems</title>
      <link>https://arxiv.org/abs/2412.05953</link>
      <description>arXiv:2412.05953v1 Announce Type: new 
Abstract: The paper deals with the implicit programming approach to a class of Mathematical Programs with Equilibrium Constraints (MPECs) and bilevel programs in the case when the corresponding reduced problems are solved using a bundle method of nonsmooth optimization. The results obtained allow us to supply the bundle algorithm with suitable, easily computable ``pseudogradients'', ensuring convergence to points satisfying a stationary condition. Both the theory and computational implementation heavily rely on the notion of SCD (subspace containing derivatives) mappings and the associated calculus. The approach is validated via a complex MPEC with equilibrium governed by a variational inequality of the 2nd kind and by an academic bilevel program with a nonsmooth upper-level objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05953v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helmut Gfrerer, Michal Ko\v{c}vara, Ji\v{r}\'i V. Outrata</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient Descent Revisited</title>
      <link>https://arxiv.org/abs/2412.06070</link>
      <description>arXiv:2412.06070v1 Announce Type: new 
Abstract: Stochastic gradient descent (SGD) has been a go-to algorithm for nonconvex stochastic optimization problems arising in machine learning. Its theory however often requires a strong framework to guarantee convergence properties. We hereby present a full scope convergence study of biased nonconvex SGD, including weak convergence, function-value convergence and global convergence, and also provide subsequent convergence rates and complexities, all under relatively mild conditions in comparison with literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06070v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azar Louzi</dc:creator>
    </item>
    <item>
      <title>A numerical investigation of Matched Source Waveform Inversion applied to acoustic transmission data</title>
      <link>https://arxiv.org/abs/2412.06074</link>
      <description>arXiv:2412.06074v1 Announce Type: new 
Abstract: Iterative inversion of seismic, ultrasonic, and other wave data by local gradient-based optimization of mean-square data prediction error (Full Waveform Inversion or FWI) can fail to converge to useful model estimates if started from an initial model predicting wave arrival times in error by more than half a wavelength (a phenomenon known as cycle skipping). Matched Source Waveform Inversion (MSWI) extends the wave propagation model by a filter that shifts predicted waves to fit observed data. The MSWI objective adds a penalty for deviation of this filter from the identity to the mean-square data misfit . The extension allows the inversion to make large model adjustments while maintaining data fit and so reduces the chances of local optimization iterates stagnating at non-informative model estimates. Theory suggests that MSWI applied to acoustic transmission data with single-arrival wavefronts may produce an estimate of refractive index similar to the result of travel time inversion, but without requiring explicit identification of travel times. Numerical experiments conform to this expectation, in that MSWI applied to single arrival transmission data gives reasonable model estimates in cases where FWI fails. This MSWI model can then be used to jumpstart FWI for further refinement of the model. The addition of moderate amounts of noise (30\%) does not negatively impact MSWI's ability to converge. However, MSWI applied to data with multiple arrivals is no longer theoretically equivalent to travel-time tomography and exhibits the same tendency to cycle-skip as does FWI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06074v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William W. Symes, Huiyi Chen, Susan E. Minkoff</dc:creator>
    </item>
    <item>
      <title>Dublin Descriptors</title>
      <link>https://arxiv.org/abs/2412.06253</link>
      <description>arXiv:2412.06253v1 Announce Type: new 
Abstract: Dublin descriptors are under consideration. It is part of one of the global integration processes between European countries and Russia, which began in 1999. It causes a lot of controversy and approval from different sides. For the sake of clarity, an assessment is being made of the industrial application of the Dublin Descriptors. The assessment is based on the method of integral indicators. To use the method, the enterprise is formalized as a model of events at each moment in time. Each event in the enterprise is tied to the student's skill. Accordingly, students' skills are grouped by educational level. Education levels are given as Dublin descriptors. The chosen approach makes it possible to determine the correlation between levels of education and skills. It makes it possible to analyze meaningful interconnection. A universal assessment of the use of Dublin descriptors in the enterprise allows the formation of up-to-date lists of employees for higher education, professional development and training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06253v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-6596/1691/1/012021</arxiv:DOI>
      <arxiv:journal_reference>Journal of Physics: Conference Series 1691 (2020) 012021</arxiv:journal_reference>
      <dc:creator>Seregey Masaev, Georgiy Dorrer, Valentina Vingert, Elena Yakimova, Svatoslv Klochkov</dc:creator>
    </item>
    <item>
      <title>Uniformly Optimal and Parameter-free First-order Methods for Convex and Function-constrained Optimization</title>
      <link>https://arxiv.org/abs/2412.06319</link>
      <description>arXiv:2412.06319v1 Announce Type: new 
Abstract: This paper presents new first-order methods for achieving optimal oracle complexities in convex optimization with convex functional constraints. Oracle complexities are measured by the number of function and gradient evaluations. To achieve this, we enable first-order methods to utilize computational oracles for solving diagonal quadratic programs in subproblems. For problems where the optimal value $f^*$ is known, such as those in overparameterized models and feasibility problems, we propose an accelerated first-order method that incorporates a modified Polyak step size and Nesterov's momentum. Notably, our method does not require knowledge of smoothness levels, H\"{o}lder continuity parameter of the gradient, or additional line search, yet achieves the optimal oracle complexity bound of $\mathcal{O}(\varepsilon^{-2/(1+3\rho)})$ under H\"{o}lder smoothness conditions. When $f^*$ is unknown, we reformulate the problem as finding the root of the optimal value function and develop inexact fixed-point iteration and secant method to compute $f^*$. These root-finding subproblems are solved inexactly using first-order methods to a specified relative accuracy. We employ the accelerated prox-level (APL) method, which is proven to be uniformly optimal for convex optimization with simple constraints. Our analysis demonstrates that APL-based level-set methods also achieve the optimal oracle complexity of $\mathcal{O}(\varepsilon^{-2/(1+3\rho)})$ for convex function-constrained optimization, without requiring knowledge of any problem-specific structures. Through experiments on various tasks, we demonstrate the advantages of our methods over existing approaches in function-constrained optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06319v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Deng, Guanghui Lan, Zhenwei Lin</dc:creator>
    </item>
    <item>
      <title>An Improved Proximity Bound for Bike-Dock Reallocation Problem in Bike Sharing System</title>
      <link>https://arxiv.org/abs/2412.06385</link>
      <description>arXiv:2412.06385v1 Announce Type: new 
Abstract: We consider a class of nonlinear integer programming problems arising from re-allocation of dock-capacity in a bike sharing system. The main aim of this note is to derive an improved proximity bound for the problem and its scaled variant. This makes it possible to refine the time bound for the polynomial-time proximity-scaling algorithm by Freund et al. (2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06385v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akiyoshi Shioura</dc:creator>
    </item>
    <item>
      <title>An Adaptively Inexact Method for Bilevel Learning Using Primal-Dual Style Differentiation</title>
      <link>https://arxiv.org/abs/2412.06436</link>
      <description>arXiv:2412.06436v1 Announce Type: new 
Abstract: We consider a bilevel learning framework for learning linear operators. In this framework, the learnable parameters are optimized via a loss function that also depends on the minimizer of a convex optimization problem (denoted lower-level problem). We utilize an iterative algorithm called `piggyback' to compute the gradient of the loss and minimizer of the lower-level problem. Given that the lower-level problem is solved numerically, the loss function and thus its gradient can only be computed inexactly. To estimate the accuracy of the computed hypergradient, we derive an a-posteriori error bound, which provides guides for setting the tolerance for the lower-level problem, as well as the piggyback algorithm. To efficiently solve the upper-level optimization, we also propose an adaptive method for choosing a suitable step-size. To illustrate the proposed method, we consider a few learned regularizer problems, such as training an input-convex neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06436v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lea Bogensperger, Matthias J. Ehrhardt, Thomas Pock, Mohammad Sadegh Salehi, Hok Shing Wong</dc:creator>
    </item>
    <item>
      <title>Low-regret shape optimization in the presence of missing Dirichlet data</title>
      <link>https://arxiv.org/abs/2412.06479</link>
      <description>arXiv:2412.06479v1 Announce Type: new 
Abstract: A shape optimization problem subject to an elliptic equation in the presence of missing data on the Dirichlet boundary condition is considered. It is formulated by optimizing the deformation field that varies the spatial domain where the Poisson equation is posed. To take into consideration the missing boundary data the problem is formulated as a no-regret problem and approximated by low-regret problems. This approach allows to obtain deformation fields which are robust against the missing information. The formulation of the regret problems was achieved by employing the Fenchel transform. Convergence of the solutions of the low-regret to the no-regret problems is analysed, the gradient of the cost is characterized and a first order numerical method is proposed. Numerical examples illustrate the robustness of the low-regret deformation fields with respect to missing data. This is likely the first time that a numerical investigation is reported on for the level of effectiveness of the low-regret approach in the presence of missing data in an optimal control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06479v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Kunisch, John Sebastian H. Simon</dc:creator>
    </item>
    <item>
      <title>DeePC-Hunt: Data-enabled Predictive Control Hyperparameter Tuning via Differentiable Optimization</title>
      <link>https://arxiv.org/abs/2412.06481</link>
      <description>arXiv:2412.06481v1 Announce Type: new 
Abstract: This paper introduces Data-enabled Predictive Control Hyperparameter Tuning via Differentiable Optimization (DeePC-Hunt), a backpropagation-based method for automatic hyperparameter tuning of the DeePC algorithm. The necessity for such a method arises from the importance of hyperparameter selection to achieve satisfactory closed-loop DeePC performance. The standard methods for hyperparameter selection are to either optimize the open-loop performance, or use manual guess-and-check. Optimizing the open-loop performance can result in unacceptable closed-loop behavior, while manual guess-and-check can pose safety challenges. DeePC-Hunt provides an alternative method for hyperparameter tuning which uses an approximate model of the system dynamics and backpropagation to directly optimize hyperparameters for the closed-loop DeePC performance. Numerical simulations demonstrate the effectiveness of DeePC in combination with DeePC-Hunt in a complex stabilization task for a nonlinear system and its superiority over model-based control strategies in terms of robustness to model misspecifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06481v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Cummins, Alberto Padoan, Keith Moffat, Florian Dorfler, John Lygeros</dc:creator>
    </item>
    <item>
      <title>A Cardinality-Constrained Approach to Combinatorial Bilevel Congestion Pricing</title>
      <link>https://arxiv.org/abs/2412.06482</link>
      <description>arXiv:2412.06482v1 Announce Type: new 
Abstract: Combinatorial bilevel congestion pricing (CBCP), a variant of the discrete network design problem, seeks to minimize the total travel time experienced by all travelers in a road network, by strategically selecting toll locations and determining the corresponding charges. Conventional wisdom suggests that these problems are intractable since they have to be formulated and solved with a significant number of integer variables. Here, we devise a scalable local algorithm for the CBCP problem that guarantees convergence to a Kuhn-Tucker-Karush point. Our approach is novel in that it eliminates the use of integer variables altogether, instead introducing a cardinality constraint that limits the number of toll locations to a user-specified upper bound. The resulting bilevel program with the cardinality constraint is then transformed into a block-separable, single-level optimization problem that can be solved efficiently after penalization and decomposition. We are able to apply the algorithm to solve, in about 20 minutes, a CBCP instance with up to 3,000 links, of which hundreds can be tolled. To the best of our knowledge, no existing algorithm can solve CBCP problems at such a scale while providing any assurance of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06482v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Guo, Jiayang Li, Yu Marco Nie, Jun Xie</dc:creator>
    </item>
    <item>
      <title>Continuity in Parametric Linear Programming</title>
      <link>https://arxiv.org/abs/2412.06502</link>
      <description>arXiv:2412.06502v1 Announce Type: new 
Abstract: In this paper we assemble some results about the upper-semicontinuity and lower-semicontinuity of the feasible correspondence and the solution correspondence of linear programming problems allowing variability of all parameters of such problems. We also prove continuity properties of optimal value functions, once again allowing all parameters to vary. We discuss sensitivity properties of the optimal value function, keeping the coefficient matrix fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06502v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Numerical Optimization of Eigenvalues of the magnetic Dirichlet Laplacian with constant magnetic field</title>
      <link>https://arxiv.org/abs/2412.06533</link>
      <description>arXiv:2412.06533v1 Announce Type: new 
Abstract: We present numerical minimizers for the first seven eigenvalues of the magnetic Dirichlet Laplacian with constant magnetic field in a wide range of field strengths. Adapting an approach by Antunes and Freitas, we use gradient descent for the minimization procedure together with the Method of Fundamental solutions for eigenvalue computation. Remarkably, we observe that when the magnetic flux exceeds the index of the target eigenvalue, the minimizer is always a disk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06533v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.SP</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Baur</dc:creator>
    </item>
    <item>
      <title>Neo-FREE: Policy Composition Through Thousand Brains And Free Energy Optimization</title>
      <link>https://arxiv.org/abs/2412.06636</link>
      <description>arXiv:2412.06636v1 Announce Type: new 
Abstract: We consider the problem of optimally composing a set of primitives to tackle control tasks. To address this problem, we introduce Neo-FREE: a control architecture inspired by the Thousand Brains Theory and Free Energy Principle from cognitive sciences. In accordance with the neocortical (Neo) processes postulated by the Thousand Brains Theory, Neo-FREE consists of functional units returning control primitives. These are linearly combined by a gating mechanism that minimizes the variational free energy (FREE). The problem of finding the optimal primitives' weights is then recast as a finite-horizon optimal control problem, which is convex even when the cost is not and the environment is nonlinear, stochastic, non-stationary. The results yield an algorithm for primitives composition and the effectiveness of Neo-FREE is illustrated via in-silico and hardware experiments on an application involving robot navigation in an environment with obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06636v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Francesca Rossi, \'Emiland Garrab\'e, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Stochastic LQR Design With Disturbance Preview</title>
      <link>https://arxiv.org/abs/2412.06662</link>
      <description>arXiv:2412.06662v1 Announce Type: new 
Abstract: This paper considers the discrete-time, stochastic LQR problem with $p$ steps of disturbance preview information where $p$ is finite. We first derive the solution for this problem on a finite horizon with linear, time-varying dynamics and time-varying costs. Next, we derive the solution on the infinite horizon with linear, time-invariant dynamics and time-invariant costs. Our proofs rely on the well-known principle of optimality. We provide an independent proof for the principle of optimality that relies only on nested information structure. Finally, we show that the finite preview controller converges to the optimal noncausal controller as the preview horizon $p$ tends to infinity. We also provide a simple example to illustrate both the finite and infinite horizon results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06662v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jietian Liu, Laurent Lessard, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>A Speed Restart Scheme for a Dynamical System with Hessian-Driven Damping and Three Constant Coefficients</title>
      <link>https://arxiv.org/abs/2412.06691</link>
      <description>arXiv:2412.06691v1 Announce Type: new 
Abstract: In this paper, we study a speed restart scheme for an inertial system with Hessian-driven damping. We establish a linear convergence rate for the function values along the restarted trajectories without assuming the strong convexity of the objective function. Our numerical experiments show improvements in the convergence rates, both for the continuous-time dynamics, and when applied to inertial algorithms as a heuristic</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06691v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiyuan Guo, Juan Jos\'e Maul\'en, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>A subgradient splitting algorithm for optimization on nonpositively curved metric spaces</title>
      <link>https://arxiv.org/abs/2412.06730</link>
      <description>arXiv:2412.06730v1 Announce Type: new 
Abstract: Many of the primal ingredients of convex optimization extend naturally from Euclidean to Hadamard spaces $\unicode{x2014}$ nonpositively curved metric spaces like Euclidean, Hilbert, and hyperbolic spaces, metric trees, and more general CAT(0) cubical complexes. Linear structure, however, and the duality theory it supports are absent. Nonetheless, we introduce a new type of subgradient for convex functions on Hadamard spaces, based on Busemann functions. This notion supports a splitting subgradient method with guaranteed complexity bounds. In particular, the algorithm solves $p$-mean problems in general Hadamard spaces: we illustrate by computing medians in BHV tree space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06730v1</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Goodwin, Adrian S. Lewis, Genaro L\'opez-Acedo, Adriana Nicolae</dc:creator>
    </item>
    <item>
      <title>Beyond Minimax Optimality: A Subgame Perfect Gradient Method</title>
      <link>https://arxiv.org/abs/2412.06731</link>
      <description>arXiv:2412.06731v1 Announce Type: new 
Abstract: The study of unconstrained convex optimization has historically been concerned with worst-case a priori convergence rates. The development of the Optimized Gradient Method (OGM), due to Drori and Teboulle, Kim and Fessler, marked a major milestone in this study, as OGM achieves the optimal worst-case convergence rate among all gradient-span first-order methods. However, this notion of worst-case optimality is relatively coarse and allows OGM to have worst-case performance even on instances where stronger convergence guarantees are possible. For example, OGM is known to converge at its worst-case rate even on the toy example $Lx^2/2$, where exact convergence in just two steps is possible.
  We introduce a notion of optimality which is stronger than minimax optimality that requires a method to give optimal dynamic guarantees that exploit any "non-adversarialness" in the first-order oracle's reported information. We then give an algorithm which achieves this stronger optimality notion: the Subgame Perfect Gradient Method (SPGM). SPGM is a refinement of OGM whose update rules and convergence guarantees are dynamically computed in response to first-order information seen during the algorithm's execution. From a game-theoretic viewpoint, OGM can be seen as one side of a Nash Equilibrium for the "minimization game" whereas SPGM can be seen as one side of a Subgame Perfect Equilibrium for the same game. We also show that SPGM can be implemented with minimal computational and storage overhead in each iteration and provide a Julia implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06731v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Partially Observed Optimal Stochastic Control: Regularity, Optimality, Approximations, and Learning</title>
      <link>https://arxiv.org/abs/2412.06735</link>
      <description>arXiv:2412.06735v1 Announce Type: new 
Abstract: In this review/tutorial article, we present recent progress on optimal control of partially observed Markov Decision Processes (POMDPs). We first present regularity and continuity conditions for POMDPs and their belief-MDP reductions, where these constitute weak Feller and Wasserstein regularity and controlled filter stability. These are then utilized to arrive at existence results on optimal policies for both discounted and average cost problems, and regularity of value functions. Then, we study rigorous approximation results involving quantization based finite model approximations as well as finite window approximations under controlled filter stability. Finally, we present several recent reinforcement learning theoretic results which rigorously establish convergence to near optimality under both criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06735v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Sublinear Regret for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems</title>
      <link>https://arxiv.org/abs/2407.17226</link>
      <description>arXiv:2407.17226v2 Announce Type: cross 
Abstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an actor-critic algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{\frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17226v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang, Yanwei Jia, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Generalized Separation of Collections of Sets</title>
      <link>https://arxiv.org/abs/2412.05336</link>
      <description>arXiv:2412.05336v1 Announce Type: cross 
Abstract: We show that the existing generalized separation statements including the conventional extremal principle and its extensions differ {in the ways norms on product spaces are defined}. We prove a general separation statement with arbitrary product norms covering the existing results of this kind. The proof is divided into a series of claims and exposes the key steps and arguments used when proving generalized separation statements. As an application, we prove dual necessary (sufficient) conditions for an abstract product norm extension of the approximate stationarity (transversality) property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05336v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Duy Cuong, Alexander Y. Kruger</dc:creator>
    </item>
    <item>
      <title>A Variational Computational-based Framework for Unsteady Incompressible Flows</title>
      <link>https://arxiv.org/abs/2412.05525</link>
      <description>arXiv:2412.05525v1 Announce Type: cross 
Abstract: Advancements in computational fluid mechanics have largely relied on Newtonian frameworks, particularly through the direct simulation of Navier-Stokes equations. In this work, we propose an alternative computational framework that employs variational methods, specifically by leveraging the principle of minimum pressure gradient, which turns the fluid mechanics problem into a minimization problem whose solution can be used to predict the flow field in unsteady incompressible viscous flows.
  This method exhibits two particulary intriguing properties. First, it circumvents the chronic issues of pressure-velocity coupling in incompressible flows, which often dominates the computational cost in computational fluid dynamics (CFD). Second, this method eliminates the reliance on unphysical assumptions at the outflow boundary, addressing another longstanding challenge in CFD.
  We apply this framework to three benchmark examples across a range of Reynolds numbers: (i) unsteady flow field in a lid-driven cavity, (ii) Poiseuille flow, and (iii) flow past a circular cylinder. The minimization framework is carried out using a physics-informed neural network (PINN), which integrates the underlying physical principles directly into the training of the model. The results from the proposed method are validated against high-fidelity CFD simulations, showing an excellent agreement. Comparison of the proposed variational method to the conventional method, wherein PINNs is directly applied to solve Navier-Stokes Equations, reveals that the proposed method outperforms conventional PINNs in terms of both convergence rate and time, demonstrating its potential for solving complex fluid mechanics problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05525v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Sababha, A. Elmaradny, H. Taha, M. Daqaq</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of wide shallow neural operators within the framework of Neural Tangent Kernel</title>
      <link>https://arxiv.org/abs/2412.05545</link>
      <description>arXiv:2412.05545v1 Announce Type: cross 
Abstract: Neural operators are aiming at approximating operators mapping between Banach spaces of functions, achieving much success in the field of scientific computing. Compared to certain deep learning-based solvers, such as Physics-Informed Neural Networks (PINNs), Deep Ritz Method (DRM), neural operators can solve a class of Partial Differential Equations (PDEs). Although much work has been done to analyze the approximation and generalization error of neural operators, there is still a lack of analysis on their training error. In this work, we conduct the convergence analysis of gradient descent for the wide shallow neural operators within the framework of Neural Tangent Kernel (NTK). The core idea lies on the fact that over-parameterization and random initialization together ensure that each weight vector remains near its initialization throughout all iterations, yielding the linear convergence of gradient descent. In this work, we demonstrate that under the setting of over-parametrization, gradient descent can find the global minimum regardless of whether it is in continuous time or discrete time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05545v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianliang Xu, Ye Li, Zhongyi Huang</dc:creator>
    </item>
    <item>
      <title>Quantum Annealing and Tensor Networks: a Powerful Combination to Solve Optimization Problems</title>
      <link>https://arxiv.org/abs/2412.05595</link>
      <description>arXiv:2412.05595v1 Announce Type: cross 
Abstract: Quantum computing has long promised to revolutionize the way we solve complex problems. At the same time, tensor networks are widely used across various fields due to their computational efficiency and capacity to represent intricate systems. While both technologies can address similar problems, the primary aim of this thesis is not to compare them. Such comparison would be unfair, as quantum devices are still in an early stage, whereas tensor network algorithms represent the state-of-the-art in quantum simulation. Instead, we explore a potential synergy between these technologies, focusing on how two flagship algorithms from each paradigm, the Density Matrix Renormalization Group (DMRG) and quantum annealing, might collaborate in the future. Furthermore, a significant challenge in the DMRG algorithm is identifying an appropriate tensor network representation for the quantum system under study. The representation commonly used is called Matrix Product Operator (MPO), and it is notoriously difficult to obtain for certain systems. This thesis outlines an approach to this problem using finite automata, which we apply to construct the MPO for our case study. Finally, we present a practical application of this framework through the quadratic knapsack problem (QKP). Despite its apparent simplicity, the QKP is a fundamental problem in computer science with numerous practical applications. In addition to quantum annealing and the DMRG algorithm, we implement a dynamic programming approach to evaluate the quality of our results. Our results highlight the power of tensor networks and the potential of quantum annealing for solving optimization problems. Moreover, this thesis is designed to be self-explanatory, ensuring that readers with a solid mathematical background can fully understand the content without prior knowledge of quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05595v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miquel Albert\'i Binimelis</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for a Discrete-Time Linear-Quadratic Control Problem with an Application</title>
      <link>https://arxiv.org/abs/2412.05906</link>
      <description>arXiv:2412.05906v1 Announce Type: cross 
Abstract: We study the discrete-time linear-quadratic (LQ) control model using reinforcement learning (RL). Using entropy to measure the cost of exploration, we prove that the optimal feedback policy for the problem must be Gaussian type. Then, we apply the results of the discrete-time LQ model to solve the discrete-time mean-variance asset-liability management problem and prove our RL algorithm's policy improvement and convergence. Finally, a numerical example sheds light on the theoretical results established using simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05906v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucky Li</dc:creator>
    </item>
    <item>
      <title>Quantum Algorithms for Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2412.06177</link>
      <description>arXiv:2412.06177v1 Announce Type: cross 
Abstract: This paper explores the use of quantum computing, specifically the use of HHL and VQLS algorithms, to solve optimal power flow problem in electrical grids. We investigate the effectiveness of these quantum algorithms in comparison to classical methods. The simulation results presented here which substantially improve the results in [1] indicate that quantum approaches yield similar solutions and optimal costs compared to classical methods, suggesting the potential use case of quantum computing for power system optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06177v1</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajad Fathi Hafshejani, Md Mohsin Uddin, David Neufeld, Daya Gaur, Robert Benkoczi</dc:creator>
    </item>
    <item>
      <title>Robust Output Tracking for an Uncertain and Nonlinear 3D PDE-ODE System: Preventing Induced Seismicity in Underground Reservoirs</title>
      <link>https://arxiv.org/abs/2412.06327</link>
      <description>arXiv:2412.06327v1 Announce Type: cross 
Abstract: This paper presents a robust control strategy for output tracking of a nonlinear 3D PDE-ODE system. The output feedback control was developed by bounding the solution and its time derivative for both the infinite-dimensional system and the nonlinear ODE, and leveraging these bounds to ensure the boundedness of the control coefficient and error dynamics perturbations. The mathematical framework demonstrates the controller's ability to manage two output types within the system, overcoming model uncertainties and heterogeneities using minimal system information and a continuous control signal. A case study addressing induced seismicity mitigation while ensuring energy production in the Groningen gas reservoir highlights the control's effectiveness. The strategy guarantees precise tracking of target seismicity rates and pressures across reservoir regions, even under parameter uncertainties. Numerical simulations validate the approach in two scenarios: gas extraction with minimal seismicity and the addition of CO$_2$ injections achieving net-zero environmental impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06327v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Diego Guti\'errez-Oribio, Ioannis Stefanou</dc:creator>
    </item>
    <item>
      <title>Sparse Identification of Nonlinear Dynamics-based Model Predictive Control for Multirotor Collision Avoidance</title>
      <link>https://arxiv.org/abs/2412.06388</link>
      <description>arXiv:2412.06388v1 Announce Type: cross 
Abstract: This paper proposes a data-driven model predictive control for multirotor collision avoidance considering uncertainty and an unknown model from a payload. To address this challenge, sparse identification of nonlinear dynamics (SINDy) is used to obtain the governing equation of the multirotor system. The SINDy can discover the equations of target systems with low data, assuming that few functions have the dominant characteristic of the system. Model predictive control (MPC) is utilized to obtain accurate trajectory tracking performance by considering state and control input constraints. To avoid a collision during operation, MPC optimization problem is again formulated using inequality constraints about an obstacle. In simulation, SINDy can discover a governing equation of multirotor system including mass parameter uncertainty and aerodynamic effects. In addition, the simulation results show that the proposed method has the capability to avoid an obstacle and track the desired trajectory accurately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06388v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jayden Dongwoo Lee, Youngjae Kim, Yoonseong Kim, Hyochoong Bang</dc:creator>
    </item>
    <item>
      <title>Efficient First Order Method for Saddle Point Problems with Higher Order Smoothness</title>
      <link>https://arxiv.org/abs/2304.12453</link>
      <description>arXiv:2304.12453v2 Announce Type: replace 
Abstract: This paper studies the complexity of finding approximate stationary points for the smooth nonconvex-strongly-concave (NC-SC) saddle point problem: $\min_x\max_yf(x,y)$. Under the standard first-order smoothness conditions where $f$ is $\ell$-smooth in both arguments and $\mu_y$-strongly concave in $y$, existing literature shows that the optimal complexity for first-order methods to obtain an $\epsilon$-stationary point is $\tilde{O}\big(\sqrt{\kappa_y}\ell\epsilon^{-2}\big)$, where $\kappa_y=\ell/\mu_y$ is the condition number. However, when $\Phi(x):=\max_y f(x,y)$ has $L_2$-Lipschitz continuous Hessian in addition, we derive a first-order algorithm with an $\tilde{O}\big(\sqrt{\kappa_y}\ell^{1/2}L_2^{1/4}\epsilon^{-7/4}\big)$ complexity by designing an accelerated proximal point algorithm enhanced with the "Convex Until Proven Guilty" technique. Moreover, an improved $\Omega\big(\sqrt{\kappa_y}\ell^{3/7}L_2^{2/7}\epsilon^{-12/7}\big)$ lower bound for first-order method is also derived for sufficiently small $\epsilon$. As a result, given the second-order smoothness of the problem, the complexity of our method improves the state-of-the-art result by a factor of $\tilde{O}\big(\big(\frac{\ell^2}{L_2\epsilon}\big)^{1/4}\big)$, while almost matching the lower bound except for a small $\tilde{O}\big(\big(\frac{\ell^2}{L_2\epsilon}\big)^{1/28}\big)$ factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12453v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nuozhou Wang, Junyu Zhang, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Globally convergent homotopies for discrete-time optimal control</title>
      <link>https://arxiv.org/abs/2306.07852</link>
      <description>arXiv:2306.07852v3 Announce Type: replace 
Abstract: Homotopy methods are attractive due to their capability of solving difficult optimisation and optimal control problems. The underlying idea is to construct a homotopy, which may be considered as a continuous (zero) curve between the difficult original problem and a related, comparatively easy one. Then, the solution of the easier one is continuously perturbed along the zero curve towards the sought-after solution of the original problem. We propose a methodology for the systematic construction of such zero curves for discrete-time optimal control problems drawing upon the theory of globally convergent homotopies for nonlinear programs. The proposed framework ensures that for almost every initial guess at a solution there exists a suitable homotopy path that is, in addition, numerically convenient to track. We demonstrate the results by solving optimal path planning problems for a linear system and the nonlinear nonholonomic car (Dubins' vehicle).</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07852v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Willem Esterhuizen, Kathrin Fla{\ss}kamp, Matthias Hoffmann, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Relaxed Equilibria for Time-Inconsistent Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2307.04227</link>
      <description>arXiv:2307.04227v2 Announce Type: replace 
Abstract: This paper considers an infinite-horizon Markov decision process (MDP) that allows for general non-exponential discount functions, in both discrete and continuous time. Due to the inherent time inconsistency, we look for a randomized equilibrium policy (i.e., relaxed equilibrium) in an intra-personal game between an agent's current and future selves. When we modify the MDP by entropy regularization, a relaxed equilibrium is shown to exist by a nontrivial entropy estimate. As the degree of regularization diminishes, the entropy-regularized MDPs approximate the original MDP, which gives the general existence of a relaxed equilibrium in the limit by weak convergence arguments. As opposed to prior studies that consider only deterministic policies, our existence of an equilibrium does not require any convexity (or concavity) of the controlled transition probabilities and reward function. Interestingly, this benefit of considering randomized policies is unique to the time-inconsistent case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04227v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Yu-Jui Huang, Zhenhua Wang, Zhou Zhou</dc:creator>
    </item>
    <item>
      <title>Q-Learning for Continuous State and Action MDPs under Average Cost Criteria</title>
      <link>https://arxiv.org/abs/2308.07591</link>
      <description>arXiv:2308.07591v3 Announce Type: replace 
Abstract: For infinite-horizon average-cost criterion problems, there exist relatively few rigorous approximation and reinforcement learning results. In this paper, for Markov Decision Processes (MDPs) with standard Borel spaces, (i) we first provide a discretization based approximation method for MDPs with continuous spaces under average cost criteria, and provide error bounds for approximations when the dynamics are only weakly continuous (for asymptotic convergence of errors as the grid sizes vanish) or Wasserstein continuous (with a rate in approximation as the grid sizes vanish) under certain ergodicity assumptions. In particular, we relax the total variation condition given in prior work to weak continuity or Wasserstein continuity. (ii) We provide synchronous and asynchronous (quantized) Q-learning algorithms for continuous spaces via quantization (where the quantized state is taken to be the actual state in corresponding Q-learning algorithms presented in the paper), and establish their convergence. (iii) We finally show that the convergence is to the optimal Q values of a finite approximate model constructed via quantization, which implies near optimality of the arrived solution. Our Q-learning convergence results and their convergence to near optimality are new for continuous spaces, and the proof method is new even for finite spaces, to our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07591v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Devran Kara, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Inexact Gauss-Newton methods with matrix approximation by sampling for nonlinear least-squares and systems</title>
      <link>https://arxiv.org/abs/2310.05501</link>
      <description>arXiv:2310.05501v3 Announce Type: replace 
Abstract: We develop and analyze stochastic inexact Gauss-Newton methods for nonlinear least-squares problems and for nonlinear systems ofequations. Random models are formed using suitable sampling strategies for the matrices involved in the deterministic models. The analysis of the expected number of iterations needed in the worst case to achieve a desired level of accuracy in the first-order optimality condition provides guidelines for applying sampling and enforcing, with \minor{a} fixed probability, a suitable accuracy in the random approximations. Results of the numerical validation of the algorithms are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05501v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Greta Malaspina, Benedetta Morini</dc:creator>
    </item>
    <item>
      <title>Algorithm for the CSR expansion of max-plus matrices using the characteristic polynomial</title>
      <link>https://arxiv.org/abs/2311.03844</link>
      <description>arXiv:2311.03844v2 Announce Type: replace 
Abstract: Max-plus algebra is a semiring with addition $a\oplus b = \max(a,b)$ and multiplication $a\otimes b = a+b$. It is applied in cases, such as combinatorial optimization and discrete event systems. We consider the power of max-plus square matrices, which is equivalent to obtaining the all-pair maximum weight paths with a fixed length in the corresponding weighted digraph. Each $n$-by-$n$ matrix admits the CSR expansion that decomposes the matrix into a sum of at most $n$ periodic terms after $O(n^{2})$ times of powers. In this study, we propose an $O(n(m+n \log n))$ time algorithm for the CSR expansion, where $m$ is the number of nonzero entries in the matrix, which improves the $O(n^{4} \log n)$ algorithm known for this problem. Our algorithm is based on finding the roots of the characteristic polynomial of the max-plus matrix. These roots play a similar role to the eigenvalues of the matrix, and become the growth rates of the terms in the CSR expansion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03844v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Nishida</dc:creator>
    </item>
    <item>
      <title>Non-convex Stochastic Composite Optimization with Polyak Momentum</title>
      <link>https://arxiv.org/abs/2403.02967</link>
      <description>arXiv:2403.02967v4 Announce Type: replace 
Abstract: The stochastic proximal gradient method is a powerful generalization of the widely used stochastic gradient descent (SGD) method and has found numerous applications in Machine Learning. However, it is notoriously known that this method fails to converge in non-convex settings where the stochastic noise is significant (i.e. when only small or bounded batch sizes are used). In this paper, we focus on the stochastic proximal gradient method with Polyak momentum. We prove this method attains an optimal convergence rate for non-convex composite optimization problems, regardless of batch size. Additionally, we rigorously analyze the variance reduction effect of the Polyak momentum in the composite optimization setting and we show the method also converges when the proximal step can only be solved inexactly. Finally, we provide numerical experiments to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02967v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Risk Quadrangle and Robust Optimization Based on Extended $\varphi$-Divergence</title>
      <link>https://arxiv.org/abs/2403.10987</link>
      <description>arXiv:2403.10987v2 Announce Type: replace 
Abstract: This paper studies robust and distributionally robust optimization based on the extended $\varphi$-divergence under the Fundamental Risk Quadrangle framework. We present the primal and dual representations of the quadrangle elements: risk, deviation, regret, error, and statistic. The framework provides an interpretation of portfolio optimization, classification and regression as robust optimization. We furnish illustrative examples demonstrating that many common problems are included in this framework. The $\varphi$-divergence risk measure used in distributionally robust optimization is a special case. We conduct a case study to visualize the risk envelope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10987v2</guid>
      <category>math.OC</category>
      <category>stat.OT</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cheng Peng, Anton Malandii, Stan Uryasev</dc:creator>
    </item>
    <item>
      <title>Accelerating preconditioned ADMM via degenerate proximal point mappings</title>
      <link>https://arxiv.org/abs/2403.18618</link>
      <description>arXiv:2403.18618v2 Announce Type: replace 
Abstract: In this paper, we aim to accelerate a preconditioned alternating direction method of multipliers (pADMM), whose proximal terms are convex quadratic functions, for solving linearly constrained convex optimization problems. To achieve this, we first reformulate the pADMM into a form of proximal point method (PPM) with a positive semidefinite preconditioner which can be degenerate due to the lack of strong convexity of the proximal terms in the pADMM. Then we accelerate the pADMM by accelerating the reformulated degenerate PPM (dPPM). Specifically, we first propose an accelerated dPPM by integrating the Halpern iteration and the fast Krasnosel'ski\u{i}-Mann iteration into it, achieving asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ convergence rates. Subsequently, building upon the accelerated dPPM, we develop an accelerated pADMM algorithm that exhibits both asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ nonergodic convergence rates concerning the Karush-Kuhn-Tucker residual and the primal objective function value gap. Preliminary numerical experiments validate the theoretical findings, demonstrating that the accelerated pADMM outperforms the pADMM in solving convex quadratic programming problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18618v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Defeng Sun, Yancheng Yuan, Guojun Zhang, Xinyuan Zhao</dc:creator>
    </item>
    <item>
      <title>Some Remarks on Controllability of the Liouville Equation</title>
      <link>https://arxiv.org/abs/2404.14683</link>
      <description>arXiv:2404.14683v3 Announce Type: replace 
Abstract: We revisit the work of Roger Brockett on controllability of the Liouville equation, with a particular focus on the following problem: Given a smooth controlled dynamical system of the form $\dot{x} = f(x,u)$ and a state-space diffeomorphism $\psi$, design a feedback control $u(t,x)$ to steer an arbitrary initial state $x_0$ to $\psi(x_0)$ in finite time. This formulation of the problem makes contact with the theory of optimal transportation and with nonlinear controllability. For controllable linear systems, Brockett showed that this is possible under a fairly restrictive condition on $\psi$. We prove that controllability suffices for a much larger class of diffeomorphisms. For nonlinear systems defined on smooth manifolds, we review a recent result of Agrachev and Caponigro regarding controllability on the group of diffeomorphisms. A corollary of this result states that, for control-affine systems satisfying a bracket generating condition, any $\psi$ in a neighborhood of the identity can be implemented using a time-varying feedback control law that switches between finitely many time-invariant flows. We prove a quantitative version which allows us to describe the implementation complexity of the Agrachev-Caponigro construction in terms of a lower bound on the number of switchings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14683v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>Contextual Bilevel Reinforcement Learning for Incentive Alignment</title>
      <link>https://arxiv.org/abs/2406.01575</link>
      <description>arXiv:2406.01575v2 Announce Type: replace 
Abstract: The optimal policy in various real-world strategic decision-making problems depends both on the environmental configuration and exogenous events. For these settings, we introduce Contextual Bilevel Reinforcement Learning (CB-RL), a stochastic bilevel decision-making model, where the lower level consists of solving a contextual Markov Decision Process (CMDP). CB-RL can be viewed as a Stackelberg Game where the leader and a random context beyond the leader's control together decide the setup of many MDPs that potentially multiple followers best respond to. This framework extends beyond traditional bilevel optimization and finds relevance in diverse fields such as RLHF, tax design, reward shaping, contract theory and mechanism design. We propose a stochastic Hyper Policy Gradient Descent (HPGD) algorithm to solve CB-RL, and demonstrate its convergence. Notably, HPGD uses stochastic hypergradient estimates, based on observations of the followers' trajectories. Therefore, it allows followers to use any training procedure and the leader to be agnostic of the specific algorithm, which aligns with various real-world scenarios. We further consider the setting when the leader can influence the training of followers and propose an accelerated algorithm. We empirically demonstrate the performance of our algorithm for reward shaping and tax design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01575v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinzenz Thoma, Barna Pasztor, Andreas Krause, Giorgia Ramponi, Yifan Hu</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Policies for Weakly Coupled Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04751</link>
      <description>arXiv:2406.04751v2 Announce Type: replace 
Abstract: We consider the problem of maximizing the expected average reward obtained over an infinite time horizon by $n$ weakly coupled Markov decision processes. Our setup is a substantial generalization of the multi-armed restless bandit problem that allows for multiple actions and constraints. We establish a connection with a deterministic and continuous-variable control problem where the objective is to maximize the average reward derived from an occupancy measure that represents the empirical distribution of the processes when $n \to \infty$. We show that a solution of this fluid problem can be used to construct policies for the weakly coupled processes that achieve the maximum expected average reward as $n \to \infty$, and we give sufficient conditions for the existence of solutions. Under certain assumptions on the constraints, we prove that these conditions are automatically satisfied if the unconstrained single-process problem admits a suitable unichain and aperiodic policy. In particular, the assumptions include multi-armed restless bandits and a broad class of problems with multiple actions and inequality constraints. Also, the policies can be constructed in an explicit way in these cases. Our theoretical results are complemented by several concrete examples and numerical experiments, which include multichain setups that are covered by the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04751v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Goldsztajn, Konstantin Avrachenkov</dc:creator>
    </item>
    <item>
      <title>McCormick envelopes in mixed-integer PDE-constrained optimization</title>
      <link>https://arxiv.org/abs/2406.07891</link>
      <description>arXiv:2406.07891v3 Announce Type: replace 
Abstract: McCormick envelopes are a standard tool for deriving convex relaxations of optimization problems that involve polynomial terms. Such McCormick relaxations provide lower bounds, for example, in branch-and-bound procedures for mixed-integer nonlinear programs but have not gained much attention in PDE-constrained optimization so far. This lack of attention may be due to the distributed nature of such problems, which on the one hand leads to infinitely many linear constraints (generally state constraints that may be difficult to handle) in addition to the state equation for a pointwise formulation of the McCormick envelopes and renders bound-tightening procedures that successively improve the resulting convex relaxations computationally intractable.
  We analyze McCormick envelopes for a problem class that is governed by a semilinear PDE involving a bilinearity and integrality constraints. We approximate the nonlinearity by averaging the involved terms over the cells of a partition of the computational domain on which the PDE is defined. This yields convex relaxations that underestimate the original problem up to an a priori error estimate that depends on the mesh size of the discretization. These approximate McCormick relaxations can be improved by means of an optimization-based bound-tightening procedure. We show that their minimizers converge to minimizers to a limit problem with a pointwise formulation of the McCormick envelopes when driving the mesh size to zero.
  We provide a computational example, for which we certify all of our imposed assumptions. The results point to both the potential of the methodology and the gaps in the research that need to be closed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07891v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sven Leyffer, Paul Manns</dc:creator>
    </item>
    <item>
      <title>Grassmannian optimization is NP-hard</title>
      <link>https://arxiv.org/abs/2406.19377</link>
      <description>arXiv:2406.19377v2 Announce Type: replace 
Abstract: We show that unconstrained quadratic optimization over a Grassmannian $\operatorname{Gr}(k,n)$ is NP-hard. Our results cover all scenarios: (i) when $k$ and $n$ are both allowed to grow; (ii) when $k$ is arbitrary but fixed; (iii) when $k$ is fixed at its lowest possible value $1$. We then deduce the NP-hardness of unconstrained cubic optimization over the Stiefel manifold $\operatorname{V}(k,n)$ and the orthogonal group $\operatorname{O}(n)$. As an addendum we demonstrate the NP-hardness of unconstrained quadratic optimization over the Cartan manifold, i.e., the positive definite cone $\mathbb{S}^n_{\scriptscriptstyle++}$ regarded as a Riemannian manifold, another popular example in manifold optimization. We will also establish the nonexistence of $\mathrm{FPTAS}$ in all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19377v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Ke Ye</dc:creator>
    </item>
    <item>
      <title>Small-Time Local Controllability of the multi-input bilinear Schr\"odinger equation thanks to a quadratic term</title>
      <link>https://arxiv.org/abs/2407.07446</link>
      <description>arXiv:2407.07446v4 Announce Type: replace 
Abstract: The goal of this article is to contribute to a better understanding of the relations between the exact controllability of nonlinear PDEs and the control theory for ODEs based on Lie brackets, through a study of the Schr\"odinger PDE with bilinear control. We focus on the small-time local controllability (STLC) around an equilibrium, when the linearized system is not controllable. We study the second-order term in the Taylor expansion of the state, with respect to the control. For scalar-input ODEs, quadratic terms never recover controllability: they induce signed drifts in the dynamics. Thus proving STLC requires to go at least to the third order. Similar results were proved for the bilinear Schr\"odinger PDE with scalar-input controls. In this article, we study the case of multi-input systems. We clarify among the quadratic Lie brackets, those that allow to recover STLC: they are bilinear with respect to two different controls. For ODEs, our result is a consequence of Sussman's sufficient condition $S(\theta)$ (when focused on quadratic terms), but we propose a new proof, designed to prepare an easier transfer to PDEs. This proof relies on a representation formula of the state inspired by the Magnus formula. By adapting it, we prove a new STLC result for the bilinear Schr\"odinger PDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07446v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eo Gherdaoui (IRMAR, ENS Rennes)</dc:creator>
    </item>
    <item>
      <title>Optimality of vaccination for an SIR epidemic with an ICU constraint</title>
      <link>https://arxiv.org/abs/2407.08425</link>
      <description>arXiv:2407.08425v2 Announce Type: replace 
Abstract: This paper studies an optimal control problem for a class of SIR epidemic models, in scenarios in which the infected population is constrained to be lower than a critical threshold imposed by the ICU (intensive care unit) capacity. The vaccination effort possibly imposed by the health-care deciders is classically modeled by a control input affecting the epidemic dynamic. After a preliminary viability analysis the existence of optimal controls is established, and their structure is characterized by using a state-constrained version of Pontryagin's theorem. The resulting optimal controls necessarily have a bang-bang regime with at most one switch. More precisely, the optimal strategies impose the maximum-allowed vaccination effort in an initial period of time, which can cease only once the ICU constraint can be satisfied without further vaccination. The switching times are characterized in order to identify conditions under which vaccination should be implemented or halted. The uniqueness of the optimal control is also discussed. Numerical examples illustrate our theoretical results and the corresponding optimal strategies. The analysis is eventually extended to the infinite horizon by $\Gamma$-convergence arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08425v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Della Rossa, Lorenzo Freddi, Dan Goreac</dc:creator>
    </item>
    <item>
      <title>Deterministic Trajectory Optimization through Probabilistic Optimal Control</title>
      <link>https://arxiv.org/abs/2407.13316</link>
      <description>arXiv:2407.13316v3 Announce Type: replace 
Abstract: In this article, we discuss two algorithms tailored to discrete-time deterministic finite-horizon nonlinear optimal control problems or so-called deterministic trajectory optimization problems. Both algorithms can be derived from an emerging theoretical paradigm that we refer to as probabilistic optimal control. The paradigm reformulates stochastic optimal control as an equivalent probabilistic inference problem and can be viewed as a generalisation of the former. The merit of this perspective is that it allows to address the problem using the Expectation-Maximization algorithm. It is shown that the application of this algorithm results in a fixed point iteration of probabilistic policies that converge to the deterministic optimal policy. Two strategies for policy evaluation are discussed, using state-of-the-art uncertainty quantification methods resulting into two distinct algorithms. The algorithms are structurally closest related to the differential dynamic programming algorithm and related methods that use sigma-point methods to avoid direct gradient evaluations. The main advantage of the algorithms is an improved balance between exploration and exploitation over the iterations, leading to improved numerical stability and accelerated convergence. These properties are demonstrated on different nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13316v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Mahmoudi Filabadi, Tom Lefebvre, Guillaume Crevecoeur</dc:creator>
    </item>
    <item>
      <title>Proximal Projection Method for Stable Linearly Constrained Optimization</title>
      <link>https://arxiv.org/abs/2407.16998</link>
      <description>arXiv:2407.16998v2 Announce Type: replace 
Abstract: Many applications using large datasets require efficient methods for minimizing a proximable convex function subject to satisfying a set of linear constraints within a specified tolerance. For this task, we present a proximal projection (PP) algorithm, which is an instance of Douglas-Rachford splitting that directly uses projections onto the set of constraints. Formal guarantees are presented to prove convergence of PP estimates to optimizers. Unlike many methods that obtain feasibility asymptotically, each PP iterate is feasible. Numerically, we show PP either matches or outperforms alternatives (e.g. linearized Bregman, primal dual hybrid gradient, proximal augmented Lagrangian, proximal gradient) on problems in basis pursuit, stable matrix completion, stable principal component pursuit, and the computation of earth mover's distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16998v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Howard Heaton</dc:creator>
    </item>
    <item>
      <title>Hybrid Minimum-Seeking in Synergistic Lyapunov Functions: Robust Global Stabilization under Unknown Control Directions</title>
      <link>https://arxiv.org/abs/2408.04882</link>
      <description>arXiv:2408.04882v2 Announce Type: replace 
Abstract: We study the problem of robust global stabilization in control-affine systems, focusing on dynamic uncertainties in the control directions \emph{and} the presence of topological obstructions that prevent the existence of smooth global control Lyapunov functions. Building on a recently developed Lie-bracket averaging result for hybrid dynamic inclusions presented in \cite{abdelgalil2023lie}, we propose a novel class of universal hybrid feedback laws that achieve robust global practical stability by identifying the minimum point of a set of appropriately chosen synergistic Lyapunov functions. As concrete applications of our results, we synthesize different hybrid high-frequency high-amplitude feedback laws for the solution of robust global stabilization problems on various types of manifolds under unknown control directions, as well as controllers for obstacle avoidance problems in vehicles characterized by kinematic models describing both holonomic and non-holonomic models. By leveraging Lie-bracket averaging for hybrid systems, we also show how the proposed hybrid minimum-seeking feedback laws can overcome lack of controllability during persistent (bounded) periods of time. Numerical simulation results are presented to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04882v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Abdelgalil, Jorge I. Poveda</dc:creator>
    </item>
    <item>
      <title>Existence of Mild Solutions for a Class of Non-Autonomous Conformable Fractional Semilinear Systems and Their Exact Null Controllability</title>
      <link>https://arxiv.org/abs/2408.13814</link>
      <description>arXiv:2408.13814v2 Announce Type: replace 
Abstract: In this paper, we investigate the controllability of systems characterized by conformable fractional-order derivatives. We begin by establishing the existence and uniqueness of the evolution operator for a class of non-autonomous fractional-order homogeneous systems. Using Schauder's fixed-point theorem and the theory of linear evolution systems, we derive sufficient conditions for the existence of a mild solution for a class of non-autonomous conformable fractional semilinear systems. This solution does not require the Lipschitz condition on the semilinear parts. Additionally, the paper addresses the exact null controllability of abstract systems. An example is presented to demonstrate the practical applications of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13814v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dev Prakash Jha, Raju K George</dc:creator>
    </item>
    <item>
      <title>Covert Vehicle Misguidance and Its Detection: A Hypothesis Testing Game over Continuous-Time Dynamics</title>
      <link>https://arxiv.org/abs/2409.05185</link>
      <description>arXiv:2409.05185v2 Announce Type: replace 
Abstract: We formulate a stochastic zero-sum game over continuous-time dynamics to analyze the competition between the attacker, who tries to covertly misguide the vehicle to an unsafe region, versus the detector, who tries to detect the attack signal based on the observed trajectory of the vehicle. Based on Girsanov's theorem and the generalized Neyman-Pearson lemma, we show that a constant bias injection attack as the attacker's strategy and a likelihood ratio test as the detector's strategy constitute the unique saddle point of the game. We also derive the first-order and the second-order exponents of the type II error as a function of the data length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05185v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Tanaka, Kenji Sawada, Yohei Watanabe, Mitsugu Iwamoto</dc:creator>
    </item>
    <item>
      <title>Reduced Sample Complexity in Scenario-Based Control System Design via Constraint Scaling</title>
      <link>https://arxiv.org/abs/2411.07361</link>
      <description>arXiv:2411.07361v3 Announce Type: replace 
Abstract: The scenario approach is widely used in robust control system design and chance-constrained optimization, maintaining convexity without requiring assumptions about the probability distribution of uncertain parameters. However, the approach can demand large sample sizes, making it intractable for safety-critical applications that require very low levels of constraint violation. To address this challenge, we propose a novel yet simple constraint scaling method, inspired by large deviations theory. Under mild nonparametric conditions on the underlying probability distribution, we show that our method yields an exponential reduction in sample size requirements for bilinear constraints with low violation levels compared to the classical approach, thereby significantly improving computational tractability. Numerical experiments on robust pole assignment problems support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07361v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaeseok Choi, Anand Deo, Constantino Lagoa, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Breakdown points of Fermat-Weber problems under gauge distances</title>
      <link>https://arxiv.org/abs/2306.13424</link>
      <description>arXiv:2306.13424v2 Announce Type: replace-cross 
Abstract: We compute the robustness of Fermat-Weber points with respect to any finite gauge. We show a breakdown point of $1/(1+\sigma)$ where $\sigma$ is the asymmetry measure of the gauge. We obtain quantitative results indicating how far a corrupted Fermat-Weber point can lie from the true value in terms of the original sample and the size of the corrupted part. If the distance from the true value depends only on the original sample, then we call the gauge `uniformly robust.' We show that polyhedral gauges are uniformly robust, but locally strictly convex norms are not, while in dimension 2 any uniform robust gauge is polyhedral.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13424v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Com\u{a}neci, Frank Plastria</dc:creator>
    </item>
    <item>
      <title>AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix</title>
      <link>https://arxiv.org/abs/2312.01658</link>
      <description>arXiv:2312.01658v2 Announce Type: replace-cross 
Abstract: Adaptive optimizers, such as Adam, have achieved remarkable success in deep learning. A key component of these optimizers is the so-called preconditioning matrix, providing enhanced gradient information and regulating the step size of each gradient direction. In this paper, we propose a novel approach to designing the preconditioning matrix by utilizing the gradient difference between two successive steps as the diagonal elements. These diagonal elements are closely related to the Hessian and can be perceived as an approximation of the inner product between the Hessian row vectors and difference of the adjacent parameter vectors. Additionally, we introduce an auto-switching function that enables the preconditioning matrix to switch dynamically between Stochastic Gradient Descent (SGD) and the adaptive optimizer. Based on these two techniques, we develop a new optimizer named AGD that enhances the generalization performance. We evaluate AGD on public datasets of Natural Language Processing (NLP), Computer Vision (CV), and Recommendation Systems (RecSys). Our experimental results demonstrate that AGD outperforms the state-of-the-art (SOTA) optimizers, achieving highly competitive or significantly better predictive performance. Furthermore, we analyze how AGD is able to switch automatically between SGD and the adaptive optimizer and its actual effects on various scenarios. The code is available at https://github.com/intelligent-machine-learning/atorch/tree/main/atorch/optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01658v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Yue, Zhiling Ye, Jiadi Jiang, Yongchao Liu, Ke Zhang</dc:creator>
    </item>
    <item>
      <title>Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad</title>
      <link>https://arxiv.org/abs/2403.02648</link>
      <description>arXiv:2403.02648v3 Announce Type: replace-cross 
Abstract: Adaptive methods are extremely popular in machine learning as they make learning rate tuning less expensive. This paper introduces a novel optimization algorithm named KATE, which presents a scale-invariant adaptation of the well-known AdaGrad algorithm. We prove the scale-invariance of KATE for the case of Generalized Linear Models. Moreover, for general smooth non-convex problems, we establish a convergence rate of $O \left(\frac{\log T}{\sqrt{T}} \right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also compare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in numerical experiments with different problems, including complex machine learning tasks like image classification and text classification on real data. The results indicate that KATE consistently outperforms AdaGrad and matches/surpasses the performance of Adam in all considered scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02648v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The Thirty-Eighth Annual Conference on Neural Information Processing Systems, 2024</arxiv:journal_reference>
      <dc:creator>Sayantan Choudhury, Nazarii Tupitsa, Nicolas Loizou, Samuel Horvath, Martin Takac, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Online Contention Resolution Schemes for Network Revenue Management and Combinatorial Auctions</title>
      <link>https://arxiv.org/abs/2403.05378</link>
      <description>arXiv:2403.05378v2 Announce Type: replace-cross 
Abstract: In the Network Revenue Management (NRM) problem, products composed of up to L resources are sold to stochastically arriving customers. We take a randomized rounding approach to NRM, motivated by the modern tool of Online Contention Resolution Schemes (OCRS). The goal is to take a fractional solution to NRM that satisfies the resource constraints in expectation, and implement it in an online policy that satisfies the resource constraints with probability 1, while (approximately) preserving all of the sales that were prescribed by the fractional solution.
  In NRM problems, customer substitution induces a negative correlation between products being demanded, making it difficult to apply the standard definition of OCRS. We start by deriving a more powerful notion of "random-element" OCRS that achieves a guarantee of 1/(1+L) for NRM with customer substitution, matching a common benchmark in the literature. We show this benchmark is unbeatable for all integers L that are the power of a prime number. We then show how to beat this benchmark under three widely applied assumptions. Finally, we show that under several assumptions, it is possible to do better than offline CRS when L&gt;= 5.
  Our results have corresponding implications for Online Combinatorial Auctions, in which buyers bid for bundles of up to L items, and buyers being single-minded is akin to having no substitution. Our result under the assumption that products comprise one item from each of up to L groups implies that 1/(1+L) can be beaten for Prophet Inequality on the intersection of L partition matroids, a problem of interest. In sum, our paper shows how to apply OCRS to all of these problems and establishes a surprising separation in the achievable guarantees when substitution is involved, under general resource constraints parametrized by L.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05378v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Will Ma, Calum MacRury, Jingwei Zhang</dc:creator>
    </item>
    <item>
      <title>Early Directional Convergence in Deep Homogeneous Neural Networks for Small Initializations</title>
      <link>https://arxiv.org/abs/2403.08121</link>
      <description>arXiv:2403.08121v2 Announce Type: replace-cross 
Abstract: This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. It is shown here that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in (Euclidean) norm and approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of the recently introduced neural correlation function. Additionally, this paper also studies the KKT points of the neural correlation function for feed-forward networks with (Leaky) ReLU and polynomial (Leaky) ReLU activations, deriving necessary and sufficient conditions for rank-one KKT points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08121v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshay Kumar, Jarvis Haupt</dc:creator>
    </item>
    <item>
      <title>On Smale's 17th problem over the reals</title>
      <link>https://arxiv.org/abs/2405.01735</link>
      <description>arXiv:2405.01735v2 Announce Type: replace-cross 
Abstract: We consider the problem of efficiently solving a system of $n$ non-linear equations in ${\mathbb R}^d$. Addressing Smale's 17th problem stated in 1998, we consider a setting whereby the $n$ equations are random homogeneous polynomials of arbitrary degrees. In the complex case and for $n= d-1$, Beltr\'{a}n and Pardo proved the existence of an efficient randomized algorithm and Lairez recently showed it can be de-randomized to produce a deterministic efficient algorithm. Here we consider the real setting, to which previously developed methods do not apply. We describe a polynomial time algorithm that finds solutions (with high probability) for $n= d -O(\sqrt{d\log d})$ if the maximal degree is bounded by $d^2$ and for $n=d-1$ if the maximal degree is larger than $d^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01735v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Montanari, Eliran Subag</dc:creator>
    </item>
    <item>
      <title>Retraction-Free Decentralized Non-convex Optimization with Orthogonal Constraints</title>
      <link>https://arxiv.org/abs/2405.11590</link>
      <description>arXiv:2405.11590v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate decentralized non-convex optimization with orthogonal constraints. Conventional algorithms for this setting require either manifold retractions or other types of projection to ensure feasibility, both of which involve costly linear algebra operations (e.g., SVD or matrix inversion). On the other hand, infeasible methods are able to provide similar performance with higher computational efficiency. Inspired by this, we propose the first decentralized version of the retraction-free landing algorithm, called \textbf{D}ecentralized \textbf{R}etraction-\textbf{F}ree \textbf{G}radient \textbf{T}racking (DRFGT). We theoretically prove that DRFGT enjoys the ergodic convergence rate of $\mathcal{O}(1/K)$, matching the convergence rate of centralized, retraction-based methods. We further establish that under a local Riemannian P{\L} condition, DRFGT achieves a much faster linear convergence rate. Numerical experiments demonstrate that DRFGT performs on par with the state-of-the-art retraction-based methods with substantially reduced computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11590v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youbang Sun, Shixiang Chen, Alfredo Garcia, Shahin Shahrampour</dc:creator>
    </item>
    <item>
      <title>FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction</title>
      <link>https://arxiv.org/abs/2407.19389</link>
      <description>arXiv:2407.19389v3 Announce Type: replace-cross 
Abstract: In federated learning (FL), accommodating clients' varied computational capacities poses a challenge, often limiting the participation of those with constrained resources in global model training. To address this issue, the concept of model heterogeneity through submodel extraction has emerged, offering a tailored solution that aligns the model's complexity with each client's computational capacity. In this work, we propose Federated Importance-Aware Submodel Extraction (FIARSE), a novel approach that dynamically adjusts submodels based on the importance of model parameters, thereby overcoming the limitations of previous static and dynamic submodel extraction methods. Compared to existing works, the proposed method offers a theoretical foundation for the submodel extraction and eliminates the need for additional information beyond the model parameters themselves to determine parameter importance, significantly reducing the overhead on clients. Extensive experiments are conducted on various datasets to showcase the superior performance of the proposed FIARSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19389v3</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feijie Wu, Xingchen Wang, Yaqing Wang, Tianci Liu, Lu Su, Jing Gao</dc:creator>
    </item>
    <item>
      <title>A novel load distribution strategy for aggregators using IoT-enabled mobile devices</title>
      <link>https://arxiv.org/abs/2409.14293</link>
      <description>arXiv:2409.14293v2 Announce Type: replace-cross 
Abstract: The rapid proliferation of Internet-of-things (IoT) as well as mobile devices such as Electric Vehicles (EVs), has led to unpredictable load at the grid. The demand to supply ratio is particularly exacerbated at a few grid aggregators (charging stations) with excessive demand due to the geographic location, peak time, etc. Existing solutions on demand response cannot achieve significant improvements based only on time-shifting the loads without considering the device properties such as charging modes and movement capabilities to enable geographic migration. Additionally, the information on the spare capacity at a few aggregators can aid in re-channeling the load from other aggregators facing excess demand to allow migration of devices. In this paper, we model these flexible properties of the devices as a mixed-integer non-linear problem (MINLP) to minimize excess load and the improve the utility (benefit) across all devices. We propose an online distributed low-complexity heuristic that prioritizes devices based on demand and deadlines to minimize the cumulative loss in utility. The proposed heuristic is tested on an exhaustive set of synthetic data and compared with solutions from a solver/optimization tool for the same runtime to show the impracticality of using a solver. A real-world EV testbed data is also tested with our proposed solution and other scheduling solutions to show the practicality of generating a feasible schedule and a loss improvement of at least 57.23%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14293v2</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>10.1109/SmartGridComm51999.2021.9632317</arxiv:journal_reference>
      <dc:creator>Nitin Shivaraman, Jakob Fittler, Saravanan Ramanathan, Arvind Easwaran, Sebastian Steinhorst</dc:creator>
    </item>
    <item>
      <title>Memory-augmented Transformers can implement Linear First-Order Optimization Methods</title>
      <link>https://arxiv.org/abs/2410.07263</link>
      <description>arXiv:2410.07263v2 Announce Type: replace-cross 
Abstract: We show that memory-augmented Transformers (Memformers) can implement linear first-order optimization methods such as conjugate gradient descent, momentum methods, and more generally, methods that linearly combine past gradients. Building on prior work that demonstrates how Transformers can simulate preconditioned gradient descent, we provide theoretical and empirical evidence that Memformers can learn more advanced optimization algorithms. Specifically, we analyze how memory registers in Memformers store suitable intermediate attention values allowing them to implement algorithms such as conjugate gradient. Our results show that Memformers can efficiently learn these methods by training on random linear regression tasks, even learning methods that outperform conjugate gradient. This work extends our knowledge about the algorithmic capabilities of Transformers, showing how they can learn complex optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07263v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchayan Dutta (UC Davis), Suvrit Sra (TU Munich)</dc:creator>
    </item>
    <item>
      <title>Distributed Thompson sampling under constrained communication</title>
      <link>https://arxiv.org/abs/2410.15543</link>
      <description>arXiv:2410.15543v2 Announce Type: replace-cross 
Abstract: In Bayesian optimization, a black-box function is maximized via the use of a surrogate model. We apply distributed Thompson sampling, using a Gaussian process as a surrogate model, to approach the multi-agent Bayesian optimization problem. In our distributed Thompson sampling implementation, each agent receives sampled points from neighbors, where the communication network is encoded in a graph; each agent utilizes their own Gaussian process to model the objective function. We demonstrate theoretical bounds on Bayesian simple regret and Bayesian average regret, where the bound depends on the structure of the communication graph. Unlike in batch Bayesian optimization, this bound is applicable in cases where the communication graph amongst agents is constrained. When compared to sequential single-agent Thompson sampling, our bound guarantees faster convergence with respect to time as long as the communication graph is connected. We confirm the efficacy of our algorithm with numerical simulations on traditional optimization test functions, illustrating the significance of graph connectivity on improving regret convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15543v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saba Zerefa, Zhaolin Ren, Haitong Ma, Na Li</dc:creator>
    </item>
    <item>
      <title>On the Crucial Role of Initialization for Matrix Factorization</title>
      <link>https://arxiv.org/abs/2410.18965</link>
      <description>arXiv:2410.18965v2 Announce Type: replace-cross 
Abstract: This work revisits the classical low-rank matrix factorization problem and unveils the critical role of initialization in shaping convergence rates for such nonconvex and nonsmooth optimization. We introduce Nystrom initialization, which significantly improves the global convergence of Scaled Gradient Descent (ScaledGD) in both symmetric and asymmetric matrix factorization tasks. Specifically, we prove that ScaledGD with Nystrom initialization achieves quadratic convergence in cases where only linear rates were previously known. Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly used for finetuning foundation models. Our approach, NoRA, i.e., LoRA with Nystrom initialization, demonstrates superior performance across various downstream tasks and model scales, from 1B to 7B parameters, in large language and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18965v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bingcong Li, Liang Zhang, Aryan Mokhtari, Niao He</dc:creator>
    </item>
    <item>
      <title>Anytime Acceleration of Gradient Descent</title>
      <link>https://arxiv.org/abs/2411.17668</link>
      <description>arXiv:2411.17668v2 Announce Type: replace-cross 
Abstract: This work investigates stepsize-based acceleration of gradient descent with {\em anytime} convergence guarantees. For smooth (non-strongly) convex optimization, we propose a stepsize schedule that allows gradient descent to achieve convergence guarantees of $O(T^{-1.119})$ for any stopping time $T$, where the stepsize schedule is predetermined without prior knowledge of the stopping time. This result provides an affirmative answer to a COLT open problem \citep{kornowski2024open} regarding whether stepsize-based acceleration can yield anytime convergence rates of $o(T^{-1})$. We further extend our theory to yield anytime convergence guarantees of $\exp(-\Omega(T/\kappa^{0.893}))$ for smooth and strongly convex optimization, with $\kappa$ being the condition number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17668v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihan Zhang, Jason D. Lee, Simon S. Du, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Singular mean-field backward stochastic Volterra integral equations in infinite dimensional spaces</title>
      <link>https://arxiv.org/abs/2411.19433</link>
      <description>arXiv:2411.19433v2 Announce Type: replace-cross 
Abstract: This paper investigates the well-posedness of singular mean-field backward stochastic Volterra integral equations (MF-BSVIEs) in infinite-dimensional spaces. We consider the equation:
  \[X(t) = \Psi(t) + \int_t^b P\big(t, s, X(s), \aleph(t, s), \aleph(s, t), \mathbb{E}[X(s)], \mathbb{E}[\aleph(t, s)], \mathbb{E}[\aleph(s, t)]\big) ds - \int_t^b \aleph(t, s) dB_s, \]
  where the focus lies on establishing the existence and uniqueness of adapted M-solutions under appropriate conditions. A key contribution of this work is the development of essential lemmas that provide a rigorous foundation for analyzing the well-posedness of these equations. In addition, we extend our analysis to singular mean-field forward stochastic Volterra integral equations (MF-FSVIEs) in infinite-dimensional spaces, demonstrating their solvability and unique adapted solutions. Finally, we strengthen our theoretical results by applying them to derive stochastic maximum principles, showcasing the practical relevance of the proposed framework. These findings contribute to the growing body of research on mean-field stochastic equations and their applications in control theory and mathematical finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19433v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>FairML: A Julia Package for Fair Classification</title>
      <link>https://arxiv.org/abs/2412.01585</link>
      <description>arXiv:2412.01585v3 Announce Type: replace-cross 
Abstract: In this paper, we propose FairML.jl, a Julia package providing a framework for fair classification in machine learning. In this framework, the fair learning process is divided into three stages. Each stage aims to reduce unfairness, such as disparate impact and disparate mistreatment, in the final prediction. For the preprocessing stage, we present a resampling method that addresses unfairness coming from data imbalances. The in-processing phase consist of a classification method. This can be either one coming from the MLJ.jl package, or a user defined one. For this phase, we incorporate fair ML methods that can handle unfairness to a certain degree through their optimization process. In the post-processing, we discuss the choice of the cut-off value for fair prediction. With simulations, we show the performance of the single phases and their combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01585v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Pablo Burgard, Jo\~ao Vitor Pamplona</dc:creator>
    </item>
  </channel>
</rss>
