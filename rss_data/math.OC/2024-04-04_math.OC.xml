<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Apr 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Tricks from the Trade for Large-Scale Markdown Pricing: Heuristic Cut Generation for Lagrangian Decomposition</title>
      <link>https://arxiv.org/abs/2404.02996</link>
      <description>arXiv:2404.02996v1 Announce Type: new 
Abstract: In automated decision making processes in the online fashion industry, the 'predict-then-optimize' paradigm is frequently applied, particularly for markdown pricing strategies. This typically involves a mixed-integer optimization step, which is crucial for maximizing profit and merchandise volume. In practice, the size and complexity of the optimization problem is prohibitive for using off-the-shelf solvers for mixed integer programs and specifically tailored approaches are a necessity. Our paper introduces specific heuristics designed to work alongside decomposition methods, leading to almost-optimal solutions. These heuristics, which include both primal heuristic methods and a cutting plane generation technique within a Lagrangian decomposition framework, are the core focus of the present paper. We provide empirical evidence for their effectiveness, drawing on real-world applications at Zalando SE, one of Europe's leading online fashion retailers, highlighting the practical value of our work. The contributions of this paper are deeply ingrained into Zalando's production environment to its large-scale catalog ranging in the millions of products and improving weekly profits by millions of Euros.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02996v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Streeck, Torsten Gellert, Andreas Schmitt, Asya Dipkaya, Vladimir Fux, Tim Januschowski, Timo Berthold</dc:creator>
    </item>
    <item>
      <title>Global Convergence of High-Order Regularization Methods with Sums-of-Squares Taylor Models</title>
      <link>https://arxiv.org/abs/2404.03035</link>
      <description>arXiv:2404.03035v1 Announce Type: new 
Abstract: High-order tensor methods that employ Taylor-based local models (of degree $p\ge 3$) within adaptive regularization frameworks have been recently proposed for both convex and nonconvex optimization problems. They have been shown to have superior, and even optimal, worst-case global convergence rates and local rates compared to Newton's method. Finding rigorous and efficient techniques for minimizing the Taylor polynomial sub-problems remains a challenging aspect for these algorithms. Ahmadi et al. recently introduced a tensor method based on sum-of-squares (SoS) reformulations, so that each Taylor polynomial sub-problem in their approach can be tractably minimized using semidefinite programming (SDP); however, the global convergence and complexity of their method have not been addressed for general nonconvex problems. This paper introduces an algorithmic framework that combines the Sum of Squares (SoS) Taylor model with adaptive regularization techniques for nonconvex smooth optimization problems. Each iteration minimizes an SoS Taylor model, offering a polynomial cost per iteration. For general nonconvex functions, the worst-case evaluation complexity bound is $\mathcal{O}(\epsilon^{-2})$, while for strongly convex functions, an improved evaluation complexity bound of $\mathcal{O}(\epsilon^{-\frac{1}{p}})$ is established. To the best of our knowledge, this is the first global rate analysis for an adaptive regularization algorithm with a tractable high-order sub-problem in nonconvex smooth optimization, opening the way for further improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03035v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenqi Zhu, Coralia Cartis</dc:creator>
    </item>
    <item>
      <title>The circle packing problem: a theoretical comparison of various convexification techniques</title>
      <link>https://arxiv.org/abs/2404.03091</link>
      <description>arXiv:2404.03091v1 Announce Type: new 
Abstract: We consider the problem of packing congruent circles with the maximum radius in a unit square as a mathematical optimization problem. Due to the presence of non-overlapping constraints, this problem is a notoriously difficult nonconvex quadratically constrained optimization problem, which possesses many local optima. We consider several popular convexification techniques, giving rise to linear programming relaxations and semidefinite programming relaxations for the circle packing problem. We compare the strength of these relaxations theoretically, thereby proving the conjectures by Anstreicher (JOGO, 2009). Our results serve as a theoretical justification for the ineffectiveness of existing machinery for convexification of non-overlapping constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03091v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aida Khajavirad</dc:creator>
    </item>
    <item>
      <title>Robust Partitioning and Operation for Maximal Uncertain-Load Delivery in Distribution Grids</title>
      <link>https://arxiv.org/abs/2404.03137</link>
      <description>arXiv:2404.03137v1 Announce Type: new 
Abstract: To mitigate the vulnerability of distribution grids to severe weather events, some electric utilities use preemptive de-energization as the primary line of defense, causing significant power outages. In such instances, networked microgrids could improve resiliency and maximize load delivery, though the modeling of three-phase unbalanced network physics and computational complexity pose challenges. These challenges are further exacerbated by an increased penetration of uncertain loads. In this paper, we present a two-stage mixed-integer robust optimization problem that configures and operates networked microgrids, and is guaranteed to be robust and feasible to all realizations of loads within a specified uncertainty set, while maximizing load delivery. To solve this problem, we propose a cutting-plane algorithm, with convergence guarantees, which approximates a convex recourse function with sub-gradient cuts. Finally, we provide a detailed case study on the IEEE 37-bus test system to demonstrate the economic benefits of networking microgrids to maximize uncertain-load delivery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03137v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hannah Moring, Harsha Nagarajan, Kshitij Girigoudar, David M. Fobes, Johanna L. Mathieu</dc:creator>
    </item>
    <item>
      <title>Run your HPC jobs in Eco-Mode: revealing the potential of user-assisted power capping in supercomputing systems</title>
      <link>https://arxiv.org/abs/2404.03271</link>
      <description>arXiv:2404.03271v1 Announce Type: new 
Abstract: The energy consumption of an exascale High-Performance Computing (HPC) supercomputer rivals that of tens of thousands of people in terms of electricity demand. Given the substantial energy footprint of exascale HPC systems and the increasing strain on power grids due to climate-related events, electricity providers are starting to impose power caps during critical periods to their users. In this context, it becomes crucial to implement strategies that manage the power consumption of supercomputers while simultaneously ensuring their uninterrupted operation.This paper investigates the proposition that HPC users can willingly sacrifice some processing performance to contribute to a global energy-saving initiative. With the objective of offering an efficient energy-saving strategy by involving users, we introduce a user-assisted supercomputer power-capping methodology. In this approach, users have the option to voluntarily permit their applications to operate in a power-capped mode, denoted as 'Eco-Mode', as necessary. Leveraging HPC simulations, along with energy traces and application metadata derived from a recent Top500 HPC supercomputer, we conducted an experimental campaign to quantify the effects of Eco-Mode on energy conservation and on user experience. Specifically, our study aimed to demonstrate that, with a sufficient number of users choosing Eco-Mode, the supercomputer maintains good performances within the specified power cap. Furthermore, we sought to determine the optimal conditions regarding the number of users embracing Eco-Mode and the magnitude of power capping required for applications (i.e., the intensity of Eco-Mode). Our findings indicate that decreasing the speed of jobs can decrease significantly the number of jobs that must be killed. Moreover, as the adoption of Eco-Mode increases among users, the likelihood of every job to be killed also decreases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03271v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luc Angelelli (UGA, CNRS, Inria, Grenoble INP, LIG), Danilo Carastan-Santos (UGA, CNRS, Inria, Grenoble INP, LIG), Pierre-Fran\c{c}ois Dutot (UGA, CNRS, Inria, Grenoble INP, LIG)</dc:creator>
    </item>
    <item>
      <title>Improving Patient Transport in Hospitals: A Literature Review of Operations Research Methods</title>
      <link>https://arxiv.org/abs/2404.03282</link>
      <description>arXiv:2404.03282v1 Announce Type: new 
Abstract: Most activities in hospitals require the presence of the patient. Delays in patient transport can therefore cause disruptions and costly downtime in many different areas and departments, which makes patient transport planning a central operational problem in hospitals. This paper provides the first literature review of Operations Research approaches for improving non-emergency patient transport in hospitals. We structure the different patient transport problems considered in the literature according to several main characteristics and introduce a four-field notation for patient transport problems that allows for a concise representation of different problem variants. We then analyze the relevant literature with respect to different aspects related to the considered problem variant, the employed modeling and solution techniques, as well as the data used and the level of practical implementation achieved. Based on our literature analysis and semi-structured interviews with hospital practitioners, we provide a comparison of current hospital practice and the existing literature on patient transport, and we identify research gaps and formulate an agenda for relevant future research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03282v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Lorenz Klein, Clemens Thielen</dc:creator>
    </item>
    <item>
      <title>LancBiO: dynamic Lanczos-aided bilevel optimization via Krylov subspace</title>
      <link>https://arxiv.org/abs/2404.03331</link>
      <description>arXiv:2404.03331v1 Announce Type: new 
Abstract: Bilevel optimization, with broad applications in machine learning, has an intricate hierarchical structure. Gradient-based methods have emerged as a common approach to large-scale bilevel problems. However, the computation of the hyper-gradient, which involves a Hessian inverse vector product, confines the efficiency and is regarded as a bottleneck. To circumvent the inverse, we construct a sequence of low-dimensional approximate Krylov subspaces with the aid of the Lanczos process. As a result, the constructed subspace is able to dynamically and incrementally approximate the Hessian inverse vector product with less effort and thus leads to a favorable estimate of the hyper-gradient. Moreover, we propose a~provable subspace-based framework for bilevel problems where one central step is to solve a small-size tridiagonal linear system. To the best of our knowledge, this is the first time that subspace techniques are incorporated into bilevel optimization. This successful trial not only enjoys $\mathcal{O}(\epsilon^{-1})$ convergence rate but also demonstrates efficiency in a synthetic problem and two deep learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03331v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Yan Yang, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Fast Computation of Robust Dynamic Operating Envelopes Based on Non-convex OPF for Unbalanced Distribution Networks</title>
      <link>https://arxiv.org/abs/2404.03355</link>
      <description>arXiv:2404.03355v1 Announce Type: new 
Abstract: Robust dynamic operating envelopes (RDOEs) solve the problem of secure allocation of latent network capacity to flexible distributed energy resources (DER) in unbalanced distribution networks. As the computational complexity of RDOEs is much higher than that of DOEs, which disregard uncertainties in network parameters and DER capacity utilisation, existing approaches to computing RDOEs have relied on linearised unbalanced three-phase optimal power flow (UTOPF) models to numerate the network feasible region approximately. The use of linearised models, however, risks producing RDOEs that undermine network integrity due to inherent errors in the approximation. This letter presents a practical sensitivity-filtering technique to simplify RDOE numerical computation based on non-convex UTOPF formulations. The accuracy and efficiency of the proposed approach are demonstrated on RDOE allocation with various fairness metrics by testing on representative Australian distribution networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03355v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bin Liu, Julio H. Braslavsky</dc:creator>
    </item>
    <item>
      <title>The Nearest Graph Laplacian in Frobenius Norm</title>
      <link>https://arxiv.org/abs/2404.03371</link>
      <description>arXiv:2404.03371v1 Announce Type: new 
Abstract: We address the problem of finding the nearest graph Laplacian to a given matrix, with the distance measured using the Frobenius norm. Specifically, for the directed graph Laplacian, we propose two novel algorithms by reformulating the problem as convex quadratic optimization problems with a special structure: one based on the active set method and the other on direct computation of Karush-Kuhn-Tucker (KKT) points. The proposed algorithms can be applied to system identification and model reduction problems involving Laplacian dynamics. We demonstrate that these algorithms possess lower time complexities and the finite termination property, unlike the interior point method and V-FISTA, the latter of which is an accelerated projected gradient method. Our numerical experiments confirm the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03371v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuhiro Sato, Masato Suzuki</dc:creator>
    </item>
    <item>
      <title>Elementary Analysis of Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2404.03372</link>
      <description>arXiv:2404.03372v1 Announce Type: new 
Abstract: Projected policy gradient under the simplex parameterization, policy gradient and natural policy gradient under the softmax parameterization, are fundamental algorithms in reinforcement learning. There have been a flurry of recent activities in studying these algorithms from the theoretical aspect. Despite this, their convergence behavior is still not fully understood, even given the access to exact policy evaluations. In this paper, we focus on the discounted MDP setting and conduct a systematic study of the aforementioned policy optimization methods. Several novel results are presented, including 1) global linear convergence of projected policy gradient for any constant step size, 2) sublinear convergence of softmax policy gradient for any constant step size, 3) global linear convergence of softmax natural policy gradient for any constant step size, 4) global linear convergence of entropy regularized softmax policy gradient for a wider range of constant step sizes than existing result, 5) tight local linear convergence rate of entropy regularized natural policy gradient, and 6) a new and concise local quadratic convergence rate of soft policy iteration without the assumption on the stationary distribution under the optimal policy. New and elementary analysis techniques have been developed to establish these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03372v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiacai Liu, Wenye Li, Ke Wei</dc:creator>
    </item>
    <item>
      <title>A unified Euler--Lagrange system for analyzing continuous-time accelerated gradient methods</title>
      <link>https://arxiv.org/abs/2404.03383</link>
      <description>arXiv:2404.03383v1 Announce Type: new 
Abstract: This paper presents an Euler--Lagrange system for a continuous-time model of the accelerated gradient methods in smooth convex optimization and proposes an associated Lyapunov-function-based convergence analysis framework. Recently, ordinary differential equations (ODEs) with dumping terms have been developed to intuitively interpret the accelerated gradient methods, and the design of unified model describing the various individual ODE models have been examined. In existing reports, the Lagrangian, which results in the Euler-Lagrange equation, and the Lyapunov function for the convergence analysis have been separately proposed for each ODE. This paper proposes a unified Euler--Lagrange system and its Lyapunov function to cover the existing various models. In the convergence analysis using the Lyapunov function, a condition that parameters in the Lagrangian and Lyapunov function must satisfy is derived, and a parameter design for improving the convergence rate naturally results in the mysterious dumping coefficients. Especially, a symmetric Bregman divergence can lead to a relaxed condition of the parameters and a resulting improved convergence rate. As an application of this study, a slight modification in the Lyapunov function establishes the similar convergence proof for ODEs with smooth approximation in nondifferentiable objective function minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03383v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsuru Toyoda, Akatsuki Nishioka, Mirai Tanaka</dc:creator>
    </item>
    <item>
      <title>Exponential decay of solutions to linear evolution equations with time-dependent time delay</title>
      <link>https://arxiv.org/abs/2404.03467</link>
      <description>arXiv:2404.03467v1 Announce Type: new 
Abstract: In this note, we analyze an abstract evolution equation with time-dependent time delay and time-dependent delay feedback coefficient. We assume that the operator corresponding to the nondelayed part of the model generates an exponentially stable semigroup. Under an appropriate assumption on the delay feedback, we prove the well-posedness and an exponential stability estimate for our model. Applications of our abstract results to concrete models are also illustrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03467v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisa Continelli, Cristina Pignotti</dc:creator>
    </item>
    <item>
      <title>Hub Network Design Problem with Capacity, Congestion and Heterogeneous Economies of Scale</title>
      <link>https://arxiv.org/abs/2404.03521</link>
      <description>arXiv:2404.03521v1 Announce Type: new 
Abstract: We propose a joint model that links the strategic level location and capacity decisions with the operational level routing and hub assignment decisions to solve hub network design problem with congestion and heterogeneous economics of scale. We also develop a novel flow-based mixed-integer second-order cone programming (MISOCP) formulation. We perform numerical experiments on a real-world data set to validate the efficiency of solving the MISOCP reformulation. The numerical studies yield observations can be used as guidelines in the design of transportation network for a logistics company.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03521v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotong Liu</dc:creator>
    </item>
    <item>
      <title>On the penalization by the perimeter in shape optimization applied to Dirichlet inverse obstacle problem</title>
      <link>https://arxiv.org/abs/2404.03536</link>
      <description>arXiv:2404.03536v1 Announce Type: new 
Abstract: This paper is devoted to the understanding of regularisation process in the shape optimization approach to the so-called Dirichlet inverse obstacle problem for elliptic operators. More precisely, we study two different regularisations of the very classical shape optimization approach consisting in minimizing a mismatched functional. The first one is an implicit regularisation when working in the class of inclusion having a uniform $\varepsilon$-cone property, a natural class in shape optimization. As this regularity is not trivial to guarantee numerically, we discuss the regularisation by perimeter penalization. We show that this second regularisation provides a stability gain in the minimization process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03536v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fabien Caubet, Marc Dambrine, J\'er\'emi Dard\'e</dc:creator>
    </item>
    <item>
      <title>A Unified Algorithmic Framework for Dynamic Assortment Optimization under MNL Choice</title>
      <link>https://arxiv.org/abs/2404.03604</link>
      <description>arXiv:2404.03604v1 Announce Type: new 
Abstract: We consider assortment and inventory planning problems with dynamic stockout-based substitution effects and no replenishment. We consider two settings: 1. Customers can see all available products when they arrive, which is commonly seen in physical stores. 2. The seller can choose to offer a subset of available products to each customer, which is typical on online platforms. Both settings are known to be computationally challenging, and the current approximation algorithms for the two settings are quite different. We develop a unified algorithm framework under the MNL choice model for both settings. Our algorithms improve on the state-of-the-art algorithms in terms of approximation guarantee, runtime, and the ability to manage uncertainty in the total number of customers and handle more complex constraints. In the process, we establish various novel properties of dynamic assortment planning (under the MNL choice) that may be useful more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03604v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Sun (Max), Rajan Udwani (Max),  Zuo-Jun (Max),  Shen</dc:creator>
    </item>
    <item>
      <title>Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra</title>
      <link>https://arxiv.org/abs/2404.03647</link>
      <description>arXiv:2404.03647v1 Announce Type: new 
Abstract: In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving undergraduate-level control problems. Controls provides an interesting case study for LLM reasoning due to its combination of mathematical theory and engineering design. We introduce ControlBench, a benchmark dataset tailored to reflect the breadth, depth, and complexity of classical control design. We use this dataset to study and evaluate the problem-solving abilities of these LLMs in the context of control engineering. We present evaluations conducted by a panel of human experts, providing insights into the accuracy, reasoning, and explanatory prowess of LLMs in control engineering. Our analysis reveals the strengths and limitations of each LLM in the context of classical control, and our results imply that Claude 3 Opus has become the state-of-the-art LLM for solving undergraduate control problems. Our study serves as an initial step towards the broader goal of employing artificial general intelligence in control engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03647v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darioush Kevian, Usman Syed, Xingang Guo, Aaron Havens, Geir Dullerud, Peter Seiler, Lianhui Qin, Bin Hu</dc:creator>
    </item>
    <item>
      <title>The Camel-Banana Problem</title>
      <link>https://arxiv.org/abs/2403.19667</link>
      <description>arXiv:2403.19667v2 Announce Type: cross 
Abstract: A camel can carry one banana at a time on its back. It is on a diet and therefore can only have one banana at a time in its stomach. As soon as it has eaten a banana it walks a mile and then it needs a new banana (in order to be able to continue its itinerary). Let there be a stock of N bananas at the border of the desert. How far can the camel penetrate into the desert, starting at this point? (Of course it can form new stocks with transported bananas.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19667v2</guid>
      <category>math.HO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Nieuw Archief voor Wiskunde, Vierde serie, Deel 14, No. 3 november 1996, pp. 415--426</arxiv:journal_reference>
      <dc:creator>Michiel de Bondt</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Policy and Lyapunov-Certificate Learning</title>
      <link>https://arxiv.org/abs/2404.03017</link>
      <description>arXiv:2404.03017v1 Announce Type: cross 
Abstract: This article presents novel methods for synthesizing distributionally robust stabilizing neural controllers and certificates for control systems under model uncertainty. A key challenge in designing controllers with stability guarantees for uncertain systems is the accurate determination of and adaptation to shifts in model parametric uncertainty during online deployment. We tackle this with a novel distributionally robust formulation of the Lyapunov derivative chance constraint ensuring a monotonic decrease of the Lyapunov certificate. To avoid the computational complexity involved in dealing with the space of probability measures, we identify a sufficient condition in the form of deterministic convex constraints that ensures the Lyapunov derivative constraint is satisfied. We integrate this condition into a loss function for training a neural network-based controller and show that, for the resulting closed-loop system, the global asymptotic stability of its equilibrium can be certified with high confidence, even with Out-of-Distribution (OoD) model uncertainties. To demonstrate the efficacy and efficiency of the proposed methodology, we compare it with an uncertainty-agnostic baseline approach and several reinforcement learning approaches in two control problems in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03017v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehan Long, Jorge Cortes, Nikolay Atanasov</dc:creator>
    </item>
    <item>
      <title>PowerSimulations.jl -- A Power Systems operations simulation Library</title>
      <link>https://arxiv.org/abs/2404.03074</link>
      <description>arXiv:2404.03074v1 Announce Type: cross 
Abstract: PowerSimulations.jl is a Julia-based BSD-licensed power system operations simulation tool developed as a flexible and open source software for quasi-static power systems simulations including Production Cost Models. PowerSimulations.jl tackles the issues of developing a simulation model in a modular way providing tools for the formulation of decision models and emulation models that can be solved independently or in an interconnected fashion. This paper discusses the software implementation of PowerSimulations.jl as a template for the development and implementation of operation simulators, providing solutions to commonly encountered issues like time series read/write and results sharing between models. The paper includes a publicly-available validation of classical operations simulations as well as examples of the advanced features of the software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03074v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Daniel Lara, Clayton Barrows, Daniel Thom, Sourabh Dalvi, Duncan S. Callaway, Dheepak Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Low Frequency Sampling in Model Predictive Path Integral Control</title>
      <link>https://arxiv.org/abs/2404.03094</link>
      <description>arXiv:2404.03094v1 Announce Type: cross 
Abstract: Sampling-based model-predictive controllers have become a powerful optimization tool for planning and control problems in various challenging environments. In this paper, we show how the default choice of uncorrelated Gaussian distributions can be improved upon with the use of a colored noise distribution. Our choice of distribution allows for the emphasis on low frequency control signals, which can result in smoother and more exploratory samples. We use this frequency-based sampling distribution with Model Predictive Path Integral (MPPI) in both hardware and simulation experiments to show better or equal performance on systems with various speeds of input response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03094v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bogdan Vlahov, Jason Gibson, David D. Fan, Patrick Spieler, Ali-akbar Agha-mohammadi, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>Methodology for Interpretable Reinforcement Learning for Optimizing Mechanical Ventilation</title>
      <link>https://arxiv.org/abs/2404.03105</link>
      <description>arXiv:2404.03105v1 Announce Type: cross 
Abstract: Mechanical ventilation is a critical life-support intervention that uses a machine to deliver controlled air and oxygen to a patient's lungs, assisting or replacing spontaneous breathing. While several data-driven approaches have been proposed to optimize ventilator control strategies, they often lack interpretability and agreement with general domain knowledge. This paper proposes a methodology for interpretable reinforcement learning (RL) using decision trees for mechanical ventilation control. Using a causal, nonparametric model-based off-policy evaluation, we evaluate the policies in their ability to gain increases in SpO2 while avoiding aggressive ventilator settings which are known to cause ventilator induced lung injuries and other complications. Numerical experiments using MIMIC-III data on the stays of real patients' intensive care unit stays demonstrate that the decision tree policy outperforms the behavior cloning policy and is comparable to state-of-the-art RL policy. Future work concerns better aligning the cost function with medical objectives to generate deeper clinical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03105v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joo Seung Lee, Malini Mahendra, Anil Aswani</dc:creator>
    </item>
    <item>
      <title>An adaptive heavy ball method for ill-posed inverse problems</title>
      <link>https://arxiv.org/abs/2404.03218</link>
      <description>arXiv:2404.03218v1 Announce Type: cross 
Abstract: In this paper we consider ill-posed inverse problems, both linear and nonlinear, by a heavy ball method in which a strongly convex regularization function is incorporated to detect the feature of the sought solution. We develop ideas on how to adaptively choose the step-sizes and the momentum coefficients to achieve acceleration over the Landweber-type method. We then analyze the method and establish its regularization property when it is terminated by the discrepancy principle. Various numerical results are reported which demonstrate the superior performance of our method over the Landweber-type method by reducing substantially the required number of iterations and the computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03218v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinian Jin, Qin Huang</dc:creator>
    </item>
    <item>
      <title>Learning-to-Optimize with PAC-Bayesian Guarantees: Theoretical Considerations and Practical Implementation</title>
      <link>https://arxiv.org/abs/2404.03290</link>
      <description>arXiv:2404.03290v1 Announce Type: cross 
Abstract: We use the PAC-Bayesian theory for the setting of learning-to-optimize. To the best of our knowledge, we present the first framework to learn optimization algorithms with provable generalization guarantees (PAC-Bayesian bounds) and explicit trade-off between convergence guarantees and convergence speed, which contrasts with the typical worst-case analysis. Our learned optimization algorithms provably outperform related ones derived from a (deterministic) worst-case analysis. The results rely on PAC-Bayesian bounds for general, possibly unbounded loss-functions based on exponential families. Then, we reformulate the learning procedure into a one-dimensional minimization problem and study the possibility to find a global minimum. Furthermore, we provide a concrete algorithmic realization of the framework and new methodologies for learning-to-optimize, and we conduct four practically relevant experiments to support our theory. With this, we showcase that the provided learning framework yields optimization algorithms that provably outperform the state-of-the-art by orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03290v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Sucker, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Optimistic Online Non-stochastic Control via FTRL</title>
      <link>https://arxiv.org/abs/2404.03309</link>
      <description>arXiv:2404.03309v1 Announce Type: cross 
Abstract: This paper brings the concept of "optimism" to the new and promising framework of online Non-stochastic Control (NSC). Namely, we study how can NSC benefit from a prediction oracle of unknown quality responsible for forecasting future costs. The posed problem is first reduced to an optimistic learning with delayed feedback problem, which is handled through the Optimistic Follow the Regularized Leader (OFTRL) algorithmic family. This reduction enables the design of OptFTRL-C, the first Disturbance Action Controller (DAC) with optimistic policy regret bounds. These new bounds are commensurate with the oracle's accuracy, ranging from $\mathcal{O}(1)$ for perfect predictions to the order-optimal $\mathcal{O}(\sqrt{T})$ even when all predictions fail. By addressing the challenge of incorporating untrusted predictions into control systems, our work contributes to the advancement of the NSC framework and paves the way towards effective and robust learning-based controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03309v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naram Mhaisen, George Iosifidis</dc:creator>
    </item>
    <item>
      <title>Setpoint control of bilinear systems from noisy data</title>
      <link>https://arxiv.org/abs/2404.03594</link>
      <description>arXiv:2404.03594v1 Announce Type: cross 
Abstract: We consider the problem of designing a controller for an unknown bilinear system using only noisy input-states data points generated by it. The controller should achieve regulation to a given state setpoint and provide a guaranteed basin of attraction. Determining the equilibrium input to achieve that setpoint is not trivial in a data-based setting and we propose the design of a controller in two scenarios. The design takes the form of linear matrix inequalities and is validated numerically for a Cuk converter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03594v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Bisoffi, Dominiek M. Steeman, Claudio De Persis</dc:creator>
    </item>
    <item>
      <title>Deriving Compact QUBO Models via Multilevel Constraint Transformation</title>
      <link>https://arxiv.org/abs/2404.03610</link>
      <description>arXiv:2404.03610v1 Announce Type: cross 
Abstract: With the advances in customized hardware for quantum annealing and digital/CMOS Annealing, Quadratic Unconstrained Binary Optimization (QUBO) models have received growing attention in the optimization literature. Motivated by an existing general-purpose approach that derives QUBO models from binary linear programs (BLP), we propose a novel Multilevel Constraint Transformation Scheme (MLCTS) that derives QUBO models with fewer ancillary binary variables. We formulate sufficient conditions for the existence of a compact QUBO formulation (i.e., in the original BLP decision space) in terms of constraint levelness and demonstrate the flexibility and applicability of MLCTS on synthetic examples and several well-known combinatorial optimization problems, i.e., the Maximum 2-Satisfiability Problem, the Linear Ordering Problem, the Community Detection Problem, and the Maximum Independence Set Problem. For a proof-of-concept, we compare the performance of two QUBO models for the latter problem on both a general-purpose software-based solver and a hardware-based QUBO solver. The MLCTS-derived models demonstrate significantly better performance for both solvers, in particular, solving up to seven times more instances with the hardware-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03610v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oksana Pichugina, Yingcong Tan, Christopher Beck</dc:creator>
    </item>
    <item>
      <title>A Multilevel Method for Self-Concordant Minimization</title>
      <link>https://arxiv.org/abs/2106.13690</link>
      <description>arXiv:2106.13690v2 Announce Type: replace 
Abstract: The analysis of second-order optimization methods based either on sub-sampling, randomization or sketching has two serious shortcomings compared to the conventional Newton method. The first shortcoming is that the analysis of the iterates has only been shown to be scale-invariant only under specific assumptions on the problem structure. The second shortfall is that the fast convergence rates of second-order methods have only been established by making assumptions regarding the input data. In this paper, we propose a randomized Newton method for self-concordant functions to address both shortfalls. We propose a Self-concordant Iterative-minimization-Galerkin-based Multilevel Algorithm (SIGMA) and establish its super-linear convergence rate using the theory of self-concordant functions. Our analysis is based on the connections between multigrid optimization methods, and the role of coarse-grained or reduced-order models in the computation of search directions. We take advantage of the insights from theanalysis to significantly improve the performance of second-order methods in machine learning applications. We report encouraging initial experiments that suggest SIGMA outperforms other state-of-the-art sub-sampled/sketched Newton methods for both medium and large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.13690v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Tsipinakis, Panos Parpas</dc:creator>
    </item>
    <item>
      <title>Ergodic control of a heterogeneous population and application to electricity pricing</title>
      <link>https://arxiv.org/abs/2204.01410</link>
      <description>arXiv:2204.01410v3 Announce Type: replace 
Abstract: We consider a control problem for a heterogeneous population composed of agents able to switch at any time between different options. The controller aims to maximize an average gain per time unit, supposing that the population is of infinite size. This leads to an ergodic control problem for a "mean-field" Markov Decision Process in which the state space is a product of simplices, and the population evolves according to controlled linear dynamics. By exploiting contraction properties of the dynamics in Hilbert's projective metric, we prove that the infinite-dimensional ergodic eigenproblem admits a solution and show that the latter is in general non unique. This allows us to obtain optimal strategies, and to quantify the gap between steady-state strategies and optimal ones. In particular, we prove in the one-dimensional case that there exist cyclic policies -- alternating between discount and profit taking stages -- which secure a greater gain than constant-price policies. On numerical aspects, we develop a policy iteration algorithm with "on-the-fly" generated transitions, specifically adapted to decomposable models, leading to substantial memory savings. We finally apply our results on realistic instances coming from an electricity pricing problem encountered in the retail markets, and numerically observe the emergence of cyclic promotions for sufficient inertia in the customer behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.01410v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Jacquet (EDF R\&amp;D OSIRIS, TROPICAL), Wim van Ackooij (EDF R\&amp;D OSIRIS), Cl\'emence Alasseur (EDF R\&amp;D OSIRIS), St\'ephane Gaubert (TROPICAL)</dc:creator>
    </item>
    <item>
      <title>A unifying view on the irreversible investment exercise boundary in a stochastic, time-inhomogeneous capacity expansion problem</title>
      <link>https://arxiv.org/abs/2209.09878</link>
      <description>arXiv:2209.09878v2 Announce Type: replace 
Abstract: Aiming at studying the investment exercise boundary, this paper devises a way to apply the Bank and El Karoui Representation Theorem to a quite general stochastic, continuous time capacity expansion problem with irreversible investment on the finite time interval and including a state dependent scrap value associated with the production facility at the terminal time T. The capacity process is a time-inhomogeneous diffusion in which a monotone non-decreasing, possibly singular, control process representing the cumulative investment enters additively. The functional to be maximized admits a supergradient, hence the optimal control satisfies some first order conditions which are solved by means of the Bank and El Karoui Representation Theorem. Its application in the case of non-zero scrap value at time T is not obvious and, as far as we know, it is new in the literature on singular stochastic control. In fact, due to the scrap value, in the supergradient appears also a non integral term. This challenge is overcome by suitably extending the horizon. The optimal investment process is shown to become active at the so-called base capacity level, given in terms of the optional solution of the Representation Theorem. Contrary to what happens in the no scrap value case, here the base capacity depends on the initial capacity y. Hence, a priori, it is not clear if and how it is related to the investment exercise boundary associated to the capacity expansion problem. Under the assumption of deterministic coefficients, discount factor, conversion factor, wage rate and interest rate, the investment boundary is shown to coincide with the base capacity. Therefore, unifying views, the base capacity is deterministic and independent of y, and its integral equation may be used to characterize the investment boundary, without any a priori regularity of it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.09878v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria B. Chiarolla</dc:creator>
    </item>
    <item>
      <title>Risk-Adaptive Approaches to Stochastic Optimization: A Survey</title>
      <link>https://arxiv.org/abs/2212.00856</link>
      <description>arXiv:2212.00856v3 Announce Type: replace 
Abstract: Uncertainty is prevalent in engineering design, data-driven problems, and decision making broadly. Due to inherent risk-averseness and ambiguity about assumptions, it is common to address uncertainty by formulating and solving conservative optimization models expressed using measures of risk and related concepts. We survey the rapid development of risk measures over the last quarter century. From their beginning in financial engineering, we recount the spread to nearly all areas of engineering and applied mathematics. Solidly rooted in convex analysis, risk measures furnish a general framework for handling uncertainty with significant computational and theoretical advantages. We describe the key facts, list several concrete algorithms, and provide an extensive list of references for further reading. The survey recalls connections with utility theory and distributionally robust optimization, points to emerging applications areas such as fair machine learning, and defines measures of reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00856v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Weighted structure tensor total variation for image denoising</title>
      <link>https://arxiv.org/abs/2306.10482</link>
      <description>arXiv:2306.10482v2 Announce Type: replace 
Abstract: For image denoising problems, the structure tensor total variation (STV)-based models show good performances when compared with other competing regularization approaches. However, the STV regularizer does not couple the local information of the image and may not maintain the image details. Therefore, we employ the anisotropic weighted matrix introduced in the anisotropic total variation (ATV) model to improve the STV model. By applying the weighted matrix to the discrete gradient of the patch-based Jacobian operator in STV, our proposed weighted STV (WSTV) model can effectively capture local information from images and maintain their details during the denoising process. The optimization problem in the model is solved by a fast first-order gradient projection algorithm with a complexity result of $O(1 / i^2)$. For images with different Gaussian noise levels, the experimental results demonstrate that the WSTV model can effectively improve the quality of restored images compared to other TV and STV-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10482v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiuhan Sheng, Lijuan Yang, Jingya Chang</dc:creator>
    </item>
    <item>
      <title>Imposing early and asymptotic constraints on LiGME with application to bivariate nonconvex enhancement of fused lasso models</title>
      <link>https://arxiv.org/abs/2309.14082</link>
      <description>arXiv:2309.14082v2 Announce Type: replace 
Abstract: For the constrained LiGME model, a nonconvexly regularized least squares estimation model, we present an iterative algorithm of guaranteed convergence to its globally optimal solution. The proposed algorithm can deal with two different types of constraints simultaneously. The first type constraint, called the asymptotic one, requires the limit of estimation sequence to achieve the corresponding condition. The second type constraint, called the early one, requires every vector in estimation sequence to achieve the condition. We also propose a bivariate nonconvex enhancement of fused lasso models with effective constraint for sparse piecewise constant signal estimations. (This is an improved version of [Yata and Yamada, ICASSP 2024].)</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14082v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wataru Yata, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Should Sports Professionals Consider Their Adversary's Strategy? A Case Study of Match Play in Golf</title>
      <link>https://arxiv.org/abs/2309.14403</link>
      <description>arXiv:2309.14403v2 Announce Type: replace 
Abstract: This study explores strategic considerations in professional golf's Match Play format, challenging the conventional focus on individual performance. Leveraging PGA Tour data, we investigate the impact of factoring in an adversary's strategy. Our findings suggest that while slight strategy adjustments can be advantageous in specific scenarios, the overall benefit of considering an opponent's strategy remains modest. This confirms the common wisdom in golf, reinforcing the recommendation to adhere to optimal stroke-play strategies due to challenges in obtaining precise opponent statistics. We believe that the methodology employed here could offer valuable insights into whether opponents' performances should also be considered in other two-player or team sports, such as tennis, darts, soccer, volleyball, etc. We hope that this research will pave the way for new avenues of study in these areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14403v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishad Wajge, Gautier Stauffer</dc:creator>
    </item>
    <item>
      <title>Approximating the set of Nash equilibria for convex games</title>
      <link>https://arxiv.org/abs/2310.04176</link>
      <description>arXiv:2310.04176v3 Announce Type: replace 
Abstract: In Feinstein and Rudloff (2023), it was shown that the set of Nash equilibria for any non-cooperative $N$ player game coincides with the set of Pareto optimal points of a certain vector optimization problem with non-convex ordering cone. To avoid dealing with a non-convex ordering cone, an equivalent characterization of the set of Nash equilibria as the intersection of the Pareto optimal points of $N$ multi-objective problems (i.e.\ with the natural ordering cone) is proven. So far, algorithms to compute the exact set of Pareto optimal points of a multi-objective problem exist only for the class of linear problems, which reduces the possibility of finding the true set of Nash equilibria by those algorithms to linear games only.
  In this paper, we will consider the larger class of convex games. As, typically, only approximate solutions can be computed for convex vector optimization problems, we first show, in total analogy to the result above, that the set of $\epsilon$-approximate Nash equilibria can be characterized by the intersection of $\epsilon$-approximate Pareto optimal points for $N$ convex multi-objective problems. Then, we propose an algorithm based on results from vector optimization and convex projections that allows for the computation of a set that, on one hand, contains the set of all true Nash equilibria, and is, on the other hand, contained in the set of $\epsilon$-approximate Nash equilibria. In addition to the joint convexity of the cost function for each player, this algorithm works provided the players are restricted by either shared polyhedral constraints or independent convex constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04176v3</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary Feinstein, Niklas Hey, Birgit Rudloff</dc:creator>
    </item>
    <item>
      <title>Tensor Completion via Integer Optimization</title>
      <link>https://arxiv.org/abs/2402.05141</link>
      <description>arXiv:2402.05141v2 Announce Type: replace 
Abstract: The main challenge with the tensor completion problem is a fundamental tension between computation power and the information-theoretic sample complexity rate. Past approaches either achieve the information-theoretic rate but lack practical algorithms to compute the corresponding solution, or have polynomial-time algorithms that require an exponentially-larger number of samples for low estimation error. This paper develops a novel tensor completion algorithm that resolves this tension by achieving both provable convergence (in numerical tolerance) in a linear number of oracle steps and the information-theoretic rate. Our approach formulates tensor completion as a convex optimization problem constrained using a gauge-based tensor norm, which is defined in a way that allows the use of integer linear optimization to solve linear separation problems over the unit-ball in this new norm. Adaptations based on this insight are incorporated into a Frank-Wolfe variant to build our algorithm. We show our algorithm scales-well using numerical experiments on tensors with up to ten million entries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05141v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Chen, Sukanya Kudva, Yongzheng Dai, Anil Aswani, Chen Chen</dc:creator>
    </item>
    <item>
      <title>Minimal covariance realization and system identification algorithm for a class of stochastic linear switched systems with i.i.d. switching</title>
      <link>https://arxiv.org/abs/2403.14259</link>
      <description>arXiv:2403.14259v4 Announce Type: replace 
Abstract: In this paper, we consider stochastic realization theory of Linear Switched Systems (LSS) with i.i.d. switching. We characterize minimality of stochastic LSSs and show existence and uniqueness (up to isomorphism) of minimal LSSs in innovation form. We present a realization algorithm to compute a minimal LSS in innovation form from output and input covariances. Finally, based on this realization algorithm, by replacing true covariances with empirical ones, we propose a statistically consistent system identification algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14259v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elie Rouphael, Manas Mejari, Mihaly Petreczky, Lotfi Belkoura</dc:creator>
    </item>
    <item>
      <title>Network Learning with Directional Sign Patterns</title>
      <link>https://arxiv.org/abs/2403.14915</link>
      <description>arXiv:2403.14915v2 Announce Type: replace 
Abstract: Complex systems can be effectively modeled via graphs that encode networked interactions, where relations between entities or nodes are often quantified by signed edge weights, e.g., promotion/inhibition in gene regulatory networks, or encoding political of friendship differences in social networks. However, it is often the case that only an aggregate consequence of such edge weights that characterize relations may be directly observable, as in protein expression of in gene regulatory networks. Thus, learning edge weights poses a significant challenge that is further exacerbated for intricate and large-scale networks. In this article, we address a model problem to determine the strength of sign-indefinite relations that explain marginal distributions that constitute our data. To this end, we develop a paradigm akin to that of the Schr\"odinger bridge problem and an efficient Sinkhorn type algorithm (more properly, Schr\"odinger-Fortet-Sinkhorn algorithm) that allows fast convergence to parameters that minimize a relative entropy/likelihood criterion between the sought signed adjacency matrix and a prior. The formalism that we present represents a novel generalization of the earlier Schr\"odinger formalism in that marginal computations may incorporate weights that model directionality in underlying relations, and further, that it can be extended to high-order networks -- the Schr\"odinger-Fortet-Sinkhorn algorithm that we derive is applicable all the same and allows geometric convergence to a sought sign-indefinite adjacency matrix or tensor, for high-order networks. We demonstrate our framework with synthetic and real-world examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14915v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Can Chen, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Extremality of collections of sets with respect to general perturbations</title>
      <link>https://arxiv.org/abs/2403.16511</link>
      <description>arXiv:2403.16511v2 Announce Type: replace 
Abstract: The paper proposes another extension of the extremal principle. A new extremality model involving arbitrary families of perturbations (deformations) of the given sets is studied. It generalizes the conventional model based on linear translations of the sets as well as its set-valued extensions. This approach leads to a more general and simpler version of fuzzy separation. We demonstrate the applicability of the new model to set-valued optimization problems, weakening the assumptions of the known results and streamlining their proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16511v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Duy Cuong, Alexander Y. Kruger, Nguyen Hieu Thao</dc:creator>
    </item>
    <item>
      <title>High-dimensional scaling limits and fluctuations of online least-squares SGD with smooth covariance</title>
      <link>https://arxiv.org/abs/2304.00707</link>
      <description>arXiv:2304.00707v2 Announce Type: replace-cross 
Abstract: We derive high-dimensional scaling limits and fluctuations for the online least-squares Stochastic Gradient Descent (SGD) algorithm by taking the properties of the data generating model explicitly into consideration. Our approach treats the SGD iterates as an interacting particle system, where the expected interaction is characterized by the covariance structure of the input. Assuming smoothness conditions on moments of order up to eight orders, and without explicitly assuming Gaussianity, we establish the high-dimensional scaling limits and fluctuations in the form of infinite-dimensional Ordinary Differential Equations (ODEs) or Stochastic Differential Equations (SDEs). Our results reveal a precise three-step phase transition of the iterates; it goes from being ballistic, to diffusive, and finally to purely random behavior, as the noise variance goes from low, to moderate and finally to very-high noise setting. In the low-noise setting, we further characterize the precise fluctuations of the (scaled) iterates as infinite-dimensional SDEs. We also show the existence and uniqueness of solutions to the derived limiting ODEs and SDEs. Our results have several applications, including characterization of the limiting mean-square estimation or prediction errors and their fluctuations, which can be obtained by analytically or numerically solving the limiting equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00707v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnakumar Balasubramanian, Promit Ghosal, Ye He</dc:creator>
    </item>
    <item>
      <title>Magnetic Fields with General Omnigenity</title>
      <link>https://arxiv.org/abs/2305.08026</link>
      <description>arXiv:2305.08026v3 Announce Type: replace-cross 
Abstract: Omnigenity is a desirable property of toroidal magnetic fields that ensures confinement of trapped particles. Confining charged particles is a basic requirement for any fusion power plant design, but it can be difficult to satisfy with the non-axisymmetric magnetic fields used by the stellarator approach. Every ideal magnetohydrodynamic equilibrium previously found to approximate omnigenity has been either axisymmetric, quasi-symmetric or has poloidally closed contours of magnetic field strength $B$. However, general omnigenous equilibria are a much larger design space than these subsets. A new model is presented and employed in the DESC stellarator optimization suite to represent and discover the full parameter space of omnigenous equilibria. Although exact omnigenity aside from quasi-symmetry is impossible, these results reveal that excellent particle confinement can be achieved in practice. Examples far from quasi-symmetry with poloidally, helically and toroidally closed $B$ contours are attained with DESC and shown to have low neoclassical collisional transport and fast particle losses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08026v3</guid>
      <category>physics.plasm-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1017/S0022377824000151</arxiv:DOI>
      <arxiv:journal_reference>Journal of Plasma Physics 90, no. 1 (2024): 905900120</arxiv:journal_reference>
      <dc:creator>Daniel W. Dudt, Alan G. Goodman, Rory Conlin, Dario Panici, Egemen Kolemen</dc:creator>
    </item>
    <item>
      <title>A Theoretical and Empirical Study on the Convergence of Adam with an "Exact" Constant Step Size in Non-Convex Settings</title>
      <link>https://arxiv.org/abs/2309.08339</link>
      <description>arXiv:2309.08339v3 Announce Type: replace-cross 
Abstract: In neural network training, RMSProp and Adam remain widely favoured optimisation algorithms. One of the keys to their performance lies in selecting the correct step size, which can significantly influence their effectiveness. Additionally, questions about their theoretical convergence properties continue to be a subject of interest. In this paper, we theoretically analyse a constant step size version of Adam in the non-convex setting and discuss why it is important for the convergence of Adam to use a fixed step size. This work demonstrates the derivation and effective implementation of a constant step size for Adam, offering insights into its performance and efficiency in non convex optimisation scenarios. (i) First, we provide proof that these adaptive gradient algorithms are guaranteed to reach criticality for smooth non-convex objectives with constant step size, and we give bounds on the running time. Both deterministic and stochastic versions of Adam are analysed in this paper. We show sufficient conditions for the derived constant step size to achieve asymptotic convergence of the gradients to zero with minimal assumptions. Next, (ii) we design experiments to empirically study Adam's convergence with our proposed constant step size against stateof the art step size schedulers on classification tasks. Lastly, (iii) we also demonstrate that our derived constant step size has better abilities in reducing the gradient norms, and empirically, we show that despite the accumulation of a few past gradients, the key driver for convergence in Adam is the non-increasing step sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08339v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alokendu Mazumder, Rishabh Sabharwal, Manan Tayal, Bhartendu Kumar, Punit Rathore</dc:creator>
    </item>
    <item>
      <title>Fleming-Viot helps speed up variational quantum algorithms in the presence of barren plateaus</title>
      <link>https://arxiv.org/abs/2311.18090</link>
      <description>arXiv:2311.18090v2 Announce Type: replace-cross 
Abstract: Inspired by the Fleming-Viot stochastic process, we propose a parallel implementation of variational quantum algorithms with the aim of helping the algorithm get out of barren plateaus, where optimization direction is unclear. In the Fleming-Viot tradition, parallel searches are called particles. In our proposed approach, the search by a Fleming-Viot particle is stopped when it encounters a region where the gradient is too small or noisy, suggesting a barren plateau area. The stopped particle continues the search after being regenerated at another location of the parameter space, potentially taking the exploration away from barren plateaus. We first analyze the behavior of the Fleming-Viot particles from a theoretical standpoint. We show that, when simulated annealing optimizers are used as particles, the Fleming-Viot system is expected to find the global optimum faster than a single simulated annealing optimizer, with a relative efficiency that increases proportionally to the percentage of barren plateaus in the domain. This result is backed up by numerical experiments carried out on synthetic problems as well as on instances of the Max-Cut problem, which show that our method performs better than plain simulated annealing when large barren plateaus are present in the domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18090v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Mastropietro (CNRS-IRIT, Universit\'e de Toulouse INP, Toulouse, France), Georgios Korpas (HSBC Lab, Innovation &amp; Ventures, HSBC, London, United Kingdom, Department of Computer Science, Czech Technical University in Prague, Czech Republic), Vyacheslav Kungurtsev (Department of Computer Science, Czech Technical University in Prague, Czech Republic), Jakub Marecek (Department of Computer Science, Czech Technical University in Prague, Czech Republic)</dc:creator>
    </item>
    <item>
      <title>Robust Market Approximations: From Discrete to Continuous Time</title>
      <link>https://arxiv.org/abs/2402.16108</link>
      <description>arXiv:2402.16108v2 Announce Type: replace-cross 
Abstract: Continuous time financial market models are often motivated as scaling limits of discrete time models. The objective of this paper is to establish such a connection for a robust framework. More specifically, we consider discrete time models that are parameterized by Markovian transition kernels, and a continuous time setting with drift and volatility uncertainty, again parameterized in a Markovian way. Our main result shows convergence of the uncertainty sets in the Hausdorff metric topology and weak convergence of the associated worst-case expectations. Furthermore, we discuss a structure preservation property of the approximation. Namely, we establish the convergence of discrete to continuous time robust superhedging prices for certain complete robust market models. As an application of our main convergence result, we derive a simple algorithm to compute continuous time robust superhedging prices via approximation and dynamic programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16108v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Criens</dc:creator>
    </item>
    <item>
      <title>An Adaptive Hydropower Management Approach for Downstream Ecosystem Preservation</title>
      <link>https://arxiv.org/abs/2403.02821</link>
      <description>arXiv:2403.02821v2 Announce Type: replace-cross 
Abstract: Hydropower plants play a pivotal role in advancing clean and sustainable energy production, contributing significantly to the global transition towards renewable energy sources. However, hydropower plants are currently perceived both positively as sources of renewable energy and negatively as disruptors of ecosystems. In this work, we highlight the overlooked potential of using hydropower plant as protectors of ecosystems by using adaptive ecological discharges. To advocate for this perspective, we propose using a neural network to predict the minimum ecological discharge value at each desired time. Additionally, we present a novel framework that seamlessly integrates it into hydropower management software, taking advantage of the well-established approach of using traditional constrained optimisation algorithms. This novel approach not only protects the ecosystems from climate change but also contributes to potentially increase the electricity production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02821v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>C. Coelho, M. Jing, M. Fernanda P. Costa, L. L. Ferr\'as</dc:creator>
    </item>
    <item>
      <title>Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance</title>
      <link>https://arxiv.org/abs/2404.01436</link>
      <description>arXiv:2404.01436v2 Announce Type: replace-cross 
Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on the first-order term in the descent lemma, which is also a function of the gradient norm. We show that Adam with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. Our complexity results for both RMSProp and Adam match with the complexity lower bound established in \cite{arjevani2023lower}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01436v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Yi Zhou, Shaofeng Zou</dc:creator>
    </item>
  </channel>
</rss>
