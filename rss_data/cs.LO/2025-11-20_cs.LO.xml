<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 08:21:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Practical Zero-Knowledge Proof for PSPACE</title>
      <link>https://arxiv.org/abs/2511.15071</link>
      <description>arXiv:2511.15071v1 Announce Type: cross 
Abstract: Efficient zero-knowledge proofs (ZKPs) have been restricted to NP statements so far, whereas they exist for all statements in PSPACE. This work presents the first practical zero-knowledge (ZK) protocols for PSPACE-complete statements by enabling ZK proofs of QBF (Quantified Boolean Formula) evaluation. The core idea is to validate quantified resolution proofs (Q-Res) in ZK. We develop an efficient polynomial encoding of Q-Res proofs, enabling proof validation through low-overhead arithmetic checks. We also design a ZK protocol to prove knowledge of a winning strategy related to the QBF, which is often equally important in practice. We implement our protocols and evaluate them on QBFEVAL. The results show that our protocols can verify 72% of QBF evaluations via Q-Res proof and 82% of instances' winning strategies within 100 seconds, for instances where such proofs or strategies can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15071v1</guid>
      <category>cs.CR</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Karthikeyan, Hengyu Liu, Kuldeep S. Meel, Ning Luo</dc:creator>
    </item>
    <item>
      <title>Towards a Formal Verification of Secure Vehicle Software Updates</title>
      <link>https://arxiv.org/abs/2511.15479</link>
      <description>arXiv:2511.15479v1 Announce Type: cross 
Abstract: With the rise of software-defined vehicles (SDVs), where software governs most vehicle functions alongside enhanced connectivity, the need for secure software updates has become increasingly critical. Software vulnerabilities can severely impact safety, the economy, and society. In response to this challenge, Strandberg et al. [escar Europe, 2021] introduced the Unified Software Update Framework (UniSUF), designed to provide a secure update framework that integrates seamlessly with existing vehicular infrastructures.
  Although UniSUF has previously been evaluated regarding cybersecurity, these assessments have not employed formal verification methods. To bridge this gap, we perform a formal security analysis of UniSUF. We model UniSUF's architecture and assumptions to reflect real-world automotive systems and develop a ProVerif-based framework that formally verifies UniSUF's compliance with essential security requirements - confidentiality, integrity, authenticity, freshness, order, and liveness - demonstrating their satisfiability through symbolic execution. Our results demonstrate that UniSUF adheres to the specified security guarantees, ensuring the correctness and reliability of its security framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15479v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cose.2025.104751.</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Security, 2025, 104751, ISSN 0167-4048</arxiv:journal_reference>
      <dc:creator>Martin Slind Hagen, Emil Lundqvist, Alex Phu, Yenan Wang, Kim Strandberg, Elad Michael Schiller</dc:creator>
    </item>
    <item>
      <title>Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs</title>
      <link>https://arxiv.org/abs/2511.15623</link>
      <description>arXiv:2511.15623v1 Announce Type: cross 
Abstract: The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15623v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leopoldo Bertossi, Nina Pardal</dc:creator>
    </item>
    <item>
      <title>From Innermost to Full Probabilistic Term Rewriting: Almost-Sure Termination, Complexity, and Modularity</title>
      <link>https://arxiv.org/abs/2409.17714</link>
      <description>arXiv:2409.17714v3 Announce Type: replace 
Abstract: There are many evaluation strategies for term rewrite systems, but automatically proving termination or analyzing complexity is usually easiest for innermost rewriting. Several syntactic criteria exist when innermost termination implies (full) termination or when runtime complexity and innermost runtime complexity coincide. We adapt these criteria to the probabilistic setting, e.g., we show when it suffices to analyze almost-sure termination w.r.t. innermost rewriting in order to prove (full) almost-sure termination of probabilistic term rewrite systems. These criteria can be applied for both termination and complexity analysis in the probabilistic setting. We implemented and evaluated our new contributions in the tool AProVE. Moreover, we also use our new results to investigate the modularity of probabilistic termination properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17714v3</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan-Christoph Kassing, J\"urgen Giesl</dc:creator>
    </item>
    <item>
      <title>Higher-order Kripke models for intuitionistic and non-classical modal logics</title>
      <link>https://arxiv.org/abs/2507.18798</link>
      <description>arXiv:2507.18798v3 Announce Type: replace 
Abstract: This paper introduces higher-order Kripke models, a generalization of standard Kripke models that is remarkably close to Kripke's original idea - both mathematically and conceptually. Standard Kripke models are now considered $0$-ary models, whereas an $n$-ary model for $n &gt; 0$ is a model whose set of objects (''possible worlds'') contains only $(n-1)$-ary Kripke models. Models with infinitely many layers are also considered. This framework is obtained by promoting a radical change of perspective in how modal semantics for non-classical logics are defined: just like classical modalities are obtained through use of an accessibility relation between classical propositional models, non-classical modalities are now obtained through use of an accessibility relation between non-classical propositional models (even when they are Kripke models already). The paper introduces the new models after dealing specifically with the case of intuitionistic modal logic. It is shown that, depending on which intuitionistic $0$-ary propositional models are allowed, we may obtain $1$-ary models equivalent to either birelational models for $IK$ or for a new logic called $MK$. Those $1$-ary models have an intuitive reading that adds to the interpretation of intuitionistic models in terms of ''timelines'' the concept of ''alternative timelines''. More generally, $n$-ary models (for $n &gt; 0$) can be read as defining a concept of ''alternative'' for any interpretation of the $(n-1)$-ary models. The semantic clauses for necessity and possibility of $MK$ are modular and can be used to obtain similar modal semantics for every non-classical logic, each of which can be provided with a similar intuitive reading. After intuitionistic modal logic is dealt with, the general structure of higher-order Kripke Models and some of its variants are defined, and a series of conjectures about their properties are stated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18798v3</guid>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Barroso-Nascimento</dc:creator>
    </item>
    <item>
      <title>VeriFlow: Modeling Distributions for Neural Network Verification</title>
      <link>https://arxiv.org/abs/2406.14265</link>
      <description>arXiv:2406.14265v3 Announce Type: replace-cross 
Abstract: Formal verification has emerged as a promising method to ensure the safety and reliability of neural networks. However, many relevant properties, such as fairness or global robustness, pertain to the entire input space. If one applies verification techniques naively, the neural network is checked even on inputs that do not occur in the real world and have no meaning. To tackle this shortcoming, we propose the VeriFlow architecture as a flow-based density model tailored to allow any verification approach to restrict its search to some data distribution of interest. We argue that our architecture is particularly well suited for this purpose because of two major properties. First, we show that the transformation that is defined by our model is piecewise affine. Therefore, the model allows the usage of verifiers based on constraint solving with linear arithmetic. Second, upper density level sets (UDL) of the data distribution are definable via linear constraints in the latent space. As a consequence, representations of UDLs specified by a given probability are effectively computable in the latent space. This property allows for effective verification with a fine-grained, probabilistically interpretable control of how a-typical the inputs subject to verification are.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14265v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faried Abu Zaid, Daniel Neider, Mustafa Yal\c{c}{\i}ner</dc:creator>
    </item>
    <item>
      <title>VeriThoughts: Enabling Automated Verilog Code Generation using Reasoning and Formal Verification</title>
      <link>https://arxiv.org/abs/2505.20302</link>
      <description>arXiv:2505.20302v3 Announce Type: replace-cross 
Abstract: This paper introduces VeriThoughts, a novel dataset designed for reasoning-based Verilog code generation. We establish a new benchmark framework grounded in formal verification methods to evaluate the quality and correctness of generated hardware descriptions. Additionally, we present a suite of specialized small-scale models optimized specifically for Verilog generation. Our work addresses the growing need for automated hardware design tools that can produce verifiably correct implementations from high-level specifications, potentially accelerating the hardware development process while maintaining rigorous correctness guarantees. Our code and data are available at \href{https://github.com/wilyub/VeriThoughts}{this URL}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20302v3</guid>
      <category>cs.PL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Yubeaton, Andre Nakkab, Weihua Xiao, Luca Collini, Ramesh Karri, Chinmay Hegde, Siddharth Garg</dc:creator>
    </item>
    <item>
      <title>Best-Effort Policies for Robust Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2508.07790</link>
      <description>arXiv:2508.07790v2 Announce Type: replace-cross 
Abstract: We study the common generalization of Markov decision processes (MDPs) with sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal in RMDPs is to compute a policy that maximizes the expected return under an adversarial choice of the transition probabilities. If the uncertainty in the probabilities is independent between the states, known as s-rectangularity, such optimal robust policies can be computed efficiently using robust value iteration. However, there might still be multiple optimal robust policies, which, while equivalent with respect to the worst-case, reflect different expected returns under non-adversarial choices of the transition probabilities. Hence, we propose a refined policy selection criterion for RMDPs, drawing inspiration from the notions of dominance and best-effort in game theory. Instead of seeking a policy that only maximizes the worst-case expected return, we additionally require the policy to achieve a maximal expected return under different (i.e., not fully adversarial) transition probabilities. We call such a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE policies always exist, characterize their structure, and present an algorithm to compute them with a manageable overhead compared to standard robust value iteration. ORBE policies offer a principled tie-breaker among optimal robust policies. Numerical experiments show the feasibility of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07790v2</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Abate, Thom Badings, Giuseppe De Giacomo, Francesco Fabiano</dc:creator>
    </item>
    <item>
      <title>Formalization of Auslander--Buchsbaum--Serre criterion in Lean4</title>
      <link>https://arxiv.org/abs/2510.24818</link>
      <description>arXiv:2510.24818v2 Announce Type: replace-cross 
Abstract: We present a comprehensive formalization in the Lean4 theorem prover of the Auslander--Buchsbaum--Serre criterion, which characterizes regular local rings as those Noetherian local rings with finite global dimension. Rather than following the well-known proof that computes the projective dimension of the residue field via quotient by regular sequences and uses the Koszul complex to bound the cotangent space dimension by the global dimension, our approach is built systematically on the formalization of depth defined via the vanishing of Ext functors. We establish key homological results including Rees' theorem, the Auslander--Buchsbaum formula, and Ischebeck's theorem, and further develop the theories of Cohen--Macaulay modules and rings, including a complete formalization of the unmixedness theorem for Cohen--Macaulay rings. To prove the Auslander--Buchsbaum--Serre criterion, we show that maximal Cohen--Macaulay modules over regular local rings are free and establish a weakened form of the Ferrand--Vasconcelos theorem specific for the unique maximal ideal. As corollaries, we deduce that regularity can be checked at maximal ideals and formalize Hilbert's Syzygy Theorem. This work demonstrates how homological algebra can be effectively employed in the formalization of commutative algebra, providing extensive infrastructure for future developments in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24818v2</guid>
      <category>math.AC</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naillin Guan, Yongle Hu</dc:creator>
    </item>
  </channel>
</rss>
