<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Dec 2024 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Log-Time K-Means Clustering for 1D Data: Novel Approaches with Proof and Implementation</title>
      <link>https://arxiv.org/abs/2412.15295</link>
      <description>arXiv:2412.15295v1 Announce Type: new 
Abstract: Clustering is a key task in machine learning, with $k$-means being widely used for its simplicity and effectiveness. While 1D clustering is common, existing methods often fail to exploit the structure of 1D data, leading to inefficiencies. This thesis introduces optimized algorithms for $k$-means++ initialization and Lloyd's algorithm, leveraging sorted data, prefix sums, and binary search for improved computational performance. The main contributions are: (1) an optimized $k$-cluster algorithm achieving $O(l \cdot k^2 \cdot \log n)$ complexity for greedy $k$-means++ initialization and $O(i \cdot k \cdot \log n)$ for Lloyd's algorithm, where $l$ is the number of greedy $k$-means++ local trials, and $i$ is the number of Lloyd's algorithm iterations, and (2) a binary search-based two-cluster algorithm, achieving $O(\log n)$ runtime with deterministic convergence to a Lloyd's algorithm local minimum. Benchmarks demonstrate over 4500x speedup compared to scikit-learn for large datasets while maintaining clustering quality measured by within-cluster sum of squares (WCSS). Additionally, the algorithms achieve a 300x speedup in an LLM quantization task, highlighting their utility in emerging applications. This thesis bridges theory and practice for 1D $k$-means clustering, delivering efficient and sound algorithms implemented in a JIT-optimized open-source Python library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15295v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jake Hyun</dc:creator>
    </item>
    <item>
      <title>Rainbow Arborescence Conjecture</title>
      <link>https://arxiv.org/abs/2412.15457</link>
      <description>arXiv:2412.15457v1 Announce Type: cross 
Abstract: The famous Ryser--Brualdi--Stein conjecture asserts that every $n \times n$ Latin square contains a partial transversal of size $n-1$. Since its appearance, the conjecture has attracted significant interest, leading to several generalizations. One of the most notable extensions is to matroid intersection given by Aharoni, Kotlar, and Ziv, focusing on the existence of a common independent transversal of the common independent sets of two matroids. In this paper, we study a special case of this setting, the Rainbow Arborescence Conjecture, which states that any graph on $n$ vertices formed by the union of $n-1$ spanning arborescences contains an arborescence using exactly one arc from each. We prove that the computational problem of testing the existence of such an arborescence with a fixed root is NP-complete, verify the conjecture in several cases, and explore relaxed versions of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15457v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krist\'of B\'erczi, Tam\'as Kir\'aly, Yutaro Yamaguchi, Yu Yokoi</dc:creator>
    </item>
    <item>
      <title>Distance Vector Domination</title>
      <link>https://arxiv.org/abs/2412.15663</link>
      <description>arXiv:2412.15663v1 Announce Type: cross 
Abstract: Identifying and mitigating the spread of fake information is a challenging issue that has become dominant with the rise of social media. We consider a generalization of the Domination problem that can be used to detect a set of individuals who, once immunized, can prevent the spreading of fake narratives. The considered problem, named {\em Distance Vector Domination} generalizes both distance and multiple domination, at individual (i.e., vertex) level. We study the parameterized complexity of the problem according to several standard and structural parameters. We prove the W[1]-hardness of the problem with respect to neighborhood diversity, even when all the distances are $1$. We also give fixed-parameter algorithms for some variants of the problem and parameter combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15663v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gennaro Cordasco, Luisa Garagano, Adele A. Rescigno</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of (d,r)-Domination via Modular Decomposition</title>
      <link>https://arxiv.org/abs/2412.15671</link>
      <description>arXiv:2412.15671v1 Announce Type: cross 
Abstract: With the rise of social media, misinformation has significant negative effects on the decision-making of individuals, organizations and communities within society. Identifying and mitigating the spread of fake information is a challenging issue. We consider a generalization of the Domination problem that can be used to detect a set of individuals who, through an awareness process, can prevent the spreading of fake narratives. The considered problem, named \textsc{$(d,r)$-Domination} generalizes both distance and multiple domination. We study the parameterized complexity of the problem according to standard and structural parameters. We give fixed-parameter algorithms as well as polynomial compressions/kernelizations for some variants of the problem and parameter combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15671v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gennaro Cordasco, Luisa Gargano, Adele A. Rescigno</dc:creator>
    </item>
    <item>
      <title>Parallelize Single-Site Dynamics up to Dobrushin Criterion</title>
      <link>https://arxiv.org/abs/2111.04044</link>
      <description>arXiv:2111.04044v2 Announce Type: replace 
Abstract: Single-site dynamics are canonical Markov chain based algorithms for sampling from high-dimensional distributions, such as the Gibbs distributions of graphical models. We introduce a simple and generic parallel algorithm that faithfully simulates single-site dynamics. Under a much relaxed, asymptotic variant of the $\ell_p$-Dobrushin's condition -- where the Dobrushin's influence matrix has a bounded $\ell_p$-induced operator norm for an arbitrary $p\in[1, \infty]$ -- our algorithm simulates $N$ steps of single-site updates within a parallel depth of $O\left({N}/{n}+\log n\right)$ on $\tilde{O}(m)$ processors, where $n$ is the number of sites and $m$ is the size of the graphical model. For Boolean-valued random variables, if the $\ell_p$-Dobrushin's condition holds -- specifically, if the $\ell_p$-induced operator norm of the Dobrushin's influence matrix is less than~$1$ -- the parallel depth can be further reduced to $O(\log N+\log n)$, achieving an exponential speedup.
  These results suggest that single-site dynamics with near-linear mixing times can be parallelized into $\mathsf{RNC}$ sampling algorithms, independent of the maximum degree of the underlying graphical model, as long as the Dobrushin influence matrix maintains a bounded operator norm. We show the effectiveness of this approach with $\mathsf{RNC}$ samplers for the hardcore and Ising models within their uniqueness regimes, as well as an $\mathsf{RNC}$ SAT sampler for satisfying solutions of CNF formulas in a local lemma regime. Furthermore, by employing non-adaptive simulated annealing, these $\mathsf{RNC}$ samplers can be transformed into $\mathsf{RNC}$ algorithms for approximate counting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.04044v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyang Liu, Yitong Yin</dc:creator>
    </item>
    <item>
      <title>Learning Low Degree Hypergraphs</title>
      <link>https://arxiv.org/abs/2202.09989</link>
      <description>arXiv:2202.09989v3 Announce Type: replace 
Abstract: We study the problem of learning a hypergraph via edge detecting queries. In this problem, a learner queries subsets of vertices of a hidden hypergraph and observes whether these subsets contain an edge or not. In general, learning a hypergraph with $m$ edges of maximum size $d$ requires $\Omega((2m/d)^{d/2})$ queries. In this paper, we aim to identify families of hypergraphs that can be learned without suffering from a query complexity that grows exponentially in the size of the edges.
  We show that hypermatchings and low-degree near-uniform hypergraphs with $n$ vertices are learnable with poly$(n)$ queries. For learning hypermatchings (hypergraphs of maximum degree $ 1$), we give an $O(\log^3 n)$-round algorithm with $O(n \log^5 n)$ queries. We complement this upper bound by showing that there are no algorithms with poly$(n)$ queries that learn hypermatchings in $o(\log \log n)$ adaptive rounds. For hypergraphs with maximum degree $\Delta$ and edge size ratio $\rho$, we give a non-adaptive algorithm with $O((2n)^{\rho \Delta+1}\log^2 n)$ queries. To the best of our knowledge, these are the first algorithms with poly$(n, m)$ query complexity for learning non-trivial families of hypergraphs that have a super-constant number of edges of super-constant size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.09989v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Balkanski, Oussama Hanguir, Shatian Wang</dc:creator>
    </item>
    <item>
      <title>Multi-View Structural Graph Summaries</title>
      <link>https://arxiv.org/abs/2407.18036</link>
      <description>arXiv:2407.18036v2 Announce Type: replace 
Abstract: A structural graph summary is a small graph representation that preserves structural information necessary for a given task. The summary is used instead of the original graph to complete the task faster. We introduce multi-view structural graph summaries and propose an algorithm for merging two summaries. We conduct a theoretical analysis of our algorithm. We run experiments on three datasets, contributing two new ones. The datasets are of different domains (web graph, source code, and news) and sizes; the interpretation of multi-view depends on the domain and are pay-level domains on the web, control vs.\@ data flow of the code, and news broadcasters. We experiment with three graph summary models: attribute collection, class collection, and their combination. We observe that merging two structural summaries has an upper bound of quadratic complexity; but under reasonable assumptions, it has linear-time worst-case complexity. The running time of merging has a strong linear correlation with the number of edges in the two summaries. Therefore, the experiments support the assumption that the upper bound of quadratic complexity is not tight and that linear complexity is possible. Furthermore, our experiments show that always merging the two smallest summaries by the number of edges is the most efficient strategy for merging multiple structural summaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18036v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonatan Frank, Andor Diera, David Richerby, Ansgar Scherp</dc:creator>
    </item>
    <item>
      <title>Online versus Offline Adversaries in Property Testing</title>
      <link>https://arxiv.org/abs/2411.18617</link>
      <description>arXiv:2411.18617v3 Announce Type: replace 
Abstract: We study property testing with incomplete or noisy inputs. The models we consider allow for adversarial manipulation of the input, but differ in whether the manipulation can be done only offline, i.e., before the execution of the algorithm, or online, i.e., as the algorithm runs. The manipulations by an adversary can come in the form of erasures or corruptions. We compare the query complexity and the randomness complexity of property testing in the offline and online models. Kalemaj, Raskhodnikova, and Varma (Theory Comput `23) provide properties that can be tested with a small number of queries with offline erasures, but cannot be tested at all with online erasures. We demonstrate that the two models are incomparable in terms of query complexity: we construct properties that can be tested with a constant number of queries in the online corruption model, but require querying a significant fraction of the input in the offline erasure model. We also construct properties that exhibit a strong separation between the randomness complexity of testing in the presence of offline and online adversaries: testing these properties in the online model requires exponentially more random bits than in the offline model, even when they are tested with nearly the same number of queries in both models. Our randomness separation relies on a novel reduction from randomness-efficient testers in the adversarial online model to query-efficient testers in the standard model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18617v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esty Kelman, Ephraim Linder, Sofya Raskhodnikova</dc:creator>
    </item>
    <item>
      <title>Breaking the Barrier: A Polynomial-Time Polylogarithmic Approximation for Directed Steiner Tree</title>
      <link>https://arxiv.org/abs/2412.10744</link>
      <description>arXiv:2412.10744v2 Announce Type: replace 
Abstract: The Directed Steiner Tree (DST) problem is defined on a directed graph $G=(V,E)$, where we are given a designated root vertex $r$ and a set of $k$ terminals $K \subseteq V \setminus {r}$. The goal is to find a minimum-cost subgraph that provides directed $r \rightarrow t$ paths for all terminals $t \in K$.
  The approximability of DST has long been a central open problem in network design. Although there exist polylogarithmic-approximation algorithms with quasi-polynomial running times (Charikar et al. 1998; Grandoni, Laekhanukit, and Li 2019; Ghuge and Nagarajan 2020), the best-known polynomial-time approximation until now has remained at $k^\epsilon$ for any constant $\epsilon &gt; 0$. Whether a polynomial-time algorithm achieving a polylogarithmic approximation exists has been a longstanding mystery.
  In this paper, we resolve this question by presenting a polynomial-time algorithm that achieves an $O(\log^3 k)$-approximation for DST on arbitrary directed graphs. This result nearly matches the state-of-the-art $O(\log^2 k / \log\log k)$ approximations known only via quasi-polynomial-time algorithms. The resulting gap -- $O(\log^3 k)$ versus $O(\log^2 k / \log\log k)$ -- mirrors the known complexity landscape for the Group Steiner Tree problem. This parallel suggests intriguing new directions: Is there a hardness result that provably separates the power of polynomial-time and quasi-polynomial-time algorithms for DST?</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10744v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bundit Laekhanukit</dc:creator>
    </item>
    <item>
      <title>Parameterised distance to local irregularity</title>
      <link>https://arxiv.org/abs/2307.04583</link>
      <description>arXiv:2307.04583v5 Announce Type: replace-cross 
Abstract: A graph $G$ is \emph{locally irregular} if no two of its adjacent vertices have the same degree. In [Fioravantes et al. Complexity of finding maximum locally irregular induced subgraph. {\it SWAT}, 2022], the authors introduced and studied the problem of finding a locally irregular induced subgraph of a given a graph $G$ of maximum order, or, equivalently, computing a subset $S$ of $V(G)$ of minimum order, whose deletion from $G$ results in a locally irregular graph; $S$ is denoted as an \emph{optimal vertex-irregulator of $G$}. In this work we provide an in-depth analysis of the parameterised complexity of computing an optimal vertex-irregulator of a given graph $G$. Moreover, we introduce and study a variation of this problem, where $S$ is a substet of the edges of $G$; in this case, $S$ is denoted as an \emph{optimal edge-irregulator of $G$}. In particular, we prove that computing an optimal vertex-irregulator of a graph $G$ is in FPT when parameterised by the vertex integrity, neighborhood diversity or cluster deletion number of $G$, while it is $W[1]$-hard when parameterised by the feedback vertex set number or the treedepth of $G$. In the case of computing an optimal edge-irregulator of a graph $G$, we prove that this problem is in FPT when parameterised by the vertex integrity of $G$, while it is NP-hard even if $G$ is a planar bipartite graph of maximum degree $4$, and $W[1]$-hard when parameterised by the size of the solution, the feedback vertex set or the treedepth of $G$. Our results paint a comprehensive picture of the tractability of both problems studied here, considering most of the standard graph-structural parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04583v5</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Foivos Fioravantes, Nikolaos Melissinos, Theofilos Triommatis</dc:creator>
    </item>
    <item>
      <title>Set-valued recursions arising from vantage-point trees</title>
      <link>https://arxiv.org/abs/2312.05651</link>
      <description>arXiv:2312.05651v2 Announce Type: replace-cross 
Abstract: We study vantage-point trees constructed using an independent sample from the uniform distribution on a fixed convex body $K$ in $(\mathbb{R}^d,\|\cdot\|)$, where $\|\cdot\|$ is an arbitrary norm on $\mathbb{R}^d$. We prove that a sequence of sets, associated with the left boundary of a vantage-point tree, forms a recurrent Harris chain on the space of convex bodies in $(\mathbb{R}^d,\|\cdot\|)$. The limiting object is a ball polyhedron, that is, an a.s.~finite intersection of closed balls in $(\mathbb{R}^d,\|\cdot\|)$ of possibly different radii. As a consequence, we derive a limit theorem for the length of the leftmost path of a vantage-point tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05651v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Congzao Dong, Alexander Marynych, Ilya Molchanov</dc:creator>
    </item>
  </channel>
</rss>
