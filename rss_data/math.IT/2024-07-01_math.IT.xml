<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jul 2024 02:46:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Interference Cancellation Information Geometry Approach for Massive MIMO Channel Estimation</title>
      <link>https://arxiv.org/abs/2406.19583</link>
      <description>arXiv:2406.19583v2 Announce Type: new 
Abstract: In this paper, the interference cancellation information geometry approaches (IC-IGAs) for massive MIMO channel estimation are proposed. The proposed algorithms are low-complexity approximations of the minimum mean square error (MMSE) estimation. To illustrate the proposed algorithms, a unified framework of the information geometry approach for channel estimation and its geometric explanation are described first. Then, a modified form that has the same mean as the MMSE estimation is constructed. Based on this, the IC-IGA algorithm and the interference cancellation simplified information geometry approach (IC-SIGA) are derived by applying the information geometry framework. The a posteriori means on the equilibrium of the proposed algorithms are proved to be equal to the mean of MMSE estimation, and the complexity of the IC-SIGA algorithm in practical massive MIMO systems is further reduced by considering the beam-based statistical channel model (BSCM) and fast Fourier transform (FFT). Simulation results show that the proposed methods achieve similar performance as the existing information geometry approach (IGA) with lower complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19583v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>An-An Lu, Bingyan Liu, Xiqi Gao</dc:creator>
    </item>
    <item>
      <title>Recent Advances in Deep Learning for Channel Coding: A Survey</title>
      <link>https://arxiv.org/abs/2406.19664</link>
      <description>arXiv:2406.19664v1 Announce Type: new 
Abstract: This paper provides a comprehensive survey on recent advances in deep learning (DL) techniques for the channel coding problems. Inspired by the recent successes of DL in a variety of research domains, its applications to the physical layer technologies have been extensively studied in recent years, and are expected to be a potential breakthrough in supporting the emerging use cases of the next generation wireless communication systems such as 6G. In this paper, we focus exclusively on the channel coding problems and review existing approaches that incorporate advanced DL techniques into code design and channel decoding. After briefly introducing the background of recent DL techniques, we categorize and summarize a variety of approaches, including model-free and mode-based DL, for the design and decoding of modern error-correcting codes, such as low-density parity check (LDPC) codes and polar codes, to highlight their potential advantages and challenges. Finally, the paper concludes with a discussion of open issues and future research directions in channel coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19664v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshiki Matsumine, Hideki Ochiai</dc:creator>
    </item>
    <item>
      <title>Subgraph Matching via Partial Optimal Transport</title>
      <link>https://arxiv.org/abs/2406.19767</link>
      <description>arXiv:2406.19767v1 Announce Type: new 
Abstract: In this work, we propose a novel approach for subgraph matching, the problem of finding a given query graph in a large source graph, based on the fused Gromov-Wasserstein distance. We formulate the subgraph matching problem as a partial fused Gromov-Wasserstein problem, which allows us to build on existing theory and computational methods in order to solve this challenging problem. We extend our method by employing a subgraph sliding approach, which makes it efficient even for large graphs. In numerical experiments, we showcase that our new algorithms have the ability to outperform state-of-the-art methods for subgraph matching on synthetic as well as realworld datasets. In particular, our methods exhibit robustness with respect to noise in the datasets and achieve very fast query times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19767v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen-Xin Pan, Isabel Haasler, Pascal Frossard</dc:creator>
    </item>
    <item>
      <title>Capacity Bounds for Broadcast Channels with Bidirectional Conferencing Decoders</title>
      <link>https://arxiv.org/abs/2406.20019</link>
      <description>arXiv:2406.20019v1 Announce Type: new 
Abstract: The two-user broadcast channel (BC) with receivers connected by cooperative links of given capacities, known as conferencing decoders, is considered. A novel outer bound on the capacity region is established. This outer bound is derived using multiple applications of the Csisz\'{a}r-K\"{o}rner identity. New achievable rate regions are also presented. A first achievable rate region is derived by applying Marton's coding as the transmission scheme, and quantize-bin-and-forward at one receiver first and then a combination of decode-and-forward and quantize-bin-and-forward at the other receiver as cooperative strategy. A second achievable rate region is given by applying a combination of decode-and-forward and quantize-bin-and-forward at one receiver first and then quantize-bin-and-forward at the other receiver. It is proved that the outer bound coincides with the first achievable rate region for a class of semi-deterministic BCs with degraded message sets. This is the first capacity result for the two-user BC with bidirectional conferencing decoders. A capacity result is also derived for a new class of more capable semi-deterministic BCs with both common and private messages and one-sided conferencing. For the Gaussian BC with conferencing decoders, if the noises at the decoders are fully correlated (i.e., the correlation is either 1 or -1), the new outer bound yields exact capacity region for two cases: i) BC with degraded message sets; ii) BC with one-sided conferencing from the weaker receiver to the stronger receiver. An interesting consequence of these results is that for a Gaussian BC with fully negatively correlated noises and conferencing decoders of fixed cooperation link capacities, it is possible to achieve a positive rate bounded away from zero using only infinitesimal amount of transmit power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.20019v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reza K. Farsani, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Equi-isoclinic subspaces from symmetry</title>
      <link>https://arxiv.org/abs/2406.19542</link>
      <description>arXiv:2406.19542v1 Announce Type: cross 
Abstract: We describe a flexible technique that constructs tight fusion frames with prescribed transitive symmetry. Applying this technique with representations of the symmetric and alternating groups, we obtain several new infinite families of equi-isoclinic tight fusion frames, each with the remarkable property that its automorphism group is either $S_n$ or $A_n$. These ensembles are optimal packings for Grassmannian space equipped with spectral distance, and as such, they find applications in block compressed sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19542v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.GR</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Fickus, Joseph W. Iverson, John Jasper, Dustin G. Mixon</dc:creator>
    </item>
    <item>
      <title>Stochastic Zeroth-Order Optimization under Strongly Convexity and Lipschitz Hessian: Minimax Sample Complexity</title>
      <link>https://arxiv.org/abs/2406.19617</link>
      <description>arXiv:2406.19617v1 Announce Type: cross 
Abstract: Optimization of convex functions under stochastic zeroth-order feedback has been a major and challenging question in online learning. In this work, we consider the problem of optimizing second-order smooth and strongly convex functions where the algorithm is only accessible to noisy evaluations of the objective function it queries. We provide the first tight characterization for the rate of the minimax simple regret by developing matching upper and lower bounds. We propose an algorithm that features a combination of a bootstrapping stage and a mirror-descent stage. Our main technical innovation consists of a sharp characterization for the spherical-sampling gradient estimator under higher-order smoothness conditions, which allows the algorithm to optimally balance the bias-variance tradeoff, and a new iterative method for the bootstrapping stage, which maintains the performance for unbounded Hessian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19617v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Yu, Yining Wang, Baihe Huang, Qi Lei, Jason D. Lee</dc:creator>
    </item>
    <item>
      <title>Alon's transmitting problem and multicolor Beck--Spencer Lemma</title>
      <link>https://arxiv.org/abs/2406.19945</link>
      <description>arXiv:2406.19945v1 Announce Type: cross 
Abstract: The Hamming graph $H(n,q)$ is defined on the vertex set $\{1,2,\ldots,q\}^n$ and two vertices are adjacent if and only if they differ in precisely one coordinate. Alon proved that for any sequence $v_1,\ldots,v_b$ of $b=\lceil\frac n2\rceil$ vertices of $H(n,2)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$. In this note, we prove that for any $q\geq 3$ and any sequence $v_1,\ldots,v_b$ of $b=\lfloor(1-\frac1q)n\rfloor$ vertices of $H(n,q)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$.
  Alon used the Beck--Spencer Lemma which, in turn, was based on the floating variable method introduced by Beck and Fiala who studied combinatorial discrepancies. For our proof, we extend the Beck--Spencer Lemma by using a multicolor version of the floating variable method due to Doerr and Srivastav.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19945v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Norihide Tokushige</dc:creator>
    </item>
    <item>
      <title>Machine Learning Predictors for Min-Entropy Estimation</title>
      <link>https://arxiv.org/abs/2406.19983</link>
      <description>arXiv:2406.19983v1 Announce Type: cross 
Abstract: This study investigates the application of machine learning predictors for min-entropy estimation in Random Number Generators (RNGs), a key component in cryptographic applications where accurate entropy assessment is essential for cybersecurity. Our research indicates that these predictors, and indeed any predictor that leverages sequence correlations, primarily estimate average min-entropy, a metric not extensively studied in this context. We explore the relationship between average min-entropy and the traditional min-entropy, focusing on their dependence on the number of target bits being predicted. Utilizing data from Generalized Binary Autoregressive Models, a subset of Markov processes, we demonstrate that machine learning models (including a hybrid of convolutional and recurrent Long Short-Term Memory layers and the transformer-based GPT-2 model) outperform traditional NIST SP 800-90B predictors in certain scenarios. Our findings underscore the importance of considering the number of target bits in min-entropy assessment for RNGs and highlight the potential of machine learning approaches in enhancing entropy estimation techniques for improved cryptographic security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19983v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Blanco-Romero, Vicente Lorenzo, Florina Almenares Mendoza, Daniel D\'iaz-S\'anchez</dc:creator>
    </item>
    <item>
      <title>Factoring Perfect Reconstruction Filter Banks into Causal Lifting Matrices: A Diophantine Approach</title>
      <link>https://arxiv.org/abs/1902.09040</link>
      <description>arXiv:1902.09040v3 Announce Type: replace 
Abstract: The elementary theory of bivariate linear Diophantine equations over polynomial rings is used to construct causal lifting factorizations for causal two-channel FIR perfect reconstruction filter banks and wavelet transforms. The Diophantine approach generates causal factorizations satisfying certain polynomial degree-reducing inequalities, enabling a new lifting factorization strategy called the Causal Complementation Algorithm. This provides a causal, hence realizable, alternative to the noncausal lifting scheme developed by Daubechies and Sweldens using the Extended Euclidean Algorithm for Laurent polynomials. The new approach replaces the Euclidean Algorithm with a slight generalization of polynomial division that ensures existence and uniqueness of quotients whose remainders satisfy user-specified divisibility constraints. The Causal Complementation Algorithm is shown to be more general than the causal (polynomial) version of the Euclidean Algorithm approach by generating additional causal lifting factorizations beyond those obtainable using the polynomial Euclidean Algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:1902.09040v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher M. Brislawn</dc:creator>
    </item>
    <item>
      <title>Automatic Regularization for Linear MMSE Filters</title>
      <link>https://arxiv.org/abs/2312.06560</link>
      <description>arXiv:2312.06560v2 Announce Type: replace 
Abstract: In this work, we consider the problem of regularization in the design of minimum mean square error (MMSE) linear filters. Using the relationship with statistical machine learning methods, using a Bayesian approach, the regularization parameter is found from the observed signals in a simple and automatic manner. The proposed approach is illustrated in system identification and beamforming examples, where the automatic regularization is shown to yield near-optimal results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06560v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Gomes de Pinho Zanco, Leszek Szczecinski, Jacob Benesty</dc:creator>
    </item>
    <item>
      <title>Age-Gain-Dependent Random Access for Event-Driven Periodic Updating</title>
      <link>https://arxiv.org/abs/2406.00720</link>
      <description>arXiv:2406.00720v3 Announce Type: replace 
Abstract: This paper considers utilizing the knowledge of age gains to reduce the network average age of information (AoI) in random access with event-driven periodic updating for the first time. Built on the form of slotted ALOHA, we require each device to determine its age gain threshold and transmission probability in an easily implementable decentralized manner, so that the unavoided contention can be limited to devices with age gains as high as possible. For the basic case that each device utilizes its knowledge of age gain of only itself, we provide an analytical modeling approach by a multi-layer discrete-time Markov chains (DTMCs), where an external infinite-horizon DTMC manages the jumps between the beginnings of frames and an internal finite-horizon DTMC manages the evolution during an arbitrary frame. Such modelling enables that optimal access parameters can be obtained offline. For the enhanced case that each device utilizes its knowledge of age gains of all the devices, we require each device to adjust its access parameters for maximizing the estimated network \textit{expected AoI reduction} (EAR) per slot, which captures the essential for improving the contribution of the throughput to the AoI performance. To estimate the network EAR, we require each device to use Bayes' rule to keep a posteriori joint probability distribution of local age and age gain of an arbitrary device based on the channel observations. Numerical results validate our theoretical analysis and demonstrate the advantage of the proposed schemes over the existing schemes in a wide range of network configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00720v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Zhu, Yiwen Zhu, Aoyu Gong, Yan Lin, Yuan-Hsuan Lo, Yijin Zhang</dc:creator>
    </item>
    <item>
      <title>Straggler-Resilient Differentially-Private Decentralized Learning</title>
      <link>https://arxiv.org/abs/2212.03080</link>
      <description>arXiv:2212.03080v3 Announce Type: replace-cross 
Abstract: We consider the straggler problem in decentralized learning over a logical ring while preserving user data privacy. Especially, we extend the recently proposed framework of differential privacy (DP) amplification by decentralization by Cyffers and Bellet to include overall training latency--comprising both computation and communication latency. Analytical results on both the convergence speed and the DP level are derived for both a skipping scheme (which ignores the stragglers after a timeout) and a baseline scheme that waits for each node to finish before the training continues. A trade-off between overall training latency, accuracy, and privacy, parameterized by the timeout of the skipping scheme, is identified and empirically validated for logistic regression on a real-world dataset and for image classification using the MNIST and CIFAR-10 datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.03080v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yauhen Yakimenka, Chung-Wei Weng, Hsuan-Yin Lin, Eirik Rosnes, J\"org Kliewer</dc:creator>
    </item>
    <item>
      <title>Ground-to-UAV sub-Terahertz channel measurement and modeling</title>
      <link>https://arxiv.org/abs/2404.02663</link>
      <description>arXiv:2404.02663v2 Announce Type: replace-cross 
Abstract: Unmanned Aerial Vehicle (UAV) assisted terahertz (THz) wireless communications have been expected to play a vital role in the next generation of wireless networks. UAVs can serve as either repeaters or data collectors within the communication link, thereby potentially augmenting the efficacy of communication systems. Despite their promise, the channel analysis and modeling specific to THz wireless channels leveraging UAVs remain under explored. This work delves into a ground-to-UAV channel at 140 GHz, with a specific focus on the influence of UAV hovering behavior on channel performance. Employing experimental measurements through an unmodulated channel setup and a geometry-based stochastic model (GBSM) that integrates three-dimensional positional coordinates and beamwidth, this work evaluates the impact of UAV dynamic movements and antenna orientation on channel performance. Our findings highlight the minimal impact of UAV orientation adjustments on channel performance and underscore the diminishing necessity for precise alignment between UAVs and ground stations as beamwidth increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02663v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Da Li, Peian Li, Jiabiao Zhao, Jianjian Liang, Jiacheng Liu, Guohao Liu, Yuanshuai Lei, Wenbo Liu, Jianqin Deng, Fuyong Liu, Jianjun Ma</dc:creator>
    </item>
    <item>
      <title>Submodular Information Selection for Hypothesis Testing with Misclassification Penalties</title>
      <link>https://arxiv.org/abs/2405.10930</link>
      <description>arXiv:2405.10930v3 Announce Type: replace-cross 
Abstract: We consider the problem of selecting an optimal subset of information sources for a hypothesis testing/classification task where the goal is to identify the true state of the world from a finite set of hypotheses, based on finite observation samples from the sources. In order to characterize the learning performance, we propose a misclassification penalty framework, which enables nonuniform treatment of different misclassification errors. In a centralized Bayesian learning setting, we study two variants of the subset selection problem: (i) selecting a minimum cost information set to ensure that the maximum penalty of misclassifying the true hypothesis is below a desired bound and (ii) selecting an optimal information set under a limited budget to minimize the maximum penalty of misclassifying the true hypothesis. Under certain assumptions, we prove that the objective (or constraints) of these combinatorial optimization problems are weak (or approximate) submodular, and establish high-probability performance guarantees for greedy algorithms. Further, we propose an alternate metric for information set selection which is based on the total penalty of misclassification. We prove that this metric is submodular and establish near-optimal guarantees for the greedy algorithms for both the information set selection problems. Finally, we present numerical simulations to validate our theoretical results over several randomly generated instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10930v3</guid>
      <category>stat.ML</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth Bhargav, Mahsa Ghasemi, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Kernel vs. Kernel: Exploring How the Data Structure Affects Neural Collapse</title>
      <link>https://arxiv.org/abs/2406.02105</link>
      <description>arXiv:2406.02105v2 Announce Type: replace-cross 
Abstract: Recently, a vast amount of literature has focused on the "Neural Collapse" (NC) phenomenon, which emerges when training neural network (NN) classifiers beyond the zero training error point. The core component of NC is the decrease in the within class variability of the network's deepest features, dubbed as NC1. The theoretical works that study NC are typically based on simplified unconstrained features models (UFMs) that mask any effect of the data on the extent of collapse. In this paper, we provide a kernel-based analysis that does not suffer from this limitation. First, given a kernel function, we establish expressions for the traces of the within- and between-class covariance matrices of the samples' features (and consequently an NC1 metric). Then, we turn to focus on kernels associated with shallow NNs. First, we consider the NN Gaussian Process kernel (NNGP), associated with the network at initialization, and the complement Neural Tangent Kernel (NTK), associated with its training in the "lazy regime". Interestingly, we show that the NTK does not represent more collapsed features than the NNGP for prototypical data models. As NC emerges from training, we then consider an alternative to NTK: the recently proposed adaptive kernel, which generalizes NNGP to model the feature mapping learned from the training data. Contrasting our NC1 analysis for these two kernels enables gaining insights into the effect of data distribution on the extent of collapse, which are empirically aligned with the behavior observed with practical training of NNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02105v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vignesh Kothapalli, Tom Tirer</dc:creator>
    </item>
  </channel>
</rss>
