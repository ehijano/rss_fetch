<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2024 01:34:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fed-RD: Privacy-Preserving Federated Learning for Financial Crime Detection</title>
      <link>https://arxiv.org/abs/2408.01609</link>
      <description>arXiv:2408.01609v1 Announce Type: new 
Abstract: We introduce Federated Learning for Relational Data (Fed-RD), a novel privacy-preserving federated learning algorithm specifically developed for financial transaction datasets partitioned vertically and horizontally across parties. Fed-RD strategically employs differential privacy and secure multiparty computation to guarantee the privacy of training data. We provide theoretical analysis of the end-to-end privacy of the training algorithm and present experimental results on realistic synthetic datasets. Our results demonstrate that Fed-RD achieves high model accuracy with minimal degradation as privacy increases, while consistently surpassing benchmark results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01609v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Md. Saikat Islam Khan, Aparna Gupta, Oshani Seneviratne, Stacy Patterson</dc:creator>
    </item>
    <item>
      <title>Impact of Major Health Events on Pharmaceutical Stocks: A Comprehensive Analysis Using Macroeconomic and Market Indicators</title>
      <link>https://arxiv.org/abs/2408.01883</link>
      <description>arXiv:2408.01883v1 Announce Type: new 
Abstract: This study investigates the impact of significant health events on pharmaceutical stock performance, employing a comprehensive analysis incorporating macroeconomic and market indicators. Using Ordinary Least Squares (OLS) regression, we evaluate the effects of thirteen major health events since 2000, including the Anthrax attacks, SARS outbreak, H1N1 pandemic, and COVID-19 pandemic, on the pharmaceutical sector. The analysis covers different phases of each event beginning, peak, and ending to capture their temporal influence on stock prices. Our findings reveal distinct patterns in stock performance, driven by market reactions to the initial news, peak impact, and eventual resolution of these crises. We also examine scenarios with and without key macroeconomic (MA) and market (MI) indicators to isolate their contributions. This detailed examination provides valuable insights for investors, policymakers, and stakeholders in understanding the interplay between major health events and health market dynamics, guiding better decision-making during future health related disruptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01883v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morteza Maleki, SeyedAli Ghahari</dc:creator>
    </item>
    <item>
      <title>Bilateral Trade Flow Prediction by Gravity-informed Graph Auto-encoder</title>
      <link>https://arxiv.org/abs/2408.01938</link>
      <description>arXiv:2408.01938v1 Announce Type: new 
Abstract: The gravity models has been studied to analyze interaction between two objects such as trade amount between a pair of countries, human migration between a pair of countries and traffic flow between two cities. Particularly in the international trade, predicting trade amount is instrumental to industry and government in business decision making and determining economic policies. Whereas the gravity models well captures such interaction between objects, the model simplifies the interaction to extract essential relationships or needs handcrafted features to drive the models. Recent studies indicate the connection between graph neural networks (GNNs) and the gravity models in international trade. However, to our best knowledge, hardly any previous studies in the this domain directly predicts trade amount by GNNs. We propose GGAE (Gravity-informed Graph Auto-encoder) and its surrogate model, which is inspired by the gravity model, showing trade amount prediction by the gravity model can be formulated as an edge weight prediction problem in GNNs and solved by GGAE and its surrogate model. Furthermore, we conducted experiments to indicate GGAE with GNNs can improve trade amount prediction compared to the traditional gravity model by considering complex relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01938v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/BigData55660.2022.10021066</arxiv:DOI>
      <dc:creator>Naoto Minakawa, Kiyoshi Izumi, Hiroki Sakaji</dc:creator>
    </item>
    <item>
      <title>Constructing Mechanical Design Agent Based on Large Language Models</title>
      <link>https://arxiv.org/abs/2408.02087</link>
      <description>arXiv:2408.02087v1 Announce Type: new 
Abstract: Since ancient times, mechanical design aids have been developed to assist human users, aimed at improving the efficiency and effectiveness of design. However, even with the widespread use of contemporary Computer-Aided Design (CAD) systems, there are still high learning costs, repetitive work, and other challenges. In recent years, the rise of Large Language Models (LLMs) has introduced new productivity opportunities to the field of mechanical design. Yet, it remains unrealistic to rely on LLMs alone to complete mechanical design tasks directly. Through a series of explorations, we propose a method for constructing a comprehensive Mechanical Design Agent (MDA) by guiding LLM learning. To verify the validity of our proposed method, we conducted a series of experiments and presented relevant cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02087v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxing Lu, Heran Li, Fangwei Ning, Yixuan Wang, Xinze Li, Yan Shi</dc:creator>
    </item>
    <item>
      <title>A systematic review and analysis of the viability of virtual reality (VR) in construction work and education</title>
      <link>https://arxiv.org/abs/2408.01450</link>
      <description>arXiv:2408.01450v1 Announce Type: cross 
Abstract: This systematic review explores the viability of virtual reality (VR) technologies for enhancing learning outcomes and operational efficiency within the construction industry. This study evaluates the current integration of VR in construction education and practice. Employing the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, this review analyzed 36 peer-reviewed journal articles from databases such as the Web of Science, ERIC, and Scopus. The methodology focused on identifying, appraising, and synthesizing all relevant studies to assess the effectiveness of VR applications in construction-related fields. This review highlights that VR significantly enhances learning by providing immersive interactive simulations that improve the understanding of every complex construction process, such as structural elements or tunnel-boring machine operations. This review contributes by systematically compiling and evaluating evidence on using VR in construction, which has seen a limited comprehensive analysis. It provides practical examples of how VR can revolutionize education and work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01450v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zia Ud Din, Payam Mohammadi, Rachael Sherman</dc:creator>
    </item>
    <item>
      <title>Active Learning for Neural PDE Solvers</title>
      <link>https://arxiv.org/abs/2408.01536</link>
      <description>arXiv:2408.01536v1 Announce Type: cross 
Abstract: Solving partial differential equations (PDEs) is a fundamental problem in engineering and science. While neural PDE solvers can be more efficient than established numerical solvers, they often require large amounts of training data that is costly to obtain. Active Learning (AL) could help surrogate models reach the same accuracy with smaller training sets by querying classical solvers with more informative initial conditions and PDE parameters. While AL is more common in other domains, it has yet to be studied extensively for neural PDE solvers. To bridge this gap, we introduce AL4PDE, a modular and extensible active learning benchmark. It provides multiple parametric PDEs and state-of-the-art surrogate models for the solver-in-the-loop setting, enabling the evaluation of existing and the development of new AL methods for PDE solving. We use the benchmark to evaluate batch active learning algorithms such as uncertainty- and feature-based methods. We show that AL reduces the average error by up to 71% compared to random sampling and significantly reduces worst-case errors. Moreover, AL generates similar datasets across repeated runs, with consistent distributions over the PDE parameters and initial conditions. The acquired datasets are reusable, providing benefits for surrogate models not involved in the data generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01536v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Musekamp, Marimuthu Kalimuthu, David Holzm\"uller, Makoto Takamoto, Mathias Niepert</dc:creator>
    </item>
    <item>
      <title>Scenario-based Thermal Management Parametrization Through Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.02022</link>
      <description>arXiv:2408.02022v1 Announce Type: cross 
Abstract: The thermal system of battery electric vehicles demands advanced control. Its thermal management needs to effectively control active components across varying operating conditions. While robust control function parametrization is required, current methodologies show significant drawbacks. They consume considerable time, human effort, and extensive real-world testing. Consequently, there is a need for innovative and intelligent solutions that are capable of autonomously parametrizing embedded controllers. Addressing this issue, our paper introduces a learning-based tuning approach. We propose a methodology that benefits from automated scenario generation for increased robustness across vehicle usage scenarios. Our deep reinforcement learning agent processes the tuning task context and incorporates an image-based interpretation of embedded parameter sets. We demonstrate its applicability to a valve controller parametrization task and verify it in real-world vehicle testing. The results highlight the competitive performance to baseline methods. This novel approach contributes to the shift towards virtual development of thermal management functions, with promising potential of large-scale parameter tuning in the automotive industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02022v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Rudolf, Philip Muhl, S\"oren Hohmann, Lutz Eckstein</dc:creator>
    </item>
    <item>
      <title>Physics-based block preconditioning for mixed-dimensional beam-solid interaction</title>
      <link>https://arxiv.org/abs/2402.18414</link>
      <description>arXiv:2402.18414v2 Announce Type: replace 
Abstract: This paper presents a scalable physics-based block preconditioner for mixed-dimensional models in beam-solid interaction and their application in engineering. In particular, it studies the linear systems arising from a regularized mortar-type approach for embedding geometrically exact beams into solid continua. Due to the lack of block diagonal dominance of the arising 2 x 2 block system, an approximate block factorization preconditioner is used. It exploits the sparsity structure of the beam sub-block to construct a sparse approximate inverse, which is then not only used to explicitly form an approximation of the Schur complement, but also acts as a smoother within the prediction step of the arising SIMPLE-type preconditioner. The correction step utilizes an algebraic multigrid method. Although, for now, the beam sub-block is tackled by a one-level method only, the multi-level nature of the computationally demanding correction step delivers a scalable preconditioner in practice. In numerical test cases, the influence of different algorithmic parameters on the quality of the sparse approximate inverse is studied and the weak scaling behavior of the proposed preconditioner on up to 1000 MPI ranks is demonstrated, before the proposed preconditioner is finally applied for the analysis of steel-reinforced concrete structures in civil engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18414v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2024.117256</arxiv:DOI>
      <dc:creator>Max Firmbach, Ivo Steinbrecher, Alexander Popp, Matthias Mayr</dc:creator>
    </item>
    <item>
      <title>Clinical Trials Protocol Authoring using LLMs</title>
      <link>https://arxiv.org/abs/2404.05044</link>
      <description>arXiv:2404.05044v2 Announce Type: replace 
Abstract: This report embarks on a mission to revolutionize clinical trial protocol development through the integration of advanced AI technologies. With a focus on leveraging the capabilities of generative AI, specifically GPT-4, this initiative aimed to streamline and enhance the efficiency and accuracy of clinical trial protocols. The methodology encompassed a detailed analysis and preparation of comprehensive drug and study level metadata, followed by the deployment of GPT-4 for automated protocol section generation. Results demonstrated a significant improvement in protocol authoring, highlighted by increases in efficiency, accuracy, and the customization of protocols to specific trial requirements. Challenges encountered during model selection and prompt engineering were systematically addressed, leading to refined methodologies that capitalized on the advanced text generation capabilities of GPT-4. This project not only showcases the practical applications and benefits of generative AI in clinical trial design but also sets a foundation for future innovations in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05044v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morteza Maleki, SeyedAli Ghahari</dc:creator>
    </item>
    <item>
      <title>Identification of cardiovascular diseases through ECG classification using wavelet transformation</title>
      <link>https://arxiv.org/abs/2404.09393</link>
      <description>arXiv:2404.09393v2 Announce Type: replace 
Abstract: Cardiovascular diseases are the leading cause of mortality globally, necessitating advancements in diagnostic techniques. This study explores the application of wavelet transformation for classifying electrocardiogram (ECG) signals to identify various cardiovascular conditions. Utilizing the MIT-BIH Arrhythmia Database, we employed both continuous and discrete wavelet transforms to decompose ECG signals into frequency sub-bands, from which we extracted eight statistical features per band. These features were then used to train and test various classifiers, including K-Nearest Neighbors and Support Vector Machines, among others. The classifiers demonstrated high efficacy, with some achieving an accuracy of up to 96% on test data, suggesting that wavelet-based feature extraction significantly enhances the prediction of cardiovascular abnormalities in ECG data. The findings advocate for further exploration of wavelet transforms in medical diagnostics to improve automation and accuracy in disease detection. Future work will focus on optimizing feature selection and classifier parameters to refine predictive performance further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09393v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morteza Maleki, Foad Haeri</dc:creator>
    </item>
    <item>
      <title>HRFT: Mining High-Frequency Risk Factor Collections End-to-End via Transformer</title>
      <link>https://arxiv.org/abs/2408.01271</link>
      <description>arXiv:2408.01271v2 Announce Type: replace 
Abstract: In quantitative trading, it is common to find patterns in short term volatile trends of the market. These patterns are known as High Frequency (HF) risk factors, serving as key indicators of future stock price volatility. Traditionally, these risk factors were generated by financial models relying heavily on domain-specific knowledge manually added rather than extensive market data. Inspired by symbolic regression (SR), which infers mathematical laws from data, we treat the extraction of formulaic risk factors from high-frequency trading (HFT) market data as an SR task. In this paper, we challenge the manual construction of risk factors and propose an end-to-end methodology, Intraday Risk Factor Transformer (IRFT), to directly predict complete formulaic factors, including constants. We use a hybrid symbolic-numeric vocabulary where symbolic tokens represent operators/stock features and numeric tokens represent constants. We train a Transformer model on the HFT dataset to generate complete formulaic HF risk factors without relying on a predefined skeleton of operators. It determines the general shape of the stock volatility law up to a choice of constants. We refine the predicted constants (a, b) using the Broyden Fletcher Goldfarb Shanno algorithm (BFGS) to mitigate non-linear issues. Compared to the 10 approaches in SRBench, a living benchmark for SR, IRFT gains a 30% excess investment return on the HS300 and SP500 datasets, with inference times orders of magnitude faster than theirs in HF risk factor mining tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01271v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyan Xu, Rundong Wang, Chen Li, Yonghong Hu, Zhonghua Lu</dc:creator>
    </item>
  </channel>
</rss>
