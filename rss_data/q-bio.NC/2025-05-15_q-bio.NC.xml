<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 May 2025 01:30:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Neural encoding of real world face perception</title>
      <link>https://arxiv.org/abs/2505.08831</link>
      <description>arXiv:2505.08831v1 Announce Type: new 
Abstract: Social perception unfolds as we freely interact with people around us. We investigated the neural basis of real world face perception using multi electrode intracranial recordings in humans during spontaneous interactions with friends, family, and others. Computational models reconstructed the faces participants looked at during natural interactions, including facial expressions and motion, from brain activity alone. The results highlighted a critical role for the social vision pathway, a network of areas spanning parietal, temporal, and occipital cortex. This network was more sharply tuned to subtle expressions compared to intense expressions, which was confirmed with controlled psychophysical experiments. These findings reveal that the human social vision pathway encodes facial expressions and motion as deviations from a neutral expression prototype during natural social interactions in real life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08831v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arish Alreja, Michael J. Ward, Lisa S. Parker, R. Mark Richardson, Louis-Philippe Morency, Taylor J. Abel, Avniel Singh Ghuman</dc:creator>
    </item>
    <item>
      <title>Wave propagation phenomena in nonlinear hierarchical neural networks with predictive coding feedback dynamics</title>
      <link>https://arxiv.org/abs/2505.09199</link>
      <description>arXiv:2505.09199v1 Announce Type: cross 
Abstract: We propose a mathematical framework to systematically explore the propagation properties of a class of continuous in time nonlinear neural network models comprising a hierarchy of processing areas, mutually connected according to the principles of predictive coding. We precisely determine the conditions under which upward propagation, downward propagation or even propagation failure can occur in both bi-infinite and semi-infinite idealizations of the model. We also study the long-time behavior of the system when either a fixed external input is constantly presented at the first layer of the network or when this external input consists in the presentation of constant input with large amplitude for a fixed time window followed by a reset to a down state of the network for all later times. In both cases, we numerically demonstrate the existence of threshold behavior for the amplitude of the external input characterizing whether or not a full propagation within the network can occur. Our theoretical results are consistent with predictive coding theories and allow us to identify regions of parameters that could be associated with dysfunctional perceptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09199v1</guid>
      <category>math.AP</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Alamia (CERCO UMR5549), L\'ea Dalli\`es (IMT), Gr\'egory Faye (IMT), Rufin Vanrullen (CERCO UMR5549)</dc:creator>
    </item>
    <item>
      <title>Phase transitions in in vivo or in vitro populations of spiking neurons belong to different universality classes</title>
      <link>https://arxiv.org/abs/2301.09600</link>
      <description>arXiv:2301.09600v4 Announce Type: replace 
Abstract: The "critical brain hypothesis" posits that neural circuitry may be tuned close to a "critical point" or "phase transition" -- a boundary between different operating regimes of the circuit. The renormalization group and theory of critical phenomena explain how systems tuned to a critical point display scale invariance due to fluctuations in activity spanning a wide range of time or spatial scales. In the brain this scale invariance has been hypothesized to have several computational benefits, including increased collective sensitivity to changes in input and robust propagation of information across a circuit. However, our theoretical understanding of critical phenomena in neural circuitry is limited because standard renormalization group methods apply to systems with either highly organized or completely random connections. Connections between neurons lie between these extremes, and may be either excitatory (positive) or inhibitory (negative), but not both. In this work we develop a renormalization group method that applies to models of spiking neural populations with some realistic biological constraints on connectivity, and derive a scaling theory for the statistics of neural activity when the population is tuned to a critical point. We show that the scaling theories differ for models of in vitro versus in vivo circuits -- they belong to different "universality classes" -- and that both may exhibit "anomalous" scaling at a critical balance of inhibition and excitation. We verify our theoretical results on simulations of neural activity data, and discuss how our scaling theory can be further extended and applied to real neural data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.09600v4</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Braden A. W. Brinkman</dc:creator>
    </item>
    <item>
      <title>Spurious reconstruction from brain activity</title>
      <link>https://arxiv.org/abs/2405.10078</link>
      <description>arXiv:2405.10078v5 Announce Type: replace 
Abstract: Advances in brain decoding, particularly visual image reconstruction, have sparked discussions about the societal implications and ethical considerations of neurotechnology. As these methods aim to recover visual experiences from brain activity and achieve prediction beyond training samples (zero-shot prediction), it is crucial to assess their capabilities and limitations to inform public expectations and regulations. Our case study of recent text-guided reconstruction methods, which leverage a large-scale dataset (Natural Scene Dataset, NSD) and text-to-image diffusion models, reveals limitations in their generalizability. We found poor performance when applying these methods to a different dataset designed to prevent category overlaps between training and test sets. UMAP visualization of the text features with NSD images showed a limited diversity of semantic and visual clusters, with overlap between training and test sets. Formal analysis and simulations demonstrated that clustered training samples can lead to "output dimension collapse," restricting predictable output feature dimensions. Simulations further showed that diversifying the training set improved generalizability. However, text features alone are insufficient for mapping to the visual space. We argue that recent realistic reconstructions may primarily be a blend of classification into trained categories and generation of inauthentic images through text-to-image diffusion (hallucination). Diverse datasets and compositional representations spanning the image space are essential for genuine zero-shot prediction. Interdisciplinary discussions grounded in understanding the current capabilities and limitations, as well as ethical considerations, of the technology are crucial for its responsible development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10078v5</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ken Shirakawa, Yoshihiro Nagano, Misato Tanaka, Shuntaro C. Aoki, Kei Majima, Yusuke Muraki, Yukiyasu Kamitani</dc:creator>
    </item>
    <item>
      <title>Efficient, simulation-free estimators of firing rates with Markovian surrogates</title>
      <link>https://arxiv.org/abs/2505.08254</link>
      <description>arXiv:2505.08254v2 Announce Type: replace 
Abstract: Spiking neural networks (SNNs) are powerful mathematical models that integrate the biological details of neural systems, but their complexity often makes them computationally expensive and analytically untractable. The firing rate of an SNN is a crucial first-order statistic to characterize network activity. However, estimating firing rates analytically from even simplified SNN models is challenging due to 1) the intricate dependence between the nonlinear network dynamics and parameters, and 2) the singularity and irreversibility of spikes. In this Letter, we propose a class of computationally efficient, simulation-free estimators of firing rates. This is based on a hierarchy of Markovian approximations that reduces the complexity of SNN dynamics. We show that while considering firing rates alone is insufficient for accurate estimations of themselves, the information of spiking synchrony dramatically improves the estimator's accuracy. This approach provides a practical tool for brain modelers, directly mapping biological parameters to firing rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08254v2</guid>
      <category>q-bio.NC</category>
      <category>math.PR</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongyi Wang, Louis Tao, Zhuo-Cheng Xiao</dc:creator>
    </item>
    <item>
      <title>A Bio-Inspired Research Paradigm of Collision Perception Neurons Enabling Neuro-Robotic Integration: The LGMD Case</title>
      <link>https://arxiv.org/abs/2501.02982</link>
      <description>arXiv:2501.02982v2 Announce Type: replace-cross 
Abstract: Compared to human vision, locust visual systems excel at rapid and precise collision detection, despite relying on only hundreds of thousands of neurons organized through a few neuropils. This efficiency makes them an attractive model system for developing artificial collision-detecting systems. Specifically, researchers have identified collision-selective neurons in the locust's optic lobe, called lobula giant movement detectors (LGMDs), which respond specifically to approaching objects. Research upon LGMD neurons began in the early 1970s. Initially, due to their large size, these neurons were identified as motion detectors, but their role as looming detectors was recognized over time. Since then, progress in neuroscience, computational modeling of LGMD's visual neural circuits, and LGMD-based robotics have advanced in tandem, each field supporting and driving the others. Today, with a deeper understanding of LGMD neurons, LGMD-based models have significantly improved collision-free navigation in mobile robots including ground and aerial robots. This review highlights recent developments in LGMD research from the perspectives of neuroscience, computational modeling, and robotics. It emphasizes a biologically plausible research paradigm, where insights from neuroscience inform real-world applications, which would in turn validate and advance neuroscience. With strong support from extensive research and growing application demand, this paradigm has reached a mature stage and demonstrates versatility across different areas of neuroscience research, thereby enhancing our understanding of the interconnections between neuroscience, computational modeling, and robotics. Furthermore, this paradigm would shed light upon the modeling and robotic research into other motion-sensitive neurons or neural circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02982v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziyan Qin, Jigen Peng, Shigang Yue, Qinbing Fu</dc:creator>
    </item>
  </channel>
</rss>
