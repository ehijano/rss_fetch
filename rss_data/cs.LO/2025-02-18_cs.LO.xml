<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 15:08:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Program Logic for Under-approximating Worst-case Resource Usage</title>
      <link>https://arxiv.org/abs/2502.11091</link>
      <description>arXiv:2502.11091v1 Announce Type: new 
Abstract: Understanding and predicting the worst-case resource usage is crucial for software quality; however, existing methods either over-approximate with potentially loose bounds or under-approximate without asymptotic guarantees. This paper presents a program logic to under-approximate worst-case resource usage, adapting incorrectness logic (IL) to reason quantitatively about resource consumption. We propose quantitative forward and backward under-approximate (QFUA and QBUA) triples, which generalize IL to identify execution paths leading to high resource usage. We also introduce a variant of QBUA that supports reasoning about high-water marks. Our logic is proven sound and complete with respect to a simple IMP-like language, and we demonstrate its utility through case studies involving arrays, pointers, and procedure calls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11091v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyue Jin, Di Wang</dc:creator>
    </item>
    <item>
      <title>Changing the Rules of the Game: Reasoning about Dynamic Phenomena in Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2502.11785</link>
      <description>arXiv:2502.11785v1 Announce Type: new 
Abstract: The design and application of multi-agent systems (MAS) require reasoning about the effects of modifications on their underlying structure. In particular, such changes may impact the satisfaction of system specifications and the strategic abilities of their autonomous components. In this paper, we are concerned with the problem of verifying and synthesising modifications (or \textit{updates}) of MAS. We propose an extension of the Alternating-Time Temporal Logic ($\mathsf{ATL}$) that enables reasoning about the dynamics of model change, called the \textit{Logic for $\mathsf{ATL}$ Model Building} ($\mathsf{LAMB}$). We show how $\mathsf{LAMB}$ can express various intuitions and ideas about the dynamics of MAS, from normative updates to mechanism design. As the main technical result, we prove that, while being strictly more expressive than $\mathsf{ATL}$, $\mathsf{LAMB}$ enjoys a P-complete model-checking procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11785v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rustam Galimullin, Maksim Gladyshev, Munyque Mittelmann, Nima Motamed</dc:creator>
    </item>
    <item>
      <title>Infinitary Refinement Types for Temporal Properties in Scott Domains</title>
      <link>https://arxiv.org/abs/2502.11917</link>
      <description>arXiv:2502.11917v1 Announce Type: new 
Abstract: We discuss an infinitary refinement type system for input-output temporal specifications of functions that handle infinite objects like streams or infinite trees. Our system is based on a reformulation of Bonsangue and Kok's infinitary extension of Abramsky's Domain Theory in Logical Form to saturated properties. We show that in an interesting range of cases, our system is complete without the need of an infinitary rule introduced by Bonsangue and Kok to reflect the well-filteredness of Scott domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11917v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Colin Riba, Alexandre Kejikian</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Initial Semantics</title>
      <link>https://arxiv.org/abs/2502.10811</link>
      <description>arXiv:2502.10811v1 Announce Type: cross 
Abstract: Initial semantics aims to capture inductive structures and their properties as initial objects in suitable categories. We focus on the initial semantics aiming to model the syntax and substitution structure of programming languages with variable binding as initial objects. Three distinct yet similar approaches to initial semantics have been proposed. An initial semantics result was first proved by Fiore, Plotkin, and Turi using {\Sigma}-monoids in their seminal paper published at LICS'99. Alternative frameworks were later introduced by Hirschowitz and Maggesi using modules over monads, and by Matthes and Uustalu using heterogeneous substitution systems. Since then, all approaches have been significantly developed by numerous researchers. While similar, the links between this different approaches remain unclear. This is especially the case as the literature is difficult to access, since it was mostly published in (short) conference papers without proofs, and contains many technical variations and evolutions.
  In this work, we introduce a framework based on monoidal categories that unifies these three distinct approaches to initial semantics, by suitably generalizing and combining them. Doing so we show that modules over monoids provide an abstract and easy to manipulate framework, that {\Sigma}-monoids and strengths naturally arise when stating and proving an initiality theorem, and that heterogeneous substitution systems enable us to prove the initiality theorem modularly. Moreover, to clarify the literature, we provide an extensive overview of related work using our framework as a cornerstone to explain the links between the different approaches and their variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10811v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Lamiaux, Benedikt Ahrens</dc:creator>
    </item>
    <item>
      <title>Dialogue-based Explanations for Logical Reasoning using Structured Argumentation</title>
      <link>https://arxiv.org/abs/2502.11291</link>
      <description>arXiv:2502.11291v1 Announce Type: cross 
Abstract: The problem of explaining inconsistency-tolerant reasoning in knowledge bases (KBs) is a prominent topic in Artificial Intelligence (AI). While there is some work on this problem, the explanations provided by existing approaches often lack critical information or fail to be expressive enough for non-binary conflicts. In this paper, we identify structural weaknesses of the state-of-the-art and propose a generic argumentation-based approach to address these problems. This approach is defined for logics involving reasoning with maximal consistent subsets and shows how any such logic can be translated to argumentation. Our work provides dialogue models as dialectic-proof procedures to compute and explain a query answer wrt inconsistency-tolerant semantics. This allows us to construct dialectical proof trees as explanations, which are more expressive and arguably more intuitive than existing explanation formalisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11291v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Loan Ho, Stefan Schlobach</dc:creator>
    </item>
    <item>
      <title>Extracting total Amb programs from proofs</title>
      <link>https://arxiv.org/abs/2307.12454</link>
      <description>arXiv:2307.12454v2 Announce Type: replace 
Abstract: We present a logical system CFP (Concurrent Fixed Point Logic) supporting the extraction of nondeterministic and concurrent programs that are provably total and correct. CFP is an intuitionistic first-order logic with inductive and coinductive definitions extended by two propositional operators: Rrestriction, a strengthening of implication, and an operator for total concurrency. The source of the extraction are formal CFP proofs, the target is a lambda calculus with constructors and recursion extended by a constructor Amb (for McCarthy's amb) which is interpreted operationally as globally angelic choice and is used to implement nondeterminism and concurrency. The correctness of extracted programs is proven via an intermediate domain-theoretic denotational semantics. We demonstrate the usefulness of our system by extracting a nondeterministic program that translates infinite Gray code into the signed digit representation. A noteworthy feature of CFP is the fact that the proof rules for restriction and concurrency involve variants of the classical law of excluded middle that would not be interpretable computationally without Amb.This is a revised and extended version of the conference paper with the same title that contains full proofs of all major results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12454v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ulrich Berger, Hideki Tsuiki</dc:creator>
    </item>
    <item>
      <title>G\"odel Incompleteness Theorem for PAC Learnable Theory from the view of complexity measurement</title>
      <link>https://arxiv.org/abs/2408.10211</link>
      <description>arXiv:2408.10211v2 Announce Type: replace 
Abstract: Different from the view that information is objective reality, this paper adopts the idea that all information needs to be compiled by the interpreter before it can be observed. From the traditional complexity definition, this paper defines the complexity under "the interpreter", which means that heuristically finding the best interpreter is equivalent to using PAC to find the most suitable interpreter. Then we generalize the observation process to the formal system with functors, in which we give concrete proof of the generalized G\"odel incompleteness theorem which indicates that there are some objects that are PAC-learnable, but the best interpreter is not found among the alternative interpreters. A strong enough machine algorithm cannot be interpretable in the face of any object. There are always objects that make a strong enough machine learning algorithm uninterpretable, which puts an upper bound on the generalization ability of strong AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10211v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhifeng Ma, Tianyi Wu, Zhangang Han</dc:creator>
    </item>
    <item>
      <title>Soundness Correction of Data Petri Nets</title>
      <link>https://arxiv.org/abs/2410.21188</link>
      <description>arXiv:2410.21188v2 Announce Type: replace 
Abstract: A process model is called sound if it always terminates properly and each model activity can occur in a process instance. Conducting soundness verification right after process design allows one to detect and eliminate design errors in a process to be implemented. The process of eliminating such errors is called soundness repair. In many repair scenarios, the resulting model should retain only the correct behavior of the source model, especially if a model is created manually. In this paper, we consider this type of soundness repair applied to data-aware process models represented as data Petri nets (DPNs). Specifically, we investigate the capabilities to repair soundness of DPNs by restricting the transition guards and propose a new repair algorithm that follows this approach. A distinctive feature of the algorithm is the absence of a requirement for an input DPN to have a sound control flow. The algorithm is implemented and results of the preliminary evaluation demonstrate its applicability to process models of moderate sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21188v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nikolai M. Suvorov, Irina A. Lomazova, Andrey Rivkin</dc:creator>
    </item>
    <item>
      <title>Weakly acyclic diagrams: A data structure for infinite-state symbolic verification</title>
      <link>https://arxiv.org/abs/2411.17250</link>
      <description>arXiv:2411.17250v2 Announce Type: replace 
Abstract: Ordered binary decision diagrams (OBDDs) are a fundamental data structure for the manipulation of Boolean functions, with strong applications to finite-state symbolic model checking. OBDDs allow for efficient algorithms using top-down dynamic programming. From an automata-theoretic perspective, OBDDs essentially are minimal deterministic finite automata recognizing languages whose words have a fixed length (the arity of the Boolean function). We introduce weakly acyclic diagrams (WADs), a generalization of OBDDs that maintains their algorithmic advantages, but can also represent infinite languages. We develop the theory of WADs and show that they can be used for symbolic model checking of various models of infinite-state systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17250v2</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Blondin, Micha\"el Cadilhac, Xin-Yi Cui, Philipp Czerner, Javier Esparza, Jakob Schulz</dc:creator>
    </item>
    <item>
      <title>$\texttt{FORM}$: Learning Expressive and Transferable First-Order Logic Reward Machines</title>
      <link>https://arxiv.org/abs/2501.00364</link>
      <description>arXiv:2501.00364v2 Announce Type: replace-cross 
Abstract: Reward machines (RMs) are an effective approach for addressing non-Markovian rewards in reinforcement learning (RL) through finite-state machines. Traditional RMs, which label edges with propositional logic formulae, inherit the limited expressivity of propositional logic. This limitation hinders the learnability and transferability of RMs since complex tasks will require numerous states and edges. To overcome these challenges, we propose First-Order Reward Machines ($\texttt{FORM}$s), which use first-order logic to label edges, resulting in more compact and transferable RMs. We introduce a novel method for $\textbf{learning}$ $\texttt{FORM}$s and a multi-agent formulation for $\textbf{exploiting}$ them and facilitate their transferability, where multiple agents collaboratively learn policies for a shared $\texttt{FORM}$. Our experimental results demonstrate the scalability of $\texttt{FORM}$s with respect to traditional RMs. Specifically, we show that $\texttt{FORM}$s can be effectively learnt for tasks where traditional RM learning approaches fail. We also show significant improvements in learning speed and task transferability thanks to the multi-agent learning framework and the abstraction provided by the first-order language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00364v2</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leo Ardon, Daniel Furelos-Blanco, Roko Parac, Alessandra Russo</dc:creator>
    </item>
    <item>
      <title>ProofWala: Multilingual Proof Data Synthesis and Theorem-Proving</title>
      <link>https://arxiv.org/abs/2502.04671</link>
      <description>arXiv:2502.04671v2 Announce Type: replace-cross 
Abstract: Neural networks have shown substantial promise at automatic theorem-proving in interactive proof assistants (ITPs) like Lean and Coq. However, most neural theorem-proving models are restricted to specific ITPs, leaving out opportunities for cross-lingual $\textit{transfer}$ between ITPs. We address this weakness with a multilingual proof framework, ${\rm P{\small ROOF}W{\small ALA}}$, that allows a standardized form of interaction between neural theorem-provers and two established ITPs (Coq and Lean). It enables the collection of multilingual proof step data -- data recording the result of proof actions on ITP states -- for training neural provers. ${\rm P{\small ROOF}W{\small ALA}}$ allows the systematic evaluation of a model's performance across different ITPs and problem domains via efficient parallel proof search algorithms. We show that multilingual training enabled by ${\rm P{\small ROOF}W{\small ALA}}$ can lead to successful transfer across ITPs. Specifically, a model trained on a mix of ${\rm P{\small ROOF}W{\small ALA}}$-generated Coq and Lean data outperforms Lean-only and Coq-only models on the standard prove-at-$k$ metric. We open source all code including code for the ${\rm P{\small ROOF}W{\small ALA}}$ Framework (https://github.com/trishullab/proof-wala), and the Multilingual ITP interaction framework (https://github.com/trishullab/itp-interface).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04671v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amitayush Thakur, George Tsoukalas, Greg Durrett, Swarat Chaudhuri</dc:creator>
    </item>
    <item>
      <title>Logical forms complement probability in understanding language model (and human) performance</title>
      <link>https://arxiv.org/abs/2502.09589</link>
      <description>arXiv:2502.09589v2 Announce Type: replace-cross 
Abstract: With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question. This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in natural language. We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance. Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical forms should be considered as important factors. In addition, we show similarities and discrepancies between the logical reasoning performances of humans and LLMs by collecting and comparing behavioral data from both.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09589v2</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan Wang, Freda Shi</dc:creator>
    </item>
  </channel>
</rss>
