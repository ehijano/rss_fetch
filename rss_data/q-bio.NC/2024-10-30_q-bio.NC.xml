<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Oct 2024 02:03:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Nanoscale Connectomics Annotation Standards Framework</title>
      <link>https://arxiv.org/abs/2410.22320</link>
      <description>arXiv:2410.22320v2 Announce Type: new 
Abstract: The promise of large-scale, high-resolution datasets from Electron Microscopy (EM) and X-ray Microtomography (XRM) lies in their ability to reveal neural structures and synaptic connectivity, which is critical for understanding the brain. Effectively managing these complex and rapidly increasing datasets will enable new scientific insights, facilitate querying, and support secondary use across the neuroscience community. However, without effective neurodata standards that permit use of these data across multiple systems and workflows, these valuable and costly datasets risk being underutilized especially as they surpass petascale levels. These standards will promote data sharing through accessible interfaces, allow researchers to build on each other's work, and guide the development of tools and capabilities that are interoperable. Herein we outline a standards framework for creating and managing annotations originating and derived from high-resolution volumetric imaging and connectomic datasets, focusing on ensuring Findable, Accessible, Interoperable, and Reusable (FAIR) practices. The goal is to enhance collaborative efforts, boost the reliability of findings, and enable comparative analysis across growing datasets of different species and modalities. We have formed a global working group with academic and industry partners in the high-resolution volumetric data generation and analysis community, focused on identifying gaps in current EM and XRM data pipelines, and refining outlines and platforms for standardizing EM and XRM methods. This focus considers existing and past community approaches and includes examining neuronal entities, biological components, and associated metadata, while emphasizing adaptability and fostering collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22320v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole K. Guittari, Miguel E. Wimbish, Patricia K. Rivlin, Mark A. Hinton, Jordan K. Matelsky, Victoria A. Rose, Jorge L. Rivera Jr., Nicole E. Stock, Brock A. Wester, Erik C. Johnson, William R. Gray-Roncal</dc:creator>
    </item>
    <item>
      <title>Towards Continuous Skin Sympathetic Nerve Activity Monitoring: Removing Muscle Noise</title>
      <link>https://arxiv.org/abs/2410.21319</link>
      <description>arXiv:2410.21319v1 Announce Type: cross 
Abstract: Continuous monitoring of non-invasive skin sympathetic nerve activity (SKNA) holds promise for understanding the sympathetic nervous system (SNS) dynamics in various physiological and pathological conditions. However, muscle noise artifacts present a challenge in accurate SKNA analysis, particularly in real-life scenarios. This study proposes a deep convolutional neural network (CNN) approach to detect and remove muscle noise from SKNA recordings obtained via ECG electrodes. Twelve healthy participants underwent controlled experimental protocols involving cognitive stress induction and voluntary muscle movements, while collecting SKNA data. Power spectral analysis revealed significant muscle noise interference within the SKNA frequency band (500-1000 Hz). A 2D CNN model was trained on the spectrograms of the data segments to classify them into baseline, stress-induced SKNA, and muscle noise-contaminated periods, achieving an average accuracy of 89.85% across all subjects. Our findings underscore the importance of addressing muscle noise for accurate SKNA monitoring, advancing towards wearable SKNA sensors for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21319v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Farnoush Baghestani, Mahdi Pirayesh Shirazi Nejad, Youngsun Kong, Ki H. Chon</dc:creator>
    </item>
    <item>
      <title>Designing an adaptive room for captivating the collective consciousness from internal states</title>
      <link>https://arxiv.org/abs/2410.21571</link>
      <description>arXiv:2410.21571v1 Announce Type: cross 
Abstract: Beyond conventional productivity metrics, human interaction and collaboration dynamics merit careful consideration in our increasingly digital workspace. This research proposes a conjectural neuro-adaptive room that enhances group interactions by adjusting the physical environment to desired internal states. Drawing inspiration from previous work on collective consciousness, the system leverages computer vision and machine learning models to analyze physiological and behavioral cues, such as facial expressions and speech analysis, to infer the overall internal state of occupants. Environmental conditions of the room, such as visual projections, lighting and sound, are actively adjusted to create an optimal setting for inducing the desired state, including focus or collaboration. Our goal is to create a dynamic and responsive environment to support group needs, fostering a sense of collective consciousness and improving workplace well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21571v1</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ad\'an Flores-Ram\'irez, \'Angel Mario Alarc\'on-L\'opez, Sof\'ia Vaca-Narvaja, Daniela Leo-Orozco</dc:creator>
    </item>
    <item>
      <title>osl-ephys: A Python toolbox for the analysis of electrophysiology data</title>
      <link>https://arxiv.org/abs/2410.22051</link>
      <description>arXiv:2410.22051v1 Announce Type: cross 
Abstract: We describe OHBA Software Library for the analysis of electrophysiological data (osl-ephys). This toolbox builds on top of the widely used MNE-Python package and provides unique analysis tools for magneto-/electro-encephalography (M/EEG) sensor and source space analysis, which can be used modularly. In particular, it facilitates processing large amounts of data using batch parallel processing, with high standards for reproducibility through a config API and log keeping, and efficient quality assurance by producing HTML processing reports. It also provides new functionality for doing coregistration, source reconstruction and parcellation in volumetric space, allowing for an alternative pipeline that avoids the need for surface-based processing, e.g., through the use of Fieldtrip. Here, we introduce osl-ephys by presenting examples applied to a publicly available M/EEG data (the multimodal faces dataset). osl-ephys is open-source software distributed on the Apache License and available as a Python package through PyPi and GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22051v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mats W. J. van Es, Chetan Gohil, Andrew J. Quinn, Mark W. Woolrich</dc:creator>
    </item>
    <item>
      <title>Leveraging Recurrent Neural Networks for Predicting Motor Movements from Primate Motor Cortex Neural Recordings</title>
      <link>https://arxiv.org/abs/2410.22283</link>
      <description>arXiv:2410.22283v1 Announce Type: cross 
Abstract: This paper presents an efficient deep learning solution for decoding motor movements from neural recordings in non-human primates. An Autoencoder Gated Recurrent Unit (AEGRU) model was adopted as the model architecture for this task. The autoencoder is only used during the training stage to achieve better generalization. Together with the preprocessing techniques, our model achieved 0.71 $R^2$ score, surpassing the baseline models in Neurobench and is ranked first for $R^2$ in the IEEE BioCAS 2024 Grand Challenge on Neural Decoding. Model pruning is also applied leading to a reduction of 41.4% of the multiply-accumulate (MAC) operations with little change in the $R^2$ score compared to the unpruned model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22283v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuanxi Wang, Zuowen Wang, Shih-Chii Liu</dc:creator>
    </item>
    <item>
      <title>Double opponency serves as a basis for color constancy</title>
      <link>https://arxiv.org/abs/2410.08823</link>
      <description>arXiv:2410.08823v2 Announce Type: replace 
Abstract: Color constancy (CC) is one of the important perceptual abilities of the human visual system, which states that despite changes in illumination, the perceived colors of surfaces generally tend to remain constant. Nevertheless, the mechanisms underlying CC have been debated for several decades. A specific type of cell, known as the double opponent cell in the primary visual cortex (V1), is strongly implicated in achieving CC. However, the exact functioning manner of this cell type remains uncertain. In this work, our quantitative analysis of concentric double-opponent cells in V1 revealed their ability to identify gray surfaces within color-biased scenes. These gray surfaces can then be used to estimate the illumination easily. For the first time, this finding offers a clear functional explanation of concentric double-opponent receptive fields of this cell type in the visual system. Building on this insight, we introduced a novel computational theory--gray-anchoring (GA) theory--to explain how CC is achieved in the visual system. Specifically, GA-based CC involves detecting and anchoring gray surfaces within complex scenes. Our new theory serves as a bridge among the retinex theory, anchoring theory, and the neural mechanisms underlying visual CC in color vision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08823v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kai-Fu Yang, Yong-Jie Li</dc:creator>
    </item>
    <item>
      <title>EEG-Deformer: A Dense Convolutional Transformer for Brain-computer Interfaces</title>
      <link>https://arxiv.org/abs/2405.00719</link>
      <description>arXiv:2405.00719v2 Announce Type: replace-cross 
Abstract: Effectively learning the temporal dynamics in electroencephalogram (EEG) signals is challenging yet essential for decoding brain activities using brain-computer interfaces (BCIs). Although Transformers are popular for their long-term sequential learning ability in the BCI field, most methods combining Transformers with convolutional neural networks (CNNs) fail to capture the coarse-to-fine temporal dynamics of EEG signals. To overcome this limitation, we introduce EEG-Deformer, which incorporates two main novel components into a CNN-Transformer: (1) a Hierarchical Coarse-to-Fine Transformer (HCT) block that integrates a Fine-grained Temporal Learning (FTL) branch into Transformers, effectively discerning coarse-to-fine temporal patterns; and (2) a Dense Information Purification (DIP) module, which utilizes multi-level, purified temporal information to enhance decoding accuracy. Comprehensive experiments on three representative cognitive tasks-cognitive attention, driving fatigue, and mental workload detection-consistently confirm the generalizability of our proposed EEG-Deformer, demonstrating that it either outperforms or performs comparably to existing state-of-the-art methods. Visualization results show that EEG-Deformer learns from neurophysiologically meaningful brain regions for the corresponding cognitive tasks. The source code can be found at https://github.com/yi-ding-cs/EEG-Deformer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00719v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Ding, Yong Li, Hao Sun, Rui Liu, Chengxuan Tong, Chenyu Liu, Xinliang Zhou, Cuntai Guan</dc:creator>
    </item>
    <item>
      <title>Dynamics of Supervised and Reinforcement Learning in the Non-Linear Perceptron</title>
      <link>https://arxiv.org/abs/2409.03749</link>
      <description>arXiv:2409.03749v2 Announce Type: replace-cross 
Abstract: The ability of a brain or a neural network to efficiently learn depends crucially on both the task structure and the learning rule. Previous works have analyzed the dynamical equations describing learning in the relatively simplified context of the perceptron under assumptions of a student-teacher framework or a linearized output. While these assumptions have facilitated theoretical understanding, they have precluded a detailed understanding of the roles of the nonlinearity and input-data distribution in determining the learning dynamics, limiting the applicability of the theories to real biological or artificial neural networks. Here, we use a stochastic-process approach to derive flow equations describing learning, applying this framework to the case of a nonlinear perceptron performing binary classification. We characterize the effects of the learning rule (supervised or reinforcement learning, SL/RL) and input-data distribution on the perceptron's learning curve and the forgetting curve as subsequent tasks are learned. In particular, we find that the input-data noise differently affects the learning speed under SL vs. RL, as well as determines how quickly learning of a task is overwritten by subsequent learning. Additionally, we verify our approach with real data using the MNIST dataset. This approach points a way toward analyzing learning dynamics for more-complex circuit architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03749v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Schmid, James M. Murray</dc:creator>
    </item>
  </channel>
</rss>
