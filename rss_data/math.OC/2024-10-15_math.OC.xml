<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2024 02:05:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>TRFD: A derivative-free trust-region method based on finite differences for composite nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2410.09165</link>
      <description>arXiv:2410.09165v1 Announce Type: new 
Abstract: In this work we present TRFD, a derivative-free trust-region method based on finite differences for minimizing composite functions of the form $f(x)=h(F(x))$, where $F$ is a black-box function assumed to have a Lipschitz continuous Jacobian, and $h$ is a known convex Lipschitz function, possibly nonsmooth. The method approximates the Jacobian of $F$ via forward finite differences. We establish an upper bound for the number of evaluations of $F$ that TRFD requires to find an $\epsilon$-approximate stationary point. For L1 and Minimax problems, we show that our complexity bound reduces to $\mathcal{O}(n\epsilon^{-2})$ for specific instances of TRFD, where $n$ is the number of variables of the problem. Assuming that $h$ is monotone and that the components of $F$ are convex, we also establish a worst-case complexity bound, which reduces to $\mathcal{O}(n\epsilon^{-1})$ for Minimax problems. Numerical results are provided to illustrate the relative efficiency of TRFD in comparison with existing derivative-free solvers for composite nonsmooth optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09165v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D\^an\^a Davar, Geovani Nunes Grapiglia</dc:creator>
    </item>
    <item>
      <title>On the Hypomonotone Class of Variational Inequalities</title>
      <link>https://arxiv.org/abs/2410.09182</link>
      <description>arXiv:2410.09182v1 Announce Type: new 
Abstract: This paper studies the behavior of the extragradient algorithm when applied to hypomonotone operators, a class of problems that extends beyond the classical monotone setting. While the extragradient method is widely known for its efficacy in solving variational inequalities with monotone and Lipschitz continuous operators, we demonstrate that its convergence is not guaranteed in the hypomonotone setting. We provide a characterization theorem that identifies the conditions under which the extragradient algorithm fails to converge. Our results highlight the necessity of stronger assumptions to guarantee convergence of extragradient and to further develop the existing VI methods for broader problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09182v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Khaled Alomar, Tatjana Chavdarova</dc:creator>
    </item>
    <item>
      <title>Analyzing Wage Theft in Day Labor Markets via Principal Agent Models</title>
      <link>https://arxiv.org/abs/2410.09305</link>
      <description>arXiv:2410.09305v1 Announce Type: new 
Abstract: In day labor markets, workers are particularly vulnerable to wage theft. This paper introduces a principal-agent model to analyze the conditions required to mitigate wage theft through fines and establishes the necessary and sufficient conditions to reduce theft. We find that the fines necessary to eliminate theft are significantly larger than those imposed by current labor laws, making wage theft likely to persist under penalty-based methods alone. Through numerical analysis, we show how wage theft disproportionately affects workers with lower reservation utilities and observe that workers with similar reservation utilities experience comparable impacts, regardless of their skill levels. To address the limitations of penalty-based approaches, we extend the model to a dynamic game incorporating worker awareness. We prove that wage theft can be fully eliminated if workers accurately predict theft using historical data and employers follow optimal fixed wage strategy. Additionally, sharing wage theft information becomes an effective long-term solution when employers use any given fixed wage strategies, emphasizing the importance of raising worker awareness through various channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09305v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James P. Bailey, Bahar Cavdar, Yanling Chang</dc:creator>
    </item>
    <item>
      <title>Anderson Acceleration in Nonsmooth Problems: Local Convergence via Active Manifold Identification</title>
      <link>https://arxiv.org/abs/2410.09420</link>
      <description>arXiv:2410.09420v2 Announce Type: new 
Abstract: Anderson acceleration is an effective technique for enhancing the efficiency of fixed-point iterations; however, analyzing its convergence in nonsmooth settings presents significant challenges. In this paper, we investigate a class of nonsmooth optimization algorithms characterized by the active manifold identification property. This class includes a diverse array of methods such as the proximal point method, proximal gradient method, proximal linear method, proximal coordinate descent method, Douglas-Rachford splitting (or the alternating direction method of multipliers), and the iteratively reweighted $\ell_1$ method, among others. Under the assumption that the optimization problem possesses an active manifold at a stationary point, we establish a local R-linear convergence rate for the Anderson-accelerated algorithm. Our extensive numerical experiments further highlight the robust performance of the proposed Anderson-accelerated methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09420v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Li, Luwei Bai, Xiao Wang, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Koopman-based Control for Stochastic Systems: Application to Enhanced Sampling</title>
      <link>https://arxiv.org/abs/2410.09452</link>
      <description>arXiv:2410.09452v1 Announce Type: new 
Abstract: We present a data-driven approach to use the Koopman generator for prediction and optimal control of control-affine stochastic systems. We provide a novel conceptual approach and a proof-of-principle for the determination of optimal control policies which accelerate the simulation of rare events in metastable stochastic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09452v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lei Guo, Jan Heiland, Feliks N\"uske</dc:creator>
    </item>
    <item>
      <title>Generic continuity of the perturbed minima of certain parametric optimization problems</title>
      <link>https://arxiv.org/abs/2410.09526</link>
      <description>arXiv:2410.09526v1 Announce Type: new 
Abstract: We show that in a quite general framework, the parameterized optimization problem can be so perturbed as to be generically well-posed. As an application, we provide a contribution to Stechkin theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09526v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hristina Topalova, Nadia Zlateva</dc:creator>
    </item>
    <item>
      <title>Second-Order Min-Max Optimization with Lazy Hessians</title>
      <link>https://arxiv.org/abs/2410.09568</link>
      <description>arXiv:2410.09568v1 Announce Type: new 
Abstract: This paper studies second-order methods for convex-concave minimax optimization. Monteiro and Svaiter (2012) proposed a method to solve the problem with an optimal iteration complexity of $\mathcal{O}(\epsilon^{-3/2})$ to find an $\epsilon$-saddle point. However, it is unclear whether the computational complexity, $\mathcal{O}((N+ d^2) d \epsilon^{-2/3})$, can be improved. In the above, we follow Doikov et al. (2023) and assume the complexity of obtaining a first-order oracle as $N$ and the complexity of obtaining a second-order oracle as $dN$. In this paper, we show that the computation cost can be reduced by reusing Hessian across iterations. Our methods take the overall computational complexity of $ \tilde{\mathcal{O}}( (N+d^2)(d+ d^{2/3}\epsilon^{-2/3}))$, which improves those of previous methods by a factor of $d^{1/3}$. Furthermore, we generalize our method to strongly-convex-strongly-concave minimax problems and establish the complexity of $\tilde{\mathcal{O}}((N+d^2) (d + d^{2/3} \kappa^{2/3}) )$ when the condition number of the problem is $\kappa$, enjoying a similar speedup upon the state-of-the-art method. Numerical experiments on both real and synthetic datasets also verify the efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09568v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lesi Chen, Chengchang Liu, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Structured Regularization for Constrained Optimization on the SPD Manifold</title>
      <link>https://arxiv.org/abs/2410.09660</link>
      <description>arXiv:2410.09660v1 Announce Type: new 
Abstract: Matrix-valued optimization tasks, including those involving symmetric positive definite (SPD) matrices, arise in a wide range of applications in machine learning, data science and statistics. Classically, such problems are solved via constrained Euclidean optimization, where the domain is viewed as a Euclidean space and the structure of the matrices (e.g., positive definiteness) enters as constraints. More recently, geometric approaches that leverage parametrizations of the problem as unconstrained tasks on the corresponding matrix manifold have been proposed. While they exhibit algorithmic benefits in many settings, they cannot directly handle additional constraints, such as inequality or sparsity constraints. A remedy comes in the form of constrained Riemannian optimization methods, notably, Riemannian Frank-Wolfe and Projected Gradient Descent. However, both algorithms require potentially expensive subroutines that can introduce computational bottlenecks in practise. To mitigate these shortcomings, we introduce a class of structured regularizers, based on symmetric gauge functions, which allow for solving constrained optimization on the SPD manifold with faster unconstrained methods. We show that our structured regularizers can be chosen to preserve or induce desirable structure, in particular convexity and "difference of convex" structure. We demonstrate the effectiveness of our approach in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09660v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Cheng, Melanie Weber</dc:creator>
    </item>
    <item>
      <title>Optimal Inferential Control of Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2410.09663</link>
      <description>arXiv:2410.09663v1 Announce Type: new 
Abstract: Convolutional neural networks (CNNs) have achieved remarkable success in representing and simulating complex spatio-temporal dynamic systems within the burgeoning field of scientific machine learning. However, optimal control of CNNs poses a formidable challenge, because the ultra-high dimensionality and strong nonlinearity inherent in CNNs render them resistant to traditional gradient-based optimal control techniques. To tackle the challenge, we propose an optimal inferential control framework for CNNs that represent a complex spatio-temporal system, which sequentially infers the best control decisions based on the specified control objectives. This reformulation opens up the utilization of sequential Monte Carlo sampling, which is efficient in searching through high-dimensional spaces for nonlinear inference. We specifically leverage ensemble Kalman smoothing, a sequential Monte Carlo algorithm, to take advantage of its computational efficiency for nonlinear high-dimensional systems. Further, to harness graphics processing units (GPUs) to accelerate the computation, we develop a new sequential ensemble Kalman smoother based on matrix variate distributions. The smoother is capable of directly handling matrix-based inputs and outputs of CNNs without vectorization to fit with the parallelized computing architecture of GPUs. Numerical experiments show that the proposed approach is effective in controlling spatio-temporal systems with high-dimensional state and control spaces. All the code and data are available at https://github.com/Alivaziri/Optimal-Inferential-Control-of-CNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09663v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Vaziri, Huazhen Fang</dc:creator>
    </item>
    <item>
      <title>General Constrained Matrix Optimization</title>
      <link>https://arxiv.org/abs/2410.09682</link>
      <description>arXiv:2410.09682v1 Announce Type: new 
Abstract: This paper presents and analyzes the first matrix optimization model which allows general coordinate and spectral constraints. The breadth of problems our model covers is exemplified by a lengthy list of examples from the literature, including semidefinite programming, matrix completion, and quadratically constrained quadratic programs (QCQPs), and we demonstrate our model enables completely novel formulations of numerous problems. Our solution methodology leverages matrix factorization and constrained manifold optimization to develop an equivalent reformulation of our general matrix optimization model for which we design a feasible, first-order algorithm. We prove our algorithm converges to $(\epsilon,\epsilon)$-approximate first-order KKT points of our reformulation in $\mathcal{O}(1/\epsilon^2)$ iterations. The method we developed applies to a special class of constrained manifold optimization problems and is one of the first which generates a sequence of feasible points which converges to a KKT point. We validate our model and method through numerical experimentation. Our first experiment presents a generalized version of semidefinite programming which allows novel eigenvalue constraints, and our second numerical experiment compares our method to the classical semidefinite relaxation approach for solving QCQPs. For the QCQP numerical experiments, we demonstrate our method is able to dominate the classical state-of-the-art approach, solving more than ten times as many problems compared to the standard solution procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09682v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Casey Garner, Gilad Lerman, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Neural Solver Selection for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2410.09693</link>
      <description>arXiv:2410.09693v1 Announce Type: new 
Abstract: Machine learning has increasingly been employed to solve NP-hard combinatorial optimization problems, resulting in the emergence of neural solvers that demonstrate remarkable performance, even with minimal domain-specific knowledge. To date, the community has created numerous open-source neural solvers with distinct motivations and inductive biases. While considerable efforts are devoted to designing powerful single solvers, our findings reveal that existing solvers typically demonstrate complementary performance across different problem instances. This suggests that significant improvements could be achieved through effective coordination of neural solvers at the instance level. In this work, we propose the first general framework to coordinate the neural solvers, which involves feature extraction, selection model, and selection strategy, aiming to allocate each instance to the most suitable solvers. To instantiate, we collect several typical neural solvers with state-of-the-art performance as alternatives, and explore various methods for each component of the framework. We evaluated our framework on two extensively studied combinatorial optimization problems, Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP). Experimental results show that the proposed framework can effectively distribute instances and the resulting composite solver can achieve significantly better performance (e.g., reduce the optimality gap by 0.88\% on TSPLIB and 0.71\% on CVRPLIB) than the best individual neural solver with little extra time cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09693v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengrui Gao, Haopu Shang, Ke Xue, Chao Qian</dc:creator>
    </item>
    <item>
      <title>Revisiting Lossless Convexification: Theoretical Guarantees for Discrete-time Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2410.09748</link>
      <description>arXiv:2410.09748v1 Announce Type: new 
Abstract: Lossless Convexification (LCvx) is a modeling approach that transforms a class of nonconvex optimal control problems, where nonconvexity primarily arises from control constraints, into convex problems through convex relaxations. These convex problems can be solved using polynomial-time numerical methods after discretization, which converts the original infinite-dimensional problem into a finite-dimensional one. However, existing LCvx theory is limited to continuous-time optimal control problems, as the equivalence between the relaxed convex problem and the original nonconvex problem holds only in continuous time. This paper extends LCvx to discrete-time optimal control problems by classifying them into normal and long-horizon cases. For normal cases, after an arbitrarily small perturbation to the system dynamics (recursive equality constraints), applying the existing LCvx method to discrete-time problems results in optimal controls that meet the original nonconvex constraints at all but no more than $n_x - 1$ temporal grid points, where $n_x$ is the state dimension. For long-horizon cases, the existing LCvx method fails, but we resolve this issue by integrating it with a bisection search, leveraging the continuity of the value function from the relaxed convex problem to achieve similar results as in normal cases. This paper improves the theoretical foundation of LCvx, expanding its applicability to real-world discrete-time optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09748v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dayou Luo, Kazuya Echigo, Beh\c{c}et A\c{c}{\i}kme\c{s}e</dc:creator>
    </item>
    <item>
      <title>Ordered Weighted Averaging for Combinatorial Decision Problems with Interval Uncertainty</title>
      <link>https://arxiv.org/abs/2410.09786</link>
      <description>arXiv:2410.09786v1 Announce Type: new 
Abstract: This paper introduces a novel approach to applying the Ordered Weighted Averaging (OWA) operator for uncertain combinatorial problems characterized by interval uncertainty. In this setting, an interval of possible cost outcomes is known for each item, and we would like to minimize the sum of these item costs. By using a weighted integral over the Value-at-Risk, our method provides a more nuanced representation of uncertainty and the decision-maker's risk attitude than a previously proposed OWA aggregation method. We analyze fundamental properties of the OWA operator we propose, show that the classic discrete OWA operator converges to our framework when scenarios are sampled, and propose a 2-approximation algorithm. In computational experiments, we compare heuristic solution algorithms to alternative aggregation methods and demonstrate the improved flexibility of our setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09786v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Werner Baak, Marc Goerigk</dc:creator>
    </item>
    <item>
      <title>Duality-based Dynamical Optimal Transport of Discrete Time Systems</title>
      <link>https://arxiv.org/abs/2410.09801</link>
      <description>arXiv:2410.09801v1 Announce Type: new 
Abstract: We study dynamical optimal transport of discrete time systems (dDOT) with Lagrangian cost. The problem is approached by combining optimal control and Kantorovich duality theory. Based on the derived solution, a first order splitting algorithm is proposed for numerical implementation. While solving partial differential equations is often required in the continuous time case, a salient feature of our algorithm is that it avoids equation solving entirely. Furthermore, it is typical to solve a convex optimization problem at each grid point in continuous time settings, the discrete case reduces this to a straightforward maximization. Additionally, the proposed algorithm is highly amenable to parallelization. For linear systems with Gaussian marginals, we provide a semi-definite programming formulation based on our theory. Finally, we validate the approach with a simulation example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09801v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongjun Wu, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Phase retrieval: Global convergence of gradient descent with optimal sample complexity</title>
      <link>https://arxiv.org/abs/2410.09990</link>
      <description>arXiv:2410.09990v1 Announce Type: new 
Abstract: This paper addresses the phase retrieval problem, which aims to recover a signal vector $x$ from $m$ measurements $y_i=|\langle a_i,x^{\natural}\rangle|^2$, $i=1,\ldots,m$. A standard approach is to solve a nonconvex least squares problem using gradient descent with random initialization, which is known to work efficiently given a sufficient number of measurements. However, whether $O(n)$ measurements suffice for gradient descent to recover the ground truth efficiently has remained an open question. Prior work has established that $O(n\,{\rm poly}(\log n))$ measurements are sufficient. In this paper, we resolve this open problem by proving that $m=O(n)$ Gaussian random measurements are sufficient to guarantee, with high probability, that the objective function has a benign global landscape. This sample complexity is optimal because at least $\Omega(n)$ measurements are required for exact recovery. The landscape result allows us to further show that gradient descent with a constant step size converges to the ground truth from almost any initial point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09990v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eodore Fougereux, C\'edric Josz, Xiaopeng Li</dc:creator>
    </item>
    <item>
      <title>Theoretical and numerical indirect stabilization of coupled wave equations with a single time-delayed damping</title>
      <link>https://arxiv.org/abs/2410.09995</link>
      <description>arXiv:2410.09995v1 Announce Type: new 
Abstract: The focal point of this paper is to theoretically investigate and numerically validate the effect of time delay on the exponential stabilization of a class of coupled hyperbolic systems with delayed and non-delayed dampings. The class in question consists of two strongly coupled wave equations featuring a delayed and non-delayed damping terms on the first wave equation. Through a standard change of variables and semi-group theory, we address the well-posedness of the considered coupled system. Thereon, based on some observability inequalities, we derive sufficient conditions guaranteeing the exponential decay of a suitable energy. On the other hand, from the numerical point of view, we validate the theoretical results in $1D$ domains based on a suitable numerical approximation obtained through the Finite Difference Method. More precisely, we construct a discrete numerical scheme which preserves the energy decay property of its continuous counterpart. Our theoretical analysis and implementation of our developed numerical scheme assert the effect of the time-delayed damping on the exponential stability of strongly coupled wave equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09995v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alhabib Moumni, Mohamed Mehdaoui, Jawad Salhi, Mouhcine Tilioua</dc:creator>
    </item>
    <item>
      <title>Bishop-Phelps Type Scalarization for Vector Optimization in Real Topological-Linear Spaces</title>
      <link>https://arxiv.org/abs/2410.10026</link>
      <description>arXiv:2410.10026v1 Announce Type: new 
Abstract: It is well-known that scalarization techniques (e.g., in the sense of Gerstewitz; Kasimbeyli; Pascoletti and Serafini; Zaffaroni) are useful for generating (weakly, properly) efficient solutions of vector optimization problems. One recognized approach is the conic scalarization method in vector optimization in real normed spaces proposed by Kasimbeyli (2010, SIAM J Optim 20), which is based on augmented dual cones and Bishop-Phelps type (norm-linear) scalarizing functions. In this paper, we present new results on cone separation in real topological-linear spaces by using Bishop-Phelps type separating cones / separating seminorm-linear functions. Moreover, we study some extensions of known scalarization results in vector optimization (in the sense of Eichfelder; Gerstewitz; Jahn; Kasimbeyli; Pascoletti and Serafini). On this basis, we propose a Bishop-Phelps type scalarization method for vector optimization problems in real topological-linear spaces, which can be seen as an extension of Kasimbeyli's conic scalarization method in real normed spaces. Within this framework, we derive new Bishop-Phelps type scalarization results for the concepts of weak efficiency and different types of proper efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10026v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian G\"unther, Bahareh Khazayel, Radu Strugariu, Christiane Tammer</dc:creator>
    </item>
    <item>
      <title>Non-subdifferentiability optimality and mean value theorems via new relative subdifferentials</title>
      <link>https://arxiv.org/abs/2410.10065</link>
      <description>arXiv:2410.10065v1 Announce Type: new 
Abstract: Motivated by the optimality principles for non-subdifferentiable optimization problems, we introduce new relative subdifferentials and examine some properties for relatively lower semicontinuous functions including $\epsilon$-regular subdifferential and limiting subdifferential relative to a set. The fuzzy sum rule for the relative $\epsilon$-regular subdifferentials and the sum rule for the relative limiting subdifferentials are established. We utilize these relative subdifferentials to establish optimality conditions for non-subdifferentiable optimization problems under mild constraint qualifications. Examples are given to demonstrate that the optimality conditions obtained work better and sharper than some existing results. We also provide different versions of mean value theorems via the relative subdifferentials and employ them to characterize the equivalences between the convexity relative to a set and the monotonicity of the relative subdifferentials of a non-subdifferentiable function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10065v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vo Duc Thinh, Thai Doan Chuong, Xiaolong Qin</dc:creator>
    </item>
    <item>
      <title>The Augmented Factorization Bound for Maximum-Entropy Sampling</title>
      <link>https://arxiv.org/abs/2410.10078</link>
      <description>arXiv:2410.10078v1 Announce Type: new 
Abstract: The maximum-entropy sampling problem (MESP) aims to select the most informative principal submatrix of a prespecified size from a given covariance matrix. This paper proposes an augmented factorization bound for MESP based on concave relaxation. By leveraging majorization and Schur-concavity theory, we demonstrate that this new bound dominates the classic factorization bound of Nikolov (2015) and a recent upper bound proposed by Li et al. (2024). Furthermore, we provide theoretical guarantees that quantify how much our proposed bound improves the two existing ones and establish sufficient conditions for when the improvement is strictly attained. These results allow us to refine the celebrated approximation bounds for the two approximation algorithms of MESP. Besides, motivated by the strength of this new bound, we develop a variable fixing logic for MESP from a primal perspective. Finally, our numerical experiments demonstrate that our proposed bound achieves smaller integrality gaps and fixes more variables than the tightest bounds in the MESP literature on most benchmark instances, with the improvement being particularly significant when the condition number of the covariance matrix is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10078v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongchun Li</dc:creator>
    </item>
    <item>
      <title>Timeslot allocation for waiting list control</title>
      <link>https://arxiv.org/abs/2410.10221</link>
      <description>arXiv:2410.10221v1 Announce Type: new 
Abstract: As pressure on the healthcare system increases, patients that require elective surgery experience longer access times to pre- and post-operative appointments and surgery. Hospitals can control their waiting lists by allocating timeslots to different types of appointments. To allow appointments to be planned timely, this allocation is decided several weeks in advance. However, the consequences of the timeslot allocation are uncertain, as not all patients follow the same treatment pathway. Furthermore, as these planning decisions are made in advance, they are based on an uncertain prediction of future waiting lists. We aim to develop methods that support hospitals in timeslot allocation to reduce access times for patients and ensure that all available capacity is used. The problem is modelled as a Markov decision process (MDP). As the state space is very large, we use least-squares policy iteration to find an approximate solution, formulate an (integer) linear program to solve a deterministic variant of the MDP, and investigate several decision rules. The solution methods are tested on a case study at the Sint Maartenskliniek, a hospital in the Netherlands. Based on a simulation study, we find that all methods improve on the currently used static allocation method, with the (integer) linear program leading to the best results. However, the performance deteriorates with the number of weeks the hospital plans ahead. To counter this, we propose a method in which a percentage of timeslots is statically allocated far in advance, and the remaining timeslots are allocated when enough information is available to effectively deal with variability. For the case study, we find that statically allocating 60% of the timeslots and dynamically allocating the remainder 6 weeks in advance provides the best results in terms of meeting access time targets and efficient resource utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10221v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Y. M. van der Vlugt, J. T. van Essen, R. F. M. Vromans, M. Carlier</dc:creator>
    </item>
    <item>
      <title>Approximate and null controllability of a parabolic system with coupling terms of order one</title>
      <link>https://arxiv.org/abs/2410.10307</link>
      <description>arXiv:2410.10307v1 Announce Type: new 
Abstract: We study two notions of controllability on a parabolic system with coupling terms of order one. Based on existing results on, on one side parabolic systems with coupling terms of order zero, and on the other one parabolic systems with coupling terms of order one where the control domain is an interval, we give here some controllability conditions in the case where the coupling term is of order one and the control domain is not necessarily an interval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10307v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Am\'elie Dupouy</dc:creator>
    </item>
    <item>
      <title>Constrained Consensus-Based Optimization and Numerical Heuristics for the Few Particle Regime</title>
      <link>https://arxiv.org/abs/2410.10361</link>
      <description>arXiv:2410.10361v1 Announce Type: new 
Abstract: Consensus-based optimization (CBO) is a versatile multi-particle optimization method for performing nonconvex and nonsmooth global optimizations in high dimensions. Proofs of global convergence in probability have been achieved for a broad class of objective functions in unconstrained optimizations. In this work we adapt the algorithm for solving constrained optimizations on compact and unbounded domains with boundary by leveraging emerging reflective boundary conditions. In particular, we close a relevant gap in the literature by providing a global convergence proof for the many-particle regime comprehensive of convergence rates.
  On the one hand, for the sake of minimizing running cost, it is desirable to keep the number of particles small. On the other hand, reducing the number of particles implies a diminished capability of exploration of the algorithm. Hence numerical heuristics are needed to ensure convergence of CBO in the few-particle regime.
  In this work, we also significantly improve the convergence and complexity of CBO by utilizing an adaptive region control mechanism and by choosing geometry-specific random noise. In particular, by combining a hierarchical noise structure with a multigrid finite element method, we are able to compute global minimizers for a constrained $p$-Allen-Cahn problem with obstacles, a very challenging variational problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10361v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Beddrich, Enis Chenchene, Massimo Fornasier, Hui Huang, Barbara Wohlmuth</dc:creator>
    </item>
    <item>
      <title>Kinetic models for optimization: a unified mathematical framework for metaheuristics</title>
      <link>https://arxiv.org/abs/2410.10369</link>
      <description>arXiv:2410.10369v1 Announce Type: new 
Abstract: Metaheuristic algorithms, widely used for solving complex non-convex and non-differentiable optimization problems, often lack a solid mathematical foundation. In this review, we explore how concepts and methods from kinetic theory can offer a potential unifying framework for a variety of metaheuristic optimization methods. By applying principles from collisional and non-collisional kinetic theory, we outline how particle-based algorithms like Simulated Annealing, Genetic Algorithms, Particle Swarm Optimization, and Ensemble Kalman Filter may be described through a common statistical perspective. This approach not only provides a path to deeper theoretical insights and connects different methods under suitable asymptotic scalings, but also enables the derivation of novel algorithms using alternative numerical solvers. While not exhaustive, our review highlights how kinetic models can enhance the mathematical understanding of existing optimization algorithms and inspire new computational strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10369v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Borghi, Michael Herty, Lorenzo Pareschi</dc:creator>
    </item>
    <item>
      <title>Achieving Optimal Breakdown for Byzantine Robust Gossip</title>
      <link>https://arxiv.org/abs/2410.10418</link>
      <description>arXiv:2410.10418v1 Announce Type: new 
Abstract: Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. We investigate the notion of breakdown point, and show an upper bound on the number of adversaries that decentralized algorithms can tolerate. We introduce $\mathrm{CG}^+$, an algorithm at the intersection of $\mathrm{ClippedGossip}$ and $\mathrm{NNA}$, two popular approaches for robust decentralized learning. $\mathrm{CG}^+$ meets our upper bound, and thus obtains optimal robustness guarantees, whereas neither of the existing two does. We provide experimental evidence for this gap by presenting an attack tailored to sparse graphs which breaks $\mathrm{NNA}$ but against which $\mathrm{CG}^+$ is robust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10418v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renaud Gaucher, Aymeric Dieuleveut, Hadrien Hendrikx</dc:creator>
    </item>
    <item>
      <title>Consensus in Multiagent Systems with lack of connection</title>
      <link>https://arxiv.org/abs/2410.10486</link>
      <description>arXiv:2410.10486v1 Announce Type: new 
Abstract: We consider multi-agent systems with cooperative interactions and study the convergence to consensus in the case of time-dependent lack of interaction.
  We prove a new condition ensuring consensus: we define a graph in which directed arrows correspond to connection functions that converge (in the weak sense) to some function with a positive integral on all intervals of the form $[t,+\infty)$. If the graph has a vertex reachable from all other indices, then the system converges to consensus. We show that this requirement generalizes some known sufficient conditions for convergence, such as the Persistent Excitation one. We also give a second new condition, transversal to the known ones: total connectedness of the undirected graph formed by the non-vanishing of limiting functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10486v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Bentaibi, Laura Caravenna, Jean-Paul A. Gauthier, Francesco Rossi</dc:creator>
    </item>
    <item>
      <title>Accelerated Convergent Motion Compensated Image Reconstruction</title>
      <link>https://arxiv.org/abs/2410.10503</link>
      <description>arXiv:2410.10503v1 Announce Type: new 
Abstract: Motion correction aims to prevent motion artefacts which may be caused by respiration, heartbeat, or head movements for example. In a preliminary step, the measured data is divided in gates corresponding to motion states, and displacement maps from a reference state to each motion state are estimated. One common technique to perform motion correction is the motion compensated image reconstruction framework, where the displacement maps are integrated into the forward model corresponding to gated data. For standard algorithms, the computational cost per iteration increases linearly with the number of gates. In order to accelerate the reconstruction, we propose the use of a randomized and convergent algorithm whose per iteration computational cost scales constantly with the number of gates. We show improvement on theoretical rates of convergence and observe the predicted speed-up on two synthetic datasets corresponding to rigid and non-rigid motion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10503v1</guid>
      <category>math.OC</category>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claire Delplancke, Kris Thielemans, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Barrier Function for Bilevel Optimization with Coupled Lower-Level Constraints: Formulation, Approximation and Algorithms</title>
      <link>https://arxiv.org/abs/2410.10670</link>
      <description>arXiv:2410.10670v1 Announce Type: new 
Abstract: In this paper, we consider bilevel optimization problem where the lower-level has coupled constraints, i.e. the constraints depend both on the upper- and lower-level variables. In particular, we consider two settings for the lower-level problem. The first is when the objective is strongly convex and the constraints are convex with respect to the lower-level variable; The second is when the lower-level is a linear program. We propose to utilize a barrier function reformulation to translate the problem into an unconstrained problem. By developing a series of new techniques, we proved that both the hyperfunction value and hypergradient of the barrier reformulated problem (uniformly) converge to those of the original problem under minimal assumptions. Further, to overcome the non-Lipschitz smoothness of hyperfunction and lower-level problem for barrier reformulated problems, we design an adaptive algorithm that ensures a non-asymptotic convergence guarantee. We also design an algorithm that converges to the stationary point of the original problem asymptotically under certain assumptions. The proposed algorithms require minimal assumptions, and to our knowledge, they are the first with convergence guarantees when the lower-level problem is a linear program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10670v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Jiang, Jiaxiang Li, Mingyi Hong, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Optimizing $(L_0, L_1)$-Smooth Functions by Gradient Methods</title>
      <link>https://arxiv.org/abs/2410.10800</link>
      <description>arXiv:2410.10800v1 Announce Type: new 
Abstract: We study gradient methods for solving an optimization problem with an $(L_0, L_1)$-smooth objective function. This problem class generalizes that of Lipschitz-smooth problems and has gained interest recently, as it captures a broader range of machine learning applications. We provide novel insights on the properties of this function class and develop a general framework for analyzing optimization methods for $(L_0, L_1)$-smooth function in a principled manner. While our convergence rate estimates recover existing results for minimizing the gradient norm for nonconvex problems, our approach allows us to significantly improve the current state-of-the-art complexity results in the case of convex problems. We show that both the gradient method with Polyak stepsizes and the normalized gradient method, without any knowledge of the parameters $L_0$ and $L_1$, achieve the same complexity bounds as the method with the knowledge of these constants. In addition to that, we show that a carefully chosen accelerated gradient method can be applied to $(L_0, L_1)$-smooth functions, further improving previously known results. In all cases, the efficiency bounds we establish do not have an exponential dependency on $L_0$ or $L_1$, and do not depend on the initial gradient norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10800v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Vankov, Anton Rodomanov, Angelia Nedich, Lalitha Sankar, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Learning to Walk from Three Minutes of Real-World Data with Semi-structured Dynamics Models</title>
      <link>https://arxiv.org/abs/2410.09163</link>
      <description>arXiv:2410.09163v1 Announce Type: cross 
Abstract: Traditionally, model-based reinforcement learning (MBRL) methods exploit neural networks as flexible function approximators to represent a priori unknown environment dynamics. However, training data are typically scarce in practice, and these black-box models often fail to generalize. Modeling architectures that leverage known physics can substantially reduce the complexity of system-identification, but break down in the face of complex phenomena such as contact. We introduce a novel framework for learning semi-structured dynamics models for contact-rich systems which seamlessly integrates structured first principles modeling techniques with black-box auto-regressive models. Specifically, we develop an ensemble of probabilistic models to estimate external forces, conditioned on historical observations and actions, and integrate these predictions using known Lagrangian dynamics. With this semi-structured approach, we can make accurate long-horizon predictions with substantially less data than prior methods. We leverage this capability and propose Semi-Structured Reinforcement Learning (SSRL) a simple model-based learning framework which pushes the sample complexity boundary for real-world learning. We validate our approach on a real-world Unitree Go1 quadruped robot, learning dynamic gaits -- from scratch -- on both hard and soft surfaces with just a few minutes of real-world data. Video and code are available at: https://sites.google.com/utexas.edu/ssrl</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09163v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Levy, Tyler Westenbroek, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Two-person positive shortest path games have Nash equlibria in pure stationary strategies</title>
      <link>https://arxiv.org/abs/2410.09257</link>
      <description>arXiv:2410.09257v1 Announce Type: cross 
Abstract: We prove that every finite two-person positive shortest path game has a Nash equilibrium (NE) in pure stationary strategies, which can be computed in polynomial time. The existence result holds also for graphs with finite out-degrees. Moreover, we prove that a terminal NE exists provided at least one of two players can guarantee reaching a terminal. If no one can do it, in other words, if each of two players can cut all terminals from the initial position $s$, then, obviously, a cyclic NE exists, although its cost is infinite for both players, since we restrict ourselves to positive games. We conjecture that a terminal NE exists too, provided there exists a directed path from $s$ to a terminal. However, this is open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09257v1</guid>
      <category>cs.DM</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Endre Boros, Khaled Elbassioni, Vladimir Gurvich, Mikhail Vyalyi</dc:creator>
    </item>
    <item>
      <title>Computational complexity of the recoverable robust shortest path problem in acyclic digraphs</title>
      <link>https://arxiv.org/abs/2410.09425</link>
      <description>arXiv:2410.09425v1 Announce Type: cross 
Abstract: In this paper, the recoverable robust shortest path problem in acyclic digraphs is considered. The interval budgeted uncertainty representation is used to model the uncertain second-stage costs. The computational complexity of this problem has been open to date. In this paper, we prove that the problem is strongly NP-hard even for the case of layered acyclic digraphs. We also show that for the discrete budgeted uncertainty, the problem is not approximable unless P=NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09425v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Kasperski, Pawel Zielinski</dc:creator>
    </item>
    <item>
      <title>Identification of Non-causal Graphical Models</title>
      <link>https://arxiv.org/abs/2410.09480</link>
      <description>arXiv:2410.09480v1 Announce Type: cross 
Abstract: The paper considers the problem to estimate non-causal graphical models whose edges encode smoothing relations among the variables. We propose a new covariance extension problem and show that the solution minimizing the transportation distance with respect to white noise process is a double-sided autoregressive non-causal graphical model. Then, we generalize the paradigm to a class of graphical autoregressive moving-average models. Finally, we test the performance of the proposed method through some numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09480v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyao You, Mattia Zorzi</dc:creator>
    </item>
    <item>
      <title>Transaction Execution Mechanisms</title>
      <link>https://arxiv.org/abs/2410.09555</link>
      <description>arXiv:2410.09555v1 Announce Type: cross 
Abstract: This paper studies transaction execution mechanisms (TEMs) for blockchains as the efficient resource allocation across multiple parallel execution queues or "local fee markets." We present a model considering capacity constraints, user valuations, and delay costs in a multi-queue system with an aggregate capacity constraint due to global consensus. We show that revenue maximization tends to allocate capacity to the highest-paying queue, while welfare maximization generally serves all queues. Optimal relative pricing of different queues depends on factors such as market size, demand elasticity, and the balance between local and global congestion. Our results have implications for evolving blockchain architectures, including parallel execution, DAG-based systems, and multiple concurrent proposers, and can help design more efficient TEMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09555v1</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdoulaye Ndiaye</dc:creator>
    </item>
    <item>
      <title>Provable Acceleration of Nesterov's Accelerated Gradient for Rectangular Matrix Factorization and Linear Neural Networks</title>
      <link>https://arxiv.org/abs/2410.09640</link>
      <description>arXiv:2410.09640v1 Announce Type: cross 
Abstract: We study the convergence rate of first-order methods for rectangular matrix factorization, which is a canonical nonconvex optimization problem. Specifically, given a rank-$r$ matrix $\mathbf{A}\in\mathbb{R}^{m\times n}$, we prove that gradient descent (GD) can find a pair of $\epsilon$-optimal solutions $\mathbf{X}_T\in\mathbb{R}^{m\times d}$ and $\mathbf{Y}_T\in\mathbb{R}^{n\times d}$, where $d\geq r$, satisfying $\lVert\mathbf{X}_T\mathbf{Y}_T^\top-\mathbf{A}\rVert_\mathrm{F}\leq\epsilon\lVert\mathbf{A}\rVert_\mathrm{F}$ in $T=O(\kappa^2\log\frac{1}{\epsilon})$ iterations with high probability, where $\kappa$ denotes the condition number of $\mathbf{A}$. Furthermore, we prove that Nesterov's accelerated gradient (NAG) attains an iteration complexity of $O(\kappa\log\frac{1}{\epsilon})$, which is the best-known bound of first-order methods for rectangular matrix factorization. Different from small balanced random initialization in the existing literature, we adopt an unbalanced initialization, where $\mathbf{X}_0$ is large and $\mathbf{Y}_0$ is $0$. Moreover, our initialization and analysis can be further extended to linear neural networks, where we prove that NAG can also attain an accelerated linear convergence rate. In particular, we only require the width of the network to be greater than or equal to the rank of the output label matrix. In contrast, previous results achieving the same rate require excessive widths that additionally depend on the condition number and the rank of the input data matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09640v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenghao Xu, Yuqing Wang, Tuo Zhao, Rachel Ward, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Geometric Optimal Control of Mechanical Systems with Gravitational and Resistive Force</title>
      <link>https://arxiv.org/abs/2410.09657</link>
      <description>arXiv:2410.09657v1 Announce Type: cross 
Abstract: Optimal control plays a crucial role in numerous mechanical and robotic applications. Broadly, optimal control methods are divided into direct methods (which optimize trajectories directly via discretization) and indirect methods (which transform optimality conditions into equations that guarantee optimal trajectories). While direct methods could mask geometric insights into system dynamics due to discretization, indirect methods offer a deeper understanding of the system's geometry. In this paper, we propose a geometric framework for understanding optimal control in mechanical systems, focusing on the combined effects of inertia, drag, and gravitational forces. By modeling mechanical systems as configuration manifolds equipped with kinetic and drag metrics, alongside a potential field, we explore how these factors influence trajectory optimization. We derive optimal control equations incorporating these effects and apply them to two-link and UR5 robotic manipulators, demonstrating how manifold curvature and resistive forces shape optimal trajectories. This work offers a comprehensive geometric approach to optimal control, with broad applications to robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09657v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinwoo Choi, Alejandro Cabrera, Ross L. Hatton</dc:creator>
    </item>
    <item>
      <title>How to unlearn a learned Machine Learning model ?</title>
      <link>https://arxiv.org/abs/2410.09935</link>
      <description>arXiv:2410.09935v1 Announce Type: cross 
Abstract: In contemporary times, machine learning (ML) has sparked a remarkable revolution across numerous domains, surpassing even the loftiest of human expectations. However, despite the astounding progress made by ML, the need to regulate its outputs and capabilities has become imperative. A viable approach to address this concern is by exerting control over the data used for its training, more precisely, by unlearning the model from undesired data. In this article, I will present an elegant algorithm for unlearning a machine learning model and visualize its abilities. Additionally, I will elucidate the underlying mathematical theory and establish specific metrics to evaluate both the unlearned model's performance on desired data and its level of ignorance regarding unwanted data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09935v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seifeddine Achour</dc:creator>
    </item>
    <item>
      <title>Gradient Span Algorithms Make Predictable Progress in High Dimension</title>
      <link>https://arxiv.org/abs/2410.09973</link>
      <description>arXiv:2410.09973v1 Announce Type: cross 
Abstract: We prove that all 'gradient span algorithms' have asymptotically deterministic behavior on scaled Gaussian random functions as the dimension tends to infinity. In particular, this result explains the counterintuitive phenomenon that different training runs of many large machine learning models result in approximately equal cost curves despite random initialization on a complicated non-convex landscape.
  The distributional assumption of (non-stationary) isotropic Gaussian random functions we use is sufficiently general to serve as realistic model for machine learning training but also encompass spin glasses and random quadratic functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09973v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Felix Benning, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>Improved Regret Bound for Safe Reinforcement Learning via Tighter Cost Pessimism and Reward Optimism</title>
      <link>https://arxiv.org/abs/2410.10158</link>
      <description>arXiv:2410.10158v1 Announce Type: cross 
Abstract: This paper studies the safe reinforcement learning problem formulated as an episodic finite-horizon tabular constrained Markov decision process with an unknown transition kernel and stochastic reward and cost functions. We propose a model-based algorithm based on novel cost and reward function estimators that provide tighter cost pessimism and reward optimism. While guaranteeing no constraint violation in every episode, our algorithm achieves a regret upper bound of $\widetilde{\mathcal{O}}((\bar C - \bar C_b)^{-1}H^{2.5} S\sqrt{AK})$ where $\bar C$ is the cost budget for an episode, $\bar C_b$ is the expected cost under a safe baseline policy over an episode, $H$ is the horizon, and $S$, $A$ and $K$ are the number of states, actions, and episodes, respectively. This improves upon the best-known regret upper bound, and when $\bar C- \bar C_b=\Omega(H)$, it nearly matches the regret lower bound of $\Omega(H^{1.5}\sqrt{SAK})$. We deduce our cost and reward function estimators via a Bellman-type law of total variance to obtain tight bounds on the expected sum of the variances of value function estimates. This leads to a tighter dependence on the horizon in the function estimators. We also present numerical results to demonstrate the computational effectiveness of our proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10158v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kihyun Yu, Duksang Lee, William Overman, Dabeen Lee</dc:creator>
    </item>
    <item>
      <title>Principled Bayesian Optimisation in Collaboration with Human Experts</title>
      <link>https://arxiv.org/abs/2410.10452</link>
      <description>arXiv:2410.10452v1 Announce Type: cross 
Abstract: Bayesian optimisation for real-world problems is often performed interactively with human experts, and integrating their domain knowledge is key to accelerate the optimisation process. We consider a setup where experts provide advice on the next query point through binary accept/reject recommendations (labels). Experts' labels are often costly, requiring efficient use of their efforts, and can at the same time be unreliable, requiring careful adjustment of the degree to which any expert is trusted. We introduce the first principled approach that provides two key guarantees. (1) Handover guarantee: similar to a no-regret property, we establish a sublinear bound on the cumulative number of experts' binary labels. Initially, multiple labels per query are needed, but the number of expert labels required asymptotically converges to zero, saving both expert effort and computation time. (2) No-harm guarantee with data-driven trust level adjustment: our adaptive trust level ensures that the convergence rate will not be worse than the one without using advice, even if the advice from experts is adversarial. Unlike existing methods that employ a user-defined function that hand-tunes the trust level adjustment, our approach enables data-driven adjustments. Real-world applications empirically demonstrate that our method not only outperforms existing baselines, but also maintains robustness despite varying labelling accuracy, in tasks of battery design with human experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10452v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wenjie Xu, Masaki Adachi, Colin N. Jones, Michael A. Osborne</dc:creator>
    </item>
    <item>
      <title>Inverse Problems and Data Assimilation: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2410.10523</link>
      <description>arXiv:2410.10523v1 Announce Type: cross 
Abstract: The aim of these notes is to demonstrate the potential for ideas in machine learning to impact on the fields of inverse problems and data assimilation. The perspective is one that is primarily aimed at researchers from inverse problems and/or data assimilation who wish to see a mathematical presentation of machine learning as it pertains to their fields. As a by-product, we include a succinct mathematical treatment of various topics in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10523v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eviatar Bach, Ricardo Baptista, Daniel Sanz-Alonso, Andrew Stuart</dc:creator>
    </item>
    <item>
      <title>Geometry, Computation, and Optimality in Stochastic Optimization</title>
      <link>https://arxiv.org/abs/1909.10455</link>
      <description>arXiv:1909.10455v3 Announce Type: replace 
Abstract: We study computational and statistical consequences of problem geometry in stochastic and online optimization. By focusing on constraint set and gradient geometry, we characterize the problem families for which stochastic- and adaptive-gradient methods are (minimax) optimal and, conversely, when nonlinear updates -- such as those mirror descent employs -- are necessary for optimal convergence. When the constraint set is quadratically convex, diagonally pre-conditioned stochastic gradient methods are minimax optimal. We provide quantitative converses showing that the ``distance'' of the underlying constraints from quadratic convexity determines the sub-optimality of subgradient methods. These results apply, for example, to any $\ell_p$-ball for $p &lt; 2$, and the computation/accuracy tradeoffs they demonstrate exhibit a striking analogy to those in Gaussian sequence models.</description>
      <guid isPermaLink="false">oai:arXiv.org:1909.10455v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Cheng, Daniel Levy, John C. Duchi</dc:creator>
    </item>
    <item>
      <title>Topology Learning of unknown Networked Linear Dynamical System excited by Cyclostationary inputs</title>
      <link>https://arxiv.org/abs/2009.12667</link>
      <description>arXiv:2009.12667v2 Announce Type: replace 
Abstract: Topology learning of networked dynamical systems is an important problem with implications to optimal control, decision-making over networks, cybersecurity and safety. The majority of prior work in consistent topology estimation relies on dynamical systems excited by temporally uncorrelated processes. In this article, we present a novel algorithm for guaranteed topology learning of networks that are excited by temporally (colored) cyclostationary processes, which encompasses a wide range of temporal correlation including wide-sense stationarity. Furthermore, unlike prior work, the framework applies to linear dynamic system with complex valued dependencies, and leverages group lasso regularization for effective learning of the network structure. In the second part of the article, we analyze conditions for consistent topology learning for bidirected tree networks when a subset of the network is unobserved. Here, the full topology along with unobserved nodes are recovered from observed node's time-series alone. Our theoretical contributions are validated on simulated data as well as on real-world climate data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.12667v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish Doddi, Deepjyoti Deka, Murti Salapaka</dc:creator>
    </item>
    <item>
      <title>SAPD+: An Accelerated Stochastic Method for Nonconvex-Concave Minimax Problems</title>
      <link>https://arxiv.org/abs/2205.15084</link>
      <description>arXiv:2205.15084v4 Announce Type: replace 
Abstract: We propose a new stochastic method SAPD+ for solving nonconvex-concave minimax problems of the form $\min\max\mathcal{L}(x,y)=f(x)+\Phi(x,y)-g(y)$, where $f,g$ are closed convex and $\Phi(x,y)$ is a smooth function that is weakly convex in $x$, (strongly) concave in $y$. Let $\delta^2$ denote the variance bound for the unbiased stochastic oracle used within SAPD+ to estimate $\nabla\Phi$. When $\delta&gt;0$, for both strongly concave and merely concave settings, SAPD+ achieves the best known oracle complexities: $\mathcal{O}\Big(\kappa_y\max\Big\{1,\frac{\delta^2}{\epsilon^2}\Big\}\frac{L\mathcal{G}_0}{\epsilon^{2}}\Big)$ for the strongly concave case without assuming compactness of the problem domain, and $\mathcal{O}\Big(\frac{L^3\mathcal{D}_y^2\mathcal{G}_0}{\epsilon^{4}}\Big(1+\frac{\delta^2}{\epsilon^2}\Big)\Big)$ for the merely concave case, where $\kappa_y\geq 1$ is the condition number, $L$ is the Lipschitz constant of $\nabla \Phi$, $\mathcal{G}_0$ is the primal-dual gap of the initial point, and $\mathcal{D}_y=\sup\{\|y\|:\ y\in\mathbf{dom} g\}$. We also propose SAPD+ with variance reduction, which enjoys $\mathcal{O}\Big(\max\Big\{\kappa_y,\sqrt{\frac{\delta}{\epsilon}}\Big\}\cdot (1+\kappa_y\frac{\delta}{\epsilon})\frac{L\mathcal{G}_0}{\epsilon^2}\Big)$ oracle complexity for weakly convex-strongly concave setting --this is the best known upper complexity bound in the literature for this setting and our paper establishes it for the first time. We demonstrate the efficiency of SAPD+ on a distributionally robust learning problem with a nonconvex regularizer and also on a multi-class classification problem in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.15084v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems, 35, pp.21668-21681 (2022)</arxiv:journal_reference>
      <dc:creator>Xuan Zhang, Necdet Serhat Aybat, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>An Empirical Quantile Estimation Approach to Nonlinear Optimization Problems with Chance Constraints</title>
      <link>https://arxiv.org/abs/2211.00675</link>
      <description>arXiv:2211.00675v5 Announce Type: replace 
Abstract: We investigate an empirical quantile estimation approach to solve chance-constrained nonlinear optimization problems. Our approach is based on the reformulation of the chance constraint as an equivalent quantile constraint to provide stronger signals on the gradient. In this approach, the value of the quantile function is estimated empirically from samples drawn from the random parameters, and the gradient of the quantile function is estimated via a finite-difference approximation on top of the quantile-function-value estimation. We establish a convergence theory of this approach within the framework of an augmented Lagrangian method for solving general nonlinear constrained optimization problems. The foundation of the convergence analysis is a concentration property of the empirical quantile process, and the analysis is divided based on whether or not the quantile function is differentiable. In contrast to the sampling-and-smoothing approach used in the literature, the method developed in this paper does not involve any smoothing function and hence the quantile-function gradient approximation is easier to implement and there are less accuracy-control parameters to tune. We demonstrate the effectiveness of this approach and compare it with a smoothing method for the quantile-gradient estimation. Numerical investigation shows that the two approaches are competitive for certain problem instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00675v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-024-02532-0</arxiv:DOI>
      <dc:creator>Fengqiao Luo, Jeffrey Larson</dc:creator>
    </item>
    <item>
      <title>An Efficient Global Optimization Algorithm with Adaptive Estimates of the Local Lipschitz Constants</title>
      <link>https://arxiv.org/abs/2211.04129</link>
      <description>arXiv:2211.04129v3 Announce Type: replace 
Abstract: In this work, we present a new deterministic partition-based Global Optimization (GO) algorithm that uses estimates of the local Lipschitz constants associated with different sub-regions of the domain of the objective function. The estimates of the local Lipschitz constants associated with each partition are the result of adaptively balancing the global and local information obtained so far from the algorithm, given in terms of absolute slopes. We motivate a coupling strategy with local optimization algorithms (both gradient-based and derivative-free) to accelerate the convergence speed of the proposed approach. In the end, we compare our approach HALO (Hybrid Adaptive Lipschitzian Optimization) with respect to popular GO algorithms using hundreds of test functions. From the numerical results, the performance of HALO is very promising and can extend our arsenal of efficient procedures for attacking challenging real-world GO problems. The Python code of HALO is publicly available on GitHub. \url{https://github.com/dannyzx/HALO}</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04129v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danny D'Agostino</dc:creator>
    </item>
    <item>
      <title>CDOpt: A Python Package for a Class of Riemannian Optimization</title>
      <link>https://arxiv.org/abs/2212.02698</link>
      <description>arXiv:2212.02698v3 Announce Type: replace 
Abstract: Optimization over the embedded submanifold defined by constraints $c(x) = 0$ has attracted much interest over the past few decades due to its wide applications in various areas. Plenty of related optimization packages have been developed based on Riemannian optimization approaches, which rely on some basic geometrical materials of Riemannian manifolds, including retractions, vector transports, etc. These geometrical materials can be challenging to determine in general. Existing packages only accommodate a few well-known manifolds whose geometrical materials are easily accessible. For other manifolds which are not contained in these packages, the users have to develop the geometric materials by themselves. In addition, it is not always tractable to adopt advanced features from various state-of-the-art unconstrained optimization solvers to Riemannian optimization approaches.
  We introduce CDOpt (available at https://cdopt.github.io/), a user-friendly Python package for a class Riemannian optimization. Based on constraint dissolving approaches, Riemannian optimization problems are transformed into their equivalent unconstrained counterparts in CDOpt. Therefore, solving Riemannian optimization problems through CDOpt directly benefits from various existing solvers and the rich expertise gained over decades for unconstrained optimization. Moreover, all the computations in CDOpt related to any manifold in question are conducted on its constraints expression, hence users can easily define new manifolds in CDOpt without any background on differential geometry. Furthermore, CDOpt extends the neural layers from PyTorch and Flax, thus allows users to train manifold constrained neural networks directly by the solvers for unconstrained optimization. Extensive numerical experiments demonstrate that CDOpt is highly efficient and robust in solving various classes of Riemannian optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02698v3</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nachuan Xiao, Xiaoyin Hu, Xin Liu, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Successive Convexification with Feasibility Guarantee via Augmented Lagrangian for Non-Convex Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2304.14564</link>
      <description>arXiv:2304.14564v3 Announce Type: replace 
Abstract: This paper proposes a new algorithm that solves non-convex optimal control problems with a theoretical guarantee for global convergence to a feasible local solution of the original problem. The proposed algorithm extends the recently proposed successive convexification (SCvx) algorithm by addressing one of its key limitations, that is, the converged solution is not guaranteed to be feasible to the original non-convex problem. The main idea behind the proposed algorithm is to incorporate the SCvx-based iteration into an algorithmic framework based on the augmented Lagrangian method to enable the feasibility guarantee while retaining favorable properties of SCvx. Unlike the original SCvx, this approach iterates on both of the optimization variables and the Lagrange multipliers, which facilitates the feasibility guarantee as well as efficient convergence, in a spirit similar to the alternating direction method of multipliers (ADMM) for large-scale convex programming. Convergence analysis shows the proposed algorithm's strong global convergence to a feasible local optimum of the original problem and its convergence rate. These theoretical results are demonstrated via numerical examples with comparison against the original SCvx algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14564v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC49753.2023.10383462</arxiv:DOI>
      <dc:creator>Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Online Control with Adversarial Disturbance for Continuous-time Linear Systems</title>
      <link>https://arxiv.org/abs/2306.01952</link>
      <description>arXiv:2306.01952v3 Announce Type: replace 
Abstract: We study online control for continuous-time linear systems with finite sampling rates, where the objective is to design an online procedure that learns under non-stochastic noise and performs comparably to a fixed optimal linear controller. We present a novel two-level online algorithm, by integrating a higher-level learning strategy and a lower-level feedback control strategy. This method offers a practical and robust solution for online control, which achieves sublinear regret. Our work provides the first nonasymptotic results for controlling continuous-time linear systems with finite number of interactions with the system. Moreover, we examine how to train an agent in domain randomization environments from a non-stochastic control perspective. By applying our method to the SAC (Soft Actor-Critic) algorithm, we achieved improved results in multiple reinforcement learning tasks within domain randomization environments. Our work provides new insights into non-asymptotic analyses of controlling continuous-time systems. Furthermore, our work brings practical intuition into controller learning under non-stochastic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01952v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwei Li, Jing Dong, Can Chang, Baoxiang Wang, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic Subgradient Methods with Guaranteed Global Stability in Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2307.10053</link>
      <description>arXiv:2307.10053v4 Announce Type: replace 
Abstract: In this paper, we focus on providing convergence guarantees for stochastic subgradient methods in minimizing nonsmooth nonconvex functions. We first investigate the global stability of a general framework for stochastic subgradient methods, where the corresponding differential inclusion admits a coercive Lyapunov function. We prove that, for any sequence of sufficiently small stepsizes and approximation parameters, coupled with sufficiently controlled noises, the iterates are uniformly bounded and asymptotically stabilize around the stable set of its corresponding differential inclusion. Moreover, we develop an improved analysis to apply our proposed framework to establish the global stability of a wide range of stochastic subgradient methods, where the corresponding Lyapunov functions are possibly non-coercive. These theoretical results illustrate the promising potential of our proposed framework for establishing the global stability of various stochastic subgradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10053v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nachuan Xiao, Xiaoyin Hu, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>From Optimization to Control: Quasi Policy Iteration</title>
      <link>https://arxiv.org/abs/2311.11166</link>
      <description>arXiv:2311.11166v2 Announce Type: replace 
Abstract: Recent control algorithms for Markov decision processes (MDPs) have been designed using an implicit analogy with well-established optimization algorithms. In this paper, we review this analogy across four problem classes with a unified solution characterization allowing for a systematic transformation of algorithms from one domain to the other. In particular, we identify equivalent optimization and control algorithms that have already been pointed out in the existing literature, but mostly in a scattered way. With this unifying framework in mind, we adopt the quasi-Newton method from convex optimization to introduce a novel control algorithm coined as quasi-policy iteration (QPI). In particular, QPI is based on a novel approximation of the "Hessian" matrix in the policy iteration algorithm by exploiting two linear structural constraints specific to MDPs and by allowing for the incorporation of prior information on the transition probability kernel. While the proposed algorithm has the same computational complexity as value iteration, it interestingly exhibits an empirical convergence behavior similar to policy iteration with a very low sensitivity to the discount factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11166v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Amin Sharifi Kolarijani, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Conjugate gradient methods without line search for multiobjective optimization</title>
      <link>https://arxiv.org/abs/2312.02461</link>
      <description>arXiv:2312.02461v3 Announce Type: replace 
Abstract: This paper addresses unconstrained multiobjective optimization problems where two or more continuously differentiable functions have to be minimized. We delve into the conjugate gradient methods proposed by Lucambio P\'{e}rez and Prudente (SIAM J Optim, 28(3): 2690--2720, 2018) for such problems. Instead of the Wolfe-type line search procedure used in their work, we employ a fixed stepsize formula (or no-line-search scheme), which can mitigate the pressure of choosing stepsize caused by multiple inequalities and avoid the computational cost associated with function evaluations in specific applications. The no-line-search scheme is utilized to derive the condition of Zoutendijk's type. Global convergence encompasses the vector extensions of Fletcher--Reeves, conjugate descent, Dai--Yuan, Polak--Ribi\`{e}re--Polyak and Hestenes--Stiefel parameters, subject to certain mild assumptions. Additionally, numerical experiments are conducted to demonstrate the practical performance of the proposed stepsize rule, and comparative analyses are made with the multiobjective steepest descent methods using the Armijo line search and the multiobjective conjugate gradient methods using the Wolfe-type line search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02461v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Chen, Yong Zhao, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>The flying sidekick traveling salesman problem with multiple drops: A simple and effective heuristic approach</title>
      <link>https://arxiv.org/abs/2403.18091</link>
      <description>arXiv:2403.18091v4 Announce Type: replace 
Abstract: We study the Flying Sidekick Traveling Salesman Problem with Multiple Drops (FSTSP-MD), a multi-modal last-mile delivery model where a single truck and a single drone cooperatively deliver customer packages. In the FSTSP-MD, the drone can be launched from the truck to deliver multiple packages before it returns to the truck for a new delivery operation. The objective is to find the synchronized truck and drone delivery routes that minimize the completion time of the delivery process. We develop a simple and effective heuristic to solve the FSTSP-MD based on an order-first, split-second scheme. The core component of our heuristic is a novel split algorithm that finds FSTSP-MD solutions in polynomial time for a given sequence of customers. We embed this split algorithm into a simple heuristic approach that combines standard local search and diversification techniques. The simplicity of our heuristic does not sacrifice performance: we show that it consistently outperforms state-of-the-art solution approaches developed for both the FSTSP-MD and the FSTSP (i.e., the single-drop case) through extensive numerical experiments. Based on both stylized and real-world instances, we also show that the FSTSP-MD substantially reduces completion times compared to traditional truck-only delivery systems. We provide extensive managerial insights into the impacts of drone capabilities and customer distribution on delivery efficiency. Our discussion compares the benefits of drones with greater payload capacity and those with greater speed. We highlight which service area characteristics increase savings but also require enhanced drone capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18091v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah K. Schaumann, Abhishake Kundu, Juan C. Pina-Pardo, Matthias Winkenbach, Ricardo A. Gatica, Stephan M. Wagner, Timothy I. Matis</dc:creator>
    </item>
    <item>
      <title>Convergence of Iterative Quadratic Programming for Robust Fixed-Endpoint Transfer of Bilinear Systems</title>
      <link>https://arxiv.org/abs/2403.18131</link>
      <description>arXiv:2403.18131v2 Announce Type: replace 
Abstract: We present a computational method for open-loop minimum-norm control synthesis for fixed-endpoint transfer of bilinear ensemble systems that are indexed by two continuously varying parameters. We suppose that one ensemble parameter scales the homogeneous, linear part of the dynamics, and the second parameter scales the effect of the applied control inputs on the inhomogeneous, bilinear dynamics. This class of dynamical systems is motivated by robust quantum control pulse synthesis, where the ensemble parameters correspond to uncertainty in the free Hamiltonian and inhomogeneity in the control Hamiltonian, respectively. Our computational method is based on polynomial approximation of the ensemble state in parameter space and discretization of the evolution equations in the time domain using a product of matrix exponentials corresponding to zero-order hold controls over the time intervals. The dynamics are successively linearized about control and trajectory iterates to formulate a sequence of quadratic programs for computing perturbations to the control that successively improve the objective until the iteration converges. We use a two-stage computation to first ensure transfer to the desired terminal state, and then minimize the norm of the control function. The method is demonstrated for the canonical uniform transfer problem for the Bloch system that appears in nuclear magnetic resonance, as well as the matter-wave splitting problem for the Raman-Nath system that appears in ultra-cold atom interferometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18131v2</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Andre Luiz P. de Lima, Anatoly Zlotnik, Jr-Shin Li, Michael J. Martin</dc:creator>
    </item>
    <item>
      <title>Rapid nonlinear convex guidance using a monomial method</title>
      <link>https://arxiv.org/abs/2403.19324</link>
      <description>arXiv:2403.19324v3 Announce Type: replace 
Abstract: This paper addresses the challenge of accommodating nonlinear dynamics and constraints in rapid trajectory optimization, envisioned for use in the context of onboard guidance. We present a novel framework that uniquely employs overparameterized monomial coordinates and pre-computed fundamental solution expansions to facilitate rapid optimization while minimizing real-time computational requirements. The fundamental solution expansions are pre-computed using differential algebra. Unlike traditional approaches that repeatedly evaluate the nonlinear dynamics and constraints as part of complex shooting or collocation-based schemes, this method replaces the nonlinearity inherent to dynamics and constraint functions entirely with a computationally simpler manifold constraint. With this approach, trajectory optimization is posed efficiently as a path planning problem on the manifold. This problem is entirely convex except for the manifold constraint, readily lending itself to solution via sequential convex programming. We demonstrate the effectiveness of our approach in computing fast and accurate delta-V optimal solutions for long-range spacecraft rendezvous, including problems with nonlinear state constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19324v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan R. Burnett, Francesco Topputo</dc:creator>
    </item>
    <item>
      <title>Identification of High-Dimensional ARMA Models with Binary-Valued Observations</title>
      <link>https://arxiv.org/abs/2404.01613</link>
      <description>arXiv:2404.01613v5 Announce Type: replace 
Abstract: This paper studies system identification of high-dimensional ARMA models with binary-valued observations. The existing paper can only deal with the case where the regression term is only one-dimensional. In this paper, the ARMA model with arbitrary dimensions is considered, which is more challenging. Different from the identification of FIR models with binary-valued observations, the prediction of original system output and the parameter both need to be estimated in ARMA models. An online identification algorithm consisting of parameter estimation and prediction of original system output is proposed. The parameter estimation and the prediction of original output are strongly coupled but mutually reinforcing. By analyzing the two estimates at the same time instead of analyzing separately, we finally prove that the parameter estimate can converge to the true parameter with convergence rate O(1/k) under certain conditions. Simulations are given to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01613v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Ting Wang, Jin Guo, Yanlong Zhao</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Traveling Purchaser Problems</title>
      <link>https://arxiv.org/abs/2404.02476</link>
      <description>arXiv:2404.02476v5 Announce Type: replace 
Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently construct the route using the policy network, and once the route is determined, the associated purchasing plan can be easily derived through linear programming, while, leveraging DRL, we can train the policy network to optimize the global solution objective. Furthermore, by introducing a meta-learning strategy, the policy network can be trained stably on large-sized TPP instances, and generalize well across instances of varying sizes and distributions, even to much larger instances that are never seen during training. Experiments on various synthetic TPP instances and the TPPLIB benchmark demonstrate that our DRL-based approach can significantly outperform well-established TPP heuristics, reducing the optimality gap by 40%-90%, and also showing an advantage in runtime, especially on large-sized instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02476v5</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haofeng Yuan, Rongping Zhu, Wanlu Yang, Shiji Song, Keyou You, Wei Fan, C. L. Philip Chen</dc:creator>
    </item>
    <item>
      <title>Distributionally robust stochastic optimal control</title>
      <link>https://arxiv.org/abs/2406.05648</link>
      <description>arXiv:2406.05648v2 Announce Type: replace 
Abstract: The main goal of this paper is to discuss the construction of distributionally robust counterparts of stochastic optimal control problems. Randomized and non-randomized policies are considered. In particular, necessary and sufficient conditions for the existence of non-randomized policies are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05648v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Shapiro, Yan Li</dc:creator>
    </item>
    <item>
      <title>Learning in Herding Mean Field Games: Single-Loop Algorithm with Finite-Time Convergence Analysis</title>
      <link>https://arxiv.org/abs/2408.04780</link>
      <description>arXiv:2408.04780v4 Announce Type: replace 
Abstract: We consider discrete-time stationary mean field games (MFG) with unknown dynamics and design algorithms for finding the equilibrium in finite time. Prior solutions to the problem build upon either the contraction assumption on a mean field optimality-consistency operator or strict weak monotonicity, which may be overly restrictive. In this work, we introduce a new class of solvable MFGs, "fully herding class", which expands the known finite-time solvable class of MFGs and for the first time includes problems with multiple equilibria. We propose a direct policy optimization method, Accelerated Single-loop Actor Critic Algorithm for Mean Field Games (ASAC-MFG), that provably finds a global equilibrium for MFGs within this class, under suitable access to a single trajectory of Markovian samples. Different from the prior arts, ASAC-MFG is single-loop and single-sample-path. We establish the finite-time and finite-sample convergence of ASAC-MFG to a mean field equilibrium via new techniques we develop for multi-time-scale stochastic approximation. We support the theoretical results with illustrative numerical simulations.
  When the mean field does not affect the transition and reward, a MFG reduces to a Markov decision process (MDP) and ASAC-MFG becomes an actor-critic algorithm for finding the optimal policy in average-reward MDPs, with a sample complexity matching the state-of-the-art. Existing works derive the complexity assuming a contraction on the Bellman operator, which is invalid for average-reward MDPs. We are able to match the rate while removing the untenable assumption through an improved Lyapunov function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04780v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Sujay Bhatt, Alec Koppel, Sumitra Ganesh</dc:creator>
    </item>
    <item>
      <title>The Non-Substitution Theorem, Uniqueness of Solution and Convex combinations of basic optimal solutions for linear optimization</title>
      <link>https://arxiv.org/abs/2408.14150</link>
      <description>arXiv:2408.14150v3 Announce Type: replace 
Abstract: Our first result is a statement of a somewhat general form of a non-substitution theorem for linear programming problems, along with a very easy proof of the same. Subsequently, we provide an easy proof of theorem 1 in a 1979 paper by Olvi L Mangasarian based on a lemma that may be of some significance by itself. We also provide a simple proof of the result that states that the set of optimal solutions of a bounded linear optimization problem is the set of all convex combinations of its basic optimal solutions and the set of basic optimal solutions are the extreme points of the set of optimal solutions. We do so by appealing to the well-known lemma of Farkas and another well-known result that states that if a linear optimization problem has an optimal solution, it has at least one basic optimal solution. Both results we appeal to have easy proofs. We do not appeal to any version of the Klein-Milman Theorem or any result in advanced polyhedral combinatorics to obtain our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14150v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Differentially Private and Byzantine-Resilient Decentralized Nonconvex Optimization: System Modeling, Utility, Resilience, and Privacy Analysis</title>
      <link>https://arxiv.org/abs/2409.18632</link>
      <description>arXiv:2409.18632v5 Announce Type: replace 
Abstract: Privacy leakage and Byzantine failures are two adverse factors to the intelligent decision-making process of multi-agent systems (MASs). Considering the presence of these two issues, this paper targets the resolution of a class of nonconvex optimization problems under the Polyak-{\L}ojasiewicz (P-{\L}) condition. To address this problem, we first identify and construct the adversary system model. To enhance the robustness of stochastic gradient descent methods, we mask the local gradients with Gaussian noises and adopt a resilient aggregation method self-centered clipping (SCC) to design a differentially private (DP) decentralized Byzantine-resilient algorithm, namely DP-SCC-PL, which simultaneously achieves differential privacy and Byzantine resilience. The convergence analysis of DP-SCC-PL is challenging since the convergence error can be contributed jointly by privacy-preserving and Byzantine-resilient mechanisms, as well as the nonconvex relaxation, which is addressed via seeking the contraction relationships among the disagreement measure of reliable agents before and after aggregation, together with the optimal gap. Theoretical results reveal that DP-SCC-PL achieves consensus among all reliable agents and sublinear (inexact) convergence with well-designed step-sizes. It has also been proved that if there are no privacy issues and Byzantine agents, then the asymptotic exact convergence can be recovered. Numerical experiments verify the utility, resilience, and differential privacy of DP-SCC-PL by tackling a nonconvex optimization problem satisfying the P-{\L} condition under various Byzantine attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18632v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhui Hu, Guo Chen, Huaqing Li, Huqiang Cheng, Xiaoyu Guo, Tingwen Huang</dc:creator>
    </item>
    <item>
      <title>OPTAMI: Global Superlinear Convergence of High-order Methods</title>
      <link>https://arxiv.org/abs/2410.04083</link>
      <description>arXiv:2410.04083v2 Announce Type: replace 
Abstract: Second-order methods for convex optimization outperform first-order methods in terms of theoretical iteration convergence, achieving rates up to $O(k^{-5})$ for highly-smooth functions. However, their practical performance and applications are limited due to their multi-level structure and implementation complexity. In this paper, we present new results on high-order optimization methods, supported by their practical performance. First, we show that the basic high-order methods, such as the Cubic Regularized Newton Method, exhibit global superlinear convergence for $\mu$-strongly star-convex functions, a class that includes $\mu$-strongly convex functions and some non-convex functions. Theoretical convergence results are both inspired and supported by the practical performance of these methods. Secondly, we propose a practical version of the Nesterov Accelerated Tensor method, called NATA. It significantly outperforms the classical variant and other high-order acceleration techniques in practice. The convergence of NATA is also supported by theoretical results. Finally, we introduce an open-source computational library for high-order methods, called OPTAMI. This library includes various methods, acceleration techniques, and subproblem solvers, all implemented as PyTorch optimizers, thereby facilitating the practical application of high-order methods to a wide range of optimization problems. We hope this library will simplify research and practical comparison of methods beyond first-order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04083v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Kamzolov, Dmitry Pasechnyuk, Artem Agafonov, Alexander Gasnikov, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Efficient parameter-free restarted accelerated gradient methods for convex and strongly convex optimization</title>
      <link>https://arxiv.org/abs/2410.04248</link>
      <description>arXiv:2410.04248v2 Announce Type: replace 
Abstract: This paper develops a new parameter-free restarted method, namely RPF-SFISTA, and a new parameter-free aggressive regularization method, namely A-REG, for solving strongly convex and convex composite optimization problems, respectively. RPF-SFISTA has the major advantage that it requires no knowledge of both the strong convexity parameter of the entire composite objective and the Lipschitz constant of the gradient. Unlike several other restarted first-order methods which restart an accelerated composite gradient (ACG) method after a predetermined number of ACG iterations have been performed, RPF-SFISTA checks a key inequality at each of iterations to determine when to restart. Extensive computational experiments show that RPF-SFISTA is roughly 3 to 15 times faster than other state-of-the-art restarted methods on four important classes of problems. The A-REG method, developed for convex composite optimization, solves each of its strongly convex regularized subproblems according to a stationarity criterion by using the RPF-SFISTA method with a possibly aggressive choice of initial strong convexity estimate. This scheme is thus more aggressive than several other regularization methods which solve their subproblems by running a standard ACG method for a predetermined number of iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04248v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnesh Sujanani, Renato D. C. Monteiro</dc:creator>
    </item>
    <item>
      <title>Congestion and Penalization in Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.07363</link>
      <description>arXiv:2410.07363v2 Announce Type: replace 
Abstract: In this paper we introduce two novel models derived from the discrete optimal transport problem. The first model extends the traditional transport problem by adding a quadratic congestion factor directly into the cost function, while the second model replaces conventional constraints with weighted penalization terms. We present theoretical results, for the characterization of interior and corner solution for some specific cases, and we perform smooth comparative statics analysis. We also propose an $O((N+L)(NL)^2)$ algorithm for computing the optimal plan for the penalized model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07363v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcelo Gallardo, Manuel Loaiza, Jorge Ch\'avez</dc:creator>
    </item>
    <item>
      <title>ShieldNN: A Provably Safe NN Filter for Unsafe NN Controllers</title>
      <link>https://arxiv.org/abs/2006.09564</link>
      <description>arXiv:2006.09564v2 Announce Type: replace-cross 
Abstract: In this paper, we develop a novel closed-form Control Barrier Function (CBF) and associated controller shield for the Kinematic Bicycle Model (KBM) with respect to obstacle avoidance. The proposed CBF and shield -- designed by an algorithm we call ShieldNN -- provide two crucial advantages over existing methodologies. First, ShieldNN considers steering and velocity constraints directly with the non-affine KBM dynamics; this is in contrast to more general methods, which typically consider only affine dynamics and do not guarantee invariance properties under control constraints. Second, ShieldNN provides a closed-form set of safe controls for each state unlike more general methods, which typically rely on optimization algorithms to generate a single instantaneous for each state. Together, these advantages make ShieldNN uniquely suited as an efficient Multi-Obstacle Safe Actions (i.e. multiple-barrier-function shielding) during training time of a Reinforcement Learning (RL) enabled NN controller. We show via experiments that ShieldNN dramatically increases the completion rate of RL training episodes in the presence of multiple obstacles, thus establishing the value of ShieldNN in training RL-based controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.09564v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Ferlez, Mahmoud Elnaggar, Yasser Shoukry, Cody Fleming</dc:creator>
    </item>
    <item>
      <title>Regularized Barzilai-Borwein method</title>
      <link>https://arxiv.org/abs/2211.06624</link>
      <description>arXiv:2211.06624v5 Announce Type: replace-cross 
Abstract: We develop a novel stepsize based on \BB method for solving some challenging optimization problems efficiently, named regularized \BB (RBB) stepsize. We indicate that RBB stepsize is the close solution to a $\ell_{2}^{2}$-regularized least squares problem. When the regularized item vanishes, the RBB stepsize reduces to the original \BB stepsize. RBB stepsize includes a class of valid stepsizes, such as another version of \BB stepsize. The global convergence of the corresponding RBB algorithm is proved in solving convex quadratic optimization problems. One scheme for adaptively generating regularization parameters was proposed, named adaptive two-step parameter. An enhanced RBB stepsize is used for solving quadratic and general optimization problems more efficiently. RBB stepsize could overcome the instability of BB stepsize in many ill-conditioned optimization problems. Moreover, RBB stepsize is more robust than BB stepsize in numerical experiments. Numerical examples show the advantage of using the proposed stepsize to solve some challenging optimization problems vividly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06624v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Congpei An, Xin Xu</dc:creator>
    </item>
    <item>
      <title>Towards Understanding Generalization and Stability Gaps between Centralized and Decentralized Federated Learning</title>
      <link>https://arxiv.org/abs/2310.03461</link>
      <description>arXiv:2310.03461v2 Announce Type: replace-cross 
Abstract: As two mainstream frameworks in federated learning (FL), both centralized and decentralized approaches have shown great application value in practical scenarios. However, existing studies do not provide sufficient evidence and clear guidance for analysis of which performs better in the FL community. Although decentralized methods have been proven to approach the comparable convergence of centralized with less communication, their test performance always falls short of expectations in empirical studies. To comprehensively and fairly compare their efficiency gaps in FL, in this paper, we explore their stability and generalization efficiency. Specifically, we prove that on the general smooth non-convex objectives, 1) centralized FL (CFL) always generalizes better than decentralized FL (DFL); 2) CFL achieves the best performance via adopting partial participation instead of full participation; and, 3) there is a necessary requirement for the topology in DFL to avoid performance collapse as the training scale increases. We also conduct extensive experiments on several common setups in FL to validate that our theoretical analysis is consistent with experimental phenomena and contextually valid in several general and practical scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03461v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Sun, Li Shen, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>Markov chain entropy games and the geometry of their Nash equilibria</title>
      <link>https://arxiv.org/abs/2310.04115</link>
      <description>arXiv:2310.04115v2 Announce Type: replace-cross 
Abstract: Consider the following two-person mixed strategy game of a probabilist against Nature with respect to the parameters $(f, \mathcal{B},\pi)$, where $f$ is a convex function satisfying certain regularity conditions, $\mathcal{B}$ is either the set $\{L_i\}_{i=1}^n$ or its convex hull with each $L_i$ being a Markov infinitesimal generator on a finite state space $\mathcal{X}$ and $\pi$ is a given positive discrete distribution on $\mathcal{X}$. The probabilist chooses a prior measure $\mu$ within the set of probability measures on $\mathcal{B}$ denoted by $\mathcal{P}(\mathcal{B})$ and picks a $L \in \mathcal{B}$ at random according to $\mu$, whereas Nature follows a pure strategy to select $M \in \mathcal{L}(\pi)$, the set of $\pi$-reversible Markov generators on $\mathcal{X}$. Nature pays an amount $D_f(M||L)$, the $f$-divergence from $L$ to $M$, to the probabilist. We prove that a mixed strategy Nash equilibrium always exists, and establish a minimax result on the expected payoff of the game. This also contrasts with the pure strategy version of the game where we show a Nash equilibrium may not exist. To find approximately a mixed strategy Nash equilibrium, we propose and develop a simple projected subgradient algorithm that provably converges with a rate of $\mathcal{O}(1/\sqrt{t})$, where $t$ is the number of iterations. In addition, we elucidate the relationships of Nash equilibrium with other seemingly disparate notions such as weighted information centroid, Chebyshev center and Bayes risk. This article generalizes the two-person game of a statistician against Nature developed in the literature, and highlights the powerful interplay and synergy between modern Markov chains theory and geometry, information theory, game theory, optimization and mathematical statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04115v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>On the Optimization and Generalization of Multi-head Attention</title>
      <link>https://arxiv.org/abs/2310.12680</link>
      <description>arXiv:2310.12680v2 Announce Type: replace-cross 
Abstract: The training and generalization dynamics of the Transformer's core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on single-head attention. Inspired by the demonstrated benefits of overparameterization when training fully-connected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12680v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Puneesh Deora, Rouzbeh Ghaderi, Hossein Taheri, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Online Learning Quantum States with the Logarithmic Loss via VB-FTRL</title>
      <link>https://arxiv.org/abs/2311.04237</link>
      <description>arXiv:2311.04237v2 Announce Type: replace-cross 
Abstract: Online learning of quantum states with the logarithmic loss (LL-OLQS) is a quantum generalization of online portfolio selection (OPS), a classic open problem in online learning for over three decades. This problem also emerges in designing stochastic optimization algorithms for maximum-likelihood quantum state tomography. Recently, Jezequel et al. (arXiv:2209.13932) proposed the VB-FTRL algorithm, the first regret-optimal algorithm for OPS with moderate computational complexity. In this paper, we generalize VB-FTRL for LL-OLQS. Let $d$ denote the dimension and $T$ the number of rounds. The generalized algorithm achieves a regret rate of $O ( d^2 \log ( d + T ) )$ for LL-OLQS. Each iteration of the algorithm consists of solving a semidefinite program that can be implemented in polynomial time by, for example, cutting-plane methods. For comparison, the best-known regret rate for LL-OLQS is currently $O ( d^2 \log T )$, achieved by an exponential weight method. However, no explicit implementation is available for the exponential weight method for LL-OLQS. To facilitate the generalization, we introduce the notion of VB-convexity. VB-convexity is a sufficient condition for the volumetric barrier associated with any function to be convex and is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04237v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei-Fu Tseng, Kai-Chun Chen, Zi-Hong Xiao, Yen-Huan Li</dc:creator>
    </item>
    <item>
      <title>The Local Landscape of Phase Retrieval Under Limited Samples</title>
      <link>https://arxiv.org/abs/2311.15221</link>
      <description>arXiv:2311.15221v2 Announce Type: replace-cross 
Abstract: In this paper, we present a fine-grained analysis of the local landscape of phase retrieval under the regime of limited samples. Specifically, we aim to ascertain the minimal sample size required to guarantee a benign local landscape surrounding global minima in high dimensions. Let $n$ and $d$ denote the sample size and input dimension, respectively. We first explore the local convexity and establish that when $n=o(d\log d)$, for almost every fixed point in the local ball, the Hessian matrix has negative eigenvalues, provided $d$ is sufficiently large. % Consequently, the local landscape is highly non-convex. We next consider the one-point convexity and show that, as long as $n=\omega(d)$, with high probability, the landscape is one-point strongly convex in the local annulus: $\{w\in\mathbb{R}^d: o_d(1)\leqslant \|w-w^*\|\leqslant c\}$, where $w^*$ is the ground truth and $c$ is an absolute constant. This implies that gradient descent, initialized from any point in this domain, can converge to an $o_d(1)$-loss solution exponentially fast. Furthermore, we show that when $n=o(d\log d)$, there is a radius of $\widetilde\Theta\left(\sqrt{1/d}\right)$ such that one-point convexity breaks down in the corresponding smaller local ball. This indicates an impossibility of establishing a convergence to the exact $w^*$ for gradient descent under limited samples by relying solely on one-point convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15221v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaizhao Liu, Zihao Wang, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Future Trends in the Design of Memetic Algorithms: the Case of the Linear Ordering Problem</title>
      <link>https://arxiv.org/abs/2405.08285</link>
      <description>arXiv:2405.08285v2 Announce Type: replace-cross 
Abstract: The way heuristic optimizers are designed has evolved over the decades, as computing power has increased. Such has been the case for the Linear Ordering Problem (LOP), a field in which trajectory-based strategies led the way during the 1990s, but which have now been surpassed by memetic schemes.This paper focuses on understanding how the design of LOP optimizers will change in the future, as computing power continues to increase, yielding two main contributions.On the one hand, a metaheuristic was designed that is capable of effectively exploiting a large amount of computational resources, specifically, computing power equivalent to what a recent core can output during runs lasting over four months.Our analyses show that as the power of the computational resources increases, it will be necessary to boost the capacities of the intensification methods applied in the memetic algorithms to keep the population from stagnating.And on the other, the best-known results for today's most challenging set of instances (xLOLIB2) were significantly outperformed. New bounds were established in this benchmark, which provides a new frame of reference for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08285v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L\'azaro Lugo, Carlos Segura, Gara Miranda</dc:creator>
    </item>
    <item>
      <title>Infinite-Horizon Reinforcement Learning with Multinomial Logistic Function Approximation</title>
      <link>https://arxiv.org/abs/2406.13633</link>
      <description>arXiv:2406.13633v3 Announce Type: replace-cross 
Abstract: We study model-based reinforcement learning with non-linear function approximation where the transition function of the underlying Markov decision process (MDP) is given by a multinomial logistic (MNL) model. We develop a provably efficient discounted value iteration-based algorithm that works for both infinite-horizon average-reward and discounted-reward settings. For average-reward communicating MDPs, the algorithm guarantees a regret upper bound of $\tilde{\mathcal{O}}(dD\sqrt{T})$ where $d$ is the dimension of feature mapping, $D$ is the diameter of the underlying MDP, and $T$ is the horizon. For discounted-reward MDPs, our algorithm achieves $\tilde{\mathcal{O}}(d(1-\gamma)^{-2}\sqrt{T})$ regret where $\gamma$ is the discount factor. Then we complement these upper bounds by providing several regret lower bounds. We prove a lower bound of $\Omega(d\sqrt{DT})$ for learning communicating MDPs of diameter $D$ and a lower bound of $\Omega(d(1-\gamma)^{3/2}\sqrt{T})$ for learning discounted-reward MDPs with discount factor $\gamma$. Lastly, we show a regret lower bound of $\Omega(dH^{3/2}\sqrt{K})$ for learning $H$-horizon episodic MDPs with MNL function approximation where $K$ is the number of episodes, which improves upon the best-known lower bound for the finite-horizon setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13633v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaehyun Park, Junyeop Kwon, Dabeen Lee</dc:creator>
    </item>
    <item>
      <title>AdaGrad under Anisotropic Smoothness</title>
      <link>https://arxiv.org/abs/2406.15244</link>
      <description>arXiv:2406.15244v2 Announce Type: replace-cross 
Abstract: Adaptive gradient methods have been widely adopted in training large-scale deep neural networks, especially large foundation models. Despite the huge success in practice, their theoretical advantages over classical gradient methods with uniform step sizes across all coordinates (e.g. SGD) have not been fully understood, especially in the large batch-size setting commonly used in practice. This is because the only theoretical result that can demonstrate this benefit was obtained in the original paper of Adagrad for convex nonsmooth objective functions, which is insufficient for large batch algorithms. In this work, we attempt to resolve this gap between theory and practice by proposing a novel anisotropic generalized smoothness assumption and providing corresponding analyses of Adagrad. It is shown that under anisotropic smoothness and noise conditions, AdaGrad can achieve faster convergence guarantees in terms of better dimensional dependence than algorithms with uniform step sizes across all coordinates. Experiments in logistic regression and instruction following fine-tuning tasks provide strong evidence to support our novel assumption and theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15244v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuxing Liu, Rui Pan, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2409.08861</link>
      <description>arXiv:2409.08861v2 Announce Type: replace-cross 
Abstract: Dynamical generative models that produce samples through an iterative process, such as Flow Matching and denoising diffusion models, have seen widespread use, but there have not been many theoretically-sound methods for improving these models with reward fine-tuning. In this work, we cast reward fine-tuning as stochastic optimal control (SOC). Critically, we prove that a very specific memoryless noise schedule must be enforced during fine-tuning, in order to account for the dependency between the noise variable and the generated samples. We also propose a new algorithm named Adjoint Matching which outperforms existing SOC algorithms, by casting SOC problems as a regression problem. We find that our approach significantly improves over existing methods for reward fine-tuning, achieving better consistency, realism, and generalization to unseen human preference reward models, while retaining sample diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08861v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Michal Drozdzal, Brian Karrer, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>Convex hulls of curves in $n$-space</title>
      <link>https://arxiv.org/abs/2410.02359</link>
      <description>arXiv:2410.02359v2 Announce Type: replace-cross 
Abstract: Let $K\subseteq{\mathbb R}^n$ be a convex semialgebraic set. The semidefinite extension degree ${\mathrm{sxdeg}}(K)$ of $K$ is the smallest number $d$ such that $K$ is a linear image of an intersection of finitely many spectrahedra, each of which is described by a linear matrix inequality of size $\le d$. This invariant can be considered to be a measure for the intrinsic complexity of semidefinite optimization over the set $K$. For an arbitrary semialgebraic set $S\subseteq{\mathbb R}^n$ of dimension one, our main result states that the closed convex hull $K$ of $S$ satisfies ${\mathrm{sxdeg}}(K)\le1+\lfloor\frac n2\rfloor$. This bound is best possible in several ways. Before, the result was known for $n=2$, and also for general $n$ in the case where $S$ is a monomial curve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02359v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claus Scheiderer</dc:creator>
    </item>
    <item>
      <title>Model Developmental Safety: A Safety-Centric Method and Applications in Vision-Language Models</title>
      <link>https://arxiv.org/abs/2410.03955</link>
      <description>arXiv:2410.03955v2 Announce Type: replace-cross 
Abstract: In the real world, a learning-enabled system usually undergoes multiple cycles of model development to enhance the system's ability to handle difficult or emerging tasks. This continual model development process raises a significant issue that the model development for acquiring new or improving existing capabilities may inadvertently lose capabilities of the old model, also known as catastrophic forgetting. Existing continual learning studies focus on mitigating catastrophic forgetting by trading off performance on previous tasks and new tasks to ensure good average performance. However, they are inadequate for many applications especially in safety-critical domains, as failure to strictly preserve the performance of the old model not only introduces safety risks and uncertainties but also imposes substantial expenses in the re-improving and re-validation of existing properties. To address this issue, we introduce model developmental safety as a guarantee of a learning system such that in the model development process the new model should strictly preserve the existing protected capabilities of the old model while improving its performance on target tasks. To ensure the model developmental safety, we present a safety-centric framework by formulating the model developmental safety as data-dependent constraints. Under this framework, we study how to develop a pretrained vision-language model (aka the CLIP model) for acquiring new capabilities or improving existing capabilities of image classification. We propose an efficient constrained optimization algorithm with theoretical guarantee and use its insights to finetune a CLIP model with task-dependent heads for promoting the model developmental safety. Our experiments on improving vision perception capabilities on autonomous driving and scene recognition datasets demonstrate the efficacy of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03955v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gang Li, Wendi Yu, Yao Yao, Wei Tong, Yingbin Liang, Qihang Lin, Tianbao Yang</dc:creator>
    </item>
  </channel>
</rss>
