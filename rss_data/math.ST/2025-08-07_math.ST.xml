<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 04:02:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Asymptotic universal moment matching properties of normal distributions</title>
      <link>https://arxiv.org/abs/2508.03790</link>
      <description>arXiv:2508.03790v1 Announce Type: new 
Abstract: Moment matching is an easy-to-implement and usually effective method to reduce variance of Monte Carlo simulation estimates. On the other hand, there is no guarantee that moment matching will always reduce simulation variance for general integration problems at least asymptotically, i.e. when the number of samples is large. We study the characterization of conditions on a given underlying distribution $X$ under which asymptotic variance reduction is guaranteed for a general integration problem $\mathbb{E}[f(X)]$ when moment matching techniques are applied. We show that a sufficient and necessary condition for such asymptotic variance reduction property is $X$ being a normal distribution. Moreover, when $X$ is a normal distribution, formulae for efficient estimation of simulation variance for (first and second order) moment matching Monte Carlo are obtained. These formulae allow estimations of simulation variance as by-products of the simulation process, in a way similar to variance estimations for plain Monte Carlo. Moreover, we propose non-linear moment matching schemes for any given continuous distribution such that asymptotic variance reduction is guaranteed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03790v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Liu</dc:creator>
    </item>
    <item>
      <title>Computable Bounds for Strong Approximations with Applications</title>
      <link>https://arxiv.org/abs/2508.03833</link>
      <description>arXiv:2508.03833v1 Announce Type: new 
Abstract: The Koml\'os$\unicode{x2013}$Major$\unicode{x2013}$Tusn\'ady (KMT) inequality for partial sums is one of the most celebrated results in probability theory. Yet its practical application is hindered by its dependence on unknown constants. This paper addresses this limitation for bounded i.i.d. random variables. At the cost of an additional logarithmic factor, we propose a computable version of the KMT inequality that depends only on the variables' range and standard deviation. We also derive an empirical version of the inequality that achieves nominal coverage even when the standard deviation is unknown. We then demonstrate the practicality of our bounds through applications to online change point detection and first hitting time probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03833v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyu Ye, Morgane Austern</dc:creator>
    </item>
    <item>
      <title>Convergence of empirical Gromov-Wasserstein distance</title>
      <link>https://arxiv.org/abs/2508.03985</link>
      <description>arXiv:2508.03985v1 Announce Type: new 
Abstract: We study rates of convergence for estimation of the Gromov-Wasserstein distance. For two marginals supported on compact subsets of $\R^{d_x}$ and $\R^{d_y}$, respectively, with $\min \{ d_x,d_y \} &gt; 4$, prior work established the rate $n^{-\frac{2}{\min\{d_x,d_y\}}}$ for the plug-in empirical estimator based on $n$ i.i.d. samples. We extend this fundamental result to marginals with unbounded supports, assuming only finite polynomial moments. Our proof techniques for the upper bounds can be adapted to obtain sample complexity results for penalized Wasserstein alignment that encompasses the Gromov-Wasserstein distance and Wasserstein Procrustes in unbounded settings. Furthermore, we establish matching minimax lower bounds (up to logarithmic factors) for estimating the Gromov-Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03985v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Kato, Boyu Wang</dc:creator>
    </item>
    <item>
      <title>Parameter Estimation for Weakly Interacting Hypoelliptic Diffusions</title>
      <link>https://arxiv.org/abs/2508.04287</link>
      <description>arXiv:2508.04287v1 Announce Type: new 
Abstract: We study parameter estimation for interacting particle systems (IPSs) consisting of $N$ weakly interacting multivariate hypoelliptic SDEs. We propose a locally Gaussian approximation of the transition dynamics, carefully designed to address the degenerate structure of the noise (diffusion matrix), thus leading to the formation of a well-defined full likelihood. Our approach permits carrying out statistical inference for a wide class of hypoelliptic IPSs that are not covered by recent works as the latter rely on the Euler-Maruyama scheme. We analyze a contrast estimator based on the developed likelihood with $n$ high-frequency particle observations over a fixed period $[0,T]$ and show its asymptotic normality as $n, N \to \infty$ with a requirement that the step-size $\Delta_n = T/n$ is such that $N\Delta_n\rightarrow 0$, assuming that all particle coordinates (e.g.~position and velocity) are observed. In practical situations where only partial observations (e.g. particle positions but not velocities) are available, the proposed locally Gaussian approximation offers greater flexibility for inference, when combined with established Bayesian techniques. In particular, unlike the Euler-Maruyama-based approaches, we do not have to impose restrictive structures on the hypoelliptic IPSs. We present numerical experiments that illustrate the effectiveness of our approach, both with complete and partial particle observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04287v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuga Iguchi, Alexandros Beskos, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>Matrix Rosenthal and Concentration Inequalities for Markov Chains with Applications in Statistical Learning</title>
      <link>https://arxiv.org/abs/2508.04327</link>
      <description>arXiv:2508.04327v1 Announce Type: cross 
Abstract: In this paper, we study moment and concentration inequalities of the spectral norm for sums of dependent random matrices.
  We establish novel Rosenthal-Burkholder inequalities for matrix martingales, as well as matrix Rosenthal, Hoeffding, and Bernstein inequalities for ergodic Markov chains.
  Compared with previous work on matrix concentration inequalities for Markov chains, our results do not require the assumptions of a non-zero absolute spectral gap and bounded matrix functions.
  Furthermore, our results have leading terms that match the Markov chain central limit theorem, rather than relying on variance proxies.
  We also give dimension-free versions of the inequalities, which are independent of the ambient dimension $d$ and relies on the effective rank of some matrix instead.
  This enables the generalization of our results to linear operators in infinite-dimensional Hilbert spaces.
  Our results have extensive applications in statistics and machine learning; in particular, we obtain improved bounds in covariance estimation and principal component analysis on Markovian data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04327v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Peng, Yuchen Xin, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic Taylor expansion via Poisson point processes</title>
      <link>https://arxiv.org/abs/2508.04703</link>
      <description>arXiv:2508.04703v1 Announce Type: cross 
Abstract: We generalize Taylor's theorem by introducing a stochastic formulation based on an underlying Poisson point process model. We utilize this approach to propose a novel non-linear regression framework and perform statistical inference of the model parameters. Theoretical properties of the proposed estimator are also proven, including its convergence, uniformly almost surely, to the true function. The theory is presented for the univariate and multivariate cases, and we exemplify the proposed methodology using several examples via simulations and an application to stock market data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04703v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weichao Wu, Athanasios C. Micheas</dc:creator>
    </item>
    <item>
      <title>Survey Data Integration for Distribution Function Estimation</title>
      <link>https://arxiv.org/abs/2409.14284</link>
      <description>arXiv:2409.14284v3 Announce Type: replace 
Abstract: Integration of probabilistic and non-probabilistic samples for the estimation of finite population totals (or means) has recently received considerable attention in the field of survey sampling; yet, to the best of our knowledge, this framework has not been extended to cumulative distribution function (CDF) estimation. To address this gap, we propose a novel CDF estimator that integrates data from probability samples with data from, potentially big, nonprobability samples. Assuming that a set of shared covariates are observed in both, while the response variable is observed only in the latter, the proposed estimator uses a survey-weighted empirical CDF of regression residuals trained on the convenience sample to estimate the CDF of the response variable. Under some assumptions, we derive the asymptotic bias and variance of our CDF estimator and show that it is asymptotically unbiased for the finite population CDF if ignorability holds. Our empirical results imply that the proposed CDF estimator is robust to model misspecification under ignorability, and robust to ignorability under model misspecification; when both assumptions are violated, our residual-based CDF estimator still outperforms its `plug-in' mass imputation and naive siblings, albeit with noted decreases in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14284v3</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Flood, Sayed Mostafa</dc:creator>
    </item>
    <item>
      <title>Optimal Learning via Moderate Deviations Theory</title>
      <link>https://arxiv.org/abs/2305.14496</link>
      <description>arXiv:2305.14496v4 Announce Type: replace-cross 
Abstract: This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable reformulations as finite convex programs even when they are infinite-dimensional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14496v4</guid>
      <category>stat.ML</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Ganguly, Tobias Sutter</dc:creator>
    </item>
  </channel>
</rss>
