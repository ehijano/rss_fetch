<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Aug 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A deep spatio-temporal attention model of dynamic functional network connectivity shows sensitivity to Alzheimer's in asymptomatic individuals</title>
      <link>https://arxiv.org/abs/2408.00378</link>
      <description>arXiv:2408.00378v1 Announce Type: new 
Abstract: Alzheimer's disease (AD) progresses from asymptomatic changes to clinical symptoms, emphasizing the importance of early detection for proper treatment. Functional magnetic resonance imaging (fMRI), particularly dynamic functional network connectivity (dFNC), has emerged as an important biomarker for AD. Nevertheless, studies probing at-risk subjects in the pre-symptomatic stage using dFNC are limited. To identify at-risk subjects and understand alterations of dFNC in different stages, we leverage deep learning advancements and introduce a transformer-convolution framework for predicting at-risk subjects based on dFNC, incorporating spatial-temporal self-attention to capture brain network dependencies and temporal dynamics. Our model significantly outperforms other popular machine learning methods. By analyzing individuals with diagnosed AD and mild cognitive impairment (MCI), we studied the AD progression and observed a higher similarity between MCI and asymptomatic AD. The interpretable analysis highlights the cognitive-control network's diagnostic importance, with the model focusing on intra-visual domain dFNC when predicting asymptomatic AD subjects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00378v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuxiang Wei, Anees Abrol, James Lah, Deqiang Qiu, Vince D. Calhoun</dc:creator>
    </item>
    <item>
      <title>Multiscale topology optimization of functionally graded lattice structures based on physics-augmented neural network material models</title>
      <link>https://arxiv.org/abs/2408.00510</link>
      <description>arXiv:2408.00510v1 Announce Type: new 
Abstract: We present a new framework for the simultaneous optimiziation of both the topology as well as the relative density grading of cellular structures and materials, also known as lattices. Due to manufacturing constraints, the optimization problem falls into the class of NP-complete mixed-integer nonlinear programming problems. To tackle this difficulty, we obtain a relaxed problem from a multiplicative split of the relative density and a penalization approach. The sensitivities of the objective function are derived such that any gradient-based solver might be applied for the iterative update of the design variables. In a next step, we introduce a material model that is parametric in the design variables of interest and suitable to describe the isotropic deformation behavior of quasi-stochastic lattices. For that, we derive and implement further physical constraints and enhance a physics-augmented neural network from the literature that was formulated initially for rhombic materials. Finally, to illustrate the applicability of the method, we incorporate the material model into our computational framework and exemplary optimize two-and three-dimensional benchmark structures as well as a complex aircraft component.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00510v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jonathan Stollberg, Tarun Gangwar, Oliver Weeger, Dominik Schillinger</dc:creator>
    </item>
    <item>
      <title>Spatial Weather, Socio-Economic and Political Risks in Probabilistic Load Forecasting</title>
      <link>https://arxiv.org/abs/2408.00507</link>
      <description>arXiv:2408.00507v1 Announce Type: cross 
Abstract: Accurate forecasts of the impact of spatial weather and pan-European socio-economic and political risks on hourly electricity demand for the mid-term horizon are crucial for strategic decision-making amidst the inherent uncertainty. Most importantly, these forecasts are essential for the operational management of power plants, ensuring supply security and grid stability, and in guiding energy trading and investment decisions. The primary challenge for this forecasting task lies in disentangling the multifaceted drivers of load, which include national deterministic (daily, weekly, annual, and holiday patterns) and national stochastic weather and autoregressive effects. Additionally, transnational stochastic socio-economic and political effects add further complexity, in particular, due to their non-stationarity. To address this challenge, we present an interpretable probabilistic mid-term forecasting model for the hourly load that captures, besides all deterministic effects, the various uncertainties in load. This model recognizes transnational dependencies across 24 European countries, with multivariate modeled socio-economic and political states and cross-country dependent forecasting. Built from interpretable Generalized Additive Models (GAMs), the model enables an analysis of the transmission of each incorporated effect to the hour-specific load. Our findings highlight the vulnerability of countries reliant on electric heating under extreme weather scenarios. This emphasizes the need for high-resolution forecasting of weather effects on pan-European electricity consumption especially in anticipation of widespread electric heating adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00507v1</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.RM</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monika Zimmermann, Florian Ziel</dc:creator>
    </item>
    <item>
      <title>Evaluation of Performance Measures for Qualifying Flood Models with Satellite Observations</title>
      <link>https://arxiv.org/abs/2408.00571</link>
      <description>arXiv:2408.00571v1 Announce Type: cross 
Abstract: This work discusses how to choose performance measures to compare numerical simulations of a flood event with one satellite image, e.g., in a model calibration or validation procedure. A series of criterion are proposed to evaluate the sensitivity of performance measures with respect to the flood extent, satellite characteristics (position, orientation), and measurements/processing errors (satellite raw values or extraction of the flood maps). Their relevance is discussed numerically in the case of one flooding event (on the Garonne River in France in February 2021), using a distribution of water depths simulated from a shallow-water model parameterized by an uncertain friction field. After identifying the performance measures respecting the most criteria, a correlation analysis is carried out to identify how various performance measures are similar. Then, a methodology is proposed to rank performance measures and select the most robust to observation errors. The methodology is shown useful at identifying four performance measures out of 28 in the study case. Note that the various top-ranked performance measures do not lead to the same calibration result as regards the friction field of the shallow-water model. The methodology can be applied to the comparison of any flood model with any flood event.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00571v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.CE</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Paul Travert, S\'ebastien Boyaval, C\'edric Goeury, Vito Bacchi, Fabrice Zaoui</dc:creator>
    </item>
    <item>
      <title>Synthetic dual image generation for reduction of labeling efforts in semantic segmentation of micrographs with a customized metric function</title>
      <link>https://arxiv.org/abs/2408.00707</link>
      <description>arXiv:2408.00707v1 Announce Type: cross 
Abstract: Training of semantic segmentation models for material analysis requires micrographs and their corresponding masks. It is quite unlikely that perfect masks will be drawn, especially at the edges of objects, and sometimes the amount of data that can be obtained is small, since only a few samples are available. These aspects make it very problematic to train a robust model. We demonstrate a workflow for the improvement of semantic segmentation models of micrographs through the generation of synthetic microstructural images in conjunction with masks. The workflow only requires joining a few micrographs with their respective masks to create the input for a Vector Quantised-Variational AutoEncoder model that includes an embedding space, which is trained such that a generative model (PixelCNN) learns the distribution of each input, transformed into discrete codes, and can be used to sample new codes. The latter will eventually be decoded by VQ-VAE to generate images alongside corresponding masks for semantic segmentation. To evaluate the synthetic data, we have trained U-Net models with different amounts of these synthetic data in conjunction with real data. These models were then evaluated using non-synthetic images only. Additionally, we introduce a customized metric derived from the mean Intersection over Union (mIoU). The proposed metric prevents a few falsely predicted pixels from greatly reducing the value of the mIoU. We have achieved a reduction in sample preparation and acquisition times, as well as the efforts, needed for image processing and labeling tasks, are less when it comes to training semantic segmentation model. The approach could be generalized to various types of image data such that it serves as a user-friendly solution for training models with a small number of real images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00707v1</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias Oscar Volman Stern, Dominic Hohs, Andreas Jansche, Timo Bernthaler, Gerhard Schneider</dc:creator>
    </item>
    <item>
      <title>Unstructured Moving Least Squares Material Point Methods: A Stable Kernel Approach With Continuous Gradient Reconstruction on General Unstructured Tessellations</title>
      <link>https://arxiv.org/abs/2312.10338</link>
      <description>arXiv:2312.10338v2 Announce Type: replace 
Abstract: The Material Point Method (MPM) is a hybrid Eulerian Lagrangian simulation technique for solid mechanics with significant deformation. Structured background grids are commonly employed in the standard MPM, but they may give rise to several accuracy problems in handling complex geometries. When using (2D) unstructured triangular or (3D) tetrahedral background elements, however, significant challenges arise (\eg, cell-crossing error). Substantial numerical errors develop due to the inherent $\mathcal{C}^0$ continuity property of the interpolation function, which causes discontinuous gradients across element boundaries. Prior efforts in constructing $\mathcal{C}^1$ continuous interpolation functions have either not been adapted for unstructured grids or have only been applied to 2D triangular meshes. In this study, an Unstructured Moving Least Squares MPM (UMLS-MPM) is introduced to accommodate 2D and 3D simplex tessellation. The central idea is to incorporate a diminishing function into the sample weights of the MLS kernel, ensuring an analytically continuous velocity gradient estimation. Numerical analyses confirm the method's capability in mitigating cell crossing inaccuracies and realizing expected convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10338v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00466-024-02524-x</arxiv:DOI>
      <arxiv:journal_reference>Comput. Mech. 2024. Unstructured moving least squares material point methods: a stable kernel approach with continuous gradient reconstruction on general unstructured tessellations</arxiv:journal_reference>
      <dc:creator>Yadi Cao, Yidong Zhao, Minchen Li, Yin Yang, Jinhyun Choo, Demetri Terzopoulos, Chenfanfu Jiang</dc:creator>
    </item>
    <item>
      <title>Statistical analysis of geoinformation data for increasing railway safety</title>
      <link>https://arxiv.org/abs/2406.01083</link>
      <description>arXiv:2406.01083v2 Announce Type: replace 
Abstract: The impact of rail transport on the environment is one of the crucial factors for the sustainable development of this form of mass transport. We present a data-driven analysis of wild animal railway accidents in the region of southern Poland, a step to create the train driver warning system. We built our method by harnessing the Bayesian approach to the statistical analysis of information about the geolocation of the accidents. The implementation of the proposed model does not require advanced knowledge of data mining and can be applied even in less developed railway systems with small IT support. Furthermore, we have discovered unusual patterns of accidents while considering the number of trains and their speed and time at particular geographical locations of the railway network. We test the developed approach using data from southern Poland, compromising wildlife habitats and one of the most urbanised regions in Central Europe, based on this we conclude that our model is best suited to railway lines that pass through varying types of landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01083v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katarzyna Gawlak, Jaros{\l}aw Konieczny, Krzysztof Domino, Jaros{\l}aw Adam Miszczak</dc:creator>
    </item>
    <item>
      <title>Graph neural network-based surrogate modelling for real-time hydraulic prediction of urban drainage networks</title>
      <link>https://arxiv.org/abs/2404.10324</link>
      <description>arXiv:2404.10324v2 Announce Type: replace-cross 
Abstract: Physics-based models are computationally time-consuming and infeasible for real-time scenarios of urban drainage networks, and a surrogate model is needed to accelerate the online predictive modelling. Fully-connected neural networks (NNs) are potential surrogate models, but may suffer from low interpretability and efficiency in fitting complex targets. Owing to the state-of-the-art modelling power of graph neural networks (GNNs) and their match with urban drainage networks in the graph structure, this work proposes a GNN-based surrogate of the flow routing model for the hydraulic prediction problem of drainage networks, which regards recent hydraulic states as initial conditions, and future runoff and control policy as boundary conditions. To incorporate hydraulic constraints and physical relationships into drainage modelling, physics-guided mechanisms are designed on top of the surrogate model to restrict the prediction variables with flow balance and flooding occurrence constraints. According to case results in a stormwater network, the GNN-based model is more cost-effective with better hydraulic prediction accuracy than the NN-based model after equal training epochs, and the designed mechanisms further limit prediction errors with interpretable domain knowledge. As the model structure adheres to the flow routing mechanisms and hydraulic constraints in urban drainage networks, it provides an interpretable and effective solution for data-driven surrogate modelling. Simultaneously, the surrogate model accelerates the predictive modelling of urban drainage networks for real-time use compared with the physics-based model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10324v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.watres.2024.122142</arxiv:DOI>
      <arxiv:journal_reference>Water Research, 2024, 263, 122142</arxiv:journal_reference>
      <dc:creator>Zhiyu Zhang, Chenkaixiang Lu, Wenchong Tian, Zhenliang Liao, Zhiguo Yuan</dc:creator>
    </item>
  </channel>
</rss>
