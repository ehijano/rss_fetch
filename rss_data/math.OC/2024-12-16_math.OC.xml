<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Dec 2024 03:56:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MPAX: Mathematical Programming in JAX</title>
      <link>https://arxiv.org/abs/2412.09734</link>
      <description>arXiv:2412.09734v1 Announce Type: new 
Abstract: We introduce MPAX (Mathematical Programming in JAX), a versatile and efficient toolbox for integrating mathematical programming into machine learning workflows. MPAX implemented firstorder methods in JAX, providing native support for hardware accelerations along with features like batch solving, auto-differentiation, and device parallelism. Currently in beta version, MPAX supports linear programming and will be extended to solve more general mathematical programming problems and specialized modules for common machine learning tasks. The solver is available at https://github.com/MIT-Lu-Lab/MPAX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09734v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Zedong Peng, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>Optimal Prediction of Multivalued Functions from Point Samples</title>
      <link>https://arxiv.org/abs/2412.09894</link>
      <description>arXiv:2412.09894v1 Announce Type: new 
Abstract: Predicting the value of a function $f$ at a new point given its values at old points is an ubiquitous scientific endeavor, somewhat less developed when $f$ produces multiple values that depend on one another, e.g. when it outputs likelihoods or concentrations. Considering the points as fixed (not random) entities and focusing on the worst-case, this article uncovers a prediction procedure that is optimal relatively to some model-set information about $f$. When the model sets are convex, this procedure turns out to be an affine map constructed by solving a convex optimization program. The theoretical result is specified in the two practical frameworks of (reproducing kernel) Hilbert spaces and of spaces of continuous functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09894v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Foucart</dc:creator>
    </item>
    <item>
      <title>Twice Epi-Differentiability of Orthogonally Invariant Matrix Functions and Application</title>
      <link>https://arxiv.org/abs/2412.09898</link>
      <description>arXiv:2412.09898v1 Announce Type: new 
Abstract: In this paper, our focus lies on the study of the second-order variational analysis of orthogonally invariant matrix functions. It is well-known that an orthogonally invariant matrix function is an extended-real-value function defined on ${\mathbb M}_{m,n}\,(n \leqslant m)$ of the form $f \circ \sigma$ for an absolutely symmetric function $f \colon \R^n \rightarrow [-\infty,+\infty]$ and the singular values $\sigma \colon {\mathbb M}_{m,n} \rightarrow \R^{n}$. We establish several second-order properties of orthogonally invariant matrix functions, such as parabolic epi-differentiability, parabolic regularity, and twice epi-differentiability when their associated absolutely symmetric functions enjoy some properties. Specifically, we show that the nuclear norm of a real $m \times n$ matrix is twice epi-differentiable and we derive an explicit expression of its second-order epi-derivative. Moreover, for a convex orthogonally invariant matrix function, we calculate its second subderivative and present sufficient conditions for twice epi-differentiability. This enables us to establish second-order optimality conditions for a class of matrix optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09898v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiahuan He, Chao Kan, Wen Song</dc:creator>
    </item>
    <item>
      <title>Latent feedback control of distributed systems in multiple scenarios through deep learning-based reduced order models</title>
      <link>https://arxiv.org/abs/2412.09942</link>
      <description>arXiv:2412.09942v1 Announce Type: new 
Abstract: Continuous monitoring and real-time control of high-dimensional distributed systems are often crucial in applications to ensure a desired physical behavior, without degrading stability and system performances. Traditional feedback control design that relies on full-order models, such as high-dimensional state-space representations or partial differential equations, fails to meet these requirements due to the delay in the control computation, which requires multiple expensive simulations of the physical system. The computational bottleneck is even more severe when considering parametrized systems, as new strategies have to be determined for every new scenario. To address these challenges, we propose a real-time closed-loop control strategy enhanced by nonlinear non-intrusive Deep Learning-based Reduced Order Models (DL-ROMs). Specifically, in the offline phase, (i) full-order state-control pairs are generated for different scenarios through the adjoint method, (ii) the essential features relevant for control design are extracted from the snapshots through a combination of Proper Orthogonal Decomposition (POD) and deep autoencoders, and (iii) the low-dimensional policy bridging latent control and state spaces is approximated with a feedforward neural network. After data generation and neural networks training, the optimal control actions are retrieved in real-time for any observed state and scenario. In addition, the dynamics may be approximated through a cheap surrogate model in order to close the loop at the latent level, thus continuously controlling the system in real-time even when full-order state measurements are missing. The effectiveness of the proposed method, in terms of computational speed, accuracy, and robustness against noisy data, is finally assessed on two different high-dimensional optimal transport problems, one of which also involving an underlying fluid flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09942v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Tomasetto, Francesco Braghin, Andrea Manzoni</dc:creator>
    </item>
    <item>
      <title>Coordinated vehicle dispatching and charging scheduling for an electric ride-hailing fleet under charging congestion and dynamic prices</title>
      <link>https://arxiv.org/abs/2412.09978</link>
      <description>arXiv:2412.09978v1 Announce Type: new 
Abstract: Effective utilization of charging station capacity plays an important role in enhancing the profitability of ride-hailing systems using electric vehicles. Existing studies assume constant energy prices and uncapacitated charging stations or do not explicitly consider vehicle queueing at charging stations, resulting in over-optimistic charging infrastructure utilization. In this study, we develop a dynamic charging scheduling method (named CongestionAware) that anticipates vehicles' energy needs and coordinates their charging operations with real-time energy prices to avoid long waiting time at charging stations and increase the total profit of the system. A sequential mixed integer linear programming model is proposed to devise vehicles' day-ahead charging plans based on their experienced charging waiting times and energy consumption. The obtained charging plans are adapted within the day in response to vehicles' energy needs and charging station congestion. The developed charging policy is tested using NYC yellow taxi data in a Manhattan-like study area with a fleet size of 100 vehicles given the scenarios of 3000 and 4000 customers per day. The computational results show that our CongestionAware policy outperforms different benchmark policies with up to +15.06% profit and +19.16% service rate for 4000 customers per day. Sensitivity analysis is conducted with different system parameters and managerial insights are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09978v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tai-Yu Ma, Richard D. Connors, Francesco Viti</dc:creator>
    </item>
    <item>
      <title>A Two-Step Warm Start Method Used for Solving Large-Scale Stochastic Mixed-Integer Problems</title>
      <link>https://arxiv.org/abs/2412.10098</link>
      <description>arXiv:2412.10098v1 Announce Type: new 
Abstract: Two-stage stochastic programs become computationally challenging when the number of scenarios representing parameter uncertainties grows. Motivated by this, we propose the TULIP-algorithm ("Two-step warm start method Used for solving Large-scale stochastic mixed-Integer Problems"), a two-step approach for solving two-stage stochastic (mixed) integer linear programs with an exponential number of constraints. In this approach, we first generate a reduced set of representative scenarios and solve the root node of the corresponding integer linear program using a cutting-plane method. The generated constraints are then used to accelerate solving the original problem with the full scenario set in the second phase. We demonstrate the generic effectiveness of TULIP on two benchmark problems: the Stochastic Capacitated Vehicle Routing Problem and the Two-Stage Stochastic Steiner Forest Problem. The results of our extensive numerical experiments show that TULIP yields significant computational gains compared to solving the problem directly with branch-and-cut.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10098v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berend Markhorst, Markus Leitner, Joost Berkhout, Alessandro Zocca, Rob van der Mei</dc:creator>
    </item>
    <item>
      <title>Indirect Adaptive Control Using a Static Update Law</title>
      <link>https://arxiv.org/abs/2412.10102</link>
      <description>arXiv:2412.10102v1 Announce Type: new 
Abstract: The update law in the indirect adaptive control scheme can be extended to include feedthrough of an error term. This reduces undesired oscillations of the calculated weights. When the {\sigma}-modification is used for achieving robustness against unstructured uncertainties, the gain of the feedthrough in the update law cannot be chosen arbitrarily. Compared to our previous result, we show stability of the closed loop for a larger parameter-range for the gain of the feedthrough in the update law. This parameter-range includes a configuration for which the influence of the integration in the update law diminishes over time, i.e. for which the adaptation for large times is governed solely by the feedthrough in the update law. By initializing at zero, this allows for removing the integration from the update law, resulting in a static update law. For the purely linear case, the adaptation acts like a disturbance observer. Frequency-domain analysis of the closed loop with a second order plant shows that removing the integration from the update law with {\sigma}-modification and feedthrough affects how precisely disturbances in the low-frequency band are observed. If the damping injected into the adaptation process by the {\sigma}-modification exceeds certain bounds, then the precision is increased by using the static update law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10102v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tom Kaufmann, Johann Reger</dc:creator>
    </item>
    <item>
      <title>A note on the Moment Problem for codimension greater than 1</title>
      <link>https://arxiv.org/abs/2412.10162</link>
      <description>arXiv:2412.10162v1 Announce Type: new 
Abstract: We provide new conditions under which the alternating projection sequence converges in norm for the convex feasibility problem where a linear subspace with finite codimension $N\geq 2$ and a lattice cone in a Hilbert space are considered. The first result holds for any Hilbert lattice, assuming that the orthogonal of the linear subspace admits a basis made by disjoint vectors with respect to the lattice structure. The second result is specific for $\ell^2(\mathbb{N})$ and is proved when only one vector of the basis is not in the cone but the sign of its components is definitively constant and its support has finite intersection with the supports of the remaining vectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10162v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Battistoni, Enrico Miglierina</dc:creator>
    </item>
    <item>
      <title>Non-overshooting output shaping for switched linear systems under arbitrary switching using eigenstructure assignment</title>
      <link>https://arxiv.org/abs/2410.06688</link>
      <description>arXiv:2410.06688v1 Announce Type: cross 
Abstract: We consider the analytical control design for a pair of switched linear multiple-input multiple-output (MIMO) systems that are subject to arbitrary switching signals. A state feedback controller design method is proposed to obtain an eigenstructure assignment that ensures that the closed-loop switched system is globally asymptotically stable, and the outputs achieve the non-overshooting tracking of a step reference. Our analysis indicates whether non-overshooting or even monotonic tracking is achievable for the given system and considered outputs and provides a choice of possible eigenstructures to be assigned to the constituent subsystems. We derive a structural condition that verifies the feasibility of the chosen assignment. A constructive algorithm to obtain suitable feedback matrices is provided, and the method is illustrated with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06688v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kai Wulff, Maria Christine Honecker, Robert Schmid, Johann Reger</dc:creator>
    </item>
    <item>
      <title>Understand the Effectiveness of Shortcuts through the Lens of DCA</title>
      <link>https://arxiv.org/abs/2412.09853</link>
      <description>arXiv:2412.09853v1 Announce Type: cross 
Abstract: Difference-of-Convex Algorithm (DCA) is a well-known nonconvex optimization algorithm for minimizing a nonconvex function that can be expressed as the difference of two convex ones. Many famous existing optimization algorithms, such as SGD and proximal point methods, can be viewed as special DCAs with specific DC decompositions, making it a powerful framework for optimization. On the other hand, shortcuts are a key architectural feature in modern deep neural networks, facilitating both training and optimization. We showed that the shortcut neural network gradient can be obtained by applying DCA to vanilla neural networks, networks without shortcut connections. Therefore, from the perspective of DCA, we can better understand the effectiveness of networks with shortcuts. Moreover, we proposed a new architecture called NegNet that does not fit the previous interpretation but performs on par with ResNet and can be included in the DCA framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09853v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youran Sun, Yihua Liu, Yi-Shuai Niu</dc:creator>
    </item>
    <item>
      <title>Two Results for the Omega Limit Sets of Dynamical Systems</title>
      <link>https://arxiv.org/abs/2412.10014</link>
      <description>arXiv:2412.10014v1 Announce Type: cross 
Abstract: This paper provides two results for the omega limit sets of a dynamical system. We show that omega limit sets can be estimated by using functions that satisfy different (and in many cases less demanding) assumptions than the usual assumptions in Lyapunov theorems and LaSalle's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10014v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iasson Karafyllis</dc:creator>
    </item>
    <item>
      <title>FISTA-Condat-Vu: Automatic Differentiation for Hyperparameter Learning in Variational Models</title>
      <link>https://arxiv.org/abs/2412.10034</link>
      <description>arXiv:2412.10034v1 Announce Type: cross 
Abstract: Motivated by industrial computed tomography, we propose a memory efficient strategy to estimate the regularization hyperparameter of a non-smooth variational model. The approach is based on a combination of FISTA and Condat-Vu algorithms exploiting the convergence rate of the former and the low per-iteration complexity of the latter. The estimation is cast as a bilevel learning problem where a first-order method is obtained via reduced-memory automatic differentiation to compute the derivatives. The method is validated with experimental industrial tomographic data with the numerical implementation available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10034v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Patricio Guerrero, Simon Bellens, Wim Dewulf</dc:creator>
    </item>
    <item>
      <title>An $O(N)$ Algorithm for Solving the Smallest Enclosing Sphere Problem in the Presence of Degeneracies</title>
      <link>https://arxiv.org/abs/2412.10120</link>
      <description>arXiv:2412.10120v1 Announce Type: cross 
Abstract: Efficient algorithms for solving the Smallest Enclosing Sphere (SES) problem, such as Welzl's algorithm, often fail to handle degenerate subsets of points in 3D space. Degeneracies and ill-posed configurations present significant challenges, leading to failures in convergence, inaccuracies or increased computational cost in such cases. Existing improvements to these algorithms, while addressing some of these issues, are either computationally expensive or only partially effective. In this paper, we propose a hybrid algorithm designed to mitigate degeneracy while maintaining an overall computational complexity of $O(N)$. By combining robust preprocessing steps with efficient core computations, our approach avoids the pitfalls of degeneracy without sacrificing scalability. The proposed method is validated through theoretical analysis and experimental results, demonstrating its efficacy in addressing degenerate configurations and achieving high efficiency in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10120v1</guid>
      <category>cs.CG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Netzer Moriya</dc:creator>
    </item>
    <item>
      <title>TIGRE v3: Efficient and easy to use iterative computed tomographic reconstruction toolbox for real datasets</title>
      <link>https://arxiv.org/abs/2412.10129</link>
      <description>arXiv:2412.10129v1 Announce Type: cross 
Abstract: Computed Tomography (CT) has been widely adopted in medicine and it is increasingly being used in scientific and industrial applications. Parallelly, research in different mathematical areas concerning discrete inverse problems has led to the development of new sophisticated numerical solvers that can be applied in the context of CT. The Tomographic Iterative GPU-based Reconstruction (TIGRE) toolbox was born almost a decade ago precisely in the gap between mathematics and high performance computing for real CT data, providing user-friendly open-source software tools for image reconstruction. However, since its inception, the tools' features and codebase have had over a twenty-fold increase, and are now including greater geometric flexibility, a variety of modern algorithms for image reconstruction, high-performance computing features and support for other CT modalities, like proton CT. The purpose of this work is two-fold: first, it provides a structured overview of the current version of the TIGRE toolbox, providing appropriate descriptions and references, and serving as a comprehensive and peer-reviewed guide for the user; second, it is an opportunity to illustrate the performance of several of the available solvers showcasing real CT acquisitions, which are typically not be openly available to algorithm developers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10129v1</guid>
      <category>physics.med-ph</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ander Biguri, Tomoyuki Sadakane, Reuben Lindroos, Yi Liu, Malena Sabat\'e Landman, Yi Du, Manasavee Lohvithee, Stefanie Kaser, Sepideh Hatamikia, Robert Bryll, Emilien Valat, Sarinrat Wonglee, Thomas Blumensath, Carola-Bibiane Sch\"onlieb</dc:creator>
    </item>
    <item>
      <title>Stochastic Multiresolution Image Sketching for Inverse Imaging Problems</title>
      <link>https://arxiv.org/abs/2412.10249</link>
      <description>arXiv:2412.10249v1 Announce Type: cross 
Abstract: A challenge in high-dimensional inverse problems is developing iterative solvers to find the accurate solution of regularized optimization problems with low computational cost. An important example is computed tomography (CT) where both image and data sizes are large and therefore the forward model is costly to evaluate. Since several years algorithms from stochastic optimization are used for tomographic image reconstruction with great success by subsampling the data. Here we propose a novel way how stochastic optimization can be used to speed up image reconstruction by means of image domain sketching such that at each iteration an image of different resolution is being used. Hence, we coin this algorithm ImaSk. By considering an associated saddle-point problem, we can formulate ImaSk as a gradient-based algorithm where the gradient is approximated in the same spirit as the stochastic average gradient am\'elior\'e (SAGA) and uses at each iteration one of these multiresolution operators at random. We prove that ImaSk is linearly converging for linear forward models with strongly convex regularization functions. Numerical simulations on CT show that ImaSk is effective and increasing the number of multiresolution operators reduces the computational time to reach the modeled solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10249v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Perelli, Carola-Bibiane Schonlieb, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Quadratic unconstrained binary optimization and constraint programming approaches for lattice-based cyclic peptide docking</title>
      <link>https://arxiv.org/abs/2412.10260</link>
      <description>arXiv:2412.10260v1 Announce Type: cross 
Abstract: The peptide-protein docking problem is an important problem in structural biology that facilitates rational and efficient drug design. In this work, we explore modeling and solving this problem with the quantum-amenable quadratic unconstrained binary optimization (QUBO) formalism. Our work extends recent efforts by incorporating the objectives and constraints associated with peptide cyclization and peptide-protein docking in the two-particle model on a tetrahedral lattice. We propose a ``resource efficient'' QUBO encoding for this problem, and baseline its performance with a novel constraint programming (CP) approach. We implement an end-to-end framework that enables the evaluation of our methods on instances from the Protein Data Bank (PDB). Our results show that the QUBO approach, using a classical simulated annealing solver, is able to find feasible conformations for problems with up to 6 peptide residues and 34 target protein residues, but has trouble scaling beyond this problem size. In contrast, the CP approach can solve problems with up to 13 peptide residues and 34 target protein residues. We conclude that while QUBO can be used to successfully tackle this problem, its scaling limitations and the strong performance of the CP method suggest that it may not be the best choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10260v1</guid>
      <category>q-bio.BM</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>quant-ph</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. Kyle Brubaker, Kyle E. C. Booth, Akihiko Arakawa, Fabian Furrer, Jayeeta Ghosh, Tsutomu Sato, Helmut G. Katzgraber</dc:creator>
    </item>
    <item>
      <title>Differentially Private Decentralized Optimization with Relay Communication</title>
      <link>https://arxiv.org/abs/2212.10859</link>
      <description>arXiv:2212.10859v2 Announce Type: replace 
Abstract: Security concerns in large-scale networked environments are becoming increasingly critical. To further improve the algorithm security from the design perspective of decentralized optimization algorithms, we introduce a new measure: Privacy Leakage Frequency (PLF), which reveals the relationship between communication and privacy leakage of algorithms, showing that lower PLF corresponds to lower privacy budgets. Based on such assertion, a novel differentially private decentralized primal--dual algorithm named DP-RECAL is proposed to take advantage of operator splitting method and relay communication mechanism to experience less PLF so as to reduce the overall privacy budget. To the best of our knowledge, compared with existing differentially private algorithms, DP-RECAL presents superior privacy performance and communication complexity. In addition, with uncoordinated network-independent stepsizes, we prove the convergence of DP-RECAL for general convex problems and establish a linear convergence rate under the metric subregularity. Evaluation analysis on least squares problem and numerical experiments on real-world datasets verify our theoretical results and demonstrate that DP-RECAL can defend some classical gradient leakage attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.10859v2</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIFS.2024.3515803</arxiv:DOI>
      <dc:creator>Luqing Wang, Luyao Guo, Shaofu Yang, Xinli Shi</dc:creator>
    </item>
    <item>
      <title>Machine Learning for Optimization-Based Separation of Mixed-Integer Rounding Cuts</title>
      <link>https://arxiv.org/abs/2408.08449</link>
      <description>arXiv:2408.08449v2 Announce Type: replace 
Abstract: Mixed-integer rounding (MIR) cutting planes (cuts) are effective at improving the strength of a linear relaxation for mixed-integer linear programming (MIP) problems. The cuts in this family are derived by aggregating constraints then rounding coefficients, but finding the strongest MIR cuts requires optimizing a costly MIP for the aggregation step, so in practice, heuristic strategies for separating fractional points are employed. We propose to improve MIR cut generation in the context of a common scenario in applications, where constraints remain fixed but costs are varied. We present a hybrid cut generation framework in which we train a machine learning (ML) model to classify which constraints are involved in useful MIR cuts based on fractional points from relaxations of the problem. At test time, the predictions of the ML model create a reduced MIP-based generator of MIR cuts. In our experiments, we create an instance family from each of three benchmark MIP instances by performing a careful and costly perturbation of objective coefficients to build a dataset of 1,000 fractional points to be separated over the same constraint set. The results indicate that the reduced separator better strengthens the bound in each round of cut generation, particularly for instances in which the full separator failed to find strong cuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08449v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar Guaje, Arnaud Deza, Aleksandr M. Kazachkov, Elias B. Khalil</dc:creator>
    </item>
    <item>
      <title>Closed-loop Analysis of ADMM-based Suboptimal Linear Model Predictive Control</title>
      <link>https://arxiv.org/abs/2409.11351</link>
      <description>arXiv:2409.11351v2 Announce Type: replace 
Abstract: Many practical applications of optimal control are subject to real-time computational constraints. When applying model predictive control (MPC) in these settings, respecting timing constraints is achieved by limiting the number of iterations of the optimization algorithm used to compute control actions at each time step, resulting in so-called suboptimal MPC. This paper proposes a suboptimal MPC scheme based on the alternating direction method of multipliers (ADMM). With a focus on the linear quadratic regulator problem with state and input constraints, we show how ADMM can be used to split the MPC problem into iterative updates of an unconstrained optimal control problem (with an analytical solution), and a dynamics-free feasibility step. We show that using a warm-start approach combined with enough iterations per time-step, yields an ADMM-based suboptimal MPC scheme which asymptotically stabilizes the system and maintains recursive feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11351v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anusha Srikanthan, Aren Karapetyan, Vijay Kumar, Nikolai Matni</dc:creator>
    </item>
    <item>
      <title>Efficient Sign-Based Optimization: Accelerating Convergence via Variance Reduction</title>
      <link>https://arxiv.org/abs/2406.00489</link>
      <description>arXiv:2406.00489v3 Announce Type: replace-cross 
Abstract: Sign stochastic gradient descent (signSGD) is a communication-efficient method that transmits only the sign of stochastic gradients for parameter updating. Existing literature has demonstrated that signSGD can achieve a convergence rate of $\mathcal{O}(d^{1/2}T^{-1/4})$, where $d$ represents the dimension and $T$ is the iteration number. In this paper, we improve this convergence rate to $\mathcal{O}(d^{1/2}T^{-1/3})$ by introducing the Sign-based Stochastic Variance Reduction (SSVR) method, which employs variance reduction estimators to track gradients and leverages their signs to update. For finite-sum problems, our method can be further enhanced to achieve a convergence rate of $\mathcal{O}(m^{1/4}d^{1/2}T^{-1/2})$, where $m$ denotes the number of component functions. Furthermore, we investigate the heterogeneous majority vote in distributed settings and introduce two novel algorithms that attain improved convergence rates of $\mathcal{O}(d^{1/2}T^{-1/2} + dn^{-1/2})$ and $\mathcal{O}(d^{1/4}T^{-1/4})$ respectively, outperforming the previous results of $\mathcal{O}(dT^{-1/4} + dn^{-1/2})$ and $\mathcal{O}(d^{3/8}T^{-1/8})$, where $n$ represents the number of nodes. Numerical experiments across different tasks validate the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00489v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Sifan Yang, Wenhao Yang, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Passivity Tools for Hybrid Learning Rules in Large Populations</title>
      <link>https://arxiv.org/abs/2407.02083</link>
      <description>arXiv:2407.02083v3 Announce Type: replace-cross 
Abstract: Recent work has pioneered the use of system-theoretic passivity to study equilibrium stability for the dynamics of noncooperative strategic interactions in large populations of learning agents. In this and related works, the stability analysis leverages knowledge that certain ``canonical'' classes of learning rules used to model the agents' strategic behaviors satisfy a passivity condition known as $\delta$-passivity. In this paper, we consider that agents exhibit learning behaviors that do not align with a canonical class. Specifically, we focus on characterizing $\delta$-passivity for hybrid learning rules that combine elements from canonical classes. Our analysis also introduces and uses a more general version of $\delta$-passivity, which, for the first time, can handle discontinuous learning rules, including those showing best-response behaviors. We state and prove theorems establishing $\delta$-passivity for two broad convex cones of hybrid learning rules. These cones can merge into a larger one preserving $\delta$-passivity in scenarios limited to two strategies. In our proofs, we establish intermediate facts that are significant on their own and could potentially be used to further generalize our work. We illustrate the applicability of our results through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02083v3</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jair Certorio, Kevin Chang, Nuno C. Martins, Pierluigi Nuzzo, Yasser Shoukry</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with SGD</title>
      <link>https://arxiv.org/abs/2410.04458</link>
      <description>arXiv:2410.04458v3 Announce Type: replace-cross 
Abstract: Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in deep learning, widely recognized for its flexibility with adaptive learning rates and efficiency in handling large-scale data. However, despite its practical success, the theoretical understanding of Adam's convergence has been constrained by stringent assumptions, such as almost surely bounded stochastic gradients or uniformly bounded gradients, which are more restrictive than those typically required for analyzing stochastic gradient descent (SGD).
  In this paper, we introduce a novel and comprehensive framework for analyzing the convergence properties of Adam. This framework offers a versatile approach to establishing Adam's convergence. Specifically, we prove that Adam achieves asymptotic (last iterate sense) convergence in both the almost sure sense and the \(L_1\) sense under the relaxed assumptions typically used for SGD, namely \(L\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions, we show that Adam attains non-asymptotic sample complexity bounds similar to those of SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04458v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruinan Jin, Xiao Li, Yaoliang Yu, Baoxiang Wang</dc:creator>
    </item>
    <item>
      <title>On the Crucial Role of Initialization for Matrix Factorization</title>
      <link>https://arxiv.org/abs/2410.18965</link>
      <description>arXiv:2410.18965v3 Announce Type: replace-cross 
Abstract: This work revisits the classical low-rank matrix factorization problem and unveils the critical role of initialization in shaping convergence rates for such nonconvex and nonsmooth optimization. We introduce Nystrom initialization, which significantly improves the global convergence of Scaled Gradient Descent (ScaledGD) in both symmetric and asymmetric matrix factorization tasks. Specifically, we prove that ScaledGD with Nystrom initialization achieves quadratic convergence in cases where only linear rates were previously known. Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly used for finetuning foundation models. Our approach, NoRA, i.e., LoRA with Nystrom initialization, demonstrates superior performance across various downstream tasks and model scales, from 1B to 7B parameters, in large language and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18965v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bingcong Li, Liang Zhang, Aryan Mokhtari, Niao He</dc:creator>
    </item>
    <item>
      <title>Opinion Dynamic Under Malicious Agent Influence in Multi-Agent Systems: From the Perspective of Opinion Evolution Cost</title>
      <link>https://arxiv.org/abs/2412.01524</link>
      <description>arXiv:2412.01524v2 Announce Type: replace-cross 
Abstract: In human social systems, debates are often seen as a means to resolve differences of opinion. However, in reality, debates frequently incur significant communication costs, especially when dealing with stubborn opponents. Inspired by this phenomenon, this paper examines the impact of malicious agents on the evolution of normal agents' opinions from the perspective of opinion evolution cost, and proposes corresponding solutions for the scenario in which malicious agents hold different opinions in multi-agent systems(MASs). First, this paper analyzes the negative impact of malicious agents on the opinion evolution process, reveals the additional evolution cost it brings, and provides a theoretical basis for the subsequent solutions. Secondly, based on the characteristics of opinion evolution, the malicious agent isolation algorithm based on opinion evolution direction vector is proposed, which does not strongly restrict the proportion of malicious agents. Additionally, an evolution rate adjustment mechanism is introduced, allowing the system to flexibly regulate the evolution process in complex situations, effectively achieving the trade-off between opinion evolution rate and cost. Extensive numerical simulations demonstrate that the algorithm can effectively eliminate the negative influence of malicious agents and achieve a balance between opinion evolution costs and convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01524v2</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Suo, Runqi Chai, Senchun Chai, Ishrak MD Farhan, Xudong Zhao, Yuanqing Xia</dc:creator>
    </item>
  </channel>
</rss>
