<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Dec 2024 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Primary visual cortex contributes to color constancy by predicting rather than discounting the illuminant: evidence from a computational study</title>
      <link>https://arxiv.org/abs/2412.07102</link>
      <description>arXiv:2412.07102v1 Announce Type: new 
Abstract: Color constancy (CC) is an important ability of the human visual system to stably perceive the colors of objects despite considerable changes in the color of the light illuminating them. While increasing evidence from the field of neuroscience supports that multiple levels of the visual system contribute to the realization of CC, how the primary visual cortex (V1) plays role in CC is not fully resolved. In specific, double-opponent (DO) neurons in V1 have been thought to contribute to realizing a degree of CC, but the computational mechanism is not clear. We build an electrophysiologically based V1 neural model to learn the color of the light source from a natural image dataset with the ground truth illuminants as the labels. Based on the qualitative and quantitative analysis of the responsive properties of the learned model neurons, we found that both the spatial structures and color weights of the receptive fields of the learned model neurons are quite similar to those of the simple and DO neurons recorded in V1. Computationally, DO cells perform more robustly than the simple cells in V1 for illuminant prediction. Therefore, this work provides computational evidence supporting that V1 DO neurons serve to realize color constancy by encoding the illuminant,which is contradictory to the common hypothesis that V1 contributes to CC by discounting the illuminant using its DO cells. This evidence is expected to not only help resolve the visual mechanisms of CC, but also provide inspiration to develop more effective computer vision models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07102v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaobing Gao, Yongjie Li</dc:creator>
    </item>
    <item>
      <title>QuantFormer: Learning to Quantize for Neural Activity Forecasting in Mouse Visual Cortex</title>
      <link>https://arxiv.org/abs/2412.07264</link>
      <description>arXiv:2412.07264v1 Announce Type: new 
Abstract: Understanding complex animal behaviors hinges on deciphering the neural activity patterns within brain circuits, making the ability to forecast neural activity crucial for developing predictive models of brain dynamics. This capability holds immense value for neuroscience, particularly in applications such as real-time optogenetic interventions. While traditional encoding and decoding methods have been used to map external variables to neural activity and vice versa, they focus on interpreting past data. In contrast, neural forecasting aims to predict future neural activity, presenting a unique and challenging task due to the spatiotemporal sparsity and complex dependencies of neural signals. Existing transformer-based forecasting methods, while effective in many domains, struggle to capture the distinctiveness of neural signals characterized by spatiotemporal sparsity and intricate dependencies. To address this challenge, we here introduce QuantFormer, a transformer-based model specifically designed for forecasting neural activity from two-photon calcium imaging data. Unlike conventional regression-based approaches, QuantFormerreframes the forecasting task as a classification problem via dynamic signal quantization, enabling more effective learning of sparse neural activation patterns. Additionally, QuantFormer tackles the challenge of analyzing multivariate signals from an arbitrary number of neurons by incorporating neuron-specific tokens, allowing scalability across diverse neuronal populations. Trained with unsupervised quantization on the Allen dataset, QuantFormer sets a new benchmark in forecasting mouse visual cortex activity. It demonstrates robust performance and generalization across various stimuli and individuals, paving the way for a foundational model in neural signal prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07264v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salvatore Calcagno, Isaak Kavasidis, Simone Palazzo, Marco Brondi, Luca Sit\`a, Giacomo Turri, Daniela Giordano, Vladimir R. Kostic, Tommaso Fellin, Massimiliano Pontil, Concetto Spampinato</dc:creator>
    </item>
    <item>
      <title>Gradient Diffusion: Enhancing Multicompartmental Neuron Models for Gradient-Based Self-Tuning and Homeostatic Control</title>
      <link>https://arxiv.org/abs/2412.07327</link>
      <description>arXiv:2412.07327v1 Announce Type: new 
Abstract: Realistic brain models contain many parameters. Traditionally, gradient-free methods are used for estimating these parameters, but gradient-based methods offer many advantages including scalability. However, brain models are tied to existing brain simulators, which do not support gradient calculation. Here we show how to extend -- within the public interface of such simulators -- these neural models to also compute the gradients with respect to their parameters. We demonstrate that the computed gradients can be used to optimize a biophysically realistic multicompartmental neuron model with the gradient-based Adam optimizer. Beyond tuning, gradient-based optimization could lead the way towards dynamics learning and homeostatic control within simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07327v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lennart P. L. Landsmeer, Mario Negrello, Said Hamdioui, Christos Strydis</dc:creator>
    </item>
    <item>
      <title>Investigation of in vitro neuronal activity processing using a CMOS-integrated ZrO2-based memristive crossbar</title>
      <link>https://arxiv.org/abs/2412.07340</link>
      <description>arXiv:2412.07340v1 Announce Type: new 
Abstract: The influence of the epileptiform neuronal activity on the response of a CMOS-integrated ZrO2-based memristive crossbar and its conductivity was studied. Epileptiform neuronal activity was obtained in vitro in the hippocampus slices of laboratory mice using 4-aminopyridine experimental model. Synaptic plasticity of the memristive crossbar induced by epileptiform neuronal activity pulses was detected. Qualitatively, the results obtained in the case of normal (without pathologies) and epileptiform neuronal activity with and without noise coincide. For quantitative analysis, the value of the relative change in synaptic weight has been calculated for such important biological mechanisms of synapses as paired-pulse facilitation/depression, post-tetanic potentiation/depression, and long-term potentiation/depression. It has been shown that average value of the relative change in synaptic weight and its are smaller mainly in the case of epileptiform neuronal activity pulses. An effect of the influence of noise included in the neuronal activity was found, which consists in the fact that the current response of the memristive crossbar is smaller in the presence of noise. The results of this study can be used in the development of new generation hardware-implemented computing devices with high performance and energy efficiency for the tasks of restorative medicine and robotics. In particular, using these results, neurohybrid devices can be developed for processing epileptiform activity in real time and for its suppression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07340v1</guid>
      <category>q-bio.NC</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maria N. Koryazhkina, Albina V. Lebedeva, Darina D. Pakhomova, Ivan N. Antonov, Vyacheslav V. Razin, Elena D. Budylina, Alexey I. Belov, Alexey N. Mikhaylov, Anton A. Konakov</dc:creator>
    </item>
    <item>
      <title>Periodic solutions for a pair of delay-coupled excitable theta neurons</title>
      <link>https://arxiv.org/abs/2412.06804</link>
      <description>arXiv:2412.06804v1 Announce Type: cross 
Abstract: We consider a pair of identical theta neurons in the excitable regime, each coupled to the other via a delayed Dirac delta function with the same delay. This simple network can support different periodic solutions, and we concentrate on two important types: those for which the neurons are perfectly synchronous, and those where the neurons are exactly half a period out of phase and fire alternatingly. Owing to the specific type of pulsatile feedback, we are able to determine these solutions and their stability analytically. More specifically, (infinitely many) branches of periodic solutions of either type are created at saddle-node bifurcations, and they gain stability at symmetry-breaking bifurcations when their period as a function of delay is at its minimum. We also determine the respective branches of symmetry-broken periodic solutions and show that they are all unstable. We demonstrate by considering smoothed pulse-like coupling that the special case of the Dirac delta function can be seen as a sort of normal form: the basic structure of the different periodic solutions of the two theta neurons is preserved, but there may be additional changes of stability along the different branches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06804v1</guid>
      <category>nlin.PS</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlo R. Laing, Bernd Krauskopf</dc:creator>
    </item>
    <item>
      <title>Speaker effects in spoken language comprehension</title>
      <link>https://arxiv.org/abs/2412.07238</link>
      <description>arXiv:2412.07238v1 Announce Type: cross 
Abstract: The identity of a speaker significantly influences spoken language comprehension by affecting both perception and expectation. This review explores speaker effects, focusing on how speaker information impacts language processing. We propose an integrative model featuring the interplay between bottom-up perception-based processes driven by acoustic details and top-down expectation-based processes driven by a speaker model. The acoustic details influence lower-level perception, while the speaker model modulates both lower-level and higher-level processes such as meaning interpretation and pragmatic inferences. We define speaker-idiosyncrasy and speaker-demographics effects and demonstrate how bottom-up and top-down processes interact at various levels in different scenarios. This framework contributes to psycholinguistic theory by offering a comprehensive account of how speaker information interacts with linguistic content to shape message construction. We suggest that speaker effects can serve as indices of a language learner's proficiency and an individual's characteristics of social cognition. We encourage future research to extend these findings to AI speakers, probing the universality of speaker effects across humans and artificial agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07238v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanlin Wu, Zhenguang G. Cai</dc:creator>
    </item>
    <item>
      <title>How EEG preprocessing shapes decoding performance</title>
      <link>https://arxiv.org/abs/2410.14453</link>
      <description>arXiv:2410.14453v2 Announce Type: replace 
Abstract: EEG preprocessing varies widely between studies, but its impact on classification performance remains poorly understood. To address this gap, we analyzed seven experiments with 40 participants drawn from the public ERP CORE dataset. We systematically varied key preprocessing steps, such as filtering, referencing, baseline interval, detrending, and multiple artifact correction steps. Then we performed trial-wise binary classification (i.e., decoding) using neural networks (EEGNet), or time-resolved logistic regressions. Our findings demonstrate that preprocessing choices influenced decoding performance considerably. All artifact correction steps reduced decoding performance across all experiments and models, while higher high-pass filter cutoffs consistently enhanced decoding. For EEGNet, baseline correction further improved performance, and for time-resolved classifiers, linear detrending and lower low-pass filter cutoffs were beneficial. Other optimal preprocessing choices were specific for each experiment. The current results underline the importance of carefully selecting preprocessing steps for EEG-based decoding. If not corrected, artifacts facilitate decoding but compromise conclusive interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14453v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Kessler, Alexander Enge, Michael A. Skeide</dc:creator>
    </item>
    <item>
      <title>Policy consequences of the new neuroeconomic framework</title>
      <link>https://arxiv.org/abs/2409.07373</link>
      <description>arXiv:2409.07373v2 Announce Type: replace-cross 
Abstract: Current theories of decision making suggest that the neural circuits in mammalian brains (including humans) computationally combine representations of the past (memory), present (perception), and future (agentic goals) to take actions that achieve the needs of the agent. How information is represented within those neural circuits changes what computations are available to that system which changes how agents interact with their world to take those actions. We argue that the computational neuroscience of decision making provides a new microeconomic framework (neuroeconomics) that offers new opportunities to construct policies that interact with those decision-making systems to improve outcomes. After laying out the computational processes underlying decision making in mammalian brains, we present four applications of this logic with policy consequences: (1) precommitment to avoid falling into the trap of sunk costs, (2) media consequences for changes in housing prices after a disaster, (3) contingency management as a treatment for addiction, and (4) how social interactions underlie the success (and failure) of microfinance institutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07373v2</guid>
      <category>econ.GN</category>
      <category>q-bio.NC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. David Redish, Henri Scott Chastain, Carlisle Ford Runge, Brian M. Sweis, Scott E. Allen, Antara Haldar</dc:creator>
    </item>
  </channel>
</rss>
