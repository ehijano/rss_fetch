<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 02:48:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Technical Analysis Meets Machine Learning: Bitcoin Evidence</title>
      <link>https://arxiv.org/abs/2511.00665</link>
      <description>arXiv:2511.00665v1 Announce Type: new 
Abstract: In this note, we compare Bitcoin trading performance using two machine learning models-Light Gradient Boosting Machine (LightGBM) and Long Short-Term Memory (LSTM)-and two technical analysis-based strategies: Exponential Moving Average (EMA) crossover and a combination of Moving Average Convergence/Divergence with the Average Directional Index (MACD+ADX). The objective is to evaluate how trading signals can be used to maximize profits in the Bitcoin market. This comparison was motivated by the U.S. Securities and Exchange Commission's (SEC) approval of the first spot Bitcoin exchange-traded funds (ETFs) on 2024-01-10. Our results show that the LSTM model achieved a cumulative return of approximately 65.23% in under a year, significantly outperforming LightGBM, the EMA and MACD+ADX strategies, as well as the baseline buy-and-hold. This study highlights the potential for deeper integration of machine learning and technical analysis in the rapidly evolving cryptocurrency landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00665v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e \'Angel Islas Anguiano, Andr\'es Garc\'ia-Medina</dc:creator>
    </item>
    <item>
      <title>Trade Execution Flow as the Underlying Source of Market Dynamics</title>
      <link>https://arxiv.org/abs/2511.01471</link>
      <description>arXiv:2511.01471v1 Announce Type: new 
Abstract: In this work, we demonstrate experimentally that the execution flow, $I = dV/dt$, is the fundamental driving force of market dynamics. We develop a numerical framework to calculate execution flow from sampled moments using the Radon-Nikodym derivative. A notable feature of this approach is its ability to automatically determine thresholds that can serve as actionable triggers. The technique also determines the characteristic time scale directly from the corresponding eigenproblem. The methodology has been validated on actual market data to support these findings. Additionally, we introduce a framework based on the Christoffel function spectrum, which is invariant under arbitrary non-degenerate linear transformations of input attributes and offers an alternative to traditional principal component analysis (PCA), which is limited to unitary invariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01471v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikhail Gennadievich Belov, Victor Victorovich Dubov, Vadim Konstantinovich Ivanov, Alexander Yurievich Maslov, Olga Vladimirovna Proshina, Vladislav Gennadievich Malyshkin</dc:creator>
    </item>
    <item>
      <title>Branched Signature Model</title>
      <link>https://arxiv.org/abs/2511.00018</link>
      <description>arXiv:2511.00018v1 Announce Type: cross 
Abstract: In this paper, we introduce the branched signature model, motivated by the branched rough path framework of [Gubinelli, Journal of Differential Equations, 248(4), 2010], which generalizes the classical geometric rough path. We establish a universal approximation theorem for the branched signature model and demonstrate that iterative compositions of lower-level signature maps can approximate higher-level signatures. Furthermore, building on the existence of the extension map proposed in [Hairer-Kelly. Annales de l'Institue Henri Poincar\'e, Probabilit\'es et Statistiques 51, no. 1 (2015)], we show how to explicitly construct the extension of the original paths into higher-dimensional spaces via a map $\Psi$, so that the branched signature can be realized as the classical geometric signature of the extended path. This framework not only provides an efficient computational scheme for branched signatures but also opens new avenues for data-driven modeling and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00018v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Munawar Ali, Qi Feng</dc:creator>
    </item>
    <item>
      <title>Deep reinforcement learning for optimal trading with partial information</title>
      <link>https://arxiv.org/abs/2511.00190</link>
      <description>arXiv:2511.00190v1 Announce Type: cross 
Abstract: Reinforcement Learning (RL) applied to financial problems has been the subject of a lively area of research. The use of RL for optimal trading strategies that exploit latent information in the market is, to the best of our knowledge, not widely tackled. In this paper we study an optimal trading problem, where a trading signal follows an Ornstein-Uhlenbeck process with regime-switching dynamics. We employ a blend of RL and Recurrent Neural Networks (RNN) in order to make the most at extracting underlying information from the trading signal with latent parameters.
  The latent parameters driving mean reversion, speed, and volatility are filtered from observations of the signal, and trading strategies are derived via RL. To address this problem, we propose three Deep Deterministic Policy Gradient (DDPG)-based algorithms that integrate Gated Recurrent Unit (GRU) networks to capture temporal dependencies in the signal. The first, a one -step approach (hid-DDPG), directly encodes hidden states from the GRU into the RL trader. The second and third are two-step methods: one (prob-DDPG) makes use of posterior regime probability estimates, while the other (reg-DDPG) relies on forecasts of the next signal value. Through extensive simulations with increasingly complex Markovian regime dynamics for the trading signal's parameters, as well as an empirical application to equity pair trading, we find that prob-DDPG achieves superior cumulative rewards and exhibits more interpretable strategies. By contrast, reg-DDPG provides limited benefits, while hid-DDPG offers intermediate performance with less interpretable strategies. Our results show that the quality and structure of the information supplied to the agent are crucial: embedding probabilistic insights into latent regimes substantially improves both profitability and robustness of reinforcement learning-based trading strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00190v1</guid>
      <category>q-fin.TR</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Macr\`i, Sebastian Jaimungal, Fabrizio Lillo</dc:creator>
    </item>
    <item>
      <title>One model to solve them all: 2BSDE families via neural operators</title>
      <link>https://arxiv.org/abs/2511.01125</link>
      <description>arXiv:2511.01125v1 Announce Type: cross 
Abstract: We introduce a mild generative variant of the classical neural operator model, which leverages Kolmogorov--Arnold networks to solve infinite families of second-order backward stochastic differential equations ($2$BSDEs) on regular bounded Euclidean domains with random terminal time. Our first main result shows that the solution operator associated with a broad range of $2$BSDE families is approximable by appropriate neural operator models. We then identify a structured subclass of (infinite) families of $2$BSDEs whose neural operator approximation requires only a polynomial number of parameters in the reciprocal approximation rate, as opposed to the exponential requirement in general worst-case neural operator guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01125v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Furuya, Anastasis Kratsios, Dylan Possama\"i, Bogdan Raoni\'c</dc:creator>
    </item>
    <item>
      <title>Numerical methods for solving PIDEs arising in swing option pricing under a two-factor mean-reverting model with jumps</title>
      <link>https://arxiv.org/abs/2511.01587</link>
      <description>arXiv:2511.01587v1 Announce Type: cross 
Abstract: This paper concerns the numerical valuation of swing options with discrete action times under a linear two-factor mean-reverting model with jumps. The resulting sequence of two-dimensional partial integro-differential equations (PIDEs) are convection-dominated and possess a nonlocal integral term due to the presence of jumps. Further, the initial function is nonsmooth. We propose various second-order numerical methods that can adequately handle these challenging features. The stability and convergence of these numerical methods are analysed theoretically. By ample numerical experiments, we confirm their second-order convergence behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01587v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustapha Regragui, Karel J. in 't Hout, Mich\`ele Vanmaele, Fred Espen Benth</dc:creator>
    </item>
    <item>
      <title>Uncovering Representation Bias for Investment Decisions in Open-Source Large Language Models</title>
      <link>https://arxiv.org/abs/2510.05702</link>
      <description>arXiv:2510.05702v2 Announce Type: replace 
Abstract: Large Language Models are increasingly adopted in financial applications to support investment workflows. However, prior studies have seldom examined how these models reflect biases related to firm size, sector, or financial characteristics, which can significantly impact decision-making. This paper addresses this gap by focusing on representation bias in open-source Qwen models. We propose a balanced round-robin prompting method over approximately 150 U.S. equities, applying constrained decoding and token-logit aggregation to derive firm-level confidence scores across financial contexts. Using statistical tests and variance analysis, we find that firm size and valuation consistently increase model confidence, while risk factors tend to decrease it. Confidence varies significantly across sectors, with the Technology sector showing the greatest variability. When models are prompted for specific financial categories, their confidence rankings best align with fundamental data, moderately with technical signals, and least with growth indicators. These results highlight representation bias in Qwen models and motivate sector-aware calibration and category-conditioned evaluation protocols for safe and fair financial LLM deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05702v2</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fabrizio Dimino, Krati Saxena, Bhaskarjit Sarmah, Stefano Pasquali</dc:creator>
    </item>
    <item>
      <title>Exploring the Synergy of Quantitative Factors and Newsflow Representations from Large Language Models for Stock Return Prediction</title>
      <link>https://arxiv.org/abs/2510.15691</link>
      <description>arXiv:2510.15691v2 Announce Type: replace 
Abstract: In quantitative investing, return prediction supports various tasks, including stock selection, portfolio optimization, and risk management. Quantitative factors, such as valuation, quality, and growth, capture various characteristics of stocks. Unstructured financial data, like news and transcripts, has attracted growing attention, driven by recent advances in large language models (LLMs). This paper examines effective methods for leveraging multimodal factors and newsflow in return prediction and stock selection. First, we introduce a fusion learning framework to learn a unified representation from factors and newsflow representations generated by an LLM. Within this framework, we compare three representative methods: representation combination, representation summation, and attentive representations. Next, building on empirical observations from fusion learning, we explore the mixture model that adaptively combines predictions made by single modalities and their fusion. To mitigate the training instability observed in the mixture model, we introduce a decoupled training approach with theoretical insights. Finally, our experiments on real investment universes yield several insights into effective multimodal modeling of factors and news for stock return prediction and selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15691v2</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian Guo, Emmanuel Hauptmann</dc:creator>
    </item>
    <item>
      <title>Words That Unite The World: A Unified Framework for Deciphering Central Bank Communications Globally</title>
      <link>https://arxiv.org/abs/2505.17048</link>
      <description>arXiv:2505.17048v2 Announce Type: replace-cross 
Abstract: Central banks around the world play a crucial role in maintaining economic stability. Deciphering policy implications in their communications is essential, especially as misinterpretations can disproportionately impact vulnerable populations. To address this, we introduce the World Central Banks (WCB) dataset, the most comprehensive monetary policy corpus to date, comprising over 380k sentences from 25 central banks across diverse geographic regions, spanning 28 years of historical data. After uniformly sampling 1k sentences per bank (25k total) across all available years, we annotate and review each sentence using dual annotators, disagreement resolutions, and secondary expert reviews. We define three tasks: Stance Detection, Temporal Classification, and Uncertainty Estimation, with each sentence annotated for all three. We benchmark seven Pretrained Language Models (PLMs) and nine Large Language Models (LLMs) (Zero-Shot, Few-Shot, and with annotation guide) on these tasks, running 15,075 benchmarking experiments. We find that a model trained on aggregated data across banks significantly surpasses a model trained on an individual bank's data, confirming the principle "the whole is greater than the sum of its parts." Additionally, rigorous human evaluations, error analyses, and predictive tasks validate our framework's economic utility. Our artifacts are accessible through the HuggingFace and GitHub under the CC-BY-NC-SA 4.0 license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17048v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>q-fin.CP</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Agam Shah, Siddhant Sukhani, Huzaifa Pardawala, Saketh Budideti, Riya Bhadani, Rudra Gopal, Siddhartha Somani, Rutwik Routu, Michael Galarnyk, Soungmin Lee, Arnav Hiray, Akshar Ravichandran, Eric Kim, Pranav Aluru, Joshua Zhang, Sebastian Jaskowski, Veer Guda, Meghaj Tarte, Liqin Ye, Spencer Gosden, Rachel Yuh, Sloka Chava, Sahasra Chava, Dylan Patrick Kelly, Aiden Chiang, Harsit Mittal, Sudheer Chava</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Regime-Conditioned Diffusion (MARCD) for CVaR-Constrained Portfolio Decisions</title>
      <link>https://arxiv.org/abs/2510.10807</link>
      <description>arXiv:2510.10807v3 Announce Type: replace-cross 
Abstract: We examine whether regime-conditioned generative scenarios combined with a convex CVaR allocator improve portfolio decisions under regime shifts. We present MARCD, a generative-to-decision framework with: (i) a Gaussian HMM to infer latent regimes; (ii) a diffusion generator that produces regime-conditioned scenarios; (iii) signal extraction via blended, shrunk moments; and (iv) a governed CVaR epigraph quadratic program. Contributions: Within the Scenario stage we introduce a tail-weighted diffusion objective that up-weights low-quantile outcomes relevant for drawdowns and a regime-expert (MoE) denoiser whose gate increases with crisis posteriors; both are evaluated end-to-end through the allocator. Under strict walk-forward on liquid multi-asset ETFs (2005-2025), MARCD exhibits stronger scenario calibration and materially smaller drawdowns: MaxDD 9.3% versus 14.1% for BL (a 34% reduction) over 2020-2025 out-of-sample. The framework provides an auditable pipeline with explicit budget, box, and turnover constraints, demonstrating the value of decision-aware generative modeling in finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10807v3</guid>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Atiah Alzahrani</dc:creator>
    </item>
  </channel>
</rss>
