<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SY</link>
    <description>eess.SY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Mar 2025 04:02:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Deadlock Avoidance for Decentralized Multi-agent Systems via CBF-inspired Risk Measurement</title>
      <link>https://arxiv.org/abs/2503.09621</link>
      <description>arXiv:2503.09621v1 Announce Type: new 
Abstract: Decentralized safe control plays an important role in multi-agent systems given the scalability and robustness without reliance on a central authority. However, without an explicit global coordinator, the decentralized control methods are often prone to deadlock -- a state where the system reaches equilibrium, causing the robots to stall. In this paper, we propose a generalized decentralized framework that unifies the Control Lyapunov Function (CLF) and Control Barrier Function (CBF) to facilitate efficient task execution and ensure deadlock-free trajectories for the multi-agent systems. As the agents approach the deadlock-related undesirable equilibrium, the framework can detect the equilibrium and drive agents away before that happens. This is achieved by a secondary deadlock resolution design with an auxiliary CBF to prevent the multi-agent systems from converging to the undesirable equilibrium. To avoid dominating effects due to the deadlock resolution over the original task-related controllers, a deadlock indicator function using CBF-inspired risk measurement is proposed and encoded in the unified framework for the agents to adaptively determine when to activate the deadlock resolution. This allows the agents to follow their original control tasks and seamlessly unlock or deactivate deadlock resolution as necessary, effectively improving task efficiency. We demonstrate the effectiveness of the proposed method through theoretical analysis, numerical simulations, and real-world experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09621v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanze Zhang, Yiwei Lyu, Siwon Jo, Yupeng Yang, Wenhao Luo</dc:creator>
    </item>
    <item>
      <title>Dynamics-Invariant Quadrotor Control using Scale-Aware Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.09622</link>
      <description>arXiv:2503.09622v1 Announce Type: new 
Abstract: Due to dynamic variations such as changing payload, aerodynamic disturbances, and varying platforms, a robust solution for quadrotor trajectory tracking remains challenging. To address these challenges, we present a deep reinforcement learning (DRL) framework that achieves physical dynamics invariance by directly optimizing force/torque inputs, eliminating the need for traditional intermediate control layers. Our architecture integrates a temporal trajectory encoder, which processes finite-horizon reference positions/velocities, with a latent dynamics encoder trained on historical state-action pairs to model platform-specific characteristics. Additionally, we introduce scale-aware dynamics randomization parameterized by the quadrotor's arm length, enabling our approach to maintain stability across drones spanning from 30g to 2.1kg and outperform other DRL baselines by 85% in tracking accuracy. Extensive real-world validation of our approach on the Crazyflie 2.1 quadrotor, encompassing over 200 flights, demonstrates robust adaptation to wind, ground effects, and swinging payloads while achieving less than 0.05m RMSE at speeds up to 2.0 m/s. This work introduces a universal quadrotor control paradigm that compensates for dynamic discrepancies across varied conditions and scales, paving the way for more resilient aerial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09622v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Varad Vaidya, Jishnu Keshavan</dc:creator>
    </item>
    <item>
      <title>APECS: Adaptive Personalized Control System Architecture</title>
      <link>https://arxiv.org/abs/2503.09624</link>
      <description>arXiv:2503.09624v1 Announce Type: new 
Abstract: This paper presents the Adaptive Personalized Control System (APECS) architecture, a novel framework for human-in-the-loop control. An architecture is developed which defines appropriate constraints for the system objectives. A method for enacting Lipschitz and sector bounds on the resulting controller is derived to ensure desirable control properties. An analysis of worst-case loss functions and the optimal loss function weighting is made to implement an effective training scheme. Finally, simulations are carried out to demonstrate the effectiveness of the proposed architecture. This architecture resulted in a 4.5% performance increase compared to the human operator and 9% to an unconstrained feedforward neural network trained in the same way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09624v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius F. R. Juston, Alex Gisi, William R. Norris, Dustin Nottage, Ahmet Soylemezoglu</dc:creator>
    </item>
    <item>
      <title>Optimizing AUV speed dynamics with a data-driven Koopman operator approach</title>
      <link>https://arxiv.org/abs/2503.09628</link>
      <description>arXiv:2503.09628v1 Announce Type: new 
Abstract: Autonomous Underwater Vehicles (AUVs) play an essential role in modern ocean exploration, and their speed control systems are fundamental
  to their efficient operation. Like many other robotic systems, AUVs exhibit multivariable nonlinear dynamics and face various constraints,
  including state limitations, input constraints, and constraints on the increment input, making controller design challenging
  and requiring significant effort and time. This paper addresses these challenges by employing a data-driven Koopman operator theory combined
  with Model Predictive Control (MPC), which takes into account the aforementioned constraints. The proposed approach not only ensures
  the performance of the AUV under state and input limitations but also considers the variation in incremental input to prevent
  rapid and potentially damaging changes to the vehicle's operation. Additionally, we develop a platform based on ROS2 and Gazebo
  to validate the effectiveness of the proposed algorithms, providing new control strategies for underwater vehicles against the complex and dynamic nature of underwater environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09628v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiliang Liu, Xin Zhao, Peng Cai, Bing Cong</dc:creator>
    </item>
    <item>
      <title>Data-Driven Distributionally Robust Control for Interacting Agents under Logical Constraints</title>
      <link>https://arxiv.org/abs/2503.09816</link>
      <description>arXiv:2503.09816v1 Announce Type: new 
Abstract: In this paper, we propose a distributionally robust control synthesis for an agent with stochastic dynamics that interacts with other agents under uncertainties and constraints expressed by signal temporal logic (STL). We formulate the control synthesis as a chance-constrained program (CCP) with STL specifications that must be satisfied with high probability under all uncertainty tubes induced by the other agents. To tackle the CCP, we propose two methods based on concentration of measure (CoM) theory and conditional value at risk (CVaR) and compare the required assumptions and resulting optimizations. These approaches convert the CCP into an expectation-constrained program (ECP), which is simpler to solve than the original CCP. To estimate the expectation using a finite set of observed data, we adopt a distributionally robust optimization (DRO) approach. The underlying DRO can be approximated as a robust data-driven optimization that provides a probabilistic under-approximation to the original ECP, where the probability depends on the number of samples. Therefore, under feasibility, the original STL constraints are satisfied with two layers of designed confidence: the confidence of the chance constraint and the confidence of the approximated data-driven optimization, which depends on the number of samples. We then provide details on solving the resulting robust data-driven optimization numerically. Finally, we compare the two proposed approaches through case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09816v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Bahari Kordabad, Eleftherios E. Vlahakis, Lars Lindemann, Sebastien Gros, Dimos V. Dimarogonas, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>Identification and Classification of Human Performance related Challenges during Remote Driving</title>
      <link>https://arxiv.org/abs/2503.09865</link>
      <description>arXiv:2503.09865v1 Announce Type: new 
Abstract: Remote driving of vehicles is gaining in importance in the transportation sector, especially when Automated Driving Systems (ADSs) reach the limits of their system boundaries. This study investigates the challenges faced by human Remote Drivers (RDs) during remote driving, particularly focusing on the identification and classification of human performance-related challenges through a comprehensive analysis of real-world remote driving data Las Vegas. For this purpose, a total of 183 RD performance-related Safety Driver (SD) interventions were analyzed and classified using an introduced severity classification. As it is essential to prevent the need for SD interventions, this study identified and analyzed harsh driving events to detect an increased likelihood of interventions by the SD. In addition, the results of the subjective RD questionnaire are used to evaluate whether the objective metrics from SD interventions and harsh driving events can also be confirmed by the RDs and whether additional challenges can be uncovered. The analysis reveals learning curves, showing a significant decrease in SD interventions as RD experience increases. Early phases of remote driving experience, especially below 200 km of experience, showed the highest frequency of safety-related events, including braking too late for traffic signs and responding impatiently to other traffic participants. Over time, RDs follow defined rules for improving their control, with experience leading to less harsh braking, acceleration, and steering maneuvers. The study contributes to understanding the requirements of RDS, emphasizing the importance of targeted training to address human performance limitations. It further highlights the need for system improvements to address challenges like latency and the limited haptic feedback replaced by visual feedback, which affect the RDs' perception and vehicle control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09865v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ole Hans, J\"urgen Adamy</dc:creator>
    </item>
    <item>
      <title>A Heterogeneous Multiscale Method for Efficient Simulation of Power Systems with Inverter-Based Resources</title>
      <link>https://arxiv.org/abs/2503.09892</link>
      <description>arXiv:2503.09892v1 Announce Type: new 
Abstract: As inverter-based resources (IBRs) penetrate power systems, the dynamics become more complex, exhibiting multiple timescales, including electromagnetic transient (EMT) dynamics of power electronic controllers and electromechanical dynamics of synchronous generators. Consequently, the power system model becomes highly stiff, posing a challenge for efficient simulation using existing methods that focus on dynamics within a single timescale. This paper proposes a Heterogeneous Multiscale Method for highly efficient multi-timescale simulation of a power system represented by its EMT model. The new method alternates between the microscopic EMT model of the system and an automatically reduced macroscopic model, varying the step size accordingly to achieve significant acceleration while maintaining accuracy in both fast and slow dynamics of interests. It also incorporates a semi-analytical solution method to enable a more adaptive variable-step mechanism. The new simulation method is illustrated using a two-area system and is then tested on a detailed EMT model of the IEEE 39-bus system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09892v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPWRS.2025.3539567</arxiv:DOI>
      <dc:creator>Kaiyang Huang, Min Xiong, Yang Liu, Kai Sun</dc:creator>
    </item>
    <item>
      <title>PI-Controlled Variable Time-Step Power System Simulation Using an Adaptive Order Differential Transformation Method</title>
      <link>https://arxiv.org/abs/2503.09898</link>
      <description>arXiv:2503.09898v1 Announce Type: new 
Abstract: Dynamic simulation plays a crucial role in power system transient stability analysis, but traditional numerical integration-based methods are time-consuming due to the small time step sizes. Other semi-analytical solution methods, such as the Differential Transformation method, often struggle to select proper orders and steps, leading to slow performance and numerical instability. To address these challenges, this paper proposes a novel adaptive dynamic simulation approach for power system transient
  stability analysis. The approach adds feedback control and optimization to selecting the step and order, utilizing the Differential Transformation method and a proportional-integral control strategy to control truncation errors. Order selection is formulated as an optimization problem resulting in a variable-step-optimal-order method that achieves significantly larger time step sizes without violating numerical stability. It is applied to three systems: the IEEE 9-bus, 3-generator system, IEEE 39-bus, 10-generator system, and a Polish 2383-bus, 327-generator system, promising computational efficiency and numerical robustness for large-scale power system is demonstrated in comprehensive case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09898v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPWRS.2024.3361442</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Power Systems, vol. 39, No. 5, September 2024</arxiv:journal_reference>
      <dc:creator>Kaiyang Huang, Yang Liu, Kai Sun, Feng Qiu</dc:creator>
    </item>
    <item>
      <title>Analysis and Mitigation of Cascading Failures Using a Stochastic Interaction Graph with Eigen-analysis</title>
      <link>https://arxiv.org/abs/2503.09904</link>
      <description>arXiv:2503.09904v1 Announce Type: new 
Abstract: In studies on complex network systems using graph theory, eigen-analysis is typically performed on an undirected graph model of the network. However, when analyzing cascading failures in a power system, the interactions among failures suggest the need for a directed graph beyond the topology of the power system to model directions of failure propagation. To accurately quantify failure interactions for effective mitigation strategies, this paper proposes a stochastic interaction graph model and associated eigen-analysis. Different types of modes on failure propagations are defined and characterized by the eigenvalues of a stochastic interaction matrix, whose absolute values are unity, zero, or in between. Finding and interpreting these modes helps identify the probable patterns of failure propagation, either local or widespread, and the participating components based on eigenvectors. Then, by lowering the failure probabilities of critical components highly participating in a mode of widespread failures, cascading can be mitigated. The validity of the proposed stochastic interaction graph model, eigen-analysis and the resulting mitigation strategies is demonstrated using simulated cascading failure data on an NPCC 140-bus system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09904v1</guid>
      <category>eess.SY</category>
      <category>cs.DM</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <category>math.SP</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPWRS.2024.3421957</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Power Systems, vol. 40, No. 2, March 2025</arxiv:journal_reference>
      <dc:creator>Zhenping Guo, Xiaowen Su, Kai Sun, Byungkwon Park, Srdjan Simunovic</dc:creator>
    </item>
    <item>
      <title>Human Physical Interaction based on UAV Cooperative Payload Transportation System using Adaptive Backstepping and FNTSMC</title>
      <link>https://arxiv.org/abs/2503.09930</link>
      <description>arXiv:2503.09930v1 Announce Type: new 
Abstract: This paper presents a nonlinear control strategy for an aerial cooperative payload transportation system consisting of two quadrotor UAVs rigidly connected to a payload. The system includes human physical interaction facilitated by an admittance control. The proposed control framework integrates an adaptive Backstepping controller for the position subsystem and a Fast Nonsingular Terminal Sliding Mode Control (FNTSMC) for the attitude subsystem to ensure asymptotic stabilization. The admittance controller interprets the interaction forces from the human operator, generating reference trajectories for the position controller to ensure accurate tracking of the operator's guidance. The system aims to assist humans in payload transportation, providing both stability and responsiveness. The robustness and effectiveness of the proposed control scheme in maintaining system stability and performance under various conditions are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09930v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussein N. Naser, Hashim A. Hashim, Mojtaba Ahmadi</dc:creator>
    </item>
    <item>
      <title>Growing Into an Adaptive and Reconfigurable Paradigm for Spectrum Sharing</title>
      <link>https://arxiv.org/abs/2503.09936</link>
      <description>arXiv:2503.09936v1 Announce Type: new 
Abstract: A significant movement from rigid use of the wireless spectrum toward adaptive and reconfigurable spectrum use has been prompted by increasing spectral crowding. Some bands have moved to an adaptive sharing model, and proposals are growing for this approach to be applied to additional bands. The process of moving from a fixed, rigid spectrum paradigm to adaptive and reconfigurable use involves maturation of policy and technology at multiple levels within the system of systems. Using the concept of Bloom's Taxonomy from the education discipline, this paper examines the development of a policy and technology progression toward a mature, adaptive and reconfigurable paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09936v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Baylis, Douglas Sicker, Austin Egbert, Andrew Clegg, Tom Brooks, Casey Latham, Robert J. Marks II</dc:creator>
    </item>
    <item>
      <title>Combining Cooperative Re-Routing with Intersection Coordination for Connected and Automated Vehicles in Urban Networks</title>
      <link>https://arxiv.org/abs/2503.10004</link>
      <description>arXiv:2503.10004v1 Announce Type: new 
Abstract: In this paper, we present a hierarchical framework that integrates upper-level routing with low-level optimal trajectory planning for connected and automated vehicles (CAVs) traveling in an urban network. The upper-level controller efficiently distributes traffic flows by utilizing a dynamic re-routing algorithm that leverages real-time density information and the fundamental diagrams of each network edge. This re-routing approach predicts when each edge will reach critical density and proactively adjusts the routing algorithm's weights to prevent congestion before it occurs. The low-level controller coordinates CAVs as they cross signal-free intersections, generating optimal, fuel-efficient trajectories while ensuring safe passage by satisfying all relevant constraints. We formulate the problem as an optimal control problem and derive an analytical solution. Using the SUMO micro-simulation platform, we conduct simulation experiments on a realistic network. The results show that our hierarchical framework significantly enhances network performance compared to a baseline static routing approach. By dynamically re-routing vehicles, our approach successfully reduces total travel time and mitigates congestion before it develops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10004v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panagiotis Typaldos, Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>One-bit consensus of controllable linear multi-agent systems with communication noises</title>
      <link>https://arxiv.org/abs/2503.10062</link>
      <description>arXiv:2503.10062v1 Announce Type: new 
Abstract: This paper addresses the one-bit consensus of controllable linear multi-agent systems (MASs) with communication noises. A consensus algorithm consisting of a communication protocol and a consensus controller is designed. The communication protocol introduces a linear compression encoding function to achieve a one-bit data rate, thereby saving communication costs. The consensus controller with a stabilization term and a consensus term is proposed to ensure the consensus of a potentially unstable but controllable MAS. Specifically, in the consensus term, we adopt an estimation method to overcome the information loss caused by one-bit communications and a decay step to attenuate the effect of communication noise. Two combined Lyapunov functions are constructed to overcome the difficulty arising from the coupling of the control and estimation. By establishing similar iterative structures of these two functions, this paper shows that the MAS can achieve consensus in the mean square sense at the rate of the reciprocal of the iteration number under the case with a connected fixed topology. Moreover, the theoretical results are generalized to the case with jointly connected Markovian switching topologies by establishing a certain equivalence relationship between the Markovian switching topologies and a fixed topology. Two simulation examples are given to validate the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10062v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ru An, Ying Wang, Yanlong Zhao, Ji-Feng Zhang</dc:creator>
    </item>
    <item>
      <title>Neural network-based identification of state-space switching nonlinear systems</title>
      <link>https://arxiv.org/abs/2503.10114</link>
      <description>arXiv:2503.10114v1 Announce Type: new 
Abstract: We design specific neural networks (NNs) for the identification of switching nonlinear systems in the state-space form, which explicitly model the switching behavior and address the inherent coupling between system parameters and switching modes. This coupling is specifically addressed by leveraging the expectation-maximization (EM) framework. In particular, our technique will combine a moving window approach in the E-step to efficiently estimate the switching sequence, together with an extended Kalman filter (EKF) in the M-step to train the NNs with a quadratic convergence rate. Extensive numerical simulations, involving both academic examples and a battery charge management system case study, illustrate that our technique outperforms available ones in terms of parameter estimation accuracy, model fitting, and switching sequence identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10114v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanxin Zhang, Chengpu Yu, Filippo Fabiani</dc:creator>
    </item>
    <item>
      <title>Global synchronization of multi-agent systems with nonlinear interactions</title>
      <link>https://arxiv.org/abs/2503.10205</link>
      <description>arXiv:2503.10205v1 Announce Type: new 
Abstract: The paper addresses the synchronization of multi-agent systems with continuous-time dynamics interacting through a very general class of monotonic continuous signal functions that covers estimation biases, approximation of discrete quantization, or state-dependent estimation. Our analysis reveals that, in the setup under consideration, synchronization equilibria are exactly the fixed points of the signal function. We also derive intuitive stability conditions based on whether the signal underestimates or overestimates the state of the agents around these fixed points. Moreover, we show that network topology plays a crucial role in asymptotic synchronization. These results provide interesting insights into the interplay between communication nonlinearity and network connectivity, paving the way for advanced coordination strategies in complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10205v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anthony Couthures, Vineeth S. Varma, Samson Lasaulce, Irinel-Constantin Morarescu</dc:creator>
    </item>
    <item>
      <title>Reach-Avoid-Stay-Collision-Avoidance Negotiation Framework for Multi-Agent Systems via Spatiotemporal Tubes</title>
      <link>https://arxiv.org/abs/2503.10245</link>
      <description>arXiv:2503.10245v1 Announce Type: new 
Abstract: This study presents a multi-agent negotiation-based framework to obtain collision-free paths while performing prescribed-time reach-avoid-stay (RAS) tasks for agents with unknown dynamics and bounded disturbance. By employing spatiotemporal tubes to generate time-varying state constraints, we ensure that all agents adhere to RAS specifications using synthesized controllers. To prevent inter-agent collisions, a negotiation mechanism is proposed where successful negotiations result in spatiotemporal tubes for each agent fulfilling desired tasks. This approach results in a completely distributed, approximation-free control law for each agent. The effectiveness of this mechanism was validated through simulations of multi-agent robot navigation and drone navigation tasks involving prescribed-time RAS specifications and collision avoidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10245v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohd. Faizuddin Faruqui, Ratnangshu Das, Ravi Kumar L, Pushpak Jagtap</dc:creator>
    </item>
    <item>
      <title>Some remarks on robustness of sample-and-hold stabilization</title>
      <link>https://arxiv.org/abs/2503.10328</link>
      <description>arXiv:2503.10328v1 Announce Type: new 
Abstract: This work studies robustness to system disturbance and measurement noise of some popular general practical stabilization techniques, namely, Dini aiming, optimization-based stabilization and inf-convolution stabilization. Common to all these techniques is the explicit usage of a (general nonsmooth) control Lyapunov function, thus allowing to see them as a kind of generalization to the celebrated Sontag's formula. It turns out that certain details of the above described robustness properties have not yet received the attention in literature they deserved. We provide new remarks, formalized in mathematical propositions, on robustness of selected popular stabilization techniques along with an extensive statistical case study on a robot parking problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10328v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3546990</arxiv:DOI>
      <dc:creator>Patrick Schmidt, Pavel Osinenko, Stefan Streif</dc:creator>
    </item>
    <item>
      <title>A nonlinear real time capable motion cueing algorithm based on deep reinforcement learning</title>
      <link>https://arxiv.org/abs/2503.10419</link>
      <description>arXiv:2503.10419v1 Announce Type: new 
Abstract: In motion simulation, motion cueing algorithms are used for the trajectory planning of the motion simulator platform, where workspace limitations prevent direct reproduction of reference trajectories. Strategies such as motion washout, which return the platform to its center, are crucial in these settings. For serial robotic MSPs with highly nonlinear workspaces, it is essential to maximize the efficient utilization of the MSPs kinematic and dynamic capabilities. Traditional approaches, including classical washout filtering and linear model predictive control, fail to consider platform-specific, nonlinear properties, while nonlinear model predictive control, though comprehensive, imposes high computational demands that hinder real-time, pilot-in-the-loop application without further simplification. To overcome these limitations, we introduce a novel approach using deep reinforcement learning for motion cueing, demonstrated here for the first time in a 6-degree-of-freedom setting with full consideration of the MSPs kinematic nonlinearities. Previous work by the authors successfully demonstrated the application of DRL to a simplified 2-DOF setup, which did not consider kinematic or dynamic constraints. This approach has been extended to all 6 DOF by incorporating a complete kinematic model of the MSP into the algorithm, a crucial step for enabling its application on a real motion simulator. The training of the DRL-MCA is based on Proximal Policy Optimization in an actor-critic implementation combined with an automated hyperparameter optimization. After detailing the necessary training framework and the algorithm itself, we provide a comprehensive validation, demonstrating that the DRL MCA achieves competitive performance against established algorithms. Moreover, it generates feasible trajectories by respecting all system constraints and meets all real-time requirements with low...</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10419v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Scheidel, Camilo Gonzalez, Houshyar Asadi, Tobias Bellmann, Andreas Seefried, Shady Mohamed, Saeid Nahavandi</dc:creator>
    </item>
    <item>
      <title>Optimal Estimation for Continuous-Time Nonlinear Systems Using State-Dependent Riccati Equation (SDRE)</title>
      <link>https://arxiv.org/abs/2503.10442</link>
      <description>arXiv:2503.10442v1 Announce Type: new 
Abstract: This paper introduces a unified approach for state estimation and control of nonlinear dynamic systems, employing the State-Dependent Riccati Equation (SDRE) framework. The proposed approach naturally extends classical linear quadratic Gaussian (LQG) methods into nonlinear scenarios, avoiding linearization by using state-dependent coefficient (SDC) matrices. An SDRE-based Kalman filter (SDRE-KF) is integrated within an SDRE-based control structure, providing a coherent and intuitive strategy for nonlinear system analysis and control design. To evaluate the effectiveness and robustness of the proposed methodology, comparative simulations are conducted on two benchmark nonlinear systems: a simple pendulum and a Van der Pol oscillator. Results demonstrate that the SDRE-KF achieves comparable or superior estimation accuracy compared to traditional methods, including the Extended Kalman Filter (EKF) and Particle Filter (PF). These findings underline the potential of the unified SDRE-based approach as a viable alternative for nonlinear state estimation and control, providing valuable insights for both educational purposes and practical engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10442v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adnan Tahirovic, Azra Redzovic</dc:creator>
    </item>
    <item>
      <title>Safety Filter for Limiting the Current of Grid-Forming Matrix Modular Multilevel Converters</title>
      <link>https://arxiv.org/abs/2503.10498</link>
      <description>arXiv:2503.10498v1 Announce Type: new 
Abstract: Grid-forming (GFM) converters face significant challenges in limiting current during transient grid events while preserving their grid-forming behavior. This paper offers an elegant solution to the problem with a priori guarantees, presenting a safety filter approach based on Control Barrier Functions (CBFs) to enforce current constraints with minimal deviation from the nominal voltage reference. The safety filter is implemented as a Quadratic Program, enabling real-time computation of safe voltage adjustments that ensure smooth transitions and maintain the GFM behavior during nominal operation. To provide formal safety certificate, the CBF is synthesized offline using a Sum-of-Squares optimization framework, ensuring that the converter remains within its allowable operating limits under all conditions. Additionally, a Control Lyapunov Function is incorporated to facilitate a smooth return to the nominal operating region following grid events. The proposed method is modular and can be integrated into many of the GFM control architectures, as demonstrated with two different GFM implementations. High-fidelity simulations conducted with an enhanced matrix modular multilevel converter connected to both high-inertia and low-inertia grid scenarios validate the effectiveness of the safety filter, showing that it successfully limits current during faults, preserves GFM behavior, and ensures a seamless recovery to nominal operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10498v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Schneeberger, Silvia Mastellone, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Low-Rank Matrix Regression via Least-Angle Regression</title>
      <link>https://arxiv.org/abs/2503.10569</link>
      <description>arXiv:2503.10569v1 Announce Type: new 
Abstract: Low-rank matrix regression is a fundamental problem in data science with various applications in systems and control. Nuclear norm regularization has been widely applied to solve this problem due to its convexity. However, it suffers from high computational complexity and the inability to directly specify the rank. This work introduces a novel framework for low-rank matrix regression that addresses both unstructured and Hankel matrices. By decomposing the low-rank matrix into rank-1 bases, the problem is reformulated as an infinite-dimensional sparse learning problem. The least-angle regression (LAR) algorithm is then employed to solve this problem efficiently. For unstructured matrices, a closed-form LAR solution is derived with equivalence to a normalized nuclear norm regularization problem. For Hankel matrices, a real-valued polynomial basis reformulation enables effective LAR implementation. Two numerical examples in network modeling and system realization demonstrate that the proposed approach significantly outperforms the nuclear norm method in terms of estimation accuracy and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10569v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingzhou Yin, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Analysis of a continuous opinion and discrete action dynamics model coupled with an external observation dynamics</title>
      <link>https://arxiv.org/abs/2403.09473</link>
      <description>arXiv:2403.09473v2 Announce Type: cross 
Abstract: We consider a set of consumers in a city or town (who thus generate pollution) whose opinion is governed by a continuous opinion and discrete action (CODA) dynamics model. This dynamics is coupled with an observation signal dynamics, which defines the information the consumers have access to regarding the common pollution. We show that the external observation signal has a significant impact on the asymptotic behavior of the CODA model. When the coupling is strong, it induces either a chaotic behavior or convergence towards a limit cycle. When the coupling is weak, a more classical behavior characterized by local agreements in polarized clusters is observed. In both cases, conditions under which clusters of consumers don't change their actions are provided.Numerical examples are provided to illustrate the derived analytical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09473v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Couthures, Thomas Mongaillard, Vineeth S. Varma, Samson Lasaulce, Irinel-Constantin Morarescu</dc:creator>
    </item>
    <item>
      <title>Blockchain-Enabled Management Framework for Federated Coalition Networks</title>
      <link>https://arxiv.org/abs/2503.09666</link>
      <description>arXiv:2503.09666v1 Announce Type: cross 
Abstract: In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09666v1</guid>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jorge \'Alvaro Gonz\'alez, Ana Mar\'ia Saiz Garc\'ia, Victor Monzon Baeza</dc:creator>
    </item>
    <item>
      <title>The Pitfalls of Imitation Learning when Actions are Continuous</title>
      <link>https://arxiv.org/abs/2503.09722</link>
      <description>arXiv:2503.09722v1 Announce Type: cross 
Abstract: We study the problem of imitating an expert demonstrator in a discrete-time, continuous state-and-action control system. We show that, even if the dynamics are stable (i.e. contracting exponentially quickly), and the expert is smooth and deterministic, any smooth, deterministic imitator policy necessarily suffers error on execution that is exponentially larger, as a function of problem horizon, than the error under the distribution of expert training data. Our negative result applies to both behavior cloning and offline-RL algorithms, unless they produce highly "improper" imitator policies--those which are non-smooth, non-Markovian, or which exhibit highly state-dependent stochasticity--or unless the expert trajectory distribution is sufficiently "spread." We provide experimental evidence of the benefits of these more complex policy parameterizations, explicating the benefits of today's popular policy parameterizations in robot learning (e.g. action-chunking and Diffusion Policies). We also establish a host of complementary negative and positive results for imitation in control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09722v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Simchowitz, Daniel Pfrommer, Ali Jadbabaie</dc:creator>
    </item>
    <item>
      <title>Real-Time Risky Fault-Chain Search using Time-Varying Graph RNNs</title>
      <link>https://arxiv.org/abs/2503.09775</link>
      <description>arXiv:2503.09775v1 Announce Type: cross 
Abstract: This paper introduces a data-driven graphical framework for the real-time search of risky cascading fault chains (FCs) in power-grids, crucial for enhancing grid resiliency in the face of climate change. As extreme weather events driven by climate change increase, identifying risky FCs becomes crucial for mitigating cascading failures and ensuring grid stability. However, the complexity of the spatio-temporal dependencies among grid components and the exponential growth of the search space with system size pose significant challenges to modeling and risky FC search. To tackle this, we model the search process as a partially observable Markov decision process (POMDP), which is subsequently solved via a time-varying graph recurrent neural network (GRNN). This approach captures the spatial and temporal structure induced by the system's topology and dynamics, while efficiently summarizing the system's history in the GRNN's latent space, enabling scalable and effective identification of risky FCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09775v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICLR 2025 Workshop paper at Tackling Climate Change with Machine Learning</arxiv:journal_reference>
      <dc:creator>Anmol Dwivedi, Ali Tajer</dc:creator>
    </item>
    <item>
      <title>Aerocapture Guidance for Augmented Bank Angle Modulation</title>
      <link>https://arxiv.org/abs/2503.09806</link>
      <description>arXiv:2503.09806v1 Announce Type: cross 
Abstract: This paper presents an optimal control solution for an aerocapture vehicle with two control inputs, bank angle and angle of attack, referred to as augmented bank angle modulation (ABAM). We derive the optimal control profiles using Pontryagin's Minimum Principle, validate the result numerically using the Gauss pseudospectral method (implemented in GPOPS), and introduce a novel guidance algorithm, ABAMGuid, for in-flight decision making. High-fidelity Monte Carlo simulations of a Uranus aerocapture mission demonstrate that ABAMGuid can greatly improve capture success rates and reduce the propellant needed for orbital correction following the atmospheric pass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09806v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Sonandres, Thomas Palazzo, Jonathan P. How</dc:creator>
    </item>
    <item>
      <title>SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey</title>
      <link>https://arxiv.org/abs/2503.09829</link>
      <description>arXiv:2503.09829v1 Announce Type: cross 
Abstract: Recent advances in deep learning and Transformers have driven major breakthroughs in robotics by employing techniques such as imitation learning, reinforcement learning, and LLM-based multimodal perception and decision-making. However, conventional deep learning and Transformer models often struggle to process data with inherent symmetries and invariances, typically relying on large datasets or extensive data augmentation. Equivariant neural networks overcome these limitations by explicitly integrating symmetry and invariance into their architectures, leading to improved efficiency and generalization. This tutorial survey reviews a wide range of equivariant deep learning and control methods for robotics, from classic to state-of-the-art, with a focus on SE(3)-equivariant models that leverage the natural 3D rotational and translational symmetries in visual robotic manipulation and control design. Using unified mathematical notation, we begin by reviewing key concepts from group theory, along with matrix Lie groups and Lie algebras. We then introduce foundational group-equivariant neural network design and show how the group-equivariance can be obtained through their structure. Next, we discuss the applications of SE(3)-equivariant neural networks in robotics in terms of imitation learning and reinforcement learning. The SE(3)-equivariant control design is also reviewed from the perspective of geometric control. Finally, we highlight the challenges and future directions of equivariant methods in developing more robust, sample-efficient, and multi-modal real-world robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09829v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joohwan Seo, Soochul Yoo, Junwoo Chang, Hyunseok An, Hyunwoo Ryu, Soomi Lee, Arvind Kruthiventy, Jongeun CHoi, Roberto Horowitz</dc:creator>
    </item>
    <item>
      <title>Passivity-Based Local Design Conditions for Global Optimality in Distributed Convex Optimization</title>
      <link>https://arxiv.org/abs/2503.09854</link>
      <description>arXiv:2503.09854v1 Announce Type: cross 
Abstract: In recent times, various distributed optimization algorithms have been proposed for whose specific agent dynamics global optimality and convergence is proven. However, there exist no general conditions for the design of such algorithms. In this paper, we leverage passivity theory to fi rst establish a distributed optimization framework with local design requirements for the agent dynamics in both unconstrained and constrained problems with undirected communication topologies. Under the roof of these requirements, the agents may use heterogeneous optimization algorithms without compromising global optimality and convergence. Subsequently, we propose some exemplary agent systems that comply with the established requirements. Compared to existing approaches, our algorithms do not require any global initialization nor communication of multiple variables. Consequently, the agents may leave or rejoin the networked optimization without compromising convergence to the correct global optimizer. Furthermore, we show that for unconstrained optimization, an extension to directed communication topologies is possible. Simulation results illustrate the plug-and-play capabilities and interoperability of the proposed agent dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09854v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Jane-Soneira, Charles Muller, Felix Strehle, S\"oren Hohmann</dc:creator>
    </item>
    <item>
      <title>CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2503.10296</link>
      <description>arXiv:2503.10296v1 Announce Type: cross 
Abstract: This paper discusses the integration challenges and strategies for designing mobile robots, by focusing on the task-driven, optimal selection of hardware and software to balance safety, efficiency, and minimal usage of resources such as costs, energy, computational requirements, and weight. We emphasize the interplay between perception and motion planning in decision-making by introducing the concept of occupancy queries to quantify the perception requirements for sampling-based motion planners. Sensor and algorithm performance are evaluated using False Negative Rates (FPR) and False Positive Rates (FPR) across various factors such as geometric relationships, object properties, sensor resolution, and environmental conditions. By integrating perception requirements with perception performance, an Integer Linear Programming (ILP) approach is proposed for efficient sensor and algorithm selection and placement. This forms the basis for a co-design optimization that includes the robot body, motion planner, perception pipeline, and computing unit. We refer to this framework for solving the co-design problem of mobile robots as CODEI, short for Co-design of Embodied Intelligence. A case study on developing an Autonomous Vehicle (AV) for urban scenarios provides actionable information for designers, and shows that complex tasks escalate resource demands, with task performance affecting choices of the autonomy stack. The study demonstrates that resource prioritization influences sensor choice: cameras are preferred for cost-effective and lightweight designs, while lidar sensors are chosen for better energy and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10296v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dejan Milojevic, Gioele Zardini, Miriam Elser, Andrea Censi, Emilio Frazzoli</dc:creator>
    </item>
    <item>
      <title>Safe exploration in reproducing kernel Hilbert spaces</title>
      <link>https://arxiv.org/abs/2503.10352</link>
      <description>arXiv:2503.10352v1 Announce Type: cross 
Abstract: Popular safe Bayesian optimization (BO) algorithms learn control policies for safety-critical systems in unknown environments. However, most algorithms make a smoothness assumption, which is encoded by a known bounded norm in a reproducing kernel Hilbert space (RKHS). The RKHS is a potentially infinite-dimensional space, and it remains unclear how to reliably obtain the RKHS norm of an unknown function. In this work, we propose a safe BO algorithm capable of estimating the RKHS norm from data. We provide statistical guarantees on the RKHS norm estimation, integrate the estimated RKHS norm into existing confidence intervals and show that we retain theoretical guarantees, and prove safety of the resulting safe BO algorithm. We apply our algorithm to safely optimize reinforcement learning policies on physics simulators and on a real inverted pendulum, demonstrating improved performance, safety, and scalability compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10352v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Tokmak, Kiran G. Krishnan, Thomas B. Sch\"on, Dominik Baumann</dc:creator>
    </item>
    <item>
      <title>Compliant Control of Quadruped Robots for Assistive Load Carrying</title>
      <link>https://arxiv.org/abs/2503.10401</link>
      <description>arXiv:2503.10401v1 Announce Type: cross 
Abstract: This paper presents a novel method for assistive load carrying using quadruped robots. The controller uses proprioceptive sensor data to estimate external base wrench, that is used for precise control of the robot's acceleration during payload transport. The acceleration is controlled using a combination of admittance control and Control Barrier Function (CBF) based quadratic program (QP). The proposed controller rejects disturbances and maintains consistent performance under varying load conditions. Additionally, the built-in CBF guarantees collision avoidance with the collaborative agent in front of the robot. The efficacy of the overall controller is shown by its implementation on the physical hardware as well as numerical simulations. The proposed control framework aims to enhance the quadruped robot's ability to perform assistive tasks in various scenarios, from industrial applications to search and rescue operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10401v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nimesh Khandelwal, Amritanshu Manu, Shakti S. Gupta, Mangal Kothari, Prashanth Krishnamurthy, Farshad Khorrami</dc:creator>
    </item>
    <item>
      <title>Stratified Topological Autonomy for Long-Range Coordination (STALC)</title>
      <link>https://arxiv.org/abs/2503.10475</link>
      <description>arXiv:2503.10475v1 Announce Type: cross 
Abstract: Achieving unified multi-robot coordination and motion planning in complex environments is a challenging problem. In this paper, we present a hierarchical approach to long-range coordination, which we call Stratified Topological Autonomy for Long-Range Coordination (STALC). In particular, we look at the problem of minimizing visibility to observers and maximizing safety with a multi-robot team navigating through a hazardous environment. At its core, our approach relies on the notion of a dynamic topological graph, where the edge weights vary dynamically based on the locations of the robots in the graph. To create this dynamic topological graph, we evaluate the visibility of the robot team from a discrete set of observer locations (both adversarial and friendly), and construct a topological graph whose edge weights depend on both adversary position and robot team configuration. We then impose temporal constraints on the evolution of those edge weights based on robot team state and use Mixed-Integer Programming (MIP) to generate optimal multirobot plans through the graph. The visibility information also informs the lower layers of the autonomy stack to plan minimal visibility paths through the environment for the team of robots. Our approach presents methods to reduce the computational complexity for a team of robots that interact and coordinate across the team to accomplish a common goal. We demonstrate our approach in simulated and hardware experiments in forested and urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10475v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cora A. Dimmig, Adam Goertz, Adam Polevoy, Mark Gonzales, Kevin C. Wolfe, Bradley Woosley, John Rogers, Joseph Moore</dc:creator>
    </item>
    <item>
      <title>Constrained Learning for Decentralized Multi-Objective Coverage Control</title>
      <link>https://arxiv.org/abs/2409.11311</link>
      <description>arXiv:2409.11311v2 Announce Type: replace 
Abstract: The multi-objective coverage control problem requires a robot swarm to collaboratively provide sensor coverage to multiple heterogeneous importance density fields IDFs simultaneously. We pose this as an optimization problem with constraints and study two different formulations: (1) Fair coverage, where we minimize the maximum coverage cost for any field, promoting equitable resource distribution among all fields; and (2) Constrained coverage, where each field must be covered below a certain cost threshold, ensuring that critical areas receive adequate coverage according to predefined importance levels. We study the decentralized setting where robots have limited communication and local sensing capabilities, making the system more realistic, scalable, and robust. Given the complexity, we propose a novel decentralized constrained learning approach that combines primal-dual optimization with a Learnable Perception-Action-Communication (LPAC) neural network architecture. We show that the Lagrangian of the dual problem can be reformulated as a linear combination of the IDFs, enabling the LPAC policy to serve as a primal solver. We empirically demonstrate that the proposed method (i) significantly outperforms state-of-the-art decentralized controllers by 30% on average in terms of coverage cost, (ii) transfers well to larger environments with more robots, and (iii) scalable in the number of IDFs and robots in the swarm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11311v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Cervino, Saurav Agarwal, Vijay Kumar, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>Optimal Distribution System Restoration via Tractable Modeling of Decision-Dependent Interruption Cost and Cold Load Pickup</title>
      <link>https://arxiv.org/abs/2411.12353</link>
      <description>arXiv:2411.12353v3 Announce Type: replace 
Abstract: Developing optimized restoration strategies for power distribution systems (PDSs) is critical to enhancing resilience. Prior knowledge of customer interruption cost (CIC) and load restoration behaviors, particularly cold load pickup (CLPU), is essential for effective decision-making. However, both CIC and CLPU are reciprocally influenced by the realized customer interruption duration (CID), making them decision-dependent and challenging to model, especially given the limited understanding of their underlying physical mechanisms. This paper proposes a novel and tractable modeling approach to capture the varying patterns of CIC and CLPU with CID - patterns derived from data that reflect observable surface - level correlations rather than underlying mechanisms - thereby enabling practical surrogate modeling of these decision-dependent factors. Specifically, quadratic functions are employed to model the increasing rate of CIC with respect to CID according to data fitting results. For CLPU, several defining characteristics are extracted and modeled in a piecewise linear form relative to CID, and the actual restored load accounting for CLPU is subsequently reconstructed. Building on these models, a PDS restoration optimization framework is developed, incorporating mobile energy storage systems (MESSs) and network reconfiguration strategies. Case studies validate the effectiveness of the proposed approach and highlight MESS's unique potential in accelerating CLPU-related restoration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12353v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Wang, Minwu Chen, Hongbin Wang, Gaoqiang Peng, Hongzhou Chen</dc:creator>
    </item>
    <item>
      <title>Quantitative Decentralized Stability Certificates for Grid-Forming Converter Control</title>
      <link>https://arxiv.org/abs/2503.05403</link>
      <description>arXiv:2503.05403v2 Announce Type: replace 
Abstract: We propose a decentralized framework for guaranteeing the small-signal stability of future power systems with grid-forming converters. Our approach leverages dynamic loop-shifting techniques to compensate for the lack of passivity in the network dynamics and establishes decentralized parametric stability certificates, depending on the local device-level controls and incorporating the effects of the network dynamics. By following practical tuning rules, we are able to ensure plug-and-play operation without centralized coordination. Unlike prior works, our approach accommodates coupled frequency and voltage dynamics, incorporates network dynamics, and does not rely on specific network configurations or operating points, offering a general and scalable solution for the integration of power-electronics-based devices into future power systems. We validate our theoretical stability results through numerical case studies in a high-fidelity simulation model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05403v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Verena H\"aberle, Xiuqiang He, Linbin Huang, Florian D\"orfler, Steven Low</dc:creator>
    </item>
    <item>
      <title>Game Theory in Formula 1: Multi-agent Physical and Strategical Interactions</title>
      <link>https://arxiv.org/abs/2503.05421</link>
      <description>arXiv:2503.05421v2 Announce Type: replace 
Abstract: This paper presents an optimization framework for Formula 1 racing that integrates multi-agent interactions, aerodynamic wake effects, trajectory optimization, and energy management. By employing game-theoretic methods, we formulate the minimum lap time problem as either a Nash or a Stackelberg game. Exploiting their structural similarities, we compare symmetric and hierarchical strategies to analyze competitive racing dynamics and strategic dominance. Additionally, we introduce an algorithm to refine local Stackelberg solutions. Our findings underscore the importance of jointly optimizing physical interactions, energy management, and trajectory, highlighting their strong interdependence. We examine the impact of slipstreaming on trajectory selection in corners, straights, and high-speed sections, while also identifying optimal overtaking locations based on energy allocation strategies. By incorporating a physically accurate interaction model and accounting for the optimal responses of competing agents, our approach reveals characteristic strategic behaviors observed in real-world racing. The proposed methodology contributes towards realistic Formula 1 race strategy optimizations, with potential applications in motorsport engineering and autonomous racing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05421v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giona Fieni, Marc-Philippe Neumann, Francesca Furia, Alessandro Caucino, Alberto Cerofolini, Vittorio Ravaglioli, Christopher H. Onder</dc:creator>
    </item>
    <item>
      <title>Faithful and Privacy-Preserving Implementation of Average Consensus</title>
      <link>https://arxiv.org/abs/2503.09381</link>
      <description>arXiv:2503.09381v2 Announce Type: replace 
Abstract: We propose a protocol based on mechanism design theory and encrypted control to solve average consensus problems among rational and strategic agents while preserving their privacy. The proposed protocol provides a mechanism that incentivizes the agents to faithfully implement the intended behavior specified in the protocol. Furthermore, the protocol runs over encrypted data using homomorphic encryption and secret sharing to protect the privacy of agents. We also analyze the security of the proposed protocol using a simulation paradigm in secure multi-party computation. The proposed protocol demonstrates that mechanism design and encrypted control can complement each other to achieve security under rational adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09381v2</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaoru Teranishi, Kiminao Kogiso, Takashi Tanaka</dc:creator>
    </item>
    <item>
      <title>Feasible Policy Iteration for Safe Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2304.08845</link>
      <description>arXiv:2304.08845v3 Announce Type: replace-cross 
Abstract: Safety is the priority concern when applying reinforcement learning (RL) algorithms to real-world control problems. While policy iteration provides a fundamental algorithm for standard RL, an analogous theoretical algorithm for safe RL remains absent. In this paper, we propose feasible policy iteration (FPI), the first foundational dynamic programming algorithm for safe RL. FPI alternates between policy evaluation, region identification and policy improvement. This follows actor-critic-scenery (ACS) framework where scenery refers to a feasibility function that represents a feasible region. A region-wise update rule is developed for the policy improvement step, which maximizes state-value function inside the feasible region and minimizes feasibility function outside it. With this update rule, FPI guarantees monotonic expansion of feasible region, monotonic improvement of state-value function, and geometric convergence to the optimal safe policy. Experimental results demonstrate that FPI achieves strictly zero constraint violation on low-dimensional tasks and outperforms existing methods in constraint adherence and reward performance on high-dimensional tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08845v3</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Yang, Zhilong Zheng, Shengbo Eben Li, Wei Xu, Jingjing Liu, Xianyuan Zhan, Ya-Qin Zhang</dc:creator>
    </item>
    <item>
      <title>Networked Communication for Decentralised Agents in Mean-Field Games</title>
      <link>https://arxiv.org/abs/2306.02766</link>
      <description>arXiv:2306.02766v5 Announce Type: replace-cross 
Abstract: We introduce networked communication to the mean-field game framework, in particular to oracle-free settings where $N$ decentralised agents learn along a single, non-episodic run of the empirical system. We prove that our architecture has sample guarantees bounded between those of the centralised- and independent-learning cases. We provide the order of the difference in these bounds in terms of network structure and number of communication rounds, and also contribute a policy-update stability guarantee. We discuss how the sample guarantees of the three theoretical algorithms do not actually result in practical convergence. We therefore show that in practical settings where the theoretical parameters are not observed (leading to poor estimation of the Q-function), our communication scheme considerably accelerates learning over the independent case, often performing similarly to a centralised learner while removing the restrictive assumption of the latter. We contribute further practical enhancements to all three theoretical algorithms, allowing us to present their first empirical demonstrations. Our experiments confirm that we can remove several of the theoretical assumptions of the algorithms, and display the empirical convergence benefits brought by our new networked communication. We additionally show that our networked approach has significant advantages over both alternatives in terms of robustness to update failures and to changes in population size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02766v5</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Benjamin, Alessandro Abate</dc:creator>
    </item>
    <item>
      <title>Real-Time Recurrent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2311.04830</link>
      <description>arXiv:2311.04830v3 Announce Type: replace-cross 
Abstract: We introduce a biologically plausible RL framework for solving tasks in partially observable Markov decision processes (POMDPs). The proposed algorithm combines three integral parts: (1) A Meta-RL architecture, resembling the mammalian basal ganglia; (2) A biologically plausible reinforcement learning algorithm, exploiting temporal difference learning and eligibility traces to train the policy and the value-function; (3) An online automatic differentiation algorithm for computing the gradients with respect to parameters of a shared recurrent network backbone. Our experimental results show that the method is capable of solving a diverse set of partially observable reinforcement learning tasks. The algorithm we call real-time recurrent reinforcement learning (RTRRL) serves as a model of learning in biological neural networks, mimicking reward pathways in the basal ganglia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04830v3</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Lemmel, Radu Grosu</dc:creator>
    </item>
    <item>
      <title>Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</title>
      <link>https://arxiv.org/abs/2408.11607</link>
      <description>arXiv:2408.11607v2 Announce Type: replace-cross 
Abstract: Recent algorithms allow decentralised agents, possibly connected via a communication network, to learn equilibria in Mean-Field Games from a non-episodic run of the empirical system. However, these algorithms are for tabular settings: this computationally limits the size of agents' observation space, meaning the algorithms cannot handle anything but small state spaces, nor generalise beyond policies depending only on the agent's local state to so-called 'population-dependent' policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the mean field in the observation for players' policies, it is unrealistic to assume decentralised agents have access to this global information: we therefore also provide new algorithms allowing agents to locally estimate the global empirical distribution, and to improve this estimate via inter-agent communication. We show theoretically that exchanging policy information helps networked agents outperform both independent and even centralised agents in function-approximation settings. Our experiments demonstrate this happening empirically, by an even greater margin than in tabular settings, and show that the communication network allows decentralised agents to estimate the mean field for population-dependent policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11607v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Benjamin, Alessandro Abate</dc:creator>
    </item>
    <item>
      <title>Quantifying Aleatoric and Epistemic Dynamics Uncertainty via Local Conformal Calibration</title>
      <link>https://arxiv.org/abs/2409.08249</link>
      <description>arXiv:2409.08249v3 Announce Type: replace-cross 
Abstract: Whether learned, simulated, or analytical, approximations of a robot's dynamics can be inaccurate when encountering novel environments. Many approaches have been proposed to quantify the aleatoric uncertainty of such methods, i.e. uncertainty resulting from stochasticity, however these estimates alone are not enough to properly estimate the uncertainty of a model in a novel environment, where the actual dynamics can change. Such changes can induce epistemic uncertainty, i.e. uncertainty due to a lack of information/data. Accounting for both epistemic and aleatoric dynamics uncertainty in a theoretically-grounded way remains an open problem. We introduce Local Uncertainty Conformal Calibration (LUCCa), a conformal prediction-based approach that calibrates the aleatoric uncertainty estimates provided by dynamics models to generate probabilistically-valid prediction regions of the system's state. We account for both epistemic and aleatoric uncertainty non-asymptotically, without strong assumptions about the form of the true dynamics or how it changes. The calibration is performed locally in the state-action space, leading to uncertainty estimates that are useful for planning. We validate our method by constructing probabilistically-safe plans for a double-integrator under significant changes in dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08249v3</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lu\'is Marques, Dmitry Berenson</dc:creator>
    </item>
    <item>
      <title>Underapproximating Safe Domains of Attraction for Discrete-Time Systems Using Implicit Representations of Backward Reachable Sets</title>
      <link>https://arxiv.org/abs/2409.10657</link>
      <description>arXiv:2409.10657v2 Announce Type: replace-cross 
Abstract: Analyzing and certifying stability and attractivity of nonlinear systems is a topic of research interest that has been extensively investigated by control theorists and engineers for many years. Despite that, accurately estimating domains of attraction for nonlinear systems remains a challenging task, where available estimation approaches are either conservative or limited to low-dimensional systems. In this work, we propose an iterative approach to accurately underapproximate safe (i.e., state-constrained) domains of attraction for general discrete-time autonomous nonlinear systems. Our approach relies on implicit representations of safe backward reachable sets of safe regions of attraction, where such regions can be be easily constructed using, e.g., quadratic Lyapunov functions. The iterations of our approach are monotonic (in the sense of set inclusion), where each iteration results in a safe region of attraction, given as a sublevel set, that underapproximates the safe domain of attraction. The sublevel set representations of the resulting regions of attraction can be efficiently utilized in verifying the inclusion of given points of interest in the safe domain of attraction. We illustrate our approach through two numerical examples, involving two- and four-dimensional nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10657v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Serry, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Maintaining Strong $r$-Robustness in Reconfigurable Multi-Robot Networks using Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2409.14675</link>
      <description>arXiv:2409.14675v2 Announce Type: replace-cross 
Abstract: In leader-follower consensus, strong $r$-robustness of the communication graph provides a sufficient condition for followers to achieve consensus in the presence of misbehaving agents. Previous studies have assumed that robots can form and/or switch between predetermined network topologies with known robustness properties. However, robots with distance-based communication models may not be able to achieve these topologies while moving through spatially constrained environments, such as narrow corridors, to complete their objectives. This paper introduces a Control Barrier Function (CBF) that ensures robots maintain strong $r$-robustness of their communication graph above a certain threshold without maintaining any fixed topologies. Our CBF directly addresses robustness, allowing robots to have flexible reconfigurable network structure while navigating to achieve their objectives. The efficacy of our method is tested through various simulation and hardware experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14675v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haejoon Lee, Dimitra Panagou</dc:creator>
    </item>
    <item>
      <title>Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion Dynamics</title>
      <link>https://arxiv.org/abs/2410.04301</link>
      <description>arXiv:2410.04301v3 Announce Type: replace-cross 
Abstract: This work extends the recent opinion dynamics model from Cheng et al., emphasizing the role of group pressure in consensus formation. We generalize the findings to incorporate social influence algorithms with general time-varying, opinion-dependent weights and multidimensional opinions, beyond bounded confidence dynamics. We demonstrate that, with uniformly positive conformity levels, group pressure consistently drives consensus and provide a tighter estimate for the convergence rate. Unlike previous models, the common public opinion in our framework can assume arbitrary forms within the convex hull of current opinions, offering flexibility applicable to real-world scenarios such as opinion polls with random participant selection. This analysis provides deeper insights into how group pressure mechanisms foster consensus under diverse conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04301v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Iryna Zabarianska, Anton V. Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Safe and Dynamically-Feasible Motion Planning using Control Lyapunov and Barrier Functions</title>
      <link>https://arxiv.org/abs/2410.08364</link>
      <description>arXiv:2410.08364v2 Announce Type: replace-cross 
Abstract: This paper considers the problem of designing motion planning algorithms for control-affine systems that generate collision-free paths from an initial to a final destination and can be executed using safe and dynamically-feasible controllers. We introduce the C-CLF-CBF-RRT algorithm, which produces paths with such properties and leverages rapidly exploring random trees (RRTs), control Lyapunov functions (CLFs) and control barrier functions (CBFs). We show that C-CLF-CBF-RRT is computationally efficient for linear systems with polytopic and ellipsoidal constraints, and establish its probabilistic completeness. We showcase the performance of C-CLF-CBF-RRT in different simulation and hardware experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08364v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Carlos Nieto-Granda, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>AI-Aided Kalman Filters</title>
      <link>https://arxiv.org/abs/2410.12289</link>
      <description>arXiv:2410.12289v2 Announce Type: replace-cross 
Abstract: The Kalman filter (KF) and its variants are among the most celebrated algorithms in signal processing. These methods are used for state estimation of dynamic systems by relying on mathematical representations in the form of simple state-space (SS) models, which may be crude and inaccurate descriptions of the underlying dynamics. Emerging data-centric artificial intelligence (AI) techniques tackle these tasks using deep neural networks (DNNs), which are model-agnostic. Recent developments illustrate the possibility of fusing DNNs with classic Kalman-type filtering, obtaining systems that learn to track in partially known dynamics. This article provides a tutorial-style overview of design approaches for incorporating AI in aiding KF-type algorithms. We review both generic and dedicated DNN architectures suitable for state estimation, and provide a systematic presentation of techniques for fusing AI tools with KFs and for leveraging partial SS modeling and data, categorizing design approaches into task-oriented and SS model-oriented. The usefulness of each approach in preserving the individual strengths of model-based KFs and data-driven DNNs is investigated in a qualitative and quantitative study, whose code is publicly available, illustrating the gains of hybrid model-based/data-driven designs. We also discuss existing challenges and future research directions that arise from fusing AI and Kalman-type algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12289v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nir Shlezinger, Guy Revach, Anubhab Ghosh, Saikat Chatterjee, Shuo Tang, Tales Imbiriba, Jindrich Dunik, Ondrej Straka, Pau Closas, Yonina C. Eldar</dc:creator>
    </item>
    <item>
      <title>Real-Time Decision-Making for Digital Twin in Additive Manufacturing with Model Predictive Control using Time-Series Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2501.07601</link>
      <description>arXiv:2501.07601v3 Announce Type: replace-cross 
Abstract: Digital Twin -- a virtual replica of a physical system enabling real-time monitoring, model updating, prediction, and decision-making -- combined with recent advances in machine learning, offers new opportunities for proactive control strategies in autonomous manufacturing. However, achieving real-time decision-making with Digital Twins requires efficient optimization driven by accurate predictions of highly nonlinear manufacturing systems. This paper presents a simultaneous multi-step Model Predictive Control (MPC) framework for real-time decision-making, using a multivariate deep neural network, named Time-Series Dense Encoder (TiDE), as the surrogate model. Unlike conventional MPC models which only provide one-step ahead prediction, TiDE is capable of predicting future states within the prediction horizon in one shot (multi-step), significantly accelerating the MPC. Using Directed Energy Deposition (DED) additive manufacturing as a case study, we demonstrate the effectiveness of the proposed MPC in achieving melt pool temperature tracking to ensure part quality, while reducing porosity defects by regulating laser power to maintain melt pool depth constraints. In this work, we first show that TiDE is capable of accurately predicting melt pool temperature and depth. Second, we demonstrate that the proposed MPC achieves precise temperature tracking while satisfying melt pool depth constraints within a targeted dilution range (10\%-30\%), reducing potential porosity defects. Compared to PID controller, the MPC results in smoother and less fluctuating laser power profiles with competitive or superior melt pool temperature control performance. This demonstrates the MPC's proactive control capabilities, leveraging time-series prediction and real-time optimization, positioning it as a powerful tool for future Digital Twin applications and real-time process optimization in manufacturing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07601v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi-Ping Chen, Vispi Karkaria, Ying-Kuan Tsai, Faith Rolark, Daniel Quispe, Robert X. Gao, Jian Cao, Wei Chen</dc:creator>
    </item>
    <item>
      <title>HOPS: High-order Polynomials with Self-supervised Dimension Reduction for Load Forecasting</title>
      <link>https://arxiv.org/abs/2501.10637</link>
      <description>arXiv:2501.10637v2 Announce Type: replace-cross 
Abstract: Load forecasting is a fundamental task in smart grid. Many techniques have been applied to developing load forecasting models. Due to the challenges such as the Curse of Dimensionality, overfitting, and limited computing resources, multivariate higher-order polynomial models have received limited attention in load forecasting, despite their desirable mathematical foundations and optimization properties. In this paper, we propose low rank approximation and self-supervised dimension reduction to address the aforementioned issues. To further improve computational efficiency, we also utilize a fast Conjugate Gradient based algorithm for the proposed polynomial models. Based on the load datasets from the ISO New England, the proposed method high-order polynomials with self-supervised dimension reduction (HOPS) demonstrates higher forecasting accuracy over several competitive models. Additionally, experimental results indicate that our approach alleviates redundant variable construction, achieving better forecasts with fewer input variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10637v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengyang Song, Han Feng, Shreyashi Shukla, Jue Wang, Tao Hong</dc:creator>
    </item>
    <item>
      <title>The Algorithmic State Architecture (ASA): An Integrated Framework for AI-Enabled Government</title>
      <link>https://arxiv.org/abs/2503.08725</link>
      <description>arXiv:2503.08725v2 Announce Type: replace-cross 
Abstract: As artificial intelligence transforms public sector operations, governments struggle to integrate technological innovations into coherent systems for effective service delivery. This paper introduces the Algorithmic State Architecture (ASA), a novel four-layer framework conceptualising how Digital Public Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and GovTech interact as an integrated system in AI-enabled states. Unlike approaches that treat these as parallel developments, ASA positions them as interdependent layers with specific enabling relationships and feedback mechanisms. Through comparative analysis of implementations in Estonia, Singapore, India, and the UK, we demonstrate how foundational digital infrastructure enables systematic data collection, which powers algorithmic decision-making processes, ultimately manifesting in user-facing services. Our analysis reveals that successful implementations require balanced development across all layers, with particular attention to integration mechanisms between them. The framework contributes to both theory and practice by bridging previously disconnected domains of digital government research, identifying critical dependencies that influence implementation success, and providing a structured approach for analysing the maturity and development pathways of AI-enabled government systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08725v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeynep Engin, Jon Crowcroft, David Hand, Philip Treleaven</dc:creator>
    </item>
    <item>
      <title>PCLA: A Framework for Testing Autonomous Agents in the CARLA Simulator</title>
      <link>https://arxiv.org/abs/2503.09385</link>
      <description>arXiv:2503.09385v2 Announce Type: replace-cross 
Abstract: Recent research on testing autonomous driving agents has grown significantly, especially in simulation environments. The CARLA simulator is often the preferred choice, and the autonomous agents from the CARLA Leaderboard challenge are regarded as the best-performing agents within this environment. However, researchers who test these agents, rather than training their own ones from scratch, often face challenges in utilizing them within customized test environments and scenarios. To address these challenges, we introduce PCLA (Pretrained CARLA Leaderboard Agents), an open-source Python testing framework that includes nine high-performing pre-trained autonomous agents from the Leaderboard challenges. PCLA is the first infrastructure specifically designed for testing various autonomous agents in arbitrary CARLA environments/scenarios. PCLA provides a simple way to deploy Leaderboard agents onto a vehicle without relying on the Leaderboard codebase, it allows researchers to easily switch between agents without requiring modifications to CARLA versions or programming environments, and it is fully compatible with the latest version of CARLA while remaining independent of the Leaderboard's specific CARLA version. PCLA is publicly accessible at https://github.com/MasoudJTehrani/PCLA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09385v2</guid>
      <category>cs.SE</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Jamshidiyan Tehrani, Jinhan Kim, Paolo Tonella</dc:creator>
    </item>
  </channel>
</rss>
