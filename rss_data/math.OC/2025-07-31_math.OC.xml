<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Aug 2025 01:26:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Frequency-Domain Analysis of the Euler-Bernoulli and Timoshenko Beams with Attached Masses</title>
      <link>https://arxiv.org/abs/2507.22147</link>
      <description>arXiv:2507.22147v1 Announce Type: new 
Abstract: This work is focused on the frequency-domain modeling of a simply supported flexible beam with an attached mass in the presence of dissipation. The considered system is equipped with a spring-loaded control actuator and possesses local damping effect. With the help of Hamilton's variational principle, the equations of motion are derived in the state space form with account of interface conditions involving lumped control and local damping. The transfer functions are obtained for Timoshenko and Euler--Bernoulli beam models with the output measurements provided by a sensor. Comparative Bode plots are presented for the two beam models with different choices of damping coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22147v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Julia Kalosha</dc:creator>
    </item>
    <item>
      <title>Interior-Point Algorithms for Monotone Linear Complementarity Problem Based on Different Predictor Directions</title>
      <link>https://arxiv.org/abs/2507.22185</link>
      <description>arXiv:2507.22185v1 Announce Type: new 
Abstract: In this paper, we introduce two parabolic target-space interior-point algorithms for solving monotone linear complementarity problems. The first algorithm is based on a universal tangent direction, which has been recently proposed for linear optimization problems. We prove that this method has the best known worst-case complexity bound. We extend onto LCP its auto-correcting version, and prove its local quadratic convergence under a non-degeneracy assumption. In our numerical experiments, we compare the new algorithms with a general method, recently developed for weighted monotone linear complementarity problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22185v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marianna E. -Nagy, Tibor Ill\'es, Yurii Nesterov, Petra Ren\'ata Rig\'o</dc:creator>
    </item>
    <item>
      <title>Practice-Based Optimization for the Strategic Locomotive Assignment Problem</title>
      <link>https://arxiv.org/abs/2507.22235</link>
      <description>arXiv:2507.22235v1 Announce Type: new 
Abstract: This study addresses the challenge of efficiently assigning locomotives in large freight rail networks, where operational complexity and power imbalances make cost-effective planning difficult. It presents a strategic optimization framework for the Locomotive Assignment Problem (LAP), developed in collaboration with a major North American Class I Freight Railroad. The problem is formulated as a network-based integer program over a cyclic space-time network, producing a repeatable weekly locomotive assignment plan. The model captures a comprehensive set of real-world operational constraints and jointly optimizes the placement of pick-up and set-out locomotive work events, improving the effectiveness of downstream planning. To solve large-scale instances exactly for the first time, novel reduction rules are introduced to dramatically reduce the number of light travel arcs in the space-time network. Extensive computational experiments demonstrate the performance and trade-offs on real instances under a variety of practical constraints. Beyond delivering scalable, high-quality solutions, the proposed framework serves as a practical decision-support tool grounded in the operational realities of modern freight railroads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22235v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunji Kim, Amira Hijazi, Kevin Dalmeijer, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Modified Smith predictor for unstable linear systems</title>
      <link>https://arxiv.org/abs/2507.22243</link>
      <description>arXiv:2507.22243v1 Announce Type: new 
Abstract: The paper presents a new control algorithm for unstable linear systems with input delay. In comparison with known analogues, the control law has been designed, which is a modification of the Smith predictor, and is the simplest one to implement without requiring complex integration methods. At the same time, the problem of stabilization of a closed system is effectively solved, ensuring the boundedness of all state variables and the exponential stability of the equilibrium point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22243v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Pyrkin, Konstantin Kalinin</dc:creator>
    </item>
    <item>
      <title>Parallel block coordinate descent methods with identification strategies</title>
      <link>https://arxiv.org/abs/2507.22277</link>
      <description>arXiv:2507.22277v1 Announce Type: new 
Abstract: This work presents a parallel variant of the algorithm introduced in [Acceleration of block coordinate descent methods with identification strategies Comput. Optim. Appl. 72(3):609--640, 2019] to minimize the sum of a partially separable smooth convex function and a possibly non-smooth block-separable convex function under simple constraints. It achieves better efficiency by using a strategy to identify the nonzero coordinates that allows the computational effort to be focused on using a nonuniform probability distribution in the selection of the blocks. Parallelization is achieved by extending the theoretical results from Richt\'arik and Tak\'a\v{c} [Parallel coordinate descent methods for big data optimization, Math. Prog. Ser. A 156:433--484, 2016]. We present convergence results and comparative numerical experiments on regularized regression problems using both synthetic and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22277v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rolando Lopes, Sandra A. Santos, Paulo J. S. Silva</dc:creator>
    </item>
    <item>
      <title>An Asynchronous Decentralised Optimisation Algorithm for Nonconvex Problems</title>
      <link>https://arxiv.org/abs/2507.22311</link>
      <description>arXiv:2507.22311v1 Announce Type: new 
Abstract: In this paper, we consider nonconvex decentralised optimisation and learning over a network of distributed agents. We develop an ADMM algorithm based on the Randomised Block Coordinate Douglas-Rachford splitting method which enables agents in the network to distributedly and asynchronously compute a set of first-order stationary solutions of the problem. To the best of our knowledge, this is the first decentralised and asynchronous algorithm for solving nonconvex optimisation problems with convergence proof. The numerical examples demonstrate the efficiency of the proposed algorithm for distributed Phase Retrieval and sparse Principal Component Analysis problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22311v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Behnam Mafakheri, Jonathan H. Manton, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Mean-Variance Optimization and Algorithm for Finite-Horizon Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2507.22327</link>
      <description>arXiv:2507.22327v1 Announce Type: new 
Abstract: Multi-period mean-variance optimization is a long-standing problem, caused by the failure of dynamic programming principle. This paper studies the mean-variance optimization in a setting of finite-horizon discrete-time Markov decision processes (MDPs), where the objective is to maximize the combined metrics of mean and variance of the accumulated rewards at terminal stage. By introducing the concepts of pseudo mean and pseudo variance, we convert the original mean-variance MDP to a bilevel MDP, where the outer is a single parameter optimization of the pseudo mean and the inner is a standard finite-horizon MDP with an augmented state space by adding an auxiliary state of accumulated rewards. We further study the properties of this bilevel MDP, including the optimality of history-dependent deterministic policies and the piecewise quadratic concavity of the inner MDPs' optimal values with respect to the pseudo mean. To efficiently solve this bilevel MDP, we propose an iterative algorithm that alternatingly updates the inner optimal policy and the outer pseudo mean. We prove that this algorithm converges to a local optimum. We also derive a sufficient condition under which our algorithm converges to the global optimum. Furthermore, we apply this approach to study the mean-variance optimization of multi-period portfolio selection problem, which shows that our approach exactly coincides with the classical result by Li and Ng (2000) in financial engineering. Our approach builds a new avenue to solve mean-variance optimization problems and has wide applicability to any problem modeled by MDPs, which is further demonstrated by examples of mean-variance optimization for queueing control and inventory management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22327v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Xia, Zhihui Yu</dc:creator>
    </item>
    <item>
      <title>Team Variance Optimization of n-Player Stochastic Games with Separately Controlled Chains</title>
      <link>https://arxiv.org/abs/2507.22335</link>
      <description>arXiv:2507.22335v1 Announce Type: new 
Abstract: In this paper, we study a subclass of n-player stochastic games, in which each player has their own internal state controlled only by their own action and their objective is a common goal called team variance which measures the total variation of the random rewards of all players. It is assumed that players cannot observe each others' state/action. Thus, players' internal chains are controlled separately by their own action and they are coupled through the objective of team variance. Since the variance metric is not additive or Markovian, the dynamic programming principle fails in this problem. We study this problem from the viewpoint of sensitivity-based optimization. A difference formula and a derivative formula for team variance with respect to policy perturbations are derived, which provide sensitivity information to guide decentralized optimization. The existence of a stationary pure Nash equilibrium policy is derived. We further develop a bilevel optimization algorithm that iteratively updates the team mean at the outer level and minimizes the team variance at the inner level, where the team mean serves as a signal to coordinate the optimization of n players in a decentralized manner. We prove that the algorithm can converge to a strictly local minimum or a first-order stationary point in the space of mixed policies. Finally, we demonstrate the effectiveness of our approach using a numerical experiment of energy management in smart grid, where the assumption of separately controlled chains holds naturally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22335v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Xia</dc:creator>
    </item>
    <item>
      <title>Resilient State Recovery using Prior Measurement Support Information</title>
      <link>https://arxiv.org/abs/2507.22340</link>
      <description>arXiv:2507.22340v1 Announce Type: new 
Abstract: Resilient state recovery of cyber-physical systems has attracted much research attention due to the unique challenges posed by the tight coupling between communication, computation, and the underlying physics of such systems. By modeling attacks as additive adversary signals to a sparse subset of measurements, this resilient recovery problem can be formulated as an error correction problem. To achieve exact state recovery, most existing results require less than $50\%$ of the measurement nodes to be compromised, which limits the resiliency of the estimators. In this paper, we show that observer resiliency can be further improved by incorporating data-driven prior information. We provide an analytical bridge between the precision of prior information and the resiliency of the estimator. By quantifying the relationship between the estimation error of the weighted $\ell_1$ observer and the precision of the support prior. This quantified relationship provides guidance for the estimator's weight design to achieve optimal resiliency. Several numerical simulations and an application case study are presented to validate the theoretical claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22340v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yu Zheng, Olugbenga Moses Anubi, Warren E. Dixon</dc:creator>
    </item>
    <item>
      <title>Markov Decision Processes with Value-at-Risk Criterion</title>
      <link>https://arxiv.org/abs/2507.22355</link>
      <description>arXiv:2507.22355v1 Announce Type: new 
Abstract: Value-at-risk (VaR), also known as quantile, is a crucial risk measure in finance and other fields. However, optimizing VaR metrics in Markov decision processes (MDPs) is challenging because VaR is non-additive and the traditional dynamic programming is inapplicable. This paper conducts a comprehensive study on VaR optimization in discrete-time finite MDPs. We consider VaR in two key scenarios: the VaR of steady-state rewards over an infinite horizon and the VaR of accumulated rewards over a finite horizon. By establishing the equivalence between the VaR maximization MDP and a series of probabilistic minimization MDPs, we transform the VaR maximization MDP into a constrained bilevel optimization problem. The inner-level is a policy optimization of minimizing the probability that MDP rewards fall below a target $\lambda$, while the outer-level is a single parameter optimization of $\lambda$, representing the target VaR. For the steady-state scenario, the probabilistic minimization MDP can be resolved using the expectation criterion of a standard MDP. In contrast, for the finite-horizon case, it can be addressed via an augmented-state MDP. We prove the optimality of deterministic stationary policies for steady-state VaR MDPs and deterministic history-dependent policies for finite-horizon VaR MDPs. We derive both a policy improvement rule and a necessary-sufficient condition for optimal policies. Furthermore, we develop policy iteration type algorithms to maximize the VaR in MDPs and prove their convergence. Our results are also extended to the counterpart of VaR minimization MDPs after appropriate modifications. Finally, we conduct numerical experiments to demonstrate the computational efficiency and practical applicability of our approach. Our study paves a novel way to explore the optimization of quantile-related metrics in MDPs through the duality between quantiles and probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22355v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Xia, Jinyan Pan</dc:creator>
    </item>
    <item>
      <title>Decentralized online stochastic generalized Nash Equilibrium seeking for multi-cluster games: A Byzantine-resilient algorithm</title>
      <link>https://arxiv.org/abs/2507.22357</link>
      <description>arXiv:2507.22357v1 Announce Type: new 
Abstract: This paper addresses the challenge of solving the generalized Nash Equilibrium seeking problem for decentralized stochastic online multi-cluster games amidst Byzantine agents. During the game process, each honest agent is influenced by both randomness and malicious information propagated by Byzantine agents. Additionally, none of the agents have prior knowledge about the number and identities of Byzantine agents. Furthermore, the stochastic local cost function and coupled global constraint function are only revealed to each agent in hindsight at each round. One major challenge in addressing such an issue is the stringent requirement for each honest agent to effectively mitigate the effect of decision variables of Byzantine agents on its local cost functions. To overcome this challenge, a decentralized Byzantine-resilient algorithm for online stochastic generalized Nash equilibrium (SGNE) seeking is developed, which combines variance reduction, dynamic average consensus, and robust aggregation techniques. Moreover, novel resilient versions of system-wide regret and constraint violation are proposed as metrics for evaluating the performance of the online algorithm. Under certain conditions, it is proven that these resilient metrics grow sublinearly over time in expectation. Numerical simulations are conducted to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22357v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingqian Liu, Guanghui Wen, Liyuan Chen, Yiguang Hong</dc:creator>
    </item>
    <item>
      <title>Set Invariance with Probability One for Controlled Diffusion: Score-based Approach</title>
      <link>https://arxiv.org/abs/2507.22385</link>
      <description>arXiv:2507.22385v1 Announce Type: new 
Abstract: Given a controlled diffusion and a connected, bounded, Lipschitz set, when is it possible to guarantee controlled set invariance with probability one? In this work, we answer this question by deriving the necessary and sufficient conditions for the same in terms of gradients of certain log-likelihoods -- a.k.a. score vector fields -- for two cases: given finite time horizon and infinite time horizon. The deduced conditions comprise a score-based test that provably certifies or falsifies the existence of Markovian controllers for given controlled set invariance problem data. Our results are constructive in the sense when the problem data passes the proposed test, we characterize all controllers guaranteeing the desired set invariance. When the problem data fails the proposed test, there does not exist a controller that can accomplish the desired set invariance with probability one. The computation in the proposed tests involve solving certain Dirichlet boundary value problems, and in the finite horizon case, can also account for additional constraint of hitting a target subset at the terminal time. We illustrate the results using several semi-analytical and numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22385v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Wang, Alexis M. H. Teter, Murat Arcak, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Global Descent Method for Non-convex Multi-objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2507.22390</link>
      <description>arXiv:2507.22390v1 Announce Type: new 
Abstract: In this paper, we develop a global descent method for non-convex multi-objective optimization problems. The proposed approach builds upon foundational concepts from single-objective global descent techniques while removing the need for predefined scalars or ordering information of objective functions. Initially, the proposed method identifies a local weak efficient solution using any suitable descent algorithm, then applies an auxiliary function termed the multi-objective global descent function to systematically transition toward improved local weak efficient solutions. It is justified that this method can generate a global Pareto front for non-convex problems, which has many different local Pareto fronts. Finally, comprehensive numerical experiments on benchmark non-convex multi-objective optimization problems have been done to demonstrate the method's robustness, scalability and effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22390v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bikram Adhikary, Md Abu Talhamainuddin Ansary, Savin Treanta</dc:creator>
    </item>
    <item>
      <title>On the locus of multiple maximizing geodesics on a globally hyperbolic spacetime</title>
      <link>https://arxiv.org/abs/2507.22737</link>
      <description>arXiv:2507.22737v1 Announce Type: new 
Abstract: Extending the recent work of Cannarsa, Cheng and Fathi, we investigate topological properties of the locus ${\cal NU}(M,g)$ of multiple maximizing geodesics on a globally hyperbolic spacetime $(M,g)$, i.e.\ the set of causally related pairs $(x,y)$ for which there exists more than one maximizing geodesic (up to reparametrization) from $x$ to $y$. We will prove that this set is locally contractible. We will also define the notion of a Lorentzian Aubry set ${\cal A}$ and prove that the inclusions ${\cal NU}(M,g)\hookrightarrow \operatorname{Cut}_M\hookrightarrow J^+\backslash {\cal A}$ are homotopy equivalences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22737v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.MP</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alec Metsch</dc:creator>
    </item>
    <item>
      <title>Federated Learning on Riemannian Manifolds: A Gradient-Free Projection-Based Approach</title>
      <link>https://arxiv.org/abs/2507.22855</link>
      <description>arXiv:2507.22855v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a powerful paradigm for collaborative model training across distributed clients while preserving data privacy. However, existing FL algorithms predominantly focus on unconstrained optimization problems with exact gradient information, limiting its applicability in scenarios where only noisy function evaluations are accessible or where model parameters are constrained. To address these challenges, we propose a novel zeroth-order projection-based algorithm on Riemannian manifolds for FL. By leveraging the projection operator, we introduce a computationally efficient zeroth-order Riemannian gradient estimator. Unlike existing estimators, ours requires only a simple Euclidean random perturbation, eliminating the need to sample random vectors in the tangent space, thus reducing computational cost. Theoretically, we first prove the approximation properties of the estimator and then establish the sublinear convergence of the proposed algorithm, matching the rate of its first-order counterpart. Numerically, we first assess the efficiency of our estimator using kernel principal component analysis. Furthermore, we apply the proposed algorithm to two real-world scenarios: zeroth-order attacks on deep neural networks and low-rank neural network training to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22855v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongye Wang, Zhaoye Pan, Chang He, Jiaxiang Li, Bo Jiang</dc:creator>
    </item>
    <item>
      <title>Derivative Estimation from Coarse, Irregular, Noisy Samples: An MLE-Spline Approach</title>
      <link>https://arxiv.org/abs/2507.22176</link>
      <description>arXiv:2507.22176v1 Announce Type: cross 
Abstract: We address numerical differentiation under coarse, non-uniform sampling and Gaussian noise. A maximum-likelihood estimator with $L_2$-norm constraint on a higher-order derivative is obtained, yielding spline-based solution. We introduce a non-standard parameterization of quadratic splines and develop recursive online algorithms. Two formulations -- quadratic and zero-order -- offer tradeoff between smoothness and computational speed. Simulations demonstrate superior performance over high-gain observers and super-twisting differentiators under coarse sampling and high noise, benefiting systems where higher sampling rates are impractical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22176v1</guid>
      <category>stat.ME</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin E. Avrachenkov, Leonid B. Freidovich</dc:creator>
    </item>
    <item>
      <title>CLuP practically achieves $\sim 1.77$ positive and $\sim 0.33$ negative Hopfield model ground state free energy</title>
      <link>https://arxiv.org/abs/2507.22396</link>
      <description>arXiv:2507.22396v1 Announce Type: cross 
Abstract: We study algorithmic aspects of finding $n$-dimensional \emph{positive} and \emph{negative} Hopfield ($\pm$Hop) model ground state free energies. This corresponds to classical maximization of random positive/negative semi-definite quadratic forms over binary $\left \{\pm \frac{1}{\sqrt{n}} \right \}^n$ vectors. The key algorithmic question is whether these problems can be computationally efficiently approximated within a factor $\approx 1$. Following the introduction and success of \emph{Controlled Loosening-up} (CLuP-SK) algorithms in finding near ground state energies of closely related Sherrington-Kirkpatrick (SK) models [82], we here propose a CLuP$\pm$Hop counterparts for $\pm$Hop models. Fully lifted random duality theory (fl RDT) [78] is utilized to characterize CLuP$\pm$Hop \emph{typical} dynamics. An excellent agreement between practical performance and theoretical predictions is observed. In particular, for $n$ as small as few thousands CLuP$\pm$Hop achieve $\sim 1.77$ and $\sim 0.33$ as the ground state free energies of the positive and negative Hopfield models. At the same time we obtain on the 6th level of lifting (6-spl RDT) corresponding theoretical thermodynamic ($n\rightarrow\infty$) limits $\approx 1.7784$ and $\approx 0.3281$. This positions determining Hopfield models near ground state energies as \emph{typically} easy problems. Moreover, the very same 6th lifting level evaluations allow to uncover a fundamental intrinsic difference between two models: $+$Hop's near optimal configurations are \emph{typically close} to each other whereas the $-$Hop's are \emph{typically far away}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22396v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihailo Stojnic</dc:creator>
    </item>
    <item>
      <title>A surrogate model for topology optimisation of elastic structures via parametric autoencoders</title>
      <link>https://arxiv.org/abs/2507.22539</link>
      <description>arXiv:2507.22539v1 Announce Type: cross 
Abstract: A surrogate-based topology optimisation algorithm for linear elastic structures under parametric loads and boundary conditions is proposed. Instead of learning the parametric solution of the state (and adjoint) problems or the optimisation trajectory as a function of the iterations, the proposed approach devises a surrogate version of the entire optimisation pipeline. First, the method predicts a quasi-optimal topology for a given problem configuration as a surrogate model of high-fidelity topologies optimised with the homogenisation method. This is achieved by means of a feed-forward net learning the mapping between the input parameters characterising the system setup and a latent space determined by encoder/decoder blocks reducing the dimensionality of the parametric topology optimisation problem and reconstructing a high-dimensional representation of the topology. Then, the predicted topology is used as an educated initial guess for a computationally efficient algorithm penalising the intermediate values of the design variable, while enforcing the governing equations of the system. This step allows the method to correct potential errors introduced by the surrogate model, eliminate artifacts, and refine the design in order to produce topologies consistent with the underlying physics. Different architectures are proposed and the approximation and generalisation capabilities of the resulting models are numerically evaluated. The quasi-optimal topologies allow to outperform the high-fidelity optimiser by reducing the average number of optimisation iterations by $53\%$ while achieving discrepancies below $4\%$ in the optimal value of the objective functional, even in the challenging scenario of testing the model to extrapolate beyond the training and validation domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22539v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
    <item>
      <title>A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model</title>
      <link>https://arxiv.org/abs/2507.22854</link>
      <description>arXiv:2507.22854v1 Announce Type: cross 
Abstract: We propose novel classical and quantum online algorithms for learning finite-horizon and infinite-horizon average-reward Markov Decision Processes (MDPs). Our algorithms are based on a hybrid exploration-generative reinforcement learning (RL) model wherein the agent can, from time to time, freely interact with the environment in a generative sampling fashion, i.e., by having access to a "simulator". By employing known classical and new quantum algorithms for approximating optimal policies under a generative model within our learning algorithms, we show that it is possible to avoid several paradigms from RL like "optimism in the face of uncertainty" and "posterior sampling" and instead compute and use optimal policies directly, which yields better regret bounds compared to previous works. For finite-horizon MDPs, our quantum algorithms obtain regret bounds which only depend logarithmically on the number of time steps $T$, thus breaking the $O(\sqrt{T})$ classical barrier. This matches the time dependence of the prior quantum works of Ganguly et al. (arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other parameters like state space size $S$ and action space size $A$. For infinite-horizon MDPs, our classical and quantum bounds still maintain the $O(\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we propose a novel measure of regret for infinite-horizon MDPs with respect to which our quantum algorithms have $\operatorname{poly}\log{T}$ regret, exponentially better compared to classical algorithms. Finally, we generalise all of our results to compact state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22854v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <category>stat.ML</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andris Ambainis, Joao F. Doriguello, Debbie Lim</dc:creator>
    </item>
    <item>
      <title>Synchronization of mean-field models on the circle</title>
      <link>https://arxiv.org/abs/2507.22857</link>
      <description>arXiv:2507.22857v1 Announce Type: cross 
Abstract: This paper considers a mean-field model of $n$ interacting particles whose state space is the unit circle, a generalization of the classical Kuramoto model. Global synchronization is said to occur if after starting from almost any initial state, all particles coalesce to a common point on the circle. We propose a general synchronization criterion in terms of $L_1$-norm of the third derivative of the particle interaction function. As an application we resolve a conjecture for the so-called self-attention dynamics (stylized model of transformers), by showing synchronization for all $\beta \ge -0.16$, which significantly extends the previous bound of $0\le \beta \le 1$ from Criscitiello, Rebjock, McRae, and Boumal (2024). We also show that global synchronization does not occur when $\beta &lt; -2/3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22857v1</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yury Polyanskiy, Philippe Rigollet, Andrew Yao</dc:creator>
    </item>
    <item>
      <title>Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis</title>
      <link>https://arxiv.org/abs/2307.14364</link>
      <description>arXiv:2307.14364v2 Announce Type: replace 
Abstract: Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14364v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Jiao, Kai Yang, Dongjin Song</dc:creator>
    </item>
    <item>
      <title>Approximability of the Containment Problem for Zonotopes and Ellipsotopes</title>
      <link>https://arxiv.org/abs/2404.11185</link>
      <description>arXiv:2404.11185v4 Announce Type: replace 
Abstract: The zonotope containment problem, i.e., whether one zonotope is contained in another, is a central problem in control theory. Applications include detecting faults and robustifying controllers by computing invariant sets, and obtain fixed points in reachability analysis. Despite the inherent co-NP-hardness of this problem, an approximation algorithm developed by S. Sadraddini and R. Tedrake has gained widespread recognition for its swift execution and consistent reliability in practice. In our study, we substantiate the precision of the algorithm with a definitive proof, elucidating the empirical accuracy observed in practice. Our proof hinges on establishing a connection between the containment problem and the computation of matrix norms, thereby enabling the extension of the approximation algorithm to encompass ellipsotopes -- a broader class of sets derived from zonotopes. We also explore the computational complexity of the ellipsotope containment problem with a focus on approximability. Finally, we present new methods to compute safe sets for linear dynamical systems, demonstrating the practical relevance of approximating the ellipsotope containment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11185v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3583624</arxiv:DOI>
      <dc:creator>Adrian Kulmburg, Lukas Sch\"afer, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>Effective Front-Descent Algorithms with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2405.08450</link>
      <description>arXiv:2405.08450v3 Announce Type: replace 
Abstract: In this manuscript, we address continuous unconstrained multi-objective optimization problems and we discuss descent type methods for the reconstruction of the Pareto set. Specifically, we analyze the class of Front Descent methods, which generalizes the Front Steepest Descent algorithm allowing the employment of suitable, effective search directions (e.g., Newton, Quasi-Newton, Barzilai-Borwein). We provide a deep characterization of the behavior and the mechanisms of the algorithmic framework, and we prove that, under reasonable assumptions, standard convergence results and some complexity bounds hold for the generalized approach. Moreover, we prove that popular search directions can indeed be soundly used within the framework. Then, we provide a completely novel type of convergence results, concerning the sequence of sets produced by the procedure. In particular, iterate sets are shown to asymptotically approach stationarity for all of their points; the convergence result is accompanied by a worst-case iteration complexity bound; additionally, in finite precision settings, the sets are shown to only be enriched through exploration steps in later iterations, and suitable stopping conditions can be devised. Finally, the results from a large experimental benchmark show that the proposed class of approaches far outperforms state-of-the-art methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08450v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Pierluigi Mansueto, Davide Pucci</dc:creator>
    </item>
    <item>
      <title>A General Mixed-Order Primal-Dual Dynamical System with Tikhonov Regularization</title>
      <link>https://arxiv.org/abs/2409.17493</link>
      <description>arXiv:2409.17493v3 Announce Type: replace 
Abstract: In a Hilbert space, we propose a class of general mixed-order primal-dual dynamical systems with Tikhonov regularization for a convex optimization problem with linear equality constraints. The proposed dynamical system is characterized by three time-dependent parameters, i.e., general viscous damping, time scaling, and Tikhonov regularization coefficients, which can incorporate as special cases some existing mixed-order primal-dual dynamical systems in the literature. With some appropriate conditions on the parameters, we analyze by constructing suitable Lyapunov functions the asymptotic convergence properties of the proposed dynamical system, where a convergence rate of O(1/(t^2\beta(t))) for the objective function error and a convergence rate of o(1/\beta(t)) for the primal-dual gap are established. Moreover, we further prove the strong convergence of the trajectory generated by the proposed dynamical system. Finally, we carry out some numerical experiments to illustrate the obtained theoretical results of the proposed dynamical system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17493v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-025-02798-y</arxiv:DOI>
      <arxiv:journal_reference>Journal of Optimization Theory and Applications, vol. 207, July 2025</arxiv:journal_reference>
      <dc:creator>Honglu Li, Rong Hu, Xin He, Yibin Xiao</dc:creator>
    </item>
    <item>
      <title>Free-Gate: Planning, Control And Policy Composition via Free Energy Gating</title>
      <link>https://arxiv.org/abs/2412.06636</link>
      <description>arXiv:2412.06636v3 Announce Type: replace 
Abstract: We consider the problem of optimally composing a set of primitives to tackle planning and control tasks. To address this problem, we introduce a free energy computational model for planning and control via policy composition: Free-Gate. Within Free-Gate, control primitives are combined via a gating mechanism that minimizes variational free energy. This composition problem is formulated as a finite-horizon optimal control problem, which we prove remains convex even when the cost is not convex in states/actions and the environment is nonlinear, stochastic and non-stationary. We develop an algorithm that computes the optimal primitives composition and demonstrate its effectiveness via in-silico and hardware experiments on an application involving robot navigation in an environment with obstacles. The experiments highlight that Free-Gate enables the robot to navigate to the destination despite only having available simple motor primitives that, individually, could not fulfill the task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06636v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Francesca Rossi, \'Emiland Garrab\'e, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Coordinated vehicle dispatching and charging scheduling for an electric ride-hailing fleet under charging congestion and dynamic prices</title>
      <link>https://arxiv.org/abs/2412.09978</link>
      <description>arXiv:2412.09978v3 Announce Type: replace 
Abstract: Effective utilization of charging station capacity plays an important role in enhancing the profitability of ride-hailing systems using electric vehicles. Existing studies assume constant energy prices and uncapacitated charging stations or do not explicitly consider vehicle queueing at charging stations, resulting in over-optimistic charging infrastructure utilization. In this study, we develop a dynamic charging scheduling method (named CongestionAware) that anticipates vehicles' energy needs and coordinates their charging operations with real-time energy prices to avoid long waiting time at charging stations and increase the total profit of the system. A sequential mixed integer linear programming model is proposed to devise vehicles' day-ahead charging plans based on their experienced charging waiting times and energy consumption. The obtained charging plans are adapted within the day in response to vehicles' energy needs and charging station congestion. The developed charging policy is tested using NYC yellow taxi data in a Manhattan-like study area with a fleet size of 100 vehicles given the scenarios of 3000 and 4000 customers per day. The computational results show that our CongestionAware policy outperforms different benchmark policies with up to +15.06% profit and +19.16% service rate for 4000 customers per day. Sensitivity analysis is conducted with different system parameters and managerial insights are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09978v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tai-Yu Ma, Richard D. Connors, Francesco Viti</dc:creator>
    </item>
    <item>
      <title>The Ball-Proximal (="Broximal") Point Method: a New Algorithm, Convergence Theory, and Applications</title>
      <link>https://arxiv.org/abs/2502.02002</link>
      <description>arXiv:2502.02002v2 Announce Type: replace 
Abstract: Non-smooth and non-convex global optimization poses significant challenges across various applications, where standard gradient-based methods often struggle. We propose the Ball-Proximal Point Method, Broximal Point Method, or Ball Point Method (BPM) for short - a novel algorithmic framework inspired by the classical Proximal Point Method (PPM) (Rockafellar, 1976), which, as we show, sheds new light on several foundational optimization paradigms and phenomena, including non-convex and non-smooth optimization, acceleration, smoothing, adaptive stepsize selection, and trust-region methods. At the core of BPM lies the ball-proximal ("broximal") operator, which arises from the classical proximal operator by replacing the quadratic distance penalty by a ball constraint. Surprisingly, and in sharp contrast with the sublinear rate of PPM in the nonsmooth convex regime, we prove that BPM converges linearly and in a finite number of steps in the same regime. Furthermore, by introducing the concept of ball-convexity, we prove that BPM retains the same global convergence guarantees under weaker assumptions, making it a powerful tool for a broader class of potentially non-convex optimization problems. Just like PPM plays the role of a conceptual method inspiring the development of practically efficient algorithms and algorithmic elements, e.g., gradient descent, adaptive step sizes, acceleration (Ahn &amp; Sra, 2020), and "W" in AdamW (Zhuang et al., 2022), we believe that BPM should be understood in the same manner: as a blueprint and inspiration for further development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02002v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaja Gruntkowska, Hanmin Li, Aadi Rane, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Structure of average distance minimizers in general dimensions</title>
      <link>https://arxiv.org/abs/2503.23256</link>
      <description>arXiv:2503.23256v2 Announce Type: replace 
Abstract: For a fixed, compactly supported probability measure $\mu$ on the $d$-dimensional space $\mathbb{R}^d$, we consider the problem of minimizing the $p^{\mathrm{th}}$-power average distance functional over all compact, connected $\Sigma \subseteq \mathbb{R}^d$ with Hausdorff 1-measure $\mathcal{H}^1(\Sigma) \leq l$. This problem, known as the average distance problem, was first studied by Buttazzo, Oudet, and Stepanov in 2002, and has undergone a considerable amount of research since. We will provide a novel approach to studying this problem by analyzing it using the so-called \textit{barycentre field} considered previously by Hayase and two of the authors. This allows us to provide a complete topological description of minimizers in arbitrary dimensions when $p = 2$ and $p &gt; \frac{1}{2}(3 + \sqrt{5}) \approx 2.618$, the first such result that includes the case when $d &gt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23256v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas O'Brien, Forest Kobayashi, Young-Heon Kim</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust LQG with Kullback-Leibler Ambiguity Sets</title>
      <link>https://arxiv.org/abs/2505.08370</link>
      <description>arXiv:2505.08370v2 Announce Type: replace 
Abstract: The Linear Quadratic Gaussian (LQG) controller is known to be inherently fragile to model misspecifications common in real-world situations. We consider discrete-time partially observable stochastic linear systems and provide a robustification of the standard LQG against distributional uncertainties on the process and measurement noise. Our distributionally robust formulation specifies the admissible perturbations by defining a relative entropy based ambiguity set individually for each time step along a finite-horizon trajectory, and minimizes the worst-case cost across all admissible distributions. We prove that the optimal control policy is still linear, as in standard LQG, and derive a computational scheme grounded on iterative best response that provably converges to the set of saddle points. Finally, we consider the case of endogenous uncertainty captured via decision-dependent ambiguity sets and we propose an approximation scheme based on dynamic programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08370v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Fochesato, Lucia Falconi, Mattia Zorzi, Augusto Ferrante, John Lygeros</dc:creator>
    </item>
    <item>
      <title>MOSS: Multi-Objective Optimization for Stable Rule Sets</title>
      <link>https://arxiv.org/abs/2506.08030</link>
      <description>arXiv:2506.08030v2 Announce Type: replace 
Abstract: We present MOSS, a multi-objective optimization framework for constructing stable sets of decision rules. MOSS incorporates three important criteria for interpretability: sparsity, accuracy, and stability, into a single multi-objective optimization framework. Importantly, MOSS allows a practitioner to rapidly evaluate the trade-off between accuracy and stability in sparse rule sets in order to select an appropriate model. We develop a specialized cutting plane algorithm in our framework to rapidly compute the Pareto frontier between these two objectives, and our algorithm scales to problem instances beyond the capabilities of commercial optimization solvers. Our experiments show that MOSS outperforms state-of-the-art rule ensembles in terms of both predictive performance and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08030v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian Liu, Rahul Mazumder</dc:creator>
    </item>
    <item>
      <title>The Sweet Spot of Bound Tightening for Topology Optimization</title>
      <link>https://arxiv.org/abs/2507.16496</link>
      <description>arXiv:2507.16496v2 Announce Type: replace 
Abstract: Topology optimization has emerged as a powerful and increasingly relevant strategy for enhancing the flexibility and efficiency of power system operations. However, solving these problems is computationally demanding due to their combinatorial nature and the use of big-M formulations. Optimization-based bound tightening (OBBT) is a well-known strategy to improve the solution of mixed-integer linear programs (MILPs) by computing tighter bounds for continuous variables. Yet, existing OBBT approaches in topology optimization typically relax all switching decisions in the bounding subproblems, leading to excessively loose feasible regions and limited bound improvements. In this work, we propose a topology-aware bound tightening method that uses network structure to determine which switching variables to relax. Through extensive computational experiments on the IEEE 118-bus system, we find that keeping a small subset of switching variables as binary, while relaxing the rest, strikes a sweet spot between the computational effort required to solve the bounding problems and the tightness of the resulting bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16496v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salvador Pineda, Juan Miguel Morales</dc:creator>
    </item>
    <item>
      <title>A Mean-Field Game of Market Entry: Portfolio Liquidation with Trading Constraints</title>
      <link>https://arxiv.org/abs/2403.10441</link>
      <description>arXiv:2403.10441v3 Announce Type: replace-cross 
Abstract: We consider both $N$-player and mean-field games of optimal portfolio liquidation in which the players are not allowed to change the direction of trading. Players with an initially short position of stocks are only allowed to buy while players with an initially long position are only allowed to sell the stock. Under suitable conditions on the model parameters we show that the games are equivalent to games of timing where the players need to determine the optimal times of market entry and exit. We identify the equilibrium entry and exit times and prove that equilibrium mean-trading rates can be characterized in terms of the solutions to a highly non-linear higher-order integral equation with endogenous terminal condition. We prove the existence of a unique solution to the integral equation from which we obtain the existence of a unique equilibrium both in the mean-field and the $N$-player game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10441v3</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanxing Fu, Paul P. Hager, Ulrich Horst</dc:creator>
    </item>
    <item>
      <title>Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency</title>
      <link>https://arxiv.org/abs/2411.03875</link>
      <description>arXiv:2411.03875v4 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03875v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejcon.2025.101286</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Control, 2025, S. 101286</arxiv:journal_reference>
      <dc:creator>Robin Str\"asser, Julian Berberich, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Convergence Properties of Natural Gradient Descent for Minimizing KL Divergence</title>
      <link>https://arxiv.org/abs/2504.19259</link>
      <description>arXiv:2504.19259v2 Announce Type: replace-cross 
Abstract: The Kullback-Leibler (KL) divergence plays a central role in probabilistic machine learning, where it commonly serves as the canonical loss function. Optimization in such settings is often performed over the probability simplex, where the choice of parameterization significantly impacts convergence. In this work, we study the problem of minimizing the KL divergence and analyze the behavior of gradient-based optimization algorithms under two dual coordinate systems within the framework of information geometry$-$ the exponential family ($\theta$ coordinates) and the mixture family ($\eta$ coordinates). We compare Euclidean gradient descent (GD) in these coordinates with the coordinate-invariant natural gradient descent (NGD), where the natural gradient is a Riemannian gradient that incorporates the intrinsic geometry of the underlying statistical model. In continuous time, we prove that the convergence rates of GD in the $\theta$ and $\eta$ coordinates provide lower and upper bounds, respectively, on the convergence rate of NGD. Moreover, under affine reparameterizations of the dual coordinates, the convergence rates of GD in $\eta$ and $\theta$ coordinates can be scaled to $2c$ and $\frac{2}{c}$, respectively, for any $c&gt;0$, while NGD maintains a fixed convergence rate of $2$, remaining invariant to such transformations and sandwiched between them. Although this suggests that NGD may not exhibit uniformly superior convergence in continuous time, we demonstrate that its advantages become pronounced in discrete time, where it achieves faster convergence and greater robustness to noise, outperforming GD. Our analysis hinges on bounding the spectrum and condition number of the Hessian of the KL divergence at the optimum, which coincides with the Fisher information matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19259v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adwait Datar, Nihat Ay</dc:creator>
    </item>
    <item>
      <title>Bootstrapping Nonequilibrium Stochastic Processes</title>
      <link>https://arxiv.org/abs/2505.13609</link>
      <description>arXiv:2505.13609v3 Announce Type: replace-cross 
Abstract: We show that bootstrap methods based on the positivity of probability measures provide a systematic framework for studying both synchronous and asynchronous nonequilibrium stochastic processes on infinite lattices. First, we formulate linear programming problems that use positivity and invariance property of invariant measures to derive rigorous bounds on their expectation values. Second, for time evolution in asynchronous processes, we exploit the master equation along with positivity and initial conditions to construct linear and semidefinite programming problems that yield bounds on expectation values at both short and late times. We illustrate both approaches using two canonical examples: the contact process in 1+1 and 2+1 dimensions, and the Domany-Kinzel model in both synchronous and asynchronous forms in 1+1 dimensions. Our bounds on invariant measures yield rigorous lower bounds on critical rates, while those on time evolutions provide two-sided bounds on the half-life of the infection density and the temporal correlation length in the subcritical phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13609v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>hep-th</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minjae Cho</dc:creator>
    </item>
    <item>
      <title>On the convergence of critical points on real algebraic sets and applications to optimization</title>
      <link>https://arxiv.org/abs/2506.20565</link>
      <description>arXiv:2506.20565v2 Announce Type: replace-cross 
Abstract: Let $F \in \R[X_1,\ldots,X_n]$ and the zero set $V=\zero(\mathcal{P},\R^n)$, where $\mathcal{P}:=\{P_1,\ldots,P_s\} \subset \R[X_1,\ldots,X_n]$ is a finite set of polynomials. We investigate existence of critical points of $F$ on an infinitesimal perturbation $V_{\xi} = \zero(\{P_1-\xi_1,\ldots,P_s-\xi_s\},\R^n)$. Our main motivation is to understand the limiting behavior of local minimizers of the log-barrier function (and central paths) in polynomial optimization, whose existence plays a fundamental role, in theory and practice, for modern interior point methods. We establish different sets of conditions that ensure existence, finiteness, boundedness, and non-degeneracy of critical points of $F$ on $V_{\xi}$, respectively. These lead to new conditions for the existence, convergence, and smoothness of central paths of polynomial optimization and its extension to non-linear optimization problems involving definable sets and functions in an o-minimal structure. In particular, for non-linear programs defined by real globally analytic functions, our extension provides a stronger form of the convergence result obtained by Drummond and Peterzil.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20565v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saugata Basu, Ali Mohammad-Nezhad</dc:creator>
    </item>
  </channel>
</rss>
