<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IR</link>
    <description>cs.IR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques</title>
      <link>https://arxiv.org/abs/2505.00105</link>
      <description>arXiv:2505.00105v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation enhances language models by retrieving relevant information from external knowledge bases, relying on high-dimensional vector embeddings typically stored in float32 precision. However, storing these embeddings at scale presents significant memory challenges. To address this issue, we systematically investigate on MTEB benchmark two complementary optimization strategies: quantization, evaluating standard formats (float16, int8, binary) and low-bit floating-point types (float8), and dimensionality reduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and Autoencoders. Our results show that float8 quantization achieves a 4x storage reduction with minimal performance degradation (&lt;0.3%), significantly outperforming int8 quantization at the same compression level, being simpler to implement. PCA emerges as the most effective dimensionality reduction technique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions) with float8 quantization offers an excellent trade-off, achieving 8x total compression with less performance impact than using int8 alone (which provides only 4x compression). To facilitate practical application, we propose a methodology based on visualizing the performance-storage trade-off space to identify the optimal configuration that maximizes performance within their specific memory constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00105v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Naam\'an Huerga-P\'erez, Rub\'en \'Alvarez, Rub\'en Ferrero-Guill\'en, Alberto Mart\'inez-Guti\'errez, Javier D\'iez-Gonz\'alez</dc:creator>
    </item>
    <item>
      <title>EnronQA: Towards Personalized RAG over Private Documents</title>
      <link>https://arxiv.org/abs/2505.00263</link>
      <description>arXiv:2505.00263v1 Announce Type: new 
Abstract: Retrieval Augmented Generation (RAG) has become one of the most popular methods for bringing knowledge-intensive context to large language models (LLM) because of its ability to bring local context at inference time without the cost or data leakage risks associated with fine-tuning. A clear separation of private information from the LLM training has made RAG the basis for many enterprise LLM workloads as it allows the company to augment LLM's understanding using customers' private documents. Despite its popularity for private documents in enterprise deployments, current RAG benchmarks for validating and optimizing RAG pipelines draw their corpora from public data such as Wikipedia or generic web pages and offer little to no personal context. Seeking to empower more personal and private RAG we release the EnronQA benchmark, a dataset of 103,638 emails with 528,304 question-answer pairs across 150 different user inboxes. EnronQA enables better benchmarking of RAG pipelines over private data and allows for experimentation on the introduction of personalized retrieval settings over realistic data. Finally, we use EnronQA to explore the tradeoff in memorization and retrieval when reasoning over private documents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00263v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos</dc:creator>
    </item>
    <item>
      <title>Graph Spectral Filtering with Chebyshev Interpolation for Recommendation</title>
      <link>https://arxiv.org/abs/2505.00552</link>
      <description>arXiv:2505.00552v1 Announce Type: new 
Abstract: Graph convolutional networks have recently gained prominence in collaborative filtering (CF) for recommendations. However, we identify potential bottlenecks in two foundational components. First, the embedding layer leads to a latent space with limited capacity, overlooking locally observed but potentially valuable preference patterns. Also, the widely-used neighborhood aggregation is limited in its ability to leverage diverse preference patterns in a fine-grained manner. Building on spectral graph theory, we reveal that these limitations stem from graph filtering with a cut-off in the frequency spectrum and a restricted linear form. To address these issues, we introduce ChebyCF, a CF framework based on graph spectral filtering. Instead of a learned embedding, it takes a user's raw interaction history to utilize the full spectrum of signals contained in it. Also, it adopts Chebyshev interpolation to effectively approximate a flexible non-linear graph filter, and further enhances it by using an additional ideal pass filter and degree-based normalization. Through extensive experiments, we verify that ChebyCF overcomes the aforementioned bottlenecks and achieves state-of-the-art performance across multiple benchmarks and reasonably fast inference. Our code is available at https://github.com/chanwoo0806/ChebyCF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00552v1</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chanwoo Kim, Jinkyu Sung, Yebonn Han, Joonseok Lee</dc:creator>
    </item>
    <item>
      <title>Efficient Recommendation with Millions of Items by Dynamic Pruning of Sub-Item Embeddings</title>
      <link>https://arxiv.org/abs/2505.00560</link>
      <description>arXiv:2505.00560v1 Announce Type: new 
Abstract: A large item catalogue is a major challenge for deploying modern sequential recommender models, since it makes the memory footprint of the model large and increases inference latency. One promising approach to address this is RecJPQ, which replaces item embeddings with sub-item embeddings. However, slow inference remains problematic because finding the top highest-scored items usually requires scoring all items in the catalogue, which may not be feasible for large catalogues. By adapting dynamic pruning concepts from document retrieval, we propose the RecJPQPrune dynamic pruning algorithm to efficiently find the top highest-scored items without computing the scores of all items in the catalogue. Our RecJPQPrune algorithm is safe-up-to-rank K since it theoretically guarantees that no potentially high-scored item is excluded from the final top K recommendation list, thereby ensuring no impact on effectiveness. Our experiments on two large datasets and three recommendation models demonstrate the efficiency achievable using RecJPQPrune: for instance, on the Tmall dataset with 2.2M items, we can reduce the median model scoring time by 64 times compared to the Transformer Default baseline, and 5.3 times compared to a recent scoring approach called PQTopK. Overall, this paper demonstrates the effective and efficient inference of Transformer-based recommendation models at catalogue scales not previously reported in the literature. Indeed, our RecJPQPrune algorithm can score 2 million items in under 10 milliseconds without GPUs, and without relying on Approximate Nearest Neighbour (ANN) techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00560v1</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3729963</arxiv:DOI>
      <dc:creator>Aleksandr V. Petrov, Craig Macdonald, Nicola Tonellotto</dc:creator>
    </item>
    <item>
      <title>Investigating Task Arithmetic for Zero-Shot Information Retrieval</title>
      <link>https://arxiv.org/abs/2505.00649</link>
      <description>arXiv:2505.00649v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown impressive zero-shot performance across a variety of Natural Language Processing tasks, including document re-ranking. However, their effectiveness degrades on unseen tasks and domains, largely due to shifts in vocabulary and word distributions. In this paper, we investigate Task Arithmetic, a technique that combines the weights of LLMs pre-trained on different tasks or domains via simple mathematical operations, such as addition or subtraction, to adapt retrieval models without requiring additional fine-tuning. Our method is able to synthesize diverse tasks and domain knowledge into a single model, enabling effective zero-shot adaptation in different retrieval contexts. Extensive experiments on publicly available scientific, biomedical, and multilingual datasets show that our method improves state-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in P@10. In addition to these empirical gains, our analysis provides insights into the strengths and limitations of Task Arithmetic as a practical strategy for zero-shot learning and model adaptation. We make our code publicly available at https://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00649v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3730216</arxiv:DOI>
      <dc:creator>Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi</dc:creator>
    </item>
    <item>
      <title>Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation</title>
      <link>https://arxiv.org/abs/2505.00028</link>
      <description>arXiv:2505.00028v1 Announce Type: cross 
Abstract: In recent years, end-to-end speech-to-speech (S2S) dialogue systems have garnered increasing research attention due to their advantages over traditional cascaded systems, including achieving lower latency and more natural integration of nonverbal cues such as emotion and speaker identity. However, these end-to-end systems face key challenges, particularly in incorporating external knowledge, a capability commonly addressed by Retrieval-Augmented Generation (RAG) in text-based large language models (LLMs). The core difficulty lies in the modality gap between input speech and retrieved textual knowledge, which hinders effective integration. To address this issue, we propose a novel end-to-end RAG framework that directly retrieves relevant textual knowledge from speech queries, eliminating the need for intermediate speech-to-text conversion via techniques like ASR. Experimental results demonstrate that our method significantly improves the performance of end-to-end S2S dialogue systems while achieving higher retrieval efficiency. Although the overall performance still lags behind cascaded models, our framework offers a promising direction for enhancing knowledge integration in end-to-end S2S systems. We will release the code and dataset to support reproducibility and promote further research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00028v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengchao Feng, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, Xie Chen</dc:creator>
    </item>
    <item>
      <title>Graph RAG for Legal Norms: A Hierarchical and Temporal Approach</title>
      <link>https://arxiv.org/abs/2505.00039</link>
      <description>arXiv:2505.00039v1 Announce Type: cross 
Abstract: This article proposes an adaptation of Graph Retrieval Augmented Generation (Graph RAG) specifically designed for the analysis and comprehension of legal norms, which are characterized by their predefined hierarchical structure, extensive network of internal and external references and multiple temporal versions. By combining structured knowledge graphs with contextually enriched text segments, Graph RAG offers a promising solution to address the inherent complexity and vast volume of legal data. The integration of hierarchical structure and temporal evolution into knowledge graphs - along with the concept of comprehensive Text Units - facilitates the construction of richer, interconnected representations of legal knowledge. Through a detailed analysis of Graph RAG and its application to legal norm datasets, this article aims to significantly advance the field of Artificial Intelligence applied to Law, creating opportunities for more effective systems in legal research, legislative analysis, and decision support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00039v1</guid>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hudson de Martim</dc:creator>
    </item>
    <item>
      <title>Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity</title>
      <link>https://arxiv.org/abs/2505.00056</link>
      <description>arXiv:2505.00056v1 Announce Type: cross 
Abstract: Meme clustering is critical for toxicity detection, virality modeling, and typing, but it has received little attention in previous research. Clustering similar Internet memes is challenging due to their multimodality, cultural context, and adaptability. Existing approaches rely on databases, overlook semantics, and struggle to handle diverse dimensions of similarity. This paper introduces a novel method that uses template-based matching with multi-dimensional similarity features, thus eliminating the need for predefined databases and supporting adaptive matching. Memes are clustered using local and global features across similarity categories such as form, visual content, text, and identity. Our combined approach outperforms existing clustering methods, producing more consistent and coherent clusters, while similarity-based feature sets enable adaptability and align with human intuition. We make all supporting code publicly available to support subsequent research. Code: https://github.com/tygobl/meme-clustering</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00056v1</guid>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICWSM 2025</arxiv:journal_reference>
      <dc:creator>Tygo Bloem, Filip Ilievski</dc:creator>
    </item>
    <item>
      <title>Leveraging LLMs for Influence Path Planning in Proactive Recommendation</title>
      <link>https://arxiv.org/abs/2409.04827</link>
      <description>arXiv:2409.04827v2 Announce Type: replace 
Abstract: Recommender systems are pivotal in Internet social platforms, yet they often cater to users' historical interests, leading to critical issues like echo chambers. To broaden user horizons, proactive recommender systems aim to guide user interest to gradually like a target item beyond historical interests through an influence path,i.e., a sequence of recommended items. As a representative, Influential Recommender System (IRS) designs a sequential model for influence path planning but faces issues of lacking target item inclusion and path coherence. To address the issues, we leverage the advanced planning capabilities of Large Language Models (LLMs) and propose an LLM-based Influence Path Planning (LLM-IPP) method. LLM-IPP generates coherent and effective influence paths by capturing user interest shifts and item characteristics. We introduce novel evaluation metrics and user simulators to benchmark LLM-IPP against traditional methods. Our experiments demonstrate that LLM-IPP significantly enhances user acceptability and path coherence, outperforming existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04827v2</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3701716.3715537</arxiv:DOI>
      <dc:creator>Mingze Wang, Shuxian Bi, Wenjie Wang, Chongming Gao, Yangyang Li, Fuli Feng</dc:creator>
    </item>
    <item>
      <title>Bridging Personalization and Control in Scientific Personalized Search</title>
      <link>https://arxiv.org/abs/2411.02790</link>
      <description>arXiv:2411.02790v2 Announce Type: replace 
Abstract: Personalized search is a problem where models benefit from learning user preferences from per-user historical interaction data. The inferred preferences enable personalized ranking models to improve the relevance of documents for users. However, personalization is also seen as opaque in its use of historical interactions and is not amenable to users' control. Further, personalization limits the diversity of information users are exposed to. While search results may be automatically diversified this does little to address the lack of control over personalization. In response, we introduce a model for personalized search that enables users to control personalized rankings proactively. Our model, CtrlCE, is a novel cross-encoder model augmented with an editable memory built from users' historical interactions. The editable memory allows cross-encoders to be personalized efficiently and enables users to control personalized ranking. Next, because all queries do not require personalization, we introduce a calibrated mixing model which determines when personalization is necessary. This enables users to control personalization via their editable memory only when necessary. To thoroughly evaluate CtrlCE, we demonstrate its empirical performance in four domains of science, its ability to selectively request user control in a calibration evaluation of the mixing model, and the control provided by its editable memory in a user study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02790v2</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3729913</arxiv:DOI>
      <dc:creator>Sheshera Mysore, Garima Dhanania, Kishor Patil, Surya Kallumadi, Andrew McCallum, Hamed Zamani</dc:creator>
    </item>
    <item>
      <title>Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking</title>
      <link>https://arxiv.org/abs/2501.18265</link>
      <description>arXiv:2501.18265v2 Announce Type: replace 
Abstract: Evaluating the truthfulness of online content is critical for combating misinformation. This study examines the efficiency and effectiveness of crowdsourced truthfulness assessments through a comparative analysis of two approaches: one involving full-length webpages as evidence for each claim, and another using summaries for each evidence document generated with a large language model. Using an A/B testing setting, we engage a diverse pool of participants tasked with evaluating the truthfulness of statements under these conditions. Our analysis explores both the quality of assessments and the behavioral patterns of participants. The results reveal that relying on summarized evidence offers comparable accuracy and error metrics to the Standard modality while significantly improving efficiency. Workers in the Summary setting complete a significantly higher number of assessments, reducing task duration and costs. Additionally, the Summary modality maximizes internal agreement and maintains consistent reliance on and perceived usefulness of evidence, demonstrating its potential to streamline large-scale truthfulness evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18265v2</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3729960</arxiv:DOI>
      <dc:creator>Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro</dc:creator>
    </item>
    <item>
      <title>Hypencoder: Hypernetworks for Information Retrieval</title>
      <link>https://arxiv.org/abs/2502.05364</link>
      <description>arXiv:2502.05364v2 Announce Type: replace 
Abstract: Existing information retrieval systems are largely constrained by their reliance on vector inner products to assess query-document relevance, which naturally limits the expressiveness of the relevance score they can produce. We propose a new paradigm; instead of representing a query as a vector, we use a small neural network that acts as a learned query-specific relevance function. This small neural network takes a document representation as input (in this work we use a single vector) and produces a scalar relevance score. To produce the small neural network we use a hypernetwork, a network that produces the weights of other networks, as our query encoder. We name this category of encoder models Hypencoders. Experiments on in-domain search tasks show that Hypencoders significantly outperform strong dense retrieval models and even surpass reranking models and retrieval models with an order of magnitude more parameters. To assess the extent of Hypencoders' capabilities, we evaluate on a set of hard retrieval tasks including tip-of-the-tongue and instruction-following retrieval tasks. On harder tasks, we find that the performance gap widens substantially compared to standard retrieval tasks. Furthermore, to demonstrate the practicality of our method, we implement an approximate search algorithm and show that our model is able to retrieve from a corpus of 8.8M documents in under 60 milliseconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05364v2</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Killingback, Hansi Zeng, Hamed Zamani</dc:creator>
    </item>
    <item>
      <title>Reproducing NevIR: Negation in Neural Information Retrieval</title>
      <link>https://arxiv.org/abs/2502.13506</link>
      <description>arXiv:2502.13506v3 Announce Type: replace 
Abstract: Negation is a fundamental aspect of human communication, yet it remains a challenge for Language Models (LMs) in Information Retrieval (IR). Despite the heavy reliance of modern neural IR systems on LMs, little attention has been given to their handling of negation. In this study, we reproduce and extend the findings of NevIR, a benchmark study that revealed most IR models perform at or below the level of random ranking when dealing with negation. We replicate NevIR's original experiments and evaluate newly developed state-of-the-art IR models. Our findings show that a recently emerging category-listwise Large Language Model (LLM) re-rankers-outperforms other models but still underperforms human performance. Additionally, we leverage ExcluIR, a benchmark dataset designed for exclusionary queries with extensive negation, to assess the generalisability of negation understanding. Our findings suggest that fine-tuning on one dataset does not reliably improve performance on the other, indicating notable differences in their data distributions. Furthermore, we observe that only cross-encoders and listwise LLM re-rankers achieve reasonable performance across both negation tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13506v3</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3730294</arxiv:DOI>
      <dc:creator>Coen van den Elsen, Francien Barkhof, Thijmen Nijdam, Simon Lupart, Mohammad Aliannejadi</dc:creator>
    </item>
    <item>
      <title>Process-Supervised LLM Recommenders via Flow-guided Tuning</title>
      <link>https://arxiv.org/abs/2503.07377</link>
      <description>arXiv:2503.07377v2 Announce Type: replace 
Abstract: While large language models (LLMs) are increasingly adapted for recommendation systems via supervised fine-tuning (SFT), this approach amplifies popularity bias due to its likelihood maximization objective, compromising recommendation diversity and fairness. To address this, we present Flow-guided fine-tuning recommender (Flower), which replaces SFT with a Generative Flow Network (GFlowNet) framework that enacts process supervision through token-level reward propagation. Flower's key innovation lies in decomposing item-level rewards into constituent token rewards, enabling direct alignment between token generation probabilities and their reward signals. This mechanism achieves three critical advancements: (1) popularity bias mitigation and fairness enhancement through empirical distribution matching, (2) preservation of diversity through GFlowNet's proportional sampling, and (3) flexible integration of personalized preferences via adaptable token rewards. Experiments demonstrate Flower's superior distribution-fitting capability and its significant advantages over traditional SFT in terms of accuracy, fairness, and diversity, highlighting its potential to improve LLM-based recommendation systems. The implementation is available via https://github.com/MrPeach0301/Flower</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07377v2</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chongming Gao, Mengyao Gao, Chenxiao Fan, Shuai Yuan, Wentao Shi, Xiangnan He</dc:creator>
    </item>
    <item>
      <title>KAP: MLLM-assisted OCR Text Enhancement for Hybrid Retrieval in Chinese Non-Narrative Documents</title>
      <link>https://arxiv.org/abs/2503.08452</link>
      <description>arXiv:2503.08452v3 Announce Type: replace 
Abstract: Hybrid Retrieval systems, combining Sparse and Dense Retrieval methods, struggle with Traditional Chinese non-narrative documents due to their complex formatting, rich vocabulary, and the insufficient understanding of Chinese synonyms by common embedding models. Previous approaches inadequately address the dual needs of these systems, focusing mainly on general text quality improvement rather than optimizing for retrieval. We propose Knowledge-Aware Preprocessing (KAP), a novel framework that transforms noisy OCR outputs into retrieval-optimized text. KAP adopts a two-stage approach: it first extracts text using OCR, then employs Multimodal Large Language Models to refine the output by integrating visual information from the original documents. This design reduces OCR noise, reconstructs structural elements, and formats the text to satisfy the distinct requirements of sparse and dense retrieval. Empirical results demonstrate that KAP consistently and significantly outperforms conventional preprocessing approaches. Our code is available at https://github.com/JustinHsu1019/KAP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08452v3</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hsin-Ling Hsu, Ping-Sheng Lin, Jing-Di Lin, Jengnan Tzeng</dc:creator>
    </item>
    <item>
      <title>DWTRec: An Efficient Wavelet Enhanced Model for Sequential Recommendation</title>
      <link>https://arxiv.org/abs/2503.23436</link>
      <description>arXiv:2503.23436v4 Announce Type: replace 
Abstract: Transformer-based sequential recommender systems have achieved notable successes. Despite their effectiveness, recent studies reveal that self-attention mechanism used in current Transformer-based sequential recommendation models is constantly a low-pass filter which results in several problems. These problems include being incompetent in learning evolving user patterns and capturing users' abrupt interests. To integrate low and high frequency information effectively and overcome these problems, we propose a novel Wavelet enhanced hybrid attention network called DWTRec for sequential recommendation. Due to excellent characteristics of Wavelet Transform in signal processing, we can perform fine-grained signals decomposition while removing noise and capturing trending signals behind non-stationary sequences of user-item interactions. To address the bound distortion problem of the reconstructed signal of Discrete Wavelet Transform, we design a learning algorithm which adapts to different datasets. Our findings suggest a promising approach to improve the modeling power of self-attention. We tested our method on six datasets with different domains, different sparsity levels, and different average sequence lengths. Experiments show that our method outperforms all eight baseline models in recommendation performance on all datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23436v4</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Lu, Mingxi Ge, Jiuyi Zhang, Wanli Zhu, Guanjin Li, Fangming Gu</dc:creator>
    </item>
    <item>
      <title>OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning</title>
      <link>https://arxiv.org/abs/2504.17811</link>
      <description>arXiv:2504.17811v2 Announce Type: replace 
Abstract: Representation learning, a task of learning latent vectors to represent entities, is a key task in improving search and recommender systems in web applications. Various representation learning methods have been developed, including graph-based approaches for relationships among entities, sequence-based methods for capturing the temporal evolution of user activities, and content-based models for leveraging text and visual content. However, the development of a unifying framework that integrates these diverse techniques to support multiple applications remains a significant challenge. This paper presents OmniSage, a large-scale representation framework that learns universal representations for a variety of applications at Pinterest. OmniSage integrates graph neural networks with content-based models and user sequence models by employing multiple contrastive learning tasks to effectively process graph data, user sequence data, and content signals. To support the training and inference of OmniSage, we developed an efficient infrastructure capable of supporting Pinterest graphs with billions of nodes. The universal representations generated by OmniSage have significantly enhanced user experiences on Pinterest, leading to an approximate 2.5% increase in sitewide repins (saves) across five applications. This paper highlights the impact of unifying representation learning methods, and we will open source the OmniSage code by the time of publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17811v2</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirudhan Badrinath, Alex Yang, Kousik Rajesh, Prabhat Agarwal, Jaewon Yang, Haoyu Chen, Jiajing Xu, Charles Rosenberg</dc:creator>
    </item>
    <item>
      <title>How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation</title>
      <link>https://arxiv.org/abs/2504.19489</link>
      <description>arXiv:2504.19489v4 Announce Type: replace 
Abstract: Recently, numerous community search methods for large graphs have been proposed, at the core of which is defining and measuring cohesion. This paper experimentally evaluates the effectiveness of these community search algorithms w.r.t. cohesiveness in the context of online social networks. Social communities are formed and developed under the influence of group cohesion theory, which has been extensively studied in social psychology. However, current generic methods typically measure cohesiveness using structural or attribute-based approaches and overlook domain-specific concepts such as group cohesion. We introduce five novel psychology-informed cohesiveness measures, based on the concept of group cohesion from social psychology, and propose a novel framework called CHASE for evaluating eight representative community search algorithms w.r.t. these measures on online social networks. Our analysis reveals that there is no clear correlation between structural and psychological cohesiveness, and no algorithm effectively identifies psychologically cohesive communities in online social networks. This study provides new insights that could guide the development of future community search methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19489v4</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3729997</arxiv:DOI>
      <dc:creator>Yining Zhao, Sourav S Bhowmick, Nastassja L. Fischer, SH Annabel Chen</dc:creator>
    </item>
    <item>
      <title>Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets</title>
      <link>https://arxiv.org/abs/2504.20119</link>
      <description>arXiv:2504.20119v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has advanced significantly in recent years. The complexity of RAG systems, which involve multiple components-such as indexing, retrieval, and generation-along with numerous other parameters, poses substantial challenges for systematic evaluation and quality enhancement. Previous research highlights that evaluating RAG systems is essential for documenting advancements, comparing configurations, and identifying effective approaches for domain-specific applications. This study systematically reviews 63 academic articles to provide a comprehensive overview of state-of-the-art RAG evaluation methodologies, focusing on four key areas: datasets, retrievers, indexing and databases, and the generator component. We observe the feasibility of an automated evaluation approach for each component of a RAG system, leveraging an LLM capable of both generating evaluation datasets and conducting evaluations. In addition, we found that further practical research is essential to provide companies with clear guidance on the do's and don'ts of implementing and evaluating RAG systems. By synthesizing evaluation approaches for key RAG components and emphasizing the creation and adaptation of domain-specific datasets for benchmarking, we contribute to the advancement of systematic evaluation methods and the improvement of evaluation rigor for RAG systems. Furthermore, by examining the interplay between automated approaches leveraging LLMs and human judgment, we contribute to the ongoing discourse on balancing automation and human input, clarifying their respective contributions, limitations, and challenges in achieving robust and reliable evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20119v2</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenz Brehme, Thomas Str\"ohle, Ruth Breu</dc:creator>
    </item>
    <item>
      <title>Natural Language Processing tools for Pharmaceutical Manufacturing Information Extraction from Patents</title>
      <link>https://arxiv.org/abs/2504.20598</link>
      <description>arXiv:2504.20598v2 Announce Type: replace 
Abstract: Abundant and diverse data on medicines manufacturing and other lifecycle components has been made easily accessible in the last decades. However, a significant proportion of this information is characterised by not being tabulated and usable for machine learning purposes. Thus, natural language processing tools have been used to build databases in domains such as biomedical and chemical to address this limitation. This has allowed the development of artificial intelligence applications, which have improved drug discovery and treatments. In the pharmaceutical manufacturing context, some initiatives and datasets for primary processing can be found, but the manufacturing of drug products is an area which is still lacking, to the best of our knowledge. This works aims to explore and adapt NLP tools used in other domains to extract information on both primary and secondary manufacturing, employing patents as the main source of data. Thus, two independent, but complementary, models were developed comprising a method to select fragments of text that contain manufacturing data, and a named entity recognition system that enables extracting information on operations, materials, and conditions of a process. For the first model, the identification of relevant sections was achieved using an unsupervised approach combining Latent Dirichlet Allocation and k-Means clustering. The performance of this model measured as a Cohen's kappa between model output and manual revision was higher than 90%. NER model consisted of a deep neural network, and an f1-score micro average of 84.2% was obtained which is comparable to other works. Some considerations for these tools to be used in data extraction are discussed throughout this document.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20598v2</guid>
      <category>cs.IR</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Diego Alvarado-Maldonado, Blair Johnston, Cameron J. Brown</dc:creator>
    </item>
  </channel>
</rss>
