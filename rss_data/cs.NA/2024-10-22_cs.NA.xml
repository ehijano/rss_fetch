<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Oct 2024 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Low-synchronization Arnoldi Methods for the Matrix Exponential with Application to Exponential Integrators</title>
      <link>https://arxiv.org/abs/2410.14917</link>
      <description>arXiv:2410.14917v1 Announce Type: new 
Abstract: High order exponential integrators require computing linear combination of exponential like $\varphi$-functions of large matrices $A$ times a vector $v$. Krylov projection methods are the most general and remain an efficient choice for computing the matrix-function-vector-product evaluation when the matrix is $A$ is large and unable to be explicitly stored, or when obtaining information about the spectrum is expensive. The Krylov approximation relies on the Gram-Schmidt (GS) orthogonalization procedure to produce the orthonormal basis $V_m$. In parallel, GS orthogonalization requires \textit{global synchronizations} for inner products and vector normalization in the orthogonalization process. Reducing the amount of global synchronizations is of paramount importance for the efficiency of a numerical algorithm in a massively parallel setting. We improve the parallel strong scaling properties of exponential integrators by addressing the underlying bottleneck in the linear algebra using low-synchronization GS methods. The resulting orthogonalization algorithms have an accuracy comparable to modified Gram-Schmidt yet are better suited for distributed architecture, as only one global communication is required per orthogonalization-step. We present geophysics-based numerical experiments and standard examples routinely used to test stiff time integrators, which validate that reducing global communication leads to better parallel scalability and reduced time-to-solution for exponential integrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14917v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanya Tafolla, St\'ephane Gaudreault, Mayya Tokman</dc:creator>
    </item>
    <item>
      <title>Nonconvex Robust Quaternion Matrix Completion for Imaging Processing</title>
      <link>https://arxiv.org/abs/2410.15006</link>
      <description>arXiv:2410.15006v1 Announce Type: new 
Abstract: One of the tasks in color image processing and computer vision is to recover clean data from partial observations corrupted by noise. To this end, robust quaternion matrix completion (QMC) has recently attracted more attention and shown its effectiveness, whose convex relaxation is to minimize the quaternion nuclear norm plus the quaternion $L_1$-norm. However, there is still room to improve due to the convexity of the convex surrogates. This paper proposes a new nonconvex robust QMC model, in which the nonconvex MCP function and the quaternion $L_p$-norm are used to enhance the low-rankness and sparseness of the low-rank term and sparse term, respectively. An alternating direction method of multipliers (ADMM) algorithm is developed to solve the proposed model and its convergence is given. Moreover, a novel nonlocal-self-similarity-based nonconvex robust quaternion completion method is proposed to handle large-scale data. Numerical results on color images and videos indicate the advantages of the proposed method over some existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15006v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baohua Huang, Jiakai Chen, Wen Li</dc:creator>
    </item>
    <item>
      <title>Parsimonious convolution quadrature</title>
      <link>https://arxiv.org/abs/2410.15079</link>
      <description>arXiv:2410.15079v1 Announce Type: new 
Abstract: We present a method to rapidly approximate convolution quadrature (CQ) approximations, based on a piecewise polynomial interpolation of the Laplace domain operator, which we call the \emph{parsimonious} convolution quadrature method. For implicit Euler and second order backward difference formula based discretizations, we require $O(\sqrt{N}\log N)$ evaluations in the Laplace domain to approximate $N$ time steps of the convolution quadrature method to satisfactory accuracy. The methodology proposed here differentiates from the well-understood fast and oblivious convolution quadrature \cite{SLL06}, since it is applicable to Laplace domain operator families that are only defined and polynomially bounded on a positive half space, which includes acoustic and electromagnetic wave scattering problems. The methods is applicable to linear and nonlinear integral equations. To elucidate the core idea, we give a complete and extensive analysis of the simplest case and derive worst-case estimates for the performance of parsimonious CQ based on the implicit Euler method. For sectorial Laplace transforms, we obtain methods that require $O(\log^2 N)$ Laplace domain evaluations on the complex right-half space. We present different implementation strategies, which only differ slightly from the classical realization of CQ methods. Numerical experiments demonstrate the use of the method with a time-dependent acoustic scattering problem, which was discretized by the boundary element method in space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15079v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens M. Melenk, J\"org Nick</dc:creator>
    </item>
    <item>
      <title>A Least-Squares-Based Neural Network (LS-Net) for Solving Linear Parametric PDEs</title>
      <link>https://arxiv.org/abs/2410.15089</link>
      <description>arXiv:2410.15089v1 Announce Type: new 
Abstract: Developing efficient methods for solving parametric partial differential equations is crucial for addressing inverse problems. This work introduces a Least-Squares-based Neural Network (LS-Net) method for solving linear parametric PDEs. It utilizes a separated representation form for the parametric PDE solution via a deep neural network and a least-squares solver. In this approach, the output of the deep neural network consists of a vector-valued function, interpreted as basis functions for the parametric solution space, and the least-squares solver determines the optimal solution within the constructed solution space for each given parameter. The LS-Net method requires a quadratic loss function for the least-squares solver to find optimal solutions given the set of basis functions. In this study, we consider loss functions derived from the Deep Fourier Residual and Physics-Informed Neural Networks approaches. We also provide theoretical results similar to the Universal Approximation Theorem, stating that there exists a sufficiently large neural network that can theoretically approximate solutions of parametric PDEs with the desired accuracy. We illustrate the LS-net method by solving one- and two-dimensional problems. Numerical results clearly demonstrate the method's ability to approximate parametric solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15089v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shima Baharlouei, Jamie M. Taylor, Carlos Uriarte, David Pardo</dc:creator>
    </item>
    <item>
      <title>A novel polyhedronal scaled boundary finite element method solving three-dimensional heat conduction problems</title>
      <link>https://arxiv.org/abs/2410.15331</link>
      <description>arXiv:2410.15331v1 Announce Type: new 
Abstract: In this work, we derived the three-dimensional scaled boundary finite element formulation for thermal conduction problems. By introducing Wachspress shape functions, we proposed a novel polyhedral scaled boundary finite element method (PSBFEM) to address thermal conduction problems. The proposed method effectively addresses the challenges associated with complex geometries by integrating the polyhedral mesh and the octree mesh. The presented formulation handles both steady-state and transient thermal conduction analyses. Through a series of numerical examples, the accuracy and convergence of the proposed method were validated. The results demonstrate that mesh refinement leads to superior accuracy for the PSBFEM compared to the FEM. Moreover, Polyhedral elements provide an effective and efficient approach for complex simulations that substantially reduces computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15331v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingjiao Yan, Yang Yang, Chao Su, Zongliang Zhang, Qingsong Duan, Dengmiao Hao</dc:creator>
    </item>
    <item>
      <title>Estimation of spectral gaps for sparse symmetric matrices</title>
      <link>https://arxiv.org/abs/2410.15349</link>
      <description>arXiv:2410.15349v1 Announce Type: new 
Abstract: In this paper we propose and analyze an algorithm for identifying spectral gaps of a real symmetric matrix $A$ by simultaneously approximating the traces of spectral projectors associated with multiple different spectral slices. Our method utilizes Hutchinson's stochastic trace estimator together with the Lanczos algorithm to approximate quadratic forms involving spectral projectors. Instead of focusing on determining the gap between two particular consecutive eigenvalues of $A$, we aim to find all gaps that are wider than a specified threshold. By examining the problem from this perspective, and thoroughly analyzing both the Hutchinson and the Lanczos components of the algorithm, we obtain error bounds that allow us to determine the numbers of Hutchinson's sample vectors and Lanczos iterations needed to ensure the detection of all gaps above the target width with high probability. In particular, we conclude that the most efficient strategy is to always use a single random sample vector for Hutchinson's estimator and concentrate all computational effort in the Lanczos algorithm. Our numerical experiments demonstrate the efficiency and reliability of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15349v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Benzi (Scuola Normale Superiore di Pisa), Michele Rinelli (KU Leuven), Igor Simunec (Scuola Normale Superiore di Pisa)</dc:creator>
    </item>
    <item>
      <title>Two Robust, Efficient, and optimally Accurate Algorithms for parameterized stochastic navier-stokes Flow Problems</title>
      <link>https://arxiv.org/abs/2410.15510</link>
      <description>arXiv:2410.15510v1 Announce Type: new 
Abstract: This paper presents and analyzes two robust, efficient, and optimally accurate fully discrete finite element algorithms for computing the parameterized Navier-Stokes Equations (NSEs) flow ensemble. The timestepping algorithms are linearized, use the backward-Euler method for approximating the temporal derivative, and Ensemble Eddy Viscosity (EEV) regularized. The first algorithm is a coupled ensemble scheme, and the second algorithm is decoupled using projection splitting with grad-div stabilization. We proved the stability and convergence theorems for both algorithms. We have shown that for sufficiently large grad-div stabilization parameters, the outcomes of the projection scheme converge to the outcomes of the coupled scheme. We then combine the Stochastic Collocation Methods (SCMs) with the proposed two Uncertainty Quantification (UQ) algorithms. A series of numerical experiments are given to verify the predicted convergence rates and performance of the schemes on benchmark problems, which shows the superiority of the splitting algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15510v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neethu Suma Raveendran, Md Abdul Aziz, Muhammad Mohebujjaman</dc:creator>
    </item>
    <item>
      <title>Convolution tensor decomposition for efficient high-resolution solutions to the Allen-Cahn equation</title>
      <link>https://arxiv.org/abs/2410.15519</link>
      <description>arXiv:2410.15519v1 Announce Type: new 
Abstract: This paper presents a convolution tensor decomposition based model reduction method for solving the Allen-Cahn equation. The Allen-Cahn equation is usually used to characterize phase separation or the motion of anti-phase boundaries in materials. Its solution is time-consuming when high-resolution meshes and large time scale integration are involved. To resolve these issues, the convolution tensor decomposition method is developed, in conjunction with a stabilized semi-implicit scheme for time integration. The development enables a powerful computational framework for high-resolution solutions of Allen-Cahn problems, and allows the use of relatively large time increments for time integration without violating the discrete energy law. To further improve the efficiency and robustness of the method, an adaptive algorithm is also proposed. Numerical examples have confirmed the efficiency of the method in both 2D and 3D problems. Orders-of-magnitude speedups were obtained with the method for high-resolution problems, compared to the finite element method. The proposed computational framework opens numerous opportunities for simulating complex microstructure formation in materials on large-volume high-resolution meshes at a deeply reduced computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15519v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Lu, Chaoqian Yuan, Han Guo</dc:creator>
    </item>
    <item>
      <title>Intrinsic Finite Element Error Analysis on Manifolds with Regge Metrics, with Applications to Calculating Connection Forms</title>
      <link>https://arxiv.org/abs/2410.15579</link>
      <description>arXiv:2410.15579v1 Announce Type: new 
Abstract: We present some aspects of the theory of finite element exterior calculus as applied to partial differential equations on manifolds, especially manifolds endowed with an approximate metric called a Regge metric. Our treatment is intrinsic, avoiding wherever possible the use of preferred coordinates or a preferred embedding into an ambient space, which presents some challenges but also conceptual and possibly computational advantages. As an application, we analyze and implement a method for computing an approximate Levi-Civita connection form for a disc whose metric is itself approximate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15579v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan S. Gawlik, Jack McKee</dc:creator>
    </item>
    <item>
      <title>Long-time Integration of Nonlinear Wave Equations with Neural Operators</title>
      <link>https://arxiv.org/abs/2410.15617</link>
      <description>arXiv:2410.15617v1 Announce Type: new 
Abstract: Neural operators have shown promise in solving many types of Partial Differential Equations (PDEs). They are significantly faster compared to traditional numerical solvers once they have been trained with a certain amount of observed data. However, their numerical performance in solving time-dependent PDEs, particularly in long-time prediction of dynamic systems, still needs improvement. In this paper, we focus on solving the long-time integration of nonlinear wave equations via neural operators by replacing the initial condition with the prediction in a recurrent manner. Given limited observed temporal trajectory data, we utilize some intrinsic features of these nonlinear wave equations, such as conservation laws and well-posedness, to improve the algorithm design and reduce accumulated error. Our numerical experiments examine these improvements in the Korteweg-de Vries (KdV) equation, the sine-Gordon equation, and a semilinear wave equation on the irregular domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15617v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanhang Lei, Zhen Lei, Lei Shi</dc:creator>
    </item>
    <item>
      <title>Interdependence between Green Financial Instruments and Major Conventional Assets: A Wavelet-Based Network Analysis</title>
      <link>https://arxiv.org/abs/2410.15751</link>
      <description>arXiv:2410.15751v1 Announce Type: new 
Abstract: This paper examines the interdependence between green financial instruments, represented by green bonds and green stocks, and a set of major conventional assets, such as Treasury, investment-grade and high-yield corporate bonds, general stocks, crude oil, and gold. To that end, a novel wavelet-based network approach that allows for assessing the degree of interconnection between green financial products and traditional asset classes across different investment horizons is applied. The~empirical results show that green bonds are tightly linked to Treasury and investment-grade corporate bonds, while green stocks are strongly tied to general stocks, regardless of the specific time period and investment horizon considered. However, despite their common climate-friendly nature, there is no a remarkable association between green bonds and green stocks. This means that these green investments constitute basically two independent asset classes, with a distinct risk-return profile and aimed at a different type of investor. Furthermore, green financial products have a weak connection with high-yield corporate bonds and crude oil. These findings can have important implications for investors and policy makers in terms of investment decision, hedging strategies, and sustainability and energy policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15751v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/math9080900</arxiv:DOI>
      <arxiv:journal_reference>Mathematics, 9 (2021), 900-919</arxiv:journal_reference>
      <dc:creator>Roman Ferrer, Rafael Benitez, Vicente J. Bolos</dc:creator>
    </item>
    <item>
      <title>Solving elliptic PDEs in unbounded domains</title>
      <link>https://arxiv.org/abs/2410.15850</link>
      <description>arXiv:2410.15850v1 Announce Type: new 
Abstract: An accurate approximation of solutions to elliptic problems in infinite domains is challenging from a computational point of view. This is due to the need to replace the infinite domain with a sufficiently large and bounded computational domain, and posing artificial boundary conditions on the boundary of the truncated computational geometry, which will then pollute the solution in an interior region of interest. For elliptic problems with periodically varying coefficients (with a possibly unknown period), a modelling strategy based on exponentially regularized elliptic problem was previously developed and analysed. The main idea was to replace the infinite domain periodic problem with a regularized elliptic problem posed over a finite domain, while retaining an accuracy decaying exponentially with respect to the size of the truncated domain. In this article, we extend the analysis to problems, where no structural assumptions on the coefficient are assumed. Moreover, the analysis here uncovers an interesting property of the right hand side in the Fourier domain for the method to converge fast for problems beyond periodicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15850v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Doghonay Arjmand, Filip Marttala</dc:creator>
    </item>
    <item>
      <title>Optimization of an eigenvalue arising in optimal insulation with a lower bound</title>
      <link>https://arxiv.org/abs/2410.16050</link>
      <description>arXiv:2410.16050v1 Announce Type: new 
Abstract: An eigenvalue problem arising in optimal insulation related to the minimization of the heat decay rate of an insulated body is adapted to enforce a positive lower bound imposed on the distribution of insulating material. We prove the existence of optimal domains among a class of convex shapes and propose a numerical scheme to approximate the eigenvalue. The stability of the shape optimization among convex, bounded domains in $\mathbb{R}^3$ is proven for an approximation with polyhedral domains under a non-conformal convexity constraint. We prove that on the ball, symmetry breaking of the optimal insulation can be expected in general. To observe how the lower bound affects the breaking of symmetry in the optimal insulation and the shape optimization, the eigenvalue and optimal domains are approximated for several values of mass $m$ and lower bounds $\ell_{\min}\ge0$. The numerical experiments suggest, that in general symmetry breaking still arises, unless $m$ is close to a critical value $m_0$, and $\ell_{\min}$ large enough such that almost all of the mass $m$ is fixed through the lower bound. For $\ell_{\min}=0$, the numerical results are consistent with previous numerical experiments on shape optimization restricted to rotationally symmetric, convex domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16050v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Bartels, Giuseppe Buttazzo, Hedwig Keller</dc:creator>
    </item>
    <item>
      <title>Denoising Hyperbolic-Valued Data by Relaxed Regularizations</title>
      <link>https://arxiv.org/abs/2410.16149</link>
      <description>arXiv:2410.16149v1 Announce Type: new 
Abstract: We introduce a novel relaxation strategy for denoising hyperbolic-valued data. The main challenge is here the non-convexity of the hyperbolic sheet. Instead of considering the denoising problem directly on the hyperbolic space, we exploit the Euclidean embedding and encode the hyperbolic sheet using a novel matrix representation. For denoising, we employ the Euclidean Tikhonov and total variation (TV) model, where we incorporate our matrix representation. The major contribution is then a convex relaxation of the variational ans\"atze allowing the utilization of well-established convex optimization procedures like the alternating directions method of multipliers (ADMM). The resulting denoisers are applied to a real-world Gaussian image processing task, where we simultaneously restore the pixelwise mean and standard deviation of a retina scan series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16149v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Beinert, Jonas Bresch</dc:creator>
    </item>
    <item>
      <title>Computing Inverses of Stieltjes Transforms of Probability Measures</title>
      <link>https://arxiv.org/abs/2410.16178</link>
      <description>arXiv:2410.16178v1 Announce Type: new 
Abstract: The Stieltjes (or sometimes called the Cauchy) transform is a fundamental object associated with probability measures, corresponding to the generating function of the moments. In certain applications such as free probability it is essential to compute the inverses of the Stieltjes transform, which might be multivalued. This paper establishes conditions bounding the number of inverses based on properties of the measure which can be combined with contour integral-based root finding algorithms to rigorously compute all inverses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16178v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Chen, Sheehan Olver</dc:creator>
    </item>
    <item>
      <title>Multifidelity Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2410.14764</link>
      <description>arXiv:2410.14764v1 Announce Type: cross 
Abstract: We develop a method for multifidelity Kolmogorov-Arnold networks (KANs), which use a low-fidelity model along with a small amount of high-fidelity data to train a model for the high-fidelity data accurately. Multifidelity KANs (MFKANs) reduce the amount of expensive high-fidelity data needed to accurately train a KAN by exploiting the correlations between the low- and high-fidelity data to give accurate and robust predictions in the absence of a large high-fidelity dataset. In addition, we show that multifidelity KANs can be used to increase the accuracy of physics-informed KANs (PIKANs), without the use of training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14764v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amanda A. Howard, Bruno Jacob, Panos Stinis</dc:creator>
    </item>
    <item>
      <title>Simultaneously Solving FBSDEs with Neural Operators of Logarithmic Depth, Constant Width, and Sub-Linear Rank</title>
      <link>https://arxiv.org/abs/2410.14788</link>
      <description>arXiv:2410.14788v1 Announce Type: cross 
Abstract: Forward-backwards stochastic differential equations (FBSDEs) are central in optimal control, game theory, economics, and mathematical finance. Unfortunately, the available FBSDE solvers operate on \textit{individual} FBSDEs, meaning that they cannot provide a computationally feasible strategy for solving large families of FBSDEs as these solvers must be re-run several times. \textit{Neural operators} (NOs) offer an alternative approach for \textit{simultaneously solving} large families of FBSDEs by directly approximating the solution operator mapping \textit{inputs:} terminal conditions and dynamics of the backwards process to \textit{outputs:} solutions to the associated FBSDE. Though universal approximation theorems (UATs) guarantee the existence of such NOs, these NOs are unrealistically large. We confirm that ``small'' NOs can uniformly approximate the solution operator to structured families of FBSDEs with random terminal time, uniformly on suitable compact sets determined by Sobolev norms, to any prescribed error $\varepsilon&gt;0$ using a depth of $\mathcal{O}(\log(1/\varepsilon))$, a width of $\mathcal{O}(1)$, and a sub-linear rank; i.e. $\mathcal{O}(1/\varepsilon^r)$ for some $r&lt;1$. This result is rooted in our second main contribution, which shows that convolutional NOs of similar depth, width, and rank can approximate the solution operator to a broad class of Elliptic PDEs. A key insight here is that the convolutional layers of our NO can efficiently encode the Green's function associated to the Elliptic PDEs linked to our FBSDEs. A byproduct of our analysis is the first theoretical justification for the benefit of lifting channels in NOs: they exponentially decelerate the growth rate of the NO's rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14788v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Furuya, Anastasis Kratsios</dc:creator>
    </item>
    <item>
      <title>A Scalable Interior-Point Gauss-Newton Method for PDE-Constrained Optimization with Bound Constraints</title>
      <link>https://arxiv.org/abs/2410.14918</link>
      <description>arXiv:2410.14918v1 Announce Type: cross 
Abstract: We present a scalable approach to solve a class of elliptic partial differential equation (PDE)-constrained optimization problems with bound constraints. This approach utilizes a robust full-space interior-point (IP)-Gauss-Newton optimization method. To cope with the poorly-conditioned IP-Gauss-Newton saddle-point linear systems that need to be solved, once per optimization step, we propose two spectrally related preconditioners. These preconditioners leverage the limited informativeness of data in regularized PDE-constrained optimization problems. A block Gauss-Seidel preconditioner is proposed for the GMRES-based solution of the IP-Gauss-Newton linear systems. It is shown, for a large-class of PDE- and bound-constrained optimization problems, that the spectrum of the block Gauss-Seidel preconditioned IP-Gauss-Newton matrix is asymptotically independent of discretization and is not impacted by the ill-conditioning that notoriously plagues interior-point methods. We propose a regularization and log-barrier Hessian preconditioner for the preconditioned conjugate gradient (PCG)-based solution of the related IP-Gauss-Newton-Schur complement linear systems. The scalability of the approach is demonstrated on an example problem with bound and nonlinear elliptic PDE constraints. The numerical solution of the optimization problem is shown to require a discretization independent number of IP-Gauss-Newton linear solves. Furthermore, the linear systems are solved in a discretization and IP ill-conditioning independent number of preconditioned Krylov subspace iterations. The parallel scalability of preconditioner and linear system matrix applies, achieved with algebraic multigrid based solvers, and the aforementioned algorithmic scalability permits a parallel scalable means to compute solutions of a large class of PDE- and bound-constrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14918v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tucker Hartland, Cosmin G. Petra, Noemi Petra, Jingyi Wang</dc:creator>
    </item>
    <item>
      <title>Extensions on low-complexity DCT approximations for larger blocklengths based on minimal angle similarity</title>
      <link>https://arxiv.org/abs/2410.15244</link>
      <description>arXiv:2410.15244v1 Announce Type: cross 
Abstract: The discrete cosine transform (DCT) is a central tool for image and video coding because it can be related to the Karhunen-Lo\`eve transform (KLT), which is the optimal transform in terms of retained transform coefficients and data decorrelation. In this paper, we introduce 16-, 32-, and 64-point low-complexity DCT approximations by minimizing individually the angle between the rows of the exact DCT matrix and the matrix induced by the approximate transforms. According to some classical figures of merit, the proposed transforms outperformed the approximations for the DCT already known in the literature. Fast algorithms were also developed for the low-complexity transforms, asserting a good balance between the performance and its computational cost. Practical applications in image encoding showed the relevance of the transforms in this context. In fact, the experiments showed that the proposed transforms had better results than the known approximations in the literature for the cases of 16, 32, and 64 blocklength.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15244v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>stat.ME</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11265-023-01848-w</arxiv:DOI>
      <arxiv:journal_reference>J Sign Process Syst 95, 495-516 (2023)</arxiv:journal_reference>
      <dc:creator>A. P. Rad\"unz, L. Portella, R. S. Oliveira, F. M. Bayer, R. J. Cintra</dc:creator>
    </item>
    <item>
      <title>All In: Give me your money!</title>
      <link>https://arxiv.org/abs/2410.15329</link>
      <description>arXiv:2410.15329v1 Announce Type: cross 
Abstract: We present a computer assisted proof for a result concerning a three player betting game, introduced by Angel and Holmes. The three players start with initial capital $x, y, z &gt; 0$ respectively. At each step of this game two players are selected at random to bet on the outcome of a fair coin toss, with the size of the bet being the largest possible, namely the total capital held by the poorer of the two players at that time. The main quantity of interest is the probability of player 1 being eliminated (reaching 0 capital) first. Angel and Holmes have shown that this probability is not monotone decreasing as a function of the initial capital $x$ of player 1. They conjecture that if $x &lt; y &lt; z$ then player 1 would be better off (less likely to be eliminated first) by swapping their capital with another player.
  In this paper we present a computer-assisted proof of this conjecture. To achieve this, we introduce the theoretical framework MeshItUp, and then perform a two-stage reduction to make MeshItUp computationally feasible, through the use of mixed-integer programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15329v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angel Y. He, Mark Holmes</dc:creator>
    </item>
    <item>
      <title>A hybrid quantum solver for the Lorenz system</title>
      <link>https://arxiv.org/abs/2410.15417</link>
      <description>arXiv:2410.15417v1 Announce Type: cross 
Abstract: We develop a hybrid classical-quantum method for solving the Lorenz system. We use the forward Euler method to discretize the system in time, transforming it into a system of equations. This set of equations is solved using the Variational Quantum Linear Solver (VQLS) algorithm. We present numerical results comparing the hybrid method with the classical approach for solving the Lorenz system. The simulation results demonstrate that the VQLS method can effectively compute solutions comparable to classical methods. The method is easily extended to solving similar nonlinear differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15417v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajad Fathi Hafshejani, Daya Gaur, Arundhati Dasgupta, Robert Benkoczi, Narasimha Gosala, Alfredo Iorio</dc:creator>
    </item>
    <item>
      <title>Rectangular finite elements for modeling the mechanical behavior of auxetic materials</title>
      <link>https://arxiv.org/abs/2410.15922</link>
      <description>arXiv:2410.15922v1 Announce Type: cross 
Abstract: This study explores the application of rectangular finite elements to model the stress-strain behavior of isotropic and orthotropic materials exhibiting negative Poisson's ratio, known as auxetic materials, under static shear conditions within linear elasticity. By employing the classical compatible shape functions for linear interpolation and the incompatible shape functions for quadratic interpolation within a displacement-based finite element framework, the research assesses the effectiveness of these approaches in capturing the mechanical response of auxetic materials. Additionally, the analytical expression for an incompatible rectangular finite element applicable to orthotropic materials is proposed. Hexachiral and re-entrant honeycomb structures, known for their auxetic behavior, are modeled as continuous media with homogenized properties using analytical expressions for their effective material constants. The findings reveal that while the classical shape functions may suffice for displacement modeling, they fall short in accurately predicting stress distributions in auxetic materials. In contrast, the incompatible shape functions demonstrate superior performance in providing appropriate stress and displacement predictions. This work underscores the relevance of using the incompatible rectangular finite elements in the modeling of advanced materials with a negative Poisson's ratio. It provides computationally efficient approaches for calculating auxetic honeycomb structures and their derived multilayer composites.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15922v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. V. Mazaev</dc:creator>
    </item>
    <item>
      <title>An Efficient Local Optimizer-Tracking Solver for Differential-Algebriac Equations with Optimization Criteria</title>
      <link>https://arxiv.org/abs/2410.15963</link>
      <description>arXiv:2410.15963v1 Announce Type: cross 
Abstract: A sequential solver for differential-algebraic equations with embedded optimization criteria (DAEOs) was developed to take advantage of the theoretical work done by Deussen et al. Solvers of this type separate the optimization problem from the differential equation and solve each individually. The new solver relies on the reduction of a DAEO to a sequence of differential inclusions separated by jump events. These jump events occur when the global solution to the optimization problem jumps to a new value. Without explicit treatment, these events will reduce the order of convergence of the integration step to one. The solver implements a "local optimizer tracking" procedure to detect and correct these jump events. Local optimizer tracking is much less expensive than running a deterministic global optimizer at every time step. This preserves the order of convergence of the integrator component without sacrificing performance to perform deterministic global optimization at every time step. The newly developed solver produces correct solutions to DAEOs and runs much faster than sequential DAEO solvers that rely only on global optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15963v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alexander Fleming, Jens Deussen, Uwe Naumann</dc:creator>
    </item>
    <item>
      <title>State Estimation Using Sparse DEIM and Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2410.15982</link>
      <description>arXiv:2410.15982v1 Announce Type: cross 
Abstract: Discrete Empirical Interpolation Method (DEIM) estimates a function from its pointwise incomplete observations. In particular, this method can be used to estimate the state of a dynamical system from observational data gathered by sensors. However, when the number of observations are limited, DEIM returns large estimation errors. Sparse DEIM (S-DEIM) was recently developed to address this problem by introducing a kernel vector which previous DEIM-based methods had ignored. Unfortunately, estimating the optimal kernel vector in S-DEIM is a difficult task. Here, we introduce a data-driven method to estimate this kernel vector from sparse observational time series using recurrent neural networks. Using numerical examples, we demonstrate that this machine learning approach together with S-DEIM leads to nearly optimal state estimations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15982v1</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>nlin.CD</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Farazmand</dc:creator>
    </item>
    <item>
      <title>A family of lattices with an unbounded number of unit vectors</title>
      <link>https://arxiv.org/abs/2410.16172</link>
      <description>arXiv:2410.16172v1 Announce Type: cross 
Abstract: A family of 4-dimensional lattices $L_k \subset \mathbb{R}^2$ is defined. Each lattice is defined by 2 quadratic extensions and has a \emph{finite} number of unit vectors, but the number of unit vectors in the family is \emph{unbounded}. $L_3$ is the Moser lattice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16172v1</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helmut Ruhland</dc:creator>
    </item>
    <item>
      <title>The Eigenvalue Problem for the Laplacian via Conformal Mapping and the Gohberg--Sigal Theory</title>
      <link>https://arxiv.org/abs/2112.11026</link>
      <description>arXiv:2112.11026v2 Announce Type: replace 
Abstract: We consider the Dirichlet and Neumann eigenvalues of the Laplacian for a planar, simply connected domain. The eigenvalues admit a characterization in terms of a layer potential of the Helmholtz equation. Using the exterior conformal mapping associated with the given domain, we reformulate the layer potential as an infinite-dimensional matrix. Based on this matrix representation, we develop a finite section approach for approximating the Laplacian eigenvalues and provide a convergence analysis by applying the Gohberg--Sigal theory for operator-valued functions. Moreover, we derive an asymptotic formula for the Laplacian eigenvalues on deformed domains that results from the changes in the conformal mapping coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.11026v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.SP</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Beceanu, Jiho Hong, Hyun-Kyoung Kwon, Mikyoung Lim</dc:creator>
    </item>
    <item>
      <title>Piecewise linear interpolation of noise in finite element approximations of parabolic SPDEs</title>
      <link>https://arxiv.org/abs/2210.11102</link>
      <description>arXiv:2210.11102v3 Announce Type: replace 
Abstract: Efficient simulation of stochastic partial differential equations (SPDE) on general domains requires noise discretization. This paper employs piecewise linear interpolation of noise in a fully discrete finite element approximation of a semilinear stochastic reaction-advection-diffusion equation on a convex polyhedral domain. The Gaussian noise is white in time, spatially correlated, and modeled as a standard cylindrical Wiener process on a reproducing kernel Hilbert space. This paper provides the first rigorous analysis of the resulting noise discretization error for a general spatial covariance kernel. The kernel is assumed to be defined on a larger regular domain, allowing for sampling by the circulant embedding method. The error bound under mild kernel assumptions requires non-trivial techniques like Hilbert--Schmidt bounds on products of finite element interpolants, entropy numbers of fractional Sobolev space embeddings and an error bound for interpolants in fractional Sobolev norms. Examples with kernels encountered in applications are illustrated in numerical simulations using the FEniCS finite element software. Key findings include: noise interpolation does not introduce additional errors for Mat\'ern kernels in $d\ge2$; there exist kernels that yield dominant interpolation errors; and generating noise on a coarser mesh does not always compromise accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11102v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Lord, Andreas Petersson</dc:creator>
    </item>
    <item>
      <title>Geometry Error Analysis of a parametric mapping for Higher Order Unfitted Space-Time Methods</title>
      <link>https://arxiv.org/abs/2311.02348</link>
      <description>arXiv:2311.02348v3 Announce Type: replace 
Abstract: In [Heimann, Lehrenfeld, Preu{\ss}, SIAM J. Sci. Comp. 45(2), 2023, B139 - B165] new geometrically unfitted space-time Finite Element methods for partial differential equations posed on moving domains of higher-order accuracy in space and time have been introduced. For geometrically higher-order accuracy a parametric mapping on a background space-time tensor-product mesh has been used. In this paper, we concentrate on the geometrical accuracy of the approximation and derive rigorous bounds for the distance between the realized and an ideal mapping in different norms and derive results for the space-time regularity of the parametric mapping. These results are important and lay the ground for the error analysis of corresponding unfitted space-time finite element methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02348v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Heimann, Christoph Lehrenfeld</dc:creator>
    </item>
    <item>
      <title>A data-dependent regularization method based on the graph Laplacian</title>
      <link>https://arxiv.org/abs/2312.16936</link>
      <description>arXiv:2312.16936v2 Announce Type: replace 
Abstract: We investigate a variational method for ill-posed problems, named $\texttt{graphLa+}\Psi$, which embeds a graph Laplacian operator in the regularization term. The novelty of this method lies in constructing the graph Laplacian based on a preliminary approximation of the solution, which is obtained using any existing reconstruction method $\Psi$ from the literature. As a result, the regularization term is both dependent on and adaptive to the observed data and noise. We demonstrate that $\texttt{graphLa+}\Psi$ is a regularization method and rigorously establish both its convergence and stability properties.
  We present selected numerical experiments in 2D computerized tomography, wherein we integrate the $\texttt{graphLa+}\Psi$ method with various reconstruction techniques $\Psi$, including Filter Back Projection ($\texttt{graphLa+FBP}$), standard Tikhonov ($\texttt{graphLa+Tik}$), Total Variation ($\texttt{graphLa+TV}$), and a trained deep neural network ($\texttt{graphLa+Net}$). The $\texttt{graphLa+}\Psi$ approach significantly enhances the quality of the approximated solutions for each method $\Psi$. Notably, $\texttt{graphLa+Net}$ is outperforming, offering a robust and stable application of deep neural networks in solving inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16936v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Bianchi, Davide Evangelista, Stefano Aleotti, Marco Donatelli, Elena Loli Piccolomini, Wenbin Li</dc:creator>
    </item>
    <item>
      <title>An RADI-type method for stochastic continuous-time algebraic Riccati equations</title>
      <link>https://arxiv.org/abs/2403.02940</link>
      <description>arXiv:2403.02940v2 Announce Type: replace 
Abstract: In this paper, we propose an RADI-type method for large-scale stochastic continuous-time algebraic Riccati equations with sparse and low-rank matrices. This new variant of RADI-type methods is developed by integrating the core concept of the original RADI method with the implicit appearance of the left semi-tensor product in stochastic continuous-time algebraic Riccati equations.The method employs different shifts to accelerate convergence and uses compression techniques to reduce storage requirements and computational complexity.Unlike many existing methods for large-scale problems such as Newton-type methods and homotopy method, it calculates the residual at a low cost and does not require a stabilizing initial approximation, which can often be challenging to find. Numerical experiments are provided to demonstrate its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02940v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen-Chen Guo, Xin Liang</dc:creator>
    </item>
    <item>
      <title>Mixed finite element methods for linear Cosserat equations</title>
      <link>https://arxiv.org/abs/2403.15136</link>
      <description>arXiv:2403.15136v3 Announce Type: replace 
Abstract: We consider the equilibrium equations for a linearized Cosserat material and provide two perspectives concerning well-posedness. First, the system can be viewed as the Hodge Laplace problem on a differential complex. On the other hand, we show how the Cosserat materials can be analyzed by inheriting results from linearized elasticity. Both perspectives give rise to mixed finite element methods, which we refer to as strongly and weakly coupled, respectively. We prove convergence of both classes of methods, with particular attention to improved convergence rate estimates, and stability in the limit of vanishing characteristic length of the micropolar structure. The theoretical results are fully reflected in the actual performance of the methods, as shown by the numerical verifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15136v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wietse Marijn Boon, Omar Duran, Jan Martin Nordbotten</dc:creator>
    </item>
    <item>
      <title>Reorthogonalized Pythagorean variants of block classical Gram-Schmidt</title>
      <link>https://arxiv.org/abs/2405.01298</link>
      <description>arXiv:2405.01298v3 Announce Type: replace 
Abstract: Block classical Gram-Schmidt (BCGS) is commonly used for orthogonalizing a set of vectors $X$ in distributed computing environments due to its favorable communication properties relative to other orthogonalization approaches, such as modified Gram-Schmidt or Householder. However, it is known that BCGS (as well as recently developed low-synchronization variants of BCGS) can suffer from a significant loss of orthogonality in finite-precision arithmetic, which can contribute to instability and inaccurate solutions in downstream applications such as $s$-step Krylov subspace methods. A common solution to improve the orthogonality among the vectors is reorthogonalization. Focusing on the "Pythagorean" variant of BCGS, introduced in [E. Carson, K. Lund, &amp; M. Rozlo\v{z}n\'{i}k. SIAM J. Matrix Anal. Appl. 42(3), pp. 1365--1380, 2021], which guarantees an $O(\varepsilon)\kappa^2(X)$ bound on the loss of orthogonality as long as $O(\varepsilon)\kappa^2(X)&lt;1$, where $\varepsilon$ denotes the unit roundoff, we introduce and analyze two reorthogonalized Pythagorean BCGS variants. These variants feature favorable communication properties, with asymptotically two synchronization points per block column, as well as an improved $O(\varepsilon)$ bound on the loss of orthogonality. Our bounds are derived in a general fashion to additionally allow for the analysis of mixed-precision variants. We verify our theoretical results with a panel of test matrices and experiments from a new version of the \texttt{BlockStab} toolbox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01298v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Carson, Kathryn Lund, Yuxin Ma, Eda Oktay</dc:creator>
    </item>
    <item>
      <title>An extrapolation-driven network architecture for physics-informed deep learning</title>
      <link>https://arxiv.org/abs/2406.12460</link>
      <description>arXiv:2406.12460v3 Announce Type: replace 
Abstract: Current PINN versions with sequential learning strategies have some weaknesses, such as the failure to reproduce the previous training results by a single network, the difficulty to strictly ensure continuity and smoothness at the time interval nodes by multiple networks, and the increase in complexity and computational overhead. To compensate for these shortcomings, we first investigate the extrapolation capability of the PINN method for time-dependent PDEs. Taking advantage of this extrapolation property, we can generalize the training result obtained in a specific time subinterval to larger intervals by adding a correction term to the network parameters of the subinterval. The correction term is determined by further training with the sample points in the added subinterval. Secondly, by designing an extrapolation control function with special characteristics and combining it with a correction term, we construct a new neural network architecture whose network parameters are coupled with the time variable, which we call the extrapolation-driven network architecture. Based on this architecture, using a single neural network, we can obtain the overall PINN solution of the whole domain with the following two characteristics: (1) it completely inherits the local solution of the interval obtained from the previous training, (2) at the interval node, it strictly maintains the continuity and smoothness that the true solution has. The extrapolation-driven network architecture allows us to divide a large time domain into multiple subintervals and solve the time-dependent PDEs one by one in a chronological order. This training scheme respects the causality principle and effectively overcomes the difficulties of the conventional PINN method in solving the evolution equation on a large time domain. Numerical experiments verify the performance of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12460v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Wang, Yanzhong Yao, Zhiming Gao</dc:creator>
    </item>
    <item>
      <title>Robust First and Second-Order Differentiation for Regularized Optimal Transport</title>
      <link>https://arxiv.org/abs/2407.02015</link>
      <description>arXiv:2407.02015v2 Announce Type: replace 
Abstract: Applications such as unbalanced and fully shuffled regression can be approached by optimizing regularized optimal transport (OT) distances, such as the entropic OT and Sinkhorn distances. A common approach for this optimization is to use a first-order optimizer, which requires the gradient of the OT distance. For faster convergence, one might also resort to a second-order optimizer, which additionally requires the Hessian. The computations of these derivatives are crucial for efficient and accurate optimization. However, they present significant challenges in terms of memory consumption and numerical instability, especially for large datasets and small regularization strengths. We circumvent these issues by analytically computing the gradients for OT distances and the Hessian for the entropic OT distance, which was not previously used due to intricate tensor-wise calculations and the complex dependency on parameters within the bi-level loss function. Through analytical derivation and spectral analysis, we identify and resolve the numerical instability caused by the singularity and ill-posedness of a key linear system. Consequently, we achieve scalable and stable computation of the Hessian, enabling the implementation of the stochastic gradient descent (SGD)-Newton methods. Tests on shuffled regression examples demonstrate that the second stage of the SGD-Newton method converges orders of magnitude faster than the gradient descent-only method while achieving significantly more accurate parameter estimations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02015v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xingjie Li, Fei Lu, Molei Tao, Felix X. -F. Ye</dc:creator>
    </item>
    <item>
      <title>Matrix perturbation bounds via contour bootstrapping</title>
      <link>https://arxiv.org/abs/2407.05230</link>
      <description>arXiv:2407.05230v4 Announce Type: replace 
Abstract: Matrix perturbation bounds play an essential role in the design and analysis of spectral algorithms. In this paper, we use a "contour bootstrapping" argument to derive several new perturbation bounds. As applications, we discuss new bounds on the error occurring when one uses matrix sparsification to speed up the computation of spectral parameters. Another potential application is the estimation of the trade-off in computing with privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05230v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Phuc Tran, Van Vu</dc:creator>
    </item>
    <item>
      <title>A novel direct Helmholtz solver in inhomogeneous media based on the operator Fourier transform functional calculus</title>
      <link>https://arxiv.org/abs/2407.09436</link>
      <description>arXiv:2407.09436v2 Announce Type: replace 
Abstract: This article presents novel numerical algorithms based on pseudodifferential operators for fast, direct, solution of the Helmholtz equation in 1D, 2D, and 3D inhomogeneous unbounded media. The proposed approach relies on an Operator Fourier Transform (OFT) representation of pseudodifferential operators ({\Psi}DO) which frame the problem of computing the inverse Helmholtz operator with a spatially-dependent wave speed in terms of two sequential applications of an inverse square root {\Psi}DO. The OFT representation of the action of the inverse square root {\Psi}DO, in turn, can be effected as a superposition of solutions of a pseudo-temporal initial-boundary-value problem for a paraxial equation. The OFT framework offers several advantages over traditional direct and iterative approaches for the solution of the Helmholtz equation. The operator integral transform is amenable to standard quadrature methods and the required pseudo-temporal paraxial equation solutions can be obtained using any suitable numerical method. A specialized quadrature is derived to evaluate the OFT efficiently and an alternating direction implicit method, used in conjunction with standard finite differences, is used to solve the requisite component paraxial equation problems. Numerical studies in 1D, 2D, and 3D are presented to confirm the expected OFT-based Helmholtz solver convergence rate. In addition, the efficiency and versatility of our proposed approach is demonstrated by tackling nontrivial wave propagation problems, including two-dimensional plane wave scattering from a geometrically complex inhomogeneity, three-dimensional scattering from turbulent channel flow and plane wave transmission through a spherically-symmetric gradient-index Luneburg lens. All computations, 3D problems which involve solving the Helmholtz equation with more than one billion complex unknowns, are performed in a single workstation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09436v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Cubillos, Edwin Jimenez</dc:creator>
    </item>
    <item>
      <title>A Flexible GMRES Solver with Reduced Order Model Enhanced Synthetic Acceleration Preconditioenr for Parametric Radiative Transfer Equation</title>
      <link>https://arxiv.org/abs/2410.08735</link>
      <description>arXiv:2410.08735v2 Announce Type: replace 
Abstract: Parametric radiative transfer equation (RTE) occurs in multi-query applications such as uncertainty quantification, inverse problems, and sensitivity analysis, which require solving RTE multiple times for a range of parameters. Consequently, efficient iterative solvers are highly desired.
  Classical Synthetic Acceleration (SA) preconditioners for RTE build on low order approximations to an ideal kinetic correction equation such as its diffusion limit in Diffusion Synthetic Acceleration (DSA). Their performance depends on the effectiveness of the underlying low order approximation. In addition, they do not leverage low rank structures with respect to the parameters of the parametric problem.
  To address these issues, we proposed a ROM-enhanced SA strategy, called ROMSAD, under the Source Iteration framework in Peng (2024). In this paper, we further extend the ROMSAD preconditioner to flexible general minimal residual method (FGMRES). The main new advancement is twofold. First, after identifying the ideal kinetic correction equation within the FGMRES framework, we reformulate it into an equivalent form, allowing us to develop an iterative procedure to construct a ROM for this ideal correction equation without directly solving it. Second, we introduce a greedy algorithm to build the underlying ROM for the ROMSAD preconditioner more efficiently.
  Our numerical examples demonstrate that FGMRES with the ROMSAD preconditioner (FGMRES-ROMSAD) is more efficient than GMRES with the right DSA preconditioner. Furthermore, when the underlying ROM in ROMSAD is not highly accurate, FGMRES-ROMSAD exhibits greater robustness compared to Source Iteration accelerated by ROMSAD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08735v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichao Peng</dc:creator>
    </item>
    <item>
      <title>A fully-decoupled second-order-in-time and unconditionally energy stable scheme for a phase-field model of two phase flow with variable density</title>
      <link>https://arxiv.org/abs/2410.10195</link>
      <description>arXiv:2410.10195v2 Announce Type: replace 
Abstract: In this paper, we develop a second-order, fully decoupled, and energy-stable numerical scheme for the Cahn-Hilliard-Navier-Stokes model for two phase flow with variable density and viscosity. We propose a new decoupling Constant Scalar Auxiliary Variable (D-CSAV) method which is easy to generalize to schemes with high order accuracy in time. The method is designed using the "zero-energy-contribution" property while maintaining conservative time discretization for the "non-zero-energy-contribution" terms. Our algorithm simplifies to solving three independent linear elliptic systems per time step, two of them with constant coefficients. The update of all scalar auxiliary variables is explicit and decoupled from solving the phase field variable and velocity field. We rigorously prove unconditional energy stability of the scheme and perform extensive benchmark simulations to demonstrate accuracy and efficiency of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10195v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinpeng Zhang, Li Luo, Xiaoping Wang</dc:creator>
    </item>
    <item>
      <title>Tensor Estimation with Nearly Linear Samples Given Weak Side Information</title>
      <link>https://arxiv.org/abs/2007.00736</link>
      <description>arXiv:2007.00736v3 Announce Type: replace-cross 
Abstract: Tensor completion exhibits an interesting computational-statistical gap in terms of the number of samples needed to perform tensor estimation. While there are only $\Theta(tn)$ degrees of freedom in a $t$-order tensor with $n^t$ entries, the best known polynomial time algorithm requires $O(n^{t/2})$ samples in order to guarantee consistent estimation. In this paper, we show that weak side information is sufficient to reduce the sample complexity to $O(n)$. The side information consists of a weight vector for each of the modes which is not orthogonal to any of the latent factors along that mode; this is significantly weaker than assuming noisy knowledge of the subspaces. We provide an algorithm that utilizes this side information to produce a consistent estimator with $O(n^{1+\kappa})$ samples for any small constant $\kappa &gt; 0$. We also provide experiments on both synthetic and real-world datasets that validate our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.00736v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christina Lee Yu, Xumei Xi</dc:creator>
    </item>
    <item>
      <title>A physics-informed neural network framework for modeling obstacle-related equations</title>
      <link>https://arxiv.org/abs/2304.03552</link>
      <description>arXiv:2304.03552v2 Announce Type: replace-cross 
Abstract: Deep learning has been highly successful in some applications. Nevertheless, its use for solving partial differential equations (PDEs) has only been of recent interest with current state-of-the-art machine learning libraries, e.g., TensorFlow or PyTorch. Physics-informed neural networks (PINNs) are an attractive tool for solving partial differential equations based on sparse and noisy data. Here extend PINNs to solve obstacle-related PDEs which present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of the solution that lies above a given obstacle. The performance of the proposed PINNs is demonstrated in multiple scenarios for linear and nonlinear PDEs subject to regular and irregular obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03552v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamid El Bahja, Jan Christian Hauffen, Peter Jung, Bubacarr Bah, Issa Karambal</dc:creator>
    </item>
    <item>
      <title>Exponential quantum advantages for practical non-Hermitian eigenproblems</title>
      <link>https://arxiv.org/abs/2401.12091</link>
      <description>arXiv:2401.12091v2 Announce Type: replace-cross 
Abstract: While non-Hermitian physics has attracted considerable attention, current studies are limited to small or classically solvable systems. Quantum computing, as a powerful eigensolver, have predominantly been applied to Hermitian domain, leaving their potential for studying non-Hermitian problems largely unexplored. We extend the power of quantum computing to general non-Hermitian eigenproblems. Our approach works for finding eigenvalues without extra constrains, or eigenvalues closest to specified points or lines, thus extending results for ground energy and energy gap problems for Hermitian matrices. Our algorithms have broad applications, and as examples, we consider two central problems in non-Hermitian physics. Firstly, our approach is the first to offer an efficient quantum solution to the witness of spontaneous $PT$-symmetry breaking, and provide provable, exponential quantum advantage. Secondly, our approach enables the estimation of Liouvillian gap, which is crucial for characterizing relaxation times. Our general approach can also find applications in many other areas, such as the study of Markovian stochastic processes. These results underscore the significance of our quantum algorithms for addressing practical eigenproblems across various disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12091v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Ming Zhang, Yukun Zhang, Wenhao He, Xiao Yuan</dc:creator>
    </item>
    <item>
      <title>Stochastic Rounding Implicitly Regularizes Tall-and-Thin Matrices</title>
      <link>https://arxiv.org/abs/2403.12278</link>
      <description>arXiv:2403.12278v2 Announce Type: replace-cross 
Abstract: Motivated by the popularity of stochastic rounding in the context of machine learning and the training of large-scale deep neural network models, we consider stochastic nearness rounding of real matrices $\mathbf{A}$ with many more rows than columns. We provide novel theoretical evidence, supported by extensive experimental evaluation that, with high probability, the smallest singular value of a stochastically rounded matrix is well bounded away from zero -- regardless of how close $\mathbf{A}$ is to being rank deficient and even if $\mathbf{A}$ is rank-deficient. In other words, stochastic rounding \textit{implicitly regularizes} tall and skinny matrices $\mathbf{A}$ so that the rounded version has full column rank. Our proofs leverage powerful results in random matrix theory, and the idea that stochastic rounding errors do not concentrate in low-dimensional column spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12278v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Dexter, Christos Boutsikas, Linkai Ma, Ilse C. F. Ipsen, Petros Drineas</dc:creator>
    </item>
    <item>
      <title>A Kernelizable Primal-Dual Formulation of the Multilinear Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2410.10504</link>
      <description>arXiv:2410.10504v2 Announce Type: replace-cross 
Abstract: The ability to express a learning task in terms of a primal and a dual optimization problem lies at the core of a plethora of machine learning methods. For example, Support Vector Machine (SVM), Least-Squares Support Vector Machine (LS-SVM), Ridge Regression (RR), Lasso Regression (LR), Principal Component Analysis (PCA), and more recently Singular Value Decomposition (SVD) have all been defined either in terms of primal weights or in terms of dual Lagrange multipliers. The primal formulation is computationally advantageous in the case of large sample size while the dual is preferred for high-dimensional data. Crucially, said learning problems can be made nonlinear through the introduction of a feature map in the primal problem, which corresponds to applying the kernel trick in the dual. In this paper we derive a primal-dual formulation of the Multilinear Singular Value Decomposition (MLSVD), which recovers as special cases both PCA and SVD. Besides enabling computational gains through the derived primal formulation, we propose a nonlinear extension of the MLSVD using feature maps, which results in a dual problem where a kernel tensor arises. We discuss potential applications in the context of signal analysis and deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10504v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederiek Wesel, Kim Batselier</dc:creator>
    </item>
  </channel>
</rss>
