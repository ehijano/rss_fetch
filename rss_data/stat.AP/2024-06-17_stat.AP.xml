<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2024 02:50:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lasso Multinomial Performance Indicators for in-play Basketball Data</title>
      <link>https://arxiv.org/abs/2406.09895</link>
      <description>arXiv:2406.09895v1 Announce Type: new 
Abstract: A typical approach to quantify the contribution of each player in basketball uses the plus/minus approach. Such plus/minus ratings are estimated using simple regression models and their regularised variants with response variable either the points scored or the point differences. To capture more precisely the effect of each player and the combined effects of specific lineups, more detailed possession-based play-by-play data are needed. This is the direction we take in this article, in which we investigate the performance of regularized adjusted plus/minus (RAPM) indicators estimated by different regularized models having as a response the number of points scored in each possession. Therefore, we use possession play-by-play data from all NBA games for the season 2021-22 (322,852 possessions). We initially present simple regression model-based indices starting from the implementation of ridge regression which is the standard technique in the relevant literature. We proceed with the lasso approach which has specific advantages and better performance than ridge regression when compared with selected objective validation criteria. Then, we implement regularized binary and multinomial logistic regression models to obtain more accurate performance indicators since the response is a discrete variable taking values mainly from zero to three. Our final proposal is an improved RAPM measure which is based on the expected points of a multinomial logistic regression model where each player's contribution is weighted by his participation in the team's possessions. The proposed indicator, called weighted expected points (wEPTS), outperforms all other RAPM measures we investigate in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09895v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argyro Damoulaki, Ioannis Ntzoufras, Konstantinos Pelechrinis</dc:creator>
    </item>
    <item>
      <title>Measure This, Not That: Optimizing the Cost and Model-Based Information Content of Measurements</title>
      <link>https://arxiv.org/abs/2406.09557</link>
      <description>arXiv:2406.09557v1 Announce Type: cross 
Abstract: Model-based design of experiments (MBDoE) is a powerful framework for selecting and calibrating science-based mathematical models from data. This work extends popular MBDoE workflows by proposing a convex mixed integer (non)linear programming (MINLP) problem to optimize the selection of measurements. The solver MindtPy is modified to support calculating the D-optimality objective and its gradient via an external package, \texttt{SciPy}, using the grey-box module in Pyomo. The new approach is demonstrated in two case studies: estimating highly correlated kinetics from a batch reactor and estimating transport parameters in a large-scale rotary packed bed for CO$_2$ capture. Both case studies show how examining the Pareto-optimal trade-offs between information content measured by A- and D-optimality versus measurement budget offers practical guidance for selecting measurements for scientific experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09557v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jialu Wang, Zedong Peng, Ryan Hughes, Debangsu Bhattacharyya, David E. Bernal Neira, Alexander W. Dowling</dc:creator>
    </item>
    <item>
      <title>Ridge Regression for Paired Comparisons: A Tractable New Approach, with Application to Premier League Football</title>
      <link>https://arxiv.org/abs/2406.09597</link>
      <description>arXiv:2406.09597v1 Announce Type: cross 
Abstract: Paired comparison models, such as Bradley-Terry and Thurstone-Mosteller, are commonly used to estimate relative strengths of pairwise compared items in tournament-style datasets. With predictive performance as primary criterion, we discuss estimation of paired comparison models with a ridge penalty. A new approach is derived which combines empirical Bayes and composite likelihoods without any need to re-fit the model, as a convenient alternative to cross-validation of the ridge tuning parameter. Simulation studies, together with application to 28 seasons of English Premier League football, demonstrate much better predictive accuracy of the new approach relative to ordinary maximum likelihood. While the application of a standard bias-reducing penalty was found to improve appreciably the performance of maximum likelihood, the ridge penalty with tuning as developed here yields greater accuracy still.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09597v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristiano Varin, David Firth</dc:creator>
    </item>
    <item>
      <title>Split-Apply-Combine with Dynamic Grouping</title>
      <link>https://arxiv.org/abs/2406.09887</link>
      <description>arXiv:2406.09887v1 Announce Type: cross 
Abstract: Partitioning a data set by one or more of its attributes and computing an aggregate for each part is one of the most common operations in data analyses. There are use cases where the partitioning is determined dynamically by collapsing smaller subsets into larger ones, to ensure sufficient support for the computed aggregate. These use cases are not supported by software implementing split-apply-combine types of operations. This paper presents the \texttt{R} package \texttt{accumulate} that offers convenient interfaces for defining grouped aggregation where the grouping itself is dynamically determined, based on user-defined conditions on subsets, and a user-defined subset collapsing scheme. The formal underlying algorithm is described and analyzed as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09887v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mark P. J. van der Loo</dc:creator>
    </item>
    <item>
      <title>Quantifying patient and neighborhood risks for stillbirth and preterm birth in Philadelphia with a Bayesian spatial model</title>
      <link>https://arxiv.org/abs/2105.04981</link>
      <description>arXiv:2105.04981v5 Announce Type: replace 
Abstract: Stillbirth and preterm birth are major public health challenges. Using a Bayesian spatial model, we quantified patient-specific and neighborhood risks of stillbirth and preterm birth in the city of Philadelphia. We linked birth data from electronic health records at Penn Medicine hospitals from 2010 to 2017 with census-tract-level data from the United States Census Bureau. We found that both patient-level characteristics (e.g. self-identified race/ethnicity) and neighborhood-level characteristics (e.g. violent crime) were significantly associated with patients' risk of stillbirth or preterm birth. Our neighborhood analysis found that higher-risk census tracts had 2.68 times the average risk of stillbirth and 2.01 times the average risk of preterm birth compared to lower-risk census tracts. Higher neighborhood rates of women in poverty or on public assistance were significantly associated with greater neighborhood risk for these outcomes, whereas higher neighborhood rates of college-educated women or women in the labor force were significantly associated with lower risk. Several of these neighborhood associations were missed by the patient-level analysis. These results suggest that neighborhood-level analyses of adverse pregnancy outcomes can reveal nuanced relationships and, thus, should be considered by epidemiologists. Our findings can potentially guide place-based public health interventions to reduce stillbirth and preterm birth rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.04981v5</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cecilia Balocchi, Ray Bai, Jessica Liu, Silvia P. Canel\'on, Edward I. George, Yong Chen, Mary R. Boland</dc:creator>
    </item>
    <item>
      <title>Estimating Changepoints in Extremal Dependence, Applied to Aviation Stock Prices During COVID-19 Pandemic</title>
      <link>https://arxiv.org/abs/2308.13895</link>
      <description>arXiv:2308.13895v2 Announce Type: replace 
Abstract: The dependence in the tails of the joint distribution of two random variables is generally assessed using $\chi$-measure, the limiting conditional probability of one variable being extremely high given the other variable is also extremely high. This work is motivated by the structural changes in $\chi$-measure between the daily rate of return (RoR) of the two Indian airlines, IndiGo and SpiceJet, during the COVID-19 pandemic. We model the daily maximum and minimum RoR vectors (potentially transformed) using the bivariate H\"usler-Reiss (BHR) distribution. To estimate the changepoint in the $\chi$-measure of the BHR distribution, we explore two changepoint detection procedures based on the Likelihood Ratio Test (LRT) and Modified Information Criterion (MIC). We obtain critical values and power curves of the LRT and MIC test statistics for low through high values of $\chi$-measure. We also explore the consistency of the estimators of the changepoint based on LRT and MIC numerically. In our data application, for RoR maxima and minima, the most prominent changepoints detected by LRT and MIC are close to the announcement of the first phases of lockdown and unlock, respectively, which are realistic; thus, our study would be beneficial for portfolio optimization in the case of future pandemic situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13895v2</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Hazra, Shiladitya Bose</dc:creator>
    </item>
    <item>
      <title>Another look at forecast trimming for combinations: robustness, accuracy and diversity</title>
      <link>https://arxiv.org/abs/2208.00139</link>
      <description>arXiv:2208.00139v2 Announce Type: replace-cross 
Abstract: Forecast combination is widely recognized as a preferred strategy over forecast selection due to its ability to mitigate the uncertainty associated with identifying a single "best" forecast. Nonetheless, sophisticated combinations are often empirically dominated by simple averaging, which is commonly attributed to the weight estimation error. The issue becomes more problematic when dealing with a forecast pool containing a large number of individual forecasts. In this paper, we propose a new forecast trimming algorithm to identify an optimal subset from the original forecast pool for forecast combination tasks. In contrast to existing approaches, our proposed algorithm simultaneously takes into account the robustness, accuracy and diversity issues of the forecast pool, rather than isolating each one of these issues. We also develop five forecast trimming algorithms as benchmarks, including one trimming-free algorithm and several trimming algorithms that isolate each one of the three key issues. Experimental results show that our algorithm achieves superior forecasting performance in general in terms of both point forecasts and prediction intervals. Nevertheless, we argue that diversity does not always have to be addressed in forecast trimming. Based on the results, we offer some practical guidelines on the selection of forecast trimming algorithms for a target series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.00139v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoqian Wang, Yanfei Kang, Feng Li</dc:creator>
    </item>
    <item>
      <title>A robust statistical framework for cyber-vulnerability prioritisation under partial information in threat intelligence</title>
      <link>https://arxiv.org/abs/2302.08348</link>
      <description>arXiv:2302.08348v4 Announce Type: replace-cross 
Abstract: Proactive cyber-risk assessment is gaining momentum due to the wide range of sectors that can benefit from the prevention of cyber-incidents by preserving integrity, confidentiality, and the availability of data. The rising attention to cybersecurity also results from the increasing connectivity of cyber-physical systems, which generates multiple sources of uncertainty about emerging cyber-vulnerabilities. This work introduces a robust statistical framework for quantitative and qualitative reasoning under uncertainty about cyber-vulnerabilities and their prioritisation. Specifically, we take advantage of mid-quantile regression to deal with ordinal risk assessments, and we compare it to current alternatives for cyber-risk ranking and graded responses. For this purpose, we identify a novel accuracy measure suited for rank invariance under partial knowledge of the whole set of existing vulnerabilities. The model is tested on both simulated and real data from selected databases that support the evaluation, exploitation, or response to cyber-vulnerabilities in realistic contexts. Such datasets allow us to compare multiple models and accuracy measures, discussing the implications of partial knowledge about cyber-vulnerabilities on threat intelligence and decision-making in operational scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08348v4</guid>
      <category>stat.ME</category>
      <category>cs.CR</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Angelelli, Serena Arima, Christian Catalano, Enrico Ciavolino</dc:creator>
    </item>
    <item>
      <title>What To Do (and Not to Do) with Causal Panel Analysis under Parallel Trends: Lessons from A Large Reanalysis Study</title>
      <link>https://arxiv.org/abs/2309.15983</link>
      <description>arXiv:2309.15983v3 Announce Type: replace-cross 
Abstract: Two-way fixed effects (TWFE) models are ubiquitous in causal panel analysis in political science. However, recent methodological discussions challenge their validity in the presence of heterogeneous treatment effects (HTE) and violations of the parallel trends assumption (PTA). This burgeoning literature has introduced multiple estimators and diagnostics, leading to confusion among empirical researchers on two fronts: the reliability of existing results based on TWFE models and the current best practices. To address these concerns, we examined, replicated, and reanalyzed 37 articles from three leading political science journals that employed observational panel data with binary treatments. Using six newly introduced HTE-robust estimators, along with diagnostics tests and uncertainty measures that are robust to PTA violations, we find that only a small minority of studies are highly robust. Although HTE-robust estimates tend to be broadly consistent with TWFE estimates, discrepancies in point estimates, increased measures of uncertainty, and potential PTA violations call into question many results that were already on the margins of statistical significance. We offer recommendations for improving practice in empirical research based on these findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15983v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Albert Chiu, Xingchen Lan, Ziyi Liu, Yiqing Xu</dc:creator>
    </item>
    <item>
      <title>Extreme value methods for estimating rare events in Utopia</title>
      <link>https://arxiv.org/abs/2312.09825</link>
      <description>arXiv:2312.09825v2 Announce Type: replace-cross 
Abstract: To capture the extremal behaviour of complex environmental phenomena in practice, flexi\-ble techniques for modelling tail behaviour are required. In this paper, we introduce a variety of such methods, which were used by the Lancopula Utopiversity team to tackle the EVA (2023) Conference Data Challenge. This data challenge was split into four challenges, labelled C1-C4. Challenges C1 and C2 comprise univariate problems, where the goal is to estimate extreme quantiles for a non-stationary time series exhibiting several complex features. For these, we propose a flexible modelling technique, based on generalised additive models, with diagnostics indicating generally good performance for the observed data. Challenges C3 and C4 concern multivariate problems where the focus is on estimating joint extremal probabilities. For challenge C3, we propose an extension of available models in the multivariate literature and use this framework to estimate extreme probabilities in the presence of non-stationary dependence. Finally, for challenge C4, which concerns a 50 dimensional random vector, we employ a clustering technique to achieve dimension reduction and use a conditional modelling approach to estimate extremal probabilities across independent groups of variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09825v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L. M. Andr\'e, R. Campbell, E. D'Arcy, A. Farrell, D. Healy, L. Kakampakou, C. Murphy, C. J. R. Murphy-Barltrop, M. Speers</dc:creator>
    </item>
    <item>
      <title>Browsing behavior exposes identities on the Web</title>
      <link>https://arxiv.org/abs/2312.15489</link>
      <description>arXiv:2312.15489v2 Announce Type: replace-cross 
Abstract: How easy is it to uniquely identify a person based solely on their web browsing behavior? Here we show that when people navigate the Web, their online traces produce fingerprints that identify them. Merely the four most visited web domains are enough to identify 95% of the individuals. These digital fingerprints are stable and render high re-identifiability. We demonstrate that we can re-identify 80% of the individuals in separate time slices of data. Such a privacy threat persists even with limited information about individuals' browsing behavior, reinforcing existing concerns around online privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15489v2</guid>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcos Oliveira, Junran Yang, Daniel Griffiths, Denis Bonnay, Juhi Kulshrestha</dc:creator>
    </item>
  </channel>
</rss>
