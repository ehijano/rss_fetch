<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Apr 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Language Generation in the Limit</title>
      <link>https://arxiv.org/abs/2404.06757</link>
      <description>arXiv:2404.06757v1 Announce Type: new 
Abstract: Although current large language models are complex, the most basic specifications of the underlying language generation problem itself are simple to state: given a finite set of training samples from an unknown language, produce valid new strings from the language that don't already appear in the training data. Here we ask what we can conclude about language generation using only this specification, without further assumptions. In particular, suppose that an adversary enumerates the strings of an unknown target language L that is known only to come from one of a possibly infinite list of candidates. A computational agent is trying to learn to generate from this language; we say that the agent generates from L in the limit if after some finite point in the enumeration of L, the agent is able to produce new elements that come exclusively from L and that have not yet been presented by the adversary. Our main result is that there is an agent that is able to generate in the limit for every countable list of candidate languages. This contrasts dramatically with negative results due to Gold and Angluin in a well-studied model of language learning where the goal is to identify an unknown language from samples; the difference between these results suggests that identifying a language is a fundamentally different problem than generating from it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06757v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jon Kleinberg, Sendhil Mullainathan</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic Correlation Clustering: Breaking 3-Approximation</title>
      <link>https://arxiv.org/abs/2404.06797</link>
      <description>arXiv:2404.06797v1 Announce Type: new 
Abstract: We study the classic correlation clustering in the dynamic setting. Given $n$ objects and a complete labeling of the object-pairs as either similar or dissimilar, the goal is to partition the objects into arbitrarily many clusters while minimizing disagreements with the labels. In the dynamic setting, an update consists of a flip of a label of an edge. In a breakthrough result, [BDHSS, FOCS'19] showed how to maintain a 3-approximation with polylogarithmic update time by providing a dynamic implementation of the \pivot{} algorithm of [ACN, STOC'05]. Since then, it has been a major open problem to determine whether the 3-approximation barrier can be broken in the fully dynamic setting. In this paper, we resolve this problem. Our algorithm, \modifiedpivot{}, locally improves the output of \pivot{} by moving some vertices to other existing clusters or new singleton clusters. We present an analysis showing that this modification does indeed improve the approximation to below 3. We also show that its output can be maintained in polylogarithmic time per update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06797v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soheil Behnezhad, Moses Charikar, Vincent Cohen-Addad, Alma Ghafari, Weiyun Ma</dc:creator>
    </item>
    <item>
      <title>An asymptotically optimal algorithm for generating bin cardinalities</title>
      <link>https://arxiv.org/abs/2404.07011</link>
      <description>arXiv:2404.07011v1 Announce Type: new 
Abstract: In the balls-into-bins setting, $n$ balls are thrown uniformly at random into $n$ bins. The na\"{i}ve way to generate the final load vector takes $\Theta(n)$ time. However, it is well-known that this load vector has with high probability bin cardinalities of size $\Theta(\frac{\log n}{\log \log n})$. Here, we present an algorithm in the RAM model that generates the bin cardinalities of the final load vector in the optimal $\Theta(\frac{\log n}{\log \log n})$ time in expectation and with high probability.
  Further, the algorithm that we present is still optimal for any $m \in [n, n \log n]$ balls and can also be used as a building block to efficiently simulate more involved load balancing algorithms. In particular, for the Two-Choice algorithm, which samples two bins in each step and allocates to the least-loaded of the two, we obtain roughly a quadratic speed-up over the na\"{i}ve simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07011v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luc Devroye, Dimitrios Los</dc:creator>
    </item>
    <item>
      <title>Exploring Repetitiveness Measures for Two-Dimensional Strings</title>
      <link>https://arxiv.org/abs/2404.07030</link>
      <description>arXiv:2404.07030v1 Announce Type: new 
Abstract: Detecting and measuring repetitiveness of strings is a problem that has been extensively studied in data compression and text indexing. However, when the data are structured in a non-linear way, like in the context of two-dimensional strings, inherent redundancy offers a rich source for compression, yet systematic studies on repetitiveness measures are still lacking. In the paper we introduce extensions of repetitiveness measures to general two-dimensional strings. In particular, we propose a new extension of the measures $\delta$ and $\gamma$, diverging from previous square based definitions proposed in [Carfagna and Manzini, SPIRE 2023]. We further consider generalizations of macro schemes and straight line programs for the 2D setting and show that, in contrast to what happens on strings, 2D macro schemes and 2D SLPs can be both asymptotically smaller than $\delta$ and $\gamma$. The results of the paper can be easily extended to $d$-dimensional strings with $d &gt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07030v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Romana, Marinella Sciortino, Cristian Urbina</dc:creator>
    </item>
    <item>
      <title>Computing the $D$-base and $D$-relation in finite closure systems</title>
      <link>https://arxiv.org/abs/2404.07037</link>
      <description>arXiv:2404.07037v1 Announce Type: new 
Abstract: Implicational bases (IBs) are a common representation of finite closure systems and lattices, along with meet-irreducible elements. They appear in a wide variety of fields ranging from logic and databases to Knowledge Space Theory. Different IBs can represent the same closure system. Therefore, several IBs have been studied, such as the canonical and canonical direct bases. In this paper, we investigate the $D$-base, a refinement of the canonical direct base. It is connected with the $D$-relation, an essential tool in the study of free lattices. The $D$-base demonstrates desirable algorithmic properties, and together with the $D$-relation, it conveys essential properties of the underlying closure system. Hence, computing the $D$-base and the $D$-relation of a closure system from another representation is crucial to enjoy its benefits. However, complexity results for this task are lacking. In this paper, we give algorithms and hardness results for the computation of the $D$-base and $D$-relation. Specifically, we establish the $NP$-completeness of finding the $D$-relation from an arbitrary IB; we give an output-quasi-polynomial time algorithm to compute the $D$-base from meet-irreducible elements; and we obtain a polynomial-delay algorithm computing the $D$-base from an arbitrary IB. These results complete the picture regarding the complexity of identifying the $D$-base and $D$-relation of a closure system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07037v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kira Adaricheva, Lhouari Nourine, Simon Vilmin</dc:creator>
    </item>
    <item>
      <title>Generalized Straight-Line Programs</title>
      <link>https://arxiv.org/abs/2404.07057</link>
      <description>arXiv:2404.07057v1 Announce Type: new 
Abstract: It was recently proved that any Straight-Line Program (SLP) generating a given string can be transformed in linear time into an equivalent balanced SLP of the same asymptotic size. We generalize this proof to a general class of grammars we call Generalized SLPs (GSLPs), which allow rules of the form $A \rightarrow x$ where $x$ is any Turing-complete representation (of size $|x|$) of a sequence of symbols (potentially much longer than $|x|$). We then specialize GSLPs to so-called Iterated SLPs (ISLPs), which allow rules of the form $A \rightarrow \Pi_{i=k_1}^{k_2} B_1^{i^{c_1}}\cdots B_t^{i^{c_t}}$ of size $2t+2$. We prove that ISLPs break, for some text families, the measure $\delta$ based on substring complexity, a lower bound for most measures and compressors exploiting repetitiveness. Further, ISLPs can extract any substring of length $\lambda$, from the represented text $T[1.. n]$, in time $O(\lambda + \log^2 n\log\log n)$. This is the first compressed representation for repetitive texts breaking $\delta$ while, at the same time, supporting direct access to arbitrary text symbols in polylogarithmic time. We also show how to compute some substring queries, like range minima and next/previous smaller value, in time $O(\log^2 n \log\log n)$. Finally, we further specialize the grammars to Run-Length SLPs (RLSLPs), which restrict the rules allowed by ISLPs to the form $A \rightarrow B^t$. Apart from inheriting all the previous results with the term $\log^2 n \log\log n$ reduced to the near-optimal $\log n$, we show that RLSLPs can exploit balance to efficiently compute a wide class of substring queries we call ``composable'' -- i.e., $f(X \cdot Y)$ can be obtained from $f(X)$ and $f(Y)$...</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07057v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gonzalo Navarro, Francisco Olivares, Cristian Urbina</dc:creator>
    </item>
    <item>
      <title>On Bounds for Greedy Schemes in String Optimization based on Greedy Curvatures</title>
      <link>https://arxiv.org/abs/2404.06669</link>
      <description>arXiv:2404.06669v1 Announce Type: cross 
Abstract: We consider the celebrated bound introduced by Conforti and Cornu\'ejols (1984) for greedy schemes in submodular optimization. The bound assumes a submodular function defined on a collection of sets forming a matroid and is based on greedy curvature. We show that the bound holds for a very general class of string problems that includes maximizing submodular functions over set matroids as a special case. We also derive a bound that is computable in the sense that they depend only on quantities along the greedy trajectory. We prove that our bound is superior to the greedy curvature bound of Conforti and Cornu\'ejols. In addition, our bound holds under a condition that is weaker than submodularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06669v1</guid>
      <category>eess.SY</category>
      <category>cs.DS</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bowen Li, Brandon Van Over, Edwin K. P. Chong, Ali Pezeshki</dc:creator>
    </item>
    <item>
      <title>A Reexamination of the COnfLUX 2.5D LU Factorization Algorithm</title>
      <link>https://arxiv.org/abs/2404.06713</link>
      <description>arXiv:2404.06713v1 Announce Type: cross 
Abstract: This article conducts a reexamination of the research conducted by Kwasniewski et al., focusing on their adaptation of the 2.5D LU factorization algorithm with tournament pivoting, known as \func{COnfLUX}. Our reexamination reveals potential concerns regarding the upper bound, empirical investigation methods, and lower bound, despite the original study providing a theoretical foundation and an instantiation of the proposed algorithm. This paper offers a reexamination of these matters, highlighting probable shortcomings in the original investigation. Our observations are intended to enhance the development and comprehension of parallel matrix factorization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06713v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Tang</dc:creator>
    </item>
    <item>
      <title>Gradient Descent is Pareto-Optimal in the Oracle Complexity and Memory Tradeoff for Feasibility Problems</title>
      <link>https://arxiv.org/abs/2404.06720</link>
      <description>arXiv:2404.06720v1 Announce Type: cross 
Abstract: In this paper we provide oracle complexity lower bounds for finding a point in a given set using a memory-constrained algorithm that has access to a separation oracle. We assume that the set is contained within the unit $d$-dimensional ball and contains a ball of known radius $\epsilon&gt;0$. This setup is commonly referred to as the feasibility problem. We show that to solve feasibility problems with accuracy $\epsilon \geq e^{-d^{o(1)}}$, any deterministic algorithm either uses $d^{1+\delta}$ bits of memory or must make at least $1/(d^{0.01\delta }\epsilon^{2\frac{1-\delta}{1+1.01 \delta}-o(1)})$ oracle queries, for any $\delta\in[0,1]$. Additionally, we show that randomized algorithms either use $d^{1+\delta}$ memory or make at least $1/(d^{2\delta} \epsilon^{2(1-4\delta)-o(1)})$ queries for any $\delta\in[0,\frac{1}{4}]$. Because gradient descent only uses linear memory $\mathcal O(d\ln 1/\epsilon)$ but makes $\Omega(1/\epsilon^2)$ queries, our results imply that it is Pareto-optimal in the oracle complexity/memory tradeoff. Further, our results show that the oracle complexity for deterministic algorithms is always polynomial in $1/\epsilon$ if the algorithm has less than quadratic memory in $d$. This reveals a sharp phase transition since with quadratic $\mathcal O(d^2 \ln1/\epsilon)$ memory, cutting plane methods only require $\mathcal O(d\ln 1/\epsilon)$ queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06720v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moise Blanchard</dc:creator>
    </item>
    <item>
      <title>Compact enumeration for scheduling one machine</title>
      <link>https://arxiv.org/abs/2103.09900</link>
      <description>arXiv:2103.09900v4 Announce Type: replace 
Abstract: A Variable Parameter (VP) analysis aims to give precise time complexity expressions of algorithms with exponents appearing solely in terms of variable parameters. A variable parameter is the number of objects with specific properties. Here we describe two VP-algorithms, an implicit enumeration and a polynomial-time approximation scheme for a strongly $NP$-hard problem of scheduling $n$ independent jobs with release and due times on one machine to minimize the maximum job completion time $C_{\max}$. Thus variable parameters are amounts of some specially defined types of jobs. A partial solution without these jobs is constructed in a low degree polynomial time, and an exponential time (in the number of variable parameters) procedure is carried out to augment this solution to a complete optimal solution. We also give alternative time complexity expressions, where the exponential dependence is solely on some job parameters. Applying the fixed parameter analysis to these estimations, unexpectedly, we obtain a polynomial-time dependence. Both, intuitive probabilistic estimations and our extensive experimental study support our conjecture that the total number of the variable parameters is far less than $n$ and its ratio to $n$ asymptotically converges to 0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.09900v4</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nodari Vakhania</dc:creator>
    </item>
    <item>
      <title>DAG-Inducing Problems and Algorithms</title>
      <link>https://arxiv.org/abs/2302.14834</link>
      <description>arXiv:2302.14834v3 Announce Type: replace 
Abstract: Consider the execution of a sequential algorithm that requires the program to converge to an optimal state, and then terminate/stutter. To design such an algorithm, we need to ensure that the state space that it traverses forms a directed acyclic graph (DAG) and its sink nodes are optimal states. However, if we run the same algorithm on multiple computing nodes running in parallel, and without synchronization, it may not reach an optimal state. In most parallel processing algorithms designed in the literature, a synchronization primitive is assumed. Synchronization ensures that the nodes read fresh value, and the execution proceeds systematically, such that the subject algorithm traverses a DAG induced among the global states.
  With this observation, we investigate the conditions that guarantee that the execution of an algorithm is correct even if it is executed in parallel and without synchronization. To this end, we introduce DAG-inducing problems and DAG-inducing algorithms. We show that induction of a $\prec$-DAG (induced among the global states -- that forms as a result of a partial order induced among the local states visited by individual nodes) is a necessary and sufficient condition to allow an algorithm to run in asynchrony.
  In the paper, we first give a comprehensive description of DAG-inducing problems and DAG-inducing algorithms, along with some simple examples. Then we show some properties of an algorithm that is tolerant to asynchrony, which include the above-mentioned condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14834v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arya Tanmay Gupta, Sandeep S Kulkarni</dc:creator>
    </item>
    <item>
      <title>Universal Optimality of Dijkstra via Beyond-Worst-Case Heaps</title>
      <link>https://arxiv.org/abs/2311.11793</link>
      <description>arXiv:2311.11793v2 Announce Type: replace 
Abstract: This paper proves that Dijkstra's shortest-path algorithm is universally optimal in both its running time and number of comparisons when combined with a sufficiently efficient heap data structure.
  Universal optimality is a powerful beyond-worst-case performance guarantee for graph algorithms that informally states that a single algorithm performs as well as possible for every single graph topology. We give the first application of this notion to any sequential algorithm.
  We design a new heap data structure with a working-set property guaranteeing that the heap takes advantage of locality in heap operations. Our heap matches the optimal (worst-case) bounds of Fibonacci heaps but also provides the beyond-worst-case guarantee that the cost of extracting the minimum element is merely logarithmic in the number of elements inserted after it instead of logarithmic in the number of all elements in the heap. This makes the extraction of recently added elements cheaper.
  We prove that our working-set property is sufficient to guarantee universal optimality, specifically, for the problem of ordering vertices by their distance from the source vertex: The locality in the sequence of heap operations generated by any run of Dijkstra's algorithm on a fixed topology is strong enough that one can couple the number of comparisons performed by any heap with our working-set property to the minimum number of comparisons required to solve the distance ordering problem on this topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11793v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Haeupler, Richard Hlad\'ik, V\'aclav Rozho\v{n}, Robert Tarjan, Jakub T\v{e}tek</dc:creator>
    </item>
    <item>
      <title>A Threshold Greedy Algorithm for Noisy Submodular Maximization</title>
      <link>https://arxiv.org/abs/2312.00155</link>
      <description>arXiv:2312.00155v2 Announce Type: replace 
Abstract: We consider the maximization of a submodular objective function $f:2^U\to\mathbb{R}_{\geq 0}$, where the objective $f$ is not accessed as a value oracle but instead subject to noisy queries. We introduce a versatile adaptive sampling procedure called which determines whether the marginal gain of the function $f$ is approximately above or below an input threshold with high probability in as few noisy samples as possible. Using the sampling procedure as a subroutine, we propose sample efficient algorithms for monotone submodular maximization with cardinality and matroid constraints, as well as unconstrained non-monotone submodular maximization. The proposed algorithms achieve approximation guarantees arbitrarily close to those of the standard value oracle setting. We further provide an experimental evaluation on real instances of submodular maximization and demonstrate the sample efficiency of our proposed algorithm relative to alternative approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00155v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenjing Chen, Shuo Xing, Victoria G. Crawford</dc:creator>
    </item>
    <item>
      <title>Scheduling Multi-Server Jobs is Not Easy</title>
      <link>https://arxiv.org/abs/2404.05271</link>
      <description>arXiv:2404.05271v2 Announce Type: replace 
Abstract: The problem of online scheduling of multi-server jobs is considered, where there are a total of $K$ servers, and each job requires concurrent service from multiple servers for it to be processed. Each job on its arrival reveals its processing time, the number of servers from which it needs concurrent service and an online algorithm has to make scheduling decisions using only causal information, with the goal of minimizing the response/flow time. The worst case input model is considered and the performance metric is the competitive ratio. For the case, when all job processing time (sizes) are the same, we show that the competitive ratio of any deterministic/randomized algorithm is at least $\Omega(K)$ and propose an online algorithm whose competitive ratio is at most $K+1$. With equal job sizes, we also consider the resource augmentation regime where an online algorithm has access to more servers than an optimal offline algorithm. With resource augmentation, we propose a simple algorithm and show that it has a competitive ratio of $1$ when provided with $2K$ servers with respect to an optimal offline algorithm with $K$ servers. With unequal job sizes, we propose an online algorithm whose competitive ratio is at most $2K \log (K w_{\max})$, where $w_{\max}$ is the maximum size of any job.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05271v2</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rahul Vaze</dc:creator>
    </item>
    <item>
      <title>Adaptive control of dynamic networks</title>
      <link>https://arxiv.org/abs/2302.09743</link>
      <description>arXiv:2302.09743v2 Announce Type: replace-cross 
Abstract: Real-world network systems are inherently dynamic, with network topologies undergoing continuous changes over time. External control signals can be applied to a designated set of nodes within a network, known as the Minimum Driver Set (MDS), to steer the network from any state to a desired one. However, the efficacy of the incumbent MDS may diminish as the network topologies evolve. Previous research has often overlooked this challenge, assuming foreknowledge of future changes in network topologies. In reality, the evolution of network topologies is typically unpredictable, rendering the control of dynamic networks exceptionally challenging. Here, we introduce adaptive control - a novel approach to dynamically construct a series of MDSs to accommodate variations in network topology without prior knowledge. We present an efficient algorithm for adaptive control that minimizes adjustments to MDSs and overall control costs throughout the control period. Extensive experimental evaluation on synthetic and real dynamic networks demonstrated our algorithm's superior performance over several state-of-the-art methods. Adaptive control is general and broadly applicable to various applications in diverse fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09743v2</guid>
      <category>eess.SY</category>
      <category>cs.DS</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunyu Pan, Zhao Su, Haoyu Zheng, Changsheng Zhang, Weixiong Zhang, Xizhe Zhang</dc:creator>
    </item>
    <item>
      <title>PLAN: Variance-Aware Private Mean Estimation</title>
      <link>https://arxiv.org/abs/2306.08745</link>
      <description>arXiv:2306.08745v3 Announce Type: replace-cross 
Abstract: Differentially private mean estimation is an important building block in privacy-preserving algorithms for data analysis and machine learning. Though the trade-off between privacy and utility is well understood in the worst case, many datasets exhibit structure that could potentially be exploited to yield better algorithms. In this paper we present $\textit{Private Limit Adapted Noise}$ (PLAN), a family of differentially private algorithms for mean estimation in the setting where inputs are independently sampled from a distribution $\mathcal{D}$ over $\mathbf{R}^d$, with coordinate-wise standard deviations $\boldsymbol{\sigma} \in \mathbf{R}^d$. Similar to mean estimation under Mahalanobis distance, PLAN tailors the shape of the noise to the shape of the data, but unlike previous algorithms the privacy budget is spent non-uniformly over the coordinates. Under a concentration assumption on $\mathcal{D}$, we show how to exploit skew in the vector $\boldsymbol{\sigma}$, obtaining a (zero-concentrated) differentially private mean estimate with $\ell_2$ error proportional to $\|\boldsymbol{\sigma}\|_1$. Previous work has either not taken $\boldsymbol{\sigma}$ into account, or measured error in Mahalanobis distance $\unicode{x2013}$ in both cases resulting in $\ell_2$ error proportional to $\sqrt{d}\|\boldsymbol{\sigma}\|_2$, which can be up to a factor $\sqrt{d}$ larger. To verify the effectiveness of PLAN, we empirically evaluate accuracy on both synthetic and real world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08745v3</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Aum\"uller, Christian Janos Lebeda, Boel Nelson, Rasmus Pagh</dc:creator>
    </item>
    <item>
      <title>From Zero-Freeness to Strong Spatial Mixing via a Christoffel-Darboux Type Identity</title>
      <link>https://arxiv.org/abs/2401.09317</link>
      <description>arXiv:2401.09317v2 Announce Type: replace-cross 
Abstract: We present a unifying approach to derive the strong spatial mixing (SSM) property for the general 2-spin system from zero-free regions of its partition function. Our approach works for the multivariate partition function over all three complex parameters $(\beta, \gamma, \lambda)$, and we allow the zero-free regions of $\beta, \gamma$ or $\lambda$ to be of arbitrary shapes. As long as the zero-free region contains a positive point and it is a complex neighborhood of $\lambda=0$ when fixing $\beta, \gamma \in \mathbb{C}$, or a complex neighborhood of $\beta\gamma=1$ when fixing $\beta, \lambda\in \mathbb{C}$ or $\gamma, \lambda\in \mathbb{C}$ respectively, we are able to show that the corresponding 2-spin system exhibits SSM on such a region. The underlying graphs of the 2-spin system are not necessarily of bounded degree, while are required to include graphs with pinned vertices. We prove this result by establishing a Christoffel-Darboux type identity for the 2-spin system on trees. This identity plays an important role in our approach and is of its own interests. We also use certain tools from complex analysis such as Riemann mapping theorem.
  Our approach comprehensively turns all existing zero-free regions (to our best knowledge) of the partition function of the 2-spin system where pinned vertices are allowed into the SSM property. As a consequence, we obtain new SSM results for the 2-spin system beyond the direct argument for SSM based on tree recurrence. Moreover, we extend our approach to handle the 2-spin system with non-uniform external fields. As an application, we obtain a new SSM result for the non-uniform ferromagnetic Ising model from the celebrated Lee-Yang circle theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09317v2</guid>
      <category>math-ph</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuai Shao, Xiaowei Ye</dc:creator>
    </item>
    <item>
      <title>Higher-Order Networks Representation and Learning: A Survey</title>
      <link>https://arxiv.org/abs/2402.19414</link>
      <description>arXiv:2402.19414v2 Announce Type: replace-cross 
Abstract: Network data has become widespread, larger, and more complex over the years. Traditional network data is dyadic, capturing the relations among pairs of entities. With the need to model interactions among more than two entities, significant research has focused on higher-order networks and ways to represent, analyze, and learn from them. There are two main directions to studying higher-order networks. One direction has focused on capturing higher-order patterns in traditional (dyadic) graphs by changing the basic unit of study from nodes to small frequently observed subgraphs, called motifs. As most existing network data comes in the form of pairwise dyadic relationships, studying higher-order structures within such graphs may uncover new insights. The second direction aims to directly model higher-order interactions using new and more complex representations such as simplicial complexes or hypergraphs. Some of these models have long been proposed, but improvements in computational power and the advent of new computational techniques have increased their popularity. Our goal in this paper is to provide a succinct yet comprehensive summary of the advanced higher-order network analysis techniques. We provide a systematic review of its foundations and algorithms, along with use cases and applications of higher-order networks in various scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19414v2</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Tian, Reza Zafarani</dc:creator>
    </item>
    <item>
      <title>Algorithms for Caching and MTS with reduced number of predictions</title>
      <link>https://arxiv.org/abs/2404.06280</link>
      <description>arXiv:2404.06280v2 Announce Type: replace-cross 
Abstract: ML-augmented algorithms utilize predictions to achieve performance beyond their worst-case bounds. Producing these predictions might be a costly operation -- this motivated Im et al. '22 to introduce the study of algorithms which use predictions parsimoniously. We design parsimonious algorithms for caching and MTS with action predictions, proposed by Antoniadis et al. '20, focusing on the parameters of consistency (performance with perfect predictions) and smoothness (dependence of their performance on the prediction error). Our algorithm for caching is 1-consistent, robust, and its smoothness deteriorates with the decreasing number of available predictions. We propose an algorithm for general MTS whose consistency and smoothness both scale linearly with the decreasing number of predictions. Without the restriction on the number of available predictions, both algorithms match the earlier guarantees achieved by Antoniadis et al. '20.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06280v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karim Abdel Sadek, Marek Elias</dc:creator>
    </item>
  </channel>
</rss>
