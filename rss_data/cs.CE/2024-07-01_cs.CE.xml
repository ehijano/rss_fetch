<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jul 2024 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>WgLaSDI: Weak-Form Greedy Latent Space Dynamics Identification</title>
      <link>https://arxiv.org/abs/2407.00337</link>
      <description>arXiv:2407.00337v1 Announce Type: new 
Abstract: The parametric greedy latent space dynamics identification (gLaSDI) framework has demonstrated promising potential for accurate and efficient modeling of high-dimensional nonlinear physical systems. However, it remains challenging to handle noisy data. To enhance robustness against noise, we incorporate the weak-form estimation of nonlinear dynamics (WENDy) into gLaSDI. In the proposed weak-form gLaSDI (WgLaSDI) framework, an autoencoder and WENDy are trained simultaneously to discover intrinsic nonlinear latent-space dynamics of high-dimensional data. Compared to the standard sparse identification of nonlinear dynamics (SINDy) employed in gLaSDI, WENDy enables variance reduction and robust latent space discovery, therefore leading to more accurate and efficient reduced-order modeling. Furthermore, the greedy physics-informed active learning in WgLaSDI enables adaptive sampling of optimal training data on the fly for enhanced modeling accuracy. The effectiveness of the proposed framework is demonstrated by modeling various nonlinear dynamical problems, including viscous and inviscid Burgers' equations, time-dependent radial advection, and the Vlasov equation for plasma physics. With data that contains 5-10% Gaussian white noise, WgLaSDI outperforms gLaSDI by orders of magnitude, achieving 1-7% relative errors. Compared with the high-fidelity models, WgLaSDI achieves 121 to 1,779x speed-up.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00337v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolong He, April Tran, David M. Bortz, Youngsoo Choi</dc:creator>
    </item>
    <item>
      <title>SHADE: Semantic Hypernym Annotator for Domain-specific Entities -- DnD Domain Use Case</title>
      <link>https://arxiv.org/abs/2407.00407</link>
      <description>arXiv:2407.00407v1 Announce Type: new 
Abstract: Manual data annotation is an important NLP task but one that takes considerable amount of resources and effort. In spite of the costs, labeling and categorizing entities is essential for NLP tasks such as semantic evaluation. Even though annotation can be done by non-experts in most cases, due to the fact that this requires human labor, the process is costly. Another major challenge encountered in data annotation is maintaining the annotation consistency. Annotation efforts are typically carried out by teams of multiple annotators. The annotations need to maintain the consistency in relation to both the domain truth and annotation format while reducing human errors. Annotating a specialized domain that deviates significantly from the general domain, such as fantasy literature, will see a lot of human error and annotator disagreement. So it is vital that proper guidelines and error reduction mechanisms are enforced. One such way to enforce these constraints is using a specialized application. Such an app can ensure that the notations are consistent, and the labels can be pre-defined or restricted reducing the room for errors. In this paper, we present SHADE, an annotation software that can be used to annotate entities in the high fantasy literature domain. Specifically in Dungeons and Dragons lore extracted from the Forgotten Realms Fandom Wiki.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00407v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICIIS58898.2023.10253606</arxiv:DOI>
      <dc:creator>Akila Peiris, Nisansa de Silva</dc:creator>
    </item>
    <item>
      <title>AI-powered multimodal modeling of personalized hemodynamics in aortic stenosis</title>
      <link>https://arxiv.org/abs/2407.00535</link>
      <description>arXiv:2407.00535v1 Announce Type: new 
Abstract: Aortic stenosis (AS) is the most common valvular heart disease in developed countries. High-fidelity preclinical models can improve AS management by enabling therapeutic innovation, early diagnosis, and tailored treatment planning. However, their use is currently limited by complex workflows necessitating lengthy expert-driven manual operations. Here, we propose an AI-powered computational framework for accelerated and democratized patient-specific modeling of AS hemodynamics from computed tomography. First, we demonstrate that our automated meshing algorithms can generate task-ready geometries for both computational and benchtop simulations with higher accuracy and 100 times faster than existing approaches. Then, we show that our approach can be integrated with fluid-structure interaction and soft robotics models to accurately recapitulate a broad spectrum of clinical hemodynamic measurements of diverse AS patients. The efficiency and reliability of these algorithms make them an ideal complementary tool for personalized high-fidelity modeling of AS biomechanics, hemodynamics, and treatment planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00535v1</guid>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caglar Ozturk, Daniel H. Pak, Luca Rosalia, Debkalpa Goswami, Mary E. Robakowski, Raymond McKay, Christopher T. Nguyen, James S. Duncan, Ellen T. Roche</dc:creator>
    </item>
    <item>
      <title>Physics-augmented neural networks for constitutive modeling of hyperelastic geometrically exact beams</title>
      <link>https://arxiv.org/abs/2407.00640</link>
      <description>arXiv:2407.00640v1 Announce Type: new 
Abstract: We present neural network-based constitutive models for hyperelastic geometrically exact beams. The proposed models are physics-augmented, i.e., formulated to fulfill important mechanical conditions by construction. Strains and curvatures of the beam are used as input for feed-forward neural networks that represent the effective hyperelastic beam potential. Forces and moments are then received as the gradients of the beam potential, ensuring thermodynamic consistency. Furthermore, normalization conditions are considered via additional projection terms. To include the symmetry of beams with point-symmetric cross-sections, a flip symmetry constraint is introduced. Additionally, parameterized models are proposed that can represent the beam's constitutive behavior for varying cross-sectional geometries. The physically motivated parameterization takes into account the influence of the beam radius on the beam potential. Formulating the beam potential as a neural network provides a highly flexible model. This enables efficient constitutive surrogate modeling for geometrically exact beams with nonlinear material behavior and cross-sectional deformation, which otherwise would require computationally much more expensive methods. The models are calibrated to data generated for beams with circular, deformable cross-sections and varying radii, showing excellent accuracy and generalization. The applicability of the proposed model is further demonstrated by applying it in beam simulations. In all studied cases, the proposed model shows excellent performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00640v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jasper O. Schommartz, Dominik K. Klein, Juan C. Alzate Cobo, Oliver Weeger</dc:creator>
    </item>
    <item>
      <title>Beyond the Yield Barrier: Variational Importance Sampling Yield Analysis</title>
      <link>https://arxiv.org/abs/2407.00711</link>
      <description>arXiv:2407.00711v1 Announce Type: new 
Abstract: Optimal mean shift vector (OMSV)-based importance sampling methods have long been prevalent in yield estimation and optimization as an industry standard. However, most OMSV-based methods are designed heuristically without a rigorous understanding of their limitations. To this end, we propose VIS, the first variational analysis framework for yield problems, enabling a systematic refinement for OMSV. For instance, VIS reveals that the classic OMSV is suboptimal, and the optimal/true OMSV should always stay beyond the failure boundary, which enables a free improvement for all OMSV-based methods immediately. Using VIS, we show a progressive refinement for the classic OMSV including incorporation of full covariance in closed form, adjusting for asymmetric failure distributions, and capturing multiple failure regions, each of which contributes to a progressive improvement of more than 2x. Inheriting the simplicity of OMSV, the proposed method retains simplicity and robustness yet achieves up to 29.03x speedup over the state-of-the-art (SOTA) methods. We also demonstrate how the SOTA yield optimization, ASAIS, can immediately benefit from our True OMSV, delivering a 1.20x and 1.27x improvement in performance and efficiency, respectively, without additional computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00711v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanfang Liu, Lei He, Wei W. Xing</dc:creator>
    </item>
    <item>
      <title>Background-aware Multi-source Fusion Financial Trend Forecasting Mechanism</title>
      <link>https://arxiv.org/abs/2407.00904</link>
      <description>arXiv:2407.00904v1 Announce Type: new 
Abstract: Stock prices, as an economic indicator, reflect changes in economic development and market conditions. Traditional stock price prediction models often only consider time-series data and are limited by the mechanisms of the models themselves. Some deep learning models have high computational costs, depend on a large amount of high-quality data, and have poor interpretations, making it difficult to intuitively understand the driving factors behind the predictions. Some studies have used deep learning models to extract text features and combine them with price data to make joint predictions, but there are issues with dealing with information noise, accurate extraction of text sentiment, and how to efficiently fuse text and numerical data. To address these issues in this paper, we propose a background-aware multi-source fusion financial trend forecasting mechanism. The system leverages a large language model to extract key information from policy and stock review texts, utilizing the MacBERT model to generate feature vectors. These vectors are then integrated with stock price data to form comprehensive feature representations. These integrated features are input into a neural network comprising various deep learning architectures. By integrating multiple data sources, the system offers a holistic view of market dynamics. It harnesses the comprehensive analytical and interpretative capabilities of large language models, retaining deep semantic and sentiment information from policy texts to provide richer input features for stock trend prediction. Additionally, we compare the accuracy of six models (LSTM, BiLSTM, MogrifierLSTM, GRU, ST-LSTM, SwinLSTM). The results demonstrate that our system achieves generally better accuracy in predicting stock movements, attributed to the incorporation of large language model processing, policy information, and other influential features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00904v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengting Mo, Shanshan Yan, Yinhao Xiao</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Holomorphic Neural Networks (PIHNNs): Solving Linear Elasticity Problems</title>
      <link>https://arxiv.org/abs/2407.01088</link>
      <description>arXiv:2407.01088v1 Announce Type: new 
Abstract: We propose physics-informed holomorphic neural networks (PIHNNs) as a method to solve boundary value problems where the solution can be represented via holomorphic functions. Specifically, we consider the case of plane linear elasticity and, by leveraging the Kolosov-Muskhelishvili representation of the solution in terms of holomorphic potentials, we train a complex-valued neural network to fulfill stress and displacement boundary conditions while automatically satisfying the governing equations. This is achieved by designing the network to return only approximations that inherently satisfy the Cauchy-Riemann conditions through specific choices of layers and activation functions. To ensure generality, we provide a universal approximation theorem guaranteeing that, under basic assumptions, the proposed holomorphic neural networks can approximate any holomorphic function. Furthermore, we suggest a new tailored weight initialization technique to mitigate the issue of vanishing/exploding gradients. Compared to the standard PINN approach, noteworthy benefits of the proposed method for the linear elasticity problem include a more efficient training, as evaluations are needed solely on the boundary of the domain, lower memory requirements, due to the reduced number of training points, and $C^\infty$ regularity of the learned solution. Several benchmark examples are used to verify the correctness of the obtained PIHNN approximations, the substantial benefits over traditional PINNs, and the possibility to deal with non-trivial, multiply-connected geometries via a domain-decomposition strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01088v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Calaf\`a, Emil Hovad, Allan P. Engsig-Karup, Tito Andriollo</dc:creator>
    </item>
    <item>
      <title>Generalized Orbicular (m,n,o) T-Spherical Fuzzy Sets with Hamacher Aggregation Operators and Application to Multi-Criteria Group Decision Making</title>
      <link>https://arxiv.org/abs/2407.01267</link>
      <description>arXiv:2407.01267v1 Announce Type: new 
Abstract: This paper introduces a novel approach to enhance uncertainty representation, offering decision-makers a more comprehensive perspective for improved decision-making outcomes. We propose Generalized Orbicular (m,n,o) T-Spherical Fuzzy Set (GO-TSFS), a flexible extension of existing fuzzy set models including Globular T-spherical fuzzy sets (G-TSFSs), T-spherical fuzzy sets (T-SFSs), (p,q,r) Spherical fuzzy sets, and (p,q) Quasirung orthopair fuzzy sets (QOFSs). The framework employs three adjustable parameters m, n, and o to finely tune the influence of membership degrees, allowing for adaptable weighting of various degrees of membership. By utilizing spheres to represent membership, indeterminacy, and non-membership levels, the model enhances accuracy in depicting vague, ambiguous, and imprecise data. Building upon the foundation of GO-TSFSs, we introduce essential set operations and algebraic operations for GO-TSF Values (GO-TSFVs). Moreover, we also develop score functions, accuracy functions, and basic distance measures such as Hamming and Euclidean distances to further enhance the analytical capabilities of the framework. Additionally, we propose GO-TSF Hamacher Weighted Averaging (GO-TSFHWA) and GO-TSFH Weighted Geometric (GO-TSFHWG), aggregation operators tailored for our proposed sets. To demonstrate the practical applicability of our approach, we apply our proposed aggregation operators namely GO-TSFHWA and GO-TSFHWG to solve a Multi-Criteria Group Decision Making (MCGDM) problem, specifically for selecting the most suitable e-commerce online shopping platform from the top-rated options. Sensitivity analysis is also conducted to validate the reliability and efficacy of our results, affirming the utility and robustness of the proposed methodology in real-world decision-making scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01267v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasir Akhtar, Mehboob Ali, Miin-Shen Yang</dc:creator>
    </item>
    <item>
      <title>Adaptive and Parallel Multiscale Framework for Modeling Cohesive Failure in Engineering Scale Systems</title>
      <link>https://arxiv.org/abs/2407.00006</link>
      <description>arXiv:2407.00006v1 Announce Type: cross 
Abstract: The high computational demands of multiscale modeling necessitate advanced parallel and adaptive strategies. To address this challenge, we introduce an adaptive method that utilizes two microscale models based on an offline database for multiscale modeling of curved interfaces (e.g., adhesive layers). This database employs nonlinear classifiers, developed using Support Vector Machines from microscale sampling data, as a preprocessing step for multiscale simulations. Next, we develop a new parallel network library that enables seamless model selection with customized communication layers, ensuring scalability in parallel computing environments. The correctness and effectiveness of the hierarchically parallel solver are verified on a crack propagation problem within the curved adhesive layer. Finally, we predict the ultimate bending moment and adhesive layer failure of a wind turbine blade and validate the solver on a difficult large-scale engineering problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00006v1</guid>
      <category>cs.DC</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sion Kim, Ezra Kissel, Karel Matous</dc:creator>
    </item>
    <item>
      <title>Improving the performance of Stein variational inference through extreme sparsification of physically-constrained neural network models</title>
      <link>https://arxiv.org/abs/2407.00761</link>
      <description>arXiv:2407.00761v1 Announce Type: cross 
Abstract: Most scientific machine learning (SciML) applications of neural networks involve hundreds to thousands of parameters, and hence, uncertainty quantification for such models is plagued by the curse of dimensionality. Using physical applications, we show that $L_0$ sparsification prior to Stein variational gradient descent ($L_0$+SVGD) is a more robust and efficient means of uncertainty quantification, in terms of computational cost and performance than the direct application of SGVD or projected SGVD methods. Specifically, $L_0$+SVGD demonstrates superior resilience to noise, the ability to perform well in extrapolated regions, and a faster convergence rate to an optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00761v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Govinda Anantha Padmanabha, Jan Niklas Fuhg, Cosmin Safta, Reese E. Jones, Nikolaos Bouklas</dc:creator>
    </item>
    <item>
      <title>Relevance of the Basset history term for Lagrangian particle dynamics</title>
      <link>https://arxiv.org/abs/2407.01041</link>
      <description>arXiv:2407.01041v1 Announce Type: cross 
Abstract: The movement of small but finite spherical particles in a fluid can be described by the Maxey-Riley equation (MRE) if they are too large to be considered passive tracers. The MRE contains an integral "history term" modeling wake effects, which causes the force acting on a particle at some given time to depend on its full past trajectory. The history term causes complications in the numerical solution of the MRE and is therefore often neglected, despite both numerical and experimental evidence that its effects are generally not negligible. By numerically computing trajectories with and without the history term of a large number of particles in different flow fields, we investigate its impact on the large-scale Lagrangian dynamics of simulated particles. We show that for moderate to large Stokes numbers, ignoring the history term leads to significant differences in clustering patterns. Furthermore, we compute finite-time Lyapunov exponents and show that, even for small particles, the differences in the resulting scalar field from ignoring the BHT can be significant, in particular if the underlying flow is turbulent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01041v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julio Urizarna-Carasa, Daniel Ruprecht, Alexandra von Kameke, Kathrin Padberg-Gehle</dc:creator>
    </item>
    <item>
      <title>Multivariate sensitivity-adaptive polynomial chaos expansion for high-dimensional surrogate modeling and uncertainty quantification</title>
      <link>https://arxiv.org/abs/2310.09871</link>
      <description>arXiv:2310.09871v3 Announce Type: replace 
Abstract: This work develops a novel basis-adaptive method for constructing anisotropic polynomial chaos expansions of multidimensional (vector-valued, multi-output) model responses. The adaptive basis selection is based on multivariate sensitivity analysis metrics that can be estimated by post-processing the polynomial chaos expansion and results in a common anisotropic polynomial basis for the vector-valued response. This allows the application of the method to problems with up to moderately high-dimensional model inputs (in the order of tens) and up to very high-dimensional model responses (in the order of thousands). The method is applied to different engineering test cases for surrogate modeling and uncertainty quantification, including use cases related to electric machine and power grid modeling and simulation, and is found to produce highly accurate results with comparatively low data and computational demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09871v3</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dimitrios Loukrezis, Eric Diehl, Herbert De Gersem</dc:creator>
    </item>
    <item>
      <title>Scaffold Splits Overestimate Virtual Screening Performance</title>
      <link>https://arxiv.org/abs/2406.00873</link>
      <description>arXiv:2406.00873v2 Announce Type: replace-cross 
Abstract: Virtual Screening (VS) of vast compound libraries guided by Artificial Intelligence (AI) models is a highly productive approach to early drug discovery. Data splitting is crucial for better benchmarking of such AI models. Traditional random data splits produce similar molecules between training and test sets, conflicting with the reality of VS libraries which mostly contain structurally distinct compounds. Scaffold split, grouping molecules by shared core structure, is widely considered to reflect this real-world scenario. However, here we show that the scaffold split also overestimates VS performance. The reason is that molecules with different chemical scaffolds are often similar, which hence introduces unrealistically high similarities between training molecules and test molecules following a scaffold split. Our study examined three representative AI models on 60 NCI-60 datasets, each with approximately 30,000 to 50,000 molecules tested on a different cancer cell line. Each dataset was split with three methods: scaffold, Butina clustering and the more accurate Uniform Manifold Approximation and Projection (UMAP) clustering. Regardless of the model, model performance is much worse with UMAP splits from the results of the 2100 models trained and evaluated for each algorithm and split. These robust results demonstrate the need for more realistic data splits to tune, compare, and select models for VS. For the same reason, avoiding the scaffold split is also recommended for other molecular property prediction problems. The code to reproduce these results is available at https://github.com/ScaffoldSplitsOverestimateVS</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00873v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qianrong Guo, Saiveth Hernandez-Hernandez, Pedro J Ballester</dc:creator>
    </item>
    <item>
      <title>A Differentiable Approach to Multi-scale Brain Modeling</title>
      <link>https://arxiv.org/abs/2406.19708</link>
      <description>arXiv:2406.19708v2 Announce Type: replace-cross 
Abstract: We present a multi-scale differentiable brain modeling workflow utilizing BrainPy, a unique differentiable brain simulator that combines accurate brain simulation with powerful gradient-based optimization. We leverage this capability of BrainPy across different brain scales. At the single-neuron level, we implement differentiable neuron models and employ gradient methods to optimize their fit to electrophysiological data. On the network level, we incorporate connectomic data to construct biologically constrained network models. Finally, to replicate animal behavior, we train these models on cognitive tasks using gradient-based learning rules. Experiments demonstrate that our approach achieves superior performance and speed in fitting generalized leaky integrate-and-fire and Hodgkin-Huxley single neuron models. Additionally, training a biologically-informed network of excitatory and inhibitory spiking neurons on working memory tasks successfully replicates observed neural activity and synaptic weight distributions. Overall, our differentiable multi-scale simulation approach offers a promising tool to bridge neuroscience data across electrophysiological, anatomical, and behavioral scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19708v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chaoming Wang, Muyang Lyu, Tianqiu Zhang, Sichao He, Si Wu</dc:creator>
    </item>
  </channel>
</rss>
