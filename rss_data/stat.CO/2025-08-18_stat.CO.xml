<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Aug 2025 04:00:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A note on simulation methods for the Dirichlet-Laplace prior</title>
      <link>https://arxiv.org/abs/2508.11982</link>
      <description>arXiv:2508.11982v1 Announce Type: new 
Abstract: Bhattacharya et al. (2015, Journal of the American Statistical Association 110(512): 1479-1490) introduce a novel prior, the Dirichlet-Laplace (DL) prior, and propose a Markov chain Monte Carlo (MCMC) method to simulate posterior draws under this prior in a conditionally Gaussian setting. The original algorithm samples from conditional distributions in the wrong order, i.e., it does not correctly sample from the joint posterior distribution of all latent variables. This note details the issue and provides two simple solutions: A correction to the original algorithm and a new algorithm based on an alternative, yet equivalent, formulation of the prior. This corrigendum does not affect the theoretical results in Bhattacharya et al. (2015).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11982v1</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/01621459.2025.2540256</arxiv:DOI>
      <arxiv:journal_reference>Correction. (2025). Journal of the American Statistical Association</arxiv:journal_reference>
      <dc:creator>Luis Gruber, Gregor Kastner, Anirban Bhattacharya, Debdeep Pati, Natesh Pillai, David Dunson</dc:creator>
    </item>
    <item>
      <title>Accelerating Proximal Gradient-type Algorithms using Damped Anderson Acceleration with Restarts and Nesterov Initialization</title>
      <link>https://arxiv.org/abs/2508.12177</link>
      <description>arXiv:2508.12177v1 Announce Type: new 
Abstract: Despite their frequent slow convergence, proximal gradient schemes are widely used in large-scale optimization tasks due to their tremendous stability, scalability, and ease of computation. In this paper, we develop and investigate a general two-phase scheme for accelerating the convergence of proximal gradient algorithms. By using Nesterov's momentum method in an initialization phase, our procedure delivers fast initial descent that is robust to the choice of starting value. Once iterates are much closer to the solution after the first phase, we utilize a variation of Anderson acceleration to deliver more rapid local convergence in the second phase. Drawing upon restarting schemes developed for Nesterov acceleration, we can readily identify points where it is advantageous to switch from the first to the second phase, which enables use of the procedure without requiring one to specify the number of iterations used in each phase. For the second phase, we adapt and extend a version of Anderson acceleration with algorithm restarts, and we introduce a subsetted version of this procedure that improves performance in problems with substantial sparsity. Through simulation studies involving four representative optimization problems, we show that our proposed algorithm can generate substantial improvements over competing acceleration methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12177v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas C. Henderson, Ravi Varadhan</dc:creator>
    </item>
    <item>
      <title>A Systematic Particle Filter for Estimating Time-Varying Parameters in Advection-Diffusion Equations with Source Terms</title>
      <link>https://arxiv.org/abs/2508.12155</link>
      <description>arXiv:2508.12155v1 Announce Type: cross 
Abstract: Many real-world systems modeled using partial differential equations (PDEs) involve unknown parameters that must be estimated from limited, noisy system observations. While typically assumed to be constants, some of these unobserved parameters may vary with time. This work proposes a two-phase, offline-online numerical procedure for systematically estimating and quantifying uncertainty in time-varying parameters (TVPs) in time-dependent PDEs, specifically focusing on advection-diffusion models with TVPs involved in the source terms. Numerical results on a set of one-dimensional test problems demonstrate the effectiveness of the proposed estimation procedure in tracking unknown TVPs of different forms, while simultaneously estimating variance parameters affecting the TVP evolution model, from partial, noisy observations of the solution at discrete spatial locations and times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12155v1</guid>
      <category>stat.ME</category>
      <category>math.DS</category>
      <category>stat.CO</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Arnold</dc:creator>
    </item>
    <item>
      <title>An Introduction to Sliced Optimal Transport</title>
      <link>https://arxiv.org/abs/2508.12519</link>
      <description>arXiv:2508.12519v1 Announce Type: cross 
Abstract: Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal transport (OT) that exploits the tractability of one-dimensional OT problems. By combining tools from OT, integral geometry, and computational statistics, SOT enables fast and scalable computation of distances, barycenters, and kernels for probability measures, while retaining rich geometric structure. This paper provides a comprehensive review of SOT, covering its mathematical foundations, methodological advances, computational methods, and applications. We discuss key concepts of OT and one-dimensional OT, the role of tools from integral geometry such as Radon transform in projecting measures, and statistical techniques for estimating sliced distances. The paper further explores recent methodological advances, including non-linear projections, improved Monte Carlo approximations, statistical estimation techniques for one-dimensional optimal transport, weighted slicing techniques, and transportation plan estimation methods. Variational problems, such as minimum sliced Wasserstein estimation, barycenters, gradient flows, kernel constructions, and embeddings are examined alongside extensions to unbalanced, partial, multi-marginal, and Gromov-Wasserstein settings. Applications span machine learning, statistics, computer graphics and computer visions, highlighting SOT's versatility as a practical computational tool. This work will be of interest to researchers and practitioners in machine learning, data sciences, and computational disciplines seeking efficient alternatives to classical OT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12519v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khai Nguyen</dc:creator>
    </item>
    <item>
      <title>On computing and the complexity of computing higher-order $U$-statistics, exactly</title>
      <link>https://arxiv.org/abs/2508.12627</link>
      <description>arXiv:2508.12627v1 Announce Type: cross 
Abstract: Higher-order $U$-statistics abound in fields such as statistics, machine learning, and computer science, but are known to be highly time-consuming to compute in practice. Despite their widespread appearance, a comprehensive study of their computational complexity is surprisingly lacking. This paper aims to fill that gap by presenting several results related to the computational aspect of $U$-statistics. First, we derive a useful decomposition from an $m$-th order $U$-statistic to a linear combination of $V$-statistics with orders not exceeding $m$, which are generally more feasible to compute. Second, we explore the connection between exactly computing $V$-statistics and Einstein summation, a tool often used in computational mathematics, quantum computing, and quantum information sciences for accelerating tensor computations. Third, we provide an optimistic estimate of the time complexity for exactly computing $U$-statistics, based on the treewidth of a particular graph associated with the $U$-statistic kernel. The above ingredients lead to a new, much more runtime-efficient algorithm of exactly computing general higher-order $U$-statistics. We also wrap our new algorithm into an open-source Python package called $\texttt{u-stats}$. We demonstrate via three statistical applications that $\texttt{u-stats}$ achieves impressive runtime performance compared to existing benchmarks. This paper aspires to achieve two goals: (1) to capture the interest of researchers in both statistics and other related areas further to advance the algorithmic development of $U$-statistics, and (2) to offer the package $\texttt{u-stats}$ as a valuable tool for practitioners, making the implementation of methods based on higher-order $U$-statistics a more delightful experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12627v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Chen, Ruiqi Zhang, Lin Liu</dc:creator>
    </item>
    <item>
      <title>A self-supervised learning approach for denoising autoregressive models with additive noise: finite and infinite variance cases</title>
      <link>https://arxiv.org/abs/2508.12970</link>
      <description>arXiv:2508.12970v1 Announce Type: cross 
Abstract: The autoregressive time series model is a popular second-order stationary process, modeling a wide range of real phenomena. However, in applications, autoregressive signals are often corrupted by additive noise. Further, the autoregressive process and the corruptive noise may be highly impulsive, stemming from an infinite-variance distribution. The model estimation techniques that account for additional noise tend to show reduced efficacy when there is very strong noise present in the data, especially when the noise is heavy-tailed. Moreover, identification of a model corrupted with heavy-tailed, particularly infinite-variance noise, can be a very challenging task. In this paper, we propose a novel self-supervised learning method to denoise the additive noise-corrupted autoregressive model. Our approach is motivated by recent work in computer vision and does not require full knowledge of the noise distribution. We use the proposed method to recover exemplary finite- and infinite-variance autoregressive signals, namely, Gaussian- and alpha-stable distributed signals, respectively, from their noise-corrupted versions. The simulation study conducted on both synthetic and semi-synthetic data demonstrates the efficiency of our method compared to several baseline methods, particularly when the corruption is significant and impulsive in nature. Finally, we apply the presented methodology to forecast the pure autoregressive signal from the noise-corrupted data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12970v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sayantan Banerjee, Agnieszka Wylomanska, Sundar S</dc:creator>
    </item>
    <item>
      <title>Synchronization and semantization in deep spiking networks</title>
      <link>https://arxiv.org/abs/2508.12975</link>
      <description>arXiv:2508.12975v1 Announce Type: cross 
Abstract: Recent studies have shown how spiking networks can learn complex functionality through error-correcting plasticity, but the resulting structures and dynamics remain poorly studied. To elucidate how these models may link to observed dynamics in vivo and thus how they may ultimately explain cortical computation, we need a better understanding of their emerging patterns. We train a multi-layer spiking network, as a conceptual analog of the bottom-up visual hierarchy, for visual input classification using spike-time encoding. After learning, we observe the development of distinct spatio-temporal activity patterns. While input patterns are synchronous by construction, activity in early layers first spreads out over time, followed by re-convergence into sharp pulses as classes are gradually extracted. The emergence of synchronicity is accompanied by the formation of increasingly distinct pathways, reflecting the gradual semantization of input activity. We thus observe hierarchical networks learning spike latency codes to naturally acquire activity patterns characterized by synchronicity and separability, with pronounced excitatory pathways ascending through the layers. This provides a rigorous computational hypothesis for the experimentally observed synchronicity in the visual system as a natural consequence of deep learning in cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12975v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <category>stat.CO</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonas Oberste-Frielinghaus, Anno C. Kurth, Julian G\"oltz, Laura Kriener, Junji Ito, Mihai A. Petrovici, Sonja Gr\"un</dc:creator>
    </item>
    <item>
      <title>Quantile Importance Sampling</title>
      <link>https://arxiv.org/abs/2305.03158</link>
      <description>arXiv:2305.03158v3 Announce Type: replace 
Abstract: In Bayesian inference, the approximation of integrals of the form $\psi = \mathbb{E}_{F}{l(X)} = \int_{\chi} l(\mathbf{x}) d F(\mathbf{x})$ is a fundamental challenge. Such integrals are crucial for evidence estimation, which is important for various purposes, including model selection and numerical analysis. The existing strategies for evidence estimation are classified into four categories: deterministic approximation, density estimation, importance sampling, and vertical representation (Llorente et al., 2020). In this paper, we show that the Riemann sum estimator due to Yakowitz (1978) can be used in the context of nested sampling (Skilling, 2006) to achieve a $O(n^{-4})$ rate of convergence, faster than the usual Ergodic Central Limit Theorem. We provide a brief overview of the literature on the Riemann sum estimators and the nested sampling algorithm and its connections to vertical likelihood Monte Carlo. We provide theoretical and numerical arguments to show how merging these two ideas may result in improved and more robust estimators for evidence estimation, especially in higher dimensional spaces. We also briefly discuss the idea of simulating the Lorenz curve that avoids the problem of intractable $\Lambda$ functions, essential for the vertical representation and nested sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03158v3</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jyotishka Datta, Nicholas G. Polson</dc:creator>
    </item>
    <item>
      <title>Approximate Bayesian Computation sequential Monte Carlo via random forests</title>
      <link>https://arxiv.org/abs/2406.15865</link>
      <description>arXiv:2406.15865v2 Announce Type: replace 
Abstract: Approximate Bayesian Computation (ABC) is a popular inference method when likelihoods are hard to come by. Practical bottlenecks of ABC applications include selecting statistics that summarize the data without losing too much information or introducing uncertainty, and choosing distance functions and tolerance thresholds that balance accuracy and computational efficiency. Recent studies have shown that ABC methods using random forest (RF) methodology perform well while circumventing many of ABC's drawbacks. However, RF construction is computationally expensive for large numbers of trees and model simulations, and there can be high uncertainty in the posterior if the prior distribution is uninformative. Here we further adapt random forests to the ABC setting in two ways. The first exploits distributional random forests to provide a direct method for inferring the joint posterior distribution of parameters of interest, while the second describes a sequential Monte Carlo approach which updates the prior distribution iteratively to focus on the most likely regions in the parameter space. We show that the new methods can accurately infer posterior distributions for a wide range of deterministic and stochastic models in different scientific areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15865v2</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khanh N. Dinh, C\'ecile Liu, Zijin Xiang, Zhihan Liu, Simon Tavar\'e</dc:creator>
    </item>
    <item>
      <title>The Lasso Distribution: Properties, Sampling Methods, and Applications in Bayesian Lasso Regression</title>
      <link>https://arxiv.org/abs/2506.07394</link>
      <description>arXiv:2506.07394v3 Announce Type: replace 
Abstract: In this paper, we introduce a new probability distribution, the Lasso distribution. We derive several fundamental properties of the distribution, including closed-form expressions for its moments and moment-generating function. Additionally, we present an efficient and numerically stable algorithm for generating random samples from the distribution, facilitating its use in both theoretical and applied settings. We establish that the Lasso distribution belongs to the exponential family. A direct application of the Lasso distribution arises in the context of an existing Gibbs sampler, where the full conditional distribution of each regression coefficient follows this distribution. This leads to a more computationally efficient and theoretically grounded sampling scheme. To facilitate the adoption of our methodology, we provide an R package, BayesianLasso, available on CRAN, implementing the proposed methods. Our findings offer new insights into the probabilistic structure underlying the Lasso penalty and provide practical improvements in Bayesian inference for high-dimensional regression problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07394v3</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Javad Davoudabadi, Jonathon Tidswell, Samuel Muller, Garth Tarr, John T. Ormerod</dc:creator>
    </item>
    <item>
      <title>A Consistent and Scalable Algorithm for Best Subset Selection in Single Index Models</title>
      <link>https://arxiv.org/abs/2309.06230</link>
      <description>arXiv:2309.06230v2 Announce Type: replace-cross 
Abstract: Analysis of high-dimensional data has led to increased interest in both single index models (SIMs) and the best-subset selection. SIMs provide an interpretable and flexible modeling framework for high-dimensional data, while the best-subset selection aims to find a sparse model from a large set of predictors. However, the best-subset selection in high-dimensional models is known to be computationally intractable. Existing proxy algorithms are appealing but do not yield the bestsubset solution. In this paper, we directly tackle the intractability by proposing a provably scalable algorithm for the best-subset selection in high-dimensional SIMs. We directly proved the subset selection consistency and oracle property for our algorithmic solution, distinguishing it from other state-of-the-art support recovery methods in SIMs. The algorithm comprises a generalized information criterion to determine the support size of the regression coefficients, eliminating the model selection tuning. Moreover, our method does not assume an error distribution or a specific link function and hence is flexible to apply. Extensive simulation results demonstrate that our method is not only computationally efficient but also able to exactly recover the best subset in various settings (e.g., linear regression, Poisson regression, heteroscedastic models).</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06230v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Borui Tang, Jin Zhu, Junxian Zhu, Xueqin Wang, Heping Zhang</dc:creator>
    </item>
    <item>
      <title>Two-sample comparison through additive tree models for density ratios</title>
      <link>https://arxiv.org/abs/2508.03059</link>
      <description>arXiv:2508.03059v2 Announce Type: replace-cross 
Abstract: The ratio of two densities characterizes their differences. We consider learning the density ratio given i.i.d. observations from each of the two distributions. We propose additive tree models for the density ratio along with efficient algorithms for training these models using a new loss function called the balancing loss. With this loss, additive tree models for the density ratio can be trained using algorithms original designed for supervised learning. Specifically, they can be trained from both an optimization perspective that parallels tree boosting and from a (generalized) Bayesian perspective that parallels Bayesian additive regression trees (BART). For the former, we present two boosting algorithms -- one based on forward-stagewise fitting and the other based on gradient boosting, both of which produce a point estimate for the density ratio function. For the latter, we show that due to the loss function's resemblance to an exponential family kernel, the new loss can serve as a pseudo-likelihood for which conjugate priors exist, thereby enabling effective generalized Bayesian inference on the density ratio using backfitting samplers designed for BART. The resulting uncertainty quantification on the inferred density ratio is critical for applications involving high-dimensional and complex distributions in which uncertainty given limited data can often be substantial. We provide insights on the balancing loss through its close connection to the exponential loss in binary classification and to the variational form of f-divergence, in particular that of the squared Hellinger distance. Our numerical experiments demonstrate the accuracy of the proposed approach while providing unique capabilities in uncertainty quantification. We demonstrate the application of our method in a case study involving assessing the quality of generative models for microbiome compositional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03059v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoki Awaya, Yuliang Xu, Li Ma</dc:creator>
    </item>
  </channel>
</rss>
