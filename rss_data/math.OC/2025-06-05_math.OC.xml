<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Solving the Assignment Problem with Conflicts</title>
      <link>https://arxiv.org/abs/2506.04274</link>
      <description>arXiv:2506.04274v1 Announce Type: new 
Abstract: A variant of the well-known Assignment Problem is studied in this paper, where pairs of assignments are conflicting, and cannot be selected at the same time. This configures a set of hard constraints. The problem, which models real applications, looks for a complete assignment that minimizes the total cost, while no conflict is violated. In this paper, we consider a previously known mixed integer linear program representing the problem and we solve it with the open-source solver CP-SAT, part of the Google OR-Tools computational suite. An experimental campaign on the instances available from the literature, indicates that the approach we propose achieves results comparable with, those of state-of-the-art solvers, notwithstanding its intrinsic conceptual and implementation simplicity. The solver adopted is also able to provide heuristic solutions quicker and better than the heuristic methods previously discussed in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04274v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Montemanni, Derek H. Smith</dc:creator>
    </item>
    <item>
      <title>Maximizing the Value of Predictions in Control: Accuracy Is Not Enough</title>
      <link>https://arxiv.org/abs/2506.04497</link>
      <description>arXiv:2506.04497v1 Announce Type: new 
Abstract: We study the value of stochastic predictions in online optimal control with random disturbances. Prior work provides performance guarantees based on prediction error but ignores the stochastic dependence between predictions and disturbances. We introduce a general framework modeling their joint distribution and define "prediction power" as the control cost improvement from the optimal use of predictions compared to ignoring the predictions. In the time-varying Linear Quadratic Regulator (LQR) setting, we derive a closed-form expression for prediction power and discuss its mismatch with prediction accuracy and connection with online policy optimization. To extend beyond LQR, we study general dynamics and costs. We establish a lower bound of prediction power under two sufficient conditions that generalize the properties of the LQR setting, characterizing the fundamental benefit of incorporating stochastic predictions. We apply this lower bound to non-quadratic costs and show that even weakly dependent predictions yield significant performance gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04497v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiheng Lin, Christopher Yeh, Zaiwei Chen, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>Non-linear Multi-objective Optimization with Probabilistic Branch and Bound</title>
      <link>https://arxiv.org/abs/2506.04554</link>
      <description>arXiv:2506.04554v1 Announce Type: new 
Abstract: A multiple objective simulation optimization algorithm named Multiple Objective Probabilistic Branch and Bound with Single Observation (MOPBnB(so)) is presented for approximating the Pareto optimal set and the associated efficient frontier for stochastic multi-objective optimization problems. MOPBnB(so) evaluates a noisy function exactly once at any solution and uses neighboring solutions to estimate the objective functions, in contrast to a variant that uses multiple replications at a solution to estimate the objective functions. A finite-time performance analysis for deterministic multi-objective problems provides a bound on the probability that MOPBnB(so) captures the Pareto optimal set. Asymptotic convergence of MOPBnB(so) on stochastic problems is derived, in that the algorithm captures the Pareto optimal set and the estimations converge to the true objective function values. Numerical results reveal that the variant with multiple replications is extremely intensive in terms of computational resources compared to MOPBnB(so). In addition, numerical results show that MOPBnB(so) outperforms a genetic algorithm NSGA-II on test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04554v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Huang, Zelda B. Zabinsky</dc:creator>
    </item>
    <item>
      <title>Set Smoothness Unlocks Clarke Hyper-stationarity in Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2506.04587</link>
      <description>arXiv:2506.04587v1 Announce Type: new 
Abstract: Solving bilevel optimization (BLO) problems to global optimality is generally intractable. A common alternative is to compute a hyper-stationary point -- a stationary point of the hyper-objective function formed by minimizing/maximizing the upper-level function over the lower-level solution set. However, existing approaches either yield weak notions of stationarity or rely on restrictive assumptions to ensure the smoothness of hyper-objective functions. In this paper, we remove these impractical assumptions and show that strong (Clarke) hyper-stationarity is still computable even when the hyper-objective is nonsmooth. Our key tool is a new structural condition, called set smoothness, which captures the variational relationship between the lower-level solution set and the upper-level variable. We prove that this condition holds for a broad class of BLO problems and ensures weak convexity (resp. concavity) of pessimistic (resp. optimistic) hyper-objective functions. Building on this, we show that a zeroth-order algorithm computes approximate Clarke hyper-stationary points with a non-asymptotic convergence guarantee. To the best of our knowledge, this is the first computational guarantee for Clarke-type stationarity for nonsmooth hyper-objective functions in BLO.Our developments, especially the set smoothness property, contribute to a deeper understanding of BLO computability and may inspire applications in other fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04587v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Chen, Jiajin Li, Anthony Man-cho So</dc:creator>
    </item>
    <item>
      <title>Achieving Linear Speedup and Near-Optimal Complexity for Decentralized Optimization over Row-stochastic Networks</title>
      <link>https://arxiv.org/abs/2506.04600</link>
      <description>arXiv:2506.04600v1 Announce Type: new 
Abstract: A key challenge in decentralized optimization is determining the optimal convergence rate and designing algorithms to achieve it. While this problem has been extensively addressed for doubly-stochastic and column-stochastic mixing matrices, the row-stochastic scenario remains unexplored. This paper bridges this gap by introducing effective metrics to capture the influence of row-stochastic mixing matrices and establishing the first convergence lower bound for decentralized learning over row-stochastic networks. However, existing algorithms fail to attain this lower bound due to two key issues: deviation in the descent direction caused by the adapted gradient tracking (GT) and instability introduced by the Pull-Diag protocol. To address descent deviation, we propose a novel analysis framework demonstrating that Pull-Diag-GT achieves linear speedup, the first such result for row-stochastic decentralized optimization. Moreover, by incorporating a multi-step gossip (MG) protocol, we resolve the instability issue and attain the lower bound, achieving near-optimal complexity for decentralized optimization over row-stochastic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04600v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liyuan Liang, Xinyi Chen, Gan Luo, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Energy Consumption Optimization for Autonomous Vehicles via Positive Control Input Minimization</title>
      <link>https://arxiv.org/abs/2506.04685</link>
      <description>arXiv:2506.04685v1 Announce Type: new 
Abstract: Autonomous vehicles (AVs) present a unique opportunity to improve the sustainability of transportation systems by adopting eco-driving strategies that reduce energy consumption and emissions. This paper introduces a novel surrogate model for energy and fuel consumption that minimizes Positive Control Input (PCI). Unlike conventional objectives such as squared acceleration, which often misrepresent actual energy usage, PCI provides a more accurate and optimization-friendly alternative. Building on PCI, we propose ECO+, a convex, time-based trajectory optimization framework that ensures safety and passenger comfort while optimizing energy use for AVs approaching an intersection. To improve computational efficiency, quadratic resistive forces are approximated using piecewise affine segments, resulting in a linear programming formulation. ECO+ is validated using empirical fuel and electric energy models and benchmarked against established optimization strategies, including a state-of-the-art nonlinear solver. Simulation results demonstrate that ECO+ consistently outperforms baseline methods in reducing energy consumption, even under strict comfort constraints and in scenarios involving a leading vehicle. Moreover, initializing a nonlinear solver with ECO+ yields only marginal gains, indicating that ECO+ is effective as a standalone eco-driving strategy. These findings highlight ECO+ as a practical, scalable, and computationally efficient solution for enhancing the sustainability of autonomous urban mobility systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04685v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Hadjigeorgiou, Stelios Timotheou</dc:creator>
    </item>
    <item>
      <title>Was Residual Penalty and Neural Operators All We Needed for Solving Optimal Control Problems?</title>
      <link>https://arxiv.org/abs/2506.04742</link>
      <description>arXiv:2506.04742v1 Announce Type: new 
Abstract: Neural networks have been used to solve optimal control problems, typically by training neural networks using a combined loss function that considers data, differential equation residuals, and objective costs. We show that including cost functions in the training process is unnecessary, advocating for a simpler architecture and streamlined approach by decoupling the optimal control problem from the training process. Thus, our work shows that a simple neural operator architecture, such as DeepONet, coupled with an unconstrained optimization routine, can solve multiple optimal control problems with a single physics-informed training phase and a subsequent optimization phase. We achieve this by adding a penalty term based on the differential equation residual to the cost function and computing gradients with respect to the control using automatic differentiation through the trained neural operator within an iterative optimization routine. We showcase our method on nine distinct optimal control problems by training three separate DeepONet models, each corresponding to a different differential equation. For each model, we solve three problems with varying cost functions, demonstrating accurate and consistent performance across all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04742v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver G. S. Lundqvist, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>A Newton Augmented Lagrangian Method for Symmetric Cone Programming with Complexity Analysis</title>
      <link>https://arxiv.org/abs/2506.04802</link>
      <description>arXiv:2506.04802v1 Announce Type: new 
Abstract: Symmetric cone programming incorporates a broad class of convex optimization problems, including linear programming, second-order cone programming, and semidefinite programming. Although the augmented Lagrangian method (ALM) is well-suited for large-scale scenarios, its subproblems are often not second-order continuously differentiable, preventing direct use of classical Newton methods. To address this issue, we observe that barrier functions from interior-point methods (IPMs) naturally serve as effective smoothing terms to alleviate such nonsmoothness. By combining the strengths of ALM and IPMs, we construct a novel augmented Lagrangian function and subsequently develop a Newton augmented Lagrangian (NAL) method. By leveraging the self-concordance property of the barrier function, the proposed method is shown to achieve an $\mathcal{O}(\epsilon^{-1})$ complexity bound. Furthermore, we demonstrate that the condition numbers of the Schur complement matrices in the NAL method are considerably better than those of classical IPMs, as visually evidenced by a heatmap of condition numbers. Numerical experiments conducted on standard benchmarks confirm that the NAL method exhibits significant performance improvements compared to several existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04802v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui-Jin Zhang, Ruoyu Diao, Xin-Wei Liu, Yu-Hong Dai</dc:creator>
    </item>
    <item>
      <title>A robust approach to sigma point Kalman filtering</title>
      <link>https://arxiv.org/abs/2506.04815</link>
      <description>arXiv:2506.04815v1 Announce Type: new 
Abstract: In this paper, we address a robust nonlinear state estimation problem under model uncertainty by formulating a dynamic minimax game: one player designs the robust estimator, while the other selects the least favorable model from an ambiguity set of possible models centered around the nominal one. To characterize a closed-form expression for the conditional expectation characterizing the estimator, we approximate the center of this ambiguity set by means of a sigma point approximation. Furthermore, since the least favorable model is generally nonlinear and non-Gaussian, we derive a simulator based on a Markov chain Monte Carlo method to generate data from such model. Finally, some numerical examples show that the proposed filter outperforms the existing filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04815v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shenglun Yi, Mattia Zorzi</dc:creator>
    </item>
    <item>
      <title>Bilevel Optimization for Improved Flexibility Aggregation Models of Electric Vehicle Fleets</title>
      <link>https://arxiv.org/abs/2506.04843</link>
      <description>arXiv:2506.04843v1 Announce Type: new 
Abstract: Electric vehicle (EV) fleets are expected to become an increasingly important source of flexibility for power system operations. However, accurately capturing the flexibility potential of numerous and heterogeneous EVs remains a significant challenge. We propose a bilevel optimization formulation to enhance flexibility aggregations of electric vehicle fleets. The outer level minimizes scheduling deviations between the aggregated and reference EV units, while the inner level maximizes the aggregated unit's profits. Our approach introduces hourly to daily scaling factor mappings to parameterize the aggregated EV units. Compared to simple aggregation methods, the proposed framework reduces the root-mean-square error of charging power by 78~per cent, providing more accurate flexibility representations. The proposed framework also provides a foundation for several potential extensions in future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04843v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp H\"artel, Michael von Bonin</dc:creator>
    </item>
    <item>
      <title>On the construction of a gradient method of quadratic optimization, optimal from the point of view of minimizing the distance to the exact solution</title>
      <link>https://arxiv.org/abs/2506.04866</link>
      <description>arXiv:2506.04866v1 Announce Type: new 
Abstract: Problems of quadratic optimization in Hilbert space often arise when solving ill-posed problems for differential equations. In this case, the target value of the functional is known. In addition, the structure of the functional allows calculating the gradient by solving well-posed problems, which allows applying first-order methods. This article is devoted to the construction of the $m$-moment minimum error method -- an effective method that minimizes the distance to the exact solution. The convergence and optimality of the constructed method are proved, as well as the impossibility of uniform convergence of methods operating in Krylov subspaces. Numerical experiments are carried out demonstrating the efficiency of applying the $m$-moment minimum error method to solving various ill-posed problems: the initial-boundary value problem for the Helmholtz equation, the retrospective Cauchy problem for the heat equation, and the inverse problem of thermoacoustics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04866v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. V. Pletnev</dc:creator>
    </item>
    <item>
      <title>Unregularized limit of stochastic gradient method for Wasserstein distributionally robust optimization</title>
      <link>https://arxiv.org/abs/2506.04948</link>
      <description>arXiv:2506.04948v1 Announce Type: new 
Abstract: Distributionally robust optimization offers a compelling framework for model fitting in machine learning, as it systematically accounts for data uncertainty. Focusing on Wasserstein distributionally robust optimization, we investigate the regularized problem where entropic smoothing yields a sampling-based approximation of the original objective. We establish the convergence of the approximate gradient over a compact set, leading to the concentration of the regularized problem critical points onto the original problem critical set as regularization diminishes and the number of approximation samples increases. Finally, we deduce convergence guarantees for a projected stochastic gradient method. Our analysis covers a general machine learning situation with an unbounded sample space and mixed continuous-discrete data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04948v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tam Le (LPSM, UPCit\'e)</dc:creator>
    </item>
    <item>
      <title>An emergence-oriented approach to cyclic pursuit</title>
      <link>https://arxiv.org/abs/2506.05157</link>
      <description>arXiv:2506.05157v1 Announce Type: new 
Abstract: In this paper, we explore the cyclic pursuit problem of unicycles and study circular formation from an emergence perspective. We first establish a systematic study on such formation and derive a necessary and sufficient condition for its existence. Building on this theoretical foundation, we design a distributed control law that enables the spontaneous formation of circular formations through only local interactions. Notably, key geometric features -- including the radius and agent spacing -- are not imposed externally but emerge intrinsically from the initial conditions of the group. The framework further includes a local stability analysis for small agent group ($n \leq 3$), providing analytical insight into the convergence mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05157v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaozhan Yao, Yuhua Yao, Xiaoming Hu</dc:creator>
    </item>
    <item>
      <title>Optimal-PhiBE: A PDE-based Model-free framework for Continuous-time Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2506.05208</link>
      <description>arXiv:2506.05208v1 Announce Type: new 
Abstract: This paper addresses continuous-time reinforcement learning (CTRL) where the system dynamics are governed by a stochastic differential equation but are unknown, and only discrete-time observations are available. Existing approaches face limitations: model-based PDE methods suffer from non-identifiability, while model-free methods based on the optimal Bellman equation (Optimal-BE) are prone to large discretization errors sensitive to both the dynamics and reward structure. To overcome these challenges, we introduce Optimal-PhiBE, a formulation that integrates discrete-time information into a continuous-time PDE, combining the strength of both existing frameworks while mitigating their limitations. Optimal-PhiBE avoids explicit dynamics estimation, exhibits smaller discretization errors when the uncontrolled system evolves slowly, and demonstrates reduced sensitivity to oscillatory reward structures. In the linear-quadratic regulator (LQR) setting, sharp error bounds are established for both Optimal-PhiBE and Optimal-BE. The results show that Optimal-PhiBE exactly recovers the optimal policy in the undiscounted case and substantially outperforms Optimal-BE when the problem is weakly discounted or control-dominant. Furthermore, we extend Optimal-PhiBE to higher orders, providing increasingly accurate approximations. A model-free policy iteration algorithm is proposed to solve the Optimal-PhiBE directly from trajectory data. Numerical experiments are conducted to verify the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05208v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhua Zhu, Yuming Zhang, Haoyu Zhang</dc:creator>
    </item>
    <item>
      <title>Regularization of non-overshooting quasi-continuous sliding mode control for chattering suppression at equilibrium</title>
      <link>https://arxiv.org/abs/2506.05283</link>
      <description>arXiv:2506.05283v1 Announce Type: new 
Abstract: Robust finite-time feedback controller introduced for the second-order systems in [1] can be seen as a non-overshooting quasi-continuous sliding mode control. The paper proposes a regularization scheme to suppress inherent chattering due to discontinuity of the control [1] in the origin, in favor of practical applications. A detailed analysis with ISS and iISS proofs are provided along with supporting numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05283v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>Leveraging Coordinate Momentum in SignSGD and Muon: Memory-Optimized Zero-Order</title>
      <link>https://arxiv.org/abs/2506.04430</link>
      <description>arXiv:2506.04430v1 Announce Type: cross 
Abstract: Fine-tuning Large Language Models (LLMs) is essential for adapting pre-trained models to downstream tasks. Yet traditional first-order optimizers such as Stochastic Gradient Descent (SGD) and Adam incur prohibitive memory and computational costs that scale poorly with model size. In this paper, we investigate zero-order (ZO) optimization methods as a memory- and compute-efficient alternative, particularly in the context of parameter-efficient fine-tuning techniques like LoRA. We propose $\texttt{JAGUAR SignSGD}$, a ZO momentum-based algorithm that extends ZO SignSGD, requiring the same number of parameters as the standard ZO SGD and only $\mathcal{O}(1)$ function evaluations per iteration. To the best of our knowledge, this is the first study to establish rigorous convergence guarantees for SignSGD in the stochastic ZO case. We further propose $\texttt{JAGUAR Muon}$, a novel ZO extension of the Muon optimizer that leverages the matrix structure of model parameters, and we provide its convergence rate under arbitrary stochastic noise. Through extensive experiments on challenging LLM fine-tuning benchmarks, we demonstrate that the proposed algorithms meet or exceed the convergence quality of standard first-order methods, achieving significant memory reduction. Our theoretical and empirical results establish new ZO optimization methods as a practical and theoretically grounded approach for resource-constrained LLM adaptation. Our code is available at https://github.com/brain-mmo-lab/ZO_LLM</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04430v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egor Petrov, Grigoriy Evseev, Aleksey Antonov, Andrey Veprikov, Pavel Plyusnin, Nikolay Bushkov, Stanislav Moiseev, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>KOALA++: Efficient Kalman-Based Optimization of Neural Networks with Gradient-Covariance Products</title>
      <link>https://arxiv.org/abs/2506.04432</link>
      <description>arXiv:2506.04432v1 Announce Type: cross 
Abstract: We propose KOALA++, a scalable Kalman-based optimization algorithm that explicitly models structured gradient uncertainty in neural network training. Unlike second-order methods, which rely on expensive second order gradient calculation, our method directly estimates the parameter covariance matrix by recursively updating compact gradient covariance products. This design improves upon the original KOALA framework that assumed diagonal covariance by implicitly capturing richer uncertainty structure without storing the full covariance matrix and avoiding large matrix inversions. Across diverse tasks, including image classification and language modeling, KOALA++ achieves accuracy on par or better than state-of-the-art first- and second-order optimizers while maintaining the efficiency of first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04432v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixuan Xia, Aram Davtyan, Paolo Favaro</dc:creator>
    </item>
    <item>
      <title>Gordian split links in the Gehring ropelength problem</title>
      <link>https://arxiv.org/abs/2506.04644</link>
      <description>arXiv:2506.04644v1 Announce Type: cross 
Abstract: A thick link is a link in Euclidean three-space such that each component of the link lies at distance at least 1 from every other component. Strengthening the notion of thickness, we define a thickly embedded link to be a thick link whose open radius-1/2 normal disk bundles of all components are embedded. The Gehring ropelength problem asks how large the sum of the lengths of the components of a thick (respectively thickly embedded) link must be, given the link homotopy (respectively isotopy) class of the link. A thick homotopy (isotopy) is a link homotopy (isotopy) of a thick (thickly embedded) link that preserves thickness throughout, and such that during the homotopy the total length of the link never exceeds the initial total length. These notions of thick homotopy and isotopy are more permissive than other notions of physical link isotopies in which the length of each individual component must remain constant (no "length trading"). We construct an explicit example of a thickly embedded 4-component link which is topologically split but cannot be split by a thick homotopy, and thick links in every homotopy class with 2 components that are non-global local minima for ropelength. This is the first time such local minima for ropelength have been explicitly constructed. In particular, we construct a thick 2-component link in the link homotopy class of the unlink which cannot be split through a thick homotopy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04644v1</guid>
      <category>math.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Friedrich Bauermeister</dc:creator>
    </item>
    <item>
      <title>Application of SDRE to Achieve Gait Control in a Bipedal Robot for Knee-Type Exoskeleton Testing</title>
      <link>https://arxiv.org/abs/2506.04680</link>
      <description>arXiv:2506.04680v1 Announce Type: cross 
Abstract: Exoskeletons are widely used in rehabilitation and industrial applications to assist human motion. However, direct human testing poses risks due to possible exoskeleton malfunctions and inconsistent movement replication. To provide a safer and more repeatable testing environment, this study employs a bipedal robot platform to reproduce human gait, allowing for controlled exoskeleton evaluations. A control strategy based on the State-Dependent Riccati Equation (SDRE) is formulated to achieve optimal torque control for accurate gait replication. The bipedal robot dynamics are represented using double pendulum model, where SDRE-optimized control inputs minimize deviations from human motion trajectories. To align with motor behavior constraints, a parameterized control method is introduced to simplify the control process while effectively replicating human gait. The proposed approach initially adopts a ramping trapezoidal velocity model, which is then adapted into a piecewise linear velocity-time representation through motor command overwriting. This modification enables finer control over gait phase transitions while ensuring compatibility with motor dynamics. The corresponding cost function optimizes the control parameters to minimize errors in joint angles, velocities, and torques relative to SDRE control result. By structuring velocity transitions in accordance with motor limitations, the method reduce the computational load associated with real-time control. Experimental results verify the feasibility of the proposed parameterized control method in reproducing human gait. The bipedal robot platform provides a reliable and repeatable testing mechanism for knee-type exoskeletons, offering insights into exoskeleton performance under controlled conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04680v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ping-Kong Huang, Chien-Wu Lan, Chin-Tien Wu</dc:creator>
    </item>
    <item>
      <title>On Pioneering Works of Albert Shiryaev on Markov Decision Processes and Some Later Developments</title>
      <link>https://arxiv.org/abs/2506.04896</link>
      <description>arXiv:2506.04896v1 Announce Type: cross 
Abstract: This article is dedicated to three fundamental papers on Markov Decision Processes and on control with incomplete observations published by Albert Shiryaev approximately sixty years ago. One of these papers was coauthored with O.V. Viskov. We discuss some of the results and some of many rich ideas presented in these papers and survey some later developments. At the end we mention some recent studies of Albert Shiryaev on Kolmogorov's equations for jump Markov processes and on control of continuous-time jump Markov processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04896v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene A. Feinberg</dc:creator>
    </item>
    <item>
      <title>Fast PET Reconstruction with Variance Reduction and Prior-Aware Preconditioning</title>
      <link>https://arxiv.org/abs/2506.04976</link>
      <description>arXiv:2506.04976v1 Announce Type: cross 
Abstract: We investigate subset-based optimization methods for positron emission tomography (PET) image reconstruction incorporating a regularizing prior. PET reconstruction methods that use a prior, such as the relative difference prior (RDP), are of particular relevance, as they are widely used in clinical practice and have been shown to outperform conventional early-stopped and post-smoothed ordered subsets expectation maximization (OSEM).
  Our study evaluates these methods on both simulated data and real brain PET scans from the 2024 PET Rapid Image Reconstruction Challenge (PETRIC), where the main objective was to achieve RDP-regularized reconstructions as fast as possible, making it an ideal benchmark. Our key finding is that incorporating the effect of the prior into the preconditioner is crucial for ensuring fast and stable convergence.
  In extensive simulation experiments, we compare several stochastic algorithms -- including Stochastic Gradient Descent (SGD), Stochastic Averaged Gradient Amelior\'e (SAGA), and Stochastic Variance Reduced Gradient (SVRG) -- under various algorithmic design choices and evaluate their performance for varying count levels and regularization strengths. The results show that SVRG and SAGA outperformed SGD, with SVRG demonstrating a slight overall advantage. The insights gained from these simulations directly contributed to the design of our submitted algorithms, which formed the basis of the winning contribution to the PETRIC 2024 challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04976v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Zeljko Kereta, Georg Schramm</dc:creator>
    </item>
    <item>
      <title>Strong stability of linear delay-difference equations</title>
      <link>https://arxiv.org/abs/2506.05002</link>
      <description>arXiv:2506.05002v1 Announce Type: cross 
Abstract: This paper considers linear delay-difference equations, that is, equations relating the state at a given time with its past values over a given bounded interval. After providing a well-posedness result and recalling Hale--Silkowski Criterion for strong stability in the case of equations with finitely many pointwise delays, we propose a generalization of the notion of strong stability to the more general class of linear delay-difference equations with an integral term defined by a matrix-valued measure. Our main result is an extension of Melvin Criterion for the strong stability of scalar equations, showing that local and global strong stability are equivalent, and that they can be characterized in terms of the total variation of the function defining the equation. We also provide numerical illustrations of our main result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05002v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Gon\c{c}alves Netto, Yacine Chitour, Guilherme Mazanti</dc:creator>
    </item>
    <item>
      <title>Cautious Optimism: A Meta-Algorithm for Near-Constant Regret in General Games</title>
      <link>https://arxiv.org/abs/2506.05005</link>
      <description>arXiv:2506.05005v1 Announce Type: cross 
Abstract: Recent work [Soleymani et al., 2025] introduced a variant of Optimistic Multiplicative Weights Updates (OMWU) that adaptively controls the learning pace in a dynamic, non-monotone manner, achieving new state-of-the-art regret minimization guarantees in general games. In this work, we demonstrate that no-regret learning acceleration through adaptive pacing of the learners is not an isolated phenomenon. We introduce \emph{Cautious Optimism}, a framework for substantially faster regularized learning in general games. Cautious Optimism takes as input any instance of Follow-the-Regularized-Leader (FTRL) and outputs an accelerated no-regret learning algorithm by pacing the underlying FTRL with minimal computational overhead. Importantly, we retain uncoupledness (learners do not need to know other players' utilities). Cautious Optimistic FTRL achieves near-optimal $O_T(\log T)$ regret in diverse self-play (mixing-and-matching regularizers) while preserving the optimal $O(\sqrt{T})$ regret in adversarial scenarios. In contrast to prior works (e.g. Syrgkanis et al. [2015], Daskalakis et al. [2021]), our analysis does not rely on monotonic step-sizes, showcasing a novel route for fast learning in general games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05005v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashkan Soleymani, Georgios Piliouras, Gabriele Farina</dc:creator>
    </item>
    <item>
      <title>Identifying and Understanding Cross-Class Features in Adversarial Training</title>
      <link>https://arxiv.org/abs/2506.05032</link>
      <description>arXiv:2506.05032v1 Announce Type: cross 
Abstract: Adversarial training (AT) has been considered one of the most effective methods for making deep neural networks robust against adversarial attacks, while the training mechanisms and dynamics of AT remain open research problems. In this paper, we present a novel perspective on studying AT through the lens of class-wise feature attribution. Specifically, we identify the impact of a key family of features on AT that are shared by multiple classes, which we call cross-class features. These features are typically useful for robust classification, which we offer theoretical evidence to illustrate through a synthetic data model. Through systematic studies across multiple model architectures and settings, we find that during the initial stage of AT, the model tends to learn more cross-class features until the best robustness checkpoint. As AT further squeezes the training robust loss and causes robust overfitting, the model tends to make decisions based on more class-specific features. Based on these discoveries, we further provide a unified view of two existing properties of AT, including the advantage of soft-label training and robust overfitting. Overall, these insights refine the current understanding of AT mechanisms and provide new perspectives on studying them. Our code is available at https://github.com/PKU-ML/Cross-Class-Features-AT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05032v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeming Wei, Yiwen Guo, Yisen Wang</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Gradient Descent on Learning Transformers with Residual Connections</title>
      <link>https://arxiv.org/abs/2506.05249</link>
      <description>arXiv:2506.05249v1 Announce Type: cross 
Abstract: Transformer models have emerged as fundamental tools across various scientific and engineering disciplines, owing to their outstanding performance in diverse applications. Despite this empirical success, the theoretical foundations of Transformers remain relatively underdeveloped, particularly in understanding their training dynamics. Existing research predominantly examines isolated components--such as self-attention mechanisms and feedforward networks--without thoroughly investigating the interdependencies between these components, especially when residual connections are present. In this paper, we aim to bridge this gap by analyzing the convergence behavior of a structurally complete yet single-layer Transformer, comprising self-attention, a feedforward network, and residual connections. We demonstrate that, under appropriate initialization, gradient descent exhibits a linear convergence rate, where the convergence speed is determined by the minimum and maximum singular values of the output matrix from the attention layer. Moreover, our analysis reveals that residual connections serve to ameliorate the ill-conditioning of this output matrix, an issue stemming from the low-rank structure imposed by the softmax operation, thereby promoting enhanced optimization stability. We also extend our theoretical findings to a multi-layer Transformer architecture, confirming the linear convergence rate of gradient descent under suitable initialization. Empirical results corroborate our theoretical insights, illustrating the beneficial role of residual connections in promoting convergence stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05249v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Jinxin Zhou, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Cooperation and the Design of Public Goods</title>
      <link>https://arxiv.org/abs/2506.05251</link>
      <description>arXiv:2506.05251v1 Announce Type: cross 
Abstract: We consider the cooperative elements that arise in the design of public goods, such as transportation policies and infrastructure. These involve a variety of stakeholders: governments, businesses, advocates, and users. Their eventual deployment depends on the decision maker's ability to garner sufficient support from each of these groups; we formalize these strategic requirements from the perspective of cooperative game theory. Specifically, we introduce non-transferable utility, linear production (NTU LP) games, which combine the game-theoretic tensions inherent in public decision-making with the modeling flexibility of linear programming. We derive structural properties regarding the non-emptiness, representability and complexity of the core, a solution concept that models the viability of cooperation. In particular, we provide fairly general sufficient conditions under which the core of an NTU LP game is guaranteed to be non-empty, prove that determining membership in the core is co-NP-complete, and develop a cutting plane algorithm to optimize various social welfare objectives subject to core membership. Lastly, we apply these results in a data-driven case study on service plan optimization for the Chicago bus system. As our study illustrates, cooperation is necessary for the successful deployment of transportation service plans and similar public goods, but it may also have adverse or counterintuitive distributive implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05251v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. Carlos Mart\'inez Mori, Alejandro Toriello</dc:creator>
    </item>
    <item>
      <title>State Space Decomposition of Quantum Dynamical Semigroups</title>
      <link>https://arxiv.org/abs/2506.05269</link>
      <description>arXiv:2506.05269v1 Announce Type: cross 
Abstract: The mean evolution of an open quantum system in continuous time is described by a time continuous semigroup of quantum channels (completely positive and trace-preserving linear maps). Baumgartner and Narnhofer presented a general decomposition of the underlying Hilbert space into a sum of invariant subspaces, also called enclosures. We propose a new reading of this result, inspired by the work of Carbone and Pautrat. In addition, we apply this decomposition to a class of open quantum random walks and to quantum trajectories, where we study its uniqueness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05269v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Mousset, Nina H. Amini</dc:creator>
    </item>
    <item>
      <title>Symmetry breaking for local minimizers of a free discontinuity problem</title>
      <link>https://arxiv.org/abs/2506.05270</link>
      <description>arXiv:2506.05270v1 Announce Type: cross 
Abstract: We study a functional defined on the class of piecewise constant functions, combining a jump penalization, which discourages discontinuities, with a fidelity term that penalizes deviations from a given linear function, called the forcing term.
  In one dimension, it is not difficult to see that local minimizers form staircases that approximate the forcing term. Here we show that in two dimensions symmetry breaking occurs, leading to the emergence of exotic minimizers whose level sets are not simple stripes with boundaries orthogonal to the gradient of the forcing term.
  The proof relies on the calibration method for free discontinuity problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05270v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Massimo Gobbino, Nicola Picenni</dc:creator>
    </item>
    <item>
      <title>Tight analyses of first-order methods with error feedback</title>
      <link>https://arxiv.org/abs/2506.05271</link>
      <description>arXiv:2506.05271v1 Announce Type: cross 
Abstract: Communication between agents often constitutes a major computational bottleneck in distributed learning. One of the most common mitigation strategies is to compress the information exchanged, thereby reducing communication overhead. To counteract the degradation in convergence associated with compressed communication, error feedback schemes -- most notably $\mathrm{EF}$ and $\mathrm{EF}^{21}$ -- were introduced. In this work, we provide a tight analysis of both of these methods. Specifically, we find the Lyapunov function that yields the best possible convergence rate for each method -- with matching lower bounds. This principled approach yields sharp performance guarantees and enables a rigorous, apples-to-apples comparison between $\mathrm{EF}$, $\mathrm{EF}^{21}$, and compressed gradient descent. Our analysis is carried out in a simplified yet representative setting, which allows for clean theoretical insights and fair comparison of the underlying mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05271v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Berg Thomsen, Adrien Taylor, Aymeric Dieuleveut</dc:creator>
    </item>
    <item>
      <title>Direct-search methods in the year 2025: Theoretical guarantees and algorithmic paradigms</title>
      <link>https://arxiv.org/abs/2403.05322</link>
      <description>arXiv:2403.05322v2 Announce Type: replace 
Abstract: Optimizing a function without using derivatives is a challenging paradigm, that precludes from using classical algorithms from nonlinear optimization, and may thus seem intractable other than by using heuristics. Nevertheless, the field of derivative-free optimization has succeeded in producing algorithms that do not rely on derivatives and yet are endowed with convergence guarantees. One class of such methods, called direct-search methods, is particularly popular thanks to its simplicity of implementation, even though its theoretical underpinnings are not always easy to grasp.
  In this work, we survey contemporary direct-search algorithms from a theoretical viewpoint, with the aim of highlighting the key theoretical features of these methods. \rev{We provide a basic introduction to the main classes of direct-search methods, including line-search techniques that have received little attention in earlier surveys. We also put a particular emphasis on probabilistic direct-search techniques and their application to noisy problems, a topic that has undergone significant algorithmic development in recent years. Finally, we complement existing surveys by reviewing the main theoretical advances for solving constrained and multiobjective optimization using direct-search algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05322v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. J. Dzahini, F. Rinaldi, C. W. Royer, D. Zeffiro</dc:creator>
    </item>
    <item>
      <title>Long-Term Open-Pit Mine Planning with Large Neighbourhood Search</title>
      <link>https://arxiv.org/abs/2403.18213</link>
      <description>arXiv:2403.18213v3 Announce Type: replace 
Abstract: We present a Large Neighbourhood Search based approach for solving complex long-term open-pit mine planning problems. An initial feasible solution, generated by a sliding windows heuristic, is improved through repeated solves of a restricted mixed-integer program. Each iteration leaves only a subset of the variables in the planning model free to take on new values. We form these subsets through the use of neighbourhood formation strategies that exploit model structure. We show that our approach is able to find near-optimal solutions to problems that cannot be solved by an off-the-shelf solver in a reasonable time frame, or with reasonable computational resources. Our method substantially reduces the solve times required for large models, allowing mine planners to explore multiple scenarios in a timely fashion. Our approach is being used by Rio Tinto to solve large long-term mine planning problems, and has been responsible for generating millions of dollars in value insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18213v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michelle Blom, Adrian R. Pearce, Pascal Cote</dc:creator>
    </item>
    <item>
      <title>An SDE Perspective on Stochastic Inertial Gradient Dynamics with Time-Dependent Viscosity and Geometric Damping</title>
      <link>https://arxiv.org/abs/2407.04562</link>
      <description>arXiv:2407.04562v2 Announce Type: replace 
Abstract: Our approach is part of the close link between continuous dissipative dynamical systems and optimization algorithms. We aim to solve convex minimization problems by means of stochastic inertial differential equations which are driven by the gradient of the objective function. This will provide a general mathematical framework for analyzing fast optimization algorithms with stochastic gradient input. Our study is a natural extension of our previous work devoted to the first-order in time stochastic steepest descent. Our goal is to develop these results further by considering second-order stochastic differential equations in time, incorporating a viscous time-dependent damping and a Hessian-driven damping. To develop this program, we rely on stochastic Lyapunov analysis. Assuming a square-integrability condition on the diffusion term times a function dependant on the viscous damping, and that the Hessian-driven damping is a positive constant, our first main result shows that almost surely, there is convergence of the values, and states fast convergence of the values in expectation. Besides, in the case where the Hessian-driven damping is zero, we conclude with the fast convergence of the values in expectation and in almost sure sense, we also managed to prove almost sure weak convergence of the trajectory. We provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex and strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04562v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Inertial Methods with Viscous and Hessian driven Damping for Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2407.12518</link>
      <description>arXiv:2407.12518v4 Announce Type: replace 
Abstract: In this paper, we aim to study non-convex minimization problems via second-order (in-time) dynamics, including a non-vanishing viscous damping and a geometric Hessian-driven damping. Second-order systems that only rely on a viscous damping may suffer from oscillation problems towards the minima, while the inclusion of a Hessian-driven damping term is known to reduce this effect without explicit construction of the Hessian in practice. There are essentially two ways to introduce the Hessian-driven damping term: explicitly or implicitly. For each setting, we provide conditions on the damping coefficients to ensure convergence of the gradient towards zero. Moreover, if the objective function is definable, we show global convergence of the trajectory towards a critical point as well as convergence rates. Besides, in the autonomous case, if the objective function is Morse, we conclude that the trajectory converges to a local minimum of the objective for almost all initializations. We also study algorithmic schemes for both dynamics and prove discrete analogues of the previous properties under appropriate stepsize conditions. In particular, we consider the case where the objective is only locally Lipschitz smooth and propose a backtracking strategy for which we establish convergence guarantees. Our work is the first one that handles this situation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12518v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control is Almost Optimal for Restless Bandit</title>
      <link>https://arxiv.org/abs/2410.06307</link>
      <description>arXiv:2410.06307v2 Announce Type: replace 
Abstract: We consider the discrete time infinite horizon average reward restless markovian bandit (RMAB) problem. We propose a \emph{model predictive control} based non-stationary policy with a rolling computational horizon $\tau$. At each time-slot, this policy solves a $\tau$ horizon linear program whose first control value is kept as a control for the RMAB. Our solution requires minimal assumptions and quantifies the loss in optimality in terms of $\tau$ and the number of arms, $N$. We show that its sub-optimality gap is $O(1/\sqrt{N})$ in general, and $\exp(-\Omega(N))$ under a local-stability condition. Our proof is based on a framework from dynamic control known as \emph{dissipativity}. Our solution easy to implement and performs very well in practice when compared to the state of the art. Further, both our solution and our proof methodology can easily be generalized to more general constrained MDP settings and should thus, be of great interest to the burgeoning RMAB community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06307v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Gast, Dheeraj Narasimha</dc:creator>
    </item>
    <item>
      <title>Out-of-distribution Robust Optimization</title>
      <link>https://arxiv.org/abs/2410.14899</link>
      <description>arXiv:2410.14899v3 Announce Type: replace 
Abstract: In this paper, we consider the contextual robust optimization problem under an out-of-distribution setting. The contextual robust optimization problem considers a risk-sensitive objective function for an optimization problem with the presence of a context vector (also known as covariates or side information) capturing related information. While the existing works mainly consider the in-distribution setting, and the resultant robustness achieved is in an out-of-sample sense, our paper studies an out-of-distribution setting where there can be a difference between the test environment and the training environment where the data are collected. We propose methods that handle this out-of-distribution setting, and the key relies on a density ratio estimation for the distribution shift. We show that additional structures such as covariate shift and label shift are not only helpful in defending distribution shift but also necessary in avoiding non-trivial solutions compared to other principled methods such as distributionally robust optimization. We also illustrate how the covariates can be useful in this procedure. Numerical experiments generate more intuitions and demonstrate that the proposed methods can help avoid over-conservative solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14899v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongze Cai, Hansheng Jiang, Xiaocheng Li</dc:creator>
    </item>
    <item>
      <title>Sparse Polynomial Matrix Optimization</title>
      <link>https://arxiv.org/abs/2411.15479</link>
      <description>arXiv:2411.15479v3 Announce Type: replace 
Abstract: A polynomial matrix inequality is a formula asserting that a polynomial matrix is positive semidefinite. Polynomial matrix optimization concerns minimizing the smallest eigenvalue of a symmetric polynomial matrix subject to a tuple of polynomial matrix inequalities. This work explores the use of sparsity methods in reducing the complexity of sum-of-squares based methods in verifying polynomial matrix inequalities or solving polynomial matrix optimization. In the unconstrained setting, Newton polytopes can be employed to sparsify the monomial basis, resulting in smaller semidefinite programs. In the general setting, we show how to exploit different types of sparsity (term sparsity, correlative sparsity, matrix sparsity) encoded in polynomial matrices to derive sparse semidefinite programming relaxations for polynomial matrix optimization. For term sparsity, we show that the block structures of the term sparsity iterations with maximal chordal extensions converge to the one determined by PMI sign symmetries. For correlative sparsity, unlike the scalar case, we provide a counterexample showing that asymptotic convergence does not hold under the Archimedean condition and the running intersection property. By employing the theory of matrix-valued measures, we establish several results on detecting global optimality and retrieving optimal solutions under correlative sparsity. The effectiveness of sparsity methods on reducing computational complexity is demonstrated on various examples of polynomial matrix optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15479v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared Miller, Jie Wang, Feng Guo</dc:creator>
    </item>
    <item>
      <title>Positivstellens\"atze for polynomial matrices with universal quantifiers</title>
      <link>https://arxiv.org/abs/2501.03470</link>
      <description>arXiv:2501.03470v3 Announce Type: replace 
Abstract: This paper investigates Positivstellens\"atze for polynomial matrices subject to universally quantified polynomial matrix inequality constraints. We first establish a matrix-valued Positivstellensatz under the Archimedean condition, incorporating universal quantifiers. For scalar-valued polynomial objectives, we further develop a sparse Positivstellensatz that leverages correlative sparsity patterns within these quantified constraints. Moving beyond the Archimedean framework, we then derive a series of generalized Positivstellens\"atze under analogous settings. These results collectively unify and extend foundational theorems in three distinct contexts: classical polynomial Positivstellens\"atze, their universally quantified counterparts, and matrix polynomial formulations. Applications of the established Positivstellens\"atze to robust polynomial matrix optimization are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03470v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng Guo, Jie Wang</dc:creator>
    </item>
    <item>
      <title>Micro-Macro Decomposition of Particle Swarm Optimization Methods</title>
      <link>https://arxiv.org/abs/2501.10306</link>
      <description>arXiv:2501.10306v2 Announce Type: replace 
Abstract: Solving non-convex minimization problems using multi-particle metaheuristic derivative-free optimization methods is still an active area of research. Popular methods are Particle Swarm Optimization (PSO) methods, that iteratively update a population of particles according to dynamics inspired by social interactions between individuals. We present a modification to include constrained minimization problems using exact penalization. Additionally, we utilize the hierarchical structure of PSO to introduce a micro-macro decomposition of the algorithm. The probability density of particles is written as a convex combination of microscopic and macroscopic contributions, and both parts are propagated separately. The decomposition is dynamically updated based on heuristic considerations. Numerical examples compare the results obtained using the algorithm in the microscopic scale, in the macroscopic scale, and, using the new micro-macro decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10306v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michael Herty, Sara Veneruso</dc:creator>
    </item>
    <item>
      <title>Blackout DIFUSCO</title>
      <link>https://arxiv.org/abs/2502.05221</link>
      <description>arXiv:2502.05221v2 Announce Type: replace 
Abstract: This study explores the integration of Blackout Diffusion into the DIFUSCO framework for combinatorial optimization, specifically targeting the Traveling Salesman Problem (TSP). Inspired by the success of discrete-time diffusion models (D3PM) in maintaining structural integrity, we extend the paradigm to a continuous-time framework, leveraging the unique properties of Blackout Diffusion. Continuous-time modeling introduces smoother transitions and refined control, hypothesizing enhanced solution quality over traditional discrete methods. We propose three key improvements to enhance the diffusion process. First, we transition from a discrete-time-based model to a continuous-time framework, providing a more refined and flexible formulation. Second, we refine the observation time scheduling to ensure a smooth and linear transformation throughout the diffusion process, allowing for a more natural progression of states. Finally, building upon the second improvement, we further enhance the reverse process by introducing finer time slices in regions that are particularly challenging for the model, thereby improving accuracy and stability in the reconstruction phase. Although the experimental results did not exceed the baseline performance, they demonstrate the effectiveness of these methods in balancing simplicity and complexity, offering new insights into diffusion-based combinatorial optimization. This work represents the first application of Blackout Diffusion to combinatorial optimization, providing a foundation for further advancements in this domain. * The code is available for review at https://github.com/Giventicket/BlackoutDIFUSCO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05221v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Pyo Seo</dc:creator>
    </item>
    <item>
      <title>Controlling discrete semilinear wave equations toward flocks</title>
      <link>https://arxiv.org/abs/2502.08852</link>
      <description>arXiv:2502.08852v2 Announce Type: replace 
Abstract: In this work, we initiate the research on controlling nonlinear waves propagating on lattices from a completely new perspective. We consider nonlinear waves on a lattice as a system of interacting particles and study their collective flocking behavior. By designing suitable feedback controls, we show that any admissible flock can be reached within a finite amount of time. Finally, we highlight the connection between our flocking problem and a minimal-time problem in the framework of nonlinear Hamilton-Jacobi equations and optimal control theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08852v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sarah Strikwerda, Hung Vinh Tran, Minh-Binh Tran</dc:creator>
    </item>
    <item>
      <title>Solving the semidefinite relaxation of QUBOs in matrix multiplication time, and faster with a quantum computer</title>
      <link>https://arxiv.org/abs/2301.04237</link>
      <description>arXiv:2301.04237v4 Announce Type: replace-cross 
Abstract: Recent works on quantum algorithms for solving semidefinite optimization (SDO) problems have leveraged a quantum-mechanical interpretation of positive semidefinite matrices to develop methods that obtain quantum speedups with respect to the dimension $n$ and number of constraints $m$. While their dependence on other parameters suggests no overall speedup over classical methodologies, some quantum SDO solvers provide speedups in the low-precision regime. We exploit this fact to our advantage, and present an iterative refinement scheme for the Hamiltonian Updates algorithm of Brand\~ao et al. (Quantum 6, 625 (2022)) to exponentially improve the dependence of their algorithm on precision. As a result, we obtain a classical algorithm to solve the semidefinite relaxation of Quadratic Unconstrained Binary Optimization problems (QUBOs) in matrix multiplication time. Provided access to a quantum read/classical write random access memory (QRAM), a quantum implementation of our algorithm exhibits a worst case running time of $\mathcal{O} \left(ns + n^{1.5} \cdot \text{polylog} \left(n, \| C \|_F, \frac{1}{\epsilon} \right) \right)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.04237v4</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Augustino, Giacomo Nannicini, Tam\'as Terlaky, Luis Zuluaga</dc:creator>
    </item>
    <item>
      <title>Multiplicative Dynamic Mode Decomposition</title>
      <link>https://arxiv.org/abs/2405.05334</link>
      <description>arXiv:2405.05334v2 Announce Type: replace-cross 
Abstract: Koopman operators are infinite-dimensional operators that linearize nonlinear dynamical systems, facilitating the study of their spectral properties and enabling the prediction of the time evolution of observable quantities. Recent methods have aimed to approximate Koopman operators while preserving key structures. However, approximating Koopman operators typically requires a dictionary of observables to capture the system's behavior in a finite-dimensional subspace. The selection of these functions is often heuristic, may result in the loss of spectral information, and can severely complicate structure preservation. This paper introduces Multiplicative Dynamic Mode Decomposition (MultDMD), which enforces the multiplicative structure inherent in the Koopman operator within its finite-dimensional approximation. Leveraging this multiplicative property, we guide the selection of observables and define a constrained optimization problem for the matrix approximation, which can be efficiently solved. MultDMD presents a structured approach to finite-dimensional approximations and can more accurately reflect the spectral properties of the Koopman operator. We elaborate on the theoretical framework of MultDMD, detailing its formulation, optimization strategy, and convergence properties. The efficacy of MultDMD is demonstrated through several examples, including the nonlinear pendulum, the Lorenz system, and fluid dynamics data, where we demonstrate its remarkable robustness to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05334v2</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Boull\'e, Matthew J. Colbrook</dc:creator>
    </item>
    <item>
      <title>Predictive control for nonlinear stochastic systems: Closed-loop guarantees with unbounded noise</title>
      <link>https://arxiv.org/abs/2407.13257</link>
      <description>arXiv:2407.13257v5 Announce Type: replace-cross 
Abstract: We present a stochastic model predictive control framework for nonlinear systems subject to unbounded process noise with closed-loop guarantees. First, we provide a conceptual shrinking-horizon framework that utilizes general probabilistic reachable sets and minimizes the expected cost. Then, we provide a tractable receding-horizon formulation that uses a nominal state to minimize a deterministic quadratic cost and satisfy tightened constraints. Our theoretical analysis demonstrates recursive feasibility, satisfaction of chance constraints, and bounds on the expected cost for the resulting closed-loop system. We provide a constructive design for probabilistic reachable sets of nonlinear continuously differentiable systems using stochastic contraction metrics and an assumed bound on the covariance matrices. Numerical simulations highlight the computational efficiency and theoretical guarantees of the proposed method. Overall, this paper provides a framework for computationally tractable stochastic predictive control with closed-loop guarantees for nonlinear systems with unbounded noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13257v5</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3571575</arxiv:DOI>
      <arxiv:journal_reference>Transactions on Automatic Control (2025)</arxiv:journal_reference>
      <dc:creator>Johannes K\"ohler, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Gradient flow in parameter space is equivalent to linear interpolation in output space</title>
      <link>https://arxiv.org/abs/2408.01517</link>
      <description>arXiv:2408.01517v2 Announce Type: replace-cross 
Abstract: We prove that the standard gradient flow in parameter space that underlies many training algorithms in deep learning can be continuously deformed into an adapted gradient flow which yields (constrained) Euclidean gradient flow in output space. Moreover, for the $L^{2}$ loss, if the Jacobian of the outputs with respect to the parameters is full rank (for fixed training data), then the time variable can be reparametrized so that the resulting flow is simply linear interpolation, and a global minimum can be achieved. For the cross-entropy loss, under the same rank condition and assuming the labels have positive components, we derive an explicit formula for the unique global minimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01517v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patr\'icia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Computational complexity of the recoverable robust shortest path problem in acyclic digraphs</title>
      <link>https://arxiv.org/abs/2410.09425</link>
      <description>arXiv:2410.09425v2 Announce Type: replace-cross 
Abstract: In this paper, the recoverable robust shortest path problem in acyclic digraphs is considered. The interval budgeted uncertainty representation is used to model the uncertain second-stage costs. The computational complexity of this problem has been open to date. In this paper, we prove that the problem is strongly NP-hard even for the case of layered acyclic digraphs. We also show that for the discrete budgeted uncertainty, the problem is not approximable unless P=NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09425v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Kasperski, Pawel Zielinski</dc:creator>
    </item>
    <item>
      <title>Projection-based Lyapunov method for fully heterogeneous weakly-coupled MDPs</title>
      <link>https://arxiv.org/abs/2502.06072</link>
      <description>arXiv:2502.06072v4 Announce Type: replace-cross 
Abstract: Heterogeneity poses a fundamental challenge for many real-world large-scale decision-making problems but remains largely understudied. In this paper, we study the fully heterogeneous setting of a prominent class of such problems, known as weakly-coupled Markov decision processes (WCMDPs). Each WCMDP consists of $N$ arms (or subproblems), which have distinct model parameters in the fully heterogeneous setting, leading to the curse of dimensionality when $N$ is large. We show that, under mild assumptions, an efficiently computable policy achieves an $O(1/\sqrt{N})$ optimality gap in the long-run average reward per arm for fully heterogeneous WCMDPs as $N$ becomes large. This is the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs. Our main technical innovation is the construction of projection-based Lyapunov functions that certify the convergence of rewards and costs to an optimal region, even under full heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06072v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangcheng Zhang, Yige Hong, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Higher-Order Group Synchronization</title>
      <link>https://arxiv.org/abs/2505.21932</link>
      <description>arXiv:2505.21932v2 Announce Type: replace-cross 
Abstract: Group synchronization is the problem of determining reliable global estimates from noisy local measurements on networks. The typical task for group synchronization is to assign elements of a group to the nodes of a graph in a way that respects group elements given on the edges which encode information about local pairwise relationships between the nodes. In this paper, we introduce a novel higher-order group synchronization problem which operates on a hypergraph and seeks to synchronize higher-order local measurements on the hyperedges to obtain global estimates on the nodes. Higher-order group synchronization is motivated by applications to computer vision and image processing, among other computational problems. First, we define the problem of higher-order group synchronization and discuss its mathematical foundations. Specifically, we give necessary and sufficient synchronizability conditions which establish the importance of cycle consistency in higher-order group synchronization. Then, we propose the first computational framework for general higher-order group synchronization; it acts globally and directly on higher-order measurements using a message passing algorithm. We discuss theoretical guarantees for our framework, including convergence analyses under outliers and noise. Finally, we show potential advantages of our method through numerical experiments. In particular, we show that in certain cases our higher-order method applied to rotational and angular synchronization outperforms standard pairwise synchronization methods and is more robust to outliers. We also show that our method has comparable performance on simulated cryo-electron microscopy (cryo-EM) data compared to a standard cryo-EM reconstruction package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21932v2</guid>
      <category>stat.ML</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adriana L. Duncan, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>A Causation-Based Framework for Pricing and Cost Allocation of Energy, Reserves, and Transmission in Modern Power Systems</title>
      <link>https://arxiv.org/abs/2505.24159</link>
      <description>arXiv:2505.24159v2 Announce Type: replace-cross 
Abstract: The increasing vulnerability of power systems has heightened the need for operating reserves to manage contingencies such as generator outages, line failures, and sudden load variations. Unlike energy costs, driven by consumer demand, operating reserve costs arise from addressing the most critical credible contingencies - prompting the question: how should these costs be allocated through efficient pricing mechanisms? As an alternative to previously reported schemes, this paper presents a new causation-based pricing framework for electricity markets based on contingency-constrained energy and reserve scheduling models. Major salient features include a novel security charge mechanism along with the explicit definition of prices for up-spinning reserves, down-spinning reserves, and transmission services. These features ensure more comprehensive and efficient cost-reflective market operations. Moreover, the proposed nodal pricing scheme yields revenue adequacy and neutrality while promoting reliability incentives for generators based on the cost-causation principle. An additional salient aspect of the proposed framework is the economic incentive for transmission assets, which are remunerated based on their use to deliver energy and reserves across all contingency states. Numerical results from two case studies illustrate the performance of the proposed pricing scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24159v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.PR</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luiza Ribeiro, Alexandre Street, Jose Manuel Arroyo, Rodrigo Moreno</dc:creator>
    </item>
    <item>
      <title>Branch-and-Cut for Mixed-Integer Generalized Nash Equilibrium Problems</title>
      <link>https://arxiv.org/abs/2506.02520</link>
      <description>arXiv:2506.02520v2 Announce Type: replace-cross 
Abstract: Generalized Nash equilibrium problems with mixed-integer variables form an important class of games in which each player solves a mixed-integer optimization problem with respect to her own variables and the strategy space of each player depends on the strategies chosen by the rival players. In this work, we introduce a branch-and-cut algorithm to compute exact pure Nash equilibria for different classes of such mixed-integer games. The main idea is to reformulate the equilibrium problem as a suitable bilevel problem based on the Nikaido--Isoda function of the game. The proposed branch-and-cut method is applicable to generalized Nash equilibrium problems under quite mild assumptions. Depending on the specific setting, we use tailored equilibrium or intersection cuts. The latter are well-known in mixed-integer linear optimization and we adapt them to the game setting. We prove finite termination and correctness of the algorithm and present some first numerical results for two different types of knapsack games and another game based on capacitated flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02520v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alo\"is Duguet, Tobias Harks, Martin Schmidt, Julian Schwarz</dc:creator>
    </item>
  </channel>
</rss>
