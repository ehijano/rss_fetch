<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2025 05:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning-Guided Rolling Horizon Optimization for Long-Horizon Flexible Job-Shop Scheduling</title>
      <link>https://arxiv.org/abs/2502.15791</link>
      <description>arXiv:2502.15791v1 Announce Type: new 
Abstract: Long-horizon combinatorial optimization problems (COPs), such as the Flexible Job-Shop Scheduling Problem (FJSP), often involve complex, interdependent decisions over extended time frames, posing significant challenges for existing solvers. While Rolling Horizon Optimization (RHO) addresses this by decomposing problems into overlapping shorter-horizon subproblems, such overlap often involves redundant computations. In this paper, we present L-RHO, the first learning-guided RHO framework for COPs. L-RHO employs a neural network to intelligently fix variables that in hindsight did not need to be re-optimized, resulting in smaller and thus easier-to-solve subproblems. For FJSP, this means identifying operations with unchanged machine assignments between consecutive subproblems. Applied to FJSP, L-RHO accelerates RHO by up to 54% while significantly improving solution quality, outperforming other heuristic and learning-based baselines. We also provide in-depth discussions and verify the desirable adaptability and generalization of L-RHO across numerous FJSP variates, distributions, online scenarios and benchmark instances. Moreover, we provide a theoretical analysis to elucidate the conditions under which learning is beneficial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15791v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sirui Li, Wenbin Ouyang, Yining Ma, Cathy Wu</dc:creator>
    </item>
    <item>
      <title>Orbital Depot Location Optimization for Satellite Constellation Servicing with Low-Thrust Transfers</title>
      <link>https://arxiv.org/abs/2502.15914</link>
      <description>arXiv:2502.15914v1 Announce Type: new 
Abstract: This paper addresses the critical problem of co-optimizing the optimal locations for orbital depots and the sequence of in-space servicing for a satellite constellation. While most traditional studies used network optimization for this problem, assuming a fixed set of discretized nodes in the network (i.e., a limited number of depot location candidates), this work is unique in that it develops a method to optimize the depot location in continuous space. The problem is formulated as mixed-integer nonlinear programming, and we propose a solution methodology that iteratively solves two decoupled problems: one using mixed-integer linear programming and the other using nonlinear programming with an analytic transfer solution. To demonstrate the effectiveness of our approach, we apply this methodology to a case study involving a GPS satellite constellation. Numerical experiments confirm the stability of our proposed solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15914v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Euihyeon Choi, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Chance constraints transcription and failure risk estimation for stochastic trajectory optimization</title>
      <link>https://arxiv.org/abs/2502.15949</link>
      <description>arXiv:2502.15949v1 Announce Type: new 
Abstract: Space exploration has advanced significantly, with missions increasingly using complex dynamical systems. Optimal trajectory design is crucial, involving the minimization of objective functions while ensuring robustness against measurement and control errors. Recent research has focused on stochastic solvers that address uncertainties through chance constraints, which are relaxed hard constraints allowing for a given failure risk. This study introduces three novel, general, multidimensional transcription methods for chance constraints: the spectral radius, first-order, and d-th order methods. Additionally, we introduce failure risk estimation techniques and a conservatism metric to enable comprehensive comparison with existing approaches. Applications to aerospace test cases demonstrate the effectiveness of the proposed transcriptions, highlighting that state-of-the-art methods significantly overestimate risk. Notably, the d-th order transcription dramatically outperforms the other methods, particularly in high-dimensional scenarios. This work shows that spectral radius-based methods are overly conservative and computationally intensive, while the first-order and d-th order methods offer practical and efficient alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15949v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Caleb, Roberto Armellin, Spencer Boone, St\'ephanie Lizy-Destrez</dc:creator>
    </item>
    <item>
      <title>A convex variational principle for the necessary conditions of classical optimal control</title>
      <link>https://arxiv.org/abs/2502.15973</link>
      <description>arXiv:2502.15973v1 Announce Type: new 
Abstract: A scheme for generating a family of convex variational principles is developed, the Euler- Lagrange equations of each member of the family formally corresponding to the necessary conditions of optimal control of a given system of ordinary differential equations (ODE) in a well-defined sense. The scheme is applied to the Quadratic-Quadratic Regulator problem for which an explicit form of the functional is derived, and existence of minimizers of the variational principle is rigorously shown. It is shown that the Linear-Quadratic Regulator problem with time-dependent forcing can be solved within the formalism without requiring any nonlinear considerations, in contrast to the use of a Riccati system in the classical methodology.
  Our work demonstrates a pathway for solving nonlinear control problems via convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15973v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Acharya, Janusz Ginster</dc:creator>
    </item>
    <item>
      <title>Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization</title>
      <link>https://arxiv.org/abs/2502.16020</link>
      <description>arXiv:2502.16020v1 Announce Type: new 
Abstract: We design and analyze primal-dual, feasible interior-point algorithms (IPAs) employing full Newton steps to solve convex optimization problems in standard conic form. Unlike most nonsymmetric cone programming methods, the algorithms presented in this paper require only a logarithmically homogeneous self-concordant barrier (LHSCB) of the primal cone, but compute feasible and $\varepsilon$-optimal solutions to both the primal and dual problems in $O(\sqrt\nu\log(1/\varepsilon))$ iterations, where $\nu$ is the barrier parameter of the LHSCB; this matches the best known theoretical iteration complexity of IPAs for both symmetric and nonsymmetric cone programming. The definition of the neighborhood of the central path and feasible starts ensure that the computed solutions are compatible with the dual certificates framework of (Davis and Papp, 2022). Several initialization strategies are discussed, including two-phase methods that can be applied if a strictly feasible primal solution is available, and one based on a homogeneous self-dual embedding that allows the rigorous detection of large feasible or optimal solutions. In a detailed study of a classic, notoriously difficult, polynomial optimization problem, we demonstrate that the methods are efficient and numerically reliable. Although the standard approach using semidefinite programming fails for this problem with the solvers we tried, the new IPAs compute highly accurate near-optimal solutions that can be certified to be near-optimal in exact arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16020v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D\'avid Papp, Anita Varga</dc:creator>
    </item>
    <item>
      <title>A Fenchel-Young Loss Approach to Data-Driven Inverse Optimization</title>
      <link>https://arxiv.org/abs/2502.16120</link>
      <description>arXiv:2502.16120v1 Announce Type: new 
Abstract: Data-driven inverse optimization seeks to estimate unknown parameters in an optimization model from observations of optimization solutions. Many existing methods are ineffective in handling noisy and suboptimal solution observations and also suffer from computational challenges. In this paper, we build a connection between inverse optimization and the Fenchel-Young (FY) loss originally designed for structured prediction, proposing a FY loss approach to data-driven inverse optimization. This new approach is amenable to efficient gradient-based optimization, hence much more efficient than existing methods. We provide theoretical guarantees for the proposed method and use extensive simulation and real-data experiments to demonstrate its significant advantage in parameter estimation accuracy, decision error and computational speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16120v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhehao Li, Yanchen Wu, Xiaojie Mao</dc:creator>
    </item>
    <item>
      <title>On Distributed Average Consensus Algorithms</title>
      <link>https://arxiv.org/abs/2502.16200</link>
      <description>arXiv:2502.16200v1 Announce Type: new 
Abstract: Average consensus (AC) strategies play a key role in every system that employs cooperation by means of distributed computations. To promote consensus, an $N$-agent network can repeatedly combine certain node estimates until their mean value is reached. Such algorithms are typically formulated as (global) recursive matrix-vector products of size $N$, where consensus is attained either asymptotically or in finite time. We revisit some existing approaches in these directions and propose new iterative and exact solutions to the problem. Considering directed graphs, this is carried out by interplaying with standalone conterparts, while underpinned by the so-called eigenstep method of finite-time convergence. In particular, we focus on reducing complexity so as to require, overall, as little as ${\cal O}(N)$ additions to achieve the solution exactly. For undirected graphs, the latter compares favorably to existing schemes that require, in total, ${\cal O}(KN^2)$ multiplications to deliver the AC, where $K$ refers to the number of distinct eivenvalues of the underlying graph Laplacian matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16200v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Merched</dc:creator>
    </item>
    <item>
      <title>Weak Closed-loop Solvability for Discrete-time Stochastic Linear-Quadratic Optimal Control</title>
      <link>https://arxiv.org/abs/2502.16229</link>
      <description>arXiv:2502.16229v1 Announce Type: new 
Abstract: In this paper, the solvability of discrete-time stochastic linear-quadratic (LQ) optimal control problem in finite horizon is considered. Firstly, it shows that the closed-loop solvability for the LQ control problem is optimal if and only if the generalized Riccati equation admits a regular solution by solving the forward and backward difference equations iteratively. To this ends, it finds that the open-loop solvability is strictly weaker than closed-loop solvability, that is, the LQ control problem is always open-loop optimal solvable if it is closed-loop optimal solvable but not vice versa. Secondly, by the perturbation method, it proves that the weak-closed loop strategy which is a feedback form of a state feedback representation is equivalent to the open-loop solvability of the LQ control problem. Finally, an example sheds light on the theoretical results established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16229v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Sun, Xianping Wu, Xun Li</dc:creator>
    </item>
    <item>
      <title>Assortment optimization given basket shopping behavior using the Ising model</title>
      <link>https://arxiv.org/abs/2502.16260</link>
      <description>arXiv:2502.16260v1 Announce Type: new 
Abstract: In markets where customers tend to purchase baskets of products rather than single products, assortment optimization is a major challenge for retailers. Removing a product from a retailer's assortment can result in a severe drop in aggregate demand if this product is a complement to other products. Therefore, accounting for the complementarity effect is essential when making assortment decisions. In this paper, we develop a modeling framework designed to address this problem. We model customers' choices using a Markov random field -- in particular, the Ising model -- which captures pairwise demand dependencies as well as the individual attractiveness of each product. Using the Ising model allows us to leverage existing methodologies for various purposes including parameter estimation and efficient simulation of customer choices. We formulate the assortment optimization problem under this model and show that its decision version is NP-hard. We also provide multiple theoretical insights into the structure of the optimal assortments based on the graphical representation of the Ising model, and propose several heuristic algorithms that can be used to obtain high-quality solutions to the assortment optimization problem. Our numerical analysis demonstrates that the developed simulated annealing procedure leads to an expected profit gain of 15% compared to offering an unoptimized assortment (where all products are included) and around 5% compared to using a revenue-ordered heuristic algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16260v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Vasilyev, Sebastian Maier, Ralf W. Seifert</dc:creator>
    </item>
    <item>
      <title>On approximate Pareto solutions in nonsmooth interval-valued multiobjective optimization with data uncertainty in constraints</title>
      <link>https://arxiv.org/abs/2502.16276</link>
      <description>arXiv:2502.16276v1 Announce Type: new 
Abstract: This paper deals with approximate Pareto solutions of a nonsmooth interval-valued multiobjective optimization problem with data uncertainty in constraints. We first introduce some kinds of approximate Pareto solutions for the robust counterpart (RMP) of the problem in question by considering the lower-upper interval order relation including: (almost, almost regular) $\mathcal{E}$-Pareto solution and (almost, almost regular) $\mathcal{E}$-quasi Pareto solution. By using a scalar penalty function, we obtain a result on the existence of an almost regular $\mathcal{E}$-Pareto solution of (RMP) that satisfies the Karush--Kuhn--Tucker necessary optimality condition up to a given precision. We then establish sufficient conditions and Wolfe-type $\mathcal{E}$-duality relations for approximate Pareto solutions of (RMP) under the assumption of generalized convexity. In addition, we present a dual multiobjective problem to the primal one via the $\mathcal{E}$-interval-valued vector Lagrangian function and examine duality relations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16276v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vu Hong Quan, Duong Thi Viet An, Nguyen Van Tuyen</dc:creator>
    </item>
    <item>
      <title>Optimization-free Smooth Control Barrier Function for Polygonal Collision Avoidance</title>
      <link>https://arxiv.org/abs/2502.16293</link>
      <description>arXiv:2502.16293v1 Announce Type: new 
Abstract: Polygonal collision avoidance (PCA) is short for the problem of collision avoidance between two polygons (i.e., polytopes in planar) that own their dynamic equations. This problem suffers the inherent difficulty in dealing with non-smooth boundaries and recently optimization-defined metrics, such as signed distance field (SDF) and its variants, have been proposed as control barrier functions (CBFs) to tackle PCA problems. In contrast, we propose an optimization-free smooth CBF method in this paper, which is computationally efficient and proved to be nonconservative. It is achieved by three main steps: a lower bound of SDF is expressed as a nested Boolean logic composition first, then its smooth approximation is established by applying the latest log-sum-exp method, after which a specified CBF-based safety filter is proposed to address this class of problems. To illustrate its wide applications, the optimization-free smooth CBF method is extended to solve distributed collision avoidance of two underactuated nonholonomic vehicles and drive an underactuated container crane to avoid a moving obstacle respectively, for which numerical simulations are also performed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16293v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shizhen Wu, Yongchun Fang, Ning Sun, Biao Lu, Xiao Liang, Yiming Zhao</dc:creator>
    </item>
    <item>
      <title>Analysis and Improvement of Eviction Enforcement</title>
      <link>https://arxiv.org/abs/2502.16346</link>
      <description>arXiv:2502.16346v1 Announce Type: new 
Abstract: Each year, nearly 13,000 eviction orders are issued in Cook County, Illinois. While most of these orders have an enforcement deadline, a portion does not. The Cook County Sheriff's Office (CCSO) is responsible for enforcing these orders, which involves selecting the orders to prioritize and planning daily enforcement routes. This task presents a challenge: balancing "equity" (i.e., prioritizing orders that have been waiting longer) with "efficiency" (i.e., maximizing the number of orders served). Although the current CCSO policy is highly efficient, a significant fraction of eviction orders miss their deadline. Motivated by the CCSO's operations, we study a model of eviction enforcement planning and propose a policy that dynamically prioritizes orders based on their type (deadline or no deadline), location, and waiting time. Our approach employs a budgeted prize-collecting vehicle routing problem (VRP) for daily planning, where the "prizes" are determined by solving a stochastic control problem. This stochastic control problem, which relies on the VRP for determining feasible actions at each decision point, is high-dimensional due to its spatial nature, leading to the curse of dimensionality. We overcome this challenge by building on recent advances in high-dimensional stochastic control using deep neural networks. We compare the performance of our proposed policy with two practical benchmark policies, including one that mimics the current CCSO policy, using data from CCSO. Similar to the CCSO policy, our proposed policy leads to efficient resource utilization, but it also reduces the percentage of orders that miss their deadline by 72.38% without degrading the overall service effort for either type of orders. In a counterfactual study, we show that increasing the service capacity or extending the enforcement deadline further reduces the fraction of orders missing their deadline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16346v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baris Ata, Yuwei Zhou</dc:creator>
    </item>
    <item>
      <title>Risk Measures for DC Pension Plan Decumulation</title>
      <link>https://arxiv.org/abs/2502.16364</link>
      <description>arXiv:2502.16364v1 Announce Type: new 
Abstract: As the developed world replaces Defined Benefit (DB) pension plans with Defined Contribution (DC) plans, there is a need to develop decumulation strategies for DC plan holders. Optimal decumulation can be viewed as a problem in optimal stochastic control. Formulation as a control problem requires specification of an objective function, which in turn requires a definition of reward and risk. An intuitive specification of reward is the total withdrawals over the retirement period. Most retirees view risk as the possibility of running out of savings. This paper investigates several possible left tail risk measures, in conjunction with DC plan decumulation. The risk measures studied include (i) expected shortfall (ii) linear shortfall and (iii) probability of shortfall. We establish that, under certain assumptions, the set of optimal controls associated with all expected reward and expected shortfall Pareto efficient frontier curves is identical to the set of optimal controls for all expected reward and linear shortfall Pareto efficient frontier curves. Optimal efficient frontiers are determined computationally for each risk measure, based on a parametric market model. Robustness of these strategies is determined by testing the strategies out-of-sample using block bootstrapping of historical data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16364v1</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter A. Forsyth, Yuying Li</dc:creator>
    </item>
    <item>
      <title>Convergence of Clipped SGD on Convex $(L_0,L_1)$-Smooth Functions</title>
      <link>https://arxiv.org/abs/2502.16492</link>
      <description>arXiv:2502.16492v1 Announce Type: new 
Abstract: We study stochastic gradient descent (SGD) with gradient clipping on convex functions under a generalized smoothness assumption called $(L_0,L_1)$-smoothness. Using a double-sampling clipping technique, we establish a high probability convergence rate that matches the rate in the $L$-smooth case up to poly-logarithmic factors and additive terms. We also propose a variation of adaptive SGD with gradient clipping, which achieves the same guarantee. We perform empirical experiments to examine our theory and algorithmic choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16492v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofir Gaash, Kfir Yehuda Levy, Yair Carmon</dc:creator>
    </item>
    <item>
      <title>Risk-averse Decision Making with Contextual Information: Model, Sample Average Approximation, and Kernelization</title>
      <link>https://arxiv.org/abs/2502.16607</link>
      <description>arXiv:2502.16607v1 Announce Type: new 
Abstract: We consider risk-averse contextual optimization problems where the decision maker (DM) faces two types of uncertainties: problem data uncertainty (PDU) and contextual uncertainty (CU) associated with PDU, the DM makes an optimal decision by minimizing the risk arising from PDU based on the present observation of CU and then assesses the risk of the optimal policy against the CU. A natural question arises as to whether the nested risk minimization/assessment process is equivalent to joint risk minimization/assessment against CU and PDU simultaneously. First, we demonstrate that the equivalence can be established by appropriate choices of the risk measures and give counter examples where such equivalence may fail. One of the interesting findings is that the optimal policies are independent of the choice of the risk measure against the CU under certain conditions. Second, by using the equivalence, we propose computational method for solving the risk-averse contextual optimization problem by solving a one-stage risk minimization problem. The latter is particularly helpful in data-driven environments. We consider a number of risk measures/metrics to characterize the DM's risk preference for PDU and discuss the computational tractability for the resulting risk-averse contextual optimization problem. Third, when the risk-averse contextual optimization problem is defined in the reproducing kernel Hilbert space, we show consistency of the optimal values obtained from solving sample average approximation problems. Some numerical tests, in newsvendor problem and portfolio selection problem, are performed to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16607v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Tao, Erick Delage, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Dynamic Basis Function Generation for Network Revenue Management</title>
      <link>https://arxiv.org/abs/2502.16830</link>
      <description>arXiv:2502.16830v1 Announce Type: new 
Abstract: This paper introduces an algorithm that dynamically generates basis functions to approximate the value function in Network Revenue Management. Unlike existing algorithms sampling the parameters of new basis functions, this Nonlinear Incremental Algorithm (NLIAlg) iteratively refines the value function approximation by optimizing these parameters. For larger instances, the Two-Phase Incremental Algorithm (2PIAlg) modifies NLIAlg to leverage the efficiency of LP solvers. It reduces the size of a large-dimensional nonlinear problem and transforms it into an LP by fixing the basis function parameters, which are then optimized in a second phase using the flow imbalance ideas from Adelman and Klabjan (2012). This marks the first application of these techniques in a stochastic setting. The algorithms can operate in two modes: (1) Standalone mode, to construct a value function approximation from scratch, and (2) Add-on mode, to refine an existing approximation. Our numerical experiments indicate that while NLIAlg and 2PIAlg in standalone mode are only feasible for small-scale problems, the heuristic version of 2PIAlg (H-2PIAlg) in add-on mode, using the Affine Approximation and exponential ridge basis functions, can handle extremely large instances that may cause benchmark network revenue management methods to run out of memory. In these scenarios, H-2PIAlg delivers substantially better policies and upper bounds than the Affine Approximation. Furthermore, H-2PIAlg achieves higher average revenues in policy simulations compared to network revenue management benchmarks in instances with limited capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16830v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Adelman, Christiane Barz, Alba V. Olivares-Nadal</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Methods via Inertial Systems with Hessian-driven Damping</title>
      <link>https://arxiv.org/abs/2502.16953</link>
      <description>arXiv:2502.16953v1 Announce Type: new 
Abstract: We analyze the convergence rate of a family of inertial algorithms, which can be obtained by discretization of an inertial system with Hessian-driven damping. We recover a convergence rate, up to a factor of 2 speedup upon Nesterov's scheme, for smooth strongly convex functions. As a byproduct of our analyses, we also derive linear convergence rates for convex functions satisfying quadratic growth condition or Polyak-\L ojasiewicz inequality. As a significant feature of our results, the dependence of the convergence rate on parameters of the inertial system/algorithm is revealed explicitly. This may help one get a better understanding of the acceleration mechanism underlying an inertial algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16953v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zepeng Wang, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>Fast control allocation algorithm for tilt-rotor VTOL aircraft</title>
      <link>https://arxiv.org/abs/2502.16995</link>
      <description>arXiv:2502.16995v1 Announce Type: new 
Abstract: Control algorithms initially developed for tilt-wing vertical take-off and landing (VTOL) aircraft are adapted to the tilt-rotor design. The main difference between the two types of planes is the more complicated interaction between propellers and wings in the tilt-rotor design. Unlike tilt-wing design, the tilt-rotor case varies the angle between the propeller disk and wing cord line, thus introducing a non-linear dependency of lift on thrust and tilt angle. In this paper we develop a precise control allocation method, utilizing Groebner basis algorithms to mask the non-linearity of the control action and allow the use of linear time-invariant control laws for attitude and velocity control architectures. The performance of our approach is discussed and quantified w.r.t. the accuracy of the developed propeller-wing interaction model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16995v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Bel\'ak (LAAS-POP), Didier Henrion (LAAS-POP), Martin Hrom\v{c}\'ik</dc:creator>
    </item>
    <item>
      <title>A Deterministic and Linear Model of Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2502.17012</link>
      <description>arXiv:2502.17012v1 Announce Type: new 
Abstract: We introduce a model of infinite horizon linear dynamic optimization and obtain results concerning existence of solution and satisfaction of the Euler equation and transversality condition being unconditionally sufficient for optimality of a trajectory. We show that the optimal value function is concave and continuous and the optimal trajectory satisfies the functional equation of dynamic programming. Linearity bites when it comes to the definition of optimal decision rules which can no longer be guaranteed to be single-valued. We show that the optimal decision rule is an upper semi-continuous correspondence. For linear cake-eating problems, we obtain monotonicity results for the optimal value function and a conditional monotonicity result for optimal decision rules. We also introduce the concept of a two-phase linear cake eating problem and obtain a necessary condition that must be satisfied by all solutions of such problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17012v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>StochasticDominance.jl: A Julia Package for Higher Order Stochastic Dominance</title>
      <link>https://arxiv.org/abs/2502.17043</link>
      <description>arXiv:2502.17043v1 Announce Type: new 
Abstract: Stochastic dominance is a fundamental concept in decision-making under uncertainty and quantitative finance, yet its practical application is hindered by computational intractability due to infinitely many constraints. We introduce StochasticDominance.jl, an open-source Julia package that efficiently verifies and optimizes under higher-order stochastic dominance constraints. Our approach builds on recent theoretical advancements that reduce infinite constraints to a finite number, making higher-order stochastic dominance more accessible. This package provides a user-friendly, black-box solution, enabling researchers and practitioners to incorporate stochastic dominance constraints seamlessly into their optimization frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17043v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajmadan Lakshmanan, Alois Pichler</dc:creator>
    </item>
    <item>
      <title>A Concise Lyapunov Analysis of Nesterov's Accelerated Gradient Method</title>
      <link>https://arxiv.org/abs/2502.17373</link>
      <description>arXiv:2502.17373v1 Announce Type: new 
Abstract: Convergence analysis of Nesterov's accelerated gradient method has attracted significant attention over the past decades. While extensive work has explored its theoretical properties and elucidated the intuition behind its acceleration, a simple and direct proof of its convergence rates is still lacking. We provide a concise Lyapunov analysis of the convergence rates of Nesterov's accelerated gradient method for both general convex and strongly convex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17373v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Liu</dc:creator>
    </item>
    <item>
      <title>Currency Arbitrage Optimization using Quantum Annealing, QAOA and Constraint Mapping</title>
      <link>https://arxiv.org/abs/2502.15742</link>
      <description>arXiv:2502.15742v1 Announce Type: cross 
Abstract: Currency arbitrage capitalizes on price discrepancies in currency exchange rates between markets to produce profits with minimal risk. By employing a combinatorial optimization problem, one can ascertain optimal paths within directed graphs, thereby facilitating the efficient identification of profitable trading routes. This research investigates the methodologies of quantum annealing and gate-based quantum computing in relation to the currency arbitrage problem. In this study, we implement the Quantum Approximate Optimization Algorithm (QAOA) utilizing Qiskit version 1.2. In order to optimize the parameters of QAOA, we perform simulations utilizing the AerSimulator and carry out experiments in simulation. Furthermore, we present an NchooseK-based methodology utilizing D-Wave's Ocean suite. This methodology enables a comparison of the effectiveness of quantum techniques in identifying optimal arbitrage paths. The results of our study enhance the existing literature on the application of quantum computing in financial optimization challenges, emphasizing both the prospective benefits and the present limitations of these developing technologies in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15742v1</guid>
      <category>q-fin.CP</category>
      <category>math.OC</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sangram Deshpande, Elin Ranjan Das, Frank Mueller</dc:creator>
    </item>
    <item>
      <title>Towards Understanding Gradient Flow Dynamics of Homogeneous Neural Networks Beyond the Origin</title>
      <link>https://arxiv.org/abs/2502.15952</link>
      <description>arXiv:2502.15952v1 Announce Type: cross 
Abstract: Recent works exploring the training dynamics of homogeneous neural network weights under gradient flow with small initialization have established that in the early stages of training, the weights remain small and near the origin, but converge in direction. Building on this, the current paper studies the gradient flow dynamics of homogeneous neural networks with locally Lipschitz gradients, after they escape the origin. Insights gained from this analysis are used to characterize the first saddle point encountered by gradient flow after escaping the origin. Also, it is shown that for homogeneous feed-forward neural networks, under certain conditions, the sparsity structure emerging among the weights before the escape is preserved after escaping the origin and until reaching the next saddle point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15952v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshay Kumar, Jarvis Haupt</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Gradient Descent for Non-Homogeneous Deep Networks</title>
      <link>https://arxiv.org/abs/2502.16075</link>
      <description>arXiv:2502.16075v1 Announce Type: cross 
Abstract: We establish the asymptotic implicit bias of gradient descent (GD) for generic non-homogeneous deep networks under exponential loss. Specifically, we characterize three key properties of GD iterates starting from a sufficiently small empirical risk, where the threshold is determined by a measure of the network's non-homogeneity. First, we show that a normalized margin induced by the GD iterates increases nearly monotonically. Second, we prove that while the norm of the GD iterates diverges to infinity, the iterates themselves converge in direction. Finally, we establish that this directional limit satisfies the Karush-Kuhn-Tucker (KKT) conditions of a margin maximization problem. Prior works on implicit bias have focused exclusively on homogeneous networks; in contrast, our results apply to a broad class of non-homogeneous networks satisfying a mild near-homogeneity condition. In particular, our results apply to networks with residual connections and non-homogeneous activation functions, thereby resolving an open problem posed by Ji and Telgarsky (2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16075v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Cai, Kangjie Zhou, Jingfeng Wu, Song Mei, Michael Lindsey, Peter L. Bartlett</dc:creator>
    </item>
    <item>
      <title>Entropic Selection Principle for Monge's Optimal Transport</title>
      <link>https://arxiv.org/abs/2502.16370</link>
      <description>arXiv:2502.16370v1 Announce Type: cross 
Abstract: We investigate the small regularization limit of entropic optimal transport when the cost function is the Euclidean distance in dimensions $d &gt; 1$, and the marginal measures are absolutely continuous with respect to the Lebesgue measure. Our results establish that the limiting optimal transport plan is supported on transport rays. Furthermore, within each transport ray, the limiting transport plan uniquely minimizes a relative entropy functional with respect to specific reference measures supported on the rays. This provides a complete and unique characterization of the limiting transport plan. While similar results have been obtained for $d = 1$ in \cite{Marino} and for discrete measures in \cite{peyr\'e2020computationaloptimaltransport}, this work resolves the previously open case in higher dimensions $d&gt;1.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16370v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shrey Aryan, Promit Ghosal</dc:creator>
    </item>
    <item>
      <title>Understanding Fixed Predictions via Confined Regions</title>
      <link>https://arxiv.org/abs/2502.16380</link>
      <description>arXiv:2502.16380v1 Announce Type: cross 
Abstract: Machine learning models are designed to predict outcomes using features about an individual, but fail to take into account how individuals can change them. Consequently, models can assign fixed predictions that deny individuals recourse to change their outcome. This work develops a new paradigm to identify fixed predictions by finding confined regions in which all individuals receive fixed predictions. We introduce the first method, ReVer, for this task, using tools from mixed-integer quadratically constrained programming. Our approach certifies recourse for out-of-sample data, provides interpretable descriptions of confined regions, and runs in seconds on real world datasets. We conduct a comprehensive empirical study of confined regions across diverse applications. Our results highlight that existing point-wise verification methods fail to discover confined regions, while ReVer provably succeeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16380v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Connor Lawless, Tsui-Wei Weng, Berk Ustun, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Active Learning Classification from a Signal Separation Perspective</title>
      <link>https://arxiv.org/abs/2502.16425</link>
      <description>arXiv:2502.16425v1 Announce Type: cross 
Abstract: In machine learning, classification is usually seen as a function approximation problem, where the goal is to learn a function that maps input features to class labels. In this paper, we propose a novel clustering and classification framework inspired by the principles of signal separation. This approach enables efficient identification of class supports, even in the presence of overlapping distributions. We validate our method on real-world hyperspectral datasets Salinas and Indian Pines. The experimental results demonstrate that our method is competitive with the state of the art active learning algorithms by using a very small subset of data set as training points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16425v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hrushikesh Mhaskar, Ryan O'Dowd, Efstratios Tsoukanis</dc:creator>
    </item>
    <item>
      <title>Deep unrolling for learning optimal spatially varying regularisation parameters for Total Generalised Variation</title>
      <link>https://arxiv.org/abs/2502.16532</link>
      <description>arXiv:2502.16532v1 Announce Type: cross 
Abstract: We extend a recently introduced deep unrolling framework for learning spatially varying regularisation parameters in inverse imaging problems to the case of Total Generalised Variation (TGV). The framework combines a deep convolutional neural network (CNN) inferring the two spatially varying TGV parameters with an unrolled algorithmic scheme that solves the corresponding variational problem. The two subnetworks are jointly trained end-to-end in a supervised fashion and as such the CNN learns to compute those parameters that drive the reconstructed images as close to the ground truth as possible. Numerical results in image denoising and MRI reconstruction show a significant qualitative and quantitative improvement compared to the best TGV scalar parameter case as well as to other approaches employing spatially varying parameters computed by unsupervised methods. We also observe that the inferred spatially varying parameter maps have a consistent structure near the image edges, asking for further theoretical investigations. In particular, the parameter that weighs the first-order TGV term has a triple-edge structure with alternating high-low-high values whereas the one that weighs the second-order term attains small values in a large neighbourhood around the edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16532v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thanh Trung Vu, Andreas Kofler, Kostas Papafitsoros</dc:creator>
    </item>
    <item>
      <title>Optimizing Input Data Collection for Ranking and Selection</title>
      <link>https://arxiv.org/abs/2502.16659</link>
      <description>arXiv:2502.16659v1 Announce Type: cross 
Abstract: We study a ranking and selection (R&amp;S) problem when all solutions share common parametric Bayesian input models updated with the data collected from multiple independent data-generating sources. Our objective is to identify the best system by designing a sequential sampling algorithm that collects input and simulation data given a budget. We adopt the most probable best (MPB) as the estimator of the optimum and show that its posterior probability of optimality converges to one at an exponential rate as the sampling budget increases. Assuming that the input parameters belong to a finite set, we characterize the $\epsilon$-optimal static sampling ratios for input and simulation data that maximize the convergence rate. Using these ratios as guidance, we propose the optimal sampling algorithm for R&amp;S (OSAR) that achieves the $\epsilon$-optimal ratios almost surely in the limit. We further extend OSAR by adopting the kernel ridge regression to improve the simulation output mean prediction. This not only improves OSAR's finite-sample performance, but also lets us tackle the case where the input parameters lie in a continuous space with a strong consistency guarantee for finding the optimum. We numerically demonstrate that OSAR outperforms a state-of-the-art competitor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16659v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eunhye Song, Taeho Kim</dc:creator>
    </item>
    <item>
      <title>Order-Optimal Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2502.16744</link>
      <description>arXiv:2502.16744v1 Announce Type: cross 
Abstract: Projection-based algorithms for constrained Online Convex Optimization (COCO) face scalability challenges in high-dimensional settings due to the computational complexity of projecting iterates onto constraint sets. This paper introduces a projection-free algorithm for COCO that achieves state-of-the-art performance guarantees while eliminating the need for projections. By integrating a separation oracle with adaptive Online Gradient Descent (OGD) and employing a Lyapunov-driven surrogate function, while dynamically adjusting step sizes using gradient norms, our method jointly optimizes the regret and cumulative constraint violation (CCV). We also use a blocked version of OGD that helps achieve tradeoffs betweeen the regret and CCV with the number of calls to the separation oracle. For convex cost functions, our algorithm attains an optimal regret of $\mathcal{O}(\sqrt{T})$ and a CCV of $\mathcal{O}(\sqrt{T} \log T)$, matching the best-known projection-based results, while only using $\tilde{\mathcal{O}}({T})$ calls to the separation oracle. The results also demonstrate a tradeoff where lower calls to the separation oracle increase the regret and the CCV. In the strongly convex setting, we further achieve a regret of $\mathcal{O}(\log T)$ and a CCV of $\mathcal{O}(\sqrt{T\log T} )$, while requiring ${\mathcal{O}}({T}^2)$ calls to the separation oracle. Further, tradeoff with the decreasing oracle calls is studied. These results close the gap between projection-free and projection-based approaches, demonstrating that projection-free methods can achieve performance comparable to projection-based counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16744v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyang Lu, Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Fast, Accurate Manifold Denoising by Tunneling Riemannian Optimization</title>
      <link>https://arxiv.org/abs/2502.16819</link>
      <description>arXiv:2502.16819v1 Announce Type: cross 
Abstract: Learned denoisers play a fundamental role in various signal generation (e.g., diffusion models) and reconstruction (e.g., compressed sensing) architectures, whose success derives from their ability to leverage low-dimensional structure in data. Existing denoising methods, however, either rely on local approximations that require a linear scan of the entire dataset or treat denoising as generic function approximation problems, often sacrificing efficiency and interpretability. We consider the problem of efficiently denoising a new noisy data point sampled from an unknown $d$-dimensional manifold $M \in \mathbb{R}^D$, using only noisy samples. This work proposes a framework for test-time efficient manifold denoising, by framing the concept of "learning-to-denoise" as "learning-to-optimize". We have two technical innovations: (i) online learning methods which learn to optimize over the manifold of clean signals using only noisy data, effectively "growing" an optimizer one sample at a time. (ii) mixed-order methods which guarantee that the learned optimizers achieve global optimality, ensuring both efficiency and near-optimal denoising performance. We corroborate these claims with theoretical analyses of both the complexity and denoising performance of mixed-order traversal. Our experiments on scientific manifolds demonstrate significantly improved complexity-performance tradeoffs compared to nearest neighbor search, which underpins existing provable denoising approaches based on exhaustive search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16819v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyu Wang, Mariam Avagyan, Yihan Shen, Arnaud Lamy, Tingran Wang, Szabolcs M\'arka, Zsuzsa M\'arka, John Wright</dc:creator>
    </item>
    <item>
      <title>On the Global Optimality of Fibonacci Lattices in the Torus</title>
      <link>https://arxiv.org/abs/2502.17082</link>
      <description>arXiv:2502.17082v1 Announce Type: cross 
Abstract: We investigate the question of the optimality of Fibonacci lattices with respect to tensor product energies on the torus, most notably the periodic $L_2$-discrepancy, diaphony and the worst case error of the quasi-Monte Carlo integration over certain parametrized dominating mixed smoothness Sobolev spaces $H_p^d$ of periodic functions. We consider two methods for this question.
  First, a method based on Delsarte's LP-bound from coding theory which will give us, among others, the Fibonacci lattices as the natural candidates for optimal point sets. Second, we will adapt the continuous LP-bound on the sphere (and other spaces) to the torus to get optimality in the continuous setting.
  We conclude with a more in depth look at the $5$-point Fibonacci lattice, giving an effectively computable algorithm for checking if it is optimal and rigorously proving its optimality for quasi-Monte Carlo integration in the range $0 &lt; p \leq 11.66$. We also prove a result on the universal optimality of $3$ points in any dimension.
  The novelty of this approach is the application of LP-methods for tensor product energies in the torus and the systematic study of the simultaneous global optimality of periodic point sets for a class of tensor product potential functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17082v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Nagel</dc:creator>
    </item>
    <item>
      <title>Sparse Hyperparametric Itakura-Saito NMF via Bi-Level Optimization</title>
      <link>https://arxiv.org/abs/2502.17123</link>
      <description>arXiv:2502.17123v1 Announce Type: cross 
Abstract: The selection of penalty hyperparameters is a critical aspect in Nonnegative Matrix Factorization (NMF), since these values control the trade-off between the reconstruction accuracy and the adherence to desired constraints. In this work, we focus on an NMF problem involving the Itakura-Saito (IS) divergence, effective for extracting low spectral density components from spectrograms of mixed signals, enhanced with sparsity constraints. We propose a new algorithm called SHINBO, which introduces a bi-level optimization framework to automatically and adaptively tune the row-dependent penalty hyperparameters, enhancing the ability of IS-NMF to isolate sparse, periodic signals against noise. Experimental results showed SHINBO ensures precise spectral decomposition and demonstrates superior performance in both synthetic and real-world applications. For the latter, SHINBO is particularly useful, as noninvasive vibration-based fault detection in rolling bearings, where the desired signal components often reside in high-frequency subbands but are obscured by stronger, spectrally broader noise. By addressing the critical issue of hyperparameter selection, SHINBO advances the state-of-the-art in signal recovery for complex, noise-dominated environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17123v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Selicatoa, Flavia Esposito, Andersen Ang, Nicoletta Del Buono, Rafal Zdunek</dc:creator>
    </item>
    <item>
      <title>Scaling Limits for Exponential Hedging in the Brownian Framework</title>
      <link>https://arxiv.org/abs/2502.17186</link>
      <description>arXiv:2502.17186v1 Announce Type: cross 
Abstract: In this paper, we consider scaling limits of exponential utility indifference prices for European contingent claims in the Bachelier model. We show that the scaling limit can be represented in terms of the \emph{specific relative entropy}, and in addition we construct asymptotic optimal hedging strategies. To prove the upper bound for the limit, we formulate the dual problem as a stochastic control, and show there exists a classical solution to its HJB equation. The proof for the lower bound relies on the duality result for exponential hedging in discrete time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17186v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Dolinksy, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking Control for Antenna Pointing via Symmetric Product Approximation</title>
      <link>https://arxiv.org/abs/2502.17252</link>
      <description>arXiv:2502.17252v1 Announce Type: cross 
Abstract: This paper investigates extremum seeking control for a torque-controlled antenna pointing system without direct angular measurements. We consider a two-degree-of-freedom (2-DOF) antenna system that receives an unknown signal from its environment, where the signal strength varies with the orientation of the antenna. It is assumed that only real-time measurements of the signal are available. We develop an extremum seeking control strategy that enables the antenna to autonomously adjust its direction to maximize the received signal strength based on the symmetric product approximation. Under suitable assumptions on the signal function, we prove local practical uniform asymptotic stability for the closed-loop system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17252v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Wang, Hashem Ashrafiuon, Sergey G. Nersesov</dc:creator>
    </item>
    <item>
      <title>When to Forget? Complexity Trade-offs in Machine Unlearning</title>
      <link>https://arxiv.org/abs/2502.17323</link>
      <description>arXiv:2502.17323v1 Announce Type: cross 
Abstract: Machine Unlearning (MU) aims at removing the influence of specific data points from a trained model, striving to achieve this at a fraction of the cost of full model retraining. In this paper, we analyze the efficiency of unlearning methods and establish the first upper and lower bounds on minimax computation times for this problem, characterizing the performance of the most efficient algorithm against the most difficult objective function. Specifically, for strongly convex objective functions and under the assumption that the forget data is inaccessible to the unlearning method, we provide a phase diagram for the unlearning complexity ratio -- a novel metric that compares the computational cost of the best unlearning method to full model retraining. The phase diagram reveals three distinct regimes: one where unlearning at a reduced cost is infeasible, another where unlearning is trivial because adding noise suffices, and a third where unlearning achieves significant computational advantages over retraining. These findings highlight the critical role of factors such as data dimensionality, the number of samples to forget, and privacy constraints in determining the practical feasibility of unlearning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17323v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Martin Van Waerebeke, Marco Lorenzi, Giovanni Neglia, Kevin Scaman</dc:creator>
    </item>
    <item>
      <title>Viscosity Solutions in Non-commutative Variables</title>
      <link>https://arxiv.org/abs/2502.17329</link>
      <description>arXiv:2502.17329v1 Announce Type: cross 
Abstract: Motivated by parallels between mean field games and random matrix theory, we develop stochastic optimal control problems and viscosity solutions to Hamilton-Jacobi equations in the setting of non-commutative variables. Rather than real vectors, the inputs to the equation are tuples of self-adjoint operators from a tracial von Neumann algebra. The individual noise from mean field games is replaced by a free semi-circular Brownian motion, which describes the large-$n$ limit of Brownian motion on the space of self-adjoint matrices. We introduce a classical common noise from mean field games into the non-commutative setting as well, allowing the problems to combine both classical and non-commutative randomness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17329v1</guid>
      <category>math.AP</category>
      <category>math.OA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wilfrid Gangbo, David Jekel, Kyeongsik Nam, Aaron Z. Palmer</dc:creator>
    </item>
    <item>
      <title>A unifying view on the irreversible investment exercise boundary in a stochastic, time-inhomogeneous capacity expansion problem</title>
      <link>https://arxiv.org/abs/2209.09878</link>
      <description>arXiv:2209.09878v3 Announce Type: replace 
Abstract: This paper devises a way to solve by the Bank and El Karoui Representation Theorem a quite complex stochastic, continuous time capacity expansion problem with irreversible investment on the finite time interval $[0, T]$ in the presence of a state dependent scrap value at the terminal time $T$. Standard variational methods are not feasible but the functional to be maximized admits a supergradient, hence the optimal control satisfies some first order conditions which are solved by means of the Representation Theorem. The devise introduced is new in singular stochastic control and of interest in its own right. As far as we know the Representation Theorem has never been applied to this extent. Contrary to the no scrap value case, a non integral term depending on the initial capacity $y$ arises in the supergradient making non trivial the application of the Representation Theorem and the existence of the so-called base capacity $l^{\star}_y(t)$, a positive level depending on $y$ which the optimal investment process is shown to become active at. In the special case of deterministic coefficients, the base capacity equals the boundary ${\hat y}(t)$ obtained by variational methods but only under a further assumption that allows to obtain monotonicity and positiveness of ${\hat y}(t)$ by means of probabilistic methods. Therefore getting a unifying view on the curve at which is optimal to invest is possible even in the presence of scrap value but it requires adding some extra conditions. The advantage is that the integral equation of the base capacity may then be used to characterize ${\hat y}(t)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.09878v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria B. Chiarolla</dc:creator>
    </item>
    <item>
      <title>Generalized Hukuhara directional differentiability of interval-valued functions on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2212.04541</link>
      <description>arXiv:2212.04541v5 Announce Type: replace 
Abstract: In this paper, we show that generalized Hukuhara directional differentiability of an interval-valued function (IVF) defined on Riemannian manifolds is not equivalent to the directional differentiability of its center and half-width functions and hence not to its end point functions. This contrasts with S.-L. Chen's \cite{chen} assertion which says the equivalence holds in terms of endpoint functions of an IVF which is defined on a Hadamard manifold. Additionally, the paper addresses some other inaccuracies which arise when assuming the convexity of a function at a single point in its domain. In light of these arguments, the paper presents some basic results that relate to both the convexity and directional differentiability of an IVF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04541v5</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/02331934.2024.2447996</arxiv:DOI>
      <arxiv:journal_reference>Optimization (2025)</arxiv:journal_reference>
      <dc:creator>Hilal Ahmad Bhat, Akhlad Iqbal</dc:creator>
    </item>
    <item>
      <title>A Proximal DC Algorithm for Sample Average Approximation of Chance Constrained Programming</title>
      <link>https://arxiv.org/abs/2301.00423</link>
      <description>arXiv:2301.00423v5 Announce Type: replace 
Abstract: Chance constrained programming (CCP) refers to a type of optimization problem with uncertain constraints that are satisfied with at least a prescribed probability level. In this work, we study the sample average approximation (SAA) of chance constraints. This is an important approach to solving CCP, especially in the data-driven setting where only a sample of multiple realizations of the random vector in the chance constraints is available. The SAA is obtained by replacing the underlying distribution with an empirical distribution over the available sample. Assuming that the functions in chance constraints are all convex, we reformulate the SAA of chance constraints into a difference-of-convex (DC) form. Moreover, considering that the objective function is a difference-of-convex function, the resulting formulation becomes a DC constrained DC program. Then, we propose a proximal DC algorithm for solving this reformulation. In particular, we show that the subproblems of the proximal DC are suitable for off-the-shelf solvers in some scenarios. Moreover, we not only prove the subsequential and sequential convergence of the proposed algorithm but also derive the iteration complexity for finding an approximate Karush-Kuhn-Tucker point. To support and complement our theoretical development, we show via numerical experiments that our proposed approach is competitive with a host of existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00423v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Wang, Rujun Jiang, Qingyuan Kong, Laura Balzano</dc:creator>
    </item>
    <item>
      <title>Linear System Analysis and Optimal Control of Natural Gas Dynamics in Pipeline Networks</title>
      <link>https://arxiv.org/abs/2305.06658</link>
      <description>arXiv:2305.06658v4 Announce Type: replace 
Abstract: We design nonlinear and adaptive linear model-predictive control (MPC) techniques to minimize operational costs of compressor-actuated dynamics in natural gas pipeline networks. We establish stability of the local linear system and derive rigorous bounds on error between the nonlinear and linear system solutions. These bounds are used to quantify conditions under which the linear MPC can substitute the nonlinear MPC without significant loss of predictive accuracy. Furthermore, we prove and numerically verify that the computational cost of the linear MPC is orders of magnitude lower than that of solving the baseline optimal control problem. Numerical simulations are performed on nontrivial networks to demonstrate that the proposed MPC can effectively adapt to varying load conditions while maintaining nearly 95% optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.06658v4</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Sachin Shivakumar, Dieter Armbruster, Rodrigo B. Platte, Anatoly Zlotnik</dc:creator>
    </item>
    <item>
      <title>An Output-Polynomial Time Algorithm to Determine all Supported Efficient Solutions for Multi-Objective Integer Network Flow Problems</title>
      <link>https://arxiv.org/abs/2305.12867</link>
      <description>arXiv:2305.12867v4 Announce Type: replace 
Abstract: This paper addresses the problem of enumerating all supported efficient solutions for a linear multi-objective integer minimum cost flow problem (MOIMCF). It derives an output-polynomial time algorithm to determine all supported efficient solutions for MOIMCF problems. This is the first approach to solve this general problem in output-polynomial time. Moreover, we prove that the existence of an output-polynomial time algorithm to determine all weakly supported nondominated vectors (or all weakly supported efficient solutions) for a MOIMCF problem with a fixed number of d &gt;= 3 objectives can be excluded unless P = NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12867v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David K\"onen, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>Sensitivity of robust optimization problems under drift and volatility uncertainty</title>
      <link>https://arxiv.org/abs/2311.11248</link>
      <description>arXiv:2311.11248v2 Announce Type: replace 
Abstract: We examine optimization problems in which an investor has the opportunity to trade in $d$ stocks with the goal of maximizing her worst-case cost of cumulative gains and losses. Here, worst-case refers to taking into account all possible drift and volatility processes for the stocks that fall within a $\varepsilon$-neighborhood of predefined fixed baseline processes. Although solving the worst-case problem for a fixed $\varepsilon&gt;0$ is known to be very challenging in general, we show that it can be approximated as $\varepsilon\to 0$ by the baseline problem (computed using the baseline processes) in the following sense: Firstly, the value of the worst-case problem is equal to the value of the baseline problem plus $\varepsilon$ times a correction term. This correction term can be computed explicitly and quantifies how sensitive a given optimization problem is to model uncertainty. Moreover, approximately optimal trading strategies for the worst-case problem can be obtained using optimal strategies from the corresponding baseline problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11248v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bartl, Ariel Neufeld, Kyunghyun Park</dc:creator>
    </item>
    <item>
      <title>A Hamilton-Jacobi-Bellman Approach to Ellipsoidal Approximations of Reachable Sets for Linear Time-Varying Systems</title>
      <link>https://arxiv.org/abs/2401.06352</link>
      <description>arXiv:2401.06352v2 Announce Type: replace 
Abstract: Reachable sets for a dynamical system describe collections of system states that can be reached in finite time, subject to system dynamics. They can be used to guarantee goal satisfaction in controller design or to verify that unsafe regions will be avoided. However, general-purpose methods for computing these sets suffer from the curse of dimensionality, which typically prohibits their use for systems with more than a small number of states, even if they are linear. In this paper, we demonstrate that viscosity supersolutions and subsolutions of a Hamilton-Jacobi-Bellman equation can be used to generate, respectively, under-approximating and over-approximating reachable sets for time-varying nonlinear systems. Based on this observation, we derive dynamics for a union and intersection of ellipsoidal sets that, respectively, under-approximate and over-approximate the reachable set for linear time-varying systems subject to an ellipsoidal input constraint and an ellipsoidal terminal (or initial) set. We demonstrate that the dynamics for these ellipsoids can be selected to ensure that their boundaries coincide with the boundary of the exact reachable set along a solution of the system. The ellipsoidal sets can be generated with polynomial computational complexity in the number of states, making our approximation scheme computationally tractable for continuous-time linear time-varying systems of relatively high dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06352v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2024.3512619</arxiv:DOI>
      <dc:creator>Vincent Liu, Chris Manzie, Peter M. Dower</dc:creator>
    </item>
    <item>
      <title>Solving moment and polynomial optimization problems on Sobolev spaces</title>
      <link>https://arxiv.org/abs/2401.07734</link>
      <description>arXiv:2401.07734v3 Announce Type: replace 
Abstract: Using standard tools of harmonic analysis, we state and solve the problem of moments for  non-negative measures supported on the unit ball of a Sobolev space of multivariate periodic trigonometric functions. We describe outer and inner semidefinite approximations of the cone of Sobolev moments. They are the basic components of an infinite-dimensional moment-sums of squares hierarchy, allowing to numerically solve non-convex polynomial optimization problems on infinite-dimensional Sobolev spaces with global convergence guarantees</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07734v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didier Henrion (LAAS-POP), Alessandro Rudi (PSL, DI-ENS, Inria)</dc:creator>
    </item>
    <item>
      <title>On Convergence of Adam for Stochastic Optimization under Relaxed Assumptions</title>
      <link>https://arxiv.org/abs/2402.03982</link>
      <description>arXiv:2402.03982v2 Announce Type: replace 
Abstract: The Adaptive Momentum Estimation (Adam) algorithm is highly effective in training various deep learning tasks. Despite this, there's limited theoretical understanding for Adam, especially when focusing on its vanilla form in non-convex smooth scenarios with potential unbounded gradients and affine variance noise. In this paper, we study vanilla Adam under these challenging conditions. We introduce a comprehensive noise model which governs affine variance noise, bounded noise and sub-Gaussian noise. We show that Adam can find a stationary point with a $\mathcal{O}(\text{poly}(\log T)/\sqrt{T})$ rate in high probability under this general noise model where $T$ denotes total number iterations, matching the lower rate of stochastic first-order algorithms up to logarithm factors. More importantly, we reveal that Adam is free of tuning step-sizes with any problem-parameters, yielding a better adaptation property than the Stochastic Gradient Descent under the same conditions. We also provide a probabilistic convergence result for Adam under a generalized smooth condition which allows unbounded smoothness parameters and has been illustrated empirically to more accurately capture the smooth property of many practical objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03982v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yusu Hong, Junhong Lin</dc:creator>
    </item>
    <item>
      <title>$\mathsf{QuITO}$ $\textsf{v.2}$: Trajectory Optimization with Uniform Error Guarantees under Path Constraints</title>
      <link>https://arxiv.org/abs/2404.13681</link>
      <description>arXiv:2404.13681v4 Announce Type: replace 
Abstract: This article introduces a new transcription, change point localization, and mesh refinement scheme for direct optimization-based solutions and for uniform approximation of optimal control trajectories associated with a class of nonlinear constrained optimal control problems (OCPs). The base transcription algorithm for which we establish the refinement algorithm is a direct multiple shooting technique -- $\mathsf{QuITO}$ $\textsf{v.2}$ (Quasi-Interpolation based Trajectory Optimization). The mesh refinement technique consists of two steps -- localization of certain irregular regions in an optimal control trajectory via wavelets, followed by a targeted $h$-refinement approach around such regions of irregularity. Theoretical approximation guarantees on uniform grids are presented for optimal controls with certain regularity properties, along with guarantees of localization of change points by wavelet transform. Numerical illustrations are provided for control profiles involving discontinuities to show the effectiveness of the localization and refinement strategy. We also announce, and make freely available, a new software package based on $\mathsf{QuITO}$ $\textsf{v.2}$ along with all its functionalities for completeness. The package is available at: https://github.com/chatterjee-d/QuITOv2.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13681v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Ganguly, Rihan Aaron D'Silva, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Scalarisation-based risk concepts for robust multi-objective optimisation</title>
      <link>https://arxiv.org/abs/2405.10221</link>
      <description>arXiv:2405.10221v3 Announce Type: replace 
Abstract: Robust optimisation is a well-established framework for optimising functions in the presence of uncertainty. The inherent goal of this problem is to identify a collection of inputs whose outputs are both desirable for the decision maker, whilst also being robust to the underlying uncertainties in the problem. In this work, we study the multi-objective case of this problem. We identify that the majority of all robust multi-objective algorithms rely on two key operations: robustification and scalarisation. Robustification refers to the strategy that is used to account for the uncertainty in the problem. Scalarisation refers to the procedure that is used to encode the relative importance of each objective to a scalar-valued reward. As these operations are not necessarily commutative, the order that they are performed in has an impact on the resulting solutions that are identified and the final decisions that are made. The purpose of this work is to give a thorough exposition on the effects of these different orderings and in particular highlight when one should opt for one ordering over the other. As part of our analysis, we showcase how many existing risk concepts can be integrated into the specification and solution of a robust multi-objective optimisation problem. Besides this, we also demonstrate how one can principally define the notion of a robust Pareto front and a robust performance metric based on our ``robustify and scalarise'' methodology. To illustrate the efficacy of these new ideas, we present two insightful case studies which are based on real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10221v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Tu, Nikolas Kantas, Robert M. Lee, Behrang Shafei</dc:creator>
    </item>
    <item>
      <title>Convergence rates of S.O.S hierarchies for polynomial semidefinite programs</title>
      <link>https://arxiv.org/abs/2406.12013</link>
      <description>arXiv:2406.12013v2 Announce Type: replace 
Abstract: We introduce an S.o.S hierarchy of lower bounds for a polynomial optimization problem whose constraint is expressed as a matrix polynomial semidefinite inequality. Our approach involves utilizing a penalty function framework to directly address the matrix-based constraint, making it applicable to both discrete and continuous polynomial optimization problems. We investigate the convergence rates of these bounds in both types of problems. The proposed method yields a variant of Putinar's theorem, tailored for positive polynomials within a compact semidefinite set $\mathcal{X}$ defined by a matrix polynomial semidefinite constraint. More specifically, we derive novel insights into the convergence rates and bounds on the degree of the S.o.S polynomials required to certify positivity on $\mathcal{X}$, based on Jackson's theorem and a variant of the {\L}ojasiewicz inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12013v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoang Anh Tran, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Optimal routing and transmission strategies for UAV reconnaissance missions with detection threats</title>
      <link>https://arxiv.org/abs/2406.19001</link>
      <description>arXiv:2406.19001v2 Announce Type: replace 
Abstract: We consider an autonomous reconnaissance mission where an Unmanned Aerial Vehicle (UAV) has to visit several points of interest and communicate the intel back to the base. At every point of interest, the UAV has the option to either send back all available info, or continue to the next point of interest and communicate at a later stage. Both choices have a chance of detection, meaning the mission fails. We wish to maximize the expected amount of information gathered by the mission. This is modelled by a routing problem in a weighted graph. We show that the problem is NP-complete, discuss an ILP formulation, and use a genetic algorithm to find good solutions for up to ten points of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19001v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riley Badenbroek, Relinde Jurrius, Lander Verlinde</dc:creator>
    </item>
    <item>
      <title>Convergence to periodic orbits in 3-dimensional strongly 2-cooperative systems</title>
      <link>https://arxiv.org/abs/2407.00461</link>
      <description>arXiv:2407.00461v2 Announce Type: replace 
Abstract: The flow of a $k$-cooperative system maps the set of vectors with up to~$(k-1)$ sign variations to itself. Strongly $2$-cooperative systems satisfy a strong \Poincare-Bendixson property: any bounded solution that evolves in a compact set containing no equilibria converges to a periodic orbit. For $3$-dimensional strongly $2$-cooperative nonlinear systems, we provide a simple sufficient condition that guarantees the existence, in the state space, of an invariant compact set that includes no equilibrium points. Thus, any solution emanating from this set converges to a periodic orbit. We characterize explicitly the set of initial conditions from which the trajectory converges to a periodic solution. We demonstrate our theoretical results on two well-known models in biochemistry: a 3D Goodwin oscillator model and the 3D Field-Noyes ordinary-differential-equation (ODE) model for the Belousov-Zhabotinskii reaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00461v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Katz, Giulia Giordano, Michael Margaliot</dc:creator>
    </item>
    <item>
      <title>Uniqueness Analysis of Controllability Scores and Their Application to Brain Networks</title>
      <link>https://arxiv.org/abs/2408.03023</link>
      <description>arXiv:2408.03023v2 Announce Type: replace 
Abstract: Assessing centrality in network systems is critical for understanding node importance and guiding decision-making processes. In dynamic networks, incorporating a controllability perspective is essential for identifying key nodes. This paper focuses on the Volumetric Controllability Score (VCS) and Average Energy Controllability Score (AECS) as centrality measures for selecting control nodes in linear time-invariant network systems. We prove the uniqueness of VCS and AECS for almost all specified terminal times, thereby enhancing their applicability beyond previously recognized cases. This ensures their interpretability, comparability, and reproducibility across different researchers. Our analysis reveals substantial differences between VCS and AECS in linear systems with symmetric and skew-symmetric transition matrices. We also investigate the dependence of VCS and AECS on the terminal time and prove that when this parameter is extremely small, both scores become essentially uniform. Additionally, we prove that the existing algorithm for computing VCS and AECS converges linearly to both measures under several assumptions. Finally, evaluations on brain networks modeled via Laplacian dynamics using real data reveal contrasting evaluation tendencies and correlations for VCS and AECS, with AECS favoring brain regions associated with cognitive and motor functions, while VCS emphasizes sensory and emotional regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03023v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuhiro Sato, Ryohei Kawamura</dc:creator>
    </item>
    <item>
      <title>On Stability in Optimistic Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2408.13323</link>
      <description>arXiv:2408.13323v2 Announce Type: replace 
Abstract: Solutions of bilevel optimization problems tend to suffer from instability under changes to problem data. In the optimistic setting, we construct a lifted formulation that exhibits desirable stability properties under mild assumptions that neither invoke convexity nor smoothness. The upper- and lower-level problems might involve integer restrictions and disjunctive constraints. In a range of results, we invoke at most pointwise and local calmness for the lower-level problem in a sense that holds broadly. The lifted formulation is computationally attractive with structural properties being brought out and an outer approximation algorithm becoming available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13323v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Analysis of the SiMPL method for density-based topology optimization</title>
      <link>https://arxiv.org/abs/2409.19341</link>
      <description>arXiv:2409.19341v3 Announce Type: replace 
Abstract: We present a rigorous convergence analysis of a new method for density-based topology optimization that provides point-wise bound preserving design updates and faster convergence than other popular first-order topology optimization methods. Due to its strong bound preservation, the method is exceptionally robust, as demonstrated in numerous examples here and in the companion article [31]. Furthermore, it is easy to implement with clear structure and analytical expressions for the updates. Our analysis covers two versions of the method, characterized by the employed line search strategies. We consider a modified Armijo backtracking line search and a Bregman backtracking line search. For both line search algorithms, our algorithm delivers a strict monotone decrease in the objective function and further intuitive convergence properties, e.g., strong and pointwise convergence of the density variables on the active sets, norm convergence to zero of the increments, convergence of the Lagrange multipliers, and more. In addition, the numerical experiments demonstrate apparent mesh-independent convergence of the algorithm. We refer to the new algorithm as the SiMPL method, pronounced like ``simple", which stands for {Si}gmoidal {M}irror descent with a {P}rojected {L}atent variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19341v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Keith, Dohyun Kim, Boyan S. Lazarov, Thomas M. Surowiec</dc:creator>
    </item>
    <item>
      <title>Shape optimization for contact problem involving Signorini unilateral conditions</title>
      <link>https://arxiv.org/abs/2410.12315</link>
      <description>arXiv:2410.12315v2 Announce Type: replace 
Abstract: This paper investigates a shape optimization problem involving the Signorini unilateral conditions in a linear elastic model, without any penalization procedure. The shape sensitivity analysis is performed using tools from convex and variational analysis such as proximal operators and the notion of twice epi-differentiability. We prove that the solution to the Signorini problem admits a directional derivative with respect to the shape which moreover coincides with the solution to another Signorini problem. Then, the shape gradient of the corresponding energy functional is explicitly characterized which allows us to perform numerical simulations to illustrate this methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12315v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aymeric Jacob de Cordemoy</dc:creator>
    </item>
    <item>
      <title>A Simple Introduction to the SiMPL Method for Density-Based Topology Optimization</title>
      <link>https://arxiv.org/abs/2411.19421</link>
      <description>arXiv:2411.19421v3 Announce Type: replace 
Abstract: We introduce a novel method for solving density-based topology optimization problems: Sigmoidal Mirror descent with a Projected Latent variable (SiMPL). The SiMPL method (pronounced as ``the simple method'') optimizes a design using only first-order derivative information of the objective function. The bound constraints on the density field are enforced with the help of the (negative) Fermi--Dirac entropy, which is also used to define a non-symmetric distance function called a Bregman divergence on the set of admissible designs. This Bregman divergence leads to a simple update rule that is further simplified with the help of a so-called latent variable. Because the SiMPL method involves discretizing the latent variable, it produces a sequence of pointwise-feasible iterates, even when high-order finite elements are used in the discretization. Numerical experiments demonstrate that the method outperforms other popular first-order optimization algorithms. To outline the general applicability of the technique, we include examples with (self-load) compliance minimization and compliant mechanism optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19421v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dohyun Kim, Boyan Stefanov Lazarov, Thomas M. Surowiec, Brendan Keith</dc:creator>
    </item>
    <item>
      <title>Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping</title>
      <link>https://arxiv.org/abs/2412.19529</link>
      <description>arXiv:2412.19529v2 Announce Type: replace 
Abstract: Recently, the study of heavy-tailed noises in first-order nonconvex stochastic optimization has gotten a lot of attention since it was recognized as a more realistic condition as suggested by many empirical observations. Specifically, the stochastic noise (the difference between the stochastic and true gradient) is considered to have only a finite $\mathfrak{p}$-th moment where $\mathfrak{p}\in\left(1,2\right]$ instead of assuming it always satisfies the classical finite variance assumption. To deal with this more challenging setting, people have proposed different algorithms and proved them to converge at an optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate for smooth objectives after $T$ iterations. Notably, all these new-designed algorithms are based on the same technique - gradient clipping. Naturally, one may want to know whether the clipping method is a necessary ingredient and the only way to guarantee convergence under heavy-tailed noises. In this work, by revisiting the existing Batched Normalized Stochastic Gradient Descent with Momentum (Batched NSGDM) algorithm, we provide the first convergence result under heavy-tailed noises but without gradient clipping. Concretely, we prove that Batched NSGDM can achieve the optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate even under the relaxed smooth condition. More interestingly, we also establish the first $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{2\mathfrak{p}}})$ convergence rate in the case where the tail index $\mathfrak{p}$ is unknown in advance, which is arguably the common scenario in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19529v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Algebraic Control: Complete Stable Inversion with Necessary and Sufficient Conditions</title>
      <link>https://arxiv.org/abs/2501.00172</link>
      <description>arXiv:2501.00172v2 Announce Type: replace 
Abstract: Recent advances in learning-based control have increased interest in stable inversion to meet growing performance demands. Here, we establish necessary and sufficient conditions for stable inversion, addressing challenges in non-minimum phase, non-square, and singular systems. An H-Infinity based algebraic approximation is introduced for near-perfect tracking without preview. Additionally, we propose a novel robust control strategy combining the nominal model with dual feedforward control to form a feedback structure. Numerical comparison demonstrates the approach's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00172v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Burak K\"urk\c{c}\"u, Masayoshi Tomizuka</dc:creator>
    </item>
    <item>
      <title>Revisiting LocalSGD and SCAFFOLD: Improved Rates and Missing Analysis</title>
      <link>https://arxiv.org/abs/2501.04443</link>
      <description>arXiv:2501.04443v3 Announce Type: replace 
Abstract: LocalSGD and SCAFFOLD are widely used methods in distributed stochastic optimization, with numerous applications in machine learning, large-scale data processing, and federated learning. However, rigorously establishing their theoretical advantages over simpler methods, such as minibatch SGD (MbSGD), has proven challenging, as existing analyses often rely on strong assumptions, unrealistic premises, or overly restrictive scenarios.
  In this work, we revisit the convergence properties of LocalSGD and SCAFFOLD under a variety of existing or weaker conditions, including gradient similarity, Hessian similarity, weak convexity, and Lipschitz continuity of the Hessian. Our analysis shows that (i) LocalSGD achieves faster convergence compared to MbSGD for weakly convex functions without requiring stronger gradient similarity assumptions; (ii) LocalSGD benefits significantly from higher-order similarity and smoothness; and (iii) SCAFFOLD demonstrates faster convergence than MbSGD for a broader class of non-quadratic functions. These theoretical insights provide a clearer understanding of the conditions under which LocalSGD and SCAFFOLD outperform MbSGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04443v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruichen Luo, Sebastian U Stich, Samuel Horv\'ath, Martin Tak\'a\v{c}</dc:creator>
    </item>
    <item>
      <title>Semantics of Instability in Networked Control</title>
      <link>https://arxiv.org/abs/2501.13226</link>
      <description>arXiv:2501.13226v2 Announce Type: replace 
Abstract: This paper addresses a scheduling problem in the context of a cyber-physical system where a sensor and a controller communicate over an unreliable channel. The sensor observes the state of a source at each time, and according to a scheduling policy determines whether to transmit a compressed sampled state, transmit the uncompressed sampled state, or remain idle. Upon receiving the transmitted information, the controller executes a control action aimed at stabilizing the system, such that the effectiveness of stabilization depends on the quality of the received sensory information. Our primary objective is to derive an optimal scheduling policy that optimizes system performance subject to resource constraints, when the performance is measured by a dual-aspect metric penalizing both the frequency of transitioning to unstable states and the continuous duration of remaining in those states. We formulate this problem as a Markov decision process, and derive an optimal multi-threshold scheduling policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13226v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saad Kriouile, Mohamad Assaad, Touraj Soleymani</dc:creator>
    </item>
    <item>
      <title>EV Fleet Flexibility Estimation and Forecasting for V2X Applications</title>
      <link>https://arxiv.org/abs/2502.06435</link>
      <description>arXiv:2502.06435v2 Announce Type: replace 
Abstract: Forecasting the flexibility potential of Vehicle-to-Everything (V2X) systems is important for the future of energy networks, where the integration of renewable energy sources and electric vehicles poses significant challenges. In this paper, we present a novel method for estimating and predicting V2X flexibility potential of an EV fleet, based on an aggregate polytope representation, addressing the need for accurate and reliable forecasting methods in the realm of sustainable transportation. The method is robust against individual uncertainties of EV owners behaviours as it is applied at an aggregate level, and the reformulation of the V2X potential as a set of linear constraints allows the proposed method to be integrated into different optimisation problems and therefore be applied for diverse V2X applications. Case studies showcase the capability of the method in capturing the V2X flexibility potential and demonstrate it effectiveness for different V2X applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06435v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaimaa Essayeh, Amin Vilan, Omid Homaee, Vahid Vahidinasab</dc:creator>
    </item>
    <item>
      <title>Dynamic Rolling Horizon Optimization for Network-Constrained V2X Value Stacking of Electric Vehicles Under Uncertainties</title>
      <link>https://arxiv.org/abs/2502.09290</link>
      <description>arXiv:2502.09290v2 Announce Type: replace 
Abstract: Electric vehicle (EV) coordination can provide significant benefits through vehicle-to-everything (V2X) by interacting with the grid, buildings, and other EVs. This work aims to develop a V2X value-stacking framework, including vehicle-to-building (V2B), vehicle-to-grid (V2G), and energy trading, to maximize economic benefits for residential communities while maintaining distribution voltage. This work also seeks to quantify the impact of prediction errors related to building load, renewable energy, and EV arrivals. A dynamic rolling-horizon optimization (RHO) method is employed to leverage multiple revenue streams and maximize the potential of EV coordination. To address energy uncertainties, including hourly local building load, local photovoltaic (PV) generation, and EV arrivals, this work develops a Transformer-based forecasting model named Gated Recurrent Units-Encoder-Temporal Fusion Decoder (GRU-EN-TFD). The simulation results, using real data from Australia's National Electricity Market, and the Independent System Operators in New England and New York in the US, reveal that V2X value stacking can significantly reduce energy costs. The proposed GRU-EN-TFD model outperforms the benchmark forecast model. Uncertainties in EV arrivals have a more substantial impact on value-stacking performance, highlighting the significance of its accurate forecast. This work provides new insights into the dynamic interactions among residential communities, unlocking the full potential of EV batteries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09290v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.renene.2025.122668</arxiv:DOI>
      <arxiv:journal_reference>Renewable Energy, 2025</arxiv:journal_reference>
      <dc:creator>Canchen Jiang, Ariel Liebman, Bo Jie, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Stochastic Accelerated Gradient Methods for Generalized Smooth Optimizations</title>
      <link>https://arxiv.org/abs/2502.11125</link>
      <description>arXiv:2502.11125v2 Announce Type: replace 
Abstract: We investigate the Randomized Stochastic Accelerated Gradient (RSAG) method, utilizing either constant or adaptive step sizes, for stochastic optimization problems with generalized smooth objective functions. Under relaxed affine variance assumptions for the stochastic gradient noise, we establish high-probability convergence rates of order $\tilde{O}\left(\sqrt{\log(1/\delta)/T}\right)$ for function value gaps in the convex setting, and for the squared gradient norms in the non-convex setting. Furthermore, when the noise parameters are sufficiently small, the convergence rate improves to $\tilde{O}\left(\log(1/\delta)/T\right)$, where $T$ denotes the total number of iterations and $\delta$ is the probability margin. Our analysis is also applicable to SGD with both constant and adaptive step sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11125v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenhao Yu, Yusu Hong, Junhong Lin</dc:creator>
    </item>
    <item>
      <title>Variable aggregation for nonlinear optimization problems</title>
      <link>https://arxiv.org/abs/2502.13869</link>
      <description>arXiv:2502.13869v2 Announce Type: replace 
Abstract: Variable aggregation has been largely studied as an important pre-solve algorithm for optimization of linear and mixed-integer programs. Although some nonlinear solvers and algebraic modeling languages implement variable aggregation as a pre-solve, the impact it can have on constrained nonlinear programs is unexplored. In this work, we formalize variable aggregation as a pre-solve algorithm to develop reduced-space formulations of nonlinear programs. A novel approximate maximum variable aggregation strategy is developed to aggregate as many variables as possible. Furthermore, aggregation strategies that preserve the problem structure are compared against approximate maximum aggregation. Our results show that variable aggregation can generally help to improve the convergence reliability of nonlinear programs. It can also help in reducing total solve time. However, Hessian evaluation can become a bottleneck if aggregation significantly increases the number of variables appearing nonlinearly in many constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13869v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sakshi Naik, Lorenz Biegler, Russell Bent, Robert Parker</dc:creator>
    </item>
    <item>
      <title>Gaining efficiency in deep policy gradient method for continuous-time optimal control problems</title>
      <link>https://arxiv.org/abs/2502.14141</link>
      <description>arXiv:2502.14141v2 Announce Type: replace 
Abstract: In this paper, we propose an efficient implementation of deep policy gradient method (PGM) for optimal control problems in continuous time. The proposed method has the ability to manage the allocation of computational resources, number of trajectories, and complexity of architecture of the neural network. This is, in particular, important for continuous-time problems that require a fine time discretization. Each step of this method focuses on a different time scale and learns a policy, modeled by a neural network, for a discretized optimal control problem. The first step has the coarsest time discretization. As we proceed to other steps, the time discretization becomes finer. The optimal trained policy in each step is also used to provide data for the next step. We accompany the multi-scale deep PGM with a theoretical result on allocation of computational resources to obtain a targeted efficiency and test our methods on the linear-quadratic stochastic optimal control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14141v2</guid>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arash Fahim, Md. Arafatur Rahman</dc:creator>
    </item>
    <item>
      <title>Observability of the linear Zakharov--Kuznetsov equation</title>
      <link>https://arxiv.org/abs/2311.09844</link>
      <description>arXiv:2311.09844v3 Announce Type: replace-cross 
Abstract: We study the linear Zakharov--Kuznetsov equation with periodic boundary conditions. Employing some tools from the nonharmonic Fourier series we obtain several internal observability theorems. Then we prove various exact controllability and rapid uniform stabilization results by applying a duality principle and a general feedback construction. The method presented here introduces a new insight into the control of dispersive equations in two-dimensional cases and may be adapted to more general equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09844v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roberto de A. Capistrano Filho, Vilmos Komornik, Ademir F. Pazoto</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Federated Optimization over Semi-Decentralized Networks</title>
      <link>https://arxiv.org/abs/2311.18787</link>
      <description>arXiv:2311.18787v4 Announce Type: replace-cross 
Abstract: In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number of agents and local updates. Our numerical results highlight the superior communication efficiency of PISCO and its resilience to data heterogeneity and various network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18787v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Wang, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Achieving Instance-dependent Sample Complexity for Constrained Markov Decision Process</title>
      <link>https://arxiv.org/abs/2402.16324</link>
      <description>arXiv:2402.16324v3 Announce Type: replace-cross 
Abstract: We consider the reinforcement learning problem for the constrained Markov decision process (CMDP), which plays a central role in satisfying safety or resource constraints in sequential learning and decision-making. In this problem, we are given finite resources and a MDP with unknown transition probabilities. At each stage, we take an action, collecting a reward and consuming some resources, all assumed to be unknown and need to be learned over time. In this work, we take the first step towards deriving optimal problem-dependent guarantees for the CMDP problems. We derive a logarithmic regret bound, which translates into a $O(\frac{1}{\Delta\cdot\epsilon}\cdot\log^2(1/\epsilon))$ sample complexity bound, with $\Delta$ being a problem-dependent parameter, yet independent of $\epsilon$. Our sample complexity bound improves upon the state-of-art $O(1/\epsilon^2)$ sample complexity for CMDP problems established in the previous literature, in terms of the dependency on $\epsilon$. To achieve this advance, we develop a new framework for analyzing CMDP problems. To be specific, our algorithm operates in the primal space and we resolve the primal LP for the CMDP problem at each period in an online manner, with adaptive remaining resource capacities. The key elements of our algorithm are: i) a characterization of the instance hardness via LP basis, ii) an eliminating procedure that identifies one optimal basis of the primal LP, and; iii) a resolving procedure that is adaptive to the remaining resources and sticks to the characterized optimal basis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16324v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiashuo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Geometry and factorization of multivariate Markov chains with applications to the swapping algorithm</title>
      <link>https://arxiv.org/abs/2404.12589</link>
      <description>arXiv:2404.12589v3 Announce Type: replace-cross 
Abstract: This paper analyzes the factorizability and geometry of transition matrices of multivariate Markov chains. Specifically, we demonstrate that the induced chains on factors of a product space can be regarded as information projections with respect to the Kullback-Leibler divergence. This perspective yields Han-Shearer type inequalities and submodularity of the entropy rate of Markov chains, as well as applications in the context of large deviations and mixing time comparison. As a concrete algorithmic application, we introduce a projection sampler based on the swapping algorithm, which resamples the highest-temperature coordinate at stationarity at each step. We prove that such practice accelerates the mixing time by multiplicative factors related to the number of temperatures and the dimension of the underlying state space when compared with the original swapping algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12589v3</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Youjia Wang, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>Private Online Learning via Lazy Algorithms</title>
      <link>https://arxiv.org/abs/2406.03620</link>
      <description>arXiv:2406.03620v2 Announce Type: replace-cross 
Abstract: We study the problem of private online learning, specifically, online prediction from experts (OPE) and online convex optimization (OCO). We propose a new transformation that transforms lazy online learning algorithms into private algorithms. We apply our transformation for differentially private OPE and OCO using existing lazy algorithms for these problems. Our final algorithms obtain regret, which significantly improves the regret in the high privacy regime $\varepsilon \ll 1$, obtaining $\sqrt{T \log d} + T^{1/3} \log(d)/\varepsilon^{2/3}$ for DP-OPE and $\sqrt{T} + T^{1/3} \sqrt{d}/\varepsilon^{2/3}$ for DP-OCO. We also complement our results with a lower bound for DP-OPE, showing that these rates are optimal for a natural family of low-switching private algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03620v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Asi, Tomer Koren, Daogao Liu, Kunal Talwar</dc:creator>
    </item>
    <item>
      <title>Communication-efficient Vertical Federated Learning via Compressed Error Feedback</title>
      <link>https://arxiv.org/abs/2406.14420</link>
      <description>arXiv:2406.14420v3 Announce Type: replace-cross 
Abstract: Communication overhead is a known bottleneck in federated learning (FL). To address this, lossy compression is commonly used on the information communicated between the server and clients during training. In horizontal FL, where each client holds a subset of the samples, such communication-compressed training methods have recently seen significant progress. However, in their vertical FL counterparts, where each client holds a subset of the features, our understanding remains limited. To address this, we propose an error feedback compressed vertical federated learning (EF-VFL) method to train split neural networks. In contrast to previous communication-compressed methods for vertical FL, EF-VFL does not require a vanishing compression error for the gradient norm to converge to zero for smooth nonconvex problems. By leveraging error feedback, our method can achieve a $\mathcal{O}(1/T)$ convergence rate for a sufficiently large batch size, improving over the state-of-the-art $\mathcal{O}(1/\sqrt{T})$ rate under $\mathcal{O}(1/\sqrt{T})$ compression error, and matching the rate of uncompressed methods. Further, when the objective function satisfies the Polyak-{\L}ojasiewicz inequality, our method converges linearly. In addition to improving convergence, our method also supports the use of private labels. Numerical experiments show that EF-VFL significantly improves over the prior art, confirming our theoretical results. The code for this work can be found at https://github.com/Valdeira/EF-VFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14420v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Valdeira, Jo\~ao Xavier, Cl\'audia Soares, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Have ASkotch: A Neat Solution for Large-scale Kernel Ridge Regression</title>
      <link>https://arxiv.org/abs/2407.10070</link>
      <description>arXiv:2407.10070v2 Announce Type: replace-cross 
Abstract: Kernel ridge regression (KRR) is a fundamental computational tool, appearing in problems that range from computational chemistry to health analytics, with a particular interest due to its starring role in Gaussian process regression. However, full KRR solvers are challenging to scale to large datasets: both direct (i.e., Cholesky decomposition) and iterative methods (i.e., PCG) incur prohibitive computational and storage costs. The standard approach to scale KRR to large datasets chooses a set of inducing points and solves an approximate version of the problem, inducing points KRR. However, the resulting solution tends to have worse predictive performance than the full KRR solution. In this work, we introduce a new solver, ASkotch, for full KRR that provides better solutions faster than state-of-the-art solvers for full and inducing points KRR. ASkotch is a scalable, accelerated, iterative method for full KRR that provably obtains linear convergence. Under appropriate conditions, we show that ASkotch obtains condition-number-free linear convergence. This convergence analysis rests on the theory of ridge leverage scores and determinantal point processes. ASkotch outperforms state-of-the-art KRR solvers on a testbed of 23 large-scale KRR regression and classification tasks derived from a wide range of application domains, demonstrating the superiority of full KRR over inducing points KRR. Our work opens up the possibility of as-yet-unimagined applications of full KRR across a number of disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10070v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pratik Rathore, Zachary Frangella, Jiaming Yang, Micha{\l} Derezi\'nski, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Solving Functional Optimization with Deep Networks and Variational Principles</title>
      <link>https://arxiv.org/abs/2410.06277</link>
      <description>arXiv:2410.06277v3 Announce Type: replace-cross 
Abstract: Can neural networks solve math problems using first a principle alone? This paper shows how to leverage the fundamental theorem of the calculus of variations to design deep neural networks to solve functional optimization without requiring training data (e.g., ground-truth optimal solutions). Our approach is particularly crucial when the solution is a function defined over an unknown interval or support\textemdash such as in minimum-time control problems. By incorporating the necessary conditions satisfied by the optimal function solution, as derived from the calculus of variation, in the design of the deep architecture, CalVNet leverages overparameterized neural networks to learn these optimal functions directly. We validate CalVNet by showing that, without relying on ground-truth data and simply incorporating first principles, it successfully derives the Kalman filter for linear filtering, the bang-bang optimal control for minimum-time problems, and finds geodesics on manifolds. Our results demonstrate that CalVNet can be trained in an unsupervised manner, without relying on ground-truth data, establishing a promising framework for addressing general, potentially unsolved functional optimization problems that still lack analytical solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06277v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kawisorn Kamtue, Jose M. F. Moura, Orathai Sangpetch</dc:creator>
    </item>
    <item>
      <title>Nonlinear Assimilation via Score-based Sequential Langevin Sampling</title>
      <link>https://arxiv.org/abs/2411.13443</link>
      <description>arXiv:2411.13443v2 Announce Type: replace-cross 
Abstract: This paper presents score-based sequential Langevin sampling (SSLS), a novel approach to nonlinear data assimilation within a recursive Bayesian framework. The proposed method decomposes the assimilation process into alternating prediction and update steps, leveraging dynamic models for state prediction while incorporating observational data through score-based Langevin Monte Carlo during updates. To address challenges in posterior sampling, we introduce an annealing strategy within the update mechanism. We provide theoretical guarantees for SSLS convergence in total variation (TV) distance under certain conditions, providing insights into error behavior with respect to key hyper-parameters. Our numerical experiments across challenging scenarios -- including high-dimensional systems, strong nonlinearity, and sparse observations -- demonstrate the robust performance of the proposed method. Furthermore, SSLS effectively quantifies the uncertainty associated with the estimated states, making it particularly valuable for the error calibration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13443v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhao Ding, Chenguang Duan, Yuling Jiao, Jerry Zhijian Yang, Cheng Yuan, Pingwen Zhang</dc:creator>
    </item>
    <item>
      <title>Backtracking New Q-Newton's method for finding roots of meromorphic functions in 1 complex variable: Global convergence, and local stable/unstable curves</title>
      <link>https://arxiv.org/abs/2412.02476</link>
      <description>arXiv:2412.02476v2 Announce Type: replace-cross 
Abstract: In this paper, we research more in depth properties of Backtracking New Q-Newton's method (recently designed by the third author), when used to find roots of meromorphic functions.
  If $f=P/Q$, where $P$ and $Q$ are polynomials in 1 complex variable z with $\deg (P)&gt;\deg (Q)$, we show the existence of an exceptional set $\mathcal{E}\subset\mathbf{C}$, which is contained in a countable union of real analytic curves in $\mathbf{R}^2=\mathbf{C}$, so that the following statements A and B hold. Here, $\{z_n\}$ is the sequence constructed by BNQN with an initial point $z_0$ which is not a pole of $f$.
  A) If $z_0\in\mathbf{C}\backslash\mathcal{E}$, then $\{z_n\}$ converges to a root of $f$.
  B) If $z_0\in \mathcal{E}$, then $\{z_n\}$ converges to a critical point - but not a root - of $f$.
  Experiments seem to indicate that in general, even when $f$ is a polynomial, the set $\mathcal{E}$ is not contained in a finite union of real analytic curves. We provide further results relevant to whether locally $\mathcal{E}$ is contained in a finite number of real analytic curves. A similar result holds for general meromorphic functions. Moreover, unlike previous work, here we do not require that the parameters of BNQN are random, or that the meromorphic function $f$ is generic.
  Based on the theoretical results, we explain (both rigorously and heuristically) of what observed in experiments with BNQN, in previous works by the authors. In particular, the dynamics of BNQN (an iterative method) seems to have some striking similarities to Newton's method (a continuous method) and the classical Poincar\'e-Bendixon theorem for differentiable real dynamical systems on the complex plane. This is the more interesting given that discrete versions of Newton's method (e.g. Relaxed Newton's method) does not behave this way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02476v2</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <category>math.NA</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>John Erik Forn{\ae}ss, Mi Hu, Tuyen Trung Truong</dc:creator>
    </item>
  </channel>
</rss>
