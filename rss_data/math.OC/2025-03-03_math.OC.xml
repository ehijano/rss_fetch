<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Mar 2025 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Analyzing the Impact of AC False Data Injection Attacks on Power System Operation</title>
      <link>https://arxiv.org/abs/2502.20473</link>
      <description>arXiv:2502.20473v1 Announce Type: new 
Abstract: False Data Injection (FDI) attacks are a significant threat to modern power systems. Although numerous research studies have focused on FDI attacks on power systems, these studies have primarily concentrated on designing or detecting DC FDI attacks, with less attention given to the impact analysis of AC FDI attacks. AC FDI attacks are potentially more harmful as they can easily bypass bad data detection (BDD) algorithms. In this paper, we present a unified approach to investigate the impact of AC FDI attacks on power transmission lines using the PowerWorld simulator. We also investigate the impact of different FDI attack designs, including those optimally designed to evade BDD algorithms and compare them accordingly. Our findings demonstrate that in designing optimal AC FDI attacks, a trade-off between the residuals of state variables and the corresponding impacts of the proposed attack should be considered. This is because optimal attacks result in fewer changes in the attacked variable states and their estimated residuals compared to arbitrary AC FDI attacks. Moreover, the impacts of optimal AC FDI attacks can be less severe than those of arbitrary attacks. We implement and analyze the proposed approach on the IEEE 39-bus test system using PowerWorld simulator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20473v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Iranpour, Mohammad Rasoul Narimani</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Multi-time Scale Optimization Models and Algorithms</title>
      <link>https://arxiv.org/abs/2502.20568</link>
      <description>arXiv:2502.20568v1 Announce Type: new 
Abstract: Systems across different industries consist of interrelated processes and decisions in different time scales including long-time decisions and short-term decisions. To optimize such systems, the most effective approach is to formulate and solve multi-time scale optimization models that integrate various decision layers. In this tutorial, we provide an overview of multi-time scale optimization models and review the algorithms used to solve them. We also discuss the metric Value of the Multi-scale Model (VMM) introduced to quantify the benefits of using multi-time scale optimization models as opposed to sequentially solving optimization models from high-level to low-level. Finally, we present an illustrative example of a multi-time scale capacity expansion planning model and showcase how it can be solved using some of the algorithms (https://github.com/li-group/MultiScaleOpt-Tutorial.git). This tutorial serves as both an introductory guide for beginners with no prior experience and a high-level overview of current algorithms for solving multi-time scale optimization models, catering to experts in process systems engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20568v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asha Ramanujam, Can Li</dc:creator>
    </item>
    <item>
      <title>Enhanced Derivative-Free Optimization Using Adaptive Correlation-Induced Finite Difference Estimators</title>
      <link>https://arxiv.org/abs/2502.20819</link>
      <description>arXiv:2502.20819v1 Announce Type: new 
Abstract: Gradient-based methods are well-suited for derivative-free optimization (DFO), where finite-difference (FD) estimates are commonly used as gradient surrogates. Traditional stochastic approximation methods, such as Kiefer-Wolfowitz (KW) and simultaneous perturbation stochastic approximation (SPSA), typically utilize only two samples per iteration, resulting in imprecise gradient estimates and necessitating diminishing step sizes for convergence. In this paper, we first explore an efficient FD estimate, referred to as correlation-induced FD estimate, which is a batch-based estimate. Then, we propose an adaptive sampling strategy that dynamically determines the batch size at each iteration. By combining these two components, we develop an algorithm designed to enhance DFO in terms of both gradient estimation efficiency and sample efficiency. Furthermore, we establish the consistency of our proposed algorithm and demonstrate that, despite using a batch of samples per iteration, it achieves the same convergence rate as the KW and SPSA methods. Additionally, we propose a novel stochastic line search technique to adaptively tune the step size in practice. Finally, comprehensive numerical experiments confirm the superior empirical performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20819v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guo Liang, Guangwu Liu, Kun Zhang</dc:creator>
    </item>
    <item>
      <title>A Dynamic Bus Lane Strategy for Integrated Management of Human-Driven and Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2502.20831</link>
      <description>arXiv:2502.20831v1 Announce Type: new 
Abstract: This study introduces a dynamic bus lane (DBL) strategy, referred to as the dynamic bus priority lane (DBPL) strategy, designed for mixed traffic environments featuring both manual and automated vehicles. Unlike previous DBL strategies, this approach accounts for partially connected and autonomous vehicles (CAVs) capable of autonomous trajectory planning. By leveraging this capability, the strategy grants certain CAVs Right of Way (ROW) in bus lanes while utilizing their leading effects in general lanes to guide vehicle platoons through intersections, thereby indirectly influencing the trajectories of other vehicles. The ROW allocation is optimized using a mixed-integer linear programming (MILP) model, aimed at minimizing total vehicle travel time. Since different CAVs entering the bus lane affect other vehicles travel times, the model incorporates lane change effects when estimating the states of CAVs, human-driven vehicles (HDVs), and connected autonomous buses (CABs) as they approach the stop bar. A dynamic control framework with a rolling horizon procedure is established to ensure precise execution of the ROW optimization under varying traffic conditions. Simulation experiments across two scenarios assess the performance of the proposed DBPL strategy at different CAV market penetration rates (MPRs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20831v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Li, Zhenzhou Yuan, Rui Yue, Guangchuan Yang, Fan Zhang, Zong Tian, Chuang Zhu</dc:creator>
    </item>
    <item>
      <title>A Laplace duality for integration</title>
      <link>https://arxiv.org/abs/2502.20842</link>
      <description>arXiv:2502.20842v1 Announce Type: new 
Abstract: We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\in$ R d : g(x) $\le$ y}, where g is nonnegative and Ky is compact for all y $\in$ [0, +$\infty$). Under some assumptions, we show that for every y $\in$ (0, $\infty$) there exists a distinguished scalar $\lambda$y $\in$ (0, +$\infty$) such that which is the counterpart analogue for integration of Lagrangian duality for optimization. A crucial ingredient is the Laplace transform, the analogue for integration of Legendre-Fenchel transform in optimization. In particular, if both f and g are positively homogeneous then $\lambda$y is a simple explicitly rational function of y. In addition if g is quadratic form then computing v(y) reduces to computing the integral of f with respect to a specific Gaussian measure for which exact and approximate numerical methods (e.g. cubatures) are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20842v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean B Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>An inertial proximal splitting algorithm for hierarchical bilevel equilibria in Hilbert spaces</title>
      <link>https://arxiv.org/abs/2502.20999</link>
      <description>arXiv:2502.20999v1 Announce Type: new 
Abstract: In this article, we aim to approximate a solution to the bilevel equilibrium problem $\mathbf{(BEP})$ for short: find $\bar{x} \in \mathbf{S}_f$ such that $
g(\bar{x}, y) \geq 0, \,\, \forall y \in \mathbf{S}_f, $
where $
\mathbf{S}_f = \{ u \in \mathbf{K} : f(u, z) \geq 0, \forall z \in \mathbf{K} \}. $
Here, $\mathbf{K}$ is a closed convex subset of a real Hilbert space $\mathcal{H}$, and $f$ and $g$ are two real-valued bifunctions defined on $\mathbf{K} \times \mathbf{K}$. We propose an inertial version of the proximal splitting algorithm introduced by Z. Chbani and H. Riahi: \textit{Weak and strong convergence of prox-penalization and splitting algorithms for bilevel equilibrium problems}. \textit{Numer. Algebra Control Optim.}, 3 (2013), pp. 353-366. Under suitable conditions, we establish the weak and strong convergence of the sequence generated by the proposed iterative method. We also report a numerical example illustrating our theoretical result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20999v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aicha Balhag, Zakaria Mazgouri, Hassan Riahi, Michel Th\'era</dc:creator>
    </item>
    <item>
      <title>A Stochastic Newton-type Method for Non-smooth Optimization</title>
      <link>https://arxiv.org/abs/2502.21078</link>
      <description>arXiv:2502.21078v1 Announce Type: new 
Abstract: We introduce a new framework for analyzing (Quasi-}Newton type methods applied to non-smooth optimization problems. The source of randomness comes from the evaluation of the (approximation) of the Hessian. We derive, using a variant of Chernoff bounds for stopping times, expectation and probability bounds for the random variable representing the number of iterations of the algorithm until approximate first order optimality conditions are validated. As an important distinction to previous results in the literature, we do not require that the estimator is unbiased or that it has finite variance. We then showcase our theoretical results in a stochastic Quasi-Newton method for X-ray free electron laser orbital tomography and in a sketched Newton method for image denoising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21078v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Pinta Titus</dc:creator>
    </item>
    <item>
      <title>Bridging Model Reference Adaptive Control and Data Informativity</title>
      <link>https://arxiv.org/abs/2502.21091</link>
      <description>arXiv:2502.21091v1 Announce Type: new 
Abstract: The goal of model reference adaptive control (MRAC) is to ensure that the trajectories of an unknown dynamical system track those of a given reference model. This is done by means of a feedback controller that adaptively changes its gains using data collected online from the closed-loop system. One of the approaches to solve the MRAC problem is to impose conditions on the data that guarantee convergence of the gains to a solution of the so-called matching equations. In the literature, various extensions of the concept of persistent excitation have been proposed in an effort to weaken the conditions on the data required for this convergence.Despite these efforts, it is not well-understood what are the weakest possible data requirements ensuring convergence of MRAC. In this paper, we propose a new framework to study the MRAC problem, using the concept of data informativity. Our main contribution is to provide \textit{necessary and sufficient} conditions for the convergence of the adaptive gains to a solution of the matching equations. These necessary and sufficient conditions can be readily checked online as new data are generated by the closed-loop system. Our results reveal that existing excitation conditions impose stronger requirements on the collected data than required. Notably, the necessary and sufficient conditions provided in this paper are weaker than those for unique system identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21091v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiwei Wang, Simone Baldi, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>Adaptive Accelerated Proximal Gradient Methods with Variance Reduction for Composite Nonconvex Finite-Sum Minimization</title>
      <link>https://arxiv.org/abs/2502.21099</link>
      <description>arXiv:2502.21099v1 Announce Type: new 
Abstract: This paper proposes {\sf AAPG-SPIDER}, an Adaptive Accelerated Proximal Gradient (AAPG) method with variance reduction for minimizing composite nonconvex finite-sum functions. It integrates three acceleration techniques: adaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic path-integrated estimator SPIDER. While targeting stochastic finite-sum problems, {\sf AAPG-SPIDER} simplifies to {\sf AAPG} in the full-batch, non-stochastic setting, which is also of independent interest. To our knowledge, {\sf AAPG-SPIDER} and {\sf AAPG} are the first learning-rate-free methods to achieve optimal iteration complexity for this class of \textit{composite} minimization problems. Specifically, {\sf AAPG} achieves the optimal iteration complexity of $\mathcal{O}(N \epsilon^{-2})$, while {\sf AAPG-SPIDER} achieves $\mathcal{O}(N + \sqrt{N} \epsilon^{-2})$ for finding $\epsilon$-approximate stationary points, where $N$ is the number of component functions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish non-ergodic convergence rates for both methods. Preliminary experiments on sparse phase retrieval and linear eigenvalue problems demonstrate the superior performance of {\sf AAPG-SPIDER} and {\sf AAPG} compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21099v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>On a class of adversarial classification problems which admit a continuous solution</title>
      <link>https://arxiv.org/abs/2502.21170</link>
      <description>arXiv:2502.21170v1 Announce Type: new 
Abstract: We consider a class of adversarial classification problems in the form of zero-sum games between a classifier and an adversary. The latter is able to corrupt data, at the expense of some optimal transport cost. We show that quite general assumptions on the loss functions of the classifier and the transport cost functions of the adversary ensure the existence of a Nash equilibrium with a continuous (or even Lipschitz) classifier's strategy. We also consider a softmax-like regularization of this problem and present numerical results for this regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21170v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guillaume Carlier, Maxime Sylvestre</dc:creator>
    </item>
    <item>
      <title>A relax-fix-and-exclude algorithm for an MINLP problem with multilinear interpolations</title>
      <link>https://arxiv.org/abs/2502.21249</link>
      <description>arXiv:2502.21249v1 Announce Type: new 
Abstract: This paper introduces a novel algorithm for Mixed-Integer Nonlinear Programming (MINLP) problems with multilinear interpolations of look-up tables. These problems arise when objective or constraints contain black-box functions only known at a finite set of evaluations on a predefined grid. We derive a piecewise-linear relaxation for the multilinear constraints resulting from the multilinear interpolations used to approximate the true functions. Supported by the fact that our proposed relaxation defines the convex hull of the original problem, we propose a novel algorithm that iteratively solves the MILP relaxation and refines the solution space through variable fixing and exclusion strategies. This approach ensures convergence to an optimal solution, which we demonstrate, while maintaining computational efficiency. We apply the proposed algorithm to a real-world offshore oil production optimization problem. In comparison to the Gurobi solver, our algorithm was able to find the optimal solution at least four times faster, and to consistently provide better incumbents under limited time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21249v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruno Machado Pacheco, Pedro Marcolin Antunes, Eduardo Camponogara, Laio Oriel Seman, Vin\'icius Ramos Rosa, Bruno Ferreira Vieira, Cesar Longhi</dc:creator>
    </item>
    <item>
      <title>Efficient Risk-sensitive Planning via Entropic Risk Measures</title>
      <link>https://arxiv.org/abs/2502.20423</link>
      <description>arXiv:2502.20423v1 Announce Type: cross 
Abstract: Risk-sensitive planning aims to identify policies maximizing some tail-focused metrics in Markov Decision Processes (MDPs). Such an optimization task can be very costly for the most widely used and interpretable metrics such as threshold probabilities or (Conditional) Values at Risk. Indeed, previous work showed that only Entropic Risk Measures (EntRM) can be efficiently optimized  through dynamic programming, leaving a hard-to-interpret parameter to choose.     We show that the computation of the full set of optimal policies for EntRM across parameter values leads to tight approximations for the metrics of interest. We prove that this optimality front can be computed effectively thanks to a novel structural analysis and smoothness properties of entropic risks.     Empirical results demonstrate that our approach achieves strong performance in a variety of decision-making scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20423v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Marthe (ENS de Lyon, UMPA-ENSL), Samuel Bounan (UMPA-ENSL, MC2), Aur\'elien Garivier (UMPA-ENSL, MC2), Claire Vernade</dc:creator>
    </item>
    <item>
      <title>Leveraging Convex Relaxation to Identify the Feasibility of Conducting AC False Data Injection Attack in Power Systems</title>
      <link>https://arxiv.org/abs/2502.20464</link>
      <description>arXiv:2502.20464v1 Announce Type: cross 
Abstract: FDI (False Data Injection) attacks are critical to address as they can compromise the integrity and reliability of data in cyber-physical systems, leading to potentially severe consequences in sectors such as power systems. The feasibility of FDI attacks has been extensively studied from various perspectives, including access to measurements and sensors, knowledge of the system, and design considerations using residual-based detection methods. Most research has focused on DC-based FDI attacks; however, designing AC FDI attacks involves solving a nonlinear optimization problem, presenting additional challenges in assessing their feasibility. Specifically, it is often unclear whether the infeasibility of some designed AC FDI attacks is due to the nonconvexity and nonlinearity inherent to AC power flows or if it stems from inherent infeasibility in specific cases, with local solvers returning infeasibility. This paper addresses this issue by leveraging the principle that if a convexified AC FDI attack design problem is infeasible, the attack design itself is infeasible, irrespective of nonlinear solution challenges. We propose an AC FDI attack design based on convexified power flow equations and assess the feasibility of the proposed attack by examining the extent of the attackable region. This approach utilizes a Quadratic Convex (QC) relaxation technique to convexify AC power flows. To evaluate the proposed method, we implement it on the IEEE 118-bus test system and assess the feasibility of an AC FDI attack across various attack zones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20464v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Iranpour, Mohammad Rasoul Narimani</dc:creator>
    </item>
    <item>
      <title>Equivariant Reinforcement Learning Frameworks for Quadrotor Low-Level Control</title>
      <link>https://arxiv.org/abs/2502.20500</link>
      <description>arXiv:2502.20500v1 Announce Type: cross 
Abstract: Improving sampling efficiency and generalization capability is critical for the successful data-driven control of quadrotor unmanned aerial vehicles (UAVs) that are inherently unstable. While various reinforcement learning (RL) approaches have been applied to autonomous quadrotor flight, they often require extensive training data, posing multiple challenges and safety risks in practice. To address these issues, we propose data-efficient, equivariant monolithic and modular RL frameworks for quadrotor low-level control. Specifically, by identifying the rotational and reflectional symmetries in quadrotor dynamics and encoding these symmetries into equivariant network models, we remove redundancies of learning in the state-action space. This approach enables the optimal control action learned in one configuration to automatically generalize into other configurations via symmetry, thereby enhancing data efficiency. Experimental results demonstrate that our equivariant approaches significantly outperform their non-equivariant counterparts in terms of learning efficiency and flight performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20500v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beomyeol Yu, Taeyoung Lee</dc:creator>
    </item>
    <item>
      <title>Unified Feedback Linearization for Nonlinear Systems with Dexterous and Energy-Saving Modes</title>
      <link>https://arxiv.org/abs/2502.20524</link>
      <description>arXiv:2502.20524v1 Announce Type: cross 
Abstract: Systems with a high number of inputs compared to the degrees of freedom (e.g. a mobile robot with Mecanum wheels) often have a minimal set of energy-efficient inputs needed to achieve a main task (e.g. position tracking) and a set of energy-intense inputs needed to achieve an additional auxiliary task (e.g. orientation tracking). This letter presents a unified control scheme, derived through feedback linearization, that can switch between two modes: an energy-saving mode, which tracks the main task using only the energy-efficient inputs while forcing the energy-intense inputs to zero, and a dexterous mode, which also uses the energy-intense inputs to track the auxiliary task as needed. The proposed control guarantees the exponential tracking of the main task and that the dynamics associated with the main task evolve independently of the a priori unknown switching signal. When the control is operating in dexterous mode, the exponential tracking of the auxiliary task is also guaranteed. Numerical simulations on an omnidirectional Mecanum wheel robot validate the effectiveness of the proposed approach and demonstrate the effect of the switching signal on the exponential tracking behavior of the main and auxiliary tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20524v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirko Mizzoni, Pieter van Goor, Antonio Franchi</dc:creator>
    </item>
    <item>
      <title>Localization of tumor through a non-conventional numerical shape optimization technique</title>
      <link>https://arxiv.org/abs/2502.20656</link>
      <description>arXiv:2502.20656v1 Announce Type: cross 
Abstract: This paper introduces a method for estimating the shape and location of an embedded tumor. The approach utilizes shape optimization techniques, applying the coupled complex boundary method. By rewriting the problem--characterized by a measured temperature profile and corresponding flux (e.g., from infrared thermography)--into a complex boundary value problem with a complex Robin boundary condition, the method simplifies the over-specified nature of the problem. The size and location of the tumor are identified by optimizing a cost function based on the imaginary part of the solution across the domain. Shape sensitivity analysis is conducted to compute the shape derivative of the functional. An iterative algorithm, which uses the Riesz representative of the gradient, is developed to numerically determine the geometry of the tumor via the finite element method. Additionally, we analyze the mesh sensitivity of the finite element solution of the associated state problem and derive a bound on its variation in terms of mesh deformation and its gradient. The result, valid in any dimension, applies to arbitrary unstructured simplicial meshes and finite element approximations. Numerical examples are provided to validate the theoretical findings and demonstrate the feasibility of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20656v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius Fergy Tiongson Rabago</dc:creator>
    </item>
    <item>
      <title>Tuning-Free Structured Sparse PCA via Deep Unfolding Networks</title>
      <link>https://arxiv.org/abs/2502.20837</link>
      <description>arXiv:2502.20837v1 Announce Type: cross 
Abstract: Sparse principal component analysis (PCA) is a well-established dimensionality reduction technique that is often used for unsupervised feature selection (UFS). However, determining the regularization parameters is rather challenging, and conventional approaches, including grid search and Bayesian optimization, not only bring great computational costs but also exhibit high sensitivity. To address these limitations, we first establish a structured sparse PCA formulation by integrating $\ell_1$-norm and $\ell_{2,1}$-norm to capture the local and global structures, respectively. Building upon the off-the-shelf alternating direction method of multipliers (ADMM) optimization framework, we then design an interpretable deep unfolding network that translates iterative optimization steps into trainable neural architectures. This innovation enables automatic learning of the regularization parameters, effectively bypassing the empirical tuning requirements of conventional methods. Numerical experiments on benchmark datasets validate the advantages of our proposed method over the existing state-of-the-art methods. Our code will be accessible at https://github.com/xianchaoxiu/SPCA-Net.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20837v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Chen, Xianchao Xiu</dc:creator>
    </item>
    <item>
      <title>Time-optimal problem in the space of probabilities measures</title>
      <link>https://arxiv.org/abs/2502.20871</link>
      <description>arXiv:2502.20871v1 Announce Type: cross 
Abstract: This paper focuses on the value function in the time-optimal problem for a continuity equation in the space of probability measures. We derive the dynamic programming principle for this problem. In particular, we prove that the Kruzhkov transform of the value function coincides with a unique discontinuous viscosity solution to the corresponding Dirichlet problem for the Hamilton-Jacobi equation. Finally, we establish the $\Gamma$-convergence of the value function in a perturbed problem to the value function in the unperturbed problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20871v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yurii Averboukh, Ekaterina Kolpakova</dc:creator>
    </item>
    <item>
      <title>Jointly Assigning Processes to Machines and Generating Plans for Autonomous Mobile Robots in a Smart Factory</title>
      <link>https://arxiv.org/abs/2502.21101</link>
      <description>arXiv:2502.21101v1 Announce Type: cross 
Abstract: A modern smart factory runs a manufacturing procedure using a collection of programmable machines. Typically, materials are ferried between these machines using a team of mobile robots. To embed a manufacturing procedure in a smart factory, a factory operator must a) assign its processes to the smart factory's machines and b) determine how agents should carry materials between machines. A good embedding maximizes the smart factory's throughput; the rate at which it outputs products. Existing smart factory management systems solve the aforementioned problems sequentially, limiting the throughput that they can achieve. In this paper we introduce ACES, the Anytime Cyclic Embedding Solver, the first solver which jointly optimizes the assignment of processes to machines and the assignment of paths to agents. We evaluate ACES and show that it can scale to real industrial scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21101v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Leet, Aidan Sciortino, Sven Koenig</dc:creator>
    </item>
    <item>
      <title>3.415-Approximation for Coflow Scheduling via Iterated Rounding</title>
      <link>https://arxiv.org/abs/2502.21197</link>
      <description>arXiv:2502.21197v1 Announce Type: cross 
Abstract: We provide an algorithm giving a $\frac{140}{41}$($&lt;3.415$)-approximation for Coflow Scheduling and a $4.36$-approximation for Coflow Scheduling with release dates. This improves upon the best known $4$- and respectively $5$-approximations and addresses an open question posed by Agarwal, Rajakrishnan, Narayan, Agarwal, Shmoys, and Vahdat [Aga+18], Fukunaga [Fuk22], and others. We additionally show that in an asymptotic setting, the algorithm achieves a ($2+\epsilon$)-approximation, which is essentially optimal under $\mathbb{P}\neq\mathbb{NP}$. The improvements are achieved using a novel edge allocation scheme using iterated LP rounding together with a framework which enables establishing strong bounds for combinations of several edge allocation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21197v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars Rohwedder, Leander Schnaars</dc:creator>
    </item>
    <item>
      <title>An Adaptive Multiparameter Penalty Selection Method for Multiconstraint and Multiblock ADMM</title>
      <link>https://arxiv.org/abs/2502.21202</link>
      <description>arXiv:2502.21202v1 Announce Type: cross 
Abstract: This work presents a new method for online selection of multiple penalty parameters for the alternating direction method of multipliers (ADMM) algorithm applied to optimization problems with multiple constraints or functionals with block matrix components. ADMM is widely used for solving constrained optimization problems in a variety of fields, including signal and image processing. Implementations of ADMM often utilize a single hyperparameter, referred to as the penalty parameter, which needs to be tuned to control the rate of convergence. However, in problems with multiple constraints, ADMM may demonstrate slow convergence regardless of penalty parameter selection due to scale differences between constraints. Accounting for scale differences between constraints to improve convergence in these cases requires introducing a penalty parameter for each constraint. The proposed method is able to adaptively account for differences in scale between constraints, providing robustness with respect to problem transformations and initial selection of penalty parameters. It is also simple to understand and implement. Our numerical experiments demonstrate that the proposed method performs favorably compared to a variety of existing penalty parameter selection methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21202v1</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luke Lozenski, Michael T. McCann, Brendt Wohlberg</dc:creator>
    </item>
    <item>
      <title>Extremal Betti Numbers and Persistence in Flag Complexes</title>
      <link>https://arxiv.org/abs/2502.21294</link>
      <description>arXiv:2502.21294v1 Announce Type: cross 
Abstract: We investigate several problems concerning extremal Betti numbers and persistence in filtrations of flag complexes. For graphs on $n$ vertices, we show that $\beta_k(X(G))$ is maximal when $G=\mathcal{T}_{n,k+1}$, the Tur\'an graph on $k+1$ partition classes, where $X(G)$ denotes the flag complex of $G$. Building on this, we construct an edgewise (one edge at a time) filtration $\mathcal{G}=G_1\subseteq \cdots \subseteq \mathcal{T}_{n,k+1}$ for which $\beta_k(X(G_i))$ is maximal for all graphs on $n$ vertices and $i$ edges. Moreover, the persistence barcode $\mathcal{B}_k(X(G))$ achieves a maximal number of intervals, and total persistence, among all edgewise filtrations with $|E(\mathcal{T}_{n,k+1})|$ edges.
  For $k=1$, we consider edgewise filtrations of the complete graph $K_n$. We show that the maximal number of intervals in the persistence barcode is obtained precisely when $G_{\lceil n/2\rceil \cdot \lfloor n/2 \rfloor}=\mathcal{T}_{n,2}$. Among such filtrations, we characterize those achieving maximal total persistence. We further show that no filtration can optimize $\beta_1(X(G_i))$ for all $i$, and conjecture that our filtrations maximize the total persistence over all edgewise filtrations of $K_n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21294v1</guid>
      <category>math.CO</category>
      <category>math.AT</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lies Beers, Magnus Bakke Botnan</dc:creator>
    </item>
    <item>
      <title>Pontryagin maximum principle for the deterministic mean field type optimal control problem via the Lagrangian approach</title>
      <link>https://arxiv.org/abs/2207.01892</link>
      <description>arXiv:2207.01892v3 Announce Type: replace 
Abstract: We study necessary optimality conditions for the deterministic mean field type free-endpoint optimal control problem. Our study relies on the Lagrangian approach that treats the mean field type control system as a crowd of infinitely many agents who are labeled by elements of some probability space. First, we derive the Pontryagin maximum principle in the Lagrangian form. Furthermore, we consider the Kantorovich and Eulerian formalizations which describe mean field type control systems via distributions on the set of trajectories and nonlocal continuity equation respectively. We prove that local minimizers in the Kantorovich or Eulerian formulations determine local minimizers within the Lagrangian approach. Using this, we deduce the Pontryagin maximum principle in the Kantorovich and Eulerian forms. To illustrate the general theory, we examine a model system of mean field type linear quadratic regulator. We show that the optimal strategy in this case is determined by a linear feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.01892v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yurii Averboukh, Dmitry Khlopin</dc:creator>
    </item>
    <item>
      <title>Quantized Distributed Nonconvex Optimization Algorithms with Linear Convergence under the Polyak--${\L}$ojasiewicz Condition</title>
      <link>https://arxiv.org/abs/2207.08106</link>
      <description>arXiv:2207.08106v4 Announce Type: replace 
Abstract: This paper considers distributed optimization for minimizing the average of local nonconvex cost functions, by using local information exchange over undirected communication networks. To reduce the required communication capacity, we introduce an encoder--decoder scheme. By integrating them with distributed gradient tracking and proportional integral algorithms, respectively, we then propose two quantized distributed nonconvex optimization algorithms. Assuming the global cost function satisfies the Polyak--{\L}ojasiewicz condition, which does not require the global cost function to be convex and the global minimizer is not necessarily unique, we show that our proposed algorithms linearly converge to a global optimal point and that larger quantization level leads to faster convergence speed. Moreover, we show that a low data rate is sufficient to guarantee linear convergence when the algorithm parameters are properly chosen. The theoretical results are illustrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.08106v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Xu, Xinlei Yi, Jiayue Sun, Yang Shi, Karl H. Johansson, Tao Yang</dc:creator>
    </item>
    <item>
      <title>First-order Conditions for Optimization in the Wasserstein Space</title>
      <link>https://arxiv.org/abs/2209.12197</link>
      <description>arXiv:2209.12197v2 Announce Type: replace 
Abstract: We study first-order optimality conditions for constrained optimization in the Wasserstein space, whereby one seeks to minimize a real-valued function over the space of probability measures endowed with the Wasserstein distance. Our analysis combines recent insights on the geometry and the differential structure of the Wasserstein space with more classical calculus of variations. We show that simple rationales such as "setting the derivative to zero" and "gradients are aligned at optimality" carry over to the Wasserstein space. We deploy our tools to study and solve optimization problems in the setting of distributionally robust optimization and statistical inference. The generality of our methodology allows us to naturally deal with functionals, such as mean-variance, Kullback-Leibler divergence, and Wasserstein distance, which are traditionally difficult to study in a unified framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12197v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/23M156687X</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Mathematics of Data Science, 7(1), 274-300 (2025)</arxiv:journal_reference>
      <dc:creator>Nicolas Lanzetti, Saverio Bolognani, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>LoCoDL: Communication-Efficient Distributed Learning with Local Training and Compression</title>
      <link>https://arxiv.org/abs/2403.04348</link>
      <description>arXiv:2403.04348v2 Announce Type: replace 
Abstract: In Distributed optimization and Learning, and even more in the modern framework of federated learning, communication, which is slow and costly, is critical. We introduce LoCoDL, a communication-efficient algorithm that leverages the two popular and effective techniques of Local training, which reduces the communication frequency, and Compression, in which short bitstreams are sent instead of full-dimensional vectors of floats. LoCoDL works with a large class of unbiased compressors that includes widely-used sparsification and quantization methods. LoCoDL provably benefits from local training and compression and enjoys a doubly-accelerated communication complexity, with respect to the condition number of the functions and the model dimension, in the general heterogenous regime with strongly convex functions. This is confirmed in practice, with LoCoDL outperforming existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04348v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Condat, Artavazd Maranjyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Online Trajectory Optimization for Persistent Monitoring Problems in Partitioned Environments</title>
      <link>https://arxiv.org/abs/2403.19769</link>
      <description>arXiv:2403.19769v2 Announce Type: replace 
Abstract: We consider the problem of using an autonomous agent to persistently monitor a collection of dynamic targets distributed in an environment. We generalize existing work by allowing the agent's dynamics to vary throughout the environment, leading to a hybrid dynamical system. This introduces an additional layer of complexity towards the planning portion of the problem: we must not only identify in which order to visit the points of interest, but also in which order to traverse the regions. We design an offline high-level sequence planner together with an online trajectory optimizer realizing the computed visiting sequence. We provide numerical experiments to illustrate the performance of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19769v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jonas Hall, Christos G. Cassandras, Sean B. Andersson</dc:creator>
    </item>
    <item>
      <title>Discrete Shortest Paths in Optimal Power Flow Feasible Regions</title>
      <link>https://arxiv.org/abs/2408.02172</link>
      <description>arXiv:2408.02172v2 Announce Type: replace 
Abstract: Optimal power flow (OPF) is a critical optimization problem for power systems to operate at points where cost or other operational objectives are optimized. Due to the non-convexity of the set of feasible OPF operating points, it is non-trivial to transition the power system from its current operating point to the optimal one without violating constraints. On top of that, practical considerations dictate that the transition should be achieved using a small number of small-magnitude control actions. To solve this problem, this paper proposes an algorithm for computing a transition path by framing it as a shortest path problem. This problem is formulated in terms of a discretized piece-wise linear path, where the number of pieces is fixed a priori in order to limit the number of control actions. This formulation yields a nonlinear optimization problem (NLP) with a sparse block tridiagonal structure, which we leverage by utilizing a specialized interior point method. An initial feasible path for our method is generated by solving a sequence of relaxations which are then tightened in a homotopy-like procedure. Numerical experiments illustrate the effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02172v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Turizo, Diego Cifuentes, Anton Leykin, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Fading memory and the convolution theorem</title>
      <link>https://arxiv.org/abs/2408.07386</link>
      <description>arXiv:2408.07386v2 Announce Type: replace 
Abstract: Several topological and analytical notions of continuity and fading memory for causal and time-invariant filters are introduced, and the relations between them are analyzed. A significant generalization of the convolution theorem that establishes the equivalence between the fading memory property and the availability of convolution representations of linear filters is proved. This result extends a previous similar characterization to a complete array of weighted norms in the definition of the fading memory property. Additionally, the main theorem shows that the availability of convolution representations can be characterized, at least when the codomain is finite-dimensional, not only by the fading memory property but also by the reunion of two purely topological notions that are called minimal continuity and minimal fading memory property. Finally, when the input space and the codomain of a linear functional are Hilbert spaces, it is shown that minimal continuity and the minimal fading memory property guarantee the existence of interesting embeddings of the associated reproducing kernel Hilbert spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07386v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan-Pablo Ortega, Florian Rossmannek</dc:creator>
    </item>
    <item>
      <title>Bounding the Optimal Number of Policies for Robust K-Adaptability</title>
      <link>https://arxiv.org/abs/2409.12630</link>
      <description>arXiv:2409.12630v2 Announce Type: replace 
Abstract: In the realm of robust optimization the k-adaptability approach is one promising method to derive approximate solutions for two-stage robust optimization problems. Instead of allowing all possible second-stage decisions, the k-adaptability approach aims at calculating a limited set of k such decisions already in the first-stage before the uncertainty reveals. The parameter k can be adjusted to control the quality of the approximation. However, not much is known on how many solutions k are needed to achieve an optimal solution for the two-stage robust problem. In this work we derive bounds on k which guarantee optimality for general non-linear problems with integer decisions where the uncertainty appears in the objective function or in the constraints. For convex uncertainty sets we show that for objective uncertainty the bound is the same as for the linear case and depends linearly on the dimension of the uncertainty, while for constraint uncertainty the dependence can be exponential, still providing the first generic bound for a wide class of problems. The results give new insights on how many solutions are needed for problems as the decision dependent information discovery problem or the capital budgeting problem with constraint uncertainty. Finally, for finite uncertainty sets we show that calculating the minimal optimal value for k is NP-hard and derive a greedy method which approximates this k for the case where no first-stage decisions exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12630v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Kurtz</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of Third-order Tensor Methods with Adaptive Regularization for Unconstrained Optimization</title>
      <link>https://arxiv.org/abs/2501.00404</link>
      <description>arXiv:2501.00404v2 Announce Type: replace 
Abstract: High-order tensor methods that employ local Taylor models of degree $p$ within adaptive regularization frameworks (AR$p$) have recently received significant attention, due to their optimal global and local rates of convergence for both convex and nonconvex optimization problems. However, their numerical performance for general unconstrained optimization problems remains insufficiently explored, which we address by showcasing the numerical performance of standard second- and third-order variants ($p=2,3$) and proposing novel techniques for key algorithmic aspects when $p\geq3$ to improve numerical efficiency. To improve the adaptive choice of the regularization parameter, we extend the interpolation-based updating strategy introduced in (Gould, Porcelli, and Toint, 2012) for $p=2$ to $p\geq3$. We identify fundamental differences between the local minima of regularized subproblems for $p=2$ and $p\geq3$ and their effect on performance. Then, for $p\geq3$, we introduce a novel pre-rejection technique that rejects poor subproblem minimizers (referred to as `transient') before any function evaluation, reducing cost and selecting useful (`persistent') ones. Numerical studies confirm efficiency improvements in our modified AR$3$ algorithm. We also assess the effect of different subproblem termination conditions and the choice of the initial regularization parameter on overall performance. Finally, we benchmark our best-performing AR$3$ variants, along with those in (Birgin et al., 2020), against second-order ones (AR$2$). Encouraging results on standard test problems confirm that AR$3$ variants can outperform AR$2$ in terms of objective evaluations, derivative evaluations, and subproblem solves. We provide an efficient, extensive, and modular MATLAB software package including various AR$2$ and AR$3$ variants, allowing ease of use and experimentation for interested users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00404v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Coralia Cartis, Raphael Hauser, Yang Liu, Karl Welzel, Wenqi Zhu</dc:creator>
    </item>
    <item>
      <title>Knowledge Transfer based Evolutionary Deep Neural Network for Intelligent Fault Diagnosis</title>
      <link>https://arxiv.org/abs/2109.13479</link>
      <description>arXiv:2109.13479v4 Announce Type: replace-cross 
Abstract: A faster response with commendable accuracy in intelligent systems is essential for the reliability and smooth operations of industrial machines. Two main challenges affect the design of such intelligent systems: (i) the selection of a suitable model and (ii) domain adaptation if there is a continuous change in operating conditions. Therefore, we propose an evolutionary Net2Net transformation (EvoN2N) that finds the best suitable DNN architecture with limited availability of labeled data samples. Net2Net transformation-based quick learning algorithm has been used in the evolutionary framework of Non-dominated sorting genetic algorithm II to obtain the best DNN architecture. Net2Net transformation-based quick learning algorithm uses the concept of knowledge transfer from one generation to the next for faster fitness evaluation. The proposed framework can obtain the best model for intelligent fault diagnosis without a long and time-consuming search process. The proposed framework has been validated on the Case Western Reserve University dataset, the Paderborn University dataset, and the gearbox fault detection dataset under different operating conditions. The best models obtained are capable of demonstrating an excellent diagnostic performance and classification accuracy of almost up to 100% for most of the operating conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.13479v4</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arun K. Sharma, Nishchal K. Verma</dc:creator>
    </item>
    <item>
      <title>Non-Parametric Learning of Stochastic Differential Equations with Non-asymptotic Fast Rates of Convergence</title>
      <link>https://arxiv.org/abs/2305.15557</link>
      <description>arXiv:2305.15557v5 Announce Type: replace-cross 
Abstract: We propose a novel non-parametric learning paradigm for the identification of drift and diffusion coefficients of multi-dimensional non-linear stochastic differential equations, which relies upon discrete-time observations of the state. The key idea essentially consists of fitting a RKHS-based approximation of the corresponding Fokker-Planck equation to such observations, yielding theoretical estimates of non-asymptotic learning rates which, unlike previous works, become increasingly tighter when the regularity of the unknown drift and diffusion coefficients becomes higher. Our method being kernel-based, offline pre-processing may be profitably leveraged to enable efficient numerical implementation, offering excellent balance between precision and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15557v5</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Bonalli, Alessandro Rudi</dc:creator>
    </item>
    <item>
      <title>Local Geometry Determines Global Landscape in Low-rank Factorization for Synchronization</title>
      <link>https://arxiv.org/abs/2311.18670</link>
      <description>arXiv:2311.18670v2 Announce Type: replace-cross 
Abstract: The orthogonal group synchronization problem, which focuses on recovering orthogonal group elements from their corrupted pairwise measurements, encompasses examples such as high-dimensional Kuramoto model on general signed networks, $\mathbb{Z}_2$-synchronization, community detection under stochastic block models, and orthogonal Procrustes problem. The semidefinite relaxation (SDR) has proven its power in solving this problem; however, its expensive computational costs impede its widespread practical applications. We consider the Burer-Monteiro factorization approach to the orthogonal group synchronization, an effective and scalable low-rank factorization to solve large scale SDPs. Despite the significant empirical successes of this factorization approach, it is still a challenging task to understand when the nonconvex optimization landscape is benign, i.e., the optimization landscape possesses only one local minimizer, which is also global. In this work, we demonstrate that if the degree of freedom within the factorization exceeds twice the condition number of the ``Laplacian" (certificate matrix) at the global minimizer, the optimization landscape is absent of spurious local minima. Our main theorem is purely algebraic and versatile, and it seamlessly applies to all the aforementioned examples: the nonconvex landscape remains benign under almost identical condition that enables the success of the SDR. Additionally, we illustrate that the Burer-Monteiro factorization is robust to ``monotone adversaries", mirroring the resilience of the SDR. In other words, introducing ``favorable" adversaries into the data will not result in the emergence of new spurious local minimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18670v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>Sparse-ProxSkip: Accelerated Sparse-to-Sparse Training in Federated Learning</title>
      <link>https://arxiv.org/abs/2405.20623</link>
      <description>arXiv:2405.20623v2 Announce Type: replace-cross 
Abstract: In Federated Learning (FL), both client resource constraints and communication costs pose major problems for training large models. In the centralized setting, sparse training addresses resource constraints, while in the distributed setting, local training addresses communication costs. Recent work has shown that local training provably improves communication complexity through acceleration. In this work we show that in FL, naive integration of sparse training and acceleration fails, and we provide theoretical and empirical explanations of this phenomenon. We introduce Sparse-ProxSkip, addressing the issue and implementing the efficient technique of Straight-Through Estimator pruning into sparse training. We demonstrate the performance of Sparse-ProxSkip in extensive experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20623v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georg Meinhardt, Kai Yi, Laurent Condat, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Duality of Stochastic Observability and Constructability and Links to Fisher Information</title>
      <link>https://arxiv.org/abs/2410.19975</link>
      <description>arXiv:2410.19975v3 Announce Type: replace-cross 
Abstract: Given a set of measurements, observability characterizes the distinguishability of a system's initial state, whereas constructability focuses on the final state in a trajectory. In the presence of process and/or measurement noise, the Fisher information matrices with respect to the initial and final states$\unicode{x2013}$equivalent to the stochastic observability and constructability Gramians$\unicode{x2013}$bound the performance of corresponding estimators through the Cram\'er-Rao inequality. This letter establishes a connection between stochastic observability and constructability of discrete-time linear systems and provides a more numerically robust way for calculating the stochastic observability Gramian. We define a dual system and show that the dual system's stochastic constructability is equivalent to the original system's stochastic observability, and vice versa. This duality enables the interchange of theorems and tools for observability and constructability. For example, we use this result to translate an existing recursive formula for the stochastic constructability Gramian into a formula for recursively calculating the stochastic observability Gramian for both time-varying and time-invariant systems, where this sequence converges for the latter. Finally, we illustrate the robustness of our formula compared to existing (non-recursive) formulas through a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19975v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Burak Boyac{\i}o\u{g}lu, Floris van Breugel</dc:creator>
    </item>
    <item>
      <title>Grams: Gradient Descent with Adaptive Momentum Scaling for Training Large Language Models</title>
      <link>https://arxiv.org/abs/2412.17107</link>
      <description>arXiv:2412.17107v2 Announce Type: replace-cross 
Abstract: We introduce $\mathbf{G}$radient Descent with $\mathbf{A}$daptive $\mathbf{M}$omentum $\mathbf{S}$caling ($\mathbf{Grams}$), a novel optimization algorithm that decouples the direction and magnitude of parameter updates in deep learning. Unlike traditional optimizers that directly integrate momentum into updates, Grams separates the update direction, derived from current gradients, from momentum, which is used solely for adaptive magnitude scaling. This approach enables Grams to achieve improved loss descent compared to state-of-the-art cautious and momentum-based optimizers. We theoretically demonstrate that Grams descents faster than other state-of-the-art optimizers and establish a global convergence guarantee for Grams. We also validate its effectiveness through extensive empirical evaluations. The results demonstrate Grams' superior performance, including faster convergence and better generalization, compared to widely-used optimizers such as Adam, Lion, and their cautious variants. Our results highlight Grams' potential as a transformative approach for efficiently training large language models. Code is available at $\href{https://github.com/Gunale0926/Grams}{\text{https://github.com/Gunale0926/Grams}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17107v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yang Cao, Xiaoyu Li, Zhao Song</dc:creator>
    </item>
    <item>
      <title>Scalable Decentralized Learning with Teleportation</title>
      <link>https://arxiv.org/abs/2501.15259</link>
      <description>arXiv:2501.15259v2 Announce Type: replace-cross 
Abstract: Decentralized SGD can run with low communication costs, but its sparse communication characteristics deteriorate the convergence rate, especially when the number of nodes is large. In decentralized learning settings, communication is assumed to occur on only a given topology, while in many practical cases, the topology merely represents a preferred communication pattern, and connecting to arbitrary nodes is still possible. Previous studies have tried to alleviate the convergence rate degradation in these cases by designing topologies with large spectral gaps. However, the degradation is still significant when the number of nodes is substantial. In this work, we propose TELEPORTATION. TELEPORTATION activates only a subset of nodes, and the active nodes fetch the parameters from previous active nodes. Then, the active nodes update their parameters by SGD and perform gossip averaging on a relatively small topology comprising only the active nodes. We show that by activating only a proper number of nodes, TELEPORTATION can completely alleviate the convergence rate degradation. Furthermore, we propose an efficient hyperparameter-tuning method to search for the appropriate number of nodes to be activated. Experimentally, we showed that TELEPORTATION can train neural networks more stably and achieve higher accuracy than Decentralized SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15259v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Takezawa, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Expected Variational Inequalities</title>
      <link>https://arxiv.org/abs/2502.18605</link>
      <description>arXiv:2502.18605v2 Announce Type: replace-cross 
Abstract: Variational inequalities (VIs) encompass many fundamental problems in diverse areas ranging from engineering to economics and machine learning. However, their considerable expressivity comes at the cost of computational intractability. In this paper, we introduce and analyze a natural relaxation -- which we refer to as expected variational inequalities (EVIs) -- where the goal is to find a distribution that satisfies the VI constraint in expectation. By adapting recent techniques from game theory, we show that, unlike VIs, EVIs can be solved in polynomial time under general (nonmonotone) operators. EVIs capture the seminal notion of correlated equilibria, but enjoy a greater reach beyond games. We also employ our framework to capture and generalize several existing disparate results, including from settings such as smooth games, and games with coupled constraints or nonconcave utilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18605v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Hu Zhang, Ioannis Anagnostides, Emanuel Tewolde, Ratip Emin Berker, Gabriele Farina, Vincent Conitzer, Tuomas Sandholm</dc:creator>
    </item>
  </channel>
</rss>
