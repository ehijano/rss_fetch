<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Oct 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distributionally Robust Dynamic Structural Estimation: Serial Dependence and Sensitivity Analysis</title>
      <link>https://arxiv.org/abs/2510.22347</link>
      <description>arXiv:2510.22347v1 Announce Type: new 
Abstract: Distributional assumptions that discipline serially correlated latent variables play a central role in dynamic structural models. We propose a framework to quantify the sensitivity of scalar parameters of interest (e.g., welfare, elasticity) to such distributional assumptions. We derive bounds on the scalar parameter by perturbing a reference distribution, while imposing a stationarity condition for time-homogeneous models or a Markovian condition for time-inhomogeneous models. The bounds are the solutions to optimization problems, for which we derive a computationally tractable dual formulation. We establish consistency, convergence rate, and asymptotic distribution for the estimator of the bounds. We demonstrate the approach with two applications: an infinite-horizon dynamic demand model for new cars in the United Kingdom, Germany, and France, and a finite-horizon dynamic labor supply model for taxi drivers in New York City. In the car application, perturbed price elasticities deviate by at most 15.24% from the reference elasticities, while perturbed estimates of consumer surplus from an additional $3,000 electric vehicle subsidy vary by up to 102.75%. In the labor supply application, the perturbed Frisch labor supply elasticity deviates by at most 76.83% for weekday drivers and 42.84% for weekend drivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22347v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ertian Chen</dc:creator>
    </item>
    <item>
      <title>Estimating unrestricted spatial interdependence in panel spatial autoregressive models with latent common factors</title>
      <link>https://arxiv.org/abs/2510.22399</link>
      <description>arXiv:2510.22399v1 Announce Type: new 
Abstract: We develop a new Bayesian approach to estimating panel spatial autoregressive models with a known number of latent common factors, where N, the number of cross-sectional units, is much larger than T, the number of time periods. Without imposing any a priori structures on the spatial linkages between variables, we let the data speak for themselves. Extensive Monte Carlo studies show that our method is super-fast and our estimated spatial weights matrices and common factors strongly resemble their true counterparts. As an illustration, we examine the spatial interdependence of regional gross value added (GVA) growth rates across the European Union (EU). In addition to revealing the clear presence of predominant country-level clusters, our results indicate that only a small portion of the variation in the data is explained by the latent shocks that are uncorrelated with the explanatory variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22399v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Deborah Gefang, Stephen G Hall, George S. Tavlas</dc:creator>
    </item>
    <item>
      <title>Testing for Grouped Patterns in Panel Data Models</title>
      <link>https://arxiv.org/abs/2510.22841</link>
      <description>arXiv:2510.22841v1 Announce Type: new 
Abstract: While the literature on grouped patterns in panel data analysis has received significant attention, little to no results are available on testing for their presence. We propose using existing tools for testing slope homogeneity in panels for this purpose. We highlight the key advantages and limitations of the available testing frameworks under a sequence of doubly local alternatives, where slopes are divided into dominant and remainder groups, with the size of the remainder groups and the slopes differences shrinking at a certain rate as the sample size increases. A Monte Carlo study corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22841v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Raiola, Nazarii Salish</dc:creator>
    </item>
    <item>
      <title>Identification, Estimation, and Inference in Two-Sided Interaction Models</title>
      <link>https://arxiv.org/abs/2510.22884</link>
      <description>arXiv:2510.22884v1 Announce Type: new 
Abstract: This paper studies a class of models for two-sided interactions, where outcomes depend on latent characteristics of two distinct agent types. Models in this class have two core elements: the matching network, which records which agent pairs interact, and the interaction function, which maps latent characteristics of these agents to outcomes and determines the role of complementarities. I introduce the Tukey model, which captures complementarities with a single interaction parameter, along with two extensions that allow richer complementarity patterns. First, I establish an identification trade-off between the flexibility of the interaction function and the density of the matching network: the Tukey model is identified under mild conditions, whereas the more flexible extensions require dense networks that are rarely observed in applications. Second, I propose a cycle-based estimator for the Tukey interaction parameter and show that it is consistent and asymptotically normal even when the network is sparse. Third, I use its asymptotic distribution to construct a formal test of no complementarities. Finally, an empirical illustration shows that the Tukey model recovers economically meaningful complementarities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22884v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Crippa</dc:creator>
    </item>
    <item>
      <title>Macroeconomic Forecasting for the G7 countries under Uncertainty Shocks</title>
      <link>https://arxiv.org/abs/2510.23347</link>
      <description>arXiv:2510.23347v1 Announce Type: new 
Abstract: Accurate macroeconomic forecasting has become harder amid geopolitical disruptions, policy reversals, and volatile financial markets. Conventional vector autoregressions (VARs) overfit in high dimensional settings, while threshold VARs struggle with time varying interdependencies and complex parameter structures. We address these limitations by extending the Sims Zha Bayesian VAR with exogenous variables (SZBVARx) to incorporate domain-informed shrinkage and four newspaper based uncertainty shocks such as economic policy uncertainty, geopolitical risk, US equity market volatility, and US monetary policy uncertainty. The framework improves structural interpretability, mitigates dimensionality, and imposes empirically guided regularization. Using G7 data, we study spillovers from uncertainty shocks to five core variables (unemployment, real broad effective exchange rates, short term rates, oil prices, and CPI inflation), combining wavelet coherence (time frequency dynamics) with nonlinear local projections (state dependent impulse responses). Out-of-sample results at 12 and 24 month horizons show that SZBVARx outperforms 14 benchmarks, including classical VARs and leading machine learning models, as confirmed by Murphy difference diagrams, multivariate Diebold Mariano tests, and Giacomini White predictability tests. Credible Bayesian prediction intervals deliver robust uncertainty quantification for scenario analysis and risk management. The proposed SZBVARx offers G7 policymakers a transparent, well calibrated tool for modern macroeconomic forecasting under pervasive uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23347v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shovon Sengupta, Sunny Kumar Singh, Tanujit Chakraborty</dc:creator>
    </item>
    <item>
      <title>Choosing What to Learn: Experimental Design when Combining Experimental with Observational Evidence</title>
      <link>https://arxiv.org/abs/2510.23434</link>
      <description>arXiv:2510.23434v1 Announce Type: new 
Abstract: Experiments deliver credible but often localized effects, tied to specific sites, populations, or mechanisms. When such estimates are insufficient to extrapolate effects for broader policy questions, such as external validity and general-equilibrium (GE) effects, researchers combine trials with external evidence from reduced-form or structural observational estimates, or prior experiments. We develop a unified framework for designing experiments in this setting: the researcher selects which parameters to identify experimentally from a feasible set (which treatment arms and/or individuals to include in the experiment), allocates sample size, and specifies how to weight experimental and observational estimators. Because observational inputs may be biased in ways unknown ex ante, we develop a minimax proportional regret objective that evaluates any candidate design relative to an oracle that knows the bias and jointly chooses the design and estimator. This yields a transparent bias-variance trade-off that requires no prespecified bias bound and depends only on information about the precision of the estimators and the estimand's sensitivity to the underlying parameters. We illustrate the framework by (i) designing small-scale cash transfer experiments aimed at estimating GE effects and (ii) optimizing site selection for microfinance interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23434v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Aristotelis Epanomeritakis, Davide Viviano</dc:creator>
    </item>
    <item>
      <title>Direct Debiased Machine Learning via Bregman Divergence Minimization</title>
      <link>https://arxiv.org/abs/2510.23534</link>
      <description>arXiv:2510.23534v1 Announce Type: new 
Abstract: We develop a direct debiased machine learning framework comprising Neyman targeted estimation and generalized Riesz regression. Our framework unifies Riesz regression for automatic debiased machine learning, covariate balancing, targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In many problems involving causal effects or structural models, the parameters of interest depend on regression functions. Plugging regression functions estimated by machine learning methods into the identifying equations can yield poor performance because of first-stage bias. To reduce such bias, debiased machine learning employs Neyman orthogonal estimating equations. Debiased machine learning typically requires estimation of the Riesz representer and the regression function. For this problem, we develop a direct debiased machine learning framework with an end-to-end algorithm. We formulate estimation of the nuisance parameters, the regression function and the Riesz representer, as minimizing the discrepancy between Neyman orthogonal scores computed with known and unknown nuisance parameters, which we refer to as Neyman targeted estimation. Neyman targeted estimation includes Riesz representer estimation, and we measure discrepancies using the Bregman divergence. The Bregman divergence encompasses various loss functions as special cases, where the squared loss yields Riesz regression and the Kullback-Leibler divergence yields entropy balancing. We refer to this Riesz representer estimation as generalized Riesz regression. Neyman targeted estimation also yields TMLE as a special case for regression function estimation. Furthermore, for specific pairs of models and Riesz representer estimation methods, we can automatically obtain the covariate balancing property without explicitly solving the covariate balancing objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23534v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>The causal interpretation of panel vector autoregressions</title>
      <link>https://arxiv.org/abs/2510.23540</link>
      <description>arXiv:2510.23540v1 Announce Type: new 
Abstract: This paper discusses the different contemporaneous causal interpretations of Panel Vector Autoregressions (PVAR). I show that the interpretation of PVARs depends on the distribution of the causing variable, and can range from average treatment effects, to average causal responses, to a combination of the two. If the researcher is willing to postulate a no residual autocorrelation assumption, and some units can be thought of as controls, PVAR can identify average treatment effects on the treated. This method complements the toolkits already present in the literature, such as staggered-DiD, or LP-DiD, as it formulates assumptions in the residuals, and not in the outcome variables. Such a method features a notable advantage: it allows units to be ``sparsely'' treated, capturing the impact of interventions on the innovation component of the outcome variables. I provide an example related to the evaluation of the effects of natural disasters economic activity at the weekly frequency in the US.I conclude by discussing solutions to potential violations of the SUTVA assumption arising from interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23540v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raimondo Pala</dc:creator>
    </item>
    <item>
      <title>Pairwise Difference Representations of Moments: Gini and Generalized Lagrange identities</title>
      <link>https://arxiv.org/abs/2510.22714</link>
      <description>arXiv:2510.22714v1 Announce Type: cross 
Abstract: We provide pairwise-difference (Gini-type) representations of higher-order central moments for both general random variables and empirical moments. Such representations do not require a measure of location. For third and fourth moments, this yields pairwise-difference representations of skewness and kurtosis coefficients. We show that all central moments possess such representations, so no reference to the mean is needed for moments of any order. This is done by considering i.i.d. replications of the random variables considered, by observing that central moments can be interpreted as covariances between a random variable and powers of the same variable, and by giving recursions which link the pairwise-difference representation of any moment to lower order ones. Numerical summation identities are deduced. Through a similar approach, we give analogues of the Lagrange and Binet-Cauchy identities for general random variables, along with a simple derivation of the classic Cauchy-Schwarz inequality for covariances. Finally, an application to unbiased estimation of centered moments is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22714v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Marie Dufour, Abderrahim Taamouti, Meilin Tong</dc:creator>
    </item>
    <item>
      <title>Unifying regression-based and design-based causal inference in time-series experiments</title>
      <link>https://arxiv.org/abs/2510.22864</link>
      <description>arXiv:2510.22864v1 Announce Type: cross 
Abstract: Time-series experiments, also called switchback experiments or N-of-1 trials, play increasingly important roles in modern applications in medical and industrial areas. Under the potential outcomes framework, recent research has studied time-series experiments from the design-based perspective, relying solely on the randomness in the design to drive the statistical inference. Focusing on simpler statistical methods, we examine the design-based properties of regression-based methods for estimating treatment effects in time-series experiments. We demonstrate that the treatment effects of interest can be consistently estimated using ordinary least squares with an appropriately specified working model and transformed regressors. Our analysis allows for estimating a diverging number of treatment effects simultaneously, and establishes the consistency and asymptotic normality of the regression-based estimators. Additionally, we show that asymptotically, the heteroskedasticity and autocorrelation consistent variance estimators provide conservative estimates of the true, design-based variances. Importantly, although our approach relies on regression, our design-based framework allows for misspecification of the regression model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22864v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhexiao Lin, Peng Ding</dc:creator>
    </item>
    <item>
      <title>Bridging Stratification and Regression Adjustment: Batch-Adaptive Stratification with Post-Design Adjustment in Randomized Experiments</title>
      <link>https://arxiv.org/abs/2510.22908</link>
      <description>arXiv:2510.22908v1 Announce Type: cross 
Abstract: To increase statistical efficiency in a randomized experiment, researchers often use stratification (i.e., blocking) in the design stage. However, conventional practices of stratification fail to exploit valuable information about the predictive relationship between covariates and potential outcomes. In this paper, I introduce an adaptive stratification procedure for increasing statistical efficiency when some information is available about the relationship between covariates and potential outcomes. I show that, in a paired design, researchers can rematch observations across different batches. For inference, I propose a stratified estimator that allows for nonparametric covariate adjustment. I then discuss the conditions under which researchers should expect gains in efficiency from stratification. I show that stratification complements rather than substitutes for regression adjustment, insuring against adjustment error even when researchers plan to use covariate adjustment. To evaluate the performance of the method relative to common alternatives, I conduct simulations using both synthetic data and more realistic data derived from a political science experiment. Results demonstrate that the gains in precision and efficiency can be substantial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22908v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zikai Li</dc:creator>
    </item>
    <item>
      <title>Bayesian analysis of mixtures of lognormal distribution with an unknown number of components from grouped data</title>
      <link>https://arxiv.org/abs/2210.05115</link>
      <description>arXiv:2210.05115v4 Announce Type: replace 
Abstract: This study proposes a reversible jump Markov chain Monte Carlo method for estimating parameters of lognormal distribution mixtures for income. Using simulated data examples, we examined the proposed algorithm's performance and the accuracy of posterior distributions of the Gini coefficients. Results suggest that the parameters were estimated accurately. Therefore, the posterior distributions are close to the true distributions even when the different data generating process is accounted for. Moreover, promising results for Gini coefficients encouraged us to apply our method to real data from Japan. The empirical examples indicate two subgroups in Japan (2020) and the Gini coefficients' integrity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05115v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kazuhiko Kakamu</dc:creator>
    </item>
    <item>
      <title>Inference on common trends in functional time series</title>
      <link>https://arxiv.org/abs/2312.00590</link>
      <description>arXiv:2312.00590v5 Announce Type: replace 
Abstract: We study statistical inference on unit roots and cointegration for time series in a Hilbert space. We develop statistical inference on the number of common stochastic trends embedded in the time series, i.e., the dimension of the nonstationary subspace. We also consider tests of hypotheses on the nonstationary and stationary subspaces themselves. The Hilbert space can be of an arbitrarily large dimension, and our methods remain asymptotically valid even when the time series of interest takes values in a subspace of possibly unknown dimension. This has wide applicability in practice; for example, to cointegrated vector time series that are either high-dimensional or of finite dimension, to high-dimensional factor models that include a finite number of nonstationary factors, to cointegrated curve-valued (or function-valued) time series, and to nonstationary dynamic functional factor models. We include two empirical illustrations to the term structure of interest rates and labor market indices, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00590v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Morten {\O}rregaard Nielsen, Won-Ki Seo, Dakyung Seong</dc:creator>
    </item>
    <item>
      <title>Local Identification in Instrumental Variable Multivariate Quantile Regression Models</title>
      <link>https://arxiv.org/abs/2401.11422</link>
      <description>arXiv:2401.11422v4 Announce Type: replace 
Abstract: In the instrumental variable quantile regression (IVQR) model of Chernozhukov and Hansen (2005), a one-dimensional unobserved rank variable monotonically determines a single potential outcome. In practice, when researchers are interested in multiple outcomes, it is common to estimate separate IVQR models for each of them. This approach implicitly assumes that the rank variable in each regression affects only its associated outcome, without influencing others. In reality, however, outcomes are often jointly determined by multiple latent factors, inducing structural correlations across equations.
  To address this limitation, we propose a nonlinear instrumental variable model that accommodates multivariate unobserved heterogeneity, where each component of the latent vector acts as a rank variable corresponding to an observed outcome. When both the treatment and the instrument are discrete, we show that the structural function in our model is locally identified under a sufficiently strong positive correlation between the treatment and the instrument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11422v4</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haruki Kono</dc:creator>
    </item>
    <item>
      <title>Continuous difference-in-differences with double/debiased machine learning</title>
      <link>https://arxiv.org/abs/2408.10509</link>
      <description>arXiv:2408.10509v5 Announce Type: replace 
Abstract: This paper extends difference-in-differences to settings with continuous treatments. Specifically, the average treatment effect on the treated (ATT) at any level of treatment intensity is identified under a conditional parallel trends assumption. Estimating the ATT in this framework requires first estimating infinite-dimensional nuisance parameters, particularly the conditional density of the continuous treatment, which can introduce substantial bias. To address this challenge, we propose estimators for the causal parameters under the double/debiased machine learning framework and establish their asymptotic normality. Additionally, we provide consistent variance estimators and construct uniform confidence bands based on a multiplier bootstrap procedure. To demonstrate the effectiveness of our approach, we apply our estimators to the 1983 Medicare Prospective Payment System (PPS) reform studied by Acemoglu and Finkelstein (2008), reframing it as a DiD with continuous treatment and nonparametrically estimating its effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10509v5</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/ectj/utaf024</arxiv:DOI>
      <dc:creator>Lucas Z. Zhang</dc:creator>
    </item>
    <item>
      <title>Detecting multiple change points in linear models with heteroscedasticity</title>
      <link>https://arxiv.org/abs/2505.01296</link>
      <description>arXiv:2505.01296v3 Announce Type: replace 
Abstract: The problem of detecting change points in the parameters of a linear regression model with errors and covariates exhibiting heteroscedasticity is considered. Asymptotic results for weighted functionals of the cumulative sum (CUSUM) processes of model residuals are established when the model errors are weakly dependent and non-stationary, allowing for either abrupt or smooth changes in their variance. These theoretical results illuminate how to adapt standard change point test statistics for linear models to this setting. We studied such adapted change-point tests in simulation experiments, along with a finite sample adjustment to the proposed testing procedures. The results suggest that these methods perform well in practice for detecting multiple change points in the linear model parameters and controlling the Type I error rate in the presence of heteroscedasticity. We illustrate the use of these approaches in applications to test for instability in predictive regression models and explanatory asset pricing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01296v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lajos Horvath, Gregory Rice, Yuqian Zhao</dc:creator>
    </item>
    <item>
      <title>FARS: Factor Augmented Regression Scenarios in R</title>
      <link>https://arxiv.org/abs/2507.10679</link>
      <description>arXiv:2507.10679v4 Announce Type: replace-cross 
Abstract: In the context of macroeconomic/financial time series, the FARS package provides a comprehensive framework in R for the construction of conditional densities of the variable of interest based on the factor-augmented quantile regressions (FA-QRs) methodology, with the factors extracted from multi-level dynamic factor models (ML-DFMs) with potential overlapping group-specific factors. Furthermore, the package also allows the construction of measures of risk as well as modeling and designing economic scenarios based on the conditional densities. In particular, the package enables users to: (i) extract global and group-specific factors using a flexible multi-level factor structure; (ii) compute asymptotically valid confidence regions for the estimated factors, accounting for uncertainty in the factor loadings; (iii) obtain estimates of the parameters of the FA-QRs together with their standard deviations; (iv) recover full predictive conditional densities from estimated quantiles; (v) obtain risk measures based on extreme quantiles of the conditional densities; and (vi) estimate the conditional density and the corresponding extreme quantiles when the factors are stressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10679v4</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Pietro Bellocca, Ignacio Garr\'on, Vladimir Rodr\'iguez-Caballero, Esther Ruiz</dc:creator>
    </item>
    <item>
      <title>Beyond the Average: Distributional Causal Inference under Imperfect Compliance</title>
      <link>https://arxiv.org/abs/2509.15594</link>
      <description>arXiv:2509.15594v2 Announce Type: replace-cross 
Abstract: We study the estimation of distributional treatment effects in randomized experiments with imperfect compliance. When participants do not adhere to their assigned treatments, we leverage treatment assignment as an instrumental variable to identify the local distributional treatment effect-the difference in outcome distributions between treatment and control groups for the subpopulation of compliers. We propose a regression-adjusted estimator based on a distribution regression framework with Neyman-orthogonal moment conditions, enabling robustness and flexibility with high-dimensional covariates. Our approach accommodates continuous, discrete, and mixed discrete-continuous outcomes, and applies under a broad class of covariate-adaptive randomization schemes, including stratified block designs and simple random sampling. We derive the estimator's asymptotic distribution and show that it achieves the semiparametric efficiency bound. Simulation results demonstrate favorable finite-sample performance, and we demonstrate the method's practical relevance in an application to the Oregon Health Insurance Experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15594v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Undral Byambadalai, Tomu Hirata, Tatsushi Oka, Shota Yasui</dc:creator>
    </item>
  </channel>
</rss>
