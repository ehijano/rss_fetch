<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 02:46:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MDRefine: a Python package for refining Molecular Dynamics trajectories with experimental data</title>
      <link>https://arxiv.org/abs/2411.07798</link>
      <description>arXiv:2411.07798v1 Announce Type: cross 
Abstract: Molecular dynamics (MD) simulations play a crucial role in resolving the underlying conformational dynamics of molecular systems. However, their capability to correctly reproduce and predict dynamics in agreement with experiments is limited by the accuracy of the force-field model. This capability can be improved by refining the structural ensembles or the force-field parameters. Furthermore, discrepancies with experimental data can be due to imprecise forward models, namely, functions mapping simulated structures to experimental observables. Here, we introduce MDRefine, a Python package aimed at implementing the refinement of the ensemble, the force-field and/or the forward model by comparing MD-generated trajectories with experimental data. The software consists of several tools that can be employed separately from each other or combined together in different ways, providing a seamless interpolation between these three different types of refinement. We use some benchmark cases to show that the combined approach is superior to separately applied refinements. Source code, documentation and examples are freely available at https://pypi.org/project/MDRefine and https://github.com/bussilab/MDRefine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07798v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Gilardoni, Valerio Piomponi, Thorben Fr\"ohlking, Giovanni Bussi</dc:creator>
    </item>
    <item>
      <title>RiNALMo: General-Purpose RNA Language Models Can Generalize Well on Structure Prediction Tasks</title>
      <link>https://arxiv.org/abs/2403.00043</link>
      <description>arXiv:2403.00043v2 Announce Type: replace 
Abstract: While RNA has recently been recognized as an interesting small-molecule drug target, many challenges remain to be addressed before we take full advantage of it. This emphasizes the necessity to improve our understanding of its structures and functions. Over the years, sequencing technologies have produced an enormous amount of unlabeled RNA data, which hides a huge potential. Motivated by the successes of protein language models, we introduce RiboNucleic Acid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is the largest RNA language model to date, with 650M parameters pre-trained on 36M non-coding RNA sequences from several databases. It can extract hidden knowledge and capture the underlying structure information implicitly embedded within the RNA sequences. RiNALMo achieves state-of-the-art results on several downstream tasks. Notably, we show that its generalization capabilities overcome the inability of other deep learning methods for secondary structure prediction to generalize on unseen RNA families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00043v2</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Josip Peni\'c, Tin Vla\v{s}i\'c, Roland G. Huber, Yue Wan, Mile \v{S}iki\'c</dc:creator>
    </item>
    <item>
      <title>Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics</title>
      <link>https://arxiv.org/abs/2307.06797</link>
      <description>arXiv:2307.06797v2 Announce Type: replace-cross 
Abstract: In this study, we address the challenge of using energy-based models to produce high-quality, label-specific data in complex structured datasets, such as population genetics, RNA or protein sequences data. Traditional training methods encounter difficulties due to inefficient Markov chain Monte Carlo mixing, which affects the diversity of synthetic data and increases generation times. To address these issues, we use a novel training algorithm that exploits non-equilibrium effects. This approach, applied on the Restricted Boltzmann Machine, improves the model's ability to correctly classify samples and generate high-quality synthetic data in only a few sampling steps. The effectiveness of this method is demonstrated by its successful application to four different types of data: handwritten digits, mutations of human genomes classified by continental origin, functionally characterized sequences of an enzyme protein family, and homologous RNA sequences from specific taxonomies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06797v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>q-bio.BM</category>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE: Transactions on Pattern Analysis and Machine Intelligence, 2024</arxiv:journal_reference>
      <dc:creator>Alessandra Carbone, Aur\'elien Decelle, Lorenzo Rosset, Beatriz Seoane</dc:creator>
    </item>
    <item>
      <title>FoldMark: Protecting Protein Generative Models with Watermarking</title>
      <link>https://arxiv.org/abs/2410.20354</link>
      <description>arXiv:2410.20354v4 Announce Type: replace-cross 
Abstract: Protein structure is key to understanding protein function and is essential for progress in bioengineering, drug discovery, and molecular biology. Recently, with the incorporation of generative AI, the power and accuracy of computational protein structure prediction/design have been improved significantly. However, ethical concerns such as copyright protection and harmful content generation (biosecurity) pose challenges to the wide implementation of protein generative models. Here, we investigate whether it is possible to embed watermarks into protein generative models and their outputs for copyright authentication and the tracking of generated structures. As a proof of concept, we propose a two-stage method FoldMark as a generalized watermarking strategy for protein generative models. FoldMark first pretrain watermark encoder and decoder, which can minorly adjust protein structures to embed user-specific information and faithfully recover the information from the encoded structure. In the second step, protein generative models are fine-tuned with watermark-conditioned Low-Rank Adaptation (LoRA) modules to preserve generation quality while learning to generate watermarked structures with high recovery rates. Extensive experiments are conducted on open-source protein structure prediction models (e.g., ESMFold and MultiFlow) and de novo structure design models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method is effective across all these generative models. Meanwhile, our watermarking framework only exerts a negligible impact on the original protein structure quality and is robust under potential post-processing and adaptive attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20354v4</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zaixi Zhang, Ruofan Jin, Kaidi Fu, Le Cong, Marinka Zitnik, Mengdi Wang</dc:creator>
    </item>
  </channel>
</rss>
