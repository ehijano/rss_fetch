<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.GN</link>
    <description>q-bio.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2024 05:01:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Leveraging genomic deep learning models for non-coding variant effect prediction</title>
      <link>https://arxiv.org/abs/2411.11158</link>
      <description>arXiv:2411.11158v1 Announce Type: new 
Abstract: The majority of genetic variants identified in genome-wide association studies of complex traits are non-coding, and characterizing their function remains an important challenge in human genetics. Genomic deep learning models have emerged as a promising approach to enable in silico prediction of variant effects. These include supervised sequence-to-activity models, which predict genome-wide chromatin states or gene expression levels directly from DNA sequence, and self-supervised genomic language models. Here, we review progress in leveraging these models for non-coding variant effect prediction. We describe practical considerations for making such predictions and categorize the types of ground truth data that have been used to evaluate deep learning-based variant effect predictions, providing insight into the settings in which current models are most useful. We also discuss downstream applications of such models to understanding disease-relevant non-coding variants. Our review highlights key considerations for practitioners and opportunities for future improvements in model development and evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11158v1</guid>
      <category>q-bio.GN</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pooja Kathail, Ayesha Bajwa, Nilah M. Ioannidis</dc:creator>
    </item>
    <item>
      <title>Validating GWAS Findings through Reverse Engineering of Contingency Tables</title>
      <link>https://arxiv.org/abs/2411.11169</link>
      <description>arXiv:2411.11169v1 Announce Type: new 
Abstract: Reproducibility in genome-wide association studies (GWAS) is crucial for ensuring reliable genomic research outcomes. However, limited access to original genomic datasets (mainly due to privacy concerns) prevents researchers from reproducing experiments to validate results. In this paper, we propose a novel method for GWAS reproducibility validation that detects unintentional errors without the need for dataset sharing. Our approach leverages p-values from GWAS outcome reports to estimate contingency tables for each single nucleotide polymorphism (SNP) and calculates the Hamming distance between the minor allele frequencies (MAFs) derived from these contingency tables and publicly available phenotype-specific MAF data. By comparing the average Hamming distance, we validate results that fall within a trusted threshold as reliable, while flagging those that exceed the threshold for further inspection. This approach not only allows researchers to validate the correctness of GWAS findings of other researchers, but it also provides a self-check step for the researchers before they publish their findings. We evaluate our approach using three real-life SNP datasets from OpenSNP, showing its ability to detect unintentional errors effectively, even when small errors occur, such as 1\% of SNPs being reported incorrectly. This novel validation technique offers a promising solution to the GWAS reproducibility challenge, balancing the need for rigorous validation with the imperative of protecting sensitive genomic data, thereby enhancing trust and accuracy in genetic research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11169v1</guid>
      <category>q-bio.GN</category>
      <category>cs.CR</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzhou Jiang, Erman Ayday</dc:creator>
    </item>
    <item>
      <title>gpuPairHMM: High-speed Pair-HMM Forward Algorithm for DNA Variant Calling on GPUs</title>
      <link>https://arxiv.org/abs/2411.11547</link>
      <description>arXiv:2411.11547v1 Announce Type: cross 
Abstract: The continually increasing volume of DNA sequence data has resulted in a growing demand for fast implementations of core algorithms. Computation of pairwise alignments between candidate haplotypes and sequencing reads using Pair-HMMs is a key component in DNA variant calling tools such as the GATK HaplotypeCaller but can be highly time consuming due to its quadratic time complexity and the large number of pairs to be aligned. Unfortunately, previous approaches to accelerate this task using the massively parallel processing capabilities of modern GPUs are limited by inefficient memory access schemes. This established the need for significantly faster solutions. We address this need by presenting gpuPairHMM -- a novel GPU-based parallelization scheme for the dynamic-programming based Pair-HMM forward algorithm based on wavefronts and warp-shuffles. It gains efficiency by minimizing both memory accesses and instructions. We show that our approach achieves close-to-peak performance on several generations of modern CUDA-enabled GPUs (Volta, Ampere, Ada, Hopper). It also outperforms prior implementations on GPUs, CPUs, and FPGAs by a factor of at least 8.6, 10.4, and 14.5, respectively. gpuPairHMM is publicly available at https://github.com/asbschmidt/gpuPairHMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11547v1</guid>
      <category>cs.DC</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bertil Schmidt, Felix Kallenborn, Alexander Wichmann, Alejandro Chacon, Christian Hundt</dc:creator>
    </item>
    <item>
      <title>Supervised machine learning for microbiomics: bridging the gap between current and best practices</title>
      <link>https://arxiv.org/abs/2402.17621</link>
      <description>arXiv:2402.17621v4 Announce Type: replace 
Abstract: Machine learning (ML) is poised to drive innovations in clinical microbiomics, such as in disease diagnostics and prognostics. However, the successful implementation of ML in these domains necessitates the development of reproducible, interpretable models that meet the rigorous performance standards set by regulatory agencies. This study aims to identify key areas in need of improvement in current ML practices within microbiomics, with a focus on bridging the gap between existing methodologies and the requirements for clinical application. To do so, we analyze 100 peer-reviewed articles from 2021-2022. Within this corpus, datasets have a median size of 161.5 samples, with over one-third containing fewer than 100 samples, signaling a high potential for overfitting. Limited demographic data further raises concerns about generalizability and fairness, with 24% of studies omitting participants' country of residence, and attributes like race/ethnicity, education, and income rarely reported (11%, 2%, and 0%, respectively). Methodological issues are also common; for instance, for 86% of studies we could not confidently rule out test set omission and data leakage, suggesting a strong potential for inflated performance estimates across the literature. Reproducibility is also a concern, with 78% of studies abstaining from sharing their ML code publicly. Based on this analysis, we provide guidance to avoid common pitfalls that can hinder model performance, generalizability, and trustworthiness. An interactive tutorial on applying ML to microbiomics data accompanies the discussion, to help establish and reinforce best practices within the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17621v4</guid>
      <category>q-bio.GN</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natasha K. Dudek, Mariam Chakhvadze, Saba Kobakhidze, Omar Kantidze, Yuriy Gankin</dc:creator>
    </item>
    <item>
      <title>White-Box Diffusion Transformer for single-cell RNA-seq generation</title>
      <link>https://arxiv.org/abs/2411.06785</link>
      <description>arXiv:2411.06785v2 Announce Type: replace-cross 
Abstract: As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell RNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional analysis. However, the process of data acquisition is often constrained by high cost and limited sample availability. To overcome these limitations, we propose a hybrid model based on Diffusion model and White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq data. Diffusion model progressively introduce noise into the data and then recover the original data through a denoising process, a forward and reverse process that is particularly suitable for generating complex data distributions. White-Box transformer is a deep learning architecture that emphasizes mathematical interpretability. By minimizing the encoding rate of the data and maximizing the sparsity of the representation, it not only reduces the computational burden, but also provides clear insight into underlying structure. Our White-Box Diffusion Transformer combines the generative capabilities of Diffusion model with the mathematical interpretability of White-Box transformer. Through experiments using six different single-cell RNA-Seq datasets, we visualize both generated and real data using t-SNE dimensionality reduction technique, as well as quantify similarity between generated and real data using various metrics to demonstrate comparable performance of White-Box Diffusion Transformer and Diffusion Transformer in generating scRNA-seq data alongside significant improvements in training efficiency and resource utilization. Our code is available at https://github.com/lingximamo/White-Box-Diffusion-Transformer</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06785v2</guid>
      <category>cs.LG</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuorui Cui, Shengze Dong, Ding Liu</dc:creator>
    </item>
  </channel>
</rss>
