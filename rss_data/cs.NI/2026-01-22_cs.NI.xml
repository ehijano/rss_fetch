<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Jan 2026 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A benchmarking framework for PON-based fronthaul network design</title>
      <link>https://arxiv.org/abs/2601.14480</link>
      <description>arXiv:2601.14480v1 Announce Type: new 
Abstract: As mobile networks transition toward 5G and 6G RAN architectures, Passive Optical Networks (PONs) offer a critical solution for cost-effective fronthaul transport. However, the lack of standardized evaluation models in current literature makes an objective comparison of diverse optimization strategies difficult. This paper addresses this gap by proposing a unified benchmarking framework that standardizes cost catalogs and deployment scenarios. We formulate the network design problem using Integer Linear Programming (ILP) to establish optimality bounds and evaluate three scalable heuristic strategies: a Genetic Algorithm, K-Means Clustering (KMC+), and a graph-based Randomized Successive Splitter Assignment (RSSA+) algorithm. Simulation results show that a time-limited ILP remains a strong reference point, even when optimality is not reached. Despite being rarely used in prior fronthaul planning studies, it consistently yields solutions superior to those produced by standard heuristic methods. Among scalable approaches, RSSA+ reliably attains near-ILP performance while ensuring feasibility across all evaluated scenarios, which underscores the importance of advanced, constraint-aware algorithmic designs over simpler heuristics. The complete benchmarking framework and datasets are publicly shared in [1].</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14480v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egemen Erbayat, Gustavo B. Figueiredo, Shih-Chun Lin, Motoharu Matsuura, Hiroshi Hasegawa, Suresh Subramaniam</dc:creator>
    </item>
    <item>
      <title>5G NR Non-Terrestrial Networks: Open Challenges for Full-Stack Protocol Design</title>
      <link>https://arxiv.org/abs/2601.14883</link>
      <description>arXiv:2601.14883v1 Announce Type: new 
Abstract: As 5th generation (5G) networks continue to evolve, there is a growing interest toward the integration of Terrestrial Networks (TNs) and Non-Terrestrial Networks (NTNs). Specifically, NTNs leverage space/air base stations such as satellites, High Altitude Platforms (HAPs), and Unmanned Aerial Vehicles (UAVs) for expanding wireless coverage to underserved rural/remote areas, supporting emergency communications, and offloading traffic in highly congested urban environments. In this paper we focus on the 3GPP 5G NR-NTN standard in the context of satellite communication networks, and highlight critical challenges that must be addressed for proper full-stack protocol design, with considerations related to the PHY, MAC, and higher layers. We also present simulation results in ns-3 to demonstrate the impact of some of these challenges on the network, as an initial step toward more advanced standardization activities on 3GPP 5G NR-NTN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14883v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Rossato, Mattia Figaro, Alessandro Traspadini, Takayuki Shimizu, Chinmay Mahabal, Sanjeewa Herath, Chunghan Lee, Dogan Kutay Pekcan, Michele Zorzi, Marco Giordani</dc:creator>
    </item>
    <item>
      <title>Economic feasibility of virtual operators in 5G via network slicing</title>
      <link>https://arxiv.org/abs/2601.15103</link>
      <description>arXiv:2601.15103v1 Announce Type: new 
Abstract: The provision of services by more than one operator over a common network infrastructure, as enabled by 5G network slicing, is analyzed. Two business models to be implemented by a network operator, who owns the network, and a virtual operator, who does not, are proposed. In one business model, named \emph{strategic}, the network operator provides service to its user base and the virtual operator provides service to its user base and pays a per-subscriber fee to the network operator. In the other business model, named \emph{monopolistic}, the network operator provides service to both user bases. The two proposals are analyzed by means of a model that captures both system and economic features. As regards the systems features, the slicing of the network is modeled by means of a Discriminatory Processor Sharing queue. As regards the economic features, the incentives are modeled by means of the user utilities and the operators' revenues; and game theory is used to model the strategic interaction between the users' subscription decision and the operators' pricing decision. In both business models, it is shown that the network operator can be provided with the appropriate economic incentives so that it acquiesces in serving the virtual operator's user base (monopolistic model) and in allowing the virtual operator to provide service over the network operator's infrastructure (strategic model). From the point of view of the users, the strategic model results in a higher subscription rate than the monopolistic model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15103v1</guid>
      <category>cs.NI</category>
      <category>econ.TH</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.future.2020.03.044</arxiv:DOI>
      <dc:creator>Erwin J. Sacoto-Cabrera, Luis Guijarro, Jose R. Vidal, Vicent Pla</dc:creator>
    </item>
    <item>
      <title>VCSEL-based CPO for Scale-Up in A.I. Datacenter. Status and Perspectives</title>
      <link>https://arxiv.org/abs/2601.14342</link>
      <description>arXiv:2601.14342v1 Announce Type: cross 
Abstract: The drastic increase of bandwidth demands in AI datacenters requires new solutions with low power consumption and high bandwidth densities. Further increasing the total bandwidth with copper interconnects is challenging, thus it is crucial to introduce optics into the scale-up network. For this purpose, the most important metrics are the energy efficiency of the total link in addition to the spatial bandwidth-density and reach. With the inefficiency of copper traces at high speeds, transitioning to co-packaged optics is no longer optional but essential. Here, we show that the mature VCSEL technology offers the ideal combination of low-cost, low-latency, high-reliability, and energy efficiency at all bitrates, thanks to their unique versatility and high wall-plug-efficiency. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14342v1</guid>
      <category>physics.optics</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Kohli, Jean Teissier</dc:creator>
    </item>
    <item>
      <title>European digital identity: A missed opportunity?</title>
      <link>https://arxiv.org/abs/2601.14503</link>
      <description>arXiv:2601.14503v1 Announce Type: cross 
Abstract: Recent European efforts around digital identity -- the EUDI regulation and its OpenID architecture -- aim high, but start from a narrow and ill-defined conceptualization of authentication. Based on a broader, more grounded understanding of the term, in we identify several issues in the design of OpenID4VCI and OpenID4VP: insecure practices, static, and subject-bound credential types, and a limited query language restrict their application to classic scenarios of credential exchange -- already supported by existing solutions like OpenID Connect, SIOPv2, OIDC4IDA, and OIDC Claims Aggregation -- barring dynamic, asynchronous, or automated use cases. We also debunk OpenID's 'paradigm-shifting' trust-model, which -- when compared to existing decentralized alternatives -- does not deliver any significant increase in control, privacy, and portability of personal information. Not only the technical choices limit the capabilities of the EUDI framework; also the legislation itself cannot accommodate the promise of self-sovereign identity. In particular, we criticize the introduction of institutionalized trusted lists, and discuss their economical and political risks. Their potential to decline into an exclusory, re-centralized ecosystem endangers the vision of a user-oriented identity management in which individuals are in charge. Instead, the consequences might severely restrict people in what they can do with their personal information, and risk increased linkability and monitoring. In anticipation of revisions to the EUDI regulations, we suggest several technical alternatives that overcome some of the issues with the architecture of OpenID. In particular, OAuth's UMA extension and its A4DS profile, as well as their integration in GNAP, are worth looking into. Future research into uniform query (meta-)languages is needed to address the heterogeneity of attestations and providers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14503v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Termont (IDLab), Beatriz Esteves (IDLab)</dc:creator>
    </item>
    <item>
      <title>Holmes: An Evidence-Grounded LLM Agent for Auditable DDoS Investigation in Cloud Networks</title>
      <link>https://arxiv.org/abs/2601.14601</link>
      <description>arXiv:2601.14601v1 Announce Type: cross 
Abstract: Cloud environments face frequent DDoS threats due to centralized resources and broad attack surfaces. Modern cloud-native DDoS attacks further evolve rapidly and often blend multi-vector strategies, creating an operational dilemma: defenders need wire-speed monitoring while also requiring explainable, auditable attribution for response. Existing rule-based and supervised-learning approaches typically output black-box scores or labels, provide limited evidence chains, and generalize poorly to unseen attack variants; meanwhile, high-quality labeled data is often difficult to obtain in cloud settings.
  We present Holmes (DDoS Detective), an LLM-based DDoS detection agent that reframes the model as a virtual SRE investigator rather than an end-to-end classifier. Holmes couples a funnel-like hierarchical workflow (counters/sFlow for continuous sensing and triage; PCAP evidence collection triggered only on anomaly windows) with an Evidence Pack abstraction that converts binary packets into compact, reproducible, high-signal structured evidence. On top of this evidence interface, Holmes enforces a structure-first investigation protocol and strict JSON/quotation constraints to produce machine-consumable reports with auditable evidence anchors.
  We evaluate Holmes on CICDDoS2019 reflection/amplification attacks and script-triggered flooding scenarios. Results show that Holmes produces attribution decisions grounded in salient evidence anchors across diverse attack families, and when errors occur, its audit logs make the failure source easy to localize, demonstrating the practicality of an LLM agent for cost-controlled and traceable DDoS investigation in cloud operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14601v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haodong Chen, Ziheng Zhang, Jinghui Jiang, Qiang Su, Qiao Xiang</dc:creator>
    </item>
    <item>
      <title>Exploiting Spot Instances for Time-Critical Cloud Workloads Using Optimal Randomized Strategies</title>
      <link>https://arxiv.org/abs/2601.14612</link>
      <description>arXiv:2601.14612v1 Announce Type: cross 
Abstract: This paper addresses the challenge of deadline-aware online scheduling for jobs in hybrid cloud environments, where jobs may run on either cost-effective but unreliable spot instances or more expensive on-demand instances, under hard deadlines. We first establish a fundamental limit for existing (predominantly-) deterministic policies, proving a worst-case competitive ratio of $\Omega(K)$, where $K$ is the cost ratio between on-demand and spot instances. We then present a novel randomized scheduling algorithm, ROSS, that achieves a provably optimal competitive ratio of $\sqrt{K}$ under reasonable deadlines, significantly improving upon existing approaches. Extensive evaluations on real-world trace data from Azure and AWS demonstrate that ROSS effectively balances cost optimization and deadline guarantees, consistently outperforming the state-of-the-art by up to $30\%$ in cost savings, across diverse spot market conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14612v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neelkamal Bhuyan, Randeep Bhatia, Murali Kodialam, TV Lakshman</dc:creator>
    </item>
    <item>
      <title>Competition between service providers with strategic resource allocation: application to network slicing</title>
      <link>https://arxiv.org/abs/1912.04764</link>
      <description>arXiv:1912.04764v2 Announce Type: replace 
Abstract: We propose and analyze a business model for 5G operators. Each operator is entitled to a share of a network operated by an Infrastructure Provider (InP) and use network slicing mechanisms to request network resources as needed for service provision. The network operators become Network Slice Tenants (NSTs). The InP performs the resource allocation based on a vector of weights chosen strategically by each NST. The weights distribute the NST's share of resources between its subscribers in each cell. We propose a strategy profile in which the NST chooses weights equal to the product of its share by the ratio between the total number of subscribers in the cell and the total number of subscribers in the network. We characterize the proposed solution in terms of subscription ratios and fractions of subscribers, for different cell capacities and user sensitivities. The proposed solution provides the exact values for the Nash equilibrium if the cells are homogeneous in terms of normalized capacity, which is a measure of the total amount of resources available in the cell. Otherwise, if the cells are heterogeneous, it provides an accurate approximation. We quantify the deviation from the equilibrium and conclude that it is highly accurate.</description>
      <guid isPermaLink="false">oai:arXiv.org:1912.04764v2</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2021.3078562</arxiv:DOI>
      <dc:creator>Luis Guijarro, Jose R. Vidal, Vicent Pla</dc:creator>
    </item>
    <item>
      <title>NetSSM: Multi-Flow and State-Aware Network Trace Generation using State Space Models</title>
      <link>https://arxiv.org/abs/2503.22663</link>
      <description>arXiv:2503.22663v3 Announce Type: replace 
Abstract: Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22663v3</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3786289</arxiv:DOI>
      <dc:creator>Andrew Chu, Xi Jiang, Shinan Liu, Arjun Bhagoji, Francesco Bronzino, Paul Schmitt, Nick Feamster</dc:creator>
    </item>
    <item>
      <title>Digital Twin-Empowered Deep Reinforcement Learning for Intelligent VNF Migration in Edge-Core Networks</title>
      <link>https://arxiv.org/abs/2508.20957</link>
      <description>arXiv:2508.20957v2 Announce Type: replace 
Abstract: The growing demand for services and the rapid deployment of virtualized network functions (VNFs) pose significant challenges for achieving low-latency and energy-efficient orchestration in modern edge-core network infrastructures. To address these challenges, this study proposes a Digital Twin (DT)-empowered Deep Reinforcement Learning framework for intelligent VNF migration that jointly minimizes average end-to-end (E2E) delay and energy consumption. By formulating the VNF migration problem as a Markov Decision Process and utilizing the Advantage Actor-Critic model, the proposed framework enables adaptive and real-time migration decisions. A key innovation of the proposed framework is the integration of a DT module composed of a multi-task Variational Autoencoder and a multi-task Long Short-Term Memory network. This combination collectively simulates environment dynamics and generates high-quality synthetic experiences, significantly enhancing training efficiency and accelerating policy convergence. Simulation results demonstrate substantial performance gains, such as significant reductions in both average E2E delay and energy consumption, thereby establishing new benchmarks for intelligent VNF migration in edge-core networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20957v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Faisal Ahmed, Suresh Subramaniam, Motoharu Matsuura, Hiroshi Hasegawa, Shih-Chun Lin</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Simulated and Real Network Data Using Transfer Learning</title>
      <link>https://arxiv.org/abs/2510.00956</link>
      <description>arXiv:2510.00956v2 Announce Type: replace 
Abstract: Machine Learning (ML)-based network models provide fast and accurate predictions for complex network behaviors but require substantial training data. Collecting such data from real networks is often costly and limited, especially for critical scenarios like failures. As a result, researchers commonly rely on simulated data, which reduces accuracy when models are deployed in real environments. We propose a hybrid approach leveraging transfer learning to combine simulated and real-world data. Using RouteNet-Fermi, we show that fine-tuning a pre-trained model with a small real dataset significantly improves performance. Our experiments with OMNeT++ and a custom testbed reduce the Mean Absolute Percentage Error (MAPE) in packet delay prediction by up to 88%. With just 10 real scenarios, MAPE drops by 37%, and with 50 scenarios, by 48%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00956v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos G\"uemes-Palau, Miquel Ferriol-Galm\'es, Jordi Paillisse-Vilanova, Albert L\'opez-Bresc\'o, Pere Barlet-Ros, Albert Cabellos-Aparicio</dc:creator>
    </item>
    <item>
      <title>A Layered Protocol Architecture for the Internet of Agents</title>
      <link>https://arxiv.org/abs/2511.19699</link>
      <description>arXiv:2511.19699v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated remarkable performance improvements and the ability to learn domain-specific languages (DSLs), including APIs and tool interfaces. This capability has enabled the creation of AI agents that can perform preliminary computations and act through tool calling, which is now being standardized via protocols like MCP. However, LLMs face fundamental limitations: their context windows cannot grow indefinitely, restricting their memory and computational capacity. Agent collaboration emerges as essential for solving increasingly complex problems, mirroring how computational systems rely on different types of memory to scale. The "Internet of Agents" (IoA) represents the communication stack that enables agents to scale by distributing computation across collaborating entities.
  Current network architectural stacks (OSI and TCP/IP) were designed for data delivery between hosts and processes, not for agent collaboration with semantic understanding. To address this gap, we propose two new layers: an Agent Communication Layer (L8) and an Agent Semantic Layer (L9). L8 formalizes the structure of communication, standardizing message envelopes, speech-act performatives (e.g., REQUEST, INFORM), and interaction patterns (e.g., request-reply, publish-subscribe), building on protocols like MCP. The proposed L9 layer: (1) formalizes semantic context discovery and negotiation, (2) provides semantic grounding by binding terms to semantic context, and (3) semantically validates incoming prompts and performs disambiguation as needed. Furthermore, L9 introduces primitives for coordination and consensus, allowing agents to achieve alignment on shared states, collective goals, and distributed beliefs. Together, these layers provide the foundation for scalable, distributed agent collaboration, enabling the next generation of multi-agentic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19699v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Fleming, Luca Muscariello, Vijoy Pandey, Ramana Kompella</dc:creator>
    </item>
    <item>
      <title>Multi-Server FL with Overlapping Clients: A Latency-Aware Relay Framework</title>
      <link>https://arxiv.org/abs/2512.00025</link>
      <description>arXiv:2512.00025v2 Announce Type: replace 
Abstract: Multi-server Federated Learning (FL) has emerged as a promising solution to mitigate communication bottlenecks of single-server FL. In a typical multi-server FL architecture, the regions covered by different edge servers (ESs) may overlap. Under this architecture, clients located in the overlapping areas can access edge models from multiple ESs. Building on this observation, we propose a cloud-free multi-server FL framework that leverages Overlapping Clients (OCs) as relays for inter-server model exchange while uploading the local updated model to ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs without introducing new communication links. We derive a new convergence upper bound for non-convex objectives under non-IID data and an arbitrary number of cells, which explicitly quantifies the impact of inter-server propagation depth on convergence error. Guided by this theoretical result, we formulate an optimization problem that aims to maximize dissemination range of each ES model among all ESs within a limited latency. To solve this problem, we develop a conflict-graph-based local search algorithm optimizing the routing strategy and scheduling the transmission times of individual ESs to its neighboring ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs, achieving the widest possible transmission coverage for each model without introducing new communication links. Extensive experimental results show remarkable performance gains of our scheme compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00025v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun Ji, Zeyu Chen, Xiaoxiong Zhong, Yanan Ma, Sheng Zhang, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>Point Cloud Streaming with Latency-Driven Implicit Adaptation using MoQ</title>
      <link>https://arxiv.org/abs/2507.15673</link>
      <description>arXiv:2507.15673v2 Announce Type: replace-cross 
Abstract: Point clouds are a promising video representation for virtual and augmented reality. Their high-bitrate, however, has so far limited the practicality of live streaming systems. In this work, we leverage the delivery timeout feature within the Media Over QUIC protocol to perform implicit server-side adaptation based on an application's latency target. Through experimentation with several publisher and network configurations, we demonstrate that our system unlocks a unique trade-off on a per-client basis: applications with lower latency requirements will receive lower-quality video, while applications with more relaxed latency requirements will receive higher-quality video.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15673v2</guid>
      <category>cs.MM</category>
      <category>cs.NI</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Freeman, Michael Rudolph, Amr Rizk</dc:creator>
    </item>
    <item>
      <title>Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning</title>
      <link>https://arxiv.org/abs/2509.10132</link>
      <description>arXiv:2509.10132v2 Announce Type: replace-cross 
Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with decentralized training, enabling the development of personalized and reliable models under data heterogeneity and privacy constraints. Existing approaches typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational inference, often incorporating personalization mechanisms to better adapt to local data distributions. In this work, we propose an information-geometric projection framework for personalization in parametric BFL. By projecting the global model onto a neighborhood of the user's local model, our method enables a tunable trade-off between global generalization and local specialization. Under mild assumptions, we show that this projection step is equivalent to computing a barycenter on the statistical manifold, allowing us to derive closed-form solutions and achieve cost-free personalization. We apply the proposed approach to a variational learning setup using the Improved Variational Online Newton (IVON) optimizer and extend its application to general aggregation schemes in BFL. Empirical evaluations under heterogeneous data distributions confirm that our method effectively balances global and local performance with minimal computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10132v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (TMLR), 2026</arxiv:journal_reference>
      <dc:creator>Nour Jamoussi, Giuseppe Serra, Photios A. Stavrou, Marios Kountouris</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Quantum Semantic Communication via Sheaf Cohomology</title>
      <link>https://arxiv.org/abs/2601.10958</link>
      <description>arXiv:2601.10958v2 Announce Type: replace-cross 
Abstract: Semantic communication (SC) enables bandwidth-efficient coordination in multi-agent systems by transmitting meaning rather than raw bits. However, when agents employ heterogeneous sensing modalities and AI architectures, perfect bit-level transmission no longer guarantees mutual understanding. Although deep learning methods for semantic compression have advanced, the information-theoretic limits of semantic alignment under heterogeneity remain poorly understood. Notably, semantic ambiguity shares the same mathematical structure as quantum contextuality, as both arise from cohomological obstructions, motivating a quantum formulation of SC. In this paper, an information-theoretic framework for quantum semantic communication is proposed using sheaf cohomology. Multi-agent semantic networks are modeled as quantum sheaves, where agents meaning spaces are Hilbert spaces connected by quantum channels. The first sheaf cohomology group is shown to characterize irreducible semantic ambiguity, representing a fundamental obstruction to alignment that no local processing can resolve. The minimum communication rate required for semantic alignment is proven to scale with the logarithm of the dimension of the cohomological space, establishing a semantic analog of Shannon limits. For entanglement-assisted channels, the achievable capacity is shown to strictly exceed classical bounds, with each shared ebit reducing the required classical communication by one bit, providing a rigorous interpretation of shared context. Additionally, quantum contextuality is shown to reduce cohomological obstructions, and a duality between quantum discord and integrated semantic information is established, linking quantum correlations to irreducible semantic content. This framework provides rigorous foundations for quantum-enhanced semantic communication in autonomous multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10958v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christo Kurisummoottil Thomas, Mingzhe Chen</dc:creator>
    </item>
    <item>
      <title>AFLL: Real-time Load Stabilization for MMO Game Servers Based on Circular Causality Learning</title>
      <link>https://arxiv.org/abs/2601.10998</link>
      <description>arXiv:2601.10998v2 Announce Type: replace-cross 
Abstract: Massively Multiplayer Online (MMO) game servers must handle thousands of simultaneous players while maintaining sub-100ms response times. When server load exceeds capacity, traditional approaches either uniformly throttle all message types regardless of importance (damaging gameplay) or apply fixed heuristic rules that fail to adapt to dynamic workloads. This paper presents AFLL (Adaptive Feedback Loop Learning), a real-time load stabilization system that learns the causal relationship between outgoing server messages and subsequent incoming client requests. AFLL employs backpropagation to continuously adjust message type weights, enabling predictive throttling that blocks low-priority messages before overload occurs while guaranteeing critical message delivery. Through controlled experiments with 1,000 concurrent players, AFLL reduced average CPU time by 48.3% (13.2ms to 6.8ms), peak CPU time by 51.7% (54.0ms to 26.1ms), and thread contention by 64.4% (19.6% to 7.0%), while maintaining zero learning overhead through background computation and caching optimizations. The system achieved remarkable reproducibility (CV &lt; 2% across all metrics) and identified a three-stage causal chain linking message blocking to load reduction. AFLL demonstrates that circular causality learning enables practical real-time adaptation for latency-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10998v2</guid>
      <category>cs.DC</category>
      <category>cs.MM</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shinsuk Kang, Youngjae Kim</dc:creator>
    </item>
  </channel>
</rss>
