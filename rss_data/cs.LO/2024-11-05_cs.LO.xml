<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 05:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reachability and Safety Games under TSO Semantics</title>
      <link>https://arxiv.org/abs/2411.00847</link>
      <description>arXiv:2411.00847v1 Announce Type: new 
Abstract: We consider games played on the transition graph of concurrent programs running under the Total Store Order (TSO) weak memory model. Games are frequently used to model the interaction between a system and its environment, in this case between the concurrent processes and the nondeterministic TSO buffer updates. In our formulation, the game is played by two players, who alternatingly make a move: The process player can execute any enabled instruction of the processes, while the update player takes  care of updating the messages in the buffers that are between each process and the shared memory. We show that the reachability and safety problem of this game reduce to the analysis of single-process (non-concurrent) programs. In particular, they exhibit only finite-state behaviour. Because of this, we introduce different notions of fairness, which force the two players to behave in a more realistic way. Both the reachability and safety problem then become undecidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00847v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.409.14</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 409, 2024, pp. 154-171</arxiv:journal_reference>
      <dc:creator>Stephan Spengler</dc:creator>
    </item>
    <item>
      <title>Learning Rules Explaining Interactive Theorem Proving Tactic Prediction</title>
      <link>https://arxiv.org/abs/2411.01188</link>
      <description>arXiv:2411.01188v1 Announce Type: new 
Abstract: Formally verifying the correctness of mathematical proofs is more accessible than ever, however, the learning curve remains steep for many of the state-of-the-art interactive theorem provers (ITP). Deriving the most appropriate subsequent proof step, and reasoning about it, given the multitude of possibilities, remains a daunting task for novice users. To improve the situation, several investigations have developed machine learning based guidance for tactic selection. Such approaches struggle to learn non-trivial relationships between the chosen tactic and the structure of the proof state and represent them as symbolic expressions. To address these issues we (i) We represent the problem as an Inductive Logic Programming (ILP) task, (ii) Using the ILP representation we enriched the feature space by encoding additional, computationally expensive properties as background knowledge predicates, (iii) We use this enriched feature space to learn rules explaining when a tactic is applicable to a given proof state, (iv) we use the learned rules to filter the output of an existing tactic selection approach and empirically show improvement over the non-filtering approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01188v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liao Zhang, David M. Cerna, Cezary Kaliszyk</dc:creator>
    </item>
    <item>
      <title>Thoughts on sub-Turing interactive computability</title>
      <link>https://arxiv.org/abs/2411.01393</link>
      <description>arXiv:2411.01393v1 Announce Type: new 
Abstract: The article contains an outline of a possible new direction for Computability Logic (see www.csc.villanova.edu/~japaridz/CL/ ), focused on computability without infinite memory or other impossible-to-possess computational resources. The new approach would see such resources as external rather than internal to computing devices. They could or should be accounted for explicitly in the antecedents of logical formulas expressing computational problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01393v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giorgi Japaridze</dc:creator>
    </item>
    <item>
      <title>On SMT Theory Design: The Case of Sequences</title>
      <link>https://arxiv.org/abs/2411.01961</link>
      <description>arXiv:2411.01961v1 Announce Type: new 
Abstract: Choices in the semantics and the signature of a theory are integral in determining how the theory is used and how challenging it is to reason over it. Our interest in this paper lies in the SMT theory of sequences. Various versions of it exist in the literature and in state-of-the-art SMT solvers, but it has not yet been standardized in the SMT-LIB. We reflect on its existing variants, and we define a set of theory design criteria to help determine what makes one variant of a theory better than another. The criteria we define can be used to appraise theory proposals for other theories as well. Based on these criteria, we propose a series of changes to the SMT theory of sequences as a contribution to the discussion regarding its standardization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01961v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.29007/75tl</arxiv:DOI>
      <arxiv:journal_reference>LPAR 2024 Complementary Volume, May 2024, Mauritius, France. pp.14-29</arxiv:journal_reference>
      <dc:creator>Hichem Rami Ait El Hara, Fran\c{c}ois Bobot, Guillaume Bury</dc:creator>
    </item>
    <item>
      <title>Guiding Multi-agent Multi-task Reinforcement Learning by a Hierarchical Framework with Logical Reward Shaping</title>
      <link>https://arxiv.org/abs/2411.01184</link>
      <description>arXiv:2411.01184v1 Announce Type: cross 
Abstract: Multi-agent hierarchical reinforcement learning (MAHRL) has been studied as an effective means to solve intelligent decision problems in complex and large-scale environments. However, most current MAHRL algorithms follow the traditional way of using reward functions in reinforcement learning, which limits their use to a single task. This study aims to design a multi-agent cooperative algorithm with logic reward shaping (LRS), which uses a more flexible way of setting the rewards, allowing for the effective completion of multi-tasks. LRS uses Linear Temporal Logic (LTL) to express the internal logic relation of subtasks within a complex task. Then, it evaluates whether the subformulae of the LTL expressions are satisfied based on a designed reward structure. This helps agents to learn to effectively complete tasks by adhering to the LTL expressions, thus enhancing the interpretability and credibility of their decisions. To enhance coordination and cooperation among multiple agents, a value iteration technique is designed to evaluate the actions taken by each agent. Based on this evaluation, a reward function is shaped for coordination, which enables each agent to evaluate its status and complete the remaining subtasks through experiential learning. Experiments have been conducted on various types of tasks in the Minecraft-like environment. The results demonstrate that the proposed algorithm can improve the performance of multi-agents when learning to complete multi-tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01184v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chanjuan Liu, Jinmiao Cong, Bingcai Chen, Yaochu Jin, Enqiang Zhu</dc:creator>
    </item>
    <item>
      <title>Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast</title>
      <link>https://arxiv.org/abs/2411.02318</link>
      <description>arXiv:2411.02318v1 Announce Type: cross 
Abstract: Static verification is a powerful method for enhancing software quality, but it demands significant human labor and resources. This is particularly true of static verifiers that reason about heap manipulating programs using an ownership logic. LLMs have shown promise in a number of software engineering activities, including code generation, test generation, proof generation for theorem provers, and specification generation for static verifiers. However, prior work has not explored how well LLMs can perform specification generation for specifications based in an ownership logic, such as separation logic.
  To address this gap, this paper explores the effectiveness of large language models (LLMs), specifically OpenAI's GPT models, in generating fully correct specifications based on separation logic for static verification of human-written programs in VeriFast. Our first experiment employed traditional prompt engineering and the second used Chain-of-Thought (CoT) Prompting to identify and address common errors generated across the GPT models. The results indicate that GPT models can successfully generate specifications for verifying heap manipulating code with VeriFast. Furthermore, while CoT prompting significantly reduces syntax errors generated by the GPT models, it does not greatly improve verification error rates compared to prompt engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02318v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marilyn Rego, Wen Fan, Xin Hu, Sanya Dod, Zhaorui Ni, Danning Xie, Jenna DiVincenzo, Lin Tan</dc:creator>
    </item>
    <item>
      <title>Peano Arithmetic and $\mu$MALL</title>
      <link>https://arxiv.org/abs/2312.13634</link>
      <description>arXiv:2312.13634v2 Announce Type: replace 
Abstract: Formal theories of arithmetic have traditionally been based on either classical or intuitionistic logic, leading to the development of Peano and Heyting arithmetic, respectively. We propose to use $\mu$MALL as a formal theory of arithmetic based on linear logic. This formal system is presented as a sequent calculus proof system that extends the standard proof system for multiplicative-additive linear logic (MALL) with the addition of the logical connectives universal and existential quantifiers (first-order quantifiers), term equality and non-equality, and the least and greatest fixed point operators. We first demonstrate how functions defined using $\mu$MALL relational specifications can be computed using a simple proof search algorithm. By incorporating weakening and contraction into $\mu$MALL, we obtain $\mu$LK+, a natural candidate for a classical sequent calculus for arithmetic. While important proof theory results are still lacking for $\mu$LK+ (including cut-elimination and the completeness of focusing), we prove that $\mu$LK+ is consistent and that it contains Peano arithmetic. We also prove some conservativity results regarding $\mu$LK+ over $\mu$MALL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13634v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Manighetti, Dale Miller</dc:creator>
    </item>
    <item>
      <title>A Unifying Approach to Product Constructions for Quantitative Temporal Inference</title>
      <link>https://arxiv.org/abs/2407.10465</link>
      <description>arXiv:2407.10465v2 Announce Type: replace 
Abstract: Probabilistic programs are a powerful and convenient approach to formalise distributions over system executions. A classical verification problem for probabilistic programs is temporal inference: to compute the likelihood that the execution traces satisfy a given temporal property. This paper presents a general framework for temporal inference, which applies to a rich variety of quantitative models including those that arise in the operational semantics of probabilistic and weighted programs.
  The key idea underlying our framework is that in a variety of existing approaches, the main construction that enables temporal inference is that of a product between the system of interest and the temporal property. We provide a unifying mathematical definition of product constructions, enabled by the realisation that 1) both systems and temporal properties can be modelled as coalgebras and 2) product constructions are distributive laws in this context. Our categorical framework leads us to our main contribution: a sufficient condition for correctness, which is precisely what enables to use the product construction for temporal inference.
  We show that our framework can be instantiated to naturally recover a number of disparate approaches from the literature including, e.g., partial expected rewards in Markov reward models, resource-sensitive reachability analysis, and weighted optimization problems. Further, we demonstrate a product of weighted programs and weighted temporal properties as a new instance to show the scalability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10465v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuki Watanabe, Sebastian Junges, Jurriaan Rot, Ichiro Hasuo</dc:creator>
    </item>
    <item>
      <title>CaTT contexts are finite computads</title>
      <link>https://arxiv.org/abs/2405.00398</link>
      <description>arXiv:2405.00398v2 Announce Type: replace-cross 
Abstract: Two novel descriptions of weak {\omega}-categories have been recently proposed, using type-theoretic ideas. The first one is the dependent type theory CaTT whose models are {\omega}-categories. The second is a recursive description of a category of computads together with an adjunction to globular sets, such that the algebras for the induced monad are again {\omega}-categories. We compare the two descriptions by showing that there exits a fully faithful morphism of categories with families from the syntactic category of CaTT to the opposite of the category of computads, which gives an equivalence on the subcategory of finite computads. We derive a more direct connection between the category of models of CaTT and the category of algebras for the monad on globular sets, induced by the adjunction with computads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00398v2</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thibaut Benjamin, Ioannis Markakis, Chiara Sarti</dc:creator>
    </item>
    <item>
      <title>Constructibility, computational complexity and P versus NP</title>
      <link>https://arxiv.org/abs/2406.16843</link>
      <description>arXiv:2406.16843v2 Announce Type: replace-cross 
Abstract: If an algorithm is to be counted as a practically working solution to a decision problem, then the algorithm must must verifiable in some constructed and ``trusted'' theory such as PA or ZF. In this paper, a class of decision problems related to inconsistency proofs for a general class of formal theories is used to demonstrate that under this constructibility restriction, there are plausible arguments for the existence of decision problems which can be proved formally to be in NP, and for which there exists an explicitly constructible algorithm recognizing correct solutions in polynomial time, but for which there exists no explicitly constructible, verifiable solution algorithm. While these arguments do not solve the P versus NP problem in the classical sense of supplying a proof one way or the other in a ``trusted'' formal theory, arguably they resolve a constructive version of it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16843v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arne Hole</dc:creator>
    </item>
    <item>
      <title>PutnamBench: Evaluating Neural Theorem-Provers on the Putnam Mathematical Competition</title>
      <link>https://arxiv.org/abs/2407.11214</link>
      <description>arXiv:2407.11214v2 Announce Type: replace-cross 
Abstract: We present PutnamBench, a new multi-language benchmark for evaluating the ability of neural theorem-provers to solve competition mathematics problems. PutnamBench consists of 1692 hand-constructed formalizations of 640 theorems sourced from the William Lowell Putnam Mathematical Competition, the premier undergraduate-level mathematics competition in North America. All the problems have formalizations in Lean 4 and Isabelle; a substantial subset also has Coq formalizations. PutnamBench requires significant problem-solving ability and proficiency in a broad range of topics taught in undergraduate mathematics courses. We use PutnamBench to evaluate several established neural and symbolic theorem-provers. These approaches can only solve a handful of the PutnamBench problems, establishing the benchmark as a difficult open challenge for research on neural theorem-proving. PutnamBench is available at https://github.com/trishullab/PutnamBench.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11214v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, Swarat Chaudhuri</dc:creator>
    </item>
    <item>
      <title>Hypergraph rewriting and Causal structure of $\lambda-$calculus</title>
      <link>https://arxiv.org/abs/2409.01006</link>
      <description>arXiv:2409.01006v2 Announce Type: replace-cross 
Abstract: In this paper, we first study hypergraph rewriting in categorical terms in an attempt to define the notion of events and develop foundations of causality in graph rewriting. We introduce novel concepts within the framework of double-pushout rewriting in adhesive categories. Secondly, we will study the notion of events in $\lambda-$calculus, wherein we construct an algorithm to determine causal relations between events following the evaluation of a $\lambda-$expression satisfying certain conditions. Lastly, we attempt to extend this definition to arbitrary $\lambda-$expressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01006v2</guid>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Utkarsh Bajaj</dc:creator>
    </item>
  </channel>
</rss>
