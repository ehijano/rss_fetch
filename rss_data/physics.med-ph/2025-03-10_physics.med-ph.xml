<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Mar 2025 04:05:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Semi-Supervised Learning for Dose Prediction in Targeted Radionuclide: A Synthetic Data Study</title>
      <link>https://arxiv.org/abs/2503.05367</link>
      <description>arXiv:2503.05367v1 Announce Type: new 
Abstract: Targeted Radionuclide Therapy (TRT) is a modern strategy in radiation oncology that aims to administer a potent radiation dose specifically to cancer cells using cancer-targeting radiopharmaceuticals. Accurate radiation dose estimation tailored to individual patients is crucial. Deep learning, particularly with pre-therapy imaging, holds promise for personalizing TRT doses. However, current methods require large time series of SPECT imaging, which is hardly achievable in routine clinical practice, and thus raises issues of data availability. Our objective is to develop a semi-supervised learning (SSL) solution to personalize dosimetry using pre-therapy images. The aim is to develop an approach that achieves accurate results when PET/CT images are available, but are associated with only a few post-therapy dosimetry data provided by SPECT images. In this work, we introduce an SSL method using a pseudo-label generation approach for regression tasks inspired by the FixMatch framework. The feasibility of the proposed solution was preliminarily evaluated through an in-silico study using synthetic data and Monte Carlo simulation. Experimental results for organ dose prediction yielded promising outcomes, showing that the use of pseudo-labeled data provides better accuracy compared to using only labeled data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05367v1</guid>
      <category>physics.med-ph</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Zhang, Alexandre Bousse, Laetitia Imbert, Song Xue, Kuangyu Shi, Julien Bert</dc:creator>
    </item>
    <item>
      <title>A-SEE2.0: Active-Sensing End-Effector for Robotic Ultrasound Systems with Dense Contact Surface Perception Enabled Probe Orientation Adjustment</title>
      <link>https://arxiv.org/abs/2503.05569</link>
      <description>arXiv:2503.05569v1 Announce Type: cross 
Abstract: Conventional freehand ultrasound (US) imaging is highly dependent on the skill of the operator, often leading to inconsistent results and increased physical demand on sonographers. Robotic Ultrasound Systems (RUSS) aim to address these limitations by providing standardized and automated imaging solutions, especially in environments with limited access to skilled operators. This paper presents the development of a novel RUSS system that employs dual RGB-D depth cameras to maintain the US probe normal to the skin surface, a critical factor for optimal image quality. Our RUSS integrates RGB-D camera data with robotic control algorithms to maintain orthogonal probe alignment on uneven surfaces without preoperative data. Validation tests using a phantom model demonstrate that the system achieves robust normal positioning accuracy while delivering ultrasound images comparable to those obtained through manual scanning. A-SEE2.0 demonstrates 2.47 ${\pm}$ 1.25 degrees error for flat surface normal-positioning and 12.19 ${\pm}$ 5.81 degrees normal estimation error on mannequin surface. This work highlights the potential of A-SEE2.0 to be used in clinical practice by testing its performance during in-vivo forearm ultrasound examinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05569v1</guid>
      <category>cs.RO</category>
      <category>physics.med-ph</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yernar Zhetpissov, Xihan Ma, Kehan Yang, Haichong K. Zhang</dc:creator>
    </item>
    <item>
      <title>Compact Accelerator-Based Production of Carrier-free $^{177}$Lu From 18 MeV $D^+$ on [$^{176}$Yb]Yb$_2$O$_3$</title>
      <link>https://arxiv.org/abs/2503.05608</link>
      <description>arXiv:2503.05608v1 Announce Type: cross 
Abstract: We use experimental and simulated excitation functions to estimate the yield of deuteron activations on a [$^{176}$Yb]Yb$_2$O$_3$ target enriched to 99%. Subsequent calculations are used to determine the production of radiotherapeutic $^{177}$Lu according to a 10 mA, 18 MeV $D^+$ compact linear accelerator. The design comprises a single radio-frequency quadrupole accelerator (RFQ) and seven drift tube linacs (DTLs) that achieve a beam efficiency of 99.5% over a length of $12\,\text{m}$. Our results show that a 5-day irradiation can yield more than $1$ mg of $^{177}$Lu, exceeding $4.4$ TBq. After a 2 day processing period, it is estimated that the sample will have a radiopurity greater than 99.8% (carrier-free). Given recent EMA and FDA approvals of $^{177}$Lu-DOTATATE and $^{177}$Lu-PSMA-617, our results confirm the viability of accelerator-based $^{177}$Lu production and provide a promising clinical alternative to reactor-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05608v1</guid>
      <category>physics.acc-ph</category>
      <category>physics.med-ph</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin A. Morris, Tianhao Wei, Zhi Wang, Ying Xia, Meiyun Han, Yuanrong Lu</dc:creator>
    </item>
    <item>
      <title>Redefining spectral unmixing for in-vivo brain tissue analysis from hyperspectral imaging</title>
      <link>https://arxiv.org/abs/2503.00198</link>
      <description>arXiv:2503.00198v2 Announce Type: replace 
Abstract: In this paper, we propose a methodology for extracting molecular tumor biomarkers from hyperspectral imaging (HSI), an emerging technology for intraoperative tissue assessment. To achieve this, we employ spectral unmixing, allowing to decompose the spectral signals recorded by the HSI camera into their constituent molecular components. Traditional unmixing approaches are based on physical models that establish a relationship between tissue molecules and the recorded spectra. However, these methods commonly assume a linear relationship between the spectra and molecular content, which does not capture the whole complexity of light-matter interaction. To address this limitation, we introduce a novel unmixing procedure that allows to take into account non-linear optical effects while preserving the computational benefits of linear spectral unmixing. We validate our methodology on an in-vivo brain tissue HSI dataset and demonstrate that the extracted molecular information leads to superior classification performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00198v2</guid>
      <category>physics.med-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hartenberger, Huzeyfe Ayaz, Fatih Ozlugedik, Charly Caredda, Luca Giannoni, Fr\'ed\'eric Lange, Laurin Lux, Jonas Weidner, Alex Berger, Florian Kofler, Martin Menten, Bruno Montcel, Ilias Tachtsidis, Daniel Rueckert, Ivan Ezhov</dc:creator>
    </item>
  </channel>
</rss>
