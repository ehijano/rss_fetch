<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Feb 2025 02:54:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Trust-Aware and Cost-Optimized Blockchain Oracle Selection Model with Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.16133</link>
      <description>arXiv:2502.16133v1 Announce Type: new 
Abstract: The rapid development of blockchain technology has driven the widespread application of decentralized applications (DApps) across various fields. However, DApps cannot directly access external data and rely on oracles to interact with off-chain data. As a bridge between blockchain and external data sources, oracles pose potential risks of malicious behavior, which may inject incorrect or harmful data, leading to trust and security issues. Additionally, with the surge in data requests, the disparity in oracle trustworthiness and costs has increased, making the dynamic selection of the most suitable oracle for each request a critical challenge. To address these issues, this paper proposes a Trust-Aware and Cost-Optimized Blockchain Oracle Selection Model with Deep Reinforcement Learning (TCO-DRL). The model incorporates a comprehensive trust management mechanism to evaluate oracle reputation from multiple dimensions and employs an improved sliding time window to monitor reputation changes in real time, enhancing resistance to malicious attacks. Moreover, TCO-DRL uses deep reinforcement learning algorithms to dynamically adapt to fluctuations in oracle reputation, ensuring the selection of high-reputation oracles while optimizing node selection, thereby reducing costs without compromising data quality. We implemented and validated TCO- DRL on Ethereum. Experimental results show that, compared to existing methods, TCO-DRL reduces the allocation rate to malicious oracles by more than 39.10% and saves over 12.00% in costs. Furthermore, simulated experiments on various malicious attacks further validate the robustness and effectiveness of TCO-DRL</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16133v1</guid>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengyang Zhang, Shike Li, Hang Bao, Sixing Wu, Jianbin Li</dc:creator>
    </item>
    <item>
      <title>ZiGong 1.0: A Large Language Model for Financial Credit</title>
      <link>https://arxiv.org/abs/2502.16159</link>
      <description>arXiv:2502.16159v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated strong performance across various general Natural Language Processing (NLP) tasks. However, their effectiveness in financial credit assessment applications remains suboptimal, primarily due to the specialized financial expertise required for these tasks. To address this limitation, we propose ZiGong, a Mistral-based model enhanced through multi-task supervised fine-tuning. To specifically combat model hallucination in financial contexts, we introduce a novel data pruning methodology. Our approach utilizes a proxy model to score training samples, subsequently combining filtered data with original datasets for model training. This data refinement strategy effectively reduces hallucinations in LLMs while maintaining reliability in downstream financial applications. Experimental results show our method significantly enhances model robustness and prediction accuracy in real-world financial scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16159v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Lei, Zixuan Wang, Chu Liu, Tongyao Wang</dc:creator>
    </item>
    <item>
      <title>Interpreting core forms of urban morphology linked to urban functions with explainable graph neural network</title>
      <link>https://arxiv.org/abs/2502.16210</link>
      <description>arXiv:2502.16210v1 Announce Type: new 
Abstract: Understanding the high-order relationship between urban form and function is essential for modeling the underlying mechanisms of sustainable urban systems. Nevertheless, it is challenging to establish an accurate data representation for complex urban forms that are readily explicable in human terms. This study proposed the concept of core urban morphology representation and developed an explainable deep learning framework for explicably symbolizing complex urban forms into the novel representation, which we call CoMo. By interpretating the well-trained deep learning model with a stable weighted F1-score of 89.14%, CoMo presents a promising approach for revealing links between urban function and urban form in terms of core urban morphology representation. Using Boston as a study area, we analyzed the core urban forms at the individual-building, block, and neighborhood level that are important to corresponding urban functions. The residential core forms follow a gradual morphological pattern along the urban spine, which is consistent with a center-urban-suburban transition. Furthermore, we prove that urban morphology directly affects land use efficiency, which has a significantly strong correlation with the location (R2=0.721, p&lt;0.001). Overall, CoMo can explicably symbolize urban forms, provide evidence for the classic urban location theory, and offer mechanistic insights for digital twins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16210v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compenvurbsys.2025.102267</arxiv:DOI>
      <dc:creator>Dongsheng Chen, Yu Feng, Xun Li, Mingya Qu, Peng Luo, Liqiu Meng</dc:creator>
    </item>
    <item>
      <title>A Cut-Based BAT-MCS Approach for Binary-State Network Reliability Assessment</title>
      <link>https://arxiv.org/abs/2502.16224</link>
      <description>arXiv:2502.16224v1 Announce Type: new 
Abstract: The BAT-MCS is an integrated Monte Carlo simulation method (MCS) that combines a binary adaptation tree algorithm (BAT) with a self-regulating simulation mechanism. The BAT algorithm operates deterministically, while the Monte Carlo simulation method is stochastic. By hybridizing these two approaches, BAT-MCS successfully reduces variance, increases efficiency, and improves the quality of its binary-state network reliability. However, it has two notable weaknesses. First, the selection of the supervectors, sub-vectors that form the core of BAT-MCS, is overly simplistic, potentially affecting overall performance. Second, the calculation of the approximate reliability is complicated, which limits its strength in reducing variance. In this study, a new BAT-MCS called cBAT-MCS is proposed to enhance the performance of the BAT-MCS. The approach reduces the complexity of MCS. Selecting the super-vector based on a novel layer-cut approach can reduce both runtime and variance. Extensive numerical experiments on large-scale binary-state network demonstrate that the proposed new cBAT-MCS outperforms traditional MCS and original BAT-MCS approaches in terms of computational efficiency and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16224v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wei-Chang Yeh</dc:creator>
    </item>
    <item>
      <title>A data-constrained sharp Immersed Boundary Method for aerospace applications</title>
      <link>https://arxiv.org/abs/2502.16518</link>
      <description>arXiv:2502.16518v1 Announce Type: new 
Abstract: A numerical tool relying on sharp Immersed Boundary Method (IBM) is developed for the analysis of aerospace applications. The method, which is conceived for application using segregated solvers relying on implicit time discretization, uses a Luenberger observer to dynamically update the free coefficients governing the numerical algorithm. This technique improves the accuracy of the method and permits to target the representation of complex flow features at the wall, taking into account the velocity field and heat transfer. The method is used to investigate several test cases of increasing complexity, including a space vehicle during atmospheric reentry. The tool exhibits interesting efficacy in terms of accuracy versus computational costs required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16518v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. A. Chemak, E. Constant, M. Meldi</dc:creator>
    </item>
    <item>
      <title>Automated Keypoint Estimation for Self-Piercing Rivet Joints Using micro-CT Imaging and Transfer Learning</title>
      <link>https://arxiv.org/abs/2502.16752</link>
      <description>arXiv:2502.16752v1 Announce Type: new 
Abstract: The structural integrity of self-piercing rivet (SPR) joints is critical in automotive industries, yet its evaluation poses challenges due to the limitations of traditional destructive methods. This research introduces an innovative approach for non-destructive evaluation using micro-CT imaging, Micro-Computed Tomography, combined with machine vision and deep learning techniques, specifically focusing on automated keypoint estimation to assess joint quality. Recognizing the scarcity of real micro-CT data, this study utilizes synthetic data for initial model training, followed by transfer learning to adapt the model for real-world conditions. A UNet-based architecture is employed to localize three keypoints with precision, enabling the measurement of critical parameters such as head height, interlock, and bottom layer thickness. Extensive validation demonstrates that pre-training on synthetic data, complemented by fine-tuning with limited real data, bridges domain gaps and enhances predictive accuracy. The proposed framework not only offers a scalable and cost-efficient solution for evaluating SPR joints but also establishes a foundation for broader applications of machine vision and non-destructive testing in manufacturing processes. By addressing data scarcity and leveraging advanced machine learning techniques, this work represents a significant step toward automated quality control in engineering contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16752v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Qin Chuah, Ruwan Tennakoon, Amanda Freis, Mark Easton, Reza Hoseinnezhad, Alireza Bab-Hadiashar</dc:creator>
    </item>
    <item>
      <title>AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay</title>
      <link>https://arxiv.org/abs/2502.16789</link>
      <description>arXiv:2502.16789v1 Announce Type: new 
Abstract: Alpha mining, a critical component in quantitative investment, focuses on discovering predictive signals for future asset returns in increasingly complex financial markets. However, the pervasive issue of alpha decay, where factors lose their predictive power over time, poses a significant challenge for alpha mining. Traditional methods like genetic programming face rapid alpha decay from overfitting and complexity, while approaches driven by Large Language Models (LLMs), despite their promise, often rely too heavily on existing knowledge, creating homogeneous factors that worsen crowding and accelerate decay. To address this challenge, we propose AlphaAgent, an autonomous framework that effectively integrates LLM agents with ad hoc regularizations for mining decay-resistant alpha factors. AlphaAgent employs three key mechanisms: (i) originality enforcement through a similarity measure based on abstract syntax trees (ASTs) against existing alphas, (ii) hypothesis-factor alignment via LLM-evaluated semantic consistency between market hypotheses and generated factors, and (iii) complexity control via AST-based structural constraints, preventing over-engineered constructions that are prone to overfitting. These mechanisms collectively guide the alpha generation process to balance originality, financial rationale, and adaptability to evolving market conditions, mitigating the risk of alpha decay. Extensive evaluations show that AlphaAgent outperforms traditional and LLM-based methods in mitigating alpha decay across bull and bear markets, consistently delivering significant alpha in Chinese CSI 500 and US S&amp;P 500 markets over the past four years. Notably, AlphaAgent showcases remarkable resistance to alpha decay, elevating the potential for yielding powerful factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16789v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyi Tang, Zechuan Chen, Jiarui Yang, Jiayao Mai, Yongsen Zheng, Keze Wang, Jinrui Chen, Liang Lin</dc:creator>
    </item>
    <item>
      <title>Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning</title>
      <link>https://arxiv.org/abs/2502.16828</link>
      <description>arXiv:2502.16828v1 Announce Type: new 
Abstract: Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems. System evolution is often modeled as particles moving on a landscape under the combined effect of energy-driven drift and noise-induced diffusion, where the energy governs the long-term motion of the particles. Estimating the energy landscape of a system has been a longstanding interdisciplinary challenge, hindered by the high operational costs or the difficulty of obtaining supervisory signals. Therefore, the question of how to infer the energy landscape in the absence of true energy values is critical. In this paper, we propose a physics-informed self-supervised learning method to learn the energy landscape from the evolution trajectories of the system. It first maps the system state from the observation space to a discrete landscape space by an adaptive codebook, and then explicitly integrates energy into the graph neural Fokker-Planck equation, enabling the joint learning of energy estimation and evolution prediction. Experimental results across interdisciplinary systems demonstrate that our estimated energy has a correlation coefficient above 0.9 with the ground truth, and evolution prediction accuracy exceeds the baseline by an average of 17.65\%. The code is available at github.com/tsinghua-fib-lab/PESLA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16828v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruikun Li, Huandong Wang, Qingmin Liao, Yong Li</dc:creator>
    </item>
    <item>
      <title>Constrained Shape Analysis with Applications to RNA Structure</title>
      <link>https://arxiv.org/abs/2502.16270</link>
      <description>arXiv:2502.16270v1 Announce Type: cross 
Abstract: In many applications of shape analysis, lengths between some landmarks are constrained. For instance, biomolecules often have some bond lengths and some bond angles constrained, and variation occurs only along unconstrained bonds and constrained bonds' torsions where the latter are conveniently modelled by dihedral angles. Our work has been motivated by low resolution biomolecular chain RNA where only some prominent atomic bonds can be well identified. Here, we propose a new modelling strategy for such constrained shape analysis starting with a product of polar coordinates (polypolars), where, due to constraints, for example, some radial coordinates should be omitted, leaving products of spheres (polyspheres). We give insight into these coordinates for particular cases such as five landmarks which are motivated by a practical RNA application. We also discuss distributions for polypolar coordinates and give a specific methodology with illustration when the constrained size-and-shape variables are concentrated. There are applications of this in clustering and we give some insight into a modified version of the MINT-AGE algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16270v1</guid>
      <category>stat.ME</category>
      <category>cs.CE</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanti V. Mardia, Benjamin Eltzner, Stephan F. Huckemann</dc:creator>
    </item>
    <item>
      <title>MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra</title>
      <link>https://arxiv.org/abs/2502.16284</link>
      <description>arXiv:2502.16284v1 Announce Type: cross 
Abstract: Establishing the relationship between 3D structures and the energy states of molecular systems has proven to be a promising approach for learning 3D molecular representations. However, existing methods are limited to modeling the molecular energy states from classical mechanics. This limitation results in a significant oversight of quantum mechanical effects, such as quantized (discrete) energy level structures, which offer a more accurate estimation of molecular energy and can be experimentally measured through energy spectra. In this paper, we propose to utilize the energy spectra to enhance the pre-training of 3D molecular representations (MolSpectra), thereby infusing the knowledge of quantum mechanics into the molecular representations. Specifically, we propose SpecFormer, a multi-spectrum encoder for encoding molecular spectra via masked patch reconstruction. By further aligning outputs from the 3D encoder and spectrum encoder using a contrastive objective, we enhance the 3D encoder's understanding of molecules. Evaluations on public benchmarks reveal that our pre-trained representations surpass existing methods in predicting molecular properties and modeling dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16284v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wang, Shaozhen Liu, Yu Rong, Deli Zhao, Qiang Liu, Shu Wu, Liang Wang</dc:creator>
    </item>
    <item>
      <title>Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading Agents</title>
      <link>https://arxiv.org/abs/2502.16343</link>
      <description>arXiv:2502.16343v1 Announce Type: cross 
Abstract: Companies across all economic sectors continue to deploy large language models at a rapid pace. Reinforcement learning is experiencing a resurgence of interest due to its association with the fine-tuning of language models from human feedback. Tool-chain language models control task-specific agents; if the converse has not already appeared, it soon will. In this paper, we present what we believe is the first investigation of an intelligent trading agent based on continuous deep reinforcement learning that also controls a large language model with which it can post to a social media feed observed by other traders. We empirically investigate the performance and impact of such an agent in a simulated financial market, finding that it learns to optimize its total reward, and thereby augment its profit, by manipulating the sentiment of the posts it produces. The paper concludes with discussion, limitations, and suggestions for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16343v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Byrd</dc:creator>
    </item>
    <item>
      <title>Finding Influential Cores via Normalized Ricci Flows in Directed and Undirected Hypergraphs with Applications</title>
      <link>https://arxiv.org/abs/2502.16382</link>
      <description>arXiv:2502.16382v1 Announce Type: cross 
Abstract: Many biological and social systems are naturally represented as edge-weighted directed or undirected hypergraphs since they exhibit group interactions involving three or more system units as opposed to pairwise interactions that can be incorporated in graph-theoretic representations. However, finding influential cores in hypergraphs is still not as extensively studied as their graph-theoretic counter-parts. To this end, we develop and implement a hypergraph-curvature guided discrete time diffusion process with suitable topological surgeries and edge-weight re-normalization procedures for both undirected and directed weighted hypergraphs to find influential cores. We successfully apply our framework for directed hypergraphs to seven metabolic hypergraphs and our framework for undirected hypergraphs to two social (co-authorship) hypergraphs to find influential cores, thereby demonstrating the practical feasibility of our approach. In addition, we prove a theorem showing that a certain edge weight re-normalization procedure in a prior research work for Ricci flows for edge-weighted graphs has the undesirable outcome of modifying the edge-weights to negative numbers, thereby rendering the procedure impossible to use. To the best of our knowledge, this seems to be one of the first articles that formulates algorithmic approaches for finding core(s) of (weighted or unweighted) directed hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16382v1</guid>
      <category>cs.SI</category>
      <category>cs.CE</category>
      <category>physics.soc-ph</category>
      <category>q-bio.MN</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prithviraj Sengupta, Nazanin Azarhooshang, Reka Albert, Bhaskar DasGupta</dc:creator>
    </item>
    <item>
      <title>A Survey on Industrial Anomalies Synthesis</title>
      <link>https://arxiv.org/abs/2502.16412</link>
      <description>arXiv:2502.16412v1 Announce Type: cross 
Abstract: This paper comprehensively reviews anomaly synthesis methodologies. Existing surveys focus on limited techniques, missing an overall field view and understanding method interconnections. In contrast, our study offers a unified review, covering about 40 representative methods across Hand-crafted, Distribution-hypothesis-based, Generative models (GM)-based, and Vision-language models (VLM)-based synthesis. We introduce the first industrial anomaly synthesis (IAS) taxonomy. Prior works lack formal classification or use simplistic taxonomies, hampering structured comparisons and trend identification. Our taxonomy provides a fine-grained framework reflecting methodological progress and practical implications, grounding future research. Furthermore, we explore cross-modality synthesis and large-scale VLM. Previous surveys overlooked multimodal data and VLM in anomaly synthesis, limiting insights into their advantages. Our survey analyzes their integration, benefits, challenges, and prospects, offering a roadmap to boost IAS with multimodal learning. More resources are available at https://github.com/M-3LAB/awesome-anomaly-synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16412v1</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xichen Xu, Yanshu Wang, Yawen Huang, Jiaqi Liu, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu</dc:creator>
    </item>
    <item>
      <title>Boltzsim: A fast solver for the 1D-space electron Boltzmann equation with applications to radio-frequency glow discharge plasmas</title>
      <link>https://arxiv.org/abs/2502.16555</link>
      <description>arXiv:2502.16555v1 Announce Type: cross 
Abstract: We present an algorithm for solving the one-dimensional space collisional Boltzmann transport equation (BTE) for electrons in low-temperature plasmas (LTPs). Modeling LTPs is useful in many applications, including advanced manufacturing, material processing, and hypersonic flows, to name a few. The proposed BTE solver is based on an Eulerian formulation. It uses Chebyshev collocation method in physical space and a combination of Galerkin and discrete ordinates in velocity space. We present self-convergence results and cross-code verification studies compared to an in-house particle-in-cell (PIC) direct simulation Monte Carlo (DSMC) code. Boltzsim is our open source implementation of the solver. Furthermore, we use Boltzsim to simulate radio-frequency glow discharge plasmas (RF-GDPs) and compare with an existing methodology that approximates the electron BTE. We compare these two approaches and quantify their differences as a function of the discharge pressure. The two approaches show an 80x, 3x, 1.6x, and 0.98x difference between cycle-averaged time periodic electron number density profiles at 0.1 Torr, 0.5 Torr, 1 Torr, and 2 Torr discharge pressures, respectively. As expected, these differences are significant at low pressures, for example less than 1 Torr.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16555v1</guid>
      <category>physics.plasm-ph</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Milinda Fernando, James Almgren-Bell, Todd Oliver, Robert Moser, Philip Varghese, Laxminarayan Raja, George Biros</dc:creator>
    </item>
    <item>
      <title>An Efficient Quantum Approximate Optimization Algorithm with Fixed Linear Ramp Schedule for Truss Structure Optimization</title>
      <link>https://arxiv.org/abs/2502.16769</link>
      <description>arXiv:2502.16769v1 Announce Type: cross 
Abstract: This study proposes a novel structural optimization framework based on quantum variational circuits, in which the multiplier acting on the cross-sectional area of each rod in a truss structure as an updater is used as a design variable. Specifically, we employ a classical processor for structural analysis with the finite element method, and the Quantum Approximate Optimization Algorithm (QAOA) is subsequently performed to update the cross-sectional area so that the compliance is minimized. The advantages of this framework can be seen in three key aspects. First, by defining design variables as multipliers, rather than simply reducing the design variable to a binary candidate of inclusion or exclusion (corresponding to qubit states, ``0" and ``1"), it provides greater flexibility in adjusting the cross-sectional area of the rod at each iteration of the optimization process. Second, the multipliers acting on rods are encoded with on-off encoding, eliminating additional constraints in the convergence judgement. As a result, the objective function is in a simple format, enabling efficient optimization using QAOA.Third, a fixed linear ramp schedule (FLRS) for variational parameter setting bypasses the classical optimization process, thereby improving the operational efficiency of the framework. In the two structural cases investigated in this study, the proposed approach highlights the feasibility and applicability potential of quantum computing in advancing engineering design and optimization. Numerical experiments have demonstrated the effectiveness of this framework, providing a firm foundation for future research on quantum-assisted optimization methods in engineering fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16769v1</guid>
      <category>quant-ph</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Junsen Xiao, Naruethep Sukulthanasorn, Reika Nomura, Shuji Moriguchi, Kenjiro Terada</dc:creator>
    </item>
    <item>
      <title>Predicting Liquidity-Aware Bond Yields using Causal GANs and Deep Reinforcement Learning with LLM Evaluation</title>
      <link>https://arxiv.org/abs/2502.17011</link>
      <description>arXiv:2502.17011v1 Announce Type: cross 
Abstract: Financial bond yield forecasting is challenging due to data scarcity, nonlinear macroeconomic dependencies, and evolving market conditions. In this paper, we propose a novel framework that leverages Causal Generative Adversarial Networks (CausalGANs) and Soft Actor-Critic (SAC) reinforcement learning (RL) to generate high-fidelity synthetic bond yield data for four major bond categories (AAA, BAA, US10Y, Junk). By incorporating 12 key macroeconomic variables, we ensure statistical fidelity by preserving essential market properties. To transform this market dependent synthetic data into actionable insights, we employ a finetuned Large Language Model (LLM) Qwen2.5-7B that generates trading signals (BUY/HOLD/SELL), risk assessments, and volatility projections. We use automated, human and LLM evaluations, all of which demonstrate that our framework improves forecasting performance over existing methods, with statistical validation via predictive accuracy, MAE evaluation(0.103%), profit/loss evaluation (60% profit rate), LLM evaluation (3.37/5) and expert assessments scoring 4.67 out of 5. The reinforcement learning-enhanced synthetic data generation achieves the least Mean Absolute Error of 0.103, demonstrating its effectiveness in replicating real-world bond market dynamics. We not only enhance data-driven trading strategies but also provides a scalable, high-fidelity synthetic financial data pipeline for risk &amp; volatility management and investment decision-making. This work establishes a bridge between synthetic data generation, LLM driven financial forecasting, and language model evaluation, contributing to AI-driven financial decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17011v1</guid>
      <category>q-fin.CP</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaskaran Singh Walia, Aarush Sinha, Srinitish Srinivasan, Srihari Unnikrishnan</dc:creator>
    </item>
    <item>
      <title>Hierarchical poromechanical approach to investigate the impact of mechanical loading on human skin micro-circulation</title>
      <link>https://arxiv.org/abs/2502.17354</link>
      <description>arXiv:2502.17354v1 Announce Type: cross 
Abstract: Research on human skin anatomy reveals its complex multi-scale, multi-phase nature, with up to 70% of its composition being bounded and free water. Fluid movement plays a key role in the skin's mechanical and biological responses, influencing its time-dependent behavior and nutrient transport.
  Poroelastic modeling is a promising approach for studying skin dynamics across scales by integrating multi-physics processes. This paper introduces a hierarchical two-compartment model capturing fluid distribution in the interstitium and micro-circulation. A theoretical framework is developed with a biphasic interstitium -- distinguishing interstitial fluid and non-structural cells -- and analyzed through a one-dimensional consolidation test of a column. This biphasic approach allows separate modeling of cell and fluid motion, considering their differing characteristic times. An appendix discusses extending the model to include biological exchanges like oxygen transport. Preliminary results indicate that cell viscosity introduces a second characteristic time, and at high viscosity and short time scales, cells behave similarly to solids.
  A simplified model was used to replicate an experimental campaign on short time scales. Local pressure (up to 31 kPa) was applied to dorsal finger skin using a laser Doppler probe PF801 (Perimed Sweden), following a setup described in Fromy Brain Res (1998). The model qualitatively captured ischemia and post-occlusive reactive hyperemia, aligning with experimental data.
  All numerical simulations used the open-source software FEniCSx v0.9.0. To ensure transparency and reproducibility, anonymized experimental data and finite element codes are publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17354v1</guid>
      <category>q-bio.TO</category>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Lavigne, St\'ephane Urcun, B\'ereng\`ere Fromy, Audrey Josset-Lamaugarny, Alexandre Lagache, Camilo A. Suarez-Afanador, St\'ephane P. A. Bordas, Pierre-Yves Rohan, Giuseppe Scium\`e</dc:creator>
    </item>
    <item>
      <title>A Generative Approach to Credit Prediction with Learnable Prompts for Multi-scale Temporal Representation Learning</title>
      <link>https://arxiv.org/abs/2404.13004</link>
      <description>arXiv:2404.13004v3 Announce Type: replace 
Abstract: Recent industrial credit scoring models remain heavily reliant on manually tuned statistical learning methods. While deep learning offers promising solutions, its effectiveness is often limited by the complexity of financial data, particularly in long-horizon scenarios. In this work, we propose FinLangNet, which addresses credit scoring by reframing it as the task of generating multi-scale distributions of a user's future behavior. Within this framework, tabular data is transformed into sequential representations, enabling the generation of user embeddings across multiple temporal scales. Inspired by the recent success of prompt-based training in Large Language Models (LLMs), FinLangNet also introduces two types of prompts to model and capture user behavior at both the feature-granularity and user-granularity levels. Experimental results demonstrate that FinLangNet outperforms the online XGBoost benchmark, achieving a 7.2\% improvement in KS metric performance and a 9.9\% reduction in the relative bad debt rate. Furthermore, FinLangNet exhibits superior performance on public UEA archives, underscoring its scalability and adaptability in time series classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13004v3</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Lei, Zixuan Wang, Yiqing Feng, Junru Zhang, Yahui Li, Chu Liu, Tongyao Wang</dc:creator>
    </item>
    <item>
      <title>Tensor Network Structure Search Using Program Synthesis</title>
      <link>https://arxiv.org/abs/2502.02711</link>
      <description>arXiv:2502.02711v2 Announce Type: replace 
Abstract: Tensor networks provide a powerful framework for compressing multi-dimensional data. The optimal tensor network structure for a given data tensor depends on both the inherent data properties and the specific optimality criteria, making tensor network structure search a crucial research problem. Existing solutions typically involve sampling and validating numerous candidate structures; this is computationally expensive, limiting their practical applications. We address this challenge by formulating tensor network structure search as a program synthesis problem and proposing a highly efficient validation method that is based on constraint solving. Specifically, we design a domain specific language: it builds the correspondence between programs and network structures, and uses a novel idea of output-directed splits to compress the search space without hindering the expressiveness. We then propose a synthesis algorithm that can prioritize promising candidates through constraint solving. % Experimental results show that our approach improves search speed by $10\times$ and achieves compression ratios by $1.5\times$ to $3\times$ better than state-of-the-art. Notably, our approach scales to larger tensors that are out of reach by prior work. Finally, we demonstrate that the discovered topologies generalize to data from the same source, achieving compression ratios up to $ 2.4\times$ better than hierarchical Tuckers while maintaining the runtime around $110$ seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02711v2</guid>
      <category>cs.CE</category>
      <category>cs.PL</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Guo, Aditya Deshpande, Brian Kiedrowski, Xinyu Wang, Alex Gorodetsky</dc:creator>
    </item>
    <item>
      <title>Multi-objective Bayesian Optimisation of Spinodoid Cellular Structures for Crush Energy Absorption</title>
      <link>https://arxiv.org/abs/2411.14508</link>
      <description>arXiv:2411.14508v2 Announce Type: replace-cross 
Abstract: In the pursuit of designing safer and more efficient energy-absorbing structures, engineers must tackle the challenge of improving crush performance while balancing multiple conflicting objectives, such as maximising energy absorption and minimising peak impact forces. Accurately simulating real-world conditions necessitates the use of complex material models to replicate the non-linear behaviour of materials under impact, which comes at a significant computational cost. This study addresses these challenges by introducing a multi-objective Bayesian optimisation framework specifically developed to optimise spinodoid structures for crush energy absorption. Spinodoid structures, characterised by their scalable, non-periodic topologies and efficient stress distribution, offer a promising direction for advanced structural design. However, optimising design parameters to enhance crush performance is far from straightforward, particularly under realistic conditions. Conventional optimisation methods, although effective, often require a large number of costly simulations to identify suitable solutions, making the process both time-consuming and resource intensive. In this context, multi-objective Bayesian optimisation provides a clear advantage by intelligently navigating the design space, learning from each evaluation to reduce the number of simulations required, and efficiently addressing the complexities of non-linear material behaviour. By integrating finite element analysis with Bayesian optimisation, the framework developed in this study tackles the dual challenge of improving energy absorption and reducing peak force, particularly in scenarios where plastic deformation plays a critical role. The use of scalarisation and hypervolume-based techniques enables the identification of Pareto-optimal solutions, balancing these conflicting objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14508v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hirak Kansara, Siamak F. Khosroshahi, Leo Guo, Miguel A. Bessa, Wei Tan</dc:creator>
    </item>
    <item>
      <title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
      <link>https://arxiv.org/abs/2412.20138</link>
      <description>arXiv:2412.20138v4 Announce Type: replace-cross 
Abstract: Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/TradingAgents-AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20138v4</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijia Xiao, Edward Sun, Di Luo, Wei Wang</dc:creator>
    </item>
    <item>
      <title>A Sustainable Circular Framework for Financing Infrastructure Climate Adaptation: Integrated Carbon Markets</title>
      <link>https://arxiv.org/abs/2501.08004</link>
      <description>arXiv:2501.08004v2 Announce Type: replace-cross 
Abstract: Climate physical risks pose an increasing threat to urban infrastructure, necessitating urgent climate adaptation measures to protect lives and assets. Implementing such measures, including the development of resilient infrastructure and retrofitting existing systems, demands substantial financial investment. Unfortunately, due to the unprofitability stemming from the long-term returns, uncertainty, and complexity of infrastructure adaptation projects and the short-term profit-seeking objectives of private capital, a massive financial gap remains. This study suggests incentivizing private capital to bridge financial gaps through integrated carbon markets. Specifically, the framework combines carbon taxes and carbon markets to involve infrastructure and individuals in the climate mitigation phase, using the funds collected for climate adaptation. Moreover, it integrates lifestyle reformation, environmental mitigation, and infrastructure adaptation to establish harmonized standards and provide circular positive feedback to sustain the markets. We further explore how integrated carbon markets can facilitate fund collection and discuss the challenges of incorporating them into infrastructure climate adaptation. This study aims to foster collaboration between private and public capital to enable a more scientific, rational, and actionable implementation of integrated carbon markets, thus supporting sustainable financial backing for infrastructure climate adaptation</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08004v2</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Li, Xing Su, Chao Fan, Jun Wang, Xiangyu Wang</dc:creator>
    </item>
  </channel>
</rss>
