<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Herd of Young Mastodonts: the User-Centered Footprints of Newcomers After Twitter Acquisition</title>
      <link>https://arxiv.org/abs/2412.16383</link>
      <description>arXiv:2412.16383v1 Announce Type: new 
Abstract: The tremendous success of major Online Social Networks (OSNs) platforms has raised increasing concerns about negative phenomena, such as mass control, fake news, and echo chambers. In addition, the increasingly strict control over users' data by platform owners questions their trustworthiness as open interaction tools. These trends and, notably, the recent drastic change in X (formerly Twitter) policies and data accessibility through public APIs, have fuelled significant migration of users towards Fediverse platforms (primarily Mastodon). In this work, we provide an initial analysis of the microscopic properties of Mastodon users' social structures. Specifically, according to the Ego network model, we analyse interaction patterns between a large set of users (egos) and the other users they interact with (alters) to characterise the properties of those users' ego networks. As was observed previously in other OSNs, we found a quite regular structure compatible with the reference Dunbar's Ego Network model. Quite interestingly, our results show clear signs of ego network formation during the initial diffusion of a social networking tool, coherent with the recent surge of Mastodon activity. Therefore, our analysis motivates the use of Mastodon as an open "big data microscope" to characterise human social behaviour, making it a prime candidate to replace those OSN platforms that, unfortunately, cannot be used anymore for this purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16383v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Di Cursi, Chiara Boldrini, Andrea Passarella, Marco Conti</dc:creator>
    </item>
    <item>
      <title>Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index</title>
      <link>https://arxiv.org/abs/2412.16925</link>
      <description>arXiv:2412.16925v1 Announce Type: new 
Abstract: This study introduces the Community Sentiment and Engagement Index (CSEI), developed to capture nuanced public sentiment and engagement variations on social media, particularly in response to major events related to COVID-19. Constructed with diverse sentiment indicators, CSEI integrates features like engagement, daily post count, compound sentiment, fine-grain sentiments (fear, surprise, joy, sadness, anger, disgust, and neutral), readability, offensiveness, and domain diversity. Each component is systematically weighted through a multi-step Principal Component Analysis (PCA)-based framework, prioritizing features according to their variance contributions across temporal sentiment shifts. This approach dynamically adjusts component importance, enabling CSEI to precisely capture high-sensitivity shifts in public sentiment. The development of CSEI showed statistically significant correlations with its constituent features, underscoring internal consistency and sensitivity to specific sentiment dimensions. CSEI's responsiveness was validated using a dataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15 major events, including the WHO's declaration of COVID-19 as a pandemic, the first reported cases of COVID-19 across different countries, national lockdowns, vaccine developments, and crucial public health measures. Cumulative changes in CSEI revealed prominent peaks and valleys aligned with these events, indicating significant patterns in public sentiment across different phases of the pandemic. Pearson correlation analysis further confirmed a statistically significant relationship between CSEI daily fluctuations and these events (p = 0.0428), highlighting the capacity of CSEI to infer and interpret shifts in public sentiment and engagement in response to major events related to COVID-19.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16925v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nirmalya Thakur, Kesha A. Patel, Audrey Poon, Shuqi Cui, Nazif Azizi, Rishika Shah, Riyan Shah</dc:creator>
    </item>
    <item>
      <title>COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations</title>
      <link>https://arxiv.org/abs/2412.17180</link>
      <description>arXiv:2412.17180v1 Announce Type: new 
Abstract: This study presents a data-driven analysis of COVID-19 discourse on YouTube, examining the sentiment, toxicity, and thematic patterns of video content published between January 2023 and October 2024. The analysis involved applying advanced natural language processing (NLP) techniques: sentiment analysis with VADER, toxicity detection with Detoxify, and topic modeling using Latent Dirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of video descriptions were positive, 36.63% were neutral, and 14.05% were negative, indicating a generally informative and supportive tone in pandemic-related content. Toxicity analysis identified only 0.91% of content as toxic, suggesting minimal exposure to toxic content. Topic modeling revealed two main themes, with 66.74% of the videos covering general health information and pandemic-related impacts and 33.26% focused on news and real-time updates, highlighting the dual informational role of YouTube. A recommendation system was also developed using TF-IDF vectorization and cosine similarity, refined by sentiment, toxicity, and topic filters to ensure relevant and context-aligned video recommendations. This system achieved 69% aggregate coverage, with monthly coverage rates consistently above 85%, demonstrating robust performance and adaptability over time. Evaluation across recommendation sizes showed coverage reaching 69% for five video recommendations and 79% for ten video recommendations per video. In summary, this work presents a framework for understanding COVID-19 discourse on YouTube and a recommendation system that supports user engagement while promoting responsible and relevant content related to COVID-19.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17180v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vanessa Su, Nirmalya Thakur</dc:creator>
    </item>
    <item>
      <title>Dynamics of Collective Information Processing for Risk Encoding in Social Networks during Crises</title>
      <link>https://arxiv.org/abs/2412.17342</link>
      <description>arXiv:2412.17342v1 Announce Type: new 
Abstract: Online social networks are increasingly being utilized for collective sense making and information processing in disasters. However, the underlying mechanisms that shape the dynamics of collective intelligence in online social networks during disasters is not fully understood. To bridge this gap, we examine the mechanisms of collective information processing in human networks during five threat cases including airport power outage, hurricanes, wildfire, and blizzard, considering the temporal and spatial dimensions. Using the 13MM Twitter data generated by 5MM online users during these threats, we examined human activities, communication structures and frequency, social influence, information flow, and medium response time in social networks. The results show that the activities and structures are stable in growing networks, which lead to a stable power-law distribution of the social influence in networks. These temporally invariant patterns are not affected by people's memory and ties' strength. In addition, spatially localized communication spikes and global transmission gaps in the networks. The findings could inform about network intervention strategies to enable a healthy and efficient online environment, with potential long-term impact on risk communication and emergency response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17342v1</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Fan, Fangsheng Wu, Ali Mostafavi</dc:creator>
    </item>
    <item>
      <title>The evolution of cooperation in spatial public goods game with tolerant punishment based on reputation threshold</title>
      <link>https://arxiv.org/abs/2412.17351</link>
      <description>arXiv:2412.17351v1 Announce Type: new 
Abstract: Reputation and punishment are significant guidelines for regulating individual behavior in human society, and those with a good reputation are more likely to be imitated by others. In addition, society imposes varying degrees of punishment for behaviors that harm the interests of groups with different reputations. However, conventional pairwise interaction rules and the punishment mechanism overlook this aspect. Building on this observation, this paper enhances a spatial public goods game in two key ways: 1) We set a reputation threshold and use punishment to regulate the defection behavior of players in low-reputation groups while allowing defection behavior in high-reputation game groups. 2) Differently from pairwise interaction rules, we combine reputation and payoff as the fitness of individuals to ensure that players with both high payoff and reputation have a higher chance of being imitated. Through simulations, we find that a higher reputation threshold, combined with a stringent punishment environment, can substantially enhance the level of cooperation within the population. This mechanism provides deeper insight into the widespread phenomenon of cooperation that emerges among individuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17351v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gui Zhang, Yichao Yao, Ziyan Zeng, Minyu Feng, Manuel Chica</dc:creator>
    </item>
    <item>
      <title>Silencer: Robust Community Detection by Silencing of Noisy Pixels</title>
      <link>https://arxiv.org/abs/2412.17412</link>
      <description>arXiv:2412.17412v1 Announce Type: new 
Abstract: Real-world networks carry all kinds of noise, resulting in numerous challenges for community detection. Further improving the performance and robustness of community detection has attracted significant attention. This paper considers edge noise, which causes edges in the network to be added or removed. Existing methods achieve graph denoising through link prediction or robustness in low eigenvectors. However, they are either limited in application scenarios or not determined for effectiveness. We find that the noisy pixel in the adjacency matrix has a certain proportion in the loss function, which makes the optimization of the community detection model seriously deviate from the correct direction. Thus, we design an flexible framework to silence the contribution of noisy pixels to loss function, called Silencer. We take the nonnegative matrix factorization (NMF) and deep NMF methods as examples since they are the prime models for community detection. We first prove the convergence of Silencer in NMF. Compared with existing methods, Silencer show top performance in six real-world networks with random noise, adversarial perturbation, and mixed noise. Moreover, Silencer works on random (ER), scale-free (BA), and small-world (WS) networks, and the improvement of Silencer is gradually insignificant in the order ER, BA, and WS networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17412v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Wu, Ziang Xie, Jing Liu</dc:creator>
    </item>
    <item>
      <title>Identifying Cyberbullying Roles in Social Media</title>
      <link>https://arxiv.org/abs/2412.16417</link>
      <description>arXiv:2412.16417v1 Announce Type: cross 
Abstract: Social media has revolutionized communication, allowing people worldwide to connect and interact instantly. However, it has also led to increases in cyberbullying, which poses a significant threat to children and adolescents globally, affecting their mental health and well-being. It is critical to accurately detect the roles of individuals involved in cyberbullying incidents to effectively address the issue on a large scale. This study explores the use of machine learning models to detect the roles involved in cyberbullying interactions. After examining the AMiCA dataset and addressing class imbalance issues, we evaluate the performance of various models built with four underlying LLMs (i.e., BERT, RoBERTa, T5, and GPT-2) for role detection. Our analysis shows that oversampling techniques help improve model performance. The best model, a fine-tuned RoBERTa using oversampled data, achieved an overall F1 score of 83.5%, increasing to 89.3% after applying a prediction threshold. The top-2 F1 score without thresholding was 95.7%. Our method outperforms previously proposed models. After investigating the per-class model performance and confidence scores, we show that the models perform well in classes with more samples and less contextual confusion (e.g., Bystander Other), but struggle with classes with fewer samples (e.g., Bystander Assistant) and more contextual ambiguity (e.g., Harasser and Victim). This work highlights current strengths and limitations in the development of accurate models with limited data and complex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16417v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Sandoval, Mohammed Abuhamad, Patrick Furman, Mujtaba Nazari, Deborah L. Hall, Yasin N. Silva</dc:creator>
    </item>
    <item>
      <title>THeGCN: Temporal Heterophilic Graph Convolutional Network</title>
      <link>https://arxiv.org/abs/2412.16435</link>
      <description>arXiv:2412.16435v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) have exhibited remarkable efficacy in diverse graph learning tasks, particularly on static homophilic graphs. Recent attention has pivoted towards more intricate structures, encompassing (1) static heterophilic graphs encountering the edge heterophily issue in the spatial domain and (2) event-based continuous graphs in the temporal domain. State-of-the-art (SOTA) has been concurrently addressing these two lines of work but tends to overlook the presence of heterophily in the temporal domain, constituting the temporal heterophily issue. Furthermore, we highlight that the edge heterophily issue and the temporal heterophily issue often co-exist in event-based continuous graphs, giving rise to the temporal edge heterophily challenge. To tackle this challenge, this paper first introduces the temporal edge heterophily measurement. Subsequently, we propose the Temporal Heterophilic Graph Convolutional Network (THeGCN), an innovative model that incorporates the low/high-pass graph signal filtering technique to accurately capture both edge (spatial) heterophily and temporal heterophily. Specifically, the THeGCN model consists of two key components: a sampler and an aggregator. The sampler selects events relevant to a node at a given moment. Then, the aggregator executes message-passing, encoding temporal information, node attributes, and edge attributes into node embeddings. Extensive experiments conducted on 5 real-world datasets validate the efficacy of THeGCN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16435v1</guid>
      <category>cs.LG</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuchen Yan, Yuzhong Chen, Huiyuan Chen, Xiaoting Li, Zhe Xu, Zhichen Zeng, Zhining Liu, Hanghang Tong</dc:creator>
    </item>
    <item>
      <title>Learning Cross-Task Generalities Across Graphs via Task-trees</title>
      <link>https://arxiv.org/abs/2412.16441</link>
      <description>arXiv:2412.16441v1 Announce Type: cross 
Abstract: Foundation models aim to create general, cross-task, and cross-domain machine learning models by pretraining on large-scale datasets to capture shared patterns or concepts (generalities), such as contours, colors, textures, and edges in images, or tokens, words, and sentences in text. However, discovering generalities across graphs remains challenging, which has hindered the development of graph foundation models. To tackle this challenge, in this paper, we propose a novel approach to learn generalities across graphs via task-trees. Specifically, we first define the basic learning instances in graphs as task-trees and assume that the generalities shared across graphs are, at least partially, preserved in the task-trees of the given graphs. To validate the assumption, we first perform a theoretical analysis of task-trees in terms of stability, transferability, and generalization. We find that if a graph neural network (GNN) model is pretrained on diverse task-trees through a reconstruction task, it can learn sufficient transferable knowledge for downstream tasks using an appropriate set of fine-tuning samples. To empirically validate the assumption, we further instantiate the theorems by developing a cross-task, cross-domain graph foundation model named Graph generality Identifier on task-Trees (GIT). The extensive experiments over 30 graphs from five domains demonstrate the effectiveness of GIT in fine-tuning, in-context learning, and zero-shot learning scenarios. Particularly, the general GIT model pretrained on large-scale datasets can be quickly adapted to specific domains, matching or even surpassing expert models designed for those domains. Our data and code are available at https://github.com/Zehong-Wang/GIT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16441v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye</dc:creator>
    </item>
    <item>
      <title>Evaluating the Performance of Large Language Models in Scientific Claim Detection and Classification</title>
      <link>https://arxiv.org/abs/2412.16486</link>
      <description>arXiv:2412.16486v1 Announce Type: cross 
Abstract: The pervasive influence of social media during the COVID-19 pandemic has been a double-edged sword, enhancing communication while simultaneously propagating misinformation. This \textit{Digital Infodemic} has highlighted the urgent need for automated tools capable of discerning and disseminating factual content. This study evaluates the efficacy of Large Language Models (LLMs) as innovative solutions for mitigating misinformation on platforms like Twitter. LLMs, such as OpenAI's GPT and Meta's LLaMA, offer a pre-trained, adaptable approach that bypasses the extensive training and overfitting issues associated with traditional machine learning models. We assess the performance of LLMs in detecting and classifying COVID-19-related scientific claims, thus facilitating informed decision-making. Our findings indicate that LLMs have significant potential as automated fact-checking tools, though research in this domain is nascent and further exploration is required. We present a comparative analysis of LLMs' performance using a specialized dataset and propose a framework for their application in public health communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16486v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanjim Bin Faruk</dc:creator>
    </item>
    <item>
      <title>Distributed Target Tracking based on Localization with Linear Time-Difference-of-Arrival Measurements: A Delay-Tolerant Networked Estimation Approach</title>
      <link>https://arxiv.org/abs/2412.16988</link>
      <description>arXiv:2412.16988v1 Announce Type: cross 
Abstract: This paper considers target tracking based on a beacon signal's time-difference-of-arrival (TDOA) to a group of cooperating sensors. The sensors receive a reflected signal from the target where the time-of-arrival (TOA) renders the distance information. The existing approaches include: (i) classic centralized solutions which gather and process the target data at a central unit, (ii) distributed solutions which assume that the target data is observable in the dense neighborhood of each sensor (to be filtered locally), and (iii) double time-scale distributed methods with high rates of communication/consensus over the network. This work, in order to reduce the network connectivity in (i)-(ii) and communication rate in (iii), proposes a distributed single time-scale technique, which can also handle heterogeneous constant data-exchange delays over the static sensor network. This work assumes only distributed observability (in contrast to local observability in some existing works categorized in (ii)), i.e., the target is observable globally over a (strongly) connected network. The (strong) connectivity further allows for survivable network and $q$-redundant observer design. Each sensor locally shares information and processes the received data in its immediate neighborhood via local linear-matrix-inequalities (LMI) feedback gains to ensure tracking error stability. The same gain matrix works in the presence of heterogeneous delays with no need of redesigning algorithms. Since most existing distributed estimation scenarios are linear (based on consensus), many works use linearization of the existing nonlinear TDOA measurement models where the output matrix is a function of the target position.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16988v1</guid>
      <category>eess.SY</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Themistoklis Charalambous</dc:creator>
    </item>
    <item>
      <title>GraphHash: Graph Clustering Enables Parameter Efficiency in Recommender Systems</title>
      <link>https://arxiv.org/abs/2412.17245</link>
      <description>arXiv:2412.17245v1 Announce Type: cross 
Abstract: Deep recommender systems rely heavily on large embedding tables to handle high-cardinality categorical features such as user/item identifiers, and face significant memory constraints at scale. To tackle this challenge, hashing techniques are often employed to map multiple entities to the same embedding and thus reduce the size of the embedding tables. Concurrently, graph-based collaborative signals have emerged as powerful tools in recommender systems, yet their potential for optimizing embedding table reduction remains unexplored. This paper introduces GraphHash, the first graph-based approach that leverages modularity-based bipartite graph clustering on user-item interaction graphs to reduce embedding table sizes. We demonstrate that the modularity objective has a theoretical connection to message-passing, which provides a foundation for our method. By employing fast clustering algorithms, GraphHash serves as a computationally efficient proxy for message-passing during preprocessing and a plug-and-play graph-based alternative to traditional ID hashing. Extensive experiments show that GraphHash substantially outperforms diverse hashing baselines on both retrieval and click-through-rate prediction tasks. In particular, GraphHash achieves on average a 101.52% improvement in recall when reducing the embedding table size by more than 75%, highlighting the value of graph-based collaborative information for model reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17245v1</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyi Wu, Donald Loveland, Runjin Chen, Yozen Liu, Xin Chen, Leonardo Neves, Ali Jadbabaie, Clark Mingxuan Ju, Neil Shah, Tong Zhao</dc:creator>
    </item>
    <item>
      <title>Collective dynamics behind success</title>
      <link>https://arxiv.org/abs/2412.17472</link>
      <description>arXiv:2412.17472v1 Announce Type: cross 
Abstract: Understanding the collective dynamics behind the success of ideas, products, behaviors, and social actors is critical for decision-making across diverse contexts, including hiring, funding, career choices, and the design of interventions for social change. Methodological advances and the increasing availability of big data now allow for a broader and deeper understanding of the key facets of success. Recent studies unveil regularities beneath the collective dynamics of success, pinpoint underlying mechanisms, and even enable predictions of success across diverse domains, including science, technology, business, and the arts. However, this research also uncovers troubling biases that challenge meritocratic views of success. This review synthesizes the growing, cross-disciplinary literature on the collective dynamics behind success and calls for further research on cultural influences, the origins of inequalities, the role of algorithms in perpetuating them, and experimental methods to further probe causal mechanisms behind success. Ultimately, these efforts may help to better align success with desired societal values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17472v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-024-54612-4</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications 15 (1), 10701 (2024)</arxiv:journal_reference>
      <dc:creator>Manuel S. Mariani, Federico Battiston, Em\H{o}ke-\'Agnes Horv\'at, Giacomo Livan, Federico Musciotto, Dashun Wang</dc:creator>
    </item>
    <item>
      <title>From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News</title>
      <link>https://arxiv.org/abs/2403.09498</link>
      <description>arXiv:2403.09498v2 Announce Type: replace 
Abstract: In the digital era, the rapid propagation of fake news and rumors via social networks brings notable societal challenges and impacts public opinion regulation. Traditional fake news modeling typically forecasts the general popularity trends of different groups or numerically represents opinions shift. However, these methods often oversimplify real-world complexities and overlook the rich semantic information of news text. The advent of large language models (LLMs) provides the possibility of modeling subtle dynamics of opinion. Consequently, in this work, we introduce a Fake news Propagation Simulation framework (FPS) based on LLM, which studies the trends and control of fake news propagation in detail. Specifically, each agent in the simulation represents an individual with a distinct personality. They are equipped with both short-term and long-term memory, as well as a reflective mechanism to mimic human-like thinking. Every day, they engage in random opinion exchanges, reflect on their thinking, and update their opinions. Our simulation results uncover patterns in fake news propagation related to topic relevance, and individual traits, aligning with real-world observations. Additionally, we evaluate various intervention strategies and demonstrate that early and appropriately frequent interventions strike a balance between governance cost and effectiveness, offering valuable insights for practical applications. Our study underscores the significant utility and potential of LLMs in combating fake news.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09498v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.24963/ijcai.2024/873</arxiv:DOI>
      <dc:creator>Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing Gao, Ji Zhang, Rui Yan</dc:creator>
    </item>
    <item>
      <title>Perceived community alignment increases information sharing</title>
      <link>https://arxiv.org/abs/2304.13796</link>
      <description>arXiv:2304.13796v2 Announce Type: replace-cross 
Abstract: It has been proposed that information sharing, which is a ubiquitous and consequential behavior, plays a critical role in cultivating and maintaining a sense of shared reality. Across three studies, we tested this theory by investigating whether or not people are especially likely to share information that they believe will be interpreted similarly by others in their social circles. Using neuroimaging while members of the same community viewed brief film clips, we found that more similar neural responding of participants was associated with a greater likelihood to share content. We then tested this relationship using two behavioral studies and found (1) that people were particularly likely to share content that they believed others in their social circles would interpret similarly and (2) that perceived similarity with others leads to increased sharing likelihood. In concert, our findings support the idea that people are driven to share information to create and reinforce shared understanding, which is critical to social connection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13796v2</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisa C. Baek, Ryan Hyon, Karina L\'opez, Mason A. Porter, Carolyn Parkinson</dc:creator>
    </item>
    <item>
      <title>Learning on Large Graphs using Intersecting Communities</title>
      <link>https://arxiv.org/abs/2405.20724</link>
      <description>arXiv:2405.20724v2 Announce Type: replace-cross 
Abstract: Message Passing Neural Networks (MPNNs) are a staple of graph machine learning. MPNNs iteratively update each node's representation in an input graph by aggregating messages from the node's neighbors, which necessitates a memory complexity of the order of the number of graph edges. This complexity might quickly become prohibitive for large graphs provided they are not very sparse. In this paper, we propose a novel approach to alleviate this problem by approximating the input graph as an intersecting community graph (ICG) -- a combination of intersecting cliques. The key insight is that the number of communities required to approximate a graph does not depend on the graph size. We develop a new constructive version of the Weak Graph Regularity Lemma to efficiently construct an approximating ICG for any input graph. We then devise an efficient graph learning algorithm operating directly on ICG in linear memory and time with respect to the number of nodes (rather than edges). This offers a new and fundamentally different pipeline for learning on very large non-sparse graphs, whose applicability is demonstrated empirically on node classification tasks and spatio-temporal data processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20724v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Finkelshtein, \.Ismail \.Ilkan Ceylan, Michael Bronstein, Ron Levie</dc:creator>
    </item>
    <item>
      <title>AI Rules? Characterizing Reddit Community Policies Towards AI-Generated Content</title>
      <link>https://arxiv.org/abs/2410.11698</link>
      <description>arXiv:2410.11698v2 Announce Type: replace-cross 
Abstract: How are Reddit communities responding to AI-generated content? We explored this question through a large-scale analysis of subreddit community rules and their change over time. We collected the metadata and community rules for over $300,000$ public subreddits and measured the prevalence of rules governing AI. We labeled subreddits and AI rules according to existing taxonomies from the HCI literature and a new taxonomy we developed specific to AI rules. While rules about AI are still relatively uncommon, the number of subreddits with these rules more than doubled over the course of a year. AI rules are more common in larger subreddits and communities focused on art or celebrity topics, and less common in those focused on social support. These rules often focus on AI images and evoke, as justification, concerns about quality and authenticity. Overall, our findings illustrate the emergence of varied concerns about AI, in different community contexts. Platform designers and HCI researchers should heed these concerns if they hope to encourage community self-determination in the age of generative AI. We make our datasets public to enable future large-scale studies of community self-governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11698v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Lloyd, Jennah Gosciak, Tung Nguyen, Mor Naaman</dc:creator>
    </item>
    <item>
      <title>Faster Local Solvers for Graph Diffusion Equations</title>
      <link>https://arxiv.org/abs/2410.21634</link>
      <description>arXiv:2410.21634v2 Announce Type: replace-cross 
Abstract: Efficient computation of graph diffusion equations (GDEs), such as Personalized PageRank, Katz centrality, and the Heat kernel, is crucial for clustering, training neural networks, and many other graph-related problems. Standard iterative methods require accessing the whole graph per iteration, making them time-consuming for large-scale graphs. While existing local solvers approximate diffusion vectors through heuristic local updates, they often operate sequentially and are typically designed for specific diffusion types, limiting their applicability. Given that diffusion vectors are highly localizable, as measured by the participation ratio, this paper introduces a novel framework for approximately solving GDEs using a local diffusion process. This framework reveals the suboptimality of existing local solvers. Furthermore, our approach effectively localizes standard iterative solvers by designing simple and provably sublinear time algorithms. These new local solvers are highly parallelizable, making them well-suited for implementation on GPUs. We demonstrate the effectiveness of our framework in quickly obtaining approximate diffusion vectors, achieving up to a hundred-fold speed improvement, and its applicability to large-scale dynamic graphs. Our framework could also facilitate more efficient local message-passing mechanisms for GNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21634v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiahe Bai, Baojian Zhou, Deqing Yang, Yanghua Xiao</dc:creator>
    </item>
  </channel>
</rss>
