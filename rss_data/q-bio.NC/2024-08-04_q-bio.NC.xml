<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Aug 2024 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Linton Stereo Illusion</title>
      <link>https://arxiv.org/abs/2408.00770</link>
      <description>arXiv:2408.00770v1 Announce Type: new 
Abstract: We present a new illusion that challenges our understanding of stereo vision. The illusion consists of a small circle (at 40cm) in front of a large circle (at 50cm), with constant angular sizes throughout. We move the large circle forward by 10cm (to 40cm) and back again (to 50cm). What distance should we move the small circle forward and back, so the circles look like they are moving rigidly in depth together? Constant physical distance (10cm) or constant disparity (6.7cm)? Observers choose constant disparity. This leads us to four conclusions: First, perceived stereo depth appears to reflect retinal disparities, not 3D geometry. Second, doubling disparity appears to double perceived depth, suggesting that perceived stereo depth is proportional to disparity. Third, changes in vergence appear to have no effect on perceived depth. Fourth, stereo 'depth constancy' appears to be a cognitive (not perceptual) phenomenon, reflecting our experience of a world distorted in perceived stereo depth. Finally, when angular size is not held constant, the illusion is no longer noticeable. However, the perceived stereo depth remains the same in both conditions, suggesting that this looming cue only affects our judgment, but not our visual experience, of motion in depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00770v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Linton</dc:creator>
    </item>
    <item>
      <title>Dynamic transitions of blind spots in the Hermann grid illusion</title>
      <link>https://arxiv.org/abs/2408.00782</link>
      <description>arXiv:2408.00782v1 Announce Type: new 
Abstract: Hermann discovered the grid illusion in 1870, but its cause has remained a mystery for more than 150 years. In 1960, Baumgartner proposed a hypothesis for the illusion based on neural receptive fields, but Geier presented a counterexample in 2008. In 1994, Spillmann devised the scintillating grid illusion, an improvement on the Hermann grid illusion. I propose that a hypothesis involving blind spots (optic discs) can significantly contribute to unraveling the mystery of the grid illusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00782v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutaka Nishiyama</dc:creator>
    </item>
    <item>
      <title>Synergistic pathways of modulation enable robust task packing within neural dynamics</title>
      <link>https://arxiv.org/abs/2408.01316</link>
      <description>arXiv:2408.01316v1 Announce Type: new 
Abstract: Understanding how brain networks learn and manage multiple tasks simultaneously is of interest in both neuroscience and artificial intelligence. In this regard, a recent research thread in theoretical neuroscience has focused on how recurrent neural network models and their internal dynamics enact multi-task learning. To manage different tasks requires a mechanism to convey information about task identity or context into the model, which from a biological perspective may involve mechanisms of neuromodulation. In this study, we use recurrent network models to probe the distinctions between two forms of contextual modulation of neural dynamics, at the level of neuronal excitability and at the level of synaptic strength. We characterize these mechanisms in terms of their functional outcomes, focusing on their robustness to context ambiguity and, relatedly, their efficiency with respect to packing multiple tasks into finite size networks. We also demonstrate distinction between these mechanisms at the level of the neuronal dynamics they induce. Together, these characterizations indicate complementarity and synergy in how these mechanisms act, potentially over multiple time-scales, toward enhancing robustness of multi-task learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01316v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Vedovati, ShiNung Ching</dc:creator>
    </item>
    <item>
      <title>Human foraging strategies flexibly adapt to resource distribution and time constraints</title>
      <link>https://arxiv.org/abs/2408.01350</link>
      <description>arXiv:2408.01350v1 Announce Type: new 
Abstract: Foraging is a crucial activity, yet the extent to which humans employ flexible versus rigid strategies remains unclear. This study investigates how individuals adapt their foraging strategies in response to resource distribution and foraging time constraints. For this, we designed a video-game-like foraging task that requires participants to navigate a four-areas environment to collect coins from treasure boxes within a limited time. This task engages multiple cognitive abilities, such as navigation, learning, and memorization of treasure box locations. Findings indicate that participants adjust their foraging strategies -- encompassing both stay-or-leave decisions, such as the number of boxes opened in initial areas and behavioral aspects, such as the time to navigate from box to box -- depending on both resource distribution and foraging time. Additionally, they improved their performance over time as an effect of both enhanced navigation skills and adaptation of foraging strategies. Finally, participants' performance was initially distant from the reward-maximizing performance of optimal agents due to the learning process humans undergo; however, it approximated the optimal agent's performance towards the end of the task, without fully reaching it. These results highlight the flexibility of human foraging behavior and underscore the importance of employing optimality models and ecologically rich scenarios to study foraging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01350v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Valeria Simonelli, Davide Nuzzi, Gian Luca Lancia, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation</title>
      <link>https://arxiv.org/abs/2408.00777</link>
      <description>arXiv:2408.00777v1 Announce Type: cross 
Abstract: Multi-modal neuroimaging analysis is crucial for a comprehensive understanding of brain function and pathology, as it allows for the integration of different imaging techniques, thus overcoming the limitations of individual modalities. However, the high costs and limited availability of certain modalities pose significant challenges. To address these issues, this paper proposed the Condition-Aligned Temporal Diffusion (CATD) framework for end-to-end cross-modal synthesis of neuroimaging, enabling the generation of functional magnetic resonance imaging (fMRI)-detected Blood Oxygen Level Dependent (BOLD) signals from more accessible Electroencephalography (EEG) signals. By constructing Conditionally Aligned Block (CAB), heterogeneous neuroimages are aligned into a potential space, achieving a unified representation that provides the foundation for cross-modal transformation in neuroimaging. The combination with the constructed Dynamic Time-Frequency Segmentation (DTFS) module also enables the use of EEG signals to improve the temporal resolution of BOLD signals, thus augmenting the capture of the dynamic details of the brain. Experimental validation demonstrated the effectiveness of the framework in improving the accuracy of neural activity prediction, identifying abnormal brain regions, and enhancing the temporal resolution of BOLD signals. The proposed framework establishes a new paradigm for cross-modal synthesis of neuroimaging by unifying heterogeneous neuroimaging data into a potential representation space, showing promise in medical applications such as improving Parkinson's disease prediction and identifying abnormal brain regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00777v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiheng Yao, Shuqiang Wang</dc:creator>
    </item>
    <item>
      <title>Domain Adaptation-Enhanced Searchlight: Enabling brain decoding from visual perception to mental imagery</title>
      <link>https://arxiv.org/abs/2408.01163</link>
      <description>arXiv:2408.01163v1 Announce Type: cross 
Abstract: In cognitive neuroscience and brain-computer interface research, accurately predicting imagined stimuli is crucial. This study investigates the effectiveness of Domain Adaptation (DA) in enhancing imagery prediction using primarily visual data from fMRI scans of 18 subjects. Initially, we train a baseline model on visual stimuli to predict imagined stimuli, utilizing data from 14 brain regions. We then develop several models to improve imagery prediction, comparing different DA methods. Our results demonstrate that DA significantly enhances imagery prediction, especially with the Regular Transfer approach. We then conduct a DA-enhanced searchlight analysis using Regular Transfer, followed by permutation-based statistical tests to identify brain regions where imagery decoding is consistently above chance across subjects. Our DA-enhanced searchlight predicts imagery contents in a highly distributed set of brain regions, including the visual cortex and the frontoparietal cortex, thereby outperforming standard cross-domain classification methods. The complete code and data for this paper have been made openly available for the use of the scientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01163v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alexander Olza, David Soto, Roberto Santana</dc:creator>
    </item>
    <item>
      <title>Metareasoning in uncertain environments: a meta-BAMDP framework</title>
      <link>https://arxiv.org/abs/2408.01253</link>
      <description>arXiv:2408.01253v1 Announce Type: cross 
Abstract: In decision-making scenarios, \textit{reasoning} can be viewed as an algorithm $P$ that makes a choice of an action $a^* \in \mathcal{A}$, aiming to optimize some outcome such as maximizing the value function of a Markov decision process (MDP). However, executing $P$ itself may bear some costs (time, energy, limited capacity, etc.) and needs to be considered alongside explicit utility obtained by making the choice in the underlying decision problem. Such costs need to be taken into account in order to accurately model human behavior, as well as optimizing AI planning, as all physical systems are bound to face resource constraints. Finding the right $P$ can itself be framed as an optimization problem over the space of reasoning processes $P$, generally referred to as \textit{metareasoning}. Conventionally, human metareasoning models assume that the agent knows the transition and reward distributions of the underlying MDP. This paper generalizes such models by proposing a meta Bayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning in environments with unknown reward/transition distributions, which encompasses a far larger and more realistic set of planning problems that humans and AI systems face. As a first step, we apply the framework to two-armed Bernoulli bandit (TABB) tasks, which have often been used to study human decision making. Owing to the meta problem's complexity, our solutions are necessarily approximate, but nevertheless robust within a range of assumptions that are arguably realistic for human decision-making scenarios. These results offer a normative framework for understanding human exploration under cognitive constraints. This integration of Bayesian adaptive strategies with metareasoning enriches both the theoretical landscape of decision-making research and practical applications in designing AI systems that plan under uncertainty and resource constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01253v1</guid>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakhar Godara, Tilman Diego Al\'eman, Angela J. Yu</dc:creator>
    </item>
    <item>
      <title>A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes</title>
      <link>https://arxiv.org/abs/2408.01322</link>
      <description>arXiv:2408.01322v1 Announce Type: cross 
Abstract: How we perceive objects around us depends on what we actively attend to, yet our eye movements depend on the perceived objects. Still, object segmentation and gaze behavior are typically treated as two independent processes. Drawing on an information processing pattern from robotics, we present a mechanistic model that simulates these processes for dynamic real-world scenes. Our image-computable model uses the current scene segmentation for object-based saccadic decision-making while using the foveated object to refine its scene segmentation recursively. To model this refinement, we use a Bayesian filter, which also provides an uncertainty estimate for the segmentation that we use to guide active scene exploration. We demonstrate that this model closely resembles observers' free viewing behavior, measured by scanpath statistics, including foveation duration and saccade amplitude distributions used for parameter fitting and higher-level statistics not used for fitting. These include how object detections, inspections, and returns are balanced and a delay of returning saccades without an explicit implementation of such temporal inhibition of return. Extensive simulations and ablation studies show that uncertainty promotes balanced exploration and that semantic object cues are crucial to form the perceptual units used in object-based attention. Moreover, we show how our model's modular design allows for extensions, such as incorporating saccadic momentum or pre-saccadic attention, to further align its output with human scanpaths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01322v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vito Mengers, Nicolas Roth, Oliver Brock, Klaus Obermayer, Martin Rolfs</dc:creator>
    </item>
    <item>
      <title>Self-Organized Criticality Explains Readiness Potential</title>
      <link>https://arxiv.org/abs/2209.09075</link>
      <description>arXiv:2209.09075v2 Announce Type: replace 
Abstract: Readiness potential is a widely observed brain activity in several species including crayfish before the spontaneous behavioral initiation. However, it is poorly understood how this spontaneous activity is generated. The hypothesis that some specific, dedicated site is responsible for the spontaneity has been questioned. Here, by using intracellular recording and staining of the brain neurons in crayfish and modeling using the sandpile, which is the original model of self-organized criticality (SOC), we show that readiness potential can emerge everywhere in the brain because it is a SOC system. Despite the diversity in neurons and their morphology, brain neurons showed signatures of criticality and readiness potential. We find that the previously known readiness potential in a neuron is a consequence of the critical behavior of the entire network. Indeed, seemingly unrelated membrane potential activity in neurons in different animals can shape readiness potential when its time series are averaged after their alignment with respect to the spontaneous behavioral initiation. We show that the sandpile model not made for the potential, can form the premovement buildup activity similar to readiness potential. Scaling properties of the synaptic avalanches are in line with those of vertebrate species; thus, not only is the critical brain hypothesis supported in crayfish, but our findings might also provide a unified view of the basis of spontaneity in animal behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.09075v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katsushi Kagaya, Tomoyuki Kubota, Kohei Nakajima</dc:creator>
    </item>
    <item>
      <title>Aligned and oblique dynamics in recurrent neural networks</title>
      <link>https://arxiv.org/abs/2307.07654</link>
      <description>arXiv:2307.07654v3 Announce Type: replace 
Abstract: The relation between neural activity and behaviorally relevant variables is at the heart of neuroscience research. When strong, this relation is termed a neural representation. There is increasing evidence, however, for partial dissociations between activity in an area and relevant external variables. While many explanations have been proposed, a theoretical framework for the relationship between external and internal variables is lacking. Here, we utilize recurrent neural networks (RNNs) to explore the question of when and how neural dynamics and the network's output are related from a geometrical point of view. We find that training RNNs can lead to two dynamical regimes: dynamics can either be aligned with the directions that generate output variables, or oblique to them. We show that the choice of readout weight magnitude before training can serve as a control knob between the regimes, similar to recent findings in feedforward networks. These regimes are functionally distinct. Oblique networks are more heterogeneous and suppress noise in their output directions. They are furthermore more robust to perturbations along the output directions. Crucially, the oblique regime is specific to recurrent (but not feedforward) networks, arising from dynamical stability considerations. Finally, we show that tendencies towards the aligned or the oblique regime can be dissociated in neural recordings. Altogether, our results open a new perspective for interpreting neural activity by relating network dynamics and their output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07654v3</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Friedrich Schuessler, Francesca Mastrogiuseppe, Srdjan Ostojic, Omri Barak</dc:creator>
    </item>
    <item>
      <title>A mathematical model of the visual MacKay effect</title>
      <link>https://arxiv.org/abs/2311.07338</link>
      <description>arXiv:2311.07338v5 Announce Type: replace-cross 
Abstract: This paper investigates the intricate connection between visual perception and the mathematical modeling of neural activity in the primary visual cortex (V1). The focus is on modeling the visual MacKay effect [D. M. MacKay, Nature, 180 (1957), pp. 849--850]. While bifurcation theory has been a prominent mathematical approach for addressing issues in neuroscience, especially in describing spontaneous pattern formations in V1 due to parameter changes, it faces challenges in scenarios with localized sensory inputs. This is evident, for instance, in MacKay's psychophysical experiments, where the redundancy of visual stimuli information results in irregular shapes, making bifurcation theory and multiscale analysis less effective. To address this, we follow a mathematical viewpoint based on the input-output controllability of an Amari-type neural fields model. In this framework, we consider sensory input as a control function, a cortical representation via the retino-cortical map of the visual stimulus that captures its distinct features. This includes highly localized information in the center of MacKay's funnel pattern "MacKay rays". From a control theory point of view, the Amari-type equation's exact controllability property is discussed for linear and nonlinear response functions. For the visual MacKay effect modeling, we adjust the parameter representing intra-neuron connectivity to ensure that cortical activity exponentially stabilizes to the stationary state in the absence of sensory input. Then, we perform quantitative and qualitative studies to demonstrate that they capture all the essential features of the induced after-image reported by MacKay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07338v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Dario Prandi, Yacine Chitour</dc:creator>
    </item>
  </channel>
</rss>
