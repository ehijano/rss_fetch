<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Nov 2025 05:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Closing the SNAP Gap: Identifying Under-Enrollment in High-Poverty ZIP Codes</title>
      <link>https://arxiv.org/abs/2511.00080</link>
      <description>arXiv:2511.00080v1 Announce Type: new 
Abstract: This project began by constructing an index of economic insecurity using multiple socioeconomic indicators. Although poverty alone predicted SNAP participation more accurately than the composite index, its explanatory power was weaker than anticipated, echoing past findings that enrollment cannot be explained by income alone. This led to a shift in focus: identifying ZIP codes with high poverty but unexpectedly low SNAP participation, areas defined here as having a SNAP Gap, where ZIPs fall in the top 30 percent of family poverty and the bottom 10 percent of SNAP enrollment. Using nationally available ZIP level data from 2014 to 2023, I trained logistic classification models on four interpretable structural indicators: lack of vehicle, lack of internet access, lack of computer access, and percentage of adults with only a high school diploma. The most effective model relies on just two predictors, vehicle access and education, and outperforms tree based classifiers in both precision and calibration. Results show that economic insecurity is consistently concentrated in rural ZIP codes, with transportation access emerging as the most stable barrier to program take up. This study provides a nationwide diagnostic framework that can inform the development of scalable screening tools for targeting outreach and improving benefit access in underserved communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00080v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Auyona Ray</dc:creator>
    </item>
    <item>
      <title>Different Forms of Imbalance in Strongly Playable Discrete Games I: Two-Player RPS Games</title>
      <link>https://arxiv.org/abs/2511.00374</link>
      <description>arXiv:2511.00374v1 Announce Type: new 
Abstract: We construct several definitions of imbalance and playability, both of which are related to the existence of dominated strategies. Specifically, a maximally balanced game and a playable game cannot have dominated strategies for any player. In this context, imbalance acts as a measure of inequality in strategy, similar to measures of inequality in wealth or population dynamics. Conversely, playability is a slight strengthening of the condition that a game has no dominated strategies. It is more accurately aligned with the intuition that all strategies should see play. We show that these balance definitions are natural by exhibiting a (2n+1)-RPS that maximizes all proposed imbalance definitions among playable RPS games. We demonstrate here that this form of imbalance aligns with the prevailing notion that different definitions of inequality for economic and game-theoretic distributions must agree on both the maximal and minimal cases. In the sequel paper, we utilize these definitions for multiplayer games to demonstrate that a generalization of this imbalanced RPS is at least nearly maximally imbalanced while remaining playable for under 50 players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00374v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Itai Maimon</dc:creator>
    </item>
    <item>
      <title>Modeling Uncertainty in Integrated Assessment Models</title>
      <link>https://arxiv.org/abs/2511.00378</link>
      <description>arXiv:2511.00378v1 Announce Type: new 
Abstract: Integrated Assessment Models (IAMs) are pivotal tools that synthesize knowledge from climate science, economics, and policy to evaluate the interactions between human activities and the climate system. They serve as essential instruments for policymakers, providing insights into the potential outcomes of various climate policies and strategies. Given the complexity and inherent uncertainties in both the climate system and socio-economic processes, understanding and effectively managing uncertainty within IAMs is crucial for robust climate policy development. This review aims to provide a comprehensive overview of how IAMs handle uncertainty, highlighting recent methodological advancements and their implications for climate policy. I examine the types of uncertainties present in IAMs, discuss various modeling approaches to address these uncertainties, and explore recent developments in the field, including the incorporation of advanced computational methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00378v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongyang Cai</dc:creator>
    </item>
    <item>
      <title>A rich life cycle model of labor supply in Finland</title>
      <link>https://arxiv.org/abs/2511.00660</link>
      <description>arXiv:2511.00660v1 Announce Type: new 
Abstract: A life cycle model of consumption and labor supply describes employment decisions of a collection of individuals during their lifetime. We develop a life cycle model describing a heterogeneous population operating in Finland under a wide variety of employment states and life situations. A rich life cycle model requires a large state space representing the possible states of simulated agents. The results demonstrate that the model reproduces a number of statistics of the Finnish employment market such as the age structures of employment rate and unemployment rate, distributions of observed effective marginal tax rates and participating tax rates, and proportion of part time work. As an application of analysis of a reform, we analyze how the program of Orpo government influences employment and public finances in Finland.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00660v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antti J. Tanskanen</dc:creator>
    </item>
    <item>
      <title>Public Infrastructure Investments for Space Market Development</title>
      <link>https://arxiv.org/abs/2511.00935</link>
      <description>arXiv:2511.00935v1 Announce Type: new 
Abstract: Advanced space technology systems often face high fixed costs, can serve limited non-government demand, and are significantly driven by non-market motivations. While increased entrepreneurial activity and national ambitions in space have encouraged planners at public space agencies to develop markets around such systems, the very factors that make the recent growth of the space economy so remarkable also challenge planners' efforts to develop and sustain markets for space-related goods and services. I propose a graphical framework to visualize the number of competitors a market can sustain as a function of the industry's cost structure; the distribution of government support across direct purchases, direct investments, and shared infrastructure; and the magnitude of non-government demand. Building on public goods theory, the framework shows how marginal dollars invested in shared infrastructure can create non-rival benefits supporting more competitors per dollar than direct purchases or subsidies. I demonstrate the framework with a stylized application inspired by NASA's Commercial LEO Destinations program. Under cost and demand conditions consistent with public data, independent stations generate industry-wide losses of $355 million annually, while shared core infrastructure enables industry-wide profits of $154 million annually. I also outline key directions for future research on public investment and market development strategies for advanced technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00935v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akhil Rao</dc:creator>
    </item>
    <item>
      <title>Liquidity Shocks, Homeownership, and Income Inequality: Impact of Early Pension Withdrawals and Reduced Deposit</title>
      <link>https://arxiv.org/abs/2511.01133</link>
      <description>arXiv:2511.01133v1 Announce Type: new 
Abstract: The paper analyzes two government policies affecting housing demand: early withdrawal from pension savings (EW), and reduction of loan deposit (RD). A model incorporating demand feedback on housing prices using Australian data shows both policies raise prices in the short run. RD delays or prevents access for low-income households, particularly in supply-constrained markets. EW improves accessibility across groups and is most efficient when full withdrawal is permitted, but can reduce retirement security if pension grows faster than property prices. The results also indicate that unequal outcomes stem not from price surges themselves but from pre-existing market disparities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01133v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamza Hanbali, Gaurav Khemka, Himasha Warnakulasooriya</dc:creator>
    </item>
    <item>
      <title>Novelty and Impact of Economics Papers</title>
      <link>https://arxiv.org/abs/2511.01211</link>
      <description>arXiv:2511.01211v1 Announce Type: new 
Abstract: We propose a framework that recasts scientific novelty not as a single attribute of a paper, but as a reflection of its position within the evolving intellectual landscape. We decompose this position into two orthogonal dimensions: \textit{spatial novelty}, which measures a paper's intellectual distinctiveness from its neighbors, and \textit{temporal novelty}, which captures its engagement with a dynamic research frontier. To operationalize these concepts, we leverage Large Language Models to develop semantic isolation metrics that quantify a paper's location relative to the full-text literature. Applying this framework to a large corpus of economics articles, we uncover a fundamental trade-off: these two dimensions predict systematically different outcomes. Temporal novelty primarily predicts citation counts, whereas spatial novelty predicts disruptive impact. This distinction allows us to construct a typology of semantic neighborhoods, identifying four archetypes associated with distinct and predictable impact profiles. Our findings demonstrate that novelty can be understood as a multidimensional construct whose different forms, reflecting a paper's strategic location, have measurable and fundamentally distinct consequences for scientific progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01211v1</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaofeng Wu</dc:creator>
    </item>
    <item>
      <title>Internet of Things Platform Service Supply Innovation: Exploring the Impact of Overconfidence</title>
      <link>https://arxiv.org/abs/2511.01332</link>
      <description>arXiv:2511.01332v1 Announce Type: new 
Abstract: This paper explores the impact of manufacturers' overconfidence on their collaborative innovation with platforms in the Internet of Things (IoT) environment by constructing a game model. It is found that in both usage-based and revenue-sharing contracts, manufacturers' and platforms' innovation inputs, profit levels, and pricing strategies are significantly affected by the proportion of non-privacy-sensitive customers, and grow in tandem with the rise of this proportion. In usage-based contracts, moderate overconfidence incentivizes manufacturers to increase hardware innovation investment and improve overall supply chain revenues, but may cause platforms to reduce software innovation; under revenue-sharing contracts, overconfidence positively incentivizes hardware innovation and pricing more strongly, while platform software innovation varies nonlinearly depending on the share ratio. Comparing the differences in manufacturers' decisions with and without overconfidence suggests that moderate overconfidence can lead to supply chain Pareto improvements under a given contract. This paper provides new perspectives for understanding the complex interactions between manufacturers and platforms in IoT supply chains, as well as theoretical support and practical guidance for actual business decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01332v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xiufeng Li, Zefang Li</dc:creator>
    </item>
    <item>
      <title>Measuring Domestic Violence. Individual Attitudes and Time Use Within the Household</title>
      <link>https://arxiv.org/abs/2511.01473</link>
      <description>arXiv:2511.01473v1 Announce Type: new 
Abstract: This paper proposes a novel empirical strategy to measure cultural justifications of domestic violence within households, with direct implications for demographic behavior and gender inequality. Leveraging survey data on individual attitudes and high-frequency time-use diaries from Italian couples with children, I construct a composite index that integrates stated beliefs with observed household practices. Using structural equation modeling, I disentangle latent tolerance of domestic violence from reported attitudes and validate the index against both individual and partner characteristics, as well as time allocation patterns. Results reveal systematic heterogeneity by gender, education, and normative environments. Conservative gender and parenthood norms are strong predictors of tolerance, while higher male education reduces it. Tolerance of violence is also positively associated with reported leisure time with partners and children, suggesting that co-presence does not necessarily reflect egalitarian interaction but may coexist with unequal bargaining structures. Beyond advancing measurement, the findings highlight how cultural tolerance of domestic violence is embedded in household arrangements that influence fertility, labor supply, and the intergenerational transmission of norms. The proposed framework offers a scalable tool for economists and policymakers to monitor hidden inequalities and design interventions targeting family stability, gender equity, and child well-being.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01473v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elena Pisanelli</dc:creator>
    </item>
    <item>
      <title>Gendered Responses to Subtle Social Pressure: Experimental Evidence from Survey Results</title>
      <link>https://arxiv.org/abs/2511.01565</link>
      <description>arXiv:2511.01565v1 Announce Type: new 
Abstract: This study analyzes whether subtle variations in the survey questionnaire phrasing influence participant engagement and whether these effects differ by gender. Building on theories of social pressure and politeness norms, it is hypothesized that presumptive phrasing would reduce engagement compared to appreciative phrasing and baseline phrasing (H1), and this effect would be more pronounced among women (H2). Mixed-effects regression models showed no significant treatment effects on any outcome and no evidence of gender moderation for 164 participants and 492 observations. The only robust finding was a small negative baseline sentiment across all participants, independent of any treatment or gender. The findings contribute to refining theoretical expectations about the conditions in which linguistic framing and gender norms shape behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01565v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sevgi \c{C}olak</dc:creator>
    </item>
    <item>
      <title>Deceptively Framed Lotteries in Consumer Markets</title>
      <link>https://arxiv.org/abs/2511.01597</link>
      <description>arXiv:2511.01597v1 Announce Type: new 
Abstract: Consumers often face products sold as lotteries rather than fixed outcomes. A prominent case is the loot box in video games, where players pay for randomized rewards. We investigate how presentation formats shape consumer beliefs and willingness to pay. In an online experiment with 802 participants, sellers could frame lotteries using two common manipulations: censoring outcome probabilities and selectively highlighting rare successes. More than 80\% of sellers adopted such deceptive frames, particularly when both manipulations were available. These choices substantially inflated buyer beliefs and increased willingness to pay of up to six times the expected value. Sellers anticipated this effect and raised prices accordingly. Our results show how deceptive framing systematically shifts consumer beliefs and enables firms to extract additional surplus. For marketing practice, this highlights the strategic value of framing tools in probabilistic selling models; for policy, it underscores the importance of transparency requirements in protecting consumers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01597v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Dertwinkel-Kalt, Hans-Theo Normann, Jan-Niklas Tiede, Tobias Werner</dc:creator>
    </item>
    <item>
      <title>Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales</title>
      <link>https://arxiv.org/abs/2511.00552</link>
      <description>arXiv:2511.00552v1 Announce Type: cross 
Abstract: Accurate multi-horizon retail forecasts are critical for inventory and promotions. We present a novel study of weekly Walmart sales (45 stores, 2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store identifiers with time-varying exogenous signals (holidays, CPI, fuel price, temperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via Quantile Loss, yielding calibrated 90\% prediction intervals and interpretability through variable-selection networks, static enrichment, and temporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of \$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold chronological cross-validation, the averages are RMSE = \$64.6k USD and $R^2$ = 0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These results demonstrate practical value for inventory planning and holiday-period optimization, while maintaining model transparency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00552v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Santhi Bharath Punati, Sandeep Kanta, Udaya Bhasker Cheerala, Madhusudan G Lanjewar, Praveen Damacharla</dc:creator>
    </item>
    <item>
      <title>Low-Cost Carriers in Aviation: Significance and Developments</title>
      <link>https://arxiv.org/abs/2511.00932</link>
      <description>arXiv:2511.00932v1 Announce Type: cross 
Abstract: This paper aims to discuss the impacts of low-cost airlines on the air transport market and, in particular, to present the most recent findings from the specialized literature in this field. To this end, several papers published on the topic since 2015 were selected and analyzed. Based on this analysis, the main subjects addressed in the studies were categorized into five groups: (i) impacts of low-cost airlines on competing carriers; (ii) impacts on airports; (iii) general effects on air transport demand; (iv) effects on passengers' choice processes; and (v) broader effects on geographical regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00932v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>eess.SY</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.17506763</arxiv:DOI>
      <arxiv:journal_reference>Communications in Airline Economics Research, 1, 10671650 (2024) 1-5</arxiv:journal_reference>
      <dc:creator>Bruno Felipe de Oliveira, Alessandro V. M. Oliveira</dc:creator>
    </item>
    <item>
      <title>Large-Scale Education Reform in General Equilibrium: Regression Discontinuity Evidence from India: Comment</title>
      <link>https://arxiv.org/abs/2303.11956</link>
      <description>arXiv:2303.11956v5 Announce Type: replace 
Abstract: Mainly through regression discontinuity designs, Khanna (2023a) studies the impacts of a primary schooling expansion in India in the 1990s. Absent from the data set are four districts close to the modeled treatment discontinuity. Incorporating them cuts the impact of intention to treat on schooling attainment by two-thirds and the impact on wages by a third. Methodological revisions, including clustering by the geographic unit of treatment, double or triple standard errors, bringing estimates within a standard error of zero. These findings are robust to varying the location of the discontinuity, the bandwidth, and the radius of an exclusionary "donut." The estimates of the general equilibrium effect on the skill premium, as well as elasticities of substitution across age and skill groups, have high variance. One cause is that the treatment discontinuity does not occur quite where modeled. Moving the assumed cutoff pro-duces sharper but wrong-signed results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11956v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>David Roodman</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion under Observed Demand Shocks</title>
      <link>https://arxiv.org/abs/2502.15084</link>
      <description>arXiv:2502.15084v3 Announce Type: replace 
Abstract: This paper examines how the observability of demand shocks shapes the learning outcomes of pricing algorithms. The simulation results show that Q-learning agents autonomously adapt to demand fluctuations and develop demand-contingent pricing, which is procyclical at high $\delta$ and countercyclical at low $\delta$, consistent with Rotemberg and Saloner (1986). They also sustain supracompetitive profits, demonstrating the robustness of algorithmic collusion under observed demand shocks. Further analysis reveals that the learned pricing patterns critically depend on the information embedded in the state variable. Removing demand memory weakens demand-contingent pricing and drives learning toward rigid pricing. Price memory has a more complex effect: at high $\delta$, agents learn procyclical pricing regardless of whether price memory is present, whereas at low $\delta$, the absence of price memory leads to uniformly rigid pricing, making it essential for sustaining countercyclical pricing. These findings shed light on how Q-learning agents generate distinctive demand-contingent pricing patterns across $\delta$. Through repeated exposure to payoff variation across demand states and prices, they capture both the stronger deviation incentives that arise during booms and the discount factor's role in balancing short-term gains and long-term continuation values, thereby reproducing the pricing patterns predicted by collusion theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15084v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zexin Ye</dc:creator>
    </item>
    <item>
      <title>The Labor Market Incidence of New Technologies</title>
      <link>https://arxiv.org/abs/2504.04047</link>
      <description>arXiv:2504.04047v2 Announce Type: replace 
Abstract: This paper develops a new framework to analyze the incidence of labor market shocks, focusing on automation and artificial intelligence. Central to our theory is the distance-dependent elasticity of substitution (DIDES), where worker mobility between occupations declines with their distance in skill space. Mapping 306 occupations into cognitive, manual, and interpersonal skill dimensions, we estimate a low-dimensional latent skill model that preserves granular substitution patterns. We show that both automation and artificial intelligence cluster within skill-adjacent occupations, constraining employment adjustment and amplifying wage effects. The clustering nature of technologies generates unequal outcomes: 20--50% of labor demand shocks translate to wages (versus 30% under standard models), while mobility recovers only 20\% of losses (versus 30% from standard estimates).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04047v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tianyu Fan</dc:creator>
    </item>
    <item>
      <title>Scenario-based actuarial climate risk assessment via calibration of the DICE model to the shared socioeconomic pathways</title>
      <link>https://arxiv.org/abs/2504.11721</link>
      <description>arXiv:2504.11721v2 Announce Type: replace 
Abstract: Accounting for climate-related risks is an emerging problem for life insurers around the world. In this paper, we demonstrate how scenario trajectories for global temperature can be obtained using the cost-benefit Dynamic Integrated Climate-Economy (DICE) model calibrated to the five Shared Socioeconomic Pathways (SSPs). These scenarios can also be calculated under different carbon emission mitigation targets such as achieving net-zero carbon emissions by a specific year. We show how to calibrate the DICE model to align industrial and land-use carbon emissions with projections from six leading process-based integrated assessment models (IAMs): IMAGE, MESSAGE--GLOBIOM, AIM/CGE, GCAM, REMIND--MAgPIE and WITCH--GLOBIOM. The obtained scenario trajectories of global temperature can be linked to the climate-change induced excess mortality in various regions that, in turn, can be used for stress testing of life insurance portfolios. We illustrate this using synthetic portfolios of life insurance and annuity products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11721v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisuke Murakami, Pavel V. Shevchenko, Tomoko Matsui, Aleksandar Arandjelovi\'c, Tor A. Myrvoll</dc:creator>
    </item>
    <item>
      <title>Algorithmic Assistance with Recommendation-Dependent Preferences</title>
      <link>https://arxiv.org/abs/2208.07626</link>
      <description>arXiv:2208.07626v4 Announce Type: replace-cross 
Abstract: When an algorithm provides risk assessments, we typically think of them as helpful inputs to human decisions, such as when risk scores are presented to judges or doctors. However, a decision-maker may react not only to the information provided by the algorithm. The decision-maker may also view the algorithmic recommendation as a default action, making it costly for them to deviate, such as when a judge is reluctant to overrule a high-risk assessment for a defendant or a doctor fears the consequences of deviating from recommended procedures. To address such unintended consequences of algorithmic assistance, we propose a model of joint human-machine decision-making. Within this model, we consider the effect and design of algorithmic recommendations when they affect choices not just by shifting beliefs, but also by altering preferences. We motivate this assumption from institutional factors, such as a desire to avoid audits, as well as from well-established models in behavioral science that predict loss aversion relative to a reference point. We show that recommendation-dependent preferences create inefficiencies where the decision-maker is overly responsive to the recommendation. As a remedy, we discuss algorithms that strategically withhold recommendations and show how they can improve the quality of final decisions. Concretely, we prove that an intuitive algorithm achieves minimax optimality by sending recommendations only when it is confident that their implementation would improve over an unassisted baseline decision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07626v4</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bryce McLaughlin, Jann Spiess</dc:creator>
    </item>
    <item>
      <title>Coping with the Dunkelflaute: Power system implications of variable renewable energy droughts in Europe</title>
      <link>https://arxiv.org/abs/2411.17683</link>
      <description>arXiv:2411.17683v5 Announce Type: replace-cross 
Abstract: Coping with prolonged periods of low availability of wind and solar power, also referred to as renewable energy droughts or "Dunkelflaute", emerges as a key challenge for realizing decarbonized energy systems based on renewable energy sources. Here we investigate the role of long-duration electricity storage and geographical balancing in dealing with such events, combining a time series analysis of renewable availability with power sector modeling of 35 historical weather years. We find that extreme droughts define long-duration storage operation and investment. Assuming policy-relevant interconnection in our model, we find 351 TWh long-duration storage capacity or 7% of yearly electricity demand in the least-cost system that can cope with the most extreme event in Europe. While nuclear power can partially reduce storage needs, the storage-mitigating effect of fossil backup plants in combination with carbon removal is limited. Policymakers and system planners should prepare for a rapid expansion of long-duration storage to safeguard the renewable energy transition in Europe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17683v5</guid>
      <category>physics.soc-ph</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Kittel, Alexander Roth, Wolf-Peter Schill</dc:creator>
    </item>
    <item>
      <title>Computational Basis of LLM's Decision Making in Social Simulation</title>
      <link>https://arxiv.org/abs/2504.11671</link>
      <description>arXiv:2504.11671v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) increasingly serve as human-like decision-making agents in social science and applied settings. These LLM-agents are typically assigned human-like characters and placed in real-life contexts. However, how these characters and contexts shape an LLM's behavior remains underexplored. This study proposes and tests methods for probing, quantifying, and modifying an LLM's internal representations in a Dictator Game -- a classic behavioral experiment on fairness and prosocial behavior. We extract "vectors of variable variations" (e.g., "male" to "female") from the LLM's internal state. Manipulating these vectors during the model's inference can substantially alter how those variables relate to the model's decision-making. This approach offers a principled way to study and regulate how social concepts can be encoded and engineered within transformer-based models, with implications for alignment, debiasing, and designing AI agents for social simulations in both academic and commercial applications, strengthening sociological theory and measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11671v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ji Ma</dc:creator>
    </item>
    <item>
      <title>Mean-Field Price Formation on Trees: with Multi-Population and Non-Rational Agents</title>
      <link>https://arxiv.org/abs/2510.11261</link>
      <description>arXiv:2510.11261v2 Announce Type: replace-cross 
Abstract: This work solves the equilibrium price formation problem for the risky stock by combining mean-field game theory with the binomial tree framework, following the classic approach of Cox, Ross &amp; Rubinstein. For agents with exponential and recursive utilities of exponential-type, we prove the existence of a unique mean-field market-clearing equilibrium and derive an explicit analytic formula for equilibrium transition probabilities of the stock price on the binomial lattice. The agents face stochastic terminal liabilities and incremental endowments that depend on unhedgeable common and idiosyncratic factors, in addition to the stock price path. We also incorporate an external order flow. Furthermore, the analytic tractability of the proposed approach allows us to extend the framework in two important directions: First, we incorporate multi-population heterogeneity, allowing agents to differ in functional forms for their liabilities, endowments, and risk coefficients. Second, we relax the rational expectations hypothesis by modeling agents operating under subjective probability measures which induce stochastically biased views on the stock transition probabilities. Our numerical examples illustrate the qualitative effects of these components on the equilibrium price distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11261v2</guid>
      <category>q-fin.MF</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Masaaki Fujii</dc:creator>
    </item>
  </channel>
</rss>
