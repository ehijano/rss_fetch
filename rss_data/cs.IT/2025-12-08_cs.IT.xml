<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Dec 2025 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Low-Complexity OFDM Deep Neural Receivers</title>
      <link>https://arxiv.org/abs/2512.05249</link>
      <description>arXiv:2512.05249v1 Announce Type: new 
Abstract: Deep neural receivers (NeuralRxs) for Orthogonal Frequency Division Multiplexing (OFDM) signals are proposed for enhanced decoding performance compared to their signal-processing based counterparts. However, the existing architectures ignore the required number of epochs for training convergence and floating-point operations (FLOPs), which increase significantly with improving performance. To tackle these challenges, we propose a new residual network (ResNet) block design for OFDM NeuralRx. Specifically, we leverage small kernel sizes and dilation rates to lower the number of FLOPs (NFLOPs) and uniform channel sizes to reduce the memory access cost (MAC). The ResNet block is designed with novel channel split and shuffle blocks, element-wise additions are removed, with Gaussian error linear unit (GELU) activations. Extensive simulations show that our proposed NeuralRx reduces NFLOPs and improves training convergence while improving the decoding accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05249v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankit Gupta, Onur Dizdar, Yun Chen, Fehmi Emre Kadan, Ata Sattarzadeh, Stephen Wang</dc:creator>
    </item>
    <item>
      <title>Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective</title>
      <link>https://arxiv.org/abs/2512.05267</link>
      <description>arXiv:2512.05267v1 Announce Type: new 
Abstract: In context-specific applications such as robotics, telecommunications, and healthcare, artificial intelligence systems often face the challenge of limited training data. This scarcity introduces epistemic uncertainty, i.e., reducible uncertainty stemming from incomplete knowledge of the underlying data distribution, which fundamentally limits predictive performance. This review paper examines formal methodologies that address data-limited regimes through two complementary approaches: quantifying epistemic uncertainty and mitigating data scarcity via synthetic data augmentation. We begin by reviewing generalized Bayesian learning frameworks that characterize epistemic uncertainty through generalized posteriors in the model parameter space, as well as ``post-Bayes'' learning frameworks. We continue by presenting information-theoretic generalization bounds that formalize the relationship between training data quantity and predictive uncertainty, providing a theoretical justification for generalized Bayesian learning. Moving beyond methods with asymptotic statistical validity, we survey uncertainty quantification methods that provide finite-sample statistical guarantees, including conformal prediction and conformal risk control. Finally, we examine recent advances in data efficiency by combining limited labeled data with abundant model predictions or synthetic data. Throughout, we take an information-theoretic perspective, highlighting the role of information measures in quantifying the impact of data scarcity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05267v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osvaldo Simeone, Yaniv Romano</dc:creator>
    </item>
    <item>
      <title>Foundations of information theory for coding theory</title>
      <link>https://arxiv.org/abs/2512.05316</link>
      <description>arXiv:2512.05316v1 Announce Type: new 
Abstract: Information theory is introduced in this lecture note with a particular emphasis on its relevance to algebraic coding theory. The document develops the mathematical foundations for quantifying uncertainty and information transmission by building upon Shannon's pioneering formulation of information, entropy, and channel capacity. Examples, including the binary symmetric channel, illustrate key concepts such as entropy, conditional entropy, mutual information, and the noisy channel model. Furthermore, the note describes the principles of maximum likelihood decoding and Shannon's noisy channel coding theorem, which characterizes the theoretical limits of reliable communication over noisy channels. Students and researchers seeking a connection between probabilistic frameworks of information theory and structural and algebraic techniques used in modern coding theory will find this work helpful.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05316v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mahdi Mouloua, Essaid Mohamed</dc:creator>
    </item>
    <item>
      <title>Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations</title>
      <link>https://arxiv.org/abs/2512.05156</link>
      <description>arXiv:2512.05156v1 Announce Type: cross 
Abstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\bf Q}$ and ${\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05156v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>q-fin.CP</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Igor Halperin</dc:creator>
    </item>
    <item>
      <title>NeuromorphicRx: From Neural to Spiking Receiver</title>
      <link>https://arxiv.org/abs/2512.05246</link>
      <description>arXiv:2512.05246v1 Announce Type: cross 
Abstract: In this work, we propose a novel energy-efficient spiking neural network (SNN)-based receiver for 5G-NR OFDM system, called neuromorphic receiver (NeuromorphicRx), replacing the channel estimation, equalization and symbol demapping blocks. We leverage domain knowledge to design the input with spiking encoding and propose a deep convolutional SNN with spike-element-wise residual connections. We integrate an SNN with artificial neural network (ANN) hybrid architecture to obtain soft outputs and employ surrogate gradient descent for training. We focus on generalization across diverse scenarios and robustness through quantized aware training. We focus on interpretability of NeuromorphicRx for 5G-NR signals and perform detailed ablation study for 5G-NR signals. Our extensive numerical simulations show that NeuromorphicRx is capable of achieving significant block error rate performance gain compared to 5G-NR receivers and similar performance compared to its ANN-based counterparts with 7.6x less energy consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05246v1</guid>
      <category>cs.NE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankit Gupta, Onur Dizdar, Yun Chen, Fehmi Emre Kadan, Ata Sattarzadeh, Stephen Wang</dc:creator>
    </item>
    <item>
      <title>Universality of asymptotic graph homomorphism</title>
      <link>https://arxiv.org/abs/2512.05357</link>
      <description>arXiv:2512.05357v1 Announce Type: cross 
Abstract: The Shannon capacity of graphs, introduced by Shannon in 1956 to model zero-error communication, asks for determining the rate of growth of independent sets in strong powers of graphs. Much is still unknown about this parameter, for instance whether it is computable. Recent work has established a dual characterization of the Shannon capacity in terms of the asymptotic spectrum of graphs. A core step in this duality theory is to shift focus from Shannon capacity itself to studying the asymptotic relations between graphs, that is, the asymptotic cohomomorphisms. Towards understanding the structure of Shannon capacity, we study the "combinatorial complexity" of asymptotic cohomomorphism. As our main result, we prove that the asymptotic cohomomorphism order is universal for all countable preorders. That is, we prove that any countable preorder can be order-embedded into the asymptotic cohomomorphism order (i.e. appears as a suborder). Previously this was only known for (non-asymptotic) cohomomorphism. Our proof is based on techniques from asymptotic spectrum duality and convex structure of the asymptotic spectrum of graphs. Our approach in fact leads to a new proof of the universality of (non-asymptotic) cohomomorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05357v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Luchnikov, Jim Wittebol, Jeroen Zuiddam</dc:creator>
    </item>
    <item>
      <title>Exploiting Spatial Multiplexing Based on Pixel Antennas: An Antenna Coding Approach</title>
      <link>https://arxiv.org/abs/2512.05706</link>
      <description>arXiv:2512.05706v1 Announce Type: cross 
Abstract: An antenna coding approach for exploiting the spatial multiplexing capability of pixel antennas is proposed. This approach can leverage additional degrees of freedom in the beamspace domain to transmit more information streams. Pixel antennas are a general reconfigurable antenna design where a radiating structure with arbitrary shape and size can be discretized into sub-wavelength elements called pixels which are connected by radio frequency switches. By controlling the switch states, the pixel antenna topology can be flexibly adjusted so that the resulting radiation pattern can be reconfigured for beamspace spatial multiplexing. In this work, we introduce the antenna coder and pattern coder for pixel antennas, provide a multiple-input multiple-output (MIMO) communication system model with antenna coding in the beamspace domain, and derive the spectral efficiency. Utilizing the antenna coder, the radiation pattern of the pixel antenna is analyzed and efficient optimization algorithms are provided for antenna coding design. Numerical simulation results show that the proposed technique using pixel antennas can enhance spectral efficiency of 4-by-4 MIMO by up to 12 bits/s/Hz or equivalently reduce the required transmit power by up to 90% when compared to conventional MIMO, demonstrating the effectiveness of the antenna coding technique in spectral efficiency enhancement and its promise for future sixth generation (6G) wireless communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05706v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixiang Han, Shanpu Shen, Ross Murch</dc:creator>
    </item>
    <item>
      <title>BalLOT: Balanced $k$-means clustering with optimal transport</title>
      <link>https://arxiv.org/abs/2512.05926</link>
      <description>arXiv:2512.05926v1 Announce Type: cross 
Abstract: We consider the fundamental problem of balanced $k$-means clustering. In particular, we introduce an optimal transport approach to alternating minimization called BalLOT, and we show that it delivers a fast and effective solution to this problem. We establish this with a variety of numerical experiments before proving several theoretical guarantees. First, we prove that for generic data, BalLOT produces integral couplings at each step. Next, we perform a landscape analysis to provide theoretical guarantees for both exact and partial recoveries of planted clusters under the stochastic ball model. Finally, we propose initialization schemes that achieve one-step recovery of planted clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05926v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyan Luo, Dustin G. Mixon</dc:creator>
    </item>
    <item>
      <title>Generative Diffusion Model Driven Massive Random Access in Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2505.12382</link>
      <description>arXiv:2505.12382v2 Announce Type: replace 
Abstract: Massive random access is an important technology for achieving ultra-massive connectivity in next-generation wireless communication systems. It aims to address key challenges during the initial access phase, including active user detection (AUD), channel estimation (CE), and data detection (DD). This paper examines massive access in massive multiple-input multiple-output (MIMO) systems, where deep learning is used to tackle the challenging AUD, CE, and DD functions. First, we introduce a Transformer-AUD scheme tailored for variable pilot-length access. This approach integrates pilot length information and a spatial correlation module into a Transformer-based detector, enabling a single model to generalize across various pilot lengths and antenna numbers. Next, we propose a generative diffusion model (GDM)-driven iterative CE and DD framework. The GDM employs a score function to capture the posterior distributions of massive MIMO channels and data symbols. Part of the score function is learned from the channel dataset via neural networks, while the remaining score component is derived in a closed form by applying the symbol prior constellation distribution and known transmission model. Utilizing these posterior scores, we design an asynchronous alternating CE and DD framework that employs a predictor-corrector sampling technique to iteratively generate channel estimation and data detection results during the reverse diffusion process. Simulation results demonstrate that our proposed approaches significantly outperform baseline methods with respect to AUD, CE, and DD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12382v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keke Ying, Zhen Gao, Sheng Chen, Tony Q. S. Quek, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Characterization and constructions of binary self-orthogonal singly-even linear codes</title>
      <link>https://arxiv.org/abs/2507.12240</link>
      <description>arXiv:2507.12240v2 Announce Type: replace 
Abstract: Recent research has focused extensively on constructing binary self-orthogonal (SO) linear codes due to their applications in quantum information theory, lattice design, and related areas. Despite significant activity, the fundamental characterization remains unchanged: binary SO codes are necessarily even (all codeword weights even), while doubly-even codes (weights divisible by 4) are automatically SO. This paper advances the theory by addressing the understudied case of singly-even (even but not doublyeven) SO codes. We first provide a complete characterization of binary SO linear codes, and a necessary and sufficient condition for binary SO singly-even linear codes is given. Moreover, we give a general approach to generating many binary SO linear codes from two known SO linear codes, yielding three infinite classes of binary SO singly-even linear codes with few weights. Note that these new codes are also minimal and violate the Aschikhmin-Barg condition. Their weight distributions are determined. Furthermore, we give a necessary and sufficient condition for a Boolean function f such that the linear code proposed from f via a well-known generic construction is SO singly-even, and a general approach to constructing Boolean functions satisfying this condition is provided, yielding several infinite classes of binary SO singly-even minimal linear codes with few weights. Finally, we would like to emphasize that using the methods in this paper, we can construct more binary linear codes that are SO, singly-even, minimal, violating the AB condition, and with few weights at the same time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12240v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangquan Li, Hao Chen, Wengang Jin, Longjiang Qu</dc:creator>
    </item>
    <item>
      <title>A note on the Artstein-Avidan-Milman's generalized Legendre transforms</title>
      <link>https://arxiv.org/abs/2507.20577</link>
      <description>arXiv:2507.20577v2 Announce Type: replace 
Abstract: Artstein-Avidan and Milman [Annals of mathematics (2009), (169):661-674] characterized invertible reverse-ordering transforms on the space of lower semi-continuous extended real-valued convex functions as affine deformations of the ordinary Legendre transform. In this work, we first prove that all those generalized Legendre transforms on functions correspond to the ordinary Legendre transform on dually corresponding affine-deformed functions: In short, generalized convex conjugates are ordinary convex conjugates of dually affine-deformed functions. Second, we explain how these generalized Legendre transforms can be derived from the dual Hessian structures of information geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20577v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Nielsen</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal First-Arrival Modeling and Parameter Estimation in Drift-Diffusion Molecular Channels</title>
      <link>https://arxiv.org/abs/2508.18680</link>
      <description>arXiv:2508.18680v3 Announce Type: replace 
Abstract: We derive a closed-form joint distribution of the first arrival time (FAT) and first arrival position (FAP) in drift-diffusion molecular communication (MC) channels. In contrast to prior studies that analyze FAT or FAP in isolation, our framework explicitly captures the spatiotemporal coupling inherent in multidimensional transport. Building on this derivation, we compute the Fisher information matrix (FIM) and demonstrate that estimation accuracy for diffusivity scales proportionally with the spatial dimension, enabling increased sensitivity in higher-dimensional environments. Furthermore, we show that lateral drift -- which is unobservable from timing data alone -- can be recovered via a closed-form Maximum Likelihood Estimator (MLE) with a simple physical interpretation. Leveraging this spatial degree of freedom, we propose Drift Shift Keying (DSK), proving that joint receivers can reliably detect signals that are undetectable to timing-only receivers due to identical marginal FAT distributions. These results highlight the significant potential of spatiotemporal processing for future nanoscale communication and sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18680v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun-Feng Lo, Yen-Chi Lee</dc:creator>
    </item>
  </channel>
</rss>
