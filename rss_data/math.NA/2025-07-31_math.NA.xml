<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Aug 2025 04:01:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Convergence analysis of a second-order SAV-ZEC scheme for the Cahn-Hilliard-Navier-Stokes system</title>
      <link>https://arxiv.org/abs/2507.22949</link>
      <description>arXiv:2507.22949v1 Announce Type: new 
Abstract: Incorporating the scalar auxiliary variable (SAV) method and the zero energy contribution (ZEC) technique, we analyze a linear and fully decoupled numerical scheme for the Cahn-Hilliard-Naiver-Stokes (CHNS) system. More precisely, the fully discrete scheme combines the marker-and-cell (MAC) finite difference spatial approximation and BDF2 temporal discretization, as well as the Adams-Bashforth extrapolation for the nonlinear terms, based on the SAV-ZEC reformulation. A pressure correction approach is applied to decouple the Stokes equation. Only constant-coefficient Poisson-like solvers are needed in the implementation for the resulting numerical system. The numerical scheme is unconditionally stable with respect to a rewritten total energy functional, represented in terms of one auxiliary variable in the double-well potential, another auxiliary variable to balance all the nonlinear and coupled terms, the surface energy in the original phase variable, combined with the kinematic energy part. Specifically, the error estimate for the phase variable in the $\ell^{\infty}(0,T;H_h^1)\cap\ell^2(0,T;H_h^3)$ norm, the velocity variable in the $\ell^{\infty}(0,T;\ell^2)\cap\ell^2(0,T;H_h^1)$ norm, is derived with optimal convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22949v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingwei Sun, Zeyu Xia, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Hybrid Shifted Gegenbauer Integral-Pseudospectral Method for Solving Time-Fractional Benjamin-Bona-Mahony-Burgers Equation</title>
      <link>https://arxiv.org/abs/2507.23099</link>
      <description>arXiv:2507.23099v1 Announce Type: new 
Abstract: This paper presents a high-order hybrid shifted Gegenbauer integral-pseudospectral (HSG-IPS) method for solving the time-fractional Benjamin-Bona-Mahony-Burgers (FBBMB) equation. A key innovation of our approach is the transformation of the original equation into a fractional partial-integro differential form that contains only a first-order derivative, which can be accurately approximated using a first-order shifted Gegenbauer differentiation matrix (SGDM), while all other terms in the transformed equation are resolved using highly accurate quadrature rules. The method combines several advanced numerical techniques including the shifted Gegenbauer pseudospectral (SGPS) method, Gegenbauer-based fractional approximation (GBFA), shifted Gegenbauer integration matrix (SGIM), shifted Gegenbauer integration row vector (SGIRV), and SGDM to achieve spectral accuracy. Numerical experiments demonstrate that the HSG-IPS method outperforms existing numerical approaches, achieving significantly lower average absolute errors (AAEs) with computational times as low as 0.04-0.05 seconds. The method's robustness is validated across various fractional orders, showing excellent agreement with analytical solutions. The transformation strategy effectively circumvents the numerical instability associated with direct approximation of high-order derivatives in the original equation, while the use of shifted Gegenbauer (SG) polynomials and barycentric representations ensures numerical stability and efficiency. This work provides a powerful computational framework for modeling wave propagation, dispersion, and nonlinearity in fractional calculus applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23099v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kareem T. Elgindy</dc:creator>
    </item>
    <item>
      <title>$hp$-adaptive finite element simulation of a static anti-plane shear crack in a nonlinear strain-limiting elastic solid</title>
      <link>https://arxiv.org/abs/2507.23195</link>
      <description>arXiv:2507.23195v1 Announce Type: new 
Abstract: An $hp$-adaptive continuous Galerkin finite element method is developed to analyze a static anti-plane shear crack embedded in a nonlinear, strain-limiting elastic body. The geometrically linear material is described by a constitutive law relating stress and strain that is algebraically nonlinear. In this investigation, the constitutive relation utilized is \textit{uniformly bounded}, \textit{monotone}, \textit{coercive}, and \textit{Lipschitz continuous}, ensuring the well-posedness of the mathematical model. The governing equation, derived from the balance of linear momentum coupled with the nonlinear constitutive relationship, is formulated as a second-order quasi-linear elliptic partial differential equation. For a body with an edge crack, this governing equation is augmented with a classical traction-free boundary condition on the crack faces. An $hp$-adaptive finite element scheme is proposed for the numerical approximation of the resulting boundary value problem. The adaptive strategy is driven by a dual-component error estimation scheme: mesh refinement ($h$-adaptivity) is guided by a residual-based a posteriori error indicator of the \textit{Kelly type}, while the local polynomial degree ($p$-adaptivity) is adjusted based on an estimator of the local solution regularity. The performance, accuracy, and convergence characteristics of the proposed method are demonstrated through numerical experiments. The structure of the regularized crack-tip fields is examined for various modeling parameters. Furthermore, the presented framework establishes a robust foundation for extension to more complex and computationally demanding problems, including quasi-static and dynamic crack propagation in brittle materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23195v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. M. Mallikarjunaiah, Pavithra Venkatachalapthy</dc:creator>
    </item>
    <item>
      <title>Error analysis of the projected PO method with additive inflation for the partially observed Lorenz 96 model</title>
      <link>https://arxiv.org/abs/2507.23199</link>
      <description>arXiv:2507.23199v1 Announce Type: new 
Abstract: We consider the filtering problem with the partially observed Lorenz 96 model. Although the accuracy of the 3DVar filter applied to this problem has been established, that of the EnKF has not yet been. This study aims to establish the error bound of a variant of the EnKF, known as the PO method. By introducing the additive inflation and a projection of the background covariance to the observation space, we establish the error bound of the PO method. A numerical example validates theoretical findings and shows the potential to extend the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23199v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kota Takeda</dc:creator>
    </item>
    <item>
      <title>Improved Analysis of Khatri-Rao Random Projections and Applications</title>
      <link>https://arxiv.org/abs/2507.23207</link>
      <description>arXiv:2507.23207v1 Announce Type: new 
Abstract: Randomization has emerged as a powerful set of tools for large-scale matrix and tensor decompositions. Randomized algorithms involve computing sketches with random matrices. A prevalent approach is to take the random matrix as a standard Gaussian random matrix, for which the theory is well developed. However, this approach has the drawback that the cost of generating and multiplying by the random matrix can be prohibitively expensive. Khatri-Rao random projections (KRPs), obtained by sketching with Khatri-Rao products of random matrices, offer a viable alternative and are much cheaper to generate. However, the theoretical guarantees of using KRPs are much more pessimistic compared to their accuracy observed in practice. We attempt to close this gap by obtaining improved analysis of the use of KRPs in matrix and tensor low-rank decompositions. We propose and analyze a new algorithm for low-rank approximations of block-structured matrices (e.g., block Hankel) using KRPs. We also develop new algorithms to accelerate tensor computations in the Tucker format using KRPs, and give theoretical guarantees of the resulting low-rank approximations. Numerical experiments on synthetic and real-world tensors show the computational benefits of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23207v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arvind K. Saibaba, Bhisham Dev Verma, Grey Ballard</dc:creator>
    </item>
    <item>
      <title>An optimal preconditioner for high-order scheme arising from multi-dimensional Riesz space fractional diffusion equations with variable coefficients</title>
      <link>https://arxiv.org/abs/2507.23408</link>
      <description>arXiv:2507.23408v1 Announce Type: new 
Abstract: In this paper, we propose an efficient method for solving multi-dimensional Riesz space fractional diffusion equations with variable coefficients. The Crank-Nicolson (CN) method is used for temporal discretization, while the fourth-order fractional centered difference (4FCD) method is employed for spatial discretization. Using a novel technique, we show that the CN-4FCD scheme for the multi-dimensional case is unconditionally stable and convergent, achieving second-order accuracy in time and fourth-order accuracy in space with respect to the discrete L2-norm. Moreover, leveraging the symmetric multi-level Toeplitz-like structure of the coefficient matrix in the discrete linear systems, we enhance the computational efficiency of the proposed scheme with a sine transform-based preconditioner, ensuring a mesh-size-independent convergence rate for the conjugate gradient method. Finally, two numerical examples validate the theoretical analysis and demonstrate the superior performance of the proposed preconditioner compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23408v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan-Yuan Huang, Wei Qu, Sean Y. Hon, Siu-Long Lei</dc:creator>
    </item>
    <item>
      <title>The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG Source Localization</title>
      <link>https://arxiv.org/abs/2507.23450</link>
      <description>arXiv:2507.23450v1 Announce Type: new 
Abstract: EEG Source localization is a critical tool in neuroscience, with applications ranging from epilepsy diagnosis to cognitive research. It involves solving an ill-posed inverse problem that lacks a unique solution unless constrained by prior knowledge. The Bayesian framework enables the incorporation of such knowledge, typically encoded through prior models. Various algorithms have been proposed for source localization, and they differ significantly in how prior knowledge is incorporated. Some approaches rely on anatomical or functional constraints, while others use statistical distributions or sampling-based techniques. In this landscape, the Standardized Kalman Filter (SKF) represents a dynamic Bayesian approach that integrates temporal modeling with a Gaussian prior structure. It addresses the depth bias, a common limitation in source localization, through a post-hoc standardization step that equalizes sensitivity across cortical depths and makes deep activity detection feasible.
  This study focuses on the development and optimization of Gaussian prior models within the SKF framework for simultaneous cortical and sub-cortical activity detection. Synthetic data similar to the P20 / N20 component of the somatosensory evoked potentials (SEP) was used to identify effective prior parameter configurations for reconstructing both deep and superficial sources under different noise levels. We also investigated the role of RTS smoothing in enhancing source separability. Our results indicate that raising the standardization exponent to 1.25, along with smoothing, significantly improves depth localization accuracy at low noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23450v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dilshanie Prasikala, Joonas Lahtinen, Alexandra Koulouri, Sampsa Pursiainen</dc:creator>
    </item>
    <item>
      <title>Rational complex Bezier curves</title>
      <link>https://arxiv.org/abs/2507.23485</link>
      <description>arXiv:2507.23485v1 Announce Type: new 
Abstract: In this paper we develop the formalism of rational complex Bezier curves. This framework is a simple extension of the CAD paradigm, since it describes arc of curves in terms of control polygons and weights, which are extended to complex values. One of the major advantages of this extension is that we may make use of two different groups of projective transformations. Besides the group of projective transformations of the real plane, we have the group of complex projective transformations. This allows us to apply useful transformations like the geometric inversion to curves in design. In addition to this, the use of the complex formulation allows to lower the degree of the curves in some cases. This can be checked using the resultant of two polynomials and provides a simple formula for determining whether a rational cubic curve is a conic or not. Examples of application of the formalism to classical curves are included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23485v1</guid>
      <category>math.NA</category>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. Canton, L. Fernandez-Jambrina, M. J. Vazquez-Gallo</dc:creator>
    </item>
    <item>
      <title>Quantum simulation of Helmholtz equations via Schr{\"o}dingerization</title>
      <link>https://arxiv.org/abs/2507.23547</link>
      <description>arXiv:2507.23547v1 Announce Type: new 
Abstract: The Helmholtz equation is a prototypical model for time-harmonic wave propagation. Numerical solutions become increasingly challenging as the wave number $k$ grows, due to the equation's elliptic yet noncoercive character and the highly oscillatory nature of its solutions, with wavelengths scaling as $1/k$. These features lead to strong indefiniteness and large system sizes.
  We present a quantum algorithm for solving such indefinite problems, built upon the Schr\"odingerization framework. This approach reformulates linear differential equations into Schr\"odinger-type systems by capturing the steady state of damped dynamics. A warped phase transformation lifts the original problem to a higher-dimensional formulation, making it compatible with quantum computation. To suppress numerical pollution, the algorithm incorporates asymptotic dispersion correction. It achieves a query complexity of $\mathcal{O}(\kappa^2\text{polylog}\varepsilon^{-1})$, where $\kappa$ is the condition number and $\varepsilon$ the desired accuracy. For the Helmholtz equation, a simple preconditioner further reduces the complexity to $\mathcal{O}(\kappa\text{polylog}\varepsilon^{-1})$. Our constructive extension to the quantum setting is broadly applicable to all indefinite problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23547v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anjiao Gu, Shi Jin, Chuwen Ma</dc:creator>
    </item>
    <item>
      <title>Fitted norm preconditioners for the Hodge Laplacian in mixed form</title>
      <link>https://arxiv.org/abs/2507.23586</link>
      <description>arXiv:2507.23586v1 Announce Type: new 
Abstract: We use the practical framework for abstract perturbed saddle point problems recently introduced by Hong et al. to analyze the mixed formulation of the Hodge Laplace problem. We compose two parameter-dependent norms in which the uniform continuity and stability of the problem follow. This not only guarantees the well-posedness of the corresponding variational formulation on the continuous level, but also of related compatible discrete models.
  We further simplify the obtained norms and, in both cases, arrive at the same norm-equivalent preconditioner that is easily implementable. The efficiency and uniformity of the preconditioner are demonstrated numerically by the fast convergence and uniformly bounded number of preconditioned MINRES iterations required to solve various instances of Hodge Laplace problems in two and three space dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23586v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wietse M. Boon, Johannes Kraus, Tom\'a\v{s} Luber, Maria Lymbery</dc:creator>
    </item>
    <item>
      <title>Efficient Numerical Strategies for Entropy-Regularized Semi-Discrete Optimal Transport</title>
      <link>https://arxiv.org/abs/2507.23602</link>
      <description>arXiv:2507.23602v1 Announce Type: new 
Abstract: Semi-discrete optimal transport (SOT), which maps a continuous probability measure to a discrete one, is a fundamental problem with wide-ranging applications. Entropic regularization is often employed to solve the SOT problem, leading to a regularized (RSOT) formulation that can be solved efficiently via its convex dual. However, a significant computational challenge emerges when the continuous source measure is discretized via the finite element (FE) method to handle complex geometries or densities, such as those arising from solutions to Partial Differential Equations (PDEs). The evaluation of the dual objective function requires dense interactions between the numerous source quadrature points and all target points, creating a severe bottleneck for large-scale problems. This paper presents a cohesive framework of numerical strategies to overcome this challenge. We accelerate the dual objective and gradient evaluations by combining distance-based truncation with fast spatial queries using R-trees. For overall convergence, we integrate multilevel techniques based on hierarchies of both the FE source mesh and the discrete target measure, alongside a robust scheduling strategy for the regularization parameter. When unified, these methods drastically reduce the computational cost of RSOT, enabling its practical application to complex, large-scale scenarios. We provide an open-source C++ implementation of this framework, built upon the deal.II finite element library, available at https://github.com/SemiDiscreteOT/SemiDiscreteOT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23602v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moaad Khamlich, Francesco Romor, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>A Multi-Frequency Helmholtz Solver Based on the WaveHoltz Algorithm</title>
      <link>https://arxiv.org/abs/2507.23613</link>
      <description>arXiv:2507.23613v1 Announce Type: new 
Abstract: We develop and analyze a new approach for simultaneously computing multiple solutions to the Helmholtz equation for different frequencies and different forcing functions. The new Multi-Frequency WaveHoltz (MFWH) algorithm is an extension of the original WaveHoltz method and both are based on time-filtering solutions to an associated wave equation. With MFWH, the different Helmholtz solutions are computed simultaneously by solving a single wave equation combined with multiple time filters. The MFWH algorithm defines a fixed-point iteration which can be accelerated with Krylov methods such as GMRES. The solution of the wave equation can be efficiently solved with either explicit time-stepping or implicit time-stepping using as few as five time-steps per period. When combined with an $O(N)$ solver for the implicit equations, such a multigrid, the scheme has an $O(N)$ solution cost when the frequencies are fixed and the number of grid points $N$ increases. High-order accurate approximations in space are used together with second-order accurate approximations in time. We show how to remove time discretization errors so that the MFWH solutions converge to the corresponding solutions to the discretized Helmholtz problems. Numerical results are given using second-order accurate and fourth-accurate discretizations to confirm the convergence theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23613v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Appel\"o, Francis Appiah, Jeffrey W. Banks, Cassandra Carrick, William D. Henshaw, Donald W. Schwendeman</dc:creator>
    </item>
    <item>
      <title>Regularization of Inverse Problems by Filtered Diagonal Frame Decomposition under general source</title>
      <link>https://arxiv.org/abs/2507.23651</link>
      <description>arXiv:2507.23651v1 Announce Type: new 
Abstract: Let $X$ and $Y$ be Hilbert spaces, and $\mathbf{K}: \text{dom} \mathbf{K} \subset X \to Y$ a bounded linear operator. This paper addresses the inverse problem $\mathbf{K}x = y$, where exact data $y$ is replaced by noisy data $y^\delta$ satisfying $\|y^\delta - y\|_Y \leq \delta$. Due to the ill-posedness of such problems, we employ regularization methods to stabilize solutions. While singular value decomposition (SVD) provides a classical approach, its computation can be costly and impractical for certain operators. We explore alternatives via Diagonal Frame Decomposition (DFD), generalizing SVD-based techniques, and introduce a regularized solution $x^\delta_\alpha = \sum_{\lambda \in \Lambda} \kappa_\lambda g_\alpha(\kappa_\lambda^2) \langle y^\delta, v_\lambda \rangle \overline{u}_\lambda$. Convergence rates and optimality are analyzed under a generalized source condition $\mathbf{M}_{\varphi, E} = \{ x \in \text{dom} \mathbf{K} : \sum_{\lambda \in \Lambda} [\varphi(\kappa_\lambda^2)]^{-1} |\langle x, u_\lambda \rangle|^2 \leq E^2 \}$. Key questions include constructing DFD systems, relating DFD and SVD singular values, and extending source conditions. We present theoretical results, including modulus of continuity bounds and convergence rates for a priori and a posteriori parameter choices, with applications to polynomial and exponentially ill-posed problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23651v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Dang Duc Trong, Nguyen Dang Minh, Luu Xuan Thang, Luu Dang Khoa</dc:creator>
    </item>
    <item>
      <title>Improved Convergence Factor of Windowed Anderson Acceleration for Symmetric Fixed-Point Iterations</title>
      <link>https://arxiv.org/abs/2311.02490</link>
      <description>arXiv:2311.02490v3 Announce Type: replace 
Abstract: This paper studies the commonly utilized windowed Anderson acceleration (AA) algorithm for fixed-point methods, $x^{(k+1)}=q(x^{(k)})$. It provides the first proof that when the operator $q$ is linear and symmetric the windowed AA, which uses a sliding window of prior iterates, improves the root-linear convergence factor over the fixed-point iterations. When $q$ is nonlinear, yet has a symmetric Jacobian at a fixed point, a slightly modified AA algorithm is proved to have an analogous root-linear convergence factor improvement over fixed-point iterations. Simulations verify our observations. Furthermore, experiments with different data models demonstrate AA is significantly superior to the standard fixed-point methods for Tyler's M-estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02490v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Casey Garner, Gilad Lerman, Teng Zhang</dc:creator>
    </item>
    <item>
      <title>Weighted least-squares approximation with determinantal point processes and generalized volume sampling</title>
      <link>https://arxiv.org/abs/2312.14057</link>
      <description>arXiv:2312.14057v4 Announce Type: replace 
Abstract: We consider the problem of approximating a function from $L^2$ by an element of a given $m$-dimensional space $V_m$, associated with some feature map $\boldsymbol{\varphi}$, using evaluations of the function at random points $x_1, \dots,x_n$. After recalling some results on optimal weighted least-squares using independent and identically distributed points, we consider weighted least-squares using projection determinantal point processes (DPP) or volume sampling. These distributions introduce dependence between the points that promotes diversity in the selected features $\boldsymbol{\varphi}(x_i)$. We first provide a generalized version of volume-rescaled sampling yielding quasi-optimality results in expectation with a number of samples $n = O(m\log(m))$, that means that the expected $L^2$ error is bounded by a constant times the best approximation error in $L^2$. Also, further assuming that the function is in some normed vector space $H$ continuously embedded in $L^2$, we further prove that the approximation error in $L^2$ is almost surely bounded by the best approximation error measured in the $H$-norm. This includes the cases of functions from $L^\infty$ or reproducing kernel Hilbert spaces. Finally, we present an alternative strategy consisting in using independent repetitions of projection DPP (or volume sampling), yielding similar error bounds as with i.i.d. or volume sampling, but in practice with a much lower number of samples. Numerical experiments illustrate the performance of the different strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14057v4</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Nouy, Bertrand Michel</dc:creator>
    </item>
    <item>
      <title>On the power of adaption and randomization</title>
      <link>https://arxiv.org/abs/2406.07108</link>
      <description>arXiv:2406.07108v2 Announce Type: replace 
Abstract: We present bounds on the maximal gain of adaptive and randomized algorithms over non-adaptive, deterministic ones for approximating linear operators on convex sets. If the sets are additionally symmetric, then our results are optimal. For non-symmetric sets, we unify some notions of $n$-widths and s-numbers, and show their connection to minimal errors. We also discuss extensions to non-linear widths and approximation based on function values, and conclude with a list of open problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07108v2</guid>
      <category>math.NA</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Krieg, Erich Novak, Mario Ullrich</dc:creator>
    </item>
    <item>
      <title>Row-aware Randomized SVD with applications</title>
      <link>https://arxiv.org/abs/2408.04503</link>
      <description>arXiv:2408.04503v4 Announce Type: replace 
Abstract: The randomized singular value decomposition proposed in [27] has certainly become one of the most well-established randomization-based algorithms in numerical linear algebra. The key ingredient of the entire procedure is the computation of a subspace which is close to the column space of the target matrix $\mathbf{A}$ up to a certain probabilistic confidence. In this paper we employ a modification to the standard randomized SVD procedure which leads, in general, to better approximations to $\text{Range}(\mathbf{A})$ at the same computational cost. To this end, we explicitly construct information from the row space of $\mathbf{A}$ enhancing the quality of the approximation. We derive novel error bounds which improve over existing results for $\mathbf{A}$ having important gaps in its singular values. We also observe that very few pieces of information from $\text{Range}(\mathbf{A}^T)$ may be necessary. We thus design a variant of this algorithm equipped with a subsampling step which largely increases the efficiency of the procedure while often attaining competitive accuracy records. Our findings are supported by both theoretical analysis and numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04503v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Palitta, Sascha Portaro</dc:creator>
    </item>
    <item>
      <title>Unified discontinuous Galerkin analysis of a thermo/poro-viscoelasticity model</title>
      <link>https://arxiv.org/abs/2411.19610</link>
      <description>arXiv:2411.19610v2 Announce Type: replace 
Abstract: We present and analyze a discontinuous Galerkin method for the numerical modeling of a Kelvin-Voigt thermo/poro-viscoelastic problem. We present the derivation of the model and we develop a stability analysis in the continuous setting that holds both for the full inertial and quasi-static problems and that is robust with respect to most of the physical parameters of the problem. For spatial discretization, we propose an arbitrary-order weighted symmetric interior penalty scheme that supports general polytopal grids and is robust with respect to strong heterogeneities in the model coefficients. For the semi-discrete problem, we prove the extension of the stability result demonstrated in the continuous setting and we provide an a-priori error estimate. A wide set of numerical simulations is presented to assess the convergence and robustness properties of the proposed method. Moreover, we test the scheme with literature and physically sound test cases for proof-of-concept applications in the geophysical context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19610v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bonetti, Mattia Corti</dc:creator>
    </item>
    <item>
      <title>A simple-to-implement nonlinear preconditioning of Newton's method for solving the steady Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2501.08855</link>
      <description>arXiv:2501.08855v2 Announce Type: replace 
Abstract: The Newton's method for solving stationary Navier-Stokes equations (NSE) is known to convergent fast, however, may fail due to a bad initial guess. This work presents a simple-to-implement nonlinear preconditioning of Newton's iteration, that remains the quadratic convergence and enlarges the domain of convergence. The proposed AAPicard-Newton method adds the Anderson accelerated Picard step at each iteration of Newton's method for solving NSE, which has been shown globally stable for the relaxation parameter $\beta_{k+1}\equiv1$ in the Anderson acceleration optimization step, convergent quadratically, and converges faster with a smaller convergence rate for large Reynolds number. Several benchmark numerical tests have been tested and are well-aligned with the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08855v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Mohebujjaman, Mengying Xiao, Cheng Zhang</dc:creator>
    </item>
    <item>
      <title>Jacobian-Free Newton-Krylov with a globalization method for solving groundwater flow models of multi-layer aquifer systems</title>
      <link>https://arxiv.org/abs/2505.08884</link>
      <description>arXiv:2505.08884v2 Announce Type: replace 
Abstract: A Jacobian free Newton Krylov (JFNK) method with a globalization scheme is introduced to solve large and complex nonlinear systems of equations that arise in groundwater flow models of multi-layer aquifer systems. We explore the advantages of the JFNK method relative to the Newton-Krylov (NK) method and identify the circumstances in which the JFNK method demonstrates computing efficiency. We perform the validation and efficiency of the JFNK method on various test cases involving an unconfined single-layer aquifer and a two-layer aquifer with both confined and unconfined conditions. The results are validated by the NK method. The JFNK method is incorporated in Integrated Water Flow Model (IWFM), an integrated hydrologic model developed and maintained by California Department of Water Resources. We examine the determinacy of the JFNK's adaptability on practical models such as the California Central Valley Groundwater-Surface Water Simulation Model (C2VSim).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08884v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raghav Singhal, Emin Can Dogrul, Zhaojun Bai</dc:creator>
    </item>
    <item>
      <title>Momentum-based gradient descent methods for Lie groups</title>
      <link>https://arxiv.org/abs/2404.09363</link>
      <description>arXiv:2404.09363v2 Announce Type: replace-cross 
Abstract: Polyak's Heavy Ball (PHB; Polyak, 1964), a.k.a. Classical Momentum, and Nesterov's Accelerated Gradient (NAG; Nesterov, 1983) are well-established momentum-descent methods for optimization. Although the latter generally outperforms the former, primarily, generalizations of PHB-like methods to nonlinear spaces have not been sufficiently explored in the literature. In this paper, we propose a generalization of NAG-like methods for Lie group optimization. This generalization is based on the variational one-to-one correspondence between classical and accelerated momentum methods (Campos et al., 2023). We provide numerical experiments for chosen retractions on the group of rotations based on the Frobenius norm and the Rosenbrock function to demonstrate the effectiveness of our proposed methods, and that align with results of the Euclidean case, that is, a faster convergence rate for NAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09363v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>C\'edric M. Campos, David Mart\'in de Diego, Jos\'e Torrente</dc:creator>
    </item>
    <item>
      <title>Fully stochastic trust-region methods with Barzilai-Borwein steplengths</title>
      <link>https://arxiv.org/abs/2412.12180</link>
      <description>arXiv:2412.12180v2 Announce Type: replace-cross 
Abstract: We investigate stochastic gradient methods and stochastic counterparts of the Barzilai-Borwein steplengths and their application to finite-sum minimization problems. Our proposal is based on the Trust-Region-ish (TRish) framework introduced in [F. E. Curtis, K. Scheinberg, R. Shi, {\it A stochastic trust region algorithm based on careful step normalization}, Informs Journal on Optimization, 1, 2019]. The new framework, named TRishBB, aims to enhance the performance of TRish and at reducing the computational cost of the second-order TRish variant. We propose three different methods belonging to the TRishBB framework and present the convergence analysis for possibly nonconvex objective functions, considering biased and unbiased gradient approximations. Our analysis requires neither diminishing step-sizes nor full gradient evaluation. The numerical experiments in machine learning applications demonstrate the effectiveness of applying the Barzilai-Borwein steplength with stochastic gradients and show improved testing accuracy compared to the TRish method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12180v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Benedetta Morini, Mahsa Yousefi</dc:creator>
    </item>
    <item>
      <title>Learning dynamically inspired invariant subspaces for Koopman and transfer operator approximation</title>
      <link>https://arxiv.org/abs/2505.05085</link>
      <description>arXiv:2505.05085v2 Announce Type: replace-cross 
Abstract: Transfer and Koopman operator methods offer a framework for representing complex, nonlinear dynamical systems via linear transformations, enabling a deeper understanding of the underlying dynamics. The spectra of these operators provide important insights into system predictability and emergent behaviour, although efficiently estimating them from data can be challenging. We approach this issue through the lens of general operator and representational learning, in which we approximate these linear operators using efficient finite-dimensional representations. Specifically, we machine-learn orthonormal basis functions that are dynamically tailored to the system. This learned basis provides a particularly accurate approximation of the operator's action as well as a nearly invariant finite-dimensional subspace. We illustrate our approach with examples that showcase the retrieval of spectral properties from the estimated operator, and emphasise the dynamically adaptive quality of the machine-learned basis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05085v2</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gary Froyland, Kevin K\"uhl</dc:creator>
    </item>
    <item>
      <title>On the time integration for phase field modeling of grain growth in additive manufacturing</title>
      <link>https://arxiv.org/abs/2507.13492</link>
      <description>arXiv:2507.13492v3 Announce Type: replace-cross 
Abstract: Phase field simulations play a key role in the understanding of microstructure evolution in additive manufacturing. However, they have been found extremely computationally expensive. One of the reasons is the small time step requirement to resolve the complex microstructure evolution during the rapid solidification process. This paper investigates the possibility of using a class of stabilized time integration algorithms to accelerate such phase field simulations by increasing the time steps. The specific time integration formulation and theoretical analysis on energy stability were developed, based on a phase field model dedicated to simulating rapid solidification in additive manufacturing. The numerical results confirmed that the proposed method can ensure the numerical stability and a decreasing energy requirement for the phase field simulations with at least two orders-of-magnitude larger time steps over conventional explicit methods. 2D and 3D phase field simulations have been conducted with relevant physical and kinetic parameters for 316L stainless steels. This work provides a numerical framework for efficient phase field simulations and open numerous opportunities for large scale phase field modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13492v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoqian Yuan, Chinnapat Panwisawas, Ye Lu</dc:creator>
    </item>
  </channel>
</rss>
