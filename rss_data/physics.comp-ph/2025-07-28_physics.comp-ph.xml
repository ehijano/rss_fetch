<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Jul 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Tensor Networks for Liquids in Heterogeneous Systems</title>
      <link>https://arxiv.org/abs/2507.19352</link>
      <description>arXiv:2507.19352v1 Announce Type: new 
Abstract: Many-body correlations in strongly coupled liquids and plasmas are critical for many applications in nanofluids, biology, and fusion-related plasma physics, but their description in fully heterogeneous environments remains challenging due to the high-dimensional equations involved. Recently, tensor network decompositions have emerged as powerful tools for tackling such equations by reducing memory usage and computational complexity. In this paper, we solve for equilibrium density and density-density correlation functions of liquids in confined heterogeneous environments using tensor network methods. We demonstrate that these functions admit high compression when their lengthscale dependence is encoded via quantized tensor trains or when their spatial-coordinate dependence is represented in standard tensor-train format, but not with respect to their dependence on distinct particle coordinates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19352v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.plasm-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary A. Johnson, Luciano G. Silvestri, Pierson Guthrey, Michael S. Murillo</dc:creator>
    </item>
    <item>
      <title>Interpretable inverse design of optical multilayer thin films based on extended neural adjoint and regression activation mapping</title>
      <link>https://arxiv.org/abs/2507.18644</link>
      <description>arXiv:2507.18644v1 Announce Type: cross 
Abstract: We propose an extended neural adjoint (ENA) framework, which meets six key criteria for artificial intelligence-assisted inverse design of optical multilayer thin films (OMTs): accuracy, efficiency, diversity, scalability, flexibility, and interpretability. To enhance the scalability of the existing neural adjoint method, we present a novel forward neural network architecture for OMTs and introduce a material loss function into the existing neural adjoint loss function, facilitating the exploration of material configurations of OMTs. Furthermore, we present the detailed formulation of the regression activation mapping for the presented forward neural network architecture (F-RAM), a feature visualization method aimed at improving interpretability. We validated the efficacy of the material loss by conducting an ablation study, where each component of the loss function is systematically removed and evaluated. The results indicated that the inclusion of the material loss significantly improves accuracy and diversity. To substantiate the performance of the ENA-based inverse design, we compared it against the residual network-based global optimization network (Res-GLOnet). The ENA yielded the OMT solutions of an inverse design with higher accuracy and better diversity compared to the Res-GLOnet. To demonstrate the interpretability, we applied F-RAM to diverse OMT structures with similar optical properties, obtained by the proposed ENA method. We showed that distributions of feature importance for various OMT structures exhibiting analogous optical properties are consistent, despite variations in material configurations, layer number, and thicknesses. Furthermore, we demonstrate the flexibility of the ENA method by restricting the initial layer of OMTs to SiO2 and 100 nm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18644v1</guid>
      <category>physics.optics</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungjun Kim, Jungho Kim</dc:creator>
    </item>
    <item>
      <title>Adaptive Neural Quantum States: A Recurrent Neural Network Perspective</title>
      <link>https://arxiv.org/abs/2507.18700</link>
      <description>arXiv:2507.18700v1 Announce Type: cross 
Abstract: Neural-network quantum states (NQS) are powerful neural-network ans\"atzes that have emerged as promising tools for studying quantum many-body physics through the lens of the variational principle. These architectures are known to be systematically improvable by increasing the number of parameters. Here we demonstrate an Adaptive scheme to optimize NQSs, through the example of recurrent neural networks (RNN), using a fraction of the computation cost while reducing training fluctuations and improving the quality of variational calculations targeting ground states of prototypical models in one- and two-spatial dimensions. This Adaptive technique reduces the computational cost through training small RNNs and reusing them to initialize larger RNNs. This work opens up the possibility for optimizing graphical processing unit (GPU) resources deployed in large-scale NQS simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18700v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jake McNaughton, Mohamed Hibat-Allah</dc:creator>
    </item>
    <item>
      <title>Symmetry-reduced model reduction of shift-equivariant systems via operator inference</title>
      <link>https://arxiv.org/abs/2507.18780</link>
      <description>arXiv:2507.18780v1 Announce Type: cross 
Abstract: We consider data-driven reduced-order models of partial differential equations with shift equivariance. Shift-equivariant systems typically admit traveling solutions, and the main idea of our approach is to represent the solution in a traveling reference frame, in which it can be described by a relatively small number of basis functions. Existing methods for operator inference allow one to approximate a reduced-order model directly from data, without knowledge of the full-order dynamics. Our method adds additional terms to ensure that the reduced-order model not only approximates the spatially frozen profile of the solution, but also estimates the traveling speed as a function of that profile. We validate our approach using the Kuramoto-Sivashinsky equation, a one-dimensional partial differential equation that exhibits traveling solutions and spatiotemporal chaos. Results indicate that our method robustly captures traveling solutions, and exhibits improved numerical stability over the standard operator inference approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18780v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Shuai, Clarence W. Rowley</dc:creator>
    </item>
    <item>
      <title>Accuracy and Limitations of Machine-Learned Interatomic Potentials for Magnetic Systems: A Case Study on Fe-Cr-C</title>
      <link>https://arxiv.org/abs/2507.18935</link>
      <description>arXiv:2507.18935v1 Announce Type: cross 
Abstract: Machine-learned interatomic potentials (MLIPs) have become the gold standard for atomistic simulations, yet their extension to magnetic materials remains challenging because spin fluctuations must be captured either explicitly or implicitly. We address this problem for the technologically vital Fe-Cr-C system by constructing two deep machine learning potentials in DeePMD realization: one trained on non-magnetic DFT data (DP-NM) and one on spin-polarised DFT data (DP-M). Extensive validation against experiments reveals a striking dichotomy. The dynamic, collective properties, viscosity and melting temperatures are reproduced accurately by DP-NM but are incorrectly estimated by DP-M. Static, local properties, density, and lattice parameters are captured excellently by DP-M, especially in Fe-rich alloys, whereas DP-NM fails. This behaviour is explained by general properties of paramagnetic state: at high temperature, local magnetic moments self-average in space and time, so their explicit treatment is unnecessary for transport properties but essential for equilibrium volumes. Exploiting this insight, we show that a transfer-learning protocol, pre-training on non-magnetic DFT and fine-tuning on a small set of spin-polarised data, reduces the computational cost to develop magnetic MLIPs by more than an order of magnitude. Developing general-purpose potentials that capture static and dynamic behaviors throughout the whole composition space requires proper accounting for temperature-induced spin fluctuations in DFT calculations and correctly incorporating spin degrees of freedom into classical force fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18935v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. O. Khazieva, N. M. Chtchelkatchev, R. E. Ryltsev</dc:creator>
    </item>
    <item>
      <title>Neural network ensemble for computing cross sections for rotational transitions in H$_{2}$O + H$_{2}$O collisions</title>
      <link>https://arxiv.org/abs/2507.18974</link>
      <description>arXiv:2507.18974v1 Announce Type: cross 
Abstract: Water (H$_2$O) is one of the most abundant molecules in the universe and is found in a wide variety of astrophysical environments. Rotational transitions in H$_2$O + H$_2$O collisions are important in modeling environments rich in water molecules but they are computationally intractable using quantum mechanical methods. Here, we present a machine learning (ML) tool using an ensemble of neural networks (NNs) to predict cross sections to construct a database of rate coefficients for rotationally inelastic transitions in collisions of complex molecules such as water. The proposed methodology utilizes data computed with a mixed quantum-classical theory (MQCT). We illustrate that efficient ML models using NN can be built to accurately interpolate in the space of 12 quantum numbers for rotational transitions in two asymmetric top molecules, spanning both initial and final states. We examine various architectures of data corresponding to each collision energy, symmetry of water molecule, and excitation/de-excitation rotational transitions, and optimize the training/validation data sets. Using only about 10\% of the computed data for training, the NNs predict cross sections of state-to-state rotational transitions of H$_{2}$O + H$_{2}$O collision with average relative root mean square error of 0.409. Thermally averaged cross sections, computed using the predicted state-to-state cross sections ($\sim$90\%) and the data used for training and validation ($\sim$10\%) were compared against those obtained entirely from MQCT calculations. The agreement is found to be excellent with an average percent deviation of about $\sim$13.5\%. The methodology is robust, and thus, applicable to other complex molecular systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18974v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.space-ph</category>
      <category>quant-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bikramaditya Mandal, Dmitri Babikov, Phillip C. Stancil, Robert C. Forrey, Roman V. Krems, Naduvalath Balakrishnan</dc:creator>
    </item>
    <item>
      <title>Entanglement across scales: Quantics tensor trains as a natural framework for renormalization</title>
      <link>https://arxiv.org/abs/2507.19069</link>
      <description>arXiv:2507.19069v1 Announce Type: cross 
Abstract: Understanding entanglement remains one of the most intriguing problems in physics. While particle and site entanglement have been studied extensively, the investigation of length or energy scale entanglement, quantifying the information exchange between different length scales, has received far less attention. Here, we identify the quantics tensor train (QTT) technique, a matrix product state-inspired approach for overcoming computational bottlenecks in resource-intensive numerical calculations, as a renormalization group method by analytically expressing an exact cyclic reduction-based real-space renormalization scheme in QTT language, which serves as a natural formalism for the method. In doing so, we precisely match the QTT bond dimension, a measure of length scale entanglement, to the number of rescaled couplings generated in each coarse-graining renormalization step. While QTTs have so far been applied almost exclusively to numerical problems in physics, our analytical calculations demonstrate that they are also powerful tools for mitigating computational costs in semi-analytical treatments. We present our results for the one-dimensional tight-binding model with n-th-nearest-neighbor hopping, where the 2n rescaled couplings generated in the renormalization procedure precisely match the QTT bond dimension of the one-particle Green's function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19069v1</guid>
      <category>cond-mat.str-el</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Rohshap, Jheng-Wei Li, Alena Lorenz, Serap Hasil, Karsten Held, Anna Kauch, Markus Wallerberger</dc:creator>
    </item>
    <item>
      <title>PYSED: A tool for extracting kinetic-energy-weighted phonon dispersion and lifetime from molecular dynamics simulations</title>
      <link>https://arxiv.org/abs/2505.00353</link>
      <description>arXiv:2505.00353v3 Announce Type: replace 
Abstract: Machine learning potential-driven molecular dynamics (MD) simulations have significantly enhanced the predictive accuracy of thermal transport properties across diverse materials. However, extracting phonon-mode-resolved insights from these simulations remains a critical challenge. Here, we introduce PYSED, a Python-based package built on the spectral energy density (SED) method, designed to efficiently compute kinetic-energy-weighted phonon dispersion and extract phonon lifetime from large-scale MD simulation trajectories. By integrating high-accuracy machine-learned neuroevolution potential (NEP) models, we validate and showcase the effectiveness of the implemented SED method across systems of varying dimensionalities. Specifically, the NEP-driven MD-SED accurately reveals how phonon modes are affected by strain in carbon nanotubes, as well as by interlayer coupling strength and twist angle in two-dimensional molybdenum disulfide. For three-dimensional systems, the SED method effectively establishes the thermal transport regime diagram for metal-organic frameworks, distinguishing between particlelike and wavelike propagation regions. Moreover, using bulk silicon as an example, we show that phonon SED can efficiently capture quantum dynamics based on path-integral trajectories. The PYSED package bridges MD simulations with detailed phonon-mode insights, delivering a robust tool for investigating thermal transport properties with detailed mechanisms across various materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00353v3</guid>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ting Liang, Wenwu Jiang, Ke Xu, Hekai Bu, Zheyong Fan, Wengen Ouyang, Jianbin Xu</dc:creator>
    </item>
    <item>
      <title>Opportunities and Challenges in Unsupervised Learning: The Case of Aqueous Electrolyte Solutions</title>
      <link>https://arxiv.org/abs/2503.14197</link>
      <description>arXiv:2503.14197v2 Announce Type: replace-cross 
Abstract: Machine learning has emerged as a powerful tool in atomistic simulations, enabling the identification of complex patterns in molecular systems limiting human intervention and bias. However, the practical implementation of these methods presents significant technical challenges, particularly in the selection of hyperparameters and in the physical interpretability of machine-learned descriptors. In this work, we systematically investigate these challenges by applying an unsupervised learning protocol to a fundamental problem in physical chemistry namely, how ions perturb the local structure of water. Using the Smooth Overlap of Atomic Positions(SOAP) descriptors, we demonstrate how the intrinsic dimension (ID) serves as a guide for selecting hyperparameters and interpreting structural complexity. Furthermore, we construct a high-dimensional free energy landscape encompassing all water environments surrounding different ions. This analysis reveals how the physical properties of ions are intricately reflected in their hydration shells, shaping the landscape through specific connections between different minima. Our findings highlight the difficulty in balancing algorithmic automation with the need of employing both physical and chemical intuition, particularly for the construction of meaningful descriptors and for the interpretation of final results. By critically assessing the methodological hurdles associated with unsupervised learning, we provide a road map for researchers looking to harness these techniques for studying electrolyte and aqueous solutions in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14197v2</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulia Sormani, Alex Rodriguez, Ali Hassanali</dc:creator>
    </item>
  </channel>
</rss>
