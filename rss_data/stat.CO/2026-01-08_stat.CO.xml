<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 05:00:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Distributed Estimation for Scalar-on-Function Regression Models</title>
      <link>https://arxiv.org/abs/2601.04138</link>
      <description>arXiv:2601.04138v1 Announce Type: new 
Abstract: This paper proposes distributed estimation procedures for three scalar-on-function regression models: the functional linear model (FLM), the functional non-parametric model (FNPM), and the functional partial linear model (FPLM). The framework addresses two key challenges in functional data analysis, namely the high computational cost of large samples and limitations on sharing raw data across institutions. Monte Carlo simulations show that the distributed estimators substantially reduce computation time while preserving high estimation and prediction accuracy for all three models. When block sizes become too small, the FPLM exhibits overfitting, leading to narrower prediction intervals and reduced empirical coverage probability. An example of an empirical study using the \textit{tecator} dataset further supports these findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04138v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peilun He, Han Lin Shang, Nan Zou</dc:creator>
    </item>
    <item>
      <title>Propagating Surrogate Uncertainty in Bayesian Inverse Problems</title>
      <link>https://arxiv.org/abs/2601.03532</link>
      <description>arXiv:2601.03532v1 Announce Type: cross 
Abstract: Standard Bayesian inference schemes are infeasible for inverse problems with computationally expensive forward models. A common solution is to replace the model with a cheaper surrogate. To avoid overconfident conclusions, it is essential to acknowledge the surrogate approximation by propagating its uncertainty. At present, a variety of distinct uncertainty propagation methods have been suggested, with little understanding of how they vary. To fill this gap, we propose a mixture distribution termed the expected posterior (EP) as a general baseline for uncertainty-aware posterior approximation, justified by decision theoretic and modular Bayesian inference arguments. We then investigate the expected unnormalized posterior (EUP), a popular heuristic alternative, analyzing when it may deviate from the EP baseline. Our results show that this heuristic can break down when the surrogate uncertainty is highly non-uniform over the design space, as can be the case when the log-likelihood is emulated by a Gaussian process. Finally, we present the random kernel preconditioned Crank-Nicolson (RKpCN) algorithm, an approximate Markov chain Monte Carlo scheme that provides practical EP approximation in the challenging setting involving infinite-dimensional Gaussian process surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03532v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Gerard Roberts, Michael Dietze, Jonathan Huggins</dc:creator>
    </item>
    <item>
      <title>pintervals: an R package for model-agnostic prediction intervals</title>
      <link>https://arxiv.org/abs/2601.03994</link>
      <description>arXiv:2601.03994v1 Announce Type: cross 
Abstract: The \pkg{pintervals} package aims to provide a unified framework for constructing prediction intervals and calibrating predictions in a model-agnostic setting using set-aside calibration data. It comprises routines to construct conformal as well as parametric and bootstrapped prediction intervals from any model that outputs point predictions. Several R packages and functions already exist for constructing prediction intervals, but they often focus on specific modeling frameworks or types of predictions, or require manual customization for different models or applications. By providing a consistent interface for a variety of prediction interval construction approaches (all model-agnostic), \pkg{pintervals} allows researchers to apply and compare them across different modeling frameworks and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03994v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Randahl, Anders Hjort, Jonathan P. Williams</dc:creator>
    </item>
    <item>
      <title>Multi-index importance sampling for McKean--Vlasov stochastic differential equations</title>
      <link>https://arxiv.org/abs/2307.05149</link>
      <description>arXiv:2307.05149v2 Announce Type: replace-cross 
Abstract: This work addresses the estimation of rare-event quantities expressed as expectations of smooth observables of solutions to a broad class of McKean--Vlasov stochastic differential equations (MV-SDEs). Building on the double loop Monte Carlo (DLMC) method with stochastic optimal control-based importance sampling (IS) introduced by Ben Rached et al. (2024a), this work extends this framework to the multi-index Monte Carlo (MIMC) setting. The resulting multi-index DLMC estimator mitigates the explosion of the coefficient of variation for rare event quantities. Moreover, it exploits the sampling efficiency of MIMC by leveraging the propagation of chaos to ensure mixed-difference variances vanish in the mean-field limit. The complexity analysis relies on assumptions on mixed-difference bias and variance decay, similar to standard MIMC assumptions. Although not rigorously proved, this work presents strong numerical evidence in support of these assumptions. The primary contribution of this work is the novel numerical integration of the MIMC method with IS for MV-SDEs. This approach reduces the computational complexity from $\mathcal{O}(\mathrm{TOL}_{\mathrm{r}}^{-4})$ for the DLMC estimator to $\mathcal{O}(\mathrm{TOL}_{\mathrm{r}}^{-2} (\log \mathrm{TOL}_{\mathrm{r}}^{-1})^2)$, enabling an accurate estimation of rare-event quantities within a prescribed relative error tolerance $\mathrm{TOL}_{\mathrm{r}}$. Numerical experiments on the Kuramoto model from statistical physics demonstrate computational savings of several orders of magnitude for the multi-index DLMC estimator with IS, compared with the standard Monte Carlo (MC) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05149v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 08 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadhir Ben Rached, Abdul-Lateef Haji-Ali, Shyam Mohan Subbiah Pillai, Ra\'ul Tempone</dc:creator>
    </item>
  </channel>
</rss>
