<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Jun 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Convolutional L2LFlows: Generating Accurate Showers in Highly Granular Calorimeters Using Convolutional Normalizing Flows</title>
      <link>https://arxiv.org/abs/2405.20407</link>
      <description>arXiv:2405.20407v1 Announce Type: cross 
Abstract: In the quest to build generative surrogate models as computationally efficient alternatives to rule-based simulations, the quality of the generated samples remains a crucial frontier. So far, normalizing flows have been among the models with the best fidelity. However, as the latent space in such models is required to have the same dimensionality as the data space, scaling up normalizing flows to high dimensional datasets is not straightforward. The prior L2LFlows approach successfully used a series of separate normalizing flows and sequence of conditioning steps to circumvent this problem. In this work, we extend L2LFlows to simulate showers with a 9-times larger profile in the lateral direction. To achieve this, we introduce convolutional layers and U-Net-type connections, move from masked autoregressive flows to coupling layers, and demonstrate the successful modelling of showers in the ILD Electromagnetic Calorimeter as well as Dataset 3 from the public CaloChallenge dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20407v1</guid>
      <category>physics.ins-det</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thorsten Buss, Frank Gaede, Gregor Kasieczka, Claudius Krause, David Shih</dc:creator>
    </item>
    <item>
      <title>Universal evaluation and design of imaging systems using information estimation</title>
      <link>https://arxiv.org/abs/2405.20559</link>
      <description>arXiv:2405.20559v1 Announce Type: cross 
Abstract: Information theory, which describes the transmission of signals in the presence of noise, has enabled the development of reliable communication systems that underlie the modern world. Imaging systems can also be viewed as a form of communication, in which information about the object is "transmitted" through images. However, the application of information theory to imaging systems has been limited by the challenges of accounting for their physical constraints. Here, we introduce a framework that addresses these limitations by modeling the probabilistic relationship between objects and their measurements. Using this framework, we develop a method to estimate information using only a dataset of noisy measurements, without making any assumptions about the image formation process. We demonstrate that these estimates comprehensively quantify measurement quality across a diverse range of imaging systems and applications. Furthermore, we introduce Information-Driven Encoder Analysis Learning (IDEAL), a technique to optimize the design of imaging hardware for maximum information capture. This work provides new insights into the fundamental performance limits of imaging systems and offers powerful new tools for their analysis and design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20559v1</guid>
      <category>physics.optics</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Pinkard, Leyla Kabuli, Eric Markley, Tiffany Chien, Jiantao Jiao, Laura Waller</dc:creator>
    </item>
    <item>
      <title>Gaussian Framework and Optimal Projection of Weather Fields for Prediction of Extreme Events</title>
      <link>https://arxiv.org/abs/2405.20903</link>
      <description>arXiv:2405.20903v1 Announce Type: cross 
Abstract: Extreme events are the major weather related hazard for humanity. It is then of crucial importance to have a good understanding of their statistics and to be able to forecast them. However, lack of sufficient data makes their study particularly challenging.
  In this work we provide a simple framework to study extreme events that tackles the lack of data issue by using the whole dataset available, rather than focusing on the extremes in the dataset. To do so, we make the assumption that the set of predictors and the observable used to define the extreme event follow a jointly Gaussian distribution. This naturally gives the notion of an optimal projection of the predictors for forecasting the event.
  We take as a case study extreme heatwaves over France, and we test our method on an 8000-year-long intermediate complexity climate model time series and on the ERA5 reanalysis dataset.
  For a-posteriori statistics, we observe and motivate the fact that composite maps of very extreme events look similar to less extreme ones.
  For prediction, we show that our method is competitive with off-the-shelf neural networks on the long dataset and outperforms them on reanalysis.
  The optimal projection pattern, which makes our forecast intrinsically interpretable, highlights the importance of soil moisture deficit and quasi-stationary Rossby waves as precursors to extreme heatwaves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20903v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Valeria Mascolo, Alessandro Lovo, Corentin Herbert, Freddy Bouchet</dc:creator>
    </item>
    <item>
      <title>Predicting ptychography probe positions using single-shot phase retrieval neural network</title>
      <link>https://arxiv.org/abs/2405.20910</link>
      <description>arXiv:2405.20910v1 Announce Type: cross 
Abstract: Ptychography is a powerful imaging technique that is used in a variety of fields, including materials science, biology, and nanotechnology. However, the accuracy of the reconstructed ptychography image is highly dependent on the accuracy of the recorded probe positions which often contain errors. These errors are typically corrected jointly with phase retrieval through numerical optimization approaches. When the error accumulates along the scan path or when the error magnitude is large, these approaches may not converge with satisfactory result. We propose a fundamentally new approach for ptychography probe position prediction for data with large position errors, where a neural network is used to make single-shot phase retrieval on individual diffraction patterns, yielding the object image at each scan point. The pairwise offsets among these images are then found using a robust image registration method, and the results are combined to yield the complete scan path by constructing and solving a linear equation. We show that our method can achieve good position prediction accuracy for data with large and accumulating errors on the order of $10^2$ pixels, a magnitude that often makes optimization-based algorithms fail to converge. For ptychography instruments without sophisticated position control equipment such as interferometers, our method is of significant practical potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20910v1</guid>
      <category>physics.app-ph</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Du, Tao Zhou, Junjing Deng, Daniel J. Ching, Steven Henke, Mathew J. Cherukara</dc:creator>
    </item>
    <item>
      <title>Flexible inference in heterogeneous and attributed multilayer networks</title>
      <link>https://arxiv.org/abs/2405.20918</link>
      <description>arXiv:2405.20918v1 Announce Type: cross 
Abstract: Networked datasets are often enriched by different types of information about individual nodes or edges. However, most existing methods for analyzing such datasets struggle to handle the complexity of heterogeneous data, often requiring substantial model-specific analysis. In this paper, we develop a probabilistic generative model to perform inference in multilayer networks with arbitrary types of information. Our approach employs a Bayesian framework combined with the Laplace matching technique to ease interpretation of inferred parameters. Furthermore, the algorithmic implementation relies on automatic differentiation, avoiding the need for explicit derivations. This makes our model scalable and flexible to adapt to any combination of input data. We demonstrate the effectiveness of our method in detecting overlapping community structures and performing various prediction tasks on heterogeneous multilayer data, where nodes and edges have different types of attributes. Additionally, we showcase its ability to unveil a variety of patterns in a social support network among villagers in rural India by effectively utilizing all input information in a meaningful way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20918v1</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Martina Contisciani, Marius Hobbhahn, Eleanor A. Power, Philipp Hennig, Caterina De Bacco</dc:creator>
    </item>
    <item>
      <title>Log-Normal Waiting Time Widths Characterize Dynamics</title>
      <link>https://arxiv.org/abs/2303.05578</link>
      <description>arXiv:2303.05578v3 Announce Type: replace-cross 
Abstract: Many astronomical phenomena, including Fast Radio Bursts and Soft Gamma Repeaters, consist of brief, separated, seemingly aperiodic events. The intervals between these events vary randomly, but there are epochs of greater activity, with shorter mean intervals, and of lesser activity, with longer mean intervals. This variability can be quantified by a single dimensionless parameter, the width of a log-normal fit to the distribution of waiting times between events. If the distribution of event strengths is a power law, as is often the case, this parameter is independent of the detection threshold and is a robust measure of the intrinsic variability of the waiting times and of the underlying dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05578v3</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. I. Katz</dc:creator>
    </item>
    <item>
      <title>Learning protein-ligand unbinding pathways via single-parameter community detection</title>
      <link>https://arxiv.org/abs/2402.07103</link>
      <description>arXiv:2402.07103v3 Announce Type: replace-cross 
Abstract: Understanding the dynamics of biomolecular complexes, e.g., of protein-ligand (un)binding, requires the understanding of paths such systems take between metastable states. In MD simulation data, paths are usually not observable per se, but need to be inferred from simulation trajectories. Here we present a novel approach to cluster trajectories based on a community detection algorithm that requires the definition of only a single free parameter. Using the streptavidin-biotin complex as benchmark system and the A\textsubscript{2a} adenosine receptor in complex with the inhibitor ZM241385 as an elaborate application, we demonstrate how such clusters of trajectories correspond to pathways, and how the approach helps in the identification of reaction coordinates for a considered (un)binding process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07103v3</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor T\"anzel, Miriam J\"ager, Steffen Wolf</dc:creator>
    </item>
  </channel>
</rss>
