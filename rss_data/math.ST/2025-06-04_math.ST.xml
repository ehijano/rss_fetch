<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 01:38:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quasi-symmetry and geometric marginal homogeneity: A simplicial approach to square contingency tables</title>
      <link>https://arxiv.org/abs/2506.02474</link>
      <description>arXiv:2506.02474v1 Announce Type: new 
Abstract: Square contingency tables are traditionally analyzed with a focus on the symmetric structure of the corresponding probability tables. We view probability tables as elements of a simplex equipped with the Aitchison geometry. This perspective allows us to present a novel approach to analyzing symmetric structure using a compositionally coherent framework. We present a geometric interpretation of quasi-symmetry as an e-flat subspace and introduce a new concept called geometric marginal homogeneity, which is also characterized as an e-flat structure. We prove that both quasi-symmetric tables and geometric marginal homogeneous tables form subspaces in the simplex, and demonstrate that the measure of skew-symmetry in Aitchison geometry can be orthogonally decomposed into measures of departure from quasi-symmetry and geometric marginal homogeneity. We illustrate the application and effectiveness of our proposed methodology using data on unaided distance vision from a sample of women.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02474v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Nakamura, Tomoyuki Nakagawa, Kouji Tahata</dc:creator>
    </item>
    <item>
      <title>A non-local estimator for locally stationary Hawkes processes</title>
      <link>https://arxiv.org/abs/2506.02631</link>
      <description>arXiv:2506.02631v1 Announce Type: new 
Abstract: We consider the problem of estimating the parameters of a non-stationary Hawkes process with time-dependent reproduction rate and baseline intensity. Our approach relies on the standard maximum likelihood estimator (MLE), coinciding with the conventional approach for stationary point processes characterised by [Ogata, 1978]. In the fully parametric setting, we find that the MLE over a single observation of the process over $[0, T]$ remains consistent and asymptotically normal as $T \to \infty$. Our results extend partially to the semi-nonparametric setting where no specific shape is assumed for the reproduction rate $g \colon [0, 1] \mapsto \mathbb{R}_+$. We construct a time invariance test with null hypothesis that g is constant against the alternative that it is not, and find that it remains consistent over the whole space of continuous functions of [0, 1]. As an application, we employ our procedure in the context of the German intraday power market, where we provide evidence of fluctuations in the endogeneity rate of the order flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02631v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Deschatre, Pierre Gruet, Antoine Lotz</dc:creator>
    </item>
    <item>
      <title>Gromov-Wasserstein Bound between Reeb and Mapper Graphs</title>
      <link>https://arxiv.org/abs/2506.02810</link>
      <description>arXiv:2506.02810v1 Announce Type: new 
Abstract: Since its introduction as a computable approximation of the Reeb graph, the Mapper graph has become one of the most popular tools from topological data analysis for performing data visualization and inference. However, finding an appropriate metric (that is, a tractable metric with theoretical guarantees) for comparing Reeb and Mapper graphs, in order to, e.g., quantify the rate of convergence of the Mapper graph to the Reeb graph, is a difficult problem. While several metrics have been proposed in the literature, none is able to incorporate measure information, when data points are sampled according to an underlying probability measure. The resulting Reeb and Mapper graphs are therefore purely deterministic and combinatorial, and substantial effort is thus required to ensure their statistical validity. In this article, we handle this issue by treating Reeb and Mapper graphs as metric measure spaces. This allows us to use Gromov-Wasserstein metrics to compare these graphs directly in order to better incorporate the probability measures that data points are sampled from. Then, we describe the geometry that arises from this perspective, and we derive rates of convergence of the Mapper graph to the Reeb graph in this context. Finally, we showcase the usefulness of such metrics for Reeb and Mapper graphs in a few numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02810v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyad Oulhaj, Mathieu Carri\`ere, Bertrand Michel</dc:creator>
    </item>
    <item>
      <title>On the Benefits of Accelerated Optimization in Robust and Private Estimation</title>
      <link>https://arxiv.org/abs/2506.03044</link>
      <description>arXiv:2506.03044v1 Announce Type: new 
Abstract: We study the advantages of accelerated gradient methods, specifically based on the Frank-Wolfe method and projected gradient descent, for privacy and heavy-tailed robustness. Our approaches are as follows: For the Frank-Wolfe method, our technique is based on a tailored learning rate and a uniform lower bound on the gradient of the $\ell_2$-norm over the constraint set. For accelerating projected gradient descent, we use the popular variant based on Nesterov's momentum, and we optimize our objective over $\mathbb{R}^p$. These accelerations reduce iteration complexity, translating into stronger statistical guarantees for empirical and population risk minimization. Our analysis covers three settings: non-random data, random model-free data, and parametric models (linear regression and generalized linear models). Methodologically, we approach both privacy and robustness based on noisy gradients. We ensure differential privacy via the Gaussian mechanism and advanced composition, and we achieve heavy-tailed robustness using a geometric median-of-means estimator, which also sharpens the dependency on the dimension of the covariates. Finally, we compare our rates to existing bounds and identify scenarios where our methods attain optimal convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03044v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurentiu Andrei Marchis, Po-Ling Loh</dc:creator>
    </item>
    <item>
      <title>Party Ideologies and Political Polarization-Driven Conflicts: A Study of the Global South</title>
      <link>https://arxiv.org/abs/2506.02004</link>
      <description>arXiv:2506.02004v1 Announce Type: cross 
Abstract: Post-World War II armed conflicts have often been viewed with higher scrutiny in order to avoid a full-scale global war. This scrutiny has led to the establishment of determinants of war such as poverty, inequalities, literacy, and many more. There is a gap that exists in probing countries in the Global South for political party fragmentation and examining ideology-driven polarization's effect on armed conflicts. This paper fills this gap by asking the question: How does political identity-induced polarization affect conflicts in the Global South region? Polarization indices are created based on socially relevant issues and party stances from the V-Party Dataset. Along with control variables, they are tested against the response variables conflict frequency and conflict severity created from the UCDP (Uppsala Conflict Data Program). Through Chow's test, Regional Structural Breaks are found between regions when accounting for polarization-conflict dynamics. A multilevel mixed effects modelling approach is used to create region-specific models to find what types of polarization affect conflict in different geographies and their adherence to normative current developments. The paper highlights that vulnerable regions of the world are prone to higher polarization-induced violence. Modelling estimates indicate polarization of party credo on Minority Rights, Rejection of Political Violence, Religious Principles, and Political Pluralism are strong proponents of cultivated violence. The Global South's inhibitions and slow progress towards development are caused by hindrances from armed conflicts; this paper's results show self-inflicted political instability and fragmentation's influence on these events, making the case for urgency in addressing and building inter-group homogeneity and tolerance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02004v1</guid>
      <category>physics.soc-ph</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreyansh Padarha</dc:creator>
    </item>
    <item>
      <title>Assumption-free stability for ranking problems</title>
      <link>https://arxiv.org/abs/2506.02257</link>
      <description>arXiv:2506.02257v1 Announce Type: cross 
Abstract: In this work, we consider ranking problems among a finite set of candidates: for instance, selecting the top-$k$ items among a larger list of candidates or obtaining the full ranking of all items in the set. These problems are often unstable, in the sense that estimating a ranking from noisy data can exhibit high sensitivity to small perturbations. Concretely, if we use data to provide a score for each item (say, by aggregating preference data over a sample of users), then for two items with similar scores, small fluctuations in the data can alter the relative ranking of those items. Many existing theoretical results for ranking problems assume a separation condition to avoid this challenge, but real-world data often contains items whose scores are approximately tied, limiting the applicability of existing theory. To address this gap, we develop a new algorithmic stability framework for ranking problems, and propose two novel ranking operators for achieving stable ranking: the \emph{inflated top-$k$} for the top-$k$ selection problem and the \emph{inflated full ranking} for ranking the full list. To enable stability, each method allows for expressing some uncertainty in the output. For both of these two problems, our proposed methods provide guaranteed stability, with no assumptions on data distributions and no dependence on the total number of candidates to be ranked. Experiments on real-world data confirm that the proposed methods offer stability without compromising the informativeness of the output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02257v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiting Liang, Jake A. Soloff, Rina Foygel Barber, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Absorb and Converge: Provable Convergence Guarantee for Absorbing Discrete Diffusion Models</title>
      <link>https://arxiv.org/abs/2506.02318</link>
      <description>arXiv:2506.02318v1 Announce Type: cross 
Abstract: Discrete state space diffusion models have shown significant advantages in applications involving discrete data, such as text and image generation. It has also been observed that their performance is highly sensitive to the choice of rate matrices, particularly between uniform and absorbing rate matrices. While empirical results suggest that absorbing rate matrices often yield better generation quality compared to uniform rate matrices, existing theoretical works have largely focused on the uniform rate matrices case. Notably, convergence guarantees and error analyses for absorbing diffusion models are still missing. In this work, we provide the first finite-time error bounds and convergence rate analysis for discrete diffusion models using absorbing rate matrices. We begin by deriving an upper bound on the KL divergence of the forward process, introducing a surrogate initialization distribution to address the challenge posed by the absorbing stationary distribution, which is a singleton and causes the KL divergence to be ill-defined. We then establish the first convergence guarantees for both the $\tau$-leaping and uniformization samplers under absorbing rate matrices, demonstrating improved rates over their counterparts using uniform rate matrices. Furthermore, under suitable assumptions, we provide convergence guarantees without early stopping. Our analysis introduces several new technical tools to address challenges unique to absorbing rate matrices. These include a Jensen-type argument for bounding forward process convergence, novel techniques for bounding absorbing score functions, and a non-divergent upper bound on the score near initialization that removes the need of early-stopping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02318v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Liang, Renxiang Huang, Lifeng Lai, Ness Shroff, Yingbin Liang</dc:creator>
    </item>
    <item>
      <title>On the rate of convergence in the CLT for LSS of large-dimensional sample covariance matrices</title>
      <link>https://arxiv.org/abs/2506.02880</link>
      <description>arXiv:2506.02880v2 Announce Type: cross 
Abstract: This paper investigates the rate of convergence for the central limit theorem of linear spectral statistic (LSS) associated with large-dimensional sample covariance matrices. We consider matrices of the form ${\mathbf B}_n=\frac{1}{n}{\mathbf T}_p^{1/2}{\mathbf X}_n{\mathbf X}_n^*{\mathbf T}_p^{1/2},$ where ${\mathbf X}_n= (x_{i j} ) $ is a $p \times n$ matrix whose entries are independent and identically distributed (i.i.d.) real or complex variables, and ${\mathbf T} _p$ is a $p\times p$ nonrandom Hermitian nonnegative definite matrix with its spectral norm uniformly bounded in $p$. Employing Stein's method, we establish that if the entries $x_{ij}$ satisfy $\mathbb{E}|x_{ij}|^{10}&lt;\infty$ and the ratio of the dimension to sample size $p/n\to y&gt;0$ as $n\to\infty$, then the convergence rate of the normalized LSS of ${\mathbf B}_n$ to the standard normal distribution, measured in the Kolmogorov-Smirnov distance, is $O(n^{-1/2+\kappa})$ for any fixed $\kappa&gt;0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02880v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Cui, Jiang Hu, Zhidong Bai, Guorong Hu</dc:creator>
    </item>
    <item>
      <title>Power Enhancement of Permutation-Augmented Partial-Correlation Tests via Fixed-Row Permutations</title>
      <link>https://arxiv.org/abs/2506.02906</link>
      <description>arXiv:2506.02906v1 Announce Type: cross 
Abstract: Permutation-based partial-correlation tests guarantee finite-sample Type I error control under any fixed design and exchangeable noise, yet their power can collapse when the permutation-augmented design aligns too closely with the covariate of interest. We remedy this by fixing a design-driven subset of rows and permuting only the remainder. The fixed rows are chosen by a greedy algorithm that maximizes a lower bound on power. This strategy reduces covariate-permutation collinearity while preserving worst-case Type I error control. Simulations confirm that this refinement maintains nominal size and delivers substantial power gains over original unrestricted permutations, especially in high-collinearity regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02906v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyi Wang, Guanghui Wang, Zhaojun Wang, Changliang Zou</dc:creator>
    </item>
    <item>
      <title>Sample complexity of Schr\"odinger potential estimation</title>
      <link>https://arxiv.org/abs/2506.03043</link>
      <description>arXiv:2506.03043v1 Announce Type: cross 
Abstract: We address the problem of Schr\"odinger potential estimation, which plays a crucial role in modern generative modelling approaches based on Schr\"odinger bridges and stochastic optimal control for SDEs. Given a simple prior diffusion process, these methods search for a path between two given distributions $\rho_0$ and $\rho_T^*$ requiring minimal efforts. The optimal drift in this case can be expressed through a Schr\"odinger potential. In the present paper, we study generalization ability of an empirical Kullback-Leibler (KL) risk minimizer over a class of admissible log-potentials aimed at fitting the marginal distribution at time $T$. Under reasonable assumptions on the target distribution $\rho_T^*$ and the prior process, we derive a non-asymptotic high-probability upper bound on the KL-divergence between $\rho_T^*$ and the terminal density corresponding to the estimated log-potential. In particular, we show that the excess KL-risk may decrease as fast as $O(\log^2 n / n)$ when the sample size $n$ tends to infinity even if both $\rho_0$ and $\rho_T^*$ have unbounded supports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03043v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Puchkin, Iurii Pustovalov, Yuri Sapronov, Denis Suchkov, Alexey Naumov, Denis Belomestny</dc:creator>
    </item>
    <item>
      <title>Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds</title>
      <link>https://arxiv.org/abs/2506.03100</link>
      <description>arXiv:2506.03100v1 Announce Type: cross 
Abstract: Retrieval-augmented generation (RAG) has seen many empirical successes in recent years by aiding the LLM with external knowledge. However, its theoretical aspect has remained mostly unexplored. In this paper, we propose the first finite-sample generalization bound for RAG in in-context linear regression and derive an exact bias-variance tradeoff. Our framework views the retrieved texts as query-dependent noisy in-context examples and recovers the classical in-context learning (ICL) and standard RAG as the limit cases. Our analysis suggests that an intrinsic ceiling on generalization error exists on RAG as opposed to the ICL. Furthermore, our framework is able to model retrieval both from the training data and from external corpora by introducing uniform and non-uniform RAG noise. In line with our theory, we show the sample efficiency of ICL and RAG empirically with experiments on common QA benchmarks, such as Natural Questions and TriviaQA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03100v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yang Guo, Yutian Tao, Yifei Ming, Robert D. Nowak, Yingyu Liang</dc:creator>
    </item>
    <item>
      <title>The High-Dimensional Asymptotics of Principal Component Regression</title>
      <link>https://arxiv.org/abs/2405.11676</link>
      <description>arXiv:2405.11676v3 Announce Type: replace 
Abstract: We study principal components regression (PCR) in an asymptotic high-dimensional regression setting, where the number of data points is proportional to the dimension. We derive exact limiting formulas for the estimation and prediction risks, which depend in a complicated manner on the eigenvalues of the population covariance, the alignment between the population PCs and the true signal, and the number of selected PCs. A key challenge in the high-dimensional setting stems from the fact that the sample covariance is an inconsistent estimate of its population counterpart, so that sample PCs may fail to fully capture potential latent low-dimensional structure in the data. We demonstrate this point through several case studies, including that of a spiked covariance model.
  To calculate the asymptotic prediction risk, we leverage tools from random matrix theory which to our knowledge have not seen much use to date in the statistics literature: multi-resolvent traces and their associated eigenvector overlap measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11676v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alden Green, Elad Romanov</dc:creator>
    </item>
    <item>
      <title>eGAD! double descent is explained by Generalized Aliasing Decomposition</title>
      <link>https://arxiv.org/abs/2408.08294</link>
      <description>arXiv:2408.08294v4 Announce Type: replace 
Abstract: A central problem in data science is to use potentially noisy samples of an unknown function to predict values for unseen inputs. In classical statistics, predictive error is understood as a trade-off between the bias and the variance that balances model simplicity with its ability to fit complex functions. However, over-parameterized models exhibit counterintuitive behaviors, such as "double descent" in which models of increasing complexity exhibit decreasing generalization error. Others may exhibit more complicated patterns of predictive error with multiple peaks and valleys. Neither double descent nor multiple descent phenomena are well explained by the bias-variance decomposition.
  We introduce a novel decomposition that we call the generalized aliasing decomposition (GAD) to explain the relationship between predictive performance and model complexity. The GAD decomposes the predictive error into three parts: 1) model insufficiency, which dominates when the number of parameters is much smaller than the number of data points, 2) data insufficiency, which dominates when the number of parameters is much greater than the number of data points, and 3) generalized aliasing, which dominates between these two extremes.
  We demonstrate the applicability of the GAD to diverse applications, including random feature models from machine learning, Fourier transforms from signal processing, solution methods for differential equations, and predictive formation enthalpy in materials discovery. Because key components of the GAD can be explicitly calculated from the relationship between model class and samples without seeing any data labels, it can answer questions related to experimental design and model selection before collecting data or performing experiments. We further demonstrate this approach on several examples and discuss implications for predictive modeling and data science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08294v4</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark K. Transtrum, Gus L. W. Hart, Tyler J. Jarvis, Jared P. Whitehead</dc:creator>
    </item>
    <item>
      <title>Self-Organizing State-Space Models with Artificial Dynamics</title>
      <link>https://arxiv.org/abs/2409.08928</link>
      <description>arXiv:2409.08928v5 Announce Type: replace 
Abstract: We consider the problem of performing parameter and state inference in a state-space model (SSM) parametrized by a static parameter $\theta$. A popular idea to address this problem consists of incorporating $\theta$ in the state of the system and allowing its time evolution, modelled as a Markov chain $(\theta_t)_{t\geq 1}$. This proxy model defines a so-called self-organizing SSM (SO-SSM) to which one may apply standard particle filters. However, the practical implementation of this idea in a theoretically justified manner has remained an open problem until now. In this paper we fill this gap and in particular show that theoretically consistent SO-SSMs can be defined such that $\|\mathrm{Var}(\theta_{t+1}|\theta_{t})\|\rightarrow 0$ slowly as $t\rightarrow\infty$. This, in turn, leads to particle filter algorithms for online inference in SSMs which we find to be robust in simulation. We also develop constructions of $(\theta_t)_{t\geq 1}$ and associated theoretical guarantees tailored to the application of SO-SSMs to maximum likelihood estimation in SSMs, leading to novel iterated filtering algorithms. The algorithms developed in this work have the advantage of being simple to implement and to require minimal tuning to perform well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08928v5</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Chen, Mathieu Gerber, Christophe Andrieu, Randal Douc</dc:creator>
    </item>
    <item>
      <title>Theoretical Foundations of Conformal Prediction</title>
      <link>https://arxiv.org/abs/2411.11824</link>
      <description>arXiv:2411.11824v3 Announce Type: replace 
Abstract: This book is about conformal prediction and related inferential techniques that build on permutation tests and exchangeability. These techniques are useful in a diverse array of tasks, including hypothesis testing and providing uncertainty quantification guarantees for machine learning systems. Much of the current interest in conformal prediction is due to its ability to integrate into complex machine learning workflows, solving the problem of forming prediction sets without any assumptions on the form of the data generating distribution. Since contemporary machine learning algorithms have generally proven difficult to analyze directly, conformal prediction's main appeal is its ability to provide formal, finite-sample guarantees when paired with such methods.
  The goal of this book is to teach the reader about the fundamental technical arguments that arise when researching conformal prediction and related questions in distribution-free inference. Many of these proof strategies, especially the more recent ones, are scattered among research papers, making it difficult for researchers to understand where to look, which results are important, and how exactly the proofs work. We hope to bridge this gap by curating what we believe to be some of the most important results in the literature and presenting their proofs in a unified language, with illustrations, and with an eye towards pedagogy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11824v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasios N. Angelopoulos, Rina Foygel Barber, Stephen Bates</dc:creator>
    </item>
    <item>
      <title>High-dimensional Gaussian and bootstrap approximations for robust means</title>
      <link>https://arxiv.org/abs/2504.08435</link>
      <description>arXiv:2504.08435v2 Announce Type: replace 
Abstract: Recent years have witnessed much progress on Gaussian and bootstrap approximations to the distribution of max-type statistics of sums of independent random vectors with dimension $d$ large relative to the sample size $n$. However, for any number of moments $m&gt;2$ that the summands may possess, there exist distributions such that these approximations break down if $d$ grows faster than $n^{\frac{m}{2}-1}$. In this paper, we establish Gaussian and bootstrap approximations to the distributions of winsorized and trimmed means that allow $d$ to grow at an exponential rate in $n$ as long as $m&gt;2$ moments exist. The approximations remain valid under some amount of adversarial contamination. Our implementations of the winsorized and trimmed means are fully data-driven and do not depend on any unknown population quantities. As a consequence, the performance of the approximation guarantees ``adapts'' to $m$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08435v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anders Bredahl Kock, David Preinerstorfer</dc:creator>
    </item>
    <item>
      <title>Joint estimation of smooth graph signals from partial linear measurements</title>
      <link>https://arxiv.org/abs/2505.23240</link>
      <description>arXiv:2505.23240v2 Announce Type: replace 
Abstract: Given an undirected and connected graph $G$ on $T$ vertices, suppose each vertex $t$ has a latent signal $x_t \in \mathbb{R}^n$ associated to it. Given partial linear measurements of the signals, for a potentially small subset of the vertices, our goal is to estimate $x_t$'s. Assuming that the signals are smooth w.r.t $G$, in the sense that the quadratic variation of the signals over the graph is small, we obtain non-asymptotic bounds on the mean squared error for jointly recovering $x_t$'s, for the smoothness penalized least squares estimator. In particular, this implies for certain choices of $G$ that this estimator is weakly consistent (as $T \rightarrow \infty$) under potentially very stringent sampling, where only one coordinate is measured per vertex for a vanishingly small fraction of the vertices. The results are extended to a ``multi-layer'' ranking problem where $x_t$ corresponds to the latent strengths of a collection of $n$ items, and noisy pairwise difference measurements are obtained at each ``layer'' $t$ via a measurement graph $G_t$. Weak consistency is established for certain choices of $G$ even when the individual $G_t$'s are very sparse and disconnected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23240v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hemant Tyagi</dc:creator>
    </item>
    <item>
      <title>Accelerate Langevin Sampling with Birth-Death Process and Exploration Component</title>
      <link>https://arxiv.org/abs/2305.05529</link>
      <description>arXiv:2305.05529v2 Announce Type: replace-cross 
Abstract: Sampling a probability distribution with known likelihood is a fundamental task in computational science and engineering. Aiming at multimodality, we propose a new sampling method that takes advantage of both birth-death process and exploration component. The main idea of this method is look before you leap. We keep two sets of samplers, one at warmer temperature and one at original temperature. The former one serves as pioneer in exploring new modes and passing useful information to the other, while the latter one samples the target distribution after receiving the information. We derive a mean-field limit and show how the exploration component accelerates the sampling process. Moreover, we prove exponential asymptotic convergence under mild assumption. Finally, we test on experiments from previous literature and compare our methodology to previous ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05529v2</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lezhi Tan, Jianfeng Lu</dc:creator>
    </item>
    <item>
      <title>Fast and Multiphase Rates for Nearest Neighbor Classifiers</title>
      <link>https://arxiv.org/abs/2308.08247</link>
      <description>arXiv:2308.08247v2 Announce Type: replace-cross 
Abstract: We study the scaling of classification error rates with respect to the size of the training dataset. In contrast to classical results where rates are minimax optimal for a problem class, this work starts with the empirical observation that, even for a fixed data distribution, the error scaling can have \emph{diverse} rates across different ranges of sample size. To understand when and why the error rate is non-uniform, we theoretically analyze nearest neighbor classifiers. We show that an error scaling law can have fine-grained rates: in the early phase, the test error depends polynomially on the data dimension and decreases fast; whereas in the later phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the test error. When the data are distributed benignly, we show that the generalization error of nearest neighbor classifier can depend polynomially, instead of exponentially, on the data dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08247v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pengkun Yang, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Spectral Clustering for Directed Graphs via Likelihood Estimation on Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2403.19516</link>
      <description>arXiv:2403.19516v2 Announce Type: replace-cross 
Abstract: Graph clustering is a fundamental task in unsupervised learning with broad real-world applications. While spectral clustering methods for undirected graphs are well-established and guided by a minimum cut optimization consensus, their extension to directed graphs remains relatively underexplored due to the additional complexity introduced by edge directions. In this paper, we leverage statistical inference on stochastic block models to guide the development of a spectral clustering algorithm for directed graphs. Specifically, we study the maximum likelihood estimation under a widely used directed stochastic block model, and derive a global objective function that aligns with the underlying community structure. We further establish a theoretical upper bound on the misclustering error of its spectral relaxation, and based on this relaxation, introduce a novel, self-adaptive spectral clustering method for directed graphs. Extensive experiments on synthetic and real-world datasets demonstrate significant performance gains over existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19516v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Zhang, Xiaowen Dong, Mihai Cucuringu</dc:creator>
    </item>
    <item>
      <title>Joint Learning of Linear Dynamical Systems under Smoothness Constraints</title>
      <link>https://arxiv.org/abs/2406.01094</link>
      <description>arXiv:2406.01094v2 Announce Type: replace-cross 
Abstract: We consider the problem of joint learning of multiple linear dynamical systems. This has received significant attention recently under different types of assumptions on the model parameters. The setting we consider involves a collection of $m$ linear systems, each of which resides on a node of a given undirected graph $G = ([m], \mathcal{E})$. We assume that the system matrices are marginally stable, and satisfy a smoothness constraint w.r.t $G$ -- akin to the quadratic variation of a signal on a graph. Given access to the states of the nodes over $T$ time points, we then propose two estimators for joint estimation of the system matrices, along with non-asymptotic error bounds on the mean-squared error (MSE). In particular, we show conditions under which the MSE converges to zero as $m$ increases, typically polynomially fast w.r.t $m$. The results hold under mild (i.e., $T \sim \log m$), or sometimes, even no assumption on $T$ (i.e. $T \geq 2$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01094v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hemant Tyagi</dc:creator>
    </item>
    <item>
      <title>Quadratic Form based Multiple Contrast Tests for Comparison of Group Means</title>
      <link>https://arxiv.org/abs/2411.10121</link>
      <description>arXiv:2411.10121v2 Announce Type: replace-cross 
Abstract: Comparing the mean vectors across different groups is a cornerstone in the realm of multivariate statistics, with quadratic forms commonly serving as test statistics. However, when the overall hypothesis is rejected, identifying specific vector components or determining the groups among which differences exist requires additional investigations. Conversely, employing multiple contrast tests (MCT) allows conclusions about which components or groups contribute to these differences. However, they come with a trade-off, as MCT lose some benefits inherent to quadratic forms. In this paper, we combine both approaches to get a quadratic form based multiple contrast test that leverages the advantages of both. To understand its theoretical properties, we investigate its asymptotic distribution in a semiparametric model. We thereby focus on two common quadratic forms - the Wald-type statistic and the Anova-type statistic - although our findings are applicable to any quadratic form.
  Furthermore, we employ Monte-Carlo and resampling techniques to enhance the test's performance in small sample scenarios. Through an extensive simulation study, we assess the performance of our proposed tests against existing alternatives, highlighting their advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10121v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paavo Sattler, Markus Pauly, Merle Munko</dc:creator>
    </item>
    <item>
      <title>Improved Margin Generalization Bounds for Voting Classifiers</title>
      <link>https://arxiv.org/abs/2502.16462</link>
      <description>arXiv:2502.16462v2 Announce Type: replace-cross 
Abstract: In this paper we establish a new margin-based generalization bound for voting classifiers, refining existing results and yielding tighter generalization guarantees for widely used boosting algorithms such as AdaBoost (Freund and Schapire, 1997). Furthermore, the new margin-based generalization bound enables the derivation of an optimal weak-to-strong learner: a Majority-of-3 large-margin classifiers with an expected error matching the theoretical lower bound. This result provides a more natural alternative to the Majority-of-5 algorithm by (H{\o}gsgaard et al., 2024), and matches the Majority-of-3 result by (Aden-Ali et al., 2024) for the realizable prediction model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16462v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikael M{\o}ller H{\o}gsgaard, Kasper Green Larsen</dc:creator>
    </item>
    <item>
      <title>Kernel-based estimators for functional causal effects</title>
      <link>https://arxiv.org/abs/2503.05024</link>
      <description>arXiv:2503.05024v4 Announce Type: replace-cross 
Abstract: We propose causal effect estimators based on empirical Fr\'{e}chet means and operator-valued kernels, tailored to functional data spaces. These methods address the challenges of high-dimensionality, sequential ordering, and model complexity while preserving robustness to treatment misspecification. Using structural assumptions, we obtain compact representations of potential outcomes, enabling scalable estimation of causal effects over time and across covariates. We provide both theoretical, regarding the consistency of functional causal effects, as well as empirical comparison of a range of proposed causal effect estimators.
  Applications to binary treatment settings with functional outcomes illustrate the framework's utility in biomedical monitoring, where outcomes exhibit complex temporal dynamics. Our estimators accommodate scenarios with registered covariates and outcomes, aligning them to the Fr\'{e}chet means, as well as cases requiring higher-order representations to capture intricate covariate-outcome interactions. These advancements extend causal inference to dynamic and non-linear domains, offering new tools for understanding complex treatment effects in functional data settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05024v4</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yordan P. Raykov, Hengrui Luo, Justin D. Strait, Wasiur R. KhudaBukhsh</dc:creator>
    </item>
  </channel>
</rss>
