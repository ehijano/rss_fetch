<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Oct 2025 04:00:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Resource-dependent process times in hybrid flexible flowshops</title>
      <link>https://arxiv.org/abs/2510.18093</link>
      <description>arXiv:2510.18093v1 Announce Type: new 
Abstract: The effect of resource allocation on manufacturing motivates us to examine a scheduling variant that is of practical significance yet remains overlooked. We examine a Hybrid Flexible Flowshop (HFFS), i.e., an environment where a set of jobs is scheduled across multiple stages (each stage having multiple identical machines) yet some jobs may skip some stages. In addition, we consider processing times that depend on the resources assigned to a job at each stage, transportation times between machines and limited-capacity buffers before and after each stage. We introduce a Constraint Programming (CP) formulation, which we then decompose through Logic-Based Benders Decomposition (LBBD). We tighten formulations by a set of makespan lower bounds, the strongest of which arises from a reduction to malleable scheduling. By modifying recent instance generators, we experiment with up to 400 jobs, 8 stages, and 10 parallel machines per stage. The results demonstrate competitive integrality gaps, highlighting the efficiency of our approach at scale and on an HFFS variant quite beyond the current literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18093v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Avgerinos, Ioannis Mourtos, Dimitrios Papathanasiou, Georgios Zois</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Search for Multi-Agent Model Predictive Control</title>
      <link>https://arxiv.org/abs/2510.18211</link>
      <description>arXiv:2510.18211v1 Announce Type: new 
Abstract: Many real-world multi-agent systems exhibit nonlinear dynamics and complex inter-agent interactions. As these systems increase in scale, the main challenges arise from achieving scalability and handling nonconvexity. To address these challenges, this paper presents a distributed sampling-based optimization framework for multi-agent model predictive control (MPC). We first introduce stochastic search, a generalized sampling-based optimization method, as an effective approach to solving nonconvex MPC problems because of its exploration capabilities. Nevertheless, optimizing the multi-agent systems in a centralized fashion is not scalable as the computational complexity grows intractably as the number of agents increases. To achieve scalability, we formulate a distributed MPC problem and employ the alternating direction method of multipliers (ADMM) to leverage the distributed approach. In multi-robot navigation simulations, the proposed method shows a remarkable capability to navigate through nonconvex environments, outperforming a distributed optimization baseline using the interior point optimizer (IPOPT). In a 64-agent multi-car formation task with a challenging configuration, our method achieves 100% task completion with zero collisions, whereas distributed IPOPT fails to find a feasible solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18211v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Taehyun Yoon, Augustinos D. Saravanos, Evangelos A. Theodorou</dc:creator>
    </item>
    <item>
      <title>DualHash: A Stochastic Primal-Dual Algorithm with Theoretical Guarantee for Deep Hashing</title>
      <link>https://arxiv.org/abs/2510.18218</link>
      <description>arXiv:2510.18218v1 Announce Type: new 
Abstract: Deep hashing converts high-dimensional feature vectors into compact binary codes, enabling efficient large-scale retrieval. A fundamental challenge in deep hashing stems from the discrete nature of quantization in generating the codes. W-type regularizations, such as $||z|-1|$, have been proven effective as they encourage variables toward binary values. However, existing methods often directly optimize these regularizations without convergence guarantees. While proximal gradient methods offer a promising solution, the coupling between W-type regularizers and neural network outputs results in composite forms that generally lack closed-form proximal solutions. In this paper, we present a stochastic primal-dual hashing algorithm, referred to as DualHash, that provides rigorous complexity bounds. Using Fenchel duality, we partially transform the nonconvex W-type regularization optimization into the dual space, which results in a proximal operator that admits closed-form solutions. We derive two algorithm instances: a momentum-accelerated version with $\mathcal{O}(\varepsilon^{-4})$ complexity and an improved $\mathcal{O}(\varepsilon^{-3})$ version using variance reduction. Experiments on three image retrieval databases demonstrate the superior performance of DualHash.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18218v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luxuan Li, Xiao Wang, Chunfeng Cui</dc:creator>
    </item>
    <item>
      <title>Harmonic Cancellation in Multi-Electrolyzer P2H Plants via Phasor-Modulated Production Scheduling</title>
      <link>https://arxiv.org/abs/2510.18223</link>
      <description>arXiv:2510.18223v1 Announce Type: new 
Abstract: Thyristor rectifiers (TRs) are cost-effective power supplies for hydrogen electrolyzers (ELZs) but introduce harmonic distortion that may violate grid codes. This letter proposes a self-governing harmonic mitigation strategy through coordinated operation of multiple ELZs in large power-to-hydrogen (P2H) plants. First, the harmonic model of TR-powered ELZs is derived, revealing a natural harmonic cancellation mechanism among them. Based on this, a system-level operation scheme based on phasor modulation is developed and integrated into plant scheduling. Case studies demonstrate that the proposed method reduces harmonic currents by 21.2%-39.7% and ensures grid-code compliance, with only a 0.25% loss in hydrogen output, while increasing total revenue by over 21\% compared to production-oriented strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18223v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangjun Zeng (College of Electrical Engineering, Sichuan University), Yiwei Qiu (College of Electrical Engineering, Sichuan University), Li Jiang (College of Electrical Engineering, Sichuan University), Jie Zhu (College of Electrical Engineering, Sichuan University), Yi Zhou (College of Electrical Engineering, Sichuan University), Jiarong Li (Harvard John A. Paulson School of Engineering and Applied Sciences), Shi Chen (College of Electrical Engineering, Sichuan University), Buxiang Zhou (College of Electrical Engineering, Sichuan University)</dc:creator>
    </item>
    <item>
      <title>Explicit Reformulation of Discrete Distributionally Robust Optimization Problems</title>
      <link>https://arxiv.org/abs/2510.18302</link>
      <description>arXiv:2510.18302v1 Announce Type: new 
Abstract: Distributionally robust optimization (DRO) is an effective framework for controlling real-world systems with various uncertainties, typically modeled using distributional uncertainty balls. However, DRO problems often involve infinitely many inequality constraints, rendering exact solutions computationally expensive. In this study, we propose a discrete DRO (DDRO) method that significantly simplifies the problem by reducing it to a single trivial constraint. Specifically, the proposed method utilizes two types of distributional uncertainty balls to reformulate the DDRO problem into a single-layer smooth convex program, significantly improving tractability. Furthermore, we provide practical guidance for selecting the appropriate ball sizes. The original DDRO problem is further reformulated into two optimization problems: one minimizing the mean and standard deviation, and the other minimizing the conditional value at risk (CVaR). These formulations account for the choice of ball sizes, thereby enhancing the practical applicability of the method. The proposed method was applied to a distributionally robust patrol-agent design problem, identifying a Pareto front in which the mean and standard deviation of the mean hitting time varied by up to 3% and 14%, respectively, while achieving a CVaR reduction of up to 13%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18302v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Shida, Yuji Ito</dc:creator>
    </item>
    <item>
      <title>Designing trajectories in the Earth-Moon system: a Levenberg-Marquardt approach</title>
      <link>https://arxiv.org/abs/2510.18474</link>
      <description>arXiv:2510.18474v1 Announce Type: new 
Abstract: Trajectory design in cislunar space under a High-Fidelity Ephemeris Model (HFEM) is pursued through a nonlinear optimization perspective anchored on the transition of solutions from lower fidelity models, namely the Circular Restricted Three-Body Problem (CR3BP). The optimization problem is posed in the likeness of a multiple-shooting approach, aiming for segment-to-segment continuity while tracking proximity to the original CR3BP structures. The analysis of various formulations leads to the selection of an unconstrained least-squares problem for further investigation. The nonlinear optimization problem is convexified and the use of the Levenberg-Marquardt algorithm, as an alternative to the minimum-norm update equation found in most literature, is investigated for its control over the update step and inherent robustness. Additional techniques such as adaptive weighting are employed to further consolidate the behavior of the proposed algorithm in challenging scenarios. Numerical trials evaluate the adequacy of the methodology presented and compare it to the minimum-norm baseline over various application cases, including the generation of quasi-periodic trajectories and orbital transfers between them. The proposed approach is found to outperform the baseline in applications where the initial guess is poor and the ease of including proximity constraints provides benefits in control over the shape of the converged solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18474v1</guid>
      <category>math.OC</category>
      <category>astro-ph.EP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ant\'onio Nunes, S\'ergio Br\'as, Pedro Batista, Jo\~ao Xavier</dc:creator>
    </item>
    <item>
      <title>Connecting Representative Periods in Energy System Optimization Models using Markov-Matrices</title>
      <link>https://arxiv.org/abs/2510.18555</link>
      <description>arXiv:2510.18555v1 Announce Type: new 
Abstract: Time series aggregation is a common approach to reduce the computational complexity of large-scale energy system optimization models. However, maintaining chronological continuity between the resulting representative periods (RPs) remains a key challenge, as transitions between RPs are typically lost. This leads to inaccuracies in storage behavior, unit commitment, and other time-linked aspects of the model. We propose a novel method that uses Markov-Matrices to link RPs via probabilistic transitions and expected values. The approach is also suitable for constraints that connect multiple time steps, and can be adjusted to work with binary variables. Benefits are shown on an illustrative case study and validated using the NREL-118 bus system, where it reduces the error to one fifth of the current state-of-the-art while retaining low computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18555v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix C. A. Auer, Diego A. Tejada-Arango, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>Don't Look Back in Anger: Wasserstein Distributionally Robust Optimization with Nonstationary Data</title>
      <link>https://arxiv.org/abs/2510.18566</link>
      <description>arXiv:2510.18566v1 Announce Type: new 
Abstract: We study data-driven decision problems where historical observations are generated by a time-evolving distribution whose consecutive shifts are bounded in Wasserstein distance. We address this nonstationarity using a distributionally robust optimization model with an ambiguity set that is a Wasserstein ball centered at a weighted empirical distribution, thereby allowing for the time decay of past data in a way which accounts for the drift of the data-generating distribution. Our main technical contribution is a concentration inequality for weighted empirical distributions that explicitly captures both the effective sample size (i.e., the equivalent number of equally weighted observations) and the distributional drift. Using our concentration inequality, we select observation weights that optimally balance the effective sample size against the extent of drift. The family of optimal weightings reveals an interplay between the order of the Wasserstein ambiguity ball and the time-decay profile of the optimal weights. Classical weighting schemes, such as time windowing and exponential smoothing, emerge as special cases of our framework, for which we derive principled choices of the parameters. Numerical experiments demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18566v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominic S. T. Keehan, Edward J. Anderson, Wolfram Wiesemann</dc:creator>
    </item>
    <item>
      <title>Adaptive Riemannian ADMM for Nonsmooth Optimization: Optimal Complexity without Smoothing</title>
      <link>https://arxiv.org/abs/2510.18617</link>
      <description>arXiv:2510.18617v1 Announce Type: new 
Abstract: We study the problem of minimizing the sum of a smooth function and a nonsmooth convex regularizer over a compact Riemannian submanifold embedded in Euclidean space. By introducing an auxiliary splitting variable, we propose an adaptive Riemannian alternating direction method of multipliers (ARADMM), which, for the first time, achieves convergence without requiring smoothing of the nonsmooth term. Our approach involves only one Riemannian gradient evaluation and one proximal update per iteration. Through careful and adaptive coordination of the stepsizes and penalty parameters, we establish an optimal iteration complexity of order $\mathcal{O}(\epsilon^{-3})$ for finding an $\epsilon$-approximate KKT point, matching the complexity of existing smoothing technique-based Riemannian ADMM methods. Extensive numerical experiments on sparse PCA and robust subspace recovery demonstrate that our ARADMM consistently outperforms state-of-the-art Riemannian ADMM variants in convergence speed and solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18617v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangkang Deng, Jiachen Jin, Jiang Hu, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Quadratic Convergence of a Projection Method for a Plane Curve Feasibility Problem</title>
      <link>https://arxiv.org/abs/2510.18676</link>
      <description>arXiv:2510.18676v1 Announce Type: new 
Abstract: Under conditions that prevent tangential intersection, we prove quadratic convergence of a projection algorithm for the feasibility problem of finding a point in the intersection of a smooth curve and line in $\mathbb{R}^2$. This nonconvex problem has been studied in the literature for both Douglas-Rachford algorithm (DR) and circumcentered reflection method (CRM), because it is prototypical of inverse problems in signal processing and image recovery. This result highlights the potential of extrapolated methods to meaningfully accelerate convergence in structured feasibility problems. Numerical experiments confirm the theoretical findings. Our work lays the foundations for extending such results to higher dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18676v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jordan Collard, Scott B. Lindstrom</dc:creator>
    </item>
    <item>
      <title>Approximation and exact penalization in simple bilevel variational problems</title>
      <link>https://arxiv.org/abs/2510.18682</link>
      <description>arXiv:2510.18682v1 Announce Type: new 
Abstract: A simple bilevel variational problem where the lower level is a variational inequality while the upper level is an optimization problem is studied. We consider an inexact version of the lower problem, which guarantees enough regularity to allow the exploitation of techniques of exact penalization. Moreover, cutting planes are used to approximate the Minty gap function of the lower level. Algorithms to solve the resulting inexact bilevel problem are devised relying on these techniques and approximations. Finally, their convergence is studied in details by analysing also the effect of the given inexactness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18682v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giancarlo Bigi, Riccardo Tomassini</dc:creator>
    </item>
    <item>
      <title>A Note on Optimal Distributed State Estimation for Linear Time-Varying Systems</title>
      <link>https://arxiv.org/abs/2510.18712</link>
      <description>arXiv:2510.18712v1 Announce Type: new 
Abstract: In this technical note, we prove that the ODEFTC algorithm constitutes the first optimal distributed state estimator for continuous-time linear time-varying systems subject to stochastic disturbances. Particularly, we formally show that it is able to asymptotically recover the performance, in terms of error covariance of the estimates at each node, of the centralized Kalman-Bucy filter, which is known to be the optimal filter for the considered class of systems. Moreover, we provide a simple sufficient value for the consensus gain to guarantee the stability of the distributed estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18712v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irene Perez-Salesa, Rodrigo Aldana-Lopez, Carlos Sagues</dc:creator>
    </item>
    <item>
      <title>Designing a Circular Economy Network for PPE Masks Supply Chain: A Case Study of British Columbia, Canada</title>
      <link>https://arxiv.org/abs/2510.18735</link>
      <description>arXiv:2510.18735v1 Announce Type: new 
Abstract: In recent years, there has been growing interest in building closed-loop supply chains (SCs). However, many of the current methods struggle when it comes to fully embracing circular economy principles. Enhancing the design and management of these networks holds significant potential to promote stronger collaboration among supply chain partners, ultimately fostering more sustainable and efficient operational practices. For this purpose, this study addresses a new circular economy model based on a real case study of a mask SC in the healthcare sector in British Columbia, Canada. The objective is to show that implementing circular practices can lead to considerable financial and environmental benefits, as well as the creation of new job opportunities. To achieve this, a multi-objective mixed-integer linear programming model is developed to identify the most efficient trade-off among sustainable objectives, while adhering to imposed constraints. The proposed closed-loop SC model outperforms the existing linear model in all three aspects of sustainability, namely economic, environmental and social. The improvement leads to significant economic and environmental benefits by preventing the disposal of used masks, giving them a second chance for disinfection and reprocessing, and reintroducing them into the SC as new ones. While the results of the circular economy model demonstrate profit gains and environmental recovery, the linear SC model showed negative profit with higher carbon emissions. Regarding the social aspects, compared to the current system, our approach not only nearly doubles the number of jobs created but also significantly reduces shortages, highlighting sustainable development aspects related to equity and social welfare. The findings offer valuable insights for researchers and practitioners seeking to implement sustainability within a circular economy framework in SCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18735v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jainil Dharmil Shah, Behrooz Khorshidvand, Niloofar Gilani Larimi, Adel Guitouni</dc:creator>
    </item>
    <item>
      <title>Optimized Fish Locomotion using Design-by-Morphing and Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2510.00044</link>
      <description>arXiv:2510.00044v1 Announce Type: cross 
Abstract: This study presents a computational framework for optimizing undulatory swimming profiles using a combination of design-by-morphing and Bayesian optimization strategies. The body deformation is expressed as a linear combination of five baseline bio-inspired profiles, including two unconventional shapes to enhance diversity in the design space. The optimization objective is to maximize propulsive efficiency over a wide range of frequency-wavelength combinations. The Arbitrary Lagrangian--Eulerian formulation is employed to simulate the unsteady flow around two-dimensional undulating swimmers. The optimized profile achieves a significantly improved efficiency of 82.4\%, while the second- and third-best profiles achieve efficiencies of 51.8\% and 42.8\%, respectively, outperforming the benchmark anguilliform and carangiform profiles by leveraging advantageous surface stress distributions and effective energy recovery mechanisms. A detailed force decomposition reveals that the optimal swimmer minimizes resistive drag and maximizes constructive work contributions, particularly in the anterior and posterior body regions. Spatial and temporal work decomposition indicates a strategic redistribution of input and recovered energy, enhancing performance while reducing energetic cost. The wake topology associated with the optimized swimmer exhibits organized and coherent vortex structures, reflecting superior fluid-structure interaction characteristics compared to conventional profiles. These findings demonstrate that morphing-based parametric design, when guided by surrogate-assisted optimization, offers a powerful framework for discovering energetically efficient swimming gaits, with significant implications for the design of autonomous underwater propulsion systems and the broader field of bio-inspired locomotion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00044v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hamayun Farooq, Imran Akhtar, Muhammad Saif Ullah Khalid, Haris Moazam Sheikh</dc:creator>
    </item>
    <item>
      <title>Quantitative Stability in Discrete Optimal Transport</title>
      <link>https://arxiv.org/abs/2510.17407</link>
      <description>arXiv:2510.17407v1 Announce Type: cross 
Abstract: This work investigates several aspects related to quantitative stability in optimal transport, as well as uniqueness of the dual transport problem. Our main contributions are as follows. Chapter 1: Observations regarding the quantitative stability of optimal transport plans with respect to Wasserstein distance on the product space. Chapter 2: Extention of strong convexity inequalities for the Kantorovich functional to a larger class of source measures, using glueing arguments recently used for the quantitative stability of optimal transport maps. Chapters 3/4: A qualitative description of the behaviour of the fully discrete transport problem under perturbation of the support positions, as well as quantitative stability under uniqueness assumptions. Chapter 5: Extention of known uniqueness criteria for the dual transport problem. We show that when one marginal measure has Lipschitz-path connected support and the other has bounded support, the values of dual optimisers are unique up to a constant for a large family of costs, including $p$-costs for all $p&gt;1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17407v1</guid>
      <category>math.FA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Ford</dc:creator>
    </item>
    <item>
      <title>Assignment-Routing Optimization with Cutting-Plane Subtour Elimination: Solver and Benchmark Dataset</title>
      <link>https://arxiv.org/abs/2510.17888</link>
      <description>arXiv:2510.17888v1 Announce Type: cross 
Abstract: We study a joint routing-assignment optimization problem in which a set of items must be paired one-to-one with a set of placeholders while simultaneously determining a Hamiltonian cycle that visits every node exactly once. Both the assignment and routing decisions are optimized jointly to minimize the total travel cost. In this work, we propose a method to solve this problem using an exact MIP formulation with Gurobi, including cutting-plane subtour elimination. With analysis of the computational complexity and through extensive experiments, we analyze the computational limitations of this approach as the problem size grows and reveal the challenges associated with the need for more efficient algorithms for larger instances. The dataset, formulations, and experimental results provided here can serve as benchmarks for future studies in this research area. GitHub repository: https://github.com/QL-YUAN/Joint-Assignment-Routing-Optimization</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17888v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qilong Yuan</dc:creator>
    </item>
    <item>
      <title>An Exact Quantile-Energy Equality for Terminal Halfspaces in Linear-Gaussian Control with a Discrete-Time Companion, KL/Schrodinger Links, and High-Precision Validation</title>
      <link>https://arxiv.org/abs/2510.17945</link>
      <description>arXiv:2510.17945v1 Announce Type: cross 
Abstract: We prove an exact equality between the minimal quadratic control energy and the squared normal-quantile gap for terminal halfspaces in linear-Gaussian systems with additive control and quadratic effort $E(u)=\tfrac12\!\int u^\top M u\,dt$ where $M=B^\top\Sigma^{-1}B$. For terminal halfspace events, the minimal energy equals the squared normal-quantile gap divided by twice a controllability-to-noise ratio $R_T^2(w)=(w^\topW_c^M w)/(w^\top V_T w)$ and is attained by a matched-filter control. We provide an exact zero-order-hold discrete-time companion via block exponentials, relate the result to minimum-energy control, Gaussian isoperimetry, risk-sensitive/KL control, and Schrodinger bridges, and validate to high precision with Monte Carlo. We state assumptions, singular-$M$ handling, and edge cases. The statement is a compact synthesis and design-ready translator, not a universal principle. Novelty: while the ingredients (Gramians, Cauchy-Schwarz, Gaussian isoperimetry) are classical, to our knowledge the explicit quantile-energy equality with a constructive matched-filter achiever for terminal halfspaces, and its discrete-time companion, are not recorded together in the cited literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17945v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sandro Andric</dc:creator>
    </item>
    <item>
      <title>R2L: Reliable Reinforcement Learning: Guaranteed Return &amp; Reliable Policies in Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2510.18074</link>
      <description>arXiv:2510.18074v1 Announce Type: cross 
Abstract: In this work, we address the problem of determining reliable policies in reinforcement learning (RL), with a focus on optimization under uncertainty and the need for performance guarantees. While classical RL algorithms aim at maximizing the expected return, many real-world applications - such as routing, resource allocation, or sequential decision-making under risk - require strategies that ensure not only high average performance but also a guaranteed probability of success. To this end, we propose a novel formulation in which the objective is to maximize the probability that the cumulative return exceeds a prescribed threshold. We demonstrate that this reliable RL problem can be reformulated, via a state-augmented representation, into a standard RL problem, thereby allowing the use of existing RL and deep RL algorithms without the need for entirely new algorithmic frameworks. Theoretical results establish the equivalence of the two formulations and show that reliable strategies can be derived by appropriately adapting well-known methods such as Q-learning or Dueling Double DQN. To illustrate the practical relevance of the approach, we consider the problem of reliable routing, where the goal is not to minimize the expected travel time but rather to maximize the probability of reaching the destination within a given time budget. Numerical experiments confirm that the proposed formulation leads to policies that effectively balance efficiency and reliability, highlighting the potential of reliable RL for applications in stochastic and safety-critical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18074v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadir Farhi</dc:creator>
    </item>
    <item>
      <title>Rethinking PCA Through Duality</title>
      <link>https://arxiv.org/abs/2510.18130</link>
      <description>arXiv:2510.18130v1 Announce Type: cross 
Abstract: Motivated by the recently shown connection between self-attention and (kernel) principal component analysis (PCA), we revisit the fundamentals of PCA. Using the difference-of-convex (DC) framework, we present several novel formulations and provide new theoretical insights. In particular, we show the kernelizability and out-of-sample applicability for a PCA-like family of problems. Moreover, we uncover that simultaneous iteration, which is connected to the classical QR algorithm, is an instance of the difference-of-convex algorithm (DCA), offering an optimization perspective on this longstanding method. Further, we describe new algorithms for PCA and empirically compare them with state-of-the-art methods. Lastly, we introduce a kernelizable dual formulation for a robust variant of PCA that minimizes the $l_1$ deviation of the reconstruction errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18130v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jan Quan, Johan Suykens, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI</title>
      <link>https://arxiv.org/abs/2510.18170</link>
      <description>arXiv:2510.18170v1 Announce Type: cross 
Abstract: Goal changes are a defining feature of real world multi-turn interactions, yet current agent benchmarks primarily evaluate static objectives or one-shot tool use. We introduce AgentChangeBench, a benchmark explicitly designed to measure how tool augmented language model agents adapt to mid dialogue goal shifts across three enterprise domains. Our framework formalizes evaluation through four complementary metrics: Task Success Rate (TSR) for effectiveness, Tool Use Efficiency (TUE) for reliability, Tool Call Redundancy Rate (TCRR) for wasted effort, and Goal-Shift Recovery Time (GSRT) for adaptation latency. AgentChangeBench comprises 2,835 task sequences and five user personas, each designed to trigger realistic shift points in ongoing workflows. Using this setup, we evaluate several frontier models and uncover sharp contrasts obscured by traditional $\text{pass}@k$ scores: for example, GPT-4o reaches $92.2\%$ recovery on airline booking shifts while Gemini collapses to $48.6\%$, and retail tasks show near perfect parameter validity yet redundancy rates above $80\%$, revealing major inefficiencies. These findings demonstrate that high raw accuracy does not imply robustness under dynamic goals, and that explicit measurement of recovery time and redundancy is essential. AgentChangeBench establishes a reproducible testbed for diagnosing and improving agent resilience in realistic enterprise settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18170v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Neural Information Processing Systems (NeurIPS 2025)</arxiv:journal_reference>
      <dc:creator>Manik Rana, Calissa Man, Anotida Expected Msiiwa, Jeffrey Paine, Kevin Zhu, Sunishchal Dev, Vasu Sharma, Ahan M R</dc:creator>
    </item>
    <item>
      <title>Ensemble based Closed-Loop Optimal Control using Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2510.18195</link>
      <description>arXiv:2510.18195v1 Announce Type: cross 
Abstract: The objective of designing a control system is to steer a dynamical system with a control signal, guiding it to exhibit the desired behavior. The Hamilton-Jacobi-Bellman (HJB) partial differential equation offers a framework for optimal control system design. However, numerical solutions to this equation are computationally intensive, and analytical solutions are frequently unavailable. Knowledge-guided machine learning methodologies, such as physics-informed neural networks (PINNs), offer new alternative approaches that can alleviate the difficulties of solving the HJB equation numerically. This work presents a multistage ensemble framework to learn the optimal cost-to-go, and subsequently the corresponding optimal control signal, through the HJB equation. Prior PINN-based approaches rely on a stabilizing the HJB enforcement during training. Our framework does not use stabilizer terms and offers a means of controlling the nonlinear system, via either a singular learned control signal or an ensemble control signal policy. Success is demonstrated in closed-loop control, using both ensemble- and singular-control, of a steady-state time-invariant two-state continuous nonlinear system with an infinite time horizon, accounting of noisy, perturbed system states and varying initial conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18195v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jostein Barry-Straume, Adwait D. Verulkar, Arash Sarshar, Andrey A. Popov, Adrian Sandu</dc:creator>
    </item>
    <item>
      <title>Distributed Allocation and Resource Scheduling Algorithms Resilient to Link Failure</title>
      <link>https://arxiv.org/abs/2510.18273</link>
      <description>arXiv:2510.18273v1 Announce Type: cross 
Abstract: Distributed resource allocation (DRA) is fundamental to modern networked systems, spanning applications from economic dispatch in smart grids to CPU scheduling in data centers. Conventional DRA approaches require reliable communication, yet real-world networks frequently suffer from link failures, packet drops, and communication delays due to environmental conditions, network congestion, and security threats.
  We introduce a novel resilient DRA algorithm that addresses these critical challenges, and our main contributions are as follows: (1) guaranteed constraint feasibility at all times, ensuring resource-demand balance even during algorithm termination or network disruption; (2) robust convergence despite sector-bound nonlinearities at nodes/links, accommodating practical constraints like quantization and saturation; and (3) optimal performance under merely uniformly-connected networks, eliminating the need for continuous connectivity.
  Unlike existing approaches that require persistent network connectivity and provide only asymptotic feasibility, our graph-theoretic solution leverages network percolation theory to maintain performance during intermittent disconnections. This makes it particularly valuable for mobile multi-agent systems where nodes frequently move out of communication range. Theoretical analysis and simulations demonstrate that our algorithm converges to optimal solutions despite heterogeneous time delays and substantial link failures, significantly advancing the reliability of distributed resource allocation in practical network environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18273v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Sergio Pequito</dc:creator>
    </item>
    <item>
      <title>Coverage-Recon: Coordinated Multi-Drone Image Sampling with Online Map Feedback</title>
      <link>https://arxiv.org/abs/2510.18347</link>
      <description>arXiv:2510.18347v1 Announce Type: cross 
Abstract: This article addresses collaborative 3D map reconstruction using multiple drones. Achieving high-quality reconstruction requires capturing images of keypoints within the target scene from diverse viewing angles, and coverage control offers an effective framework to meet this requirement. Meanwhile, recent advances in real-time 3D reconstruction algorithms make it possible to render an evolving map during flight, enabling immediate feedback to guide drone motion. Building on this, we present Coverage-Recon, a novel coordinated image sampling algorithm that integrates online map feedback to improve reconstruction quality on-the-fly. In Coverage-Recon, the coordinated motion of drones is governed by a Quadratic Programming (QP)-based angle-aware coverage controller, which ensures multi-viewpoint image capture while enforcing safety constraints. The captured images are processed in real time by the NeuralRecon algorithm to generate an evolving 3D mesh. Mesh changes across the scene are interpreted as indicators of reconstruction uncertainty and serve as feedback to update the importance index of the coverage control as the map evolves. The effectiveness of Coverage-Recon is validated through simulation and experiments, demonstrating both qualitatively and quantitatively that incorporating online map feedback yields more complete and accurate 3D reconstructions than conventional methods. Project page: https://htnk-lab.github.io/coverage-recon/</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18347v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Hanif, Reiji Terunuma, Takumi Sumino, Kelvin Cheng, Takeshi Hatanaka</dc:creator>
    </item>
    <item>
      <title>Enhancing Fractional Gradient Descent with Learned Optimizers</title>
      <link>https://arxiv.org/abs/2510.18783</link>
      <description>arXiv:2510.18783v1 Announce Type: cross 
Abstract: Fractional Gradient Descent (FGD) offers a novel and promising way to accelerate optimization by incorporating fractional calculus into machine learning. Although FGD has shown encouraging initial results across various optimization tasks, it faces significant challenges with convergence behavior and hyperparameter selection. Moreover, the impact of its hyperparameters is not fully understood, and scheduling them is particularly difficult in non-convex settings such as neural network training. To address these issues, we propose a novel approach called Learning to Optimize Caputo Fractional Gradient Descent (L2O-CFGD), which meta-learns how to dynamically tune the hyperparameters of Caputo FGD (CFGD). Our method's meta-learned schedule outperforms CFGD with static hyperparameters found through an extensive search and, in some tasks, achieves performance comparable to a fully black-box meta-learned optimizer. L2O-CFGD can thus serve as a powerful tool for researchers to identify high-performing hyperparameters and gain insights on how to leverage the history-dependence of the fractional differential in optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18783v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Sobotka, Petr \v{S}im\'anek, Pavel Kord\'ik</dc:creator>
    </item>
    <item>
      <title>A Parallel Linear-Constraint Active Set Method</title>
      <link>https://arxiv.org/abs/2109.07565</link>
      <description>arXiv:2109.07565v5 Announce Type: replace 
Abstract: We present two parallel optimization algorithms for a convex function $f$. The first algorithm optimizes over linear inequality constraints in a Hilbert space, $\mathbb H$, and the second over a non convex polyhedron in $\mathbb R^n$. The algorithms reduce the inequality constraints to equality constraints, and garner information from subsets of constraints to speed up the process. Let $r \in \mathbb N$ be the number of constraints and $\nu (\cdot)$ be the time complexity of some process, then given enough threads, and information gathered earlier from subsets of the given constraints, we compute an optimal point of a polyhedral cone in $O(\nu (\langle \cdot,\cdot \rangle) + \nu (\min_A f)))$ for affine space $A$, the intersection of the faces of the cone. We then apply the method to all the faces of the polyhedron to find the linear inequality constrained optimum. The methods works on constrained spaces with empty interiors, furthermore no feasible point is required, and the algorithms recognize when the feasible space is empty. The methods iterate over surfaces of the polyhedron and the corresponding affine hulls using information garnered from previous iterations of superspaces to speed up the process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.07565v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Dov Neimand, Serban Sabau</dc:creator>
    </item>
    <item>
      <title>Dynamically Augmented CVaR for MDPs</title>
      <link>https://arxiv.org/abs/2211.07288</link>
      <description>arXiv:2211.07288v3 Announce Type: replace 
Abstract: This paper studies optimization of Conditional Value-at-Risk (CVaR) for Markov Decision Processes (MDPs) with finite state and action sets. It introduces the Dynamically augmented CVaR (DCVaR) risk measure and provides an algorithm for its optimization. This paper investigates a specially defined Robust MDP (RMDP), in which the state space is augmented with the tail risk level. This RMDP, which we call the Dynamically augmented RMDP (DRMDP), was introduced to the literature for calculations of optimal CVaR values by value iteration more than ten years ago, but, as was understood later, these value iterations compute lower bounds of minimal static CVaRs. DCVaR is defined as a time consistent version of the static CVaR, and it is a lower bound of the static CVaR. It also can be considered as a dynamic version of the nested CVaR. This paper provides an algorithm constructing a policy optimizing DCVaR of total discounted costs. The correctness of this algorithm is proved by studying a special mass transfer problem. The results on RMDPs needed for this paper are provided in the appendix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07288v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene A. Feinberg, Rui Ding</dc:creator>
    </item>
    <item>
      <title>Path Planning for Aerial Relays via Probabilistic Roadmaps</title>
      <link>https://arxiv.org/abs/2310.11752</link>
      <description>arXiv:2310.11752v3 Announce Type: replace 
Abstract: Autonomous unmanned aerial vehicles (UAVs) can be utilized as aerial relays to serve users far from terrestrial infrastructure. Unfortunately, existing algorithms for aerial relay path planning cannot accommodate general flight constraints or channel models. This is required in practice due to connectivity constraints, the presence of obstacles (e.g., buildings), and regulations. This paper proposes a framework that overcomes these limitations by spatially discretizing the flight region. To cope with the resulting exponential growth in complexity, the framework adopts a probabilistic roadmap approach, where a shortest path is found through a graph of randomly generated states. To attain high optimality with affordable complexity, the probability distribution used to generate these states is designed based on heuristic path planners with theoretical guarantees. The algorithms derived in this framework not only overcome the main limitations of existing schemes but also entail smaller computational complexity. Extensive theoretical and numerical results corroborate the merits of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11752v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Q. Viet, Daniel Romero</dc:creator>
    </item>
    <item>
      <title>Optimal state estimation: Turnpike analysis and performance results</title>
      <link>https://arxiv.org/abs/2409.14873</link>
      <description>arXiv:2409.14873v2 Announce Type: replace 
Abstract: In this paper, we introduce turnpike arguments in the context of optimal state estimation. In particular, we show that the optimal solution of the state estimation problem involving all available past data serves as turnpike for the solutions of truncated problems involving only a subset of the data. We mathematically formalize this phenomenon and derive a sufficient condition that relies on a decaying sensitivity property of the underlying nonlinear program. As second contribution, we show how a specific turnpike property can be used to establish performance guarantees when approximating the optimal solution of the full problem by a sequence of truncated problems, and we show that the resulting performance (both averaged and non-averaged) is approximately optimal with error terms that can be made arbitrarily small by an appropriate choice of the horizon length. In addition, we discuss interesting implications of these results for the practically relevant case of moving horizon estimation and illustrate our results with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14873v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/ECC65951.2025.11186977</arxiv:DOI>
      <arxiv:journal_reference>Proc. Eur. Control. Conf. (ECC), 2025, pp. 351-357</arxiv:journal_reference>
      <dc:creator>Julian D. Schiller, Lars Gr\"une, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Swarm-based optimization with jumps: a kinetic BGK framework and convergence analysis</title>
      <link>https://arxiv.org/abs/2507.00871</link>
      <description>arXiv:2507.00871v2 Announce Type: replace 
Abstract: Metaheuristic algorithms are powerful tools for global optimization, particularly for non-convex and non-differentiable problems where exact methods are often impractical. Particle-based optimization methods, inspired by swarm intelligence principles, have shown effectiveness due to their ability to balance exploration and exploitation within the search space. In this work, we introduce a novel particle-based optimization algorithm where velocities are updated via random jumps, a strategy commonly used to enhance stochastic exploration. We formalize this approach by describing the dynamics through a kinetic modelling of BGK type, offering a unified framework that accommodates general noise distributions, including heavy-tailed ones like Cauchy. Under suitable parameter scaling, the model reduces to the Consensus-Based Optimization (CBO) dynamics. For non-degenerate Gaussian noise in bounded domains, we prove propagation of chaos and convergence towards minimizers. Numerical results on benchmark problems validate the approach and highlight its connection to CBO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00871v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Borghi, Hyesung Im, Lorenzo Pareschi</dc:creator>
    </item>
    <item>
      <title>Combinatorial Algorithm for Tropical Linearly Factorized Programming</title>
      <link>https://arxiv.org/abs/2507.07596</link>
      <description>arXiv:2507.07596v2 Announce Type: replace 
Abstract: The tropical semiring is a set of numbers with addition "max" and multiplication "+". As well as in conventional algebra, linear programming problem in the tropical semiring has been developed. In this study, we introduce a new type of tropical optimization problem, namely, tropical linearly factorized programming problem. This problem involves minimizing the objective function given by the product of tropical linear forms divided by a tropical monomial, subject to tropical linear inequality constraints. The objective function is convex in the conventional sense but not in the tropical sense, while the feasible set is convex in the tropical sense but not in the conventional sense.
  Our algorithm for tropical linearly factorized programming is based on the descent method and exploits tangent digraphs. First, we demonstrate that the feasible descent direction at the current solution can be obtained by solving the minimum $s$-$t$ cut problem on a specific subgraph of the tangent digraph. Although exponentially many such digraphs may exist in general, a more efficient algorithm is devised in cases where the problem is non-degenerate. Focusing on the fact that tangent digraphs become spanning trees in non-degenerate cases, we present a simplex-like algorithm that updates the tree structure iteratively. We show that each iteration can be executed in $O(r_A+r_C)$ time, where $r_A$ and $r_C$ are the numbers of ``non-zero'' coefficients in the linear constraints and objective function, respectively. For integer instances, our algorithm finds a local optimum in $O((m+n)(r_A+r_C)MD)$ time, where $n$ and $m$ are the number of decision variables and constraints, respectively, $M$ is the maximum absolute value of coefficients and $D$ is the degree of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07596v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Nishida</dc:creator>
    </item>
    <item>
      <title>Shuffling Heuristic in Variational Inequalities: Establishing New Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2509.04133</link>
      <description>arXiv:2509.04133v3 Announce Type: replace 
Abstract: Variational inequalities have gained significant attention in machine learning and optimization research. While stochastic methods for solving these problems typically assume independent data sampling, we investigate an alternative approach -- the shuffling heuristic. This strategy involves permuting the dataset before sequential processing, ensuring equal consideration of all data points. Despite its practical utility, theoretical guarantees for shuffling in variational inequalities remain unexplored. We address this gap by providing the first theoretical convergence estimates for shuffling methods in this context. Our analysis establishes rigorous bounds and convergence rates, extending the theoretical framework for this important class of algorithms. We validate our findings through extensive experiments on diverse benchmark variational inequality problems, demonstrating faster convergence of shuffling methods compared to independent sampling approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04133v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Gleb Molodtsov, Grigoriy Evseev, Egor Petrov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Bilinear optimal control for the Stokes-Brinkman equations: a priori and a posteriori error analyses</title>
      <link>https://arxiv.org/abs/2404.18348</link>
      <description>arXiv:2404.18348v4 Announce Type: replace-cross 
Abstract: We analyze a bilinear optimal control problem for the Stokes--Brinkman equations: the control variable enters the state equations as a coefficient. In two- and three-dimensional Lipschitz domains, we perform a complete continuous analysis that includes the existence of solutions and first- and second-order optimality conditions. We also develop two finite element methods that differ fundamentally in whether the admissible control set is discretized or not. For each of the proposed methods, we perform a convergence analysis and derive a priori error estimates; the latter under the assumption that the domain is convex. Finally, assuming that the domain is Lipschitz, we develop an a posteriori error estimator for each discretization scheme, obtain a global reliability bound, and investigate local efficiency estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18348v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro Allendes, Gilberto Campa\~na, Enrique Otarola</dc:creator>
    </item>
    <item>
      <title>Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy</title>
      <link>https://arxiv.org/abs/2505.07614</link>
      <description>arXiv:2505.07614v4 Announce Type: replace-cross 
Abstract: Recent advancements in machine learning have improved performance while also increasing computational demands. While federated and distributed setups address these issues, their structure is vulnerable to malicious influences. In this paper, we address a specific threat, Byzantine attacks, where compromised clients inject adversarial updates to derail global convergence. We combine the trust scores concept with trial function methodology to dynamically filter outliers. Our methods address the critical limitations of previous approaches, allowing functionality even when Byzantine nodes are in the majority. Moreover, our algorithms adapt to widely used scaled methods like Adam and RMSProp, as well as practical scenarios, including local training and partial participation. We validate the robustness of our methods by conducting extensive experiments on both synthetic and real ECG data collected from medical institutions. Furthermore, we provide a broad theoretical analysis of our algorithms and their extensions to aforementioned practical setups. The convergence guarantees of our methods are comparable to those of classical algorithms developed without Byzantine interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07614v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gleb Molodtsov, Daniil Medyakov, Sergey Skorik, Nikolas Khachaturov, Shahane Tigranyan, Vladimir Aletov, Aram Avetisyan, Martin Tak\'a\v{c}, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Fair Supervised Learning Through Constraints on Smooth Nonconvex Unfairness-Measure Surrogates</title>
      <link>https://arxiv.org/abs/2505.15788</link>
      <description>arXiv:2505.15788v2 Announce Type: replace-cross 
Abstract: A new strategy for fair supervised machine learning is proposed. The main advantages of the proposed strategy as compared to others in the literature are as follows. (a) We introduce a new smooth nonconvex surrogate to approximate the Heaviside functions involved in discontinuous unfairness measures. The surrogate is based on smoothing methods from the optimization literature, and is new for the fair supervised learning literature. The surrogate is a tight approximation which ensures the trained prediction models are fair, as opposed to other (e.g., convex) surrogates that can fail to lead to a fair prediction model in practice. (b) Rather than rely on regularizers (that lead to optimization problems that are difficult to solve) and corresponding regularization parameters (that can be expensive to tune), we propose a strategy that employs hard constraints so that specific tolerances for unfairness can be enforced without the complications associated with the use of regularization. (c) Our proposed strategy readily allows for constraints on multiple (potentially conflicting) unfairness measures at the same time. Multiple measures can be considered with a regularization approach, but at the cost of having even more difficult optimization problems to solve and further expense for tuning. By contrast, through hard constraints, our strategy leads to optimization models that can be solved tractably with minimal tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15788v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zahra Khatti, Daniel P. Robinson, Frank E. Curtis</dc:creator>
    </item>
    <item>
      <title>Nearly Dimension-Independent Convergence of Mean-Field Black-Box Variational Inference</title>
      <link>https://arxiv.org/abs/2505.21721</link>
      <description>arXiv:2505.21721v2 Announce Type: replace-cross 
Abstract: We prove that, given a mean-field location-scale variational family, black-box variational inference (BBVI) with the reparametrization gradient converges at a rate that is nearly independent of explicit dimension dependence. Specifically, for a $d$-dimensional strongly log-concave and log-smooth target, the number of iterations for BBVI with a sub-Gaussian family to obtain a solution $\epsilon$-close to the global optimum has a dimension dependence of $\mathrm{O}(\log d)$. This is a significant improvement over the $\mathrm{O}(d)$ dependence of full-rank location-scale families. For heavy-tailed families, we prove a weaker $\mathrm{O}(d^{2/k})$ dependence, where $k$ is the number of finite moments of the family. Additionally, if the Hessian of the target log-density is constant, the complexity is free of any explicit dimension dependence. We also prove that our bound on the gradient variance, which is key to our result, cannot be improved using only spectral bounds on the Hessian of the target log-density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21721v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyurae Kim, Yi-An Ma, Trevor Campbell, Jacob R. Gardner</dc:creator>
    </item>
    <item>
      <title>Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization</title>
      <link>https://arxiv.org/abs/2506.03725</link>
      <description>arXiv:2506.03725v3 Announce Type: replace-cross 
Abstract: Quite recently, large language models have made a significant breakthrough across various disciplines. However, training them is an extremely resource-intensive task, even for major players with vast computing resources. One of the methods gaining popularity in light of these challenges is Sign-SGD. This method can be applied both as a memory-efficient approach in single-node training and as a gradient compression technique in the distributed learning. Nevertheless, it is impossible to automatically determine the effective stepsize from the theoretical standpoint. Indeed, it depends on the parameters of the dataset to which we do not have access in the real-world learning paradigm. To address this issue, we design several variants of single-node deterministic Sign-SGD. We extend our approaches to practical scenarios: stochastic single-node and multi-node learning, methods with incorporated momentum. We conduct extensive experiments on real machine learning problems that emphasize the practical applicability of our ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03725v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Sergey Stanko, Gleb Molodtsov, Philip Zmushko, Grigoriy Evseev, Egor Petrov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>A unified framework for establishing the universal approximation of transformer-type architectures</title>
      <link>https://arxiv.org/abs/2506.23551</link>
      <description>arXiv:2506.23551v2 Announce Type: replace-cross 
Abstract: We investigate the universal approximation property (UAP) of transformer-type architectures, providing a unified theoretical framework that extends prior results on residual networks to models incorporating attention mechanisms. Our work identifies token distinguishability as a fundamental requirement for UAP and introduces a general sufficient condition that applies to a broad class of architectures. Leveraging an analyticity assumption on the attention layer, we can significantly simplify the verification of this condition, providing a non-constructive approach in establishing UAP for such architectures. We demonstrate the applicability of our framework by proving UAP for transformers with various attention mechanisms, including kernel-based and sparse attention mechanisms. The corollaries of our results either generalize prior works or establish UAP for architectures not previously covered. Furthermore, our framework offers a principled foundation for designing novel transformer architectures with inherent UAP guarantees, including those with specific functional symmetries. We propose examples to illustrate these insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23551v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingpu Cheng, Ting Lin, Zuowei Shen, Qianxiao Li</dc:creator>
    </item>
    <item>
      <title>RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models</title>
      <link>https://arxiv.org/abs/2507.12201</link>
      <description>arXiv:2507.12201v2 Announce Type: replace-cross 
Abstract: Diffusion models have achieved state-of-the-art performance in generative modeling, yet their sampling procedures remain vulnerable to hallucinations-often stemming from inaccuracies in score approximation. In this work, we reinterpret diffusion sampling through the lens of optimization and introduce RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that detects and corrects high-risk sampling steps using geometric cues from the loss landscape. RODS enforces smoother sampling trajectories and adaptively adjusts perturbations, reducing hallucinations without retraining and at minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands demonstrate that RODS maintains comparable image quality and preserves generation diversity. More importantly, it improves both sampling fidelity and robustness, detecting over 70% of hallucinated samples and correcting more than 25%, all while avoiding the introduction of new artifacts. We release our code at https://github.com/Yiqi-Verna-Tian/RODS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12201v2</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiqi Tian, Pengfei Jin, Mingze Yuan, Na Li, Bo Zeng, Quanzheng Li</dc:creator>
    </item>
    <item>
      <title>A surrogate model for topology optimisation of elastic structures via parametric autoencoders</title>
      <link>https://arxiv.org/abs/2507.22539</link>
      <description>arXiv:2507.22539v2 Announce Type: replace-cross 
Abstract: A surrogate-based topology optimisation algorithm for linear elastic structures under parametric loads and boundary conditions is proposed. Instead of learning the parametric solution of the state (and adjoint) problems or the optimisation trajectory as a function of the iterations, the proposed approach devises a surrogate version of the entire optimisation pipeline. First, the method predicts a quasi-optimal topology for a given problem configuration as a surrogate model of high-fidelity topologies optimised with the homogenisation method. This is achieved by means of a feed-forward net learning the mapping between the input parameters characterising the system setup and a latent space determined by encoder/decoder blocks reducing the dimensionality of the parametric topology optimisation problem and reconstructing a high-dimensional representation of the topology. Then, the predicted topology is used as an educated initial guess for a computationally efficient algorithm penalising the intermediate values of the design variable, while enforcing the governing equations of the system. This step allows the method to correct potential errors introduced by the surrogate model, eliminate artifacts, and refine the design in order to produce topologies consistent with the underlying physics. Different architectures are proposed and the approximation and generalisation capabilities of the resulting models are numerically evaluated. The quasi-optimal topologies allow to outperform the high-fidelity optimiser by reducing the average number of optimisation iterations by $53\%$ while achieving discrepancies below $4\%$ in the optimal value of the objective functional, even in the challenging scenario of testing the model to extrapolate beyond the training and validation domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22539v2</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
  </channel>
</rss>
