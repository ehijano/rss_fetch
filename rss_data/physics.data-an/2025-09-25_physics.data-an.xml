<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Sep 2025 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Particle Filtering for Non-Deterministic Electrocardiographic Imaging</title>
      <link>https://arxiv.org/abs/2509.19404</link>
      <description>arXiv:2509.19404v1 Announce Type: cross 
Abstract: Electrocardiographic imaging (ECGI) aims to non-invasively reconstruct activation maps of the heart from temporal body surface potentials. While most existing approaches rely on inverse and optimization techniques that may yield satisfactory reconstructions, they typically provide a single deterministic solution, overlooking the inherent uncertainty of the problem stemming from its very ill-posed nature, the poor knowledge of biophysical features and the unavoidable presence of noise in the measurements. The Bayesian framework, which naturally incorporates uncertainty while also accounting for temporal correlations across time steps, can be used to address this limitation. In this work, we propose a low-dimensional representation of the activation sequence that enables the use of particle filtering, a Bayesian filtering method that does not rely on predefined assumptions regarding the shape of the posterior distribution, in contrast to approaches like the Kalman filter. This allows to produce not only activation maps but also probabilistic maps indicating the likelihood of activation at each point on the heart over time, as well as pseudo-probability maps reflecting the likelihood of a point being part of an earliest activation site. Additionally, we introduce a method to estimate the probability of the presence of a conduction lines of block on the heart surface. Combined with classical reconstruction techniques, this could help discriminate artificial from true lines of block in activation maps. We support our approach with a numerical study based on simulated data, demonstrating the potential of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19404v1</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emma Lagracie (UB), Luc de Montella</dc:creator>
    </item>
    <item>
      <title>Testing the Constancy of Type Ia Supernova Luminosities with Gaussian Process</title>
      <link>https://arxiv.org/abs/2509.19494</link>
      <description>arXiv:2509.19494v1 Announce Type: cross 
Abstract: Type Ia supernovae (SNe~Ia) are central to studies of cosmic expansion, under the assumption that their absolute magnitude $M_B$ does not evolve with redshift. Even small drifts in brightness can bias cosmological parameters such as $H_0$ and $w$. Here we test this assumption using a non-parametric Gaussian Process (GP) reconstruction of the expansion history from cosmic chronometer $H(z)$ data, which provides a model-independent baseline distance modulus, $\mu_{\rm GP}(z)$. To propagate uncertainties, we draw Monte Carlo realizations of $H(z)$ from the GP posterior and evaluate them on a Chebyshev grid, which improves numerical stability and quadrature accuracy. Supernova observations are then compared to this baseline through residuals, $\Delta M_B(z)$, and their derivatives. Applying this method to Pantheon+ (1701 SNe~Ia) and DES 5YR (435 SNe~Ia), we find that SNe~Ia are consistent with being standard candles within $1\sigma$, though both datasets exhibit localized departures: near $z \sim 1$ in Pantheon+ and at $z \sim 0.3$--$0.5$ in DES. The presence of similar features in two independent surveys suggests they are not purely statistical. Our results point toward a possible non-monotonic luminosity evolution, likely reflecting different physical drivers at different epochs, and highlight the need for a deeper astrophysical understanding of SN~Ia populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19494v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Akshay Rana</dc:creator>
    </item>
    <item>
      <title>Geometric Autoencoder Priors for Bayesian Inversion: Learn First Observe Later</title>
      <link>https://arxiv.org/abs/2509.19929</link>
      <description>arXiv:2509.19929v1 Announce Type: cross 
Abstract: Uncertainty Quantification (UQ) is paramount for inference in engineering applications. A common inference task is to recover full-field information of physical systems from a small number of noisy observations, a usually highly ill-posed problem. Critically, engineering systems often have complicated and variable geometries prohibiting the use of standard Bayesian UQ. In this work, we introduce Geometric Autoencoders for Bayesian Inversion (GABI), a framework for learning geometry-aware generative models of physical responses that serve as highly informative geometry-conditioned priors for Bayesian inversion. Following a ''learn first, observe later'' paradigm, GABI distills information from large datasets of systems with varying geometries, without requiring knowledge of governing PDEs, boundary conditions, or observation processes, into a rich latent prior. At inference time, this prior is seamlessly combined with the likelihood of the specific observation process, yielding a geometry-adapted posterior distribution. Our proposed framework is architecture agnostic. A creative use of Approximate Bayesian Computation (ABC) sampling yields an efficient implementation that utilizes modern GPU hardware. We test our method on: steady-state heat over rectangular domains; Reynold-Averaged Navier-Stokes (RANS) flow around airfoils; Helmholtz resonance and source localization on 3D car bodies; RANS airflow over terrain. We find: the predictive accuracy to be comparable to deterministic supervised learning approaches in the restricted setting where supervised learning is applicable; UQ to be well calibrated and robust on challenging problems with complex geometries. The method provides a flexible geometry-aware train-once-use-anywhere foundation model which is independent of any particular observation process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19929v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnaud Vadeboncoeur, Gregory Duth\'e, Mark Girolami, Eleni Chatzi</dc:creator>
    </item>
    <item>
      <title>First-Extinction Law for Resampling Processes</title>
      <link>https://arxiv.org/abs/2509.20101</link>
      <description>arXiv:2509.20101v1 Announce Type: cross 
Abstract: Extinction times in resampling processes are fundamental yet often intractable, as previous formulas scale as $2^M$ with the number of states $M$ present in the initial probability distribution. We solve this by treating multinomial updates as independent square-root diffusions of zero drift, yielding a closed-form law for the first-extinction time. We prove that the mean coincides exactly with the Wright-Fisher result of Baxter et al., thereby replacing exponential-cost evaluations with a linear-cost expression, and we validate this result through extensive simulations. Finally, we demonstrate predictive power for model collapse in a simple self-training setup: the onset of collapse coincides with the resampling-driven first-extinction time computed from the model's initial stationary distribution. These results hint to a unified view of resampling extinction dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20101v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>q-bio.PE</category>
      <category>stat.TH</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Benati, Alessandro Londei, Denise Lanzieri, Vittorio Loreto</dc:creator>
    </item>
    <item>
      <title>FAIR Universe HiggsML Uncertainty Dataset and Competition</title>
      <link>https://arxiv.org/abs/2410.02867</link>
      <description>arXiv:2410.02867v5 Announce Type: replace-cross 
Abstract: The FAIR Universe HiggsML Uncertainty Challenge focused on measuring the physical properties of elementary particles with imperfect simulators. Participants were required to compute and report confidence intervals for a parameter of interest regarding the Higgs boson while accounting for various systematic (epistemic) uncertainties. The dataset is a tabular dataset of 28 features and 280 million instances. Each instance represents a simulated proton-proton collision as observed at CERN's Large Hadron Collider in Geneva, Switzerland. The features of these simulations were chosen to capture key characteristics of different types of particles. These include primary attributes, such as the energy and three-dimensional momentum of the particles, as well as derived attributes, which are calculated from the primary ones using domain-specific knowledge. Additionally, a label feature designates each instance's type of proton-proton collision, distinguishing the Higgs boson events of interest from three background sources. As outlined in this paper, the permanent release of the dataset allows long-term benchmarking of new techniques. The leading submissions, including Contrastive Normalising Flows and Density Ratios estimation through classification, are described. Our challenge has brought together the physics and machine learning communities to advance our understanding and methodologies in handling systematic uncertainties within AI techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02867v5</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lisa Benato, Wahid Bhimji, Paolo Calafiura, Ragansu Chakkappai, Po-Wen Chang, Yuan-Tang Chou, Sascha Diefenbacher, Jordan Dudley, Ibrahim Elsharkawy, Steven Farrell, Aishik Ghosh, Cristina Giordano, Isabelle Guyon, Chris Harris, Yota Hashizume, Shih-Chieh Hsu, Elham E. Khoda, Claudius Krause, Ang Li, Benjamin Nachman, Peter Nugent, David Rousseau, Robert Schoefbeck, Maryam Shooshtari, Dennis Schwarz, Benjamin Thorne, Ihsan Ullah, Daohan Wang, Yulei Zhang</dc:creator>
    </item>
    <item>
      <title>Super-resolved anomalous diffusion: deciphering the joint distribution of anomalous exponent and diffusion coefficient</title>
      <link>https://arxiv.org/abs/2410.18133</link>
      <description>arXiv:2410.18133v2 Announce Type: replace-cross 
Abstract: The molecular motion in heterogeneous media displays anomalous diffusion by the mean-squared displacement $\langle X^2(t) \rangle = 2 D t^\alpha$. Motivated by experiments reporting populations of the anomalous diffusion parameters $\alpha$ and $D$, we aim to disentangle their respective contributions to the observed variability when this last is due to a true population of these parameters and when it arises due to finite-duration recordings. We introduce estimators of the anomalous diffusion parameters on the basis of the time-averaged mean squared displacement and study their statistical properties. By using a copula approach, we derive a formula for the joint density function of their estimations conditioned on their actual values. The methodology introduced is indeed universal, it is valid for any Gaussian process and can be applied to any quadratic time-averaged statistics. We also explain the experimentally reported relation $D\propto\exp(\alpha c_1+c_2)$ for which we provide the exact expression. We finally compare our findings to numerical simulations of the fractional Brownian motion and quantify their accuracy by using the Hellinger distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18133v2</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/y5pn-5ynd</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 135, (2025) 137101</arxiv:journal_reference>
      <dc:creator>Yann Lanoisel\'ee, Gianni Pagnini, Agnieszka Wy{\l}oma\'nska</dc:creator>
    </item>
    <item>
      <title>Frequentist Uncertainties on Neural Density Ratios with wifi Ensembles</title>
      <link>https://arxiv.org/abs/2506.00113</link>
      <description>arXiv:2506.00113v2 Announce Type: replace-cross 
Abstract: We introduce wifi ensembles as a novel framework to obtain asymptotic frequentist uncertainties on density ratios, with a particular focus on neural ratio estimation in the context of high-energy physics. When the density ratio of interest is a likelihood ratio conditioned on parameters, wifi ensembles can be used to perform simulation-based inference on those parameters. After training the basis functions f_i(x), uncertainties on the weights w_i can be straightforwardly propagated to the estimated parameters without requiring extraneous bootstraps. To demonstrate this approach, we present an application in quantum chromodynamics at the Large Hadron Collider, using wifi ensembles to estimate the likelihood ratio between generated quark and gluon jets. We use this learned likelihood ratio to estimate the quark fraction in a synthetic mixed quark/gluon sample, showing that the resultant uncertainties empirically satisfy the desired coverage properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00113v2</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sean Benevedes, Jesse Thaler</dc:creator>
    </item>
    <item>
      <title>Fisher information flow in artificial neural networks</title>
      <link>https://arxiv.org/abs/2509.02407</link>
      <description>arXiv:2509.02407v2 Announce Type: replace-cross 
Abstract: The estimation of continuous parameters from measured data plays a central role in many fields of physics. A key tool in understanding and improving such estimation processes is the concept of Fisher information, which quantifies how information about unknown parameters propagates through a physical system and determines the ultimate limits of precision. With Artificial Neural Networks (ANNs) gradually becoming an integral part of many measurement systems, it is essential to understand how they process and transmit parameter-relevant information internally. Here, we present a method to monitor the flow of Fisher information through an ANN performing a parameter estimation task, tracking it from the input to the output layer. We show that optimal estimation performance corresponds to the maximal transmission of Fisher information, and that training beyond this point results in information loss due to overfitting. This provides a model-free stopping criterion for network training-eliminating the need for a separate validation dataset. To demonstrate the practical relevance of our approach, we apply it to a network trained on data from an imaging experiment, highlighting its effectiveness in a realistic physical setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02407v2</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/kn3z-rmm8</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. X 15, 031072 (2025)</arxiv:journal_reference>
      <dc:creator>Maximilian Weimar, Lukas M. Rachbauer, Ilya Starshynov, Daniele Faccio, Linara Adilova, Dorian Bouchet, Stefan Rotter</dc:creator>
    </item>
    <item>
      <title>Quantum Computing Tools for Fast Detection of Gravitational Waves in the Context of LISA Space Mission</title>
      <link>https://arxiv.org/abs/2509.12929</link>
      <description>arXiv:2509.12929v2 Announce Type: replace-cross 
Abstract: The field of gravitational wave (GW) detection is progressing rapidly, with several next-generation observatories on the horizon, including LISA. GW data is challenging to analyze due to highly variable signals shaped by source properties and the presence of complex noise. These factors emphasize the need for robust, advanced analysis tools. In this context, we have initiated the development of a low-latency GW detection pipeline based on quantum neural networks (QNNs). Previously, we demonstrated that QNNs can recognize GWs simulated using post-Newtonian approximations in the Newtonian limit. We then extended this work using data from the LISA Consortium, training QNNs to distinguish between noisy GW signals and pure noise. Currently, we are evaluating performance on the Sangria LISA Data Challenge dataset and comparing it against classical methods. Our results show that QNNs can reliably distinguish GW signals embedded in noise, achieving classification accuracies above 98\%. Notably, our QNN identified 5 out of 6 mergers in the Sangria blind dataset. The remaining merger, characterized by the lowest amplitude, highlights an area for future improvement in model sensitivity. This can potentially be addressed using additional mock training datasets, which we are preparing, and by testing different QNN architectures and ansatzes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12929v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria-Catalina Isfan, Laurentiu-Ioan Caramete, Ana Caramete, Daniel Tonoiu, Alexandru Nicolin-Zaczek</dc:creator>
    </item>
  </channel>
</rss>
