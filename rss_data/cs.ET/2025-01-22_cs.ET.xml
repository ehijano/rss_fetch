<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Jan 2025 05:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Energy-Constrained Information Storage on Memristive Devices in the Presence of Resistive Drift</title>
      <link>https://arxiv.org/abs/2501.10376</link>
      <description>arXiv:2501.10376v1 Announce Type: new 
Abstract: In this paper, we examine the problem of information storage on memristors affected by resistive drift noise under energy constraints. We introduce a novel, fundamental trade-off between the information lifetime of memristive states and the energy that must be expended to bring the device into a particular state. We then treat the storage problem as one of communication over a noisy, energy-constrained channel, and propose a joint source-channel coding (JSCC) approach to storing images in an analogue fashion. To design an encoding scheme for natural images and to model the memristive channel, we make use of data-driven techniques from the field of deep learning for communications, namely deep joint source-channel coding (DeepJSCC), employing a generative model of resistive drift as a computationally tractable differentiable channel model for end-to-end optimisation. We introduce a modified version of generalised divisive normalisation (GDN), a biologically inspired form of normalisation, that we call conditional GDN (cGDN), allowing for conditioning on continuous channel characteristics, including the initial resistive state and the delay between storage and reading. Our results show that the delay-conditioned network is able to learn an energy-aware coding scheme that achieves a higher and more balanced reconstruction quality across a range of storage delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10376v1</guid>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waleed El-Geresy, Christos Papavassiliou, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Ion Transmitter for Molecular Communication</title>
      <link>https://arxiv.org/abs/2501.10392</link>
      <description>arXiv:2501.10392v1 Announce Type: new 
Abstract: Molecular communication (MC) is an emerging paradigm that takes inspiration from biological processes, enabling communication at the nanoscale and facilitating the development of the Internet of Bio-Nano Things (IoBNT). Traditional models of MC often rely on idealized assumptions that overlook practical challenges related to noise and signal behavior. This paper proposes and evaluates the first physical MC ion transmitter (ITX) using an ion exchange membrane. The circuit network model is used to simulate ion transport and analyze both transient and steady-state behavior. This analysis includes the effects of noise sources such as thermal and shot noise on signal integrity and SNR. The main contributions of this paper are to demonstrate how a practical MC ITX can produce a realistic waveform and to highlight future research challenges associated with a physical membrane-based ITX.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10392v1</guid>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaojie Zhang, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>Quantum Annealing for Robust Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2501.10431</link>
      <description>arXiv:2501.10431v1 Announce Type: new 
Abstract: Principal component analysis is commonly used for dimensionality reduction, feature extraction, denoising, and visualization. The most commonly used principal component analysis method is based upon optimization of the L2-norm, however, the L2-norm is known to exaggerate the contribution of errors and outliers. When optimizing over the L1-norm, the components generated are known to exhibit robustness or resistance to outliers in the data. The L1-norm components can be solved for with a binary optimization problem. Previously, L1-BF has been used to solve the binary optimization for multiple components simultaneously. In this paper we propose QAPCA, a new method for finding principal components using quantum annealing hardware which will optimize over the robust L1-norm. The conditions required for convergence of the annealing problem are discussed. The potential speedup when using quantum annealing is demonstrated through complexity analysis and experimental results. To showcase performance against classical principal component analysis techniques experiments upon synthetic Gaussian data, a fault detection scenario and breast cancer diagnostic data are studied. We find that the reconstruction error when using QAPCA is comparable to that when using L1-BF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10431v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Tomeo (Rochester Institute of Technology), Panos P. Markopoulos (The University of Texas at San Antonio), Andreas Savakis (Rochester Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>High-Throughput, Energy-Efficient RRAM-Based In-Memory Computing LPN Accelerator</title>
      <link>https://arxiv.org/abs/2501.10702</link>
      <description>arXiv:2501.10702v1 Announce Type: new 
Abstract: As a strong candidate for the post-quantum crypto-graphic (PQC) era, Learning Parity with Noise (LPN) has been extensively studied in the field of cryptography. However, the data transfer bottleneck between the computation and memory modules has significantly hindered the development of LPN-based cryptographic techniques due to large matrices. This work introduces an RRAM-based in-memory computing LPN accelerator aimed at overcoming data transfer bottlenecks, thereby executing LPN computation tasks efficiently. To ensure the high accuracy of the LPN AND operation, a folded current amplification circuit is proposed to address the leakage current issue caused by the limited high-resistance state of RRAM. Meanwhile, a Cumulative XOR Fast Computing Method is introduced to efficiently convert accumulated current values into LPN XOR operation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10702v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Yue, Zhelong Jiang, Zhigang Li, Yihao Chen, Gang Chen, Huaxiang Lu</dc:creator>
    </item>
    <item>
      <title>Plastic computing, the cloud continuum journey beyond infinity</title>
      <link>https://arxiv.org/abs/2501.12247</link>
      <description>arXiv:2501.12247v1 Announce Type: new 
Abstract: The ever increasing challenges introduced by the diversity of current and envisioned network technologies and IT infrastructure draw a highly distributed and heterogeneous topology where innovative services must be optimally deployed to guarantee maximum level of quality for users. Indeed, paradigms such as the cloud continuum, bringing together edge and cloud computing, along with the new opportunities coming out by considering non-terrestrial networks connecting future 6G ecosystems, all with no doubt facilitate the development of innovative services in many different areas and verticals. However, considering the intensive data and quality requirements demanded by these services, the distribution of the execution tasks must be optimally designed. On the infrastructure side, several initiatives are already active aimed at providing a Meta-OS that may seamlessly manage the different actors (services, infrastructure and users) playing under this paradigm. However, several aspects remain yet limited, particularly when referring to the mapping of resources into services, where innovative technologies based on bidirectional coordination and modeling may be pivotal for an optimal performance. In addition, the upcoming demands coming from the adoption of network technologies easing users connection with high levels of quality, such as 6G, as well the study of NTN open up the traditional cloud continuum to include also satellites that may extend the cloud paradigm further than ever considered. This paper shows a seed work toward an extendable paradigm so called as plastic computing whose main objective is to optimize service performance and users satisfaction, through considering a bidirectional strategy, easily extendable to adopt novel network and IT technologies and paradigms. Finally, two examples are briefly introduced to highlight the potential benefits of the plastic computing adoption</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12247v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavi Masip-Bruin, Jordi Garcia, Adrian Asensio, Francesco DAndria, Admela Jukan, Shahrok Daijavad, Panos Trakadas</dc:creator>
    </item>
    <item>
      <title>Integrating Artificial Open Generative Artificial Intelligence into Software Supply Chain Security</title>
      <link>https://arxiv.org/abs/2412.19088</link>
      <description>arXiv:2412.19088v1 Announce Type: cross 
Abstract: While new technologies emerge, human errors always looming. Software supply chain is increasingly complex and intertwined, the security of a service has become paramount to ensuring the integrity of products, safeguarding data privacy, and maintaining operational continuity. In this work, we conducted experiments on the promising open Large Language Models (LLMs) into two main software security challenges: source code language errors and deprecated code, with a focus on their potential to replace conventional static and dynamic security scanners that rely on predefined rules and patterns. Our findings suggest that while LLMs present some unexpected results, they also encounter significant limitations, particularly in memory complexity and the management of new and unfamiliar data patterns. Despite these challenges, the proactive application of LLMs, coupled with extensive security databases and continuous updates, holds the potential to fortify Software Supply Chain (SSC) processes against emerging threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19088v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICDABI63787.2024.10800301</arxiv:DOI>
      <arxiv:journal_reference>2024 5th International Conference on Data Analytics for Business and Industry (ICDABI)</arxiv:journal_reference>
      <dc:creator>Vasileios Alevizos, George A Papakostas, Akebu Simasiku, Dimitra Malliarou, Antonis Messinis, Sabrina Edralin, Clark Xu, Zongliang Yue</dc:creator>
    </item>
    <item>
      <title>Quantum-Enhanced Conformal Methods for Multi-Output Uncertainty: A Holistic Exploration and Experimental Analysis</title>
      <link>https://arxiv.org/abs/2501.10414</link>
      <description>arXiv:2501.10414v1 Announce Type: cross 
Abstract: In this paper, we propose a unified approach to harness quantum conformal methods for multi-output distributions, with a particular emphasis on two experimental paradigms: (i) a standard 2-qubit circuit scenario producing a four-dimensional outcome distribution, and (ii) a multi-basis measurement setting that concatenates measurement probabilities in different bases (Z, X, Y) into a twelve-dimensional output space. By combining a multioutput regression model (e.g., random forests) with distributional conformal prediction, we validate coverage and interval-set sizes on both simulated quantum data and multi-basis measurement data. Our results confirm that classical conformal prediction can effectively provide coverage guarantees even when the target probabilities derive from inherently quantum processes. Such synergy opens the door to next-generation quantum-classical hybrid frameworks, providing both improved interpretability and rigorous coverage for quantum machine learning tasks. All codes and full reproducible Colab notebooks are made available at https://github.com/detasar/QECMMOU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10414v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emre Tasar</dc:creator>
    </item>
    <item>
      <title>Q-RESTORE: Quantum-Driven Framework for Resilient and Equitable Transportation Network Restoration</title>
      <link>https://arxiv.org/abs/2501.11197</link>
      <description>arXiv:2501.11197v1 Announce Type: cross 
Abstract: Efficient and socially equitable restoration of transportation networks post disasters is crucial for community resilience and access to essential services. The ability to rapidly recover critical infrastructure can significantly mitigate the impacts of disasters, particularly in underserved communities where prolonged isolation exacerbates vulnerabilities. Traditional restoration methods prioritize functionality over computational efficiency and equity, leaving low-income communities at a disadvantage during recovery. To address this gap, this research introduces a novel framework that combines quantum computing technology with an equity-focused approach to network restoration. Optimization of road link recovery within budget constraints is achieved by leveraging D Wave's hybrid quantum solver, which targets the connectivity needs of low, average, and high income communities. This framework combines computational speed with equity, ensuring priority support for underserved populations. Findings demonstrate that this hybrid quantum solver achieves near instantaneous computation times of approximately 8.7 seconds across various budget scenarios, significantly outperforming the widely used genetic algorithm. It offers targeted restoration by first aiding low-income communities and expanding aid as budgets increase, aligning with equity goals. This work showcases quantum computing's potential in disaster recovery planning, providing a rapid and equitable solution that elevates urban resilience and social sustainability by aiding vulnerable populations in disasters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11197v1</guid>
      <category>cs.MA</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Daniel Udekwe, Ruimin Ke, Jiaqing Lu, Qian-wen Guo</dc:creator>
    </item>
    <item>
      <title>A Deep Reinforcement Learning based Scheduler for IoT Devices in Co-existence with 5G-NR</title>
      <link>https://arxiv.org/abs/2501.11574</link>
      <description>arXiv:2501.11574v1 Announce Type: cross 
Abstract: Co-existence of 5G New Radio (5G-NR) with IoT devices is considered as a promising technique to enhance the spectral usage and efficiency of future cellular networks. In this paper, a unified framework has been proposed for allocating in-band resource blocks (RBs), i.e., within a multi-cell network, to 5G-NR users in co-existence with NB-IoT and LTE-M devices. First, a benchmark (upper-bound) scheduler has been designed for joint sub-carrier (SC) and modulation and coding scheme (MCS) allocation that maximizes instantaneous throughput and fairness among users/devices, while considering synchronous RB allocation in the neighboring cells. A series of numerical simulations with realistic ICI in an urban scenario have been used to compute benchmark upper-bound solutions for characterizing performance in terms of throughput, fairness, and delay. Next, an edge learning based multi-agent deep reinforcement learning (DRL) framework has been developed for different DRL algorithms, specifically, a policy-based gradient network (PGN), a deep Q-learning based network (DQN), and an actor-critic based deep deterministic policy gradient network (DDPGN). The proposed DRL framework depends on interference allocation, where the actions are based on inter-cell-interference (ICI) instead of power, which can bypass the need for raw data sharing and/or inter-agent communication. The numerical results reveal that the interference allocation based DRL schedulers can significantly outperform their counterparts, where the actions are based on power allocation. Further, the performance of the proposed policy-based edge learning algorithms is close to the centralized ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11574v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahida Jabeen</dc:creator>
    </item>
    <item>
      <title>Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems</title>
      <link>https://arxiv.org/abs/2501.11613</link>
      <description>arXiv:2501.11613v1 Announce Type: cross 
Abstract: This study introduces Conversation Routines (CR), a structured prompt engineering framework for developing task-oriented dialog systems using Large Language Models (LLMs). While LLMs demonstrate remarkable natural language understanding capabilities, engineering them to reliably execute complex business workflows remains challenging. The proposed CR framework enables the development of Conversation Agentic Systems (CAS) through natural language specifications, embedding task-oriented logic within LLM prompts. This approach provides a systematic methodology for designing and implementing complex conversational workflows while maintaining behavioral consistency. We demonstrate the framework's effectiveness through two proof of concept implementations: a Train Ticket Booking System and an Interactive Troubleshooting Copilot. These case studies validate CR's capability to encode sophisticated behavioral patterns and decision logic while preserving natural conversational flexibility. Results show that CR enables domain experts to design conversational workflows in natural language while leveraging custom enterprise functionalities (tools) developed by software engineers, creating an efficient division of responsibilities where developers focus on core API implementation and domain experts handle conversation design. While the framework shows promise in accessibility and adaptability, we identify key challenges including computational overhead, non-deterministic behavior, and domain-specific logic optimization. Future research directions include enhancing system robustness, improving scalability for complex multi-agent interactions, and addressing the identified limitations across diverse business applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11613v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.PL</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giorgio Robino</dc:creator>
    </item>
    <item>
      <title>Towards Change Impact Analysis in Microservices-based System Evolution</title>
      <link>https://arxiv.org/abs/2501.11778</link>
      <description>arXiv:2501.11778v1 Announce Type: cross 
Abstract: Cloud-native systems are the mainstream for enterprise solutions, given their scalability, resilience, and other benefits. While the benefits of cloud-native systems fueled by microservices are known, less guidance exists on their evolution. One could assume that since microservices encapsulate their code, code changes remain encapsulated as well; however, the community is becoming more aware of the possible consequences of code change propagation across microservices. Moreover, an active mitigation instrument for negative consequences of change propagation across microservices (i.e., ripple effect) is yet missing, but the microservice community would greatly benefit from it. This paper introduces what it could look like to have an infrastructure to assist with change impact analysis across the entire microservice system and intends to facilitate advancements in laying out the foundations and building guidelines on microservice system evolution. It shares a new direction for incremental software architecture reconstruction that could serve as the infrastructure concept and demonstrates early results from prototyping to illustrate the potential impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11778v1</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Cerny, Gabriel Goulis, Amr S. Abdelfattah</dc:creator>
    </item>
    <item>
      <title>The Dilemma of Privacy Protection for Developers in the Metaverse</title>
      <link>https://arxiv.org/abs/2501.12006</link>
      <description>arXiv:2501.12006v1 Announce Type: cross 
Abstract: To investigate the level of support and awareness developers possess for dealing with sensitive data in the metaverse, we surveyed developers, consulted legal frameworks, and analyzed API documentation in the metaverse. Our preliminary results suggest that privacy is a major concern, but developer awareness and existing support are limited. Developers lack strategies to identify sensitive data that are exclusive to the metaverse. The API documentation contains guidelines for collecting sensitive information, but it omits instructions for identifying and protecting it. Legal frameworks include definitions that are subject to individual interpretation. These findings highlight the urgent need to build a transparent and common ground for privacy definitions, identify sensitive data, and implement usable protection measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12006v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argianto Rahartomo, Leonel Merino, Mohammad Ghafari, Yoshiki Ohshima</dc:creator>
    </item>
    <item>
      <title>Tactile Displays Driven by Projected Light</title>
      <link>https://arxiv.org/abs/2410.05494</link>
      <description>arXiv:2410.05494v3 Announce Type: replace 
Abstract: Tactile displays that lend tangible form to digital content could transform computing interactions. However, achieving the resolution, speed, and dynamic range needed for perceptual fidelity remains challenging. We present a tactile display that directly converts projected light into visible tactile patterns via a photomechanical surface populated with millimeter-scale optotactile pixels. The pixels transduce incident light into mechanical displacements through photostimulated thermal gas expansion, yielding millimeter scale displacements with response times of 2 to 100 milliseconds. Employing projected light for power transmission and addressing renders these displays highly scalable. We demonstrate optically driven displays with up to 1,511 addressable pixels -- several times more pixels than any prior tactile display attaining comparable performance. Perceptual studies confirm that these displays can reproduce diverse spatiotemporal tactile patterns with high fidelity. This research establishes a foundation for practical, versatile high-resolution tactile displays driven by light.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05494v3</guid>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <category>physics.optics</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Linnander, Dustin Goetz, Gregory Reardon, Vijay Kumar, Elliot Hawkes, Yon Visell</dc:creator>
    </item>
    <item>
      <title>Cache Coherence Over Disaggregated Memory</title>
      <link>https://arxiv.org/abs/2409.02088</link>
      <description>arXiv:2409.02088v3 Announce Type: replace-cross 
Abstract: Disaggregating memory from compute offers the opportunity to better utilize stranded memory in cloud data centers. It is important to cache data in the compute nodes and maintain cache coherence across multiple compute nodes. However, the limited computing power on disaggregated memory servers makes traditional cache coherence protocols suboptimal, particularly in the case of stranded memory. This paper introduces SELCC; a Shared-Exclusive Latch Cache Coherence protocol that maintains cache coherence without imposing any computational burden on the remote memory side. It aligns the state machine of the shared-exclusive latch protocol with the MSI protocol by introducing lazy latch-release and invalidation messages, thereby ensuring both atomicity of data access and cache coherence. SELCC embeds cache-ownership metadata directly into the RDMA latch word, enabling efficient cache ownership management via RDMA atomic operations. SELCC can serve as an abstraction layer over disaggregated memory with APIs that resemble main-memory accesses. A concurrent B-tree and three transaction concurrency control algorithms are realized using SELCC's abstraction layer. Experimental results show that SELCC significantly outperforms Remote-Procedure-Call-based protocols for cache coherence under limited remote computing power. Applications on SELCC achieve comparable or superior performance over disaggregated memory compared to competitors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02088v3</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruihong Wang, Jianguo Wang, Walid G. Aref</dc:creator>
    </item>
    <item>
      <title>DasAtom: A Divide-and-Shuttle Atom Approach to Quantum Circuit Transformation</title>
      <link>https://arxiv.org/abs/2409.03185</link>
      <description>arXiv:2409.03185v2 Announce Type: replace-cross 
Abstract: Neutral atom (NA) quantum systems are emerging as a leading platform for quantum computation, offering superior or competitive qubit count and gate fidelity compared to superconducting circuits and ion traps. However, the unique features of NA devices, such as long-range interactions, long qubit coherence time, and the ability to physically move qubits, present distinct challenges for quantum circuit compilation. In this paper, we introduce DasAtom, a novel divide-and-shuttle atom approach designed to optimise quantum circuit transformation for NA devices by leveraging these capabilities. DasAtom partitions circuits into subcircuits, each associated with a qubit mapping that allows all gates within the subcircuit to be directly executed. The algorithm then shuttles atoms to transition seamlessly from one mapping to the next, enhancing both execution efficiency and overall fidelity. For a 30-qubit Quantum Fourier Transform (QFT), DasAtom achieves a 414x improvement in fidelity over the move-based algorithm Enola and a 10.6x improvement over the SWAP-based algorithm Tetris. Notably, this improvement is expected to increase exponentially with the number of qubits, positioning DasAtom as a highly promising solution for scaling quantum computation on NA platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03185v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunqi Huang, Dingchao Gao, Shenggang Ying, Sanjiang Li</dc:creator>
    </item>
  </channel>
</rss>
