<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 04:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Hybrid Reconstruction Framework for Efficient High-Order Shock-Capturing on Unstructured Meshes</title>
      <link>https://arxiv.org/abs/2510.25906</link>
      <description>arXiv:2510.25906v1 Announce Type: new 
Abstract: We present a multi-dimensional, arbitrary-order hybrid reconstruction framework for compressible flows on unstructured meshes. The method advances high-resolution schemes by combining the efficiency of linear reconstruction with the robustness of nonlinear formulations, activated only when needed through a novel a priori detection strategy. This minimizes the use of costly Compact Weighted Essentially Non-Oscillatory (CWENOZ) or Monotonic Upstream-centered Scheme for Conservation Laws (MUSCL) reconstructions, reducing computational cost without compromising accuracy or stability. The framework merges CWENOZ and the Multi-dimensional Optimal Order Detection (MOOD) paradigm while introducing a redesigned Numerical Admissibility Detector (NAD) that classifies the local flow into smooth, weakly non-smooth, and discontinuous regions in a single step. Each region is then reconstructed using an optimal method: a high-order linear scheme in smooth areas, CWENOZ in weakly non-smooth zones, and a second-order MUSCL near discontinuities. This targeted a priori allocation preserves high-order accuracy where possible and ensures stable, non-oscillatory behavior near shocks and steep gradients. Implemented within the open-source unstructured finite-volume solver UCNS3D, the framework supports arbitrary-order reconstructions on mixed-element meshes. Extensive two- and three-dimensional benchmarks confirm that it retains the designed accuracy in smooth regions while greatly improving robustness in shock-dominated flows. Thanks to the reduced frequency of nonlinear reconstructions, the method achieves up to 2.5x speed-up over a CWENOZ scheme of equal order in 3D compressible turbulence. This hybrid approach thus brings high-order accuracy closer to industrial-scale CFD through its balance of efficiency, robustness, and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25906v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiren Tong, Panagiotis Tsoutsanis</dc:creator>
    </item>
    <item>
      <title>A fast spectral overlapping domain decomposition method with discretization-independent conditioning bounds</title>
      <link>https://arxiv.org/abs/2510.25991</link>
      <description>arXiv:2510.25991v1 Announce Type: new 
Abstract: A domain decomposition method for the solution of general variable-coefficient elliptic partial differential equations on regular domains is introduced. The method is based on tessellating the domain into overlapping thin slabs or shells, and then explicitly forming a reduced linear system that connects the different domains. Rank-structure ('H-matrix structure') is exploited to handle the large dense blocks that arise in the reduced linear system. Importantly, the formulation used is well-conditioned, as it converges to a second kind Fredholm equation as the precision in the local solves is refined. Moreover, the dense blocks that arise are far more data-sparse than in existing formulations, leading to faster and more efficient H-matrix arithmetic. To form the reduced linear system, black-box randomized compression is used, taking full advantage of the fact that sparse direct solvers are highly efficient on the thin sub-domains. Numerical experiments demonstrate that our solver can handle oscillatory 2D and 3D problems with as many as 28 million degrees of freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25991v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Dirckx, Anna Yesypenko, Per-Gunnar Martinsson</dc:creator>
    </item>
    <item>
      <title>A two-dimensional fractional-order element-free Galerkin method for nonlocal elasticity and complex domain problems</title>
      <link>https://arxiv.org/abs/2510.26161</link>
      <description>arXiv:2510.26161v1 Announce Type: new 
Abstract: This study presents a meshfree two-dimensional fractional-order Element-Free Galerkin (2D f-EFG) method as a viable alternative to conventional mesh-based FEM for a numerical solution of (spatial) fractional-order differential equations (FDEs). The previously developed one-dimensional f-EFG solver offers a limited demonstration of the true efficacy of EFG formulations for FDEs, as it is restricted to simple 1D line geometries. In contrast, the 2D f-EFG solver proposed and developed here effectively demonstrates the potential of meshfree approaches for solving FDEs. The proposed solver can handle complex and irregular 2D domains that are challenging for mesh-based methods. As an example, the developed framework is employed to investigate nonlocal elasticity governed by fractional-order constitutive relations in a square and circular plate. Furthermore, the proposed approach mitigates key drawbacks of FEM, including high computational cost, mesh generation, and reduced accuracy in irregular domains. The 2D f-EFG employs 2D Moving Least Squares (MLS) approximants, which are particularly effective in approximating fractional derivatives from nodal values. The 2D f-EFG solver is employed here for the numerical solution of fractional-order linear and nonlinear partial differential equations corresponding to the nonlocal elastic response of a plate. The solver developed here is validated with the benchmark results available in the literature. While the example chosen here focuses on nonlocal elasticity, the numerical method can be extended for diverse applications of fractional-order derivatives in multiscale modeling, multiphysics coupling, anomalous diffusion, and complex material behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26161v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubham Desai, Malapeta Hemasundara Rao, Sai Sidhardh</dc:creator>
    </item>
    <item>
      <title>A parallel solver for random input problems via Karhunen-Lo\`{e}ve expansion and diagonalized coarse grid correction</title>
      <link>https://arxiv.org/abs/2510.26180</link>
      <description>arXiv:2510.26180v1 Announce Type: new 
Abstract: This paper is dedicated to enhancing the computational efficiency of traditional parallel-in-time methods for solving stochastic initial-value problems. The standard parareal algorithm often suffers from slow convergence when applied to problems with stochastic inputs, primarily due to the poor quality of the initial guess. To address this issue, we propose a hybrid parallel algorithm, termed KLE-CGC, which integrates the Karhunen-Lo\`{e}ve (KL) expansion with the coarse grid correction (CGC). The method first employs the KL expansion to achieve a low-dimensional parameterization of high-dimensional stochastic parameter fields. Subsequently, a generalized Polynomial Chaos (gPC) spectral surrogate model is constructed to enable rapid prediction of the solution field. Utilizing this prediction as the initial value significantly improves the initial accuracy for the parareal iterations. A rigorous convergence analysis is provided, establishing that the proposed framework retains the same theoretical convergence rate as the standard parareal algorithm. Numerical experiments demonstrate that KLE-CGC maintains the same convergence order as the original algorithm while substantially reducing the number of iterations and improving parallel scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26180v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dou Dai, Qiuqi Li, Huailing Song</dc:creator>
    </item>
    <item>
      <title>Efficient And Stable Third-order Method for Micromagnetics Simulations</title>
      <link>https://arxiv.org/abs/2510.26181</link>
      <description>arXiv:2510.26181v1 Announce Type: new 
Abstract: To address the magnetization dynamics in ferromagnetic materials described by the Landau-Lifshitz-Gilbert equation under large damping parameters, a third-order accurate numerical scheme is developed by building upon a second-order method \cite{CaiChenWangXie2022} and leveraging its efficiency. This method boasts two key advantages: first, it only involves solving linear systems with constant coefficients, enabling the use of fast solvers and thus significantly enhancing numerical efficiency over existing first or second-order approaches. Second, it achieves third-order temporal accuracy and fourth-order spatial accuracy, while being unconditionally stable for large damping parameters. Numerical tests in 1D and 3D scenarios confirm both its third-order accuracy and efficiency gains. When large damping parameters are present, the method demonstrates unconditional stability and reproduces physically plausible structures. For domain wall dynamics simulations, it captures the linear relationship between wall velocity and both the damping parameter and external magnetic field, outperforming lower-order methods in this regard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26181v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changjian Xie, Cheng Wang</dc:creator>
    </item>
    <item>
      <title>Transcending Sparse Measurement Limits: Operator-Learning-Driven Data Super-Resolution for Inverse Source Problem</title>
      <link>https://arxiv.org/abs/2510.26227</link>
      <description>arXiv:2510.26227v1 Announce Type: new 
Abstract: Inverse source localization from Helmholtz boundary data collected over a narrow aperture is highly ill-posed and severely undersampled, undermining classical solvers (e.g., the Direct Sampling Method). We present a modular framework that significantly improves multi-source localization from extremely sparse single-frequency measurements. First, we extend a uniqueness theorem for the inverse source problem, proving that a unique solution is guaranteed under limited viewing apertures. Second, we employ a Deep Operator Network (DeepONet) with a branch-trunk architecture to interpolate the sparse measurements, lifting six to ten samples within the narrow aperture to a sufficiently dense synthetic aperture. Third, the super-resolved field is fed into the Direct Sampling Method (DSM). For a single source, we derive an error estimate showing that sparse data alone can achieve grid-level precision. In two- and three-source trials, localization from raw sparse measurements is unreliable, whereas DeepONet-reconstructed data reduce localization error by about an order of magnitude and remain effective with apertures as small as $\pi/4$. By decoupling interpolation from inversion, the framework allows the interpolation and inversion modules to be swapped with neural operators and classical algorithms, respectively, providing a practical and flexible design that improves localization accuracy compared with standard baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26227v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanyu Pan, Jianing Zhou, Xiaotong Liu, Yunqing Huang, Nianyu Yi</dc:creator>
    </item>
    <item>
      <title>Simulation of the magnetic Ginzburg-Landau equation via vortex tracking</title>
      <link>https://arxiv.org/abs/2510.26334</link>
      <description>arXiv:2510.26334v1 Announce Type: new 
Abstract: This paper deals with the numerical simulation of the 2D magnetic time-dependent Ginzburg-Landau (TDGL) equations in the regime of small but finite (inverse) Ginzburg-Landau parameter $\epsilon$ and constant (order $1$ in $\epsilon$) applied magnetic field. In this regime, a well-known feature of the TDGL equation is the appearance of quantized vortices with core size of order $\epsilon$. Moreover, in the singular limit $\epsilon \searrow 0$, these vortices evolve according to an explicit ODE system. In this work, we first introduce a new numerical method for the numerical integration of this limiting ODE system, which requires to solve a linear second order PDE at each time step. We also provide a rigorous theoretical justification for this method that applies to a general class of 2D domains. We then develop and analyze a numerical strategy based on the finite-dimensional ODE system to efficiently simulate the infinite-dimensional TDGL equations in the presence of a constant external magnetic field and for small, but finite, $\epsilon$. This method allows us to avoid resolving the $\epsilon$-scale when solving the TDGL equations, where small values of $\epsilon$ typically require very fine meshes and time steps. We provide numerical examples on a few test cases and justify the accuracy of the method with numerical investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26334v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Carvalho Corso (IANS-NMH, Stuttgart University), Gaspard Kemlin (LAMFA, UPJV), Christof Melcher (AA, RWTH), Benjamin Stamm (IANS-NMH, Stuttgart University)</dc:creator>
    </item>
    <item>
      <title>Incorporating Local H\"older Regularity into PINNs for Solving Elliptic PDEs</title>
      <link>https://arxiv.org/abs/2510.26365</link>
      <description>arXiv:2510.26365v1 Announce Type: new 
Abstract: In this paper, local H\"older regularization is incorporated into a physics-informed neural networks (PINNs) framework for solving elliptic partial differential equations (PDEs). Motivated by the interior regularity properties of linear elliptic PDEs, a modified loss function is constructed by introducing local H\"older regularization term. To approximate this term effectively, a variable-distance discrete sampling strategy is developed. Error estimates are established to assess the generalization performance of the proposed method. Numerical experiments on a range of elliptic problems demonstrate notable improvements in both prediction accuracy and robustness compared to standard physics-informed neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26365v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qirui Zhou, Jiebao Sun, Yi Ran, Boying Wu</dc:creator>
    </item>
    <item>
      <title>Asymptotic meshes from $r$-variational adaptation methods for static problems in one dimension</title>
      <link>https://arxiv.org/abs/2510.26375</link>
      <description>arXiv:2510.26375v1 Announce Type: new 
Abstract: We consider the minimization of integral functionals in one dimension and their approximation by $r$-adaptive finite elements. Including the grid of the FEM approximation as a variable in the minimization, we are able to show that the optimal grid configurations have a well-defined limit when the number of nodes in the grid is being sent to infinity. This is done by showing that the suitably renormalized energy functionals possess a limit in the sense of $\Gamma$-convergence. We provide numerical examples showing the closeness of the optimal asymptotic mesh obtained as a minimizer of the $\Gamma$-limit to the optimal finite meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26375v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darith Hun, Nicolas Mo\"es, Heiner Olbermann</dc:creator>
    </item>
    <item>
      <title>Explicit Consistency Error Estimate for Finite Element Solutions of the Poisson Equation on Convex Domains</title>
      <link>https://arxiv.org/abs/2510.26404</link>
      <description>arXiv:2510.26404v1 Announce Type: new 
Abstract: We derive explicit a priori consistency error estimates for a standard finite element discretization of the Poisson equation on convex domains, where the domain is approximated by an internal convex polyhedron. The obtained explicit estimates depend only on global geometric parameters and are applicable to general convex domains and arbitrary families of simplicial meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26404v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Su Ruibo</dc:creator>
    </item>
    <item>
      <title>The evolving surface morphochemical reaction-diffusion system for battery modeling</title>
      <link>https://arxiv.org/abs/2510.26437</link>
      <description>arXiv:2510.26437v1 Announce Type: new 
Abstract: It is well known that phase formation by electrodeposition yields films of poorly controllable morphology. This typically leads to a range of technological issues in many fields of electrochemical technology. Presently, a particularly relevant case is that of high-energy density next-generation batteries with metal anodes, that cannot yet reach practical cyclability targets, owing to uncontrolled elelctrode shape evolution. In this scenario, mathematical modelling is a key tool to lay the knowledge-base for materials-science advancements liable to lead to concretely stable battery material architectures. In this work, we introduce the Evolving Surface DIB (ESDIB) model, a reaction-diffusion system posed on a dynamically evolving electrode surface. Unlike previous fixed-surface formulations, the ESDIB model couples surface evolution to the local concentration of electrochemical species, allowing the geometry of the electrode itself to adapt in response to deposition. To handle the challenges related to the coupling between surface motion and species transport, we numerically solve the system by proposing an extension of the Lumped Evolving Surface Finite Element Method (LESFEM) for spatial discretisation, combined with an IMEX Euler scheme for time integration. The model is validated through six numerical experiments, each compared with laboratory images of electrodeposition. Results demonstrate that the ESDIB framework accurately captures branching and dendritic growth, providing a predictive and physically consistent tool for studying metal deposition phenomena in energy storage devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26437v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedetto Bozzini, Massimo Frittelli, Anotida Madzvamuse, Ivonne Sgura</dc:creator>
    </item>
    <item>
      <title>A GenEO-type coarse space with smaller eigenproblems</title>
      <link>https://arxiv.org/abs/2510.26548</link>
      <description>arXiv:2510.26548v1 Announce Type: new 
Abstract: Coarse spaces are essential to ensure robustness w.r.t. the number of subdomains in two-level overlapping Schwarz methods. Robustness with respect to the coefficients of the underlying partial differential equation (PDE) can be achieved by adaptive (or spectral) coarse spaces involving the solution of local eigenproblems. The solution of these eigenproblems, although scalable, entails a large setup cost which may exceed the cost for the iteration phase. In this paper we present and analyse a new variant of the GenEO (Generalised Eigenproblems in the Overlap) coarse space which involves solving eigenproblems only in a strip connected to the boundary of the subdomain. This leads to a significant reduction of the setup cost while the method satisfies a similar coefficient-robust condition number estimate as the original method, albeit with a possibly larger coarse space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26548v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Peter Bastian, Nils Friess</dc:creator>
    </item>
    <item>
      <title>Accelerated decomposition of bistochastic kernel matrices by low rank approximation</title>
      <link>https://arxiv.org/abs/2510.26574</link>
      <description>arXiv:2510.26574v1 Announce Type: new 
Abstract: We develop an accelerated algorithm for computing an approximate eigenvalue decomposition of bistochastic normalized kernel matrices. Our approach constructs a low rank approximation of the original kernel matrix by the pivoted partial Cholesky algorithm and uses it to compute an approximate decomposition of its bistochastic normalization without requiring the formation of the full kernel matrix. The cost of the proposed algorithm depends linearly on the size of the employed training dataset and quadratically on the rank of the low rank approximation, offering a significant cost reduction compared to the naive approach. We apply the proposed algorithm to the kernel based extraction of spatiotemporal patterns from chaotic dynamics, demonstrating its accuracy while also comparing it with an alternative algorithm consisting of subsampling and Nystroem extension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26574v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Vales, Dimitrios Giannakis</dc:creator>
    </item>
    <item>
      <title>Fast tensor-based electrostatic energy calculations in the perspective of protein-ligand docking problem</title>
      <link>https://arxiv.org/abs/2510.26611</link>
      <description>arXiv:2510.26611v1 Announce Type: new 
Abstract: We propose and justify a new approach for fast calculation of the electrostatic interaction energy of clusters of charged particles in constrained energy minimization in the framework of rigid protein-ligand docking. Our ``blind search'' docking technique is based on the low-rank range-separated (RS) tensor-based representation of the free-space electrostatic potential of the biomolecule represented on large $n\times n\times n$ 3D grid. We show that both the collective electrostatic potential of a complex protein-ligand system and the respective electrostatic interaction energy can be calculated by tensor techniques in $O(n)$-complexity, such that the numerical cost for energy calculation only mildly (logarithmically) depends on the number of particles in the system. Moreover, tensor representation of the electrostatic potential enables usage of large 3D Cartesian grids (of the order of $n^3 \sim 10^{12}$), which could allow the accurate modeling of complexes with several large proteins. In our approach selection of the correct geometric pose predictions in the localized posing process is based on the control of van der Waals distance between the target molecular clusters. Here, we confine ourselves by constrained minimization of the energy functional by using only fast tensor-based free-space electrostatic energy recalculation for various rotations and translations of both clusters. Numerical tests of the electrostatic energy-based ``protein-ligand docking'' algorithm applied to synthetic and realistic input data present a proof of concept for rather complex particle configurations. The method may be used in the framework of the traditional stochastic or deterministic posing/docking techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26611v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Benner, Boris N. Khoromskij, Venera Khoromskaia, Matthias Stein</dc:creator>
    </item>
    <item>
      <title>A Practitioner's Guide to Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2510.25781</link>
      <description>arXiv:2510.25781v1 Announce Type: cross 
Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a promising alternative to traditional Multilayer Perceptrons (MLPs), inspired by the Kolmogorov-Arnold representation theorem. Unlike MLPs, which use fixed activation functions on nodes, KANs employ learnable univariate basis functions on edges, offering enhanced expressivity and interpretability. This review provides a systematic and comprehensive overview of the rapidly expanding KAN landscape, moving beyond simple performance comparisons to offer a structured synthesis of theoretical foundations, architectural variants, and practical implementation strategies. By collecting and categorizing a vast array of open-source implementations, we map the vibrant ecosystem supporting KAN development. We begin by bridging the conceptual gap between KANs and MLPs, establishing their formal equivalence and highlighting the superior parameter efficiency of the KAN formulation. A central theme of our review is the critical role of the basis function; we survey a wide array of choices, including B-splines, Chebyshev and Jacobi polynomials, ReLU compositions, Gaussian RBFs, and Fourier series, and analyze their respective trade-offs in terms of smoothness, locality, and computational cost. We then categorize recent advancements into a clear roadmap, covering techniques for improving accuracy, efficiency, and regularization. Key topics include physics-informed loss design, adaptive sampling, domain decomposition, hybrid architectures, and specialized methods for handling discontinuities. Finally, we provide a practical "Choose-Your-KAN" guide to help practitioners select appropriate architectures, and we conclude by identifying current research gaps. The associated GitHub repository https://github.com/AmirNoori68/kan-review complements this paper and serves as a structured reference for ongoing KAN research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25781v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Noorizadegan, Sifan Wang, Leevan Ling</dc:creator>
    </item>
    <item>
      <title>Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training</title>
      <link>https://arxiv.org/abs/2510.25803</link>
      <description>arXiv:2510.25803v1 Announce Type: cross 
Abstract: Pre-training has proven effective in addressing data scarcity and performance limitations in solving PDE problems with neural operators. However, challenges remain due to the heterogeneity of PDE datasets in equation types, which leads to high errors in mixed training. Additionally, dense pre-training models that scale parameters by increasing network width or depth incur significant inference costs. To tackle these challenges, we propose a novel Mixture-of-Experts Pre-training Operator Transformer (MoE-POT), a sparse-activated architecture that scales parameters efficiently while controlling inference costs. Specifically, our model adopts a layer-wise router-gating network to dynamically select 4 routed experts from 16 expert networks during inference, enabling the model to focus on equation-specific features. Meanwhile, we also integrate 2 shared experts, aiming to capture common properties of PDE and reduce redundancy among routed experts. The final output is computed as the weighted average of the results from all activated experts. We pre-train models with parameters from 30M to 0.5B on 6 public PDE datasets. Our model with 90M activated parameters achieves up to a 40% reduction in zero-shot error compared with existing models with 120M activated parameters. Additionally, we conduct interpretability analysis, showing that dataset types can be inferred from router-gating network decisions, which validates the rationality and effectiveness of the MoE architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25803v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Wang, Haiyang Xin, Jie Wang, Xuanze Yang, Fei Zha, Huanshuo Dong, Yan Jiang</dc:creator>
    </item>
    <item>
      <title>Quantum Stochastic Gradient Descent in its continuous-time limit based on the Wigner formulation of Open Quantum Systems</title>
      <link>https://arxiv.org/abs/2510.25910</link>
      <description>arXiv:2510.25910v1 Announce Type: cross 
Abstract: The main ideas behind a research plan to use the Wigner formulation as a bridge between classical and quantum probabilistic algorithms are presented, focusing on a particular case: the Quantum analog of Stochastic Gradient Descent in its continuous-time limit based on the Wigner formulation of Open Quantum Systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25910v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose A. Morales Escalante</dc:creator>
    </item>
    <item>
      <title>Equation Discovery, Parametric Simulation, and Optimization Using the Physics-Informed Neural Network (PINN) Method for the Heat Conduction Problem</title>
      <link>https://arxiv.org/abs/2510.25925</link>
      <description>arXiv:2510.25925v1 Announce Type: cross 
Abstract: In this study, the capabilities of the Physics-Informed Neural Network (PINN) method are investigated for three major tasks: modeling, simulation, and optimization in the context of the heat conduction problem. In the modeling phase, the governing equation of heat transfer by conduction is reconstructed through equation discovery using fractional-order derivatives, enabling the identification of the fractional derivative order that best describes the physical behavior. In the simulation phase, the thermal conductivity is treated as a physical parameter, and a parametric simulation is performed to analyze its influence on the temperature field. In the optimization phase, the focus is placed on the inverse problem, where the goal is to infer unknown physical properties from observed data. The effectiveness of the PINN approach is evaluated across these three fundamental engineering problem types and compared against conventional numerical methods. The results demonstrate that although PINNs may not yet outperform traditional numerical solvers in terms of speed and accuracy for forward problems, they offer a powerful and flexible framework for parametric simulation, optimization, and equation discovery, making them highly valuable for inverse and data-driven modeling applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25925v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ehsan Ghaderi, Mohamad Ali Bijarchi, Siamak Kazemzadeh Hannani, Ali Nouri Boroujerdi</dc:creator>
    </item>
    <item>
      <title>Numerical Investigation of Single-Core to Split-Core Transitions in Nematic Liquid Crystals</title>
      <link>https://arxiv.org/abs/2510.26215</link>
      <description>arXiv:2510.26215v1 Announce Type: cross 
Abstract: We analyze single-core and split-core defect structures in nematic liquid crystals within the Landau-de Gennes framework by studying minimizers of the associated energy functional. A bifurcation occurs at a critical temperature threshold, below which both split-core and single-core configurations are solutions to the Euler-Lagrange equation, with the split-core defect possessing lower energy. Above the threshold, the split-core configuration vanishes, leaving the single-core defect as the only stable solution. We analyze the dependence of such temperature threshold on the domain size and characterize the nature of the transition between the two defect types. We carry out a quantitative study of defect core sizes as functions of temperature and domain size for both single and split core defects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26215v1</guid>
      <category>cond-mat.soft</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Siebel-Cortopassi, Pei Liu</dc:creator>
    </item>
    <item>
      <title>On a semi-discrete model of Maxwell's equations in three and two dimensions</title>
      <link>https://arxiv.org/abs/2510.26427</link>
      <description>arXiv:2510.26427v1 Announce Type: cross 
Abstract: In this paper, we develop a geometric, structure-preserving semi-discrete formulation of Maxwell's equations in both three- and two-dimensional settings within the framework of discrete exterior calculus. This approach preserves the intrinsic geometric and topological structures of the continuous theory while providing a consistent spatial discretization. We analyze the essential properties of the proposed semi-discrete model and compare them with those of the classical Maxwell's equations. As a special case, the model is illustrated on a combinatorial two-dimensional torus, where the semi-discrete Maxwell's equations take the form of a system of first-order linear ordinary differential equations. An explicit expression for the general solution of this system is also derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26427v1</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volodymyr Sushch</dc:creator>
    </item>
    <item>
      <title>How Regularization Terms Make Invertible Neural Networks Bayesian Point Estimators</title>
      <link>https://arxiv.org/abs/2510.26704</link>
      <description>arXiv:2510.26704v1 Announce Type: cross 
Abstract: Can regularization terms in the training of invertible neural networks lead to known Bayesian point estimators in reconstruction? Invertible networks are attractive for inverse problems due to their inherent stability and interpretability. Recently, optimization strategies for invertible neural networks that approximate either a reconstruction map or the forward operator have been studied from a Bayesian perspective, but each has limitations. To address this, we introduce and analyze two regularization terms for the network training that, upon inversion of the network, recover properties of classical Bayesian point estimators: while the first can be connected to the posterior mean, the second resembles the MAP estimator. Our theoretical analysis characterizes how each loss shapes both the learned forward operator and its inverse reconstruction map. Numerical experiments support our findings and demonstrate how these loss-term regularizers introduce data-dependence in a stable and interpretable way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26704v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick Heilenk\"otter</dc:creator>
    </item>
    <item>
      <title>Monte-Carlo/Moments micro-macro Parareal method for unimodal and bimodal scalar McKean-Vlasov SDEs</title>
      <link>https://arxiv.org/abs/2310.11365</link>
      <description>arXiv:2310.11365v3 Announce Type: replace 
Abstract: We propose a micro-macro parallel-in-time Parareal method for scalar McKean-Vlasov stochastic differential equations (SDEs). In the algorithm, the fine Parareal propagator is a Monte Carlo simulation of an ensemble of particles, while an approximate ordinary differential equation (ODE) description of the mean and the variance of the particle distribution is used as a coarse Parareal propagator to achieve speedup. We analyse the convergence behaviour of our method for a linear problem and provide numerical experiments indicating the parallel weak scaling of the algorithm on a set of examples. We show, with numerical experiments, that convergence typically takes place in a low number of iterations, depending on the quality of the ODE predictor. For bimodal SDEs, we avoid quality deterioration of the coarse predictor (compared to unimodal SDEs) through the usage of multiple ODEs, each describing the mean and variance of the particle distribution in locally unimodal regions of the phase space. The benefit of the proposed algorithm can be viewed through two lenses: (i) through the parallel-in-time lens, speedup is obtained through the use of a very cheap coarse integrator (an ODE moment model), and (ii) through the moment models lens, accuracy is iteratively gained through the use of parallel machinery as a corrector. In contrast to the isolated use of a moment model, the proposed method (iteratively) converges to the true distribution generated by the SDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11365v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>stat.CO</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ignace Bossuyt, Stefan Vandewalle, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Can Symmetric Positive Definite (SPD) coarse spaces perform well for indefinite Helmholtz problems?</title>
      <link>https://arxiv.org/abs/2403.18378</link>
      <description>arXiv:2403.18378v3 Announce Type: replace 
Abstract: The purpose of this work is to improve the estimates for the $\Delta$-GenEO method from the paper "Overlapping Schwarz methods with GenEO coarse spaces for indefinite and nonself-adjoint problems" by N. Bootland, V. Dolean, I. G Graham, C. Ma, R. Scheichl (https://doi.org/10.1093/imanum/drac036) when applied to the indefinite Helmholtz equation. We derive k-dependent estimates of quantities of interest ensuring the robustness of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18378v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victorita Dolean, Mark Fry, Matthias Langer</dc:creator>
    </item>
    <item>
      <title>Differentiable Programming for Differential Equations: A Review</title>
      <link>https://arxiv.org/abs/2406.09699</link>
      <description>arXiv:2406.09699v2 Announce Type: replace 
Abstract: The differentiable programming paradigm is a cornerstone of modern scientific computing. It refers to numerical methods for computing the gradient of a numerical model's output. Many scientific models are based on differential equations, where differentiable programming plays a crucial role in calculating model sensitivities, inverting model parameters, and training hybrid models that combine differential equations with data-driven approaches. Furthermore, recognizing the strong synergies between inverse methods and machine learning offers the opportunity to establish a coherent framework applicable to both fields. Differentiating functions based on the numerical solution of differential equations is non-trivial. Numerous methods based on a wide variety of paradigms have been proposed in the literature, each with pros and cons specific to the type of problem investigated. Here, we provide a comprehensive review of existing techniques to compute derivatives of numerical solutions of differential equations. We first discuss the importance of gradients of solutions of differential equations in a variety of scientific domains. Second, we lay out the mathematical foundations of the various approaches and compare them with each other. Third, we cover the computational considerations and explore the solutions available in modern scientific software. Last but not least, we provide best-practices and recommendations for practitioners. We hope that this work accelerates the fusion of scientific models and data, and fosters a modern approach to scientific modelling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09699v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Facundo Sapienza, Jordi Bolibar, Frank Sch\"afer, Brian Groenke, Avik Pal, Victor Boussange, Patrick Heimbach, Giles Hooker, Fernando P\'erez, Per-Olof Persson, Christopher Rackauckas</dc:creator>
    </item>
    <item>
      <title>Neural active manifolds: nonlinear dimensionality reduction for uncertainty quantification</title>
      <link>https://arxiv.org/abs/2408.03534</link>
      <description>arXiv:2408.03534v2 Announce Type: replace 
Abstract: We present a new approach for nonlinear dimensionality reduction, specifically designed for computationally expensive mathematical models. We leverage autoencoders to discover a one-dimensional neural active manifold (NeurAM) capturing the model output variability, through the aid of a simultaneously learnt surrogate model with inputs on this manifold. Our method only relies on model evaluations and does not require the knowledge of gradients. The proposed dimensionality reduction framework can then be applied to assist outer loop many-query tasks in scientific computing, like sensitivity analysis and multifidelity uncertainty propagation. In particular, we prove, both theoretically under idealized conditions, and numerically in challenging test cases, how NeurAM can be used to obtain multifidelity sampling estimators with reduced variance by sampling the models on the discovered low-dimensional and shared manifold among models. Several numerical examples illustrate the main features of the proposed dimensionality reduction strategy and highlight its advantages with respect to existing approaches in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03534v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Zanoni, Gianluca Geraci, Matteo Salvador, Alison L. Marsden, Daniele E. Schiavazzi</dc:creator>
    </item>
    <item>
      <title>Approximating the signature of Brownian motion for high order SDE simulation</title>
      <link>https://arxiv.org/abs/2409.10118</link>
      <description>arXiv:2409.10118v2 Announce Type: replace 
Abstract: The signature is a collection of iterated integrals describing the "shape" of a path. It appears naturally in the Taylor expansions of controlled differential equations and, as a consequence, is arguably the central object within rough path theory. In this paper, we will consider the signature of Brownian motion with time, and present both new and recently developed approximations for some of its integrals. Since these integrals (or equivalent L\'{e}vy areas) are nonlinear functions of the Brownian path, they are not Gaussian and known to be challenging to simulate. To conclude the paper, we will present some applications of these approximations to the high order numerical simulation of stochastic differential equations (SDEs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10118v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Stochastic Analysis and Applications 2025: In Honour of Terry Lyons</arxiv:journal_reference>
      <dc:creator>James Foster</dc:creator>
    </item>
    <item>
      <title>Fully discrete analysis of the Galerkin POD neural network approximation with application to 3D acoustic wave scattering</title>
      <link>https://arxiv.org/abs/2502.01859</link>
      <description>arXiv:2502.01859v3 Announce Type: replace 
Abstract: In this work, we consider the approximation of parametric maps using the so-called Galerkin POD-NN method. This technique combines the computation of a reduced basis via proper orthogonal decomposition (POD) and artificial neural networks (NNs) for the construction of fast surrogates of said parametric maps. In contrast to the existing literature, which has studied the approximation properties of this kind of architecture on a continuous level, we provide a fully discrete error analysis of this approach. More precisely, our estimates also account for discretization errors during the construction of the NN architecture. We consider the number of reduced basis in the approximation of the solution manifold, truncation in the parameter space, and, most importantly, the number of samples in the computation of the reduced space, together with the effect of the use of NNs in the approximation of the reduced coefficients. Following this error analysis, we provide a-priori bounds on the required POD tolerance, the resulting POD ranks, and NN parameters to maintain the order of convergence of quasi Monte Carlo sampling techniques. We conclude this work by showcasing the applicability of this method through a practical industrial application: the sound-soft acoustic scattering problem by a parametrically defined scatterer in three physical dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01859v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\"urgen D\"olz, Fernando Henr\'iquez</dc:creator>
    </item>
    <item>
      <title>Kernel-learning parameter prediction and evaluation in algebraic multigrid method for several PDEs</title>
      <link>https://arxiv.org/abs/2504.14930</link>
      <description>arXiv:2504.14930v2 Announce Type: replace 
Abstract: This paper explores the application of kernel learning methods for parameter prediction and evaluation in the Algebraic Multigrid Method (AMG), focusing on several Partial Differential Equation (PDE) problems. AMG is an efficient iterative solver for large-scale sparse linear systems, particularly those derived from elliptic and parabolic PDE discretizations. However, its performance heavily relies on numerous parameters, which are often set empirically and are highly sensitive to AMG's effectiveness. Traditional parameter optimization methods are either computationally expensive or lack theoretical support. To address this, we propose a Gaussian Process Regression (GPR)-based strategy to optimize AMG parameters and introduce evaluation metrics to assess their effectiveness. Trained on small-scale datasets, GPR predicts nearly optimal parameters, bypassing the time-consuming parameter sweeping process. We also use kernel learning techniques to build a kernel function library and determine the optimal kernel function through linear combination, enhancing prediction accuracy. In numerical experiments, we tested typical PDEs such as the constant-coefficient Poisson equation, variable-coefficient Poisson equation, diffusion equation, and Helmholtz equation. Results show that GPR-predicted parameters match grid search results in iteration counts while significantly reducing computational time. A comprehensive analysis using metrics like mean squared error, prediction interval coverage, and Bayesian information criterion confirms GPR's efficiency and reliability. These findings validate GPR's effectiveness in AMG parameter optimization and provide theoretical support for AMG's practical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14930v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junyue Luo, Xiaoqiang Yue, Fangfang Zhang, Juan Zhang</dc:creator>
    </item>
    <item>
      <title>Numerical Identification of a Time-Dependent Coefficient in a Time-Fractional Diffusion Equation with Integral Constraints</title>
      <link>https://arxiv.org/abs/2505.19738</link>
      <description>arXiv:2505.19738v2 Announce Type: replace 
Abstract: In this paper, we numerically address the inverse problem of identifying a time-dependent coefficient in the time-fractional diffusion equation. An a priori estimate is established to ensure uniqueness and stability of the solution. A fully implicit finite-difference scheme is proposed and rigorously analysed for stability and convergence. An efficient algorithm based on an integral formulation is implemented and verified through numerical experiments, demonstrating accuracy and robustness under noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19738v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arshyn Altybay</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of An Alternating Nonlinear GMRES on Linear Systems</title>
      <link>https://arxiv.org/abs/2506.01081</link>
      <description>arXiv:2506.01081v2 Announce Type: replace 
Abstract: In this work, we develop an alternating nonlinear Generalized Minimum Residual (NGMRES) algorithm with depth $m$ and periodicity $p$, denoted by aNGMRES($m, p$), applied to linear systems. We provide a theoretical analysis to quantify by how much one-step NGMRES($m$) using Richardson iterations as initial guesses can improve the convergence speed of the underlying fixed-point iteration for diagonalizable and symmetric positive definite cases. Our theoretical analysis gives us a better understanding of which factors affect the convergence speed. Moreover, under certain conditions, we prove the periodic equivalence between the proposed aNGMRES applied to Richardson iteration and GMRES. Specifically, aNGMRES($\infty,p$) and full GMRES are identical at the iteration index $jp$. Therefore, aNGMRES($\infty,p$) can be regarded as an alternative to GMRES for solving linear systems. For finite $m$, the iterates of aNGMRES($m,m+1$) and restarted GMRES (GMRES($m+1$)) are the same at the end of each periodic interval of length $p$, i.e, at the iteration index $jp$. In Addition, we present a convergence analysis of aNGMRES when applied to accelerate Richardson iteration. The advantages of aNGMRES($m,p$) method are that there is no need to solve a least-squares problem at each iteration which can reduce the computational cost, and it can enhance the robustness against stagnations, which could occur for NGMRES($m$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01081v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunhui He</dc:creator>
    </item>
    <item>
      <title>Forecasting Public Sentiments via Mean Field Games</title>
      <link>https://arxiv.org/abs/2506.08465</link>
      <description>arXiv:2506.08465v3 Announce Type: replace 
Abstract: Motivated by the goal of forecasting public sentiments, we consider a forecasting problem in the context of the Mean Field Games theory. We develop a numerical method, which is a version of the so-called convexification method. We provide theoretical convergence analysis that establishes global convergence of the method with a convergence rate. We also conduct numerical experiments that demonstrate the accurate performance of the convexification technique and highlight some promising features of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08465v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael V. Klibanov, Kevin McGoff, Trung Truong</dc:creator>
    </item>
    <item>
      <title>Spectral Approximation to Fractional Integral Operators</title>
      <link>https://arxiv.org/abs/2506.19332</link>
      <description>arXiv:2506.19332v4 Announce Type: replace 
Abstract: We propose a fast and stable method for constructing matrix approximations to fractional integral operators applied to series in the Chebyshev fractional polynomials. This method utilizes a recurrence relation satisfied by the fractional integrals of mapped Chebyshev polynomials and significantly outperforms existing methods. Through numerical examples, we highlight the broad applicability of these matrix approximations, including the solution of boundary value problems for fractional integral and differential equations. Additional applications include fractional differential equation initial value problems and fractional eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19332v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaolin Liu, Kuan Xu</dc:creator>
    </item>
    <item>
      <title>A Convolutional Hierarchical Deep-learning Neural Network (C-HiDeNN) Framework for Non-linear Finite Element Analysis</title>
      <link>https://arxiv.org/abs/2509.02435</link>
      <description>arXiv:2509.02435v2 Announce Type: replace 
Abstract: We present a framework for the Convolutional Hierarchical Deep-learning Neural Network (C-HiDeNN) tailored for nonlinear finite element analysis. Building upon the structured foundation of HiDeNN, C-HiDeNN introduces a convolution operator to enhance numerical approximation. A distinctive feature of C-HiDeNN is its higher-order accurate approximation achieved through an expanded set of parameters, such as the polynomial order 'p,' dilation parameter 'a,' patch size 's,' and nodal position 'X'. These parameters function as the functional equivalents of weights and biases within each C-HiDeNN patch. In addition, C-HiDeNN can be selectively applied to regions requiring high resolution to adaptively improve local prediction accuracy. To demonstrate the effectiveness of this framework, we provide numerical examples in the context of nonlinear finite element analysis. The results show that our approach achieves significantly higher accuracy than conventional Finite Element Method (FEM) while substantially reducing computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02435v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingjian Liu, Monish Yadav Pabbala, Jiachen Guo, Chanwook Park, Gino Domel, Wing Kam Liu, Dong Qian</dc:creator>
    </item>
    <item>
      <title>Real-time CBCT reconstructions using Krylov solvers in repeated scanning procedures</title>
      <link>https://arxiv.org/abs/2509.08574</link>
      <description>arXiv:2509.08574v2 Announce Type: replace 
Abstract: This work introduces a new efficient iterative solver for the reconstruction of real-time cone-beam computed tomography (CBCT), which is based on the Prior Image Constrained Compressed Sensing (PICCS) regularization and leverages the efficiency of Krylov subspace methods. In particular, we focus on the setting where a sequence of under-sampled CT scans are taken on the same object with only local changes (e.g. changes in a tumour size or the introduction of a surgical tool). This is very common, for example, in image-guided surgery, where the amount of measurements is limited to ensure the safety of the patient. In this case, we can also typically assume that a (good) initial reconstruction for the solution exists, coming from a previously over-sampled scan, so we can use this information to aid the subsequent reconstructions. The effectiveness of this method is demonstrated in both a synthetic scan and using real CT data, where it can be observed that the PICCS framework is very effective for the reduction of artifacts, and that the new method is faster than other common alternatives used in the same setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08574v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fred Hastings, S M Ragib Shahriar Islam, Malena Sabat\'e Landman, Sepideh Hatamikia, Carola-Bibiane Sch\"onlieb, Ander Biguri</dc:creator>
    </item>
    <item>
      <title>Multivariate Rational Approximation of Scattered Data Using the p-AAA Algorithm</title>
      <link>https://arxiv.org/abs/2510.22861</link>
      <description>arXiv:2510.22861v2 Announce Type: replace 
Abstract: Many algorithms for approximating data with rational functions are built on interpolation or least-squares approximation. Inspired by the adaptive Antoulas-Anderson (AAA) algorithm for the univariate case, the parametric adaptive Antoulas-Anderson (p-AAA) algorithm extends this idea to the multivariate setting, combining least-squares and interpolation formulations into a single effective approximation procedure. In its original formulation p-AAA operates on grid data, requiring access to function samples at every combination of discrete sampling points in each variable. In this work we extend the p-AAA algorithm to scattered data sets, without requiring uniform/grid sampling. In other words, our proposed p-AAA formulation operates on a set of arbitrary sampling points and is not restricted to a grid structure for the sampled data. Towards this goal, we introduce several formulations for rational least-squares optimization problems that incorporate interpolation conditions via constraints. We analyze the structure of the resulting optimization problems and introduce structured matrices whose singular value decompositions yield closed-form solutions to the underlying least-squares problems. Several examples illustrate computational aspects and the effectiveness of our proposed procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22861v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linus Balicki, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Energy Approach from $\varepsilon$-Graph to Continuum Diffusion Model with Connectivity Functional</title>
      <link>https://arxiv.org/abs/2510.25114</link>
      <description>arXiv:2510.25114v2 Announce Type: replace 
Abstract: We derive an energy-based continuum limit for $\varepsilon$-graphs endowed with a general connectivity functional. We prove that the discrete energy and its continuum counterpart differ by at most $O(\varepsilon)$; the prefactor involves only the $W^{1,1}$-norm of the connectivity density as $\varepsilon\to0$, so the error bound remains valid even when that density has strong local fluctuations. As an application, we introduce a neural-network procedure that reconstructs the connectivity density from edge-weight data and then embeds the resulting continuum model into a brain-dynamics framework. In this setting, the usual constant diffusion coefficient is replaced by the spatially varying coefficient produced by the learned density, yielding dynamics that differ significantly from those obtained with conventional constant-diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25114v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahong Yang, Sun Lee, Jeff Calder, Wenrui Hao</dc:creator>
    </item>
    <item>
      <title>A linear, unconditionally stable, second order decoupled method for the Ericksen-Leslie model with SAV approach</title>
      <link>https://arxiv.org/abs/2503.19424</link>
      <description>arXiv:2503.19424v3 Announce Type: replace-cross 
Abstract: In this paper, we present a second order, linear, fully decoupled, and unconditionally energy stable scheme for solving the Erickson-Leslie model. This approach integrates the pressure correction method with a scalar auxiliary variable technique. We rigorously demonstrate the unconditional energy stability of the proposed scheme. Furthermore, we present several numerical experiments to validate its convergence order, stability, and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19424v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruonan Cao, Nianyu Yi</dc:creator>
    </item>
    <item>
      <title>A Fourier-based inference method for learning interaction kernels in particle systems</title>
      <link>https://arxiv.org/abs/2505.05207</link>
      <description>arXiv:2505.05207v2 Announce Type: replace-cross 
Abstract: We consider the problem of inferring the interaction kernel of stochastic interacting particle systems from observations of a single particle. We adopt a semi-parametric approach and represent the interaction kernel in terms of a generalized Fourier series. The basis functions in this expansion are tailored to the problem at hand and are chosen to be orthogonal polynomials with respect to the invariant measure of the mean-field dynamics. The generalized Fourier coefficients are obtained as the solution of an appropriate linear system whose coefficients depend on the moments of the invariant measure, and which are approximated from the particle trajectory that we observe. We quantify the approximation error in the Lebesgue space weighted by the invariant measure and study the asymptotic properties of the estimator in the joint limit as the observation interval and the number of particles tend to infinity, i.e. the joint large time-mean field limit. We also explore the regime where an increasing number of generalized Fourier coefficients is needed to represent the interaction kernel. Our theoretical results are supported by extensive numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05207v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigorios A. Pavliotis, Andrea Zanoni</dc:creator>
    </item>
    <item>
      <title>Meshless projection model-order reduction via reference spaces for smoothed-particle hydrodynamics</title>
      <link>https://arxiv.org/abs/2507.07830</link>
      <description>arXiv:2507.07830v3 Announce Type: replace-cross 
Abstract: A model-order reduction framework for the meshless smoothed-particle hydrodynamics (SPH) method is presented. The proposed framework introduces the concept of modal reference spaces to overcome the challenges of discovering low-dimensional subspaces from unstructured, dynamic, and mixing numerical topology that occurs in SPH simulations. These reference spaces enable a low-dimensional representation of the field equations while maintaining the inherent meshless qualities of SPH. Modal reference spaces are constructed by projecting snapshot data onto a reference space where low-dimensionality of field quantities can be discovered via traditional modal decomposition techniques (e.g., the proper orthogonal decomposition (POD)). Modal quantities are mapped back to the meshless SPH space via scattered data interpolation during the online predictive stage. The proposed model-order reduction framework is cast into the meshless Galerkin POD and the Adjoint Petrov-Galerkin projection model-order reduction (PMOR) formulation. The PMORs are tested on three numerical experiments: 1) the Taylor--Green vortex; 2) the lid-driven cavity; and 3) the flow past an open cavity. Results show good agreement in reconstructed and predictive velocity fields, which showcase the ability of this framework to evolve the field equations in a low-dimensional subspace on an unstructured, dynamic, and mixing numerical topology. Results also show that the pressure field is sensitive to the projection error due to the stiff weakly-compressible assumption made in the current SPH framework, but this sensitivity can be alleviated through nonlinear approximations, such as the APG approach. The proposed meshless model-order reduction framework reports up to 90,000x dimensional compression within 10% error in quantities of interest, marking a step toward drastic cost reduction in SPH simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07830v3</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven N. Rodriguez, Steven L. Brunton, Liam K. Magargal, Parisa Khodabakhshi, Justin W. Jaworski, Nicoleta A. Apetre, John C. Steuben, John G. Michopoulos, Athanasios Iliopoulos</dc:creator>
    </item>
  </channel>
</rss>
