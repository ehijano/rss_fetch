<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 01:50:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Estimating Nationwide High-Dosage Tutoring Expenditures: A Predictive Model Approach</title>
      <link>https://arxiv.org/abs/2510.24899</link>
      <description>arXiv:2510.24899v1 Announce Type: new 
Abstract: This study applies an optimized XGBoost regression model to estimate district-level expenditures on high-dosage tutoring from incomplete administrative data. The COVID-19 pandemic caused unprecedented learning loss, with K-12 students losing up to half a grade level in certain subjects. To address this, the federal government allocated \$190 billion in relief. We know from previous research that small-group tutoring, summer and after school programs, and increased support staff were all common expenditures for districts. We don't know how much was spent in each category. Using a custom scraped dataset of over 7,000 ESSER (Elementary and Secondary School Emergency Relief) plans, we model tutoring allocations as a function of district characteristics such as enrollment, total ESSER funding, urbanicity, and school count. Extending the trained model to districts that mention tutoring but omit cost information yields an estimated aggregate allocation of approximately \$2.2 billion. The model achieved an out-of-sample $R^2$=0.358, demonstrating moderate predictive accuracy given substantial reporting heterogeneity. Methodologically, this work illustrates how gradient-boosted decision trees can reconstruct large-scale fiscal patterns where structured data are sparse or missing. The framework generalizes to other domains where policy evaluation depends on recovering latent financial or behavioral variables from semi-structured text and sparse administrative sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24899v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Godfrey, Trisha Banerjee</dc:creator>
    </item>
    <item>
      <title>Productivity Beliefs and Efficiency in Science</title>
      <link>https://arxiv.org/abs/2510.24916</link>
      <description>arXiv:2510.24916v1 Announce Type: new 
Abstract: We develop a method to estimate producers' productivity beliefs when output quantities and input prices are unobservable, and we use it to evaluate the market for science. Our model of researchers' labor supply shows how their willingness to pay for inputs reveals their productivity beliefs. We estimate the model's parameters using data from a nationally representative survey of researchers and find the distribution of productivity to be very skewed. Our counterfactuals indicate that a more efficient allocation of the current budget could be worth billions of dollars. There are substantial gains from developing new ways of identifying talented scientists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24916v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Bertolotti, Kyle Myers, Wei Yang Tham</dc:creator>
    </item>
    <item>
      <title>Automation Experiments and Inequality</title>
      <link>https://arxiv.org/abs/2510.24923</link>
      <description>arXiv:2510.24923v1 Announce Type: new 
Abstract: An increasingly large number of experiments study the labor productivity effects of automation technologies such as generative algorithms. A popular question in these experiments relates to inequality: does the technology increase output more for high- or low-skill workers? The answer is often used to anticipate the distributional effects of the technology as it continues to improve. In this paper, we formalize the theoretical content of this empirical test, focusing on automation experiments as commonly designed. Worker-level output depends on a task-level production function, and workers are heterogeneous in their task-level skills. Workers perform a task themselves, or they delegate it to the automation technology. The inequality effect of improved automation depends on the interaction of two factors: ($i$) the correlation in task-level skills across workers, and ($ii$) workers' skills relative to the technology's capability. Importantly, the sign of the inequality effect is often non-monotonic -- as technologies improve, inequality may decrease then increase, or vice versa. Finally, we use data and theory to highlight cases when skills are likely to be positively or negatively correlated. The model generally suggests that the diversity of automation technologies will play an important role in the evolution of inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24923v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seth Benzell, Kyle Myers</dc:creator>
    </item>
    <item>
      <title>The Latin Monetary Union and Trade: A Closer Look</title>
      <link>https://arxiv.org/abs/2510.25487</link>
      <description>arXiv:2510.25487v1 Announce Type: new 
Abstract: This paper reexamines the effects of the Latin Monetary Union (LMU) - a 19th century agreement among several European countries to standardize their currencies through a bimetallic system based on fixed gold and silver content - on trade. Unlike previous studies, this paper adopts the latest advances in gravity modeling and a more rigorous approach to defining the control group by accounting for the diversity of currency regimes during the early years of the LMU. My findings suggest that the LMU had a positive effect on trade between its members until the early 1870s, when bimetallism was still considered a viable monetary system. These effects then faded, converging to zero. Results are robust to the inclusion of additional potential confounders, the use of various samples spanning different countries and trade data sources, and alternative methodological choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25487v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacopo Timini</dc:creator>
    </item>
    <item>
      <title>The Economics of AI Training Data: A Research Agenda</title>
      <link>https://arxiv.org/abs/2510.24990</link>
      <description>arXiv:2510.24990v1 Announce Type: cross 
Abstract: Despite data's central role in AI production, it remains the least understood input. As AI labs exhaust public data and turn to proprietary sources, with deals reaching hundreds of millions of dollars, research across computer science, economics, law, and policy has fragmented. We establish data economics as a coherent field through three contributions. First, we characterize data's distinctive properties -- nonrivalry, context dependence, and emergent rivalry through contamination -- and trace historical precedents for market formation in commodities such as oil and grain. Second, we present systematic documentation of AI training data deals from 2020 to 2025, revealing persistent market fragmentation, five distinct pricing mechanisms (from per-unit licensing to commissioning), and that most deals exclude original creators from compensation. Third, we propose a formal hierarchy of exchangeable data units (token, record, dataset, corpus, stream) and argue for data's explicit representation in production functions. Building on these foundations, we outline four open research problems foundational to data economics: measuring context-dependent value, balancing governance with privacy, estimating data's contribution to production, and designing mechanisms for heterogeneous, compositional goods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24990v1</guid>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hamidah Oderinwale, Anna Kazlauskas</dc:creator>
    </item>
    <item>
      <title>Religious Competition, Cultural Change, and Domestic Violence: Evidence from Colombia</title>
      <link>https://arxiv.org/abs/2311.10831</link>
      <description>arXiv:2311.10831v2 Announce Type: replace 
Abstract: We study how religious competition-defined as the entry of a religious organization with innovative worship practices into a predominantly Catholic municipality-affects domestic violence. Using municipality-level data from Colombia and a two-way fixed effects design, we find that the arrival of the first non-Catholic church leads to a significant reduction in reported cases of domestic violence. We argue that religious competition incentivizes churches to adopt and diffuse norms and practices that more effectively discourage such violence. Effects are largest in municipalities with smaller, younger, and more homogeneous populations-contexts that facilitate both intense competition and norm diffusion. Consistent with this mechanism, areas with more new non-Catholic churches exhibit greater rejection of domestic violence-particularly among the religiously observant-and higher female labor force participation. These findings contribute to the literature on the cultural determinants of domestic violence by identifying religious competition as a catalyst for cultural change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10831v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hector Galindo-Silva, Guy Tchuente</dc:creator>
    </item>
    <item>
      <title>Minimalist Market Design: A Framework for Economists with Policy Aspirations</title>
      <link>https://arxiv.org/abs/2401.00307</link>
      <description>arXiv:2401.00307v4 Announce Type: replace 
Abstract: Minimalist market design is an economic design framework developed from the perspective of an outsider -- one seeking to improve real institutions without a commission or official mandate. It offers a structured, "minimally invasive" method for reforming institutions from within: identify their mission as understood by stakeholders, diagnose the root causes of failure, and refine only those elements that compromise that mission. By fixing what is broken and leaving the rest intact, the framework respects the tacit knowledge embedded in long-standing institutions, minimizes unintended consequences, and secures legitimacy that facilitates adoption.
  Such targeted interventions often call for novel, use-inspired theory tailored to the institutional context. In this way, minimalist market design advances both theory and practice through a reciprocal process fostering collaboration across disciplines and between academic research and real-world practice.
  Tracing the framework's evolution over twenty-five years of intertwined progress in theory and real-world implementation across a range of matching market applications -- including housing allocation, school choice, living-donor organ exchange for kidney and liver, military branch assignment in the U.S. Army, the allocation of vaccines and therapies during the COVID-19 pandemic, and the allocation of public jobs and college seats under India's reservation system -- this monograph reveals a consistent "less is more" ethos, showing how restrained, precisely targeted reforms can yield substantial policy improvements while advancing fundamental knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00307v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tayfun S\"onmez</dc:creator>
    </item>
    <item>
      <title>Solving Models of Economic Dynamics with Ridgeless Kernel Regressions</title>
      <link>https://arxiv.org/abs/2406.01898</link>
      <description>arXiv:2406.01898v4 Announce Type: replace 
Abstract: This paper proposes a ridgeless kernel method for solving infinite-horizon, deterministic, continuous-time models in economic dynamics, formulated as systems of differential-algebraic equations with asymptotic boundary conditions (e.g., transversality). Traditional shooting methods enforce the asymptotic boundary conditions by targeting a known steady state -- which is numerically unstable, hard to tune, and unable to address cases with steady-state multiplicity. Instead, our approach solves the underdetermined problem without imposing the asymptotic boundary condition, using regularization to select the unique solution fulfilling transversality among admissible trajectories. In particular, ridgeless kernel methods recover this path by selecting the minimum norm solution, coinciding with the non-explosive trajectory. We provide theoretical guarantees showing that kernel solutions satisfy asymptotic boundary conditions without imposing them directly, and we establish a consistency result ensuring convergence within the solution concept of differential-algebraic equations. Finally, we illustrate the method in canonical models and demonstrate its ability to handle problems with multiple steady states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01898v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Ebrahimi Kahou, Jesse Perla, Geoff Pleiss</dc:creator>
    </item>
    <item>
      <title>What Work is AI Actually Doing? Uncovering the Drivers of Generative AI Adoption</title>
      <link>https://arxiv.org/abs/2510.23669</link>
      <description>arXiv:2510.23669v2 Announce Type: replace 
Abstract: Purpose: The rapid integration of artificial intelligence (AI) systems like ChatGPT, Claude AI, etc., has a deep impact on how work is done. Predicting how AI will reshape work requires understanding not just its capabilities, but how it is actually being adopted. This study investigates which intrinsic task characteristics drive users' decisions to delegate work to AI systems. Methodology: This study utilizes the Anthropic Economic Index dataset of four million Claude AI interactions mapped to O*NET tasks. We systematically scored each task across seven key dimensions: Routine, Cognitive, Social Intelligence, Creativity, Domain Knowledge, Complexity, and Decision Making using 35 parameters. We then employed multivariate techniques to identify latent task archetypes and analyzed their relationship with AI usage. Findings: Tasks requiring high creativity, complexity, and cognitive demand, but low routineness, attracted the most AI engagement. Furthermore, we identified three task archetypes: Dynamic Problem Solving, Procedural &amp; Analytical Work, and Standardized Operational Tasks, demonstrating that AI applicability is best predicted by a combination of task characteristics, over individual factors. Our analysis revealed highly concentrated AI usage patterns, with just 5% of tasks accounting for 59% of all interactions. Originality: This research provides the first systematic evidence linking real-world generative AI usage to a comprehensive, multi-dimensional framework of intrinsic task characteristics. It introduces a data-driven classification of work archetypes that offers a new framework for analyzing the emerging human-AI division of labor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23669v2</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peeyush Agarwal, Harsh Agarwal, Akshat Rana</dc:creator>
    </item>
  </channel>
</rss>
