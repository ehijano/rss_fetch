<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Oct 2025 01:46:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Is Zadeh's Least-Entered Pivot Rule Exponential?</title>
      <link>https://arxiv.org/abs/2510.16055</link>
      <description>arXiv:2510.16055v1 Announce Type: new 
Abstract: In 2011, Friedmann [F 7] claimed to have proved that pathological linear programs existed for which the Simplex method using Zadeh's least-entered rule [Z 14] would take an exponential number of pivots. In 2019, Disser and Hopp [DH 5] argued that there were errors in Friedmann's 2011 construction. In 2020, Disser, Friedmann, and Hopp [DFH 3,4] again contended that the least-entered rule was exponential. We show that their arguments contain multiple flaws. In other words, the worst-case behavior of the least-entered rule has not been established. Neither [F 7] nor [DFH 3,4] provides pathological linear programs that can be tested. Instead, the authors contend that their pathological linear programs are of the form (P) as shown on page 12 of [DFH 3]. The authors contend that the constraints of (P) ensure that the probability of entering a vertex u is equal to the probability of exiting u. In fact, we note that the authors' constraints (P) are flawed in at least three ways: a) they require the probability of exiting u to exceed the probability of entering u, b) they require the probability of exiting some nodes to exceed 1, and c) they overlook flows from decision nodes to decision nodes. At my request, in August of 2025, Disser, Friedmann, and Hopp provided me with their first ten purportedly pathological LPs and the graph of their first purportedly pathological Markov Decision Process (MDP1). It is shown that: a) their first two pathological LPs are infeasible if the variables are supposed to be probabilities, as the authors contend, and b) their first purportedly pathological LP does not match up with their first purportedly pathological MDP. In other words, the authors have not come close to providing counterexamples to the least-entered rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16055v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Norman Zadeh</dc:creator>
    </item>
    <item>
      <title>Near-linear time subhypergraph counting in bounded degeneracy hypergraphs</title>
      <link>https://arxiv.org/abs/2510.16330</link>
      <description>arXiv:2510.16330v1 Announce Type: new 
Abstract: Counting small patterns in a large dataset is a fundamental algorithmic task. The most common version of this task is subgraph/homomorphism counting, wherein we count the number of occurrences of a small pattern graph $H$ in an input graph $G$. The study of this problem is a field in and of itself. Recently, both in theory and practice, there has been an interest in \emph{hypergraph} algorithms, where $G = (V,E)$ is a hypergraph. One can view $G$ as a set system where hyperedges are subsets of the universe $V$.
  Counting patterns $H$ in hypergraphs is less studied, although there are many applications in network science and database algorithms. Inspired by advances in the graph literature, we study when linear time algorithms are possible.
  We focus on input hypergraphs $G$ that have bounded \emph{degeneracy}, a well-studied concept for graph algorithms. We give a spectrum of definitions for hypergraph degeneracy that cover all existing notions. For each such definition, we give a precise characterization of the patterns $H$ that can be counted in (near) linear time. Specifically, we discover a set of ``obstruction patterns". If $H$ does not contain an obstruction, then the number of $H$-subhypergraphs can be counted exactly in $O(n\log n)$ time (where $n$ is the number of vertices in $G$). If $H$ contains an obstruction, then (assuming hypergraph variants of fine-grained complexity conjectures), there is a constant $\gamma &gt; 0$, such that there is no $o(n^{1+\gamma})$ time algorithm for counting $H$-subhypergraphs. These sets of obstructions can be defined for all notions of hypergraph degeneracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16330v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Paul-Pena, C. Seshadhri</dc:creator>
    </item>
    <item>
      <title>A (Very) Nearly Optimal Sketch for $k$-Edge Connectivity Certificates</title>
      <link>https://arxiv.org/abs/2510.16336</link>
      <description>arXiv:2510.16336v1 Announce Type: new 
Abstract: In this note, we present a simple algorithm for computing a \emph{$k$-connectivity certificate} in dynamic graph streams. Our algorithm uses $O(n \log^2 n \cdot \max\{k, \log n \log k\})$ bits of space which improves upon the $O(kn \log^3 n)$-space algorithm of Ahn, Guha, and McGregor (SODA'12). For the values of $k$ that are truly sublinear, our space usage \emph{very nearly} matches the known lower bound $\Omega(n \log^2 n \cdot \max\{k, \log n\})$ established by Nelson and Yu (SODA'19; implicit) and Robinson (DISC'24). In particular, our algorithm fully settles the space complexity at $\Theta(kn \log^2{n})$ for $k = \Omega(\log n \log \log n)$, and bridges the gap down to only a doubly-logarithmic factor of $O(\log \log n)$ for a smaller range of $k = o(\log n \log \log n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16336v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pachara Sawettamalya, Huacheng Yu</dc:creator>
    </item>
    <item>
      <title>Truly Subquadratic Time Algorithms for Diameter and Related Problems in Graphs of Bounded VC-dimension</title>
      <link>https://arxiv.org/abs/2510.16346</link>
      <description>arXiv:2510.16346v1 Announce Type: new 
Abstract: We give the first truly subquadratic time algorithm, with $O^*(n^{2-1/18})$ running time, for computing the diameter of an $n$-vertex unit-disk graph, resolving a central open problem in the literature. Our result is obtained as an instance of a general framework, applicable to different graph families and distance problems. Surprisingly, our framework completely bypasses sublinear separators (or $r$-divisions) which were used in all previous algorithms. Instead, we use low-diameter decompositions in their most elementary form. We also exploit bounded VC-dimension of set systems associated with the input graph, as well as new ideas on geometric data structures. Among the numerous applications of the general framework, we obtain:
  1. An $\tilde{O}(mn^{1-1/(2d)})$ time algorithm for computing the diameter of $m$-edge sparse unweighted graphs with constant VC-dimension $d$. The previously known algorithms by Ducoffe, Habib, and Viennot [SODA 2019] and Duraj, Konieczny, and Pot\c{e}pa [ESA 2024] are truly subquadratic only when the diameter is a small polynomial. Our result thus generalizes truly subquadratic time algorithms known for planar and minor-free graphs (in fact, it slightly improves the previous time bound for minor-free graphs).
  2. An $\tilde{O}(n^{2-1/12})$ time algorithm for computing the diameter of intersection graphs of axis-aligned squares with arbitrary size. The best-known algorithm by Duraj, Konieczny, and Pot\c{e}pa [ESA 2024] only works for unit squares and is only truly subquadratic in the low-diameter regime.
  3. The first algorithms with truly subquadratic complexity for other distance-related problems, including all-vertex eccentricities, Wiener index, and exact distance oracles. (... truncated to meet the arXiv abstract requirement.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16346v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Timothy M. Chan, Hsien-Chih Chang, Jie Gao, S\'andor Kisfaludi-Bak, Hung Le, Da Wei Zheng</dc:creator>
    </item>
    <item>
      <title>Tight Pair Query Lower Bounds for Matching and Earth Mover's Distance</title>
      <link>https://arxiv.org/abs/2510.16351</link>
      <description>arXiv:2510.16351v1 Announce Type: new 
Abstract: How many adjacency matrix queries (also known as pair queries) are required to estimate the size of a maximum matching in an $n$-vertex graph $G$? We study this fundamental question in this paper.
  On the upper bound side, an algorithm of Bhattacharya, Kiss, and Saranurak [FOCS'23] gives an estimate that is within $\epsilon n$ of the right bound with $n^{2-\Omega_\epsilon(1)}$ queries, which is subquadratic in $n$ (and thus sublinear in the matrix size) for any fixed $\epsilon &gt; 0$. On the lower bound side, while there has been a lot of progress in the adjacency list model, no non-trivial lower bound has been established for algorithms with adjacency matrix query access. In particular, the only known lower bound is a folklore bound of $\Omega(n)$, leaving a huge gap.
  In this paper, we present the first superlinear in $n$ lower bound for this problem. In fact, we close the gap mentioned above entirely by showing that the algorithm of [BKS'23] is optimal. Formally, we prove that for any fixed $\delta &gt; 0$, there is a fixed $\epsilon &gt; 0$ such that an estimate that is within $\epsilon n$ of the true bound requires $\Omega(n^{2-\delta})$ adjacency matrix queries.
  Our lower bound also has strong implications for estimating the earth mover's distance between distributions. For this problem, Beretta and Rubinstein [STOC'24] gave an $n^{2-\Omega_\epsilon(1)}$ time algorithm that obtains an additive $\epsilon$-approximation and works for any distance function. Whether this can be improved generally, or even for metric spaces, had remained open. Our lower bound rules out the possibility of any improvements over this bound, even under the strong assumption that the underlying distances are in a (1, 2)-metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16351v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Azarmehr, Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein</dc:creator>
    </item>
    <item>
      <title>Online computation of normalized substring complexity</title>
      <link>https://arxiv.org/abs/2510.16454</link>
      <description>arXiv:2510.16454v1 Announce Type: new 
Abstract: The normalized substring complexity $\delta$ of a string is defined as $\max_k \{c[k]/k\}$, where $c[k]$ is the number of \textit{distinct} substrings of length $k$. This simply defined measure has recently attracted attention due to its established relationship to popular string compression algorithms. We consider the problem of computing $\delta$ online, when the string is provided from a stream. We present two algorithms solving the problem: one working in $O(\log n)$ amortized time per character, and the other in $O(\log^3 n)$ worst-case time per character. To our knowledge, this is the first polylog-time online solution to this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16454v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory Kucherov, Yakov Nekrich</dc:creator>
    </item>
    <item>
      <title>Trading Prophets with Initial Capital</title>
      <link>https://arxiv.org/abs/2510.16516</link>
      <description>arXiv:2510.16516v1 Announce Type: new 
Abstract: Correa et al. [EC' 2023] introduced the following trading prophets problem. A trader observes a sequence of stochastic prices for a stock, each drawn from a known distribution, and at each time must decide whether to buy or sell. Unfortunately, they observed that in this setting it is impossible to compete with a prophet who knows all future stock prices.
  In this paper, we explore the trading prophets problem when we are given initial capital with which to start trading. We show that initial capital is enough to bypass the impossibility result and obtain a competitive ratio of $3$ with respect to a prophet who knows all future prices (and who also starts with capital), and we show that this competitive ratio is best possible. We further study a more realistic model in which the trader must pay multiplicative and/or additive transaction costs for trading which model dynamics such as bid-ask spreads and broker fees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16516v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yossi Azar, Niv Buchbinder, Roie Levin, Or Vardi</dc:creator>
    </item>
    <item>
      <title>Robust Dynamic Staffing with Predictions</title>
      <link>https://arxiv.org/abs/2510.16663</link>
      <description>arXiv:2510.16663v1 Announce Type: new 
Abstract: We consider a natural dynamic staffing problem in which a decision-maker sequentially hires workers over a finite horizon to meet an unknown demand revealed at the end. Predictions about demand arrive over time and become increasingly accurate, while worker availability decreases. This creates a fundamental trade-off between hiring early to avoid understaffing (when workers are more available but forecasts are less reliable) and hiring late to avoid overstaffing (when forecasts are more accurate but availability is lower). This problem is motivated by last-mile delivery operations, where companies such as Amazon rely on gig-economy workers whose availability declines closer to the operating day.
  To address practical limitations of Bayesian models (in particular, to remain agnostic to the underlying forecasting method), we study this problem under adversarial predictions. In this model, sequential predictions are adversarially chosen uncertainty intervals that (approximately) contain the true demand. The objective is to minimize worst-case staffing imbalance cost. Our main result is a simple and computationally efficient online algorithm that is minimax optimal. We first characterize the minimax cost against a restricted adversary via a polynomial-size linear program, then show how to emulate this solution in the general case. While our base model focuses on a single demand, we extend the framework to multiple demands (with egalitarian/utilitarian objectives), to settings with costly reversals of hiring decisions, and to inconsistent prediction intervals. We also introduce a practical "re-solving" variant of our algorithm, which we prove is also minimax optimal. Finally we conduct numerical experiments showing that our algorithms outperform Bayesian heuristics in both cost and speed, and are competitive with (approximate or exact) Bayesian-optimal policies when those can be computed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16663v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiding Feng, Vahideh Manshadi, Rad Niazadeh, Saba Neyshabouri</dc:creator>
    </item>
    <item>
      <title>An Exact Algorithm for the Unanimous Vote Problem</title>
      <link>https://arxiv.org/abs/2510.16678</link>
      <description>arXiv:2510.16678v1 Announce Type: new 
Abstract: Consider $n$ independent, biased coins, each with a known probability of heads. Presented with an ordering of these coins, flip (i.e., toss) each coin once, in that order, until we have observed both a *head* and a *tail*, or flipped all coins. The Unanimous Vote problem asks us to find the ordering that minimizes the expected number of flips. Gkenosis et al. [arXiv:1806.10660] gave a polynomial-time $\phi$-approximation algorithm for this problem, where $\phi \approx 1.618$ is the golden ratio. They left open whether the problem was NP-hard. We answer this question by giving an exact algorithm that runs in time $O(n \log n)$. The Unanimous Vote problem is an instance of the more general Stochastic Boolean Function Evaluation problem: it thus becomes one of the only such problems known to be solvable in polynomial time. Our proof uses simple interchange arguments to show that the optimal ordering must be close to the ordering produced by a natural greedy algorithm. Beyond our main result, we compare the optimal ordering with the best adaptive strategy, proving a tight adaptivity gap of $1.2\pm o(1)$ for the Unanimous Vote problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16678v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feyza Duman Keles, Lisa Hellerstein, Kunal Marwaha, Christopher Musco, Xinchen Yang</dc:creator>
    </item>
    <item>
      <title>All-Pairs Minimum Cut using $\tilde{O}(n^{7/4})$ Cut Queries</title>
      <link>https://arxiv.org/abs/2510.16741</link>
      <description>arXiv:2510.16741v1 Announce Type: new 
Abstract: We present the first non-trivial algorithm for the all-pairs minimum cut problem in the cut-query model. Given cut-query access to an unweighted graph $G=(V,E)$ with $n$ vertices, our randomized algorithm constructs a Gomory-Hu tree of $G$, and thus solves the all-pairs minimum cut problem, using $\tilde{O}(n^{7/4})$ cut queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16741v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yotam Kenneth-Mordoch, Robert Krauthgamer</dc:creator>
    </item>
    <item>
      <title>Combinatorial Maximum Flow via Weighted Push-Relabel on Shortcut Graphs</title>
      <link>https://arxiv.org/abs/2510.17182</link>
      <description>arXiv:2510.17182v1 Announce Type: new 
Abstract: We give a combinatorial algorithm for computing exact maximum flows in directed graphs with $n$ vertices and edge capacities from $\{1,\dots,U\}$ in $\tilde{O}(n^{2}\log U)$ time, which is near-optimal on dense graphs. This shaves an $n^{o(1)}$ factor from the recent result of [Bernstein-Blikstad-Saranurak-Tu FOCS'24] and, more importantly, greatly simplifies their algorithm. We believe that ours is by a significant margin the simplest of all algorithms that go beyond $\tilde{O}(m\sqrt{n})$ time in general graphs. To highlight this relative simplicity, we provide a full implementation of the algorithm in C++.
  The only randomized component of our work is the cut-matching game. Via existing tools, we show how to derandomize it for vertex-capacitated max flow and obtain a deterministic $\tilde{O}(n^2)$ time algorithm. This marks the first deterministic near-linear time algorithm for this problem (or even for the special case of bipartite matching) in any density regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17182v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Bernstein, Joakim Blikstad, Jason Li, Thatchaphol Saranurak, Ta-Wei Tu</dc:creator>
    </item>
    <item>
      <title>Finding 4-Additive Spanners: Faster, Stronger, and Simpler</title>
      <link>https://arxiv.org/abs/2510.17262</link>
      <description>arXiv:2510.17262v1 Announce Type: new 
Abstract: Additive spanners are fundamental graph structures with wide applications in network design, graph sparsification, and distance approximation. In particular, a $4$-additive spanner is a subgraph that preserves all pairwise distances up to an additive error of $4$. In this paper, we present a new deterministic algorithm for constructing $4$-additive spanners that matches the best known edge bound of $\tilde{O}(n^{7/5})$ (up to polylogarithmic factors), while improving the running time to $\tilde{O}(\min\{mn^{3/5}, n^{11/5}\})$, compared to the previous $\tilde{O}(mn^{3/5})$ randomized construction. Our algorithm is not only faster in the dense regime but also fully deterministic, conceptually simpler, and easier to implement and analyze.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17262v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuhan Qi</dc:creator>
    </item>
    <item>
      <title>On Algorithmic Meta-Theorems for Solution Discovery: Tractability and Barriers</title>
      <link>https://arxiv.org/abs/2510.17344</link>
      <description>arXiv:2510.17344v1 Announce Type: new 
Abstract: Solution discovery asks whether a given (infeasible) starting configuration to a problem can be transformed into a feasible solution using a limited number of transformation steps. This paper investigates meta-theorems for solution discovery for graph problems definable in monadic second-order logic (MSO$_1$ and MSO$_2$) and first-order logic (FO) where the transformation step is to slide a token to an adjacent vertex, focusing on parameterized complexity and structural graph parameters that do not involve the transformation budget $b$. We present both positive and negative results. On the algorithmic side, we prove that MSO$_2$-Discovery is in XP when parameterized by treewidth and that MSO$_1$-Discovery is fixed-parameter tractable when parameterized by neighborhood diversity. On the hardness side, we establish that FO-Discovery is W[1]-hard when parameterized by modulator to stars, modulator to paths, as well as twin cover, numbers. Additionally, we prove that MSO$_1$-Discovery is W[1]-hard when parameterized by bandwidth. These results complement the straightforward observation that solution discovery for the studied problems is fixed-parameter tractable when the budget $b$ is included in the parameter (in particular, parameterized by cliquewidth$+b$, where the cliquewidth of a graph is at most any of the studied parameters), and provide a near-complete (fixed-parameter tractability) meta-theorems investigation for solution discovery problems for MSO- and FO-definable graph problems and structural parameters larger than cliquewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17344v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Bousquet, Amer E. Mouawad, Stephanie Maaz, Naomi Nishimura, Sebastian Siebertz</dc:creator>
    </item>
    <item>
      <title>Approximating Asymmetric A Priori TSP beyond the Adaptivity Gap</title>
      <link>https://arxiv.org/abs/2510.17595</link>
      <description>arXiv:2510.17595v1 Announce Type: new 
Abstract: In Asymmetric A Priori TSP (with independent activation probabilities) we are given an instance of the Asymmetric Traveling Salesman Problem together with an activation probability for each vertex. The task is to compute a tour that minimizes the expected length after short-cutting to the randomly sampled set of active vertices.
  We prove a polynomial lower bound on the adaptivity gap for Asymmetric A Priori TSP. Moreover, we show that a poly-logarithmic approximation ratio, and hence an approximation ratio below the adaptivity gap, can be achieved by a randomized algorithm with quasi-polynomial running time.
  To achieve this, we provide a series of polynomial-time reductions. First we reduce to a novel generalization of the Asymmetric Traveling Salesman Problem, called Hop-ATSP. Next, we use directed low-diameter decompositions to obtain structured instances, for which we then provide a reduction to a covering problem. Eventually, we obtain a polynomial-time reduction of Asymmetric A Priori TSP to a problem of finding a path in an acyclic digraph minimizing a particular objective function, for which we give an O(log n)-approximation algorithm in quasi-polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17595v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Christalla, Luise Puhlmann, Vera Traub</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Property Testers for Pattern Matching</title>
      <link>https://arxiv.org/abs/2510.17645</link>
      <description>arXiv:2510.17645v1 Announce Type: new 
Abstract: The classic exact pattern matching problem, given two strings -- a pattern $P$ of length $m$ and a text $T$ of length $n$ -- asks whether $P$ occurs as a substring of $T$. A property tester for the problem needs to distinguish (with high probability) the following two cases for some threshold $k$: the YES case, where $P$ occurs as a substring of $T$, and the NO case, where $P$ has Hamming distance greater than $k$ from every substring of $T$, that is, $P$ has no $k$-mismatch occurrence in $T$.
  In this work, we provide adaptive and non-adaptive property testers for the exact pattern matching problem, jointly covering the whole spectrum of parameters. We further establish unconditional lower bounds demonstrating that the time and query complexities of our algorithms are optimal, up to $\mathrm{polylog}\, n$ factors hidden within the $\tilde O(\cdot)$ notation below.
  In the most studied regime of $n=m+\Theta(m)$, our non-adaptive property tester has the time complexity of $\tilde O(n/\sqrt{k})$, and a matching lower bound remains valid for the query complexity of adaptive algorithms. This improves both upon a folklore solution that attains the optimal query complexity but requires $\Omega(n)$ time, and upon the only previously known sublinear-time property tester, by Chan, Golan, Kociumaka, Kopelowitz, and Porat [STOC 2020], with time complexity $\tilde O(n/\sqrt[3]{k})$. The aforementioned results remain valid for $n=m+\Omega(m)$, where our optimal running time $\tilde O(\sqrt{nm/k}+n/k)$ improves upon the previously best time complexity of $\tilde O(\sqrt[3]{n^2m/k}+n/k)$. In the regime of $n=m+o(m)$, which has not been targeted in any previous work, we establish a surprising separation between adaptive and non-adaptive algorithms, whose optimal time and query complexities are $\tilde O(\sqrt{(n-m+1)m/k}+n/k)$ and $\tilde O(\min(n\sqrt{n-m+1}/k,\sqrt{nm/k}+n/k))$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17645v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ce Jin, Tomasz Kociumaka</dc:creator>
    </item>
    <item>
      <title>The Marked Edge Walk: A Novel MCMC Algorithm for Sampling of Graph Partitions</title>
      <link>https://arxiv.org/abs/2510.17714</link>
      <description>arXiv:2510.17714v1 Announce Type: new 
Abstract: Novel Markov Chain Monte Carlo (MCMC) methods have enabled the generation of large ensembles of redistricting plans through graph partitioning. However, existing algorithms such as Reversible Recombination (RevReCom) and Metropolized Forest Recombination (MFR) are constrained to sampling from distributions related to spanning trees. We introduce the marked edge walk (MEW), a novel MCMC algorithm for sampling from the space of graph partitions under a tunable distribution. The walk operates on the space of spanning trees with marked edges, allowing for calculable transition probabilities for use in the Metropolis-Hastings algorithm. Empirical results on real-world dual graphs show convergence under target distributions unrelated to spanning trees. For this reason, MEW represents an advancement in flexible ensemble generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17714v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atticus McWhorter, Daryl DeFord</dc:creator>
    </item>
    <item>
      <title>Generalized Flow in Nearly-linear Time on Moderately Dense Graphs</title>
      <link>https://arxiv.org/abs/2510.17740</link>
      <description>arXiv:2510.17740v1 Announce Type: new 
Abstract: In this paper we consider generalized flow problems where there is an $m$-edge $n$-node directed graph $G = (V,E)$ and each edge $e \in E$ has a loss factor $\gamma_e &gt;0$ governing whether the flow is increased or decreased as it crosses edge $e$. We provide a randomized $\tilde{O}( (m + n^{1.5}) \cdot \mathrm{polylog}(\frac{W}{\delta}))$ time algorithm for solving the generalized maximum flow and generalized minimum cost flow problems in this setting where $\delta$ is the target accuracy and $W$ is the maximum of all costs, capacities, and loss factors and their inverses. This improves upon the previous state-of-the-art $\tilde{O}(m \sqrt{n} \cdot \log^2(\frac{W}{\delta}) )$ time algorithm, obtained by combining the algorithm of [Daitch-Spielman, 2008] with techniques from [Lee-Sidford, 2014]. To obtain this result we provide new dynamic data structures and spectral results regarding the matrices associated to generalized flows and apply them through the interior point method framework of [Brand-Lee-Liu-Saranurak-Sidford-Song-Wang, 2021].</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17740v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunhua Jiang, Michael Kapralov, Lawrence Li, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Pattern Matching under Weighted Edit Distance</title>
      <link>https://arxiv.org/abs/2510.17752</link>
      <description>arXiv:2510.17752v1 Announce Type: new 
Abstract: In Pattern Matching with Weighted Edits (PMWED), we are given a pattern $P$ of length $m$, a text $T$ of length $n$, a positive threshold $k$, and oracle access to a weight function that specifies the costs of edits (depending on the involved characters, and normalized so that the cost of each edit is at least $1$). The goal is to compute the starting positions of all fragments of $T$ that can be obtained from $P$ with edits of total cost at most $k$. PMWED captures typical real-world applications more accurately than its unweighted variant (PMED), where all edits have unit costs.
  We obtain three main results:
  (a) a conceptually simple $\tilde{O}(nk)$-time algorithm for PMWED, very different from that of Landau and Vishkin for PMED;
  (b) a significantly more complicated $\tilde{O}(n+k^{3.5} \cdot W^4\cdot n/m)$-time algorithm for PMWED under the assumption that the weight function is a metric with integer values between $0$ and $W$; and
  (c) an $\tilde{O}(n+k^4 \cdot n/m)$-time algorithm for PMWED for the case of arbitrary weights.
  In the setting of metrics with small integer values, we nearly match the state of the art for PMED where $W=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17752v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panagiotis Charalampopoulos, Tomasz Kociumaka, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Dynamic Dyck and Tree Edit Distance: Decompositions and Reductions to String Edit Distance</title>
      <link>https://arxiv.org/abs/2510.17799</link>
      <description>arXiv:2510.17799v1 Announce Type: new 
Abstract: We present the first dynamic algorithms for Dyck and tree edit distances with subpolynomial update times. Dyck edit distance measures how far a parenthesis string is from a well-parenthesized expression, while tree edit distance quantifies the minimum number of node insertions, deletions, and substitutions required to transform one rooted, ordered, labeled tree into another. Despite extensive study, no prior work has addressed efficient dynamic algorithms for these problems, which naturally arise in evolving structured data such as LaTeX documents, JSON or XML files, and RNA secondary structures.
  Our main contribution is a set of reductions and decompositions that transform Dyck and tree edit distance instances into efficiently maintainable string edit distance instances, which can be approximated within a $n^{o(1)}$ factor in $n^{o(1)}$ update time. For Dyck edit distance, our reduction incurs only polylogarithmic overheads in approximation and update time, yielding an $n^{o(1)}$-approximation with $n^{o(1)}$ updates. For tree edit distance, we introduce a new static reduction that improves the best-known approximation ratio from $n^{3/4}$ to $\tilde{O}(\sqrt{n})$ and removes the restriction to constant-degree trees. Extending this reduction dynamically achieves $n^{1/2+o(1)}$ approximation with $n^{o(1)}$ update time.
  A key component is a dynamic maintenance algorithm for history-independent heavy-light decompositions, of independent interest. We also provide a novel static and dynamic decomposition achieving an $O(k \log n)$-approximation when the tree edit distance is at most $k$. Combined with the trivial bound $k \le n$, this yields a dynamic deterministic $O(\sqrt{n \log n})$-approximation. In the static setting, our algorithm runs in near-linear time; dynamically, it requires only polylogarithmic updates, improving on prior linear-time static $O(\sqrt{n})$-approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17799v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Debarati Das, Jacob Gilbert, MohammadTaghi Hajiaghayi, Tomasz Kociumaka, Barna Saha</dc:creator>
    </item>
    <item>
      <title>A Note on Algorithms for Computing $p_n$</title>
      <link>https://arxiv.org/abs/2510.16285</link>
      <description>arXiv:2510.16285v1 Announce Type: cross 
Abstract: We analyze algorithms for computing the $n$th prime $p_n$ and establish asymptotic bounds for several approaches. Using existing results on the complexity of evaluating the prime-counting function $\pi(x)$, we show that the binary search approach computes $p_n$ in $O(\sqrt{n} \, (\log n)^4)$ time. Assuming the Riemann Hypothesis and Cram\'er's conjecture, we construct a tighter interval around li$^{-1}(n)$, leading to an improved sieve-based algorithm running in $O(\sqrt{n} \, (\log ^{7/2} n) \, \log \log n)$ time. This improvement, though conditional, suggests that further refinements to prime gap estimates may yield provably faster methods for computing primes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16285v1</guid>
      <category>math.NT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ansh Aggarwal</dc:creator>
    </item>
    <item>
      <title>Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods</title>
      <link>https://arxiv.org/abs/2510.16609</link>
      <description>arXiv:2510.16609v1 Announce Type: cross 
Abstract: Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool use, critically depends on an interplay between a model's parametric knowledge and externally retrieved information. However, the theoretical underpinnings of this relationship remain poorly understood. Specifically, it is not clear how much pre-training knowledge is required to answer queries with a small number of augmentation steps, which is a desirable property in practice. To address this question, we formulate multi-step reasoning as an $s$-$t$ connectivity problem on a knowledge graph. We represent a model's pre-training parametric knowledge as a partial, potentially noisy subgraph. We view augmentation as querying an oracle for true edges that augment the model's knowledge. Then, we characterize the necessary and sufficient number of augmentation steps for the model to generate an accurate answer given partial prior knowledge. One key result shows a phase transition: if the prior knowledge graph over $n$ vertices is disconnected into small components, then finding a path via augmentation is inefficient and requires $\Omega(\sqrt{n})$ queries. On the other hand, once the density of correct knowledge surpasses a threshold, forming a giant component, we can find paths with an expected constant number of queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16609v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avrim Blum, Daniel Hsu, Cyrus Rashtchian, Donya Saless</dc:creator>
    </item>
    <item>
      <title>Opinion Maximization in Social Networks by Modifying Internal Opinions</title>
      <link>https://arxiv.org/abs/2510.17226</link>
      <description>arXiv:2510.17226v1 Announce Type: cross 
Abstract: Public opinion governance in social networks is critical for public health campaigns, political elections, and commercial marketing. In this paper, we addresse the problem of maximizing overall opinion in social networks by strategically modifying the internal opinions of key nodes. Traditional matrix inversion methods suffer from prohibitively high computational costs, prompting us to propose two efficient sampling-based algorithms. Furthermore, we develop a deterministic asynchronous algorithm that exactly identifies the optimal set of nodes through asynchronous update operations and progressive refinement, ensuring both efficiency and precision. Extensive experiments on real-world datasets demonstrate that our methods outperform baseline approaches. Notably, our asynchronous algorithm delivers exceptional efficiency and accuracy across all scenarios, even in networks with tens of millions of nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17226v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gengyu Wang, Runze Zhang, Zhongzhi Zhang</dc:creator>
    </item>
    <item>
      <title>Unifying the Landscape of Super-Logarithmic Dynamic Cell-Probe Lower Bounds</title>
      <link>https://arxiv.org/abs/2510.17717</link>
      <description>arXiv:2510.17717v1 Announce Type: cross 
Abstract: We prove a general translation theorem for converting one-way communication lower bounds over a product distribution to dynamic cell-probe lower bounds.
  Specifically, we consider a class of problems considered in [Pat10] where:
  1. $S_1, \ldots, S_m \in \{0, 1\}^n$ are given and publicly known.
  2. $T \in \{0, 1\}^n$ is a sequence of updates, each taking $t_u$ time.
  3. For a given $Q \in [m]$, we must output $f(S_Q, T)$ in $t_q$ time. Our main result shows that for a "hard" function $f$, for which it is difficult to obtain a non-trivial advantage over random guessing with one-way communication under some product distribution over $S_Q$ and $T$ (for example, a uniform distribution), then the above explicit dynamic cell-probe problem must have $\max \{ t_u, t_q \} \geq \tilde{\Omega}(\log^{3/2}(n))$ if $m = \Omega(n^{0.99})$. This result extends and unifies the super-logarithmic dynamic data structure lower bounds from [LWY20] and [LY25] into a more general framework.
  From a technical perspective, our approach merges the cell-sampling and chronogram techniques developed in [LWY20] and [LY25] with the new static data structure lower bound methods from [KW20] and [Ko25], thereby merging all known state-of-the-art cell-probe lower-bound techniques into one.
  As a direct consequence of our method, we establish a super-logarithmic lower bound against the Multiphase Problem [Pat10] for the case where the data structure outputs the Inner Product (mod 2) of $S_Q$ and $T$. We suspect further applications of this general method towards showing super-logarithmic dynamic cell-probe lower bounds. We list some example applications of our general method, including a novel technique for a one-way communication lower bound against small-advantage protocols for a product distribution using average min-entropy, which could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17717v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young Kun Ko</dc:creator>
    </item>
    <item>
      <title>GIST: Greedy Independent Set Thresholding for Max-Min Diversification with Submodular Utility</title>
      <link>https://arxiv.org/abs/2405.18754</link>
      <description>arXiv:2405.18754v3 Announce Type: replace 
Abstract: This work studies a novel subset selection problem called max-min diversification with monotone submodular utility ($\textsf{MDMS}$), which has a wide range of applications in machine learning, e.g., data sampling and feature selection. Given a set of points in a metric space, the goal of $\textsf{MDMS}$ is to maximize $f(S) = g(S) + \lambda \cdot \texttt{div}(S)$ subject to a cardinality constraint $|S| \le k$, where $g(S)$ is a monotone submodular function and $\texttt{div}(S) = \min_{u,v \in S : u \ne v} \text{dist}(u,v)$ is the max-min diversity objective. We propose the $\texttt{GIST}$ algorithm, which gives a $\frac{1}{2}$-approximation guarantee for $\textsf{MDMS}$ by approximating a series of maximum independent set problems with a bicriteria greedy algorithm. We also prove that it is NP-hard to approximate within a factor of $0.5584$. Finally, we show in our empirical study that $\texttt{GIST}$ outperforms state-of-the-art benchmarks for a single-shot data sampling task on ImageNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18754v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</arxiv:journal_reference>
      <dc:creator>Matthew Fahrbach, Srikumar Ramalingam, Morteza Zadimoghaddam, Sara Ahmadian, Gui Citovsky, Giulia DeSalvo</dc:creator>
    </item>
    <item>
      <title>Shortcuts and Transitive-Closure Spanners Approximation</title>
      <link>https://arxiv.org/abs/2502.08032</link>
      <description>arXiv:2502.08032v3 Announce Type: replace 
Abstract: We study polynomial-time approximation algorithms for two closely-related problems, namely computing shortcuts and transitive-closure spanners (TC spanners). For a directed unweighted graph $G=(V, E)$ and an integer $d$, a set of edges $E'\subseteq V\times V$ is called a $d$-TC spanner of $G$ if the graph $H:=(V, E')$ has (i) the same transitive-closure as $G$ and (ii) diameter at most $d.$ The set $E''\subseteq V\times V$ is a $d$-shortcut of $G$ if $E\cup E''$ is a $d$-TC spanner of $G$. Our focus is on the following $(\alpha_D, \alpha_S)$-approximation algorithm: given a directed graph $G$ and integers $d$ and $s$ such that $G$ admits a $d$-shortcut (respectively $d$-TC spanner) of size $s$, find a $(d\alpha_D)$-shortcut (resp. $(d\alpha_D)$-TC spanner) with $s\alpha_S$ edges, for as small $\alpha_S$ and $\alpha_D$ as possible.
  As our main result, we show that, under the Projection Game Conjecture (PGC), there exists a small constant $\epsilon&gt;0$, such that no polynomial-time $(n^{\epsilon},n^{\epsilon})$-approximation algorithm exists for finding $d$-shortcuts as well as $d$-TC spanners of size $s$. Previously, super-constant lower bounds were known only for $d$-TC spanners with constant $d$ and ${\alpha_D}=1$ [Bhattacharyya, Grigorescu, Jung, Raskhodnikova, Woodruff 2009]. Similar lower bounds for super-constant $d$ were previously known only for a more general case of directed spanners [Elkin, Peleg 2000]. No hardness of approximation result was known for shortcuts prior to our result.
  As a side contribution, we complement the above with an upper bound of the form $(n^{\gamma_D}, n^{\gamma_S})$-approximation which holds for $3\gamma_D + 2\gamma_S &gt; 1$ (e.g., $(n^{1/5+o(1)}, n^{1/5+o(1)})$-approximation).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08032v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parinya Chalermsook, Yonggang Jiang, Sagnik Mukhopadhyay, Danupon Nanongkai</dc:creator>
    </item>
    <item>
      <title>Solving the Correlation Cluster LP in Sublinear Time</title>
      <link>https://arxiv.org/abs/2503.20883</link>
      <description>arXiv:2503.20883v4 Announce Type: replace 
Abstract: Correlation Clustering is a fundamental and widely-studied problem in unsupervised learning and data mining. The input is a graph and the goal is to construct a clustering minimizing the number of inter-cluster edges plus the number of missing intra-cluster edges.
  CCL+24 introduced the cluster LP for Correlation Clustering, which they argued captures the problem much more succinctly than previous linear programming formulations. However, the cluster LP has exponential size, with a variable for every possible set of vertices in the input graph. Nevertheless, CCL+24 showed how to find a feasible solution for the cluster LP in time $O(n^{\text{poly}(1/\eps)})$ with objective value at most $(1+\epsilon)$ times the value of an optimal solution for the respective Correlation Clustering instance. Furthermore, they showed how to round a solution to the cluster LP, yielding a $(1.485+\eps)$-approximation algorithm for the Correlation Clustering problem.
  The main technical result of this paper is a new approach to find a feasible solution for the cluster LP with objective value at most $(1+\epsilon)$ of the optimum in time $\widetilde O(2^{\text{poly}(1/\eps)} n)$, where $n$ is the number of vertices in the graph. We also show how to implement the rounding within the same time bounds, thus achieving a fast $(1.485+\eps)$-approximation algorithm for the Correlation Clustering problem. This bridges the gap between state-of-the-art methods for approximating Correlation Clustering and the recent focus on fast algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20883v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3717823.3718181</arxiv:DOI>
      <dc:creator>Nairen Cao, Vincent Cohen-Addad, Shi Li, Euiwoong Lee, David Rasmussen Lolck, Alantha Newman, Mikkel Thorup, Lukas Vogl, Shuyi Yan, Hanwen Zhang</dc:creator>
    </item>
    <item>
      <title>LimTDD: A Compact Decision Diagram Integrating Tensor and Local Invertible Map Representations</title>
      <link>https://arxiv.org/abs/2504.01168</link>
      <description>arXiv:2504.01168v3 Announce Type: replace 
Abstract: Tensor networks serve as a powerful tool for efficiently representing and manipulating high-dimensional data in applications such as quantum physics, machine learning, and data compression. Tensor Decision Diagrams (TDDs) offer an efficient framework for tensor representation by leveraging decision diagram techniques. However, the current implementation of TDDs and other decision diagrams fail to exploit tensor isomorphisms, limiting their compression potential. This paper introduces Local Invertible Map Tensor Decision Diagrams (LimTDDs), an extension of TDDs that incorporates local invertible maps (LIMs) to achieve more compact representations. Unlike LIMDD, which uses Pauli operators for quantum states, LimTDD employs the $XP$-stabilizer group, enabling broader applicability across tensor-based tasks. We present efficient algorithms for normalization, slicing, addition, and contraction, critical for tensor network applications. Theoretical analysis demonstrates that LimTDDs achieve greater compactness than TDDs and, in best-case scenarios and for quantum state representations, offer exponential compression advantages over both TDDs and LIMDDs. Experimental results in quantum circuit tensor computation and simulation confirm LimTDD's superior efficiency. Open-source code is available at https://github.com/Veriqc/LimTDD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01168v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Hong, Aochu Dai, Dingchao Gao, Sanjiang Li, Zhengfeng Ji, Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>A Method for Generating Connected Erdos-Renyi Random Graphs</title>
      <link>https://arxiv.org/abs/2504.05907</link>
      <description>arXiv:2504.05907v2 Announce Type: replace 
Abstract: We propose a novel exact algorithm for generating connected Erdos-Renyi random graphs $G(n,p)$. The method couples the graph exploration process to an inhomogeneous Poisson random walk, which yields an exact sampler that runs in $O(n)$ time in the sparse regime $p=c/n$. We also show how the method extends to the $G(n,M)$ model via an additional acceptance-rejection step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05907v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris Chinyaev</dc:creator>
    </item>
    <item>
      <title>Finite Pinwheel Scheduling: the k-Visits Problem</title>
      <link>https://arxiv.org/abs/2507.11681</link>
      <description>arXiv:2507.11681v2 Announce Type: replace 
Abstract: Pinwheel Scheduling is a fundamental scheduling problem, in which each task $i$ is associated with a positive integer $d_i$, and the objective is to schedule one task per time slot, ensuring each task perpetually appears at least once in every $d_i$ time slots. Although conjectured to be PSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless a compact input encoding is used) or even contained in NP.
  We introduce k-Visits, a finite version of Pinwheel Scheduling, where given n deadlines, the goal is to schedule each task exactly k times. While we observe that the 1-Visit problem is trivial, we prove that 2-Visits is strongly NP-complete through a surprising reduction from Numerical 3-Dimensional Matching (N3DM). As intermediate steps in the reduction, we define NP-complete variants of N3DM which may be of independent interest. We further extend our strong NP-hardness result to a generalization of k-Visits $k\geq 2$ in which the deadline of each task may vary throughout the schedule, as well as to a similar generalization of Pinwheel Scheduling, thus making progress towards settling the complexity of Pinwheel Scheduling.
  Additionally, we prove that 2-Visits can be solved in linear time if all deadlines are distinct, rendering it one of the rare natural problems which exhibit the interesting dichotomy of being in P if their input is a set and NP-complete if the input is a multiset. We achieve this through a Turing reduction from 2-Visits to a variation of N3DM, which we call Position Matching. Based on this reduction, we also show an FPT algorithm for 2-Visits parameterized by a value related to how close the input deadlines are to each other, as well as a linear-time algorithm for instances with up to two distinct deadlines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11681v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sotiris Kanellopoulos, Christos Pergaminelis, Maria Kokkou, Euripides Markou, Aris Pagourtzis</dc:creator>
    </item>
    <item>
      <title>An Exact Solver for Submodular Knapsack Problems</title>
      <link>https://arxiv.org/abs/2507.16149</link>
      <description>arXiv:2507.16149v2 Announce Type: replace 
Abstract: We study the problem of maximizing a monotone increasing submodular function over a set of weighted elements subject to a knapsack constraint. Although this problem is NP-hard, many applications require exact solutions, as approximate solutions are often insufficient in practice. To address this need, we propose an exact branch-and-bound algorithm tailored for the submodular knapsack problem and introduce several acceleration techniques to enhance its efficiency. We evaluate these techniques on artificial instances of three benchmark problems as well as on instances derived from real-world data. We compare the proposed solver with two solvers by Sakaue and Ishihata (2018), which currently achieve the strongest performance reported in the literature, as well as with a branch-and-cut algorithm implemented using Gurobi that solves a binary linear reformulation of the submodular knapsack problem, demonstrating that our methods are highly successful.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16149v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabine M\"unch, Stephen Raach</dc:creator>
    </item>
    <item>
      <title>Unbiased Insights: Optimal Streaming Algorithms for $\ell_p$ Sampling, the Forget Model, and Beyond</title>
      <link>https://arxiv.org/abs/2508.07067</link>
      <description>arXiv:2508.07067v2 Announce Type: replace 
Abstract: We study $\ell_p$ sampling and frequency moment estimation in a single-pass insertion-only data stream. For $p \in (0,2)$, we present a nearly space-optimal approximate $\ell_p$ sampler that uses $\widetilde{O}(\log n \log(1/\delta))$ bits of space and for $p = 2$, we present a sampler with space complexity $\widetilde{O}(\log^2 n \log(1/\delta))$. This space complexity is optimal for $p \in (0, 2)$ and improves upon prior work by a $\log n$ factor. We further extend our construction to a continuous $\ell_p$ sampler, which outputs a valid sample index at every point during the stream.
  Leveraging these samplers, we design nearly unbiased estimators for $F_p$ in data streams that include forget operations, which reset individual element frequencies and introduce significant non-linear challenges. As a result, we obtain near-optimal algorithms for estimating $F_p$ for all $p$ in this model, originally proposed by Pavan, Chakraborty, Vinodchandran, and Meel [PODS'24], resolving all three open problems they posed.
  Furthermore, we generalize this model to what we call the suffix-prefix deletion model, and extend our techniques to estimate entropy as a corollary of our moment estimation algorithms. Finally, we show how to handle arbitrary coordinate-wise functions during the stream, for any $g \in \mathbb{G}$, where $\mathbb{G}$ includes all (linear or non-linear) contraction functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07067v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Honghao Lin, Hoai-An Nguyen, William Swartworth, David P. Woodruff</dc:creator>
    </item>
    <item>
      <title>Simple Algorithms for Fully Dynamic Edge Connectivity</title>
      <link>https://arxiv.org/abs/2508.07783</link>
      <description>arXiv:2508.07783v2 Announce Type: replace 
Abstract: In the fully dynamic edge connectivity problem, the input is a simple graph $G$ undergoing edge insertions and deletions, and the goal is to maintain its edge connectivity, denoted $\lambda_G$. We present two simple randomized algorithms solving this problem. The first algorithm maintains the edge connectivity in worst-case update time $\tilde{O}(n)$ per edge update, matching the known bound but with simpler analysis. Our second algorithm achieves worst-case update time $\tilde{O}(n/\lambda_G)$ and worst-case query time $\tilde{O}(n^2/\lambda_G^2)$, which is the first algorithm with worst-case update and query time $o(n)$ for large edge connectivity, namely, $\lambda_G = \omega(\sqrt{n})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07783v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yotam Kenneth-Mordoch, Robert Krauthgamer</dc:creator>
    </item>
    <item>
      <title>Competitive Online Transportation Simplified</title>
      <link>https://arxiv.org/abs/2508.08381</link>
      <description>arXiv:2508.08381v2 Announce Type: replace 
Abstract: The setting for the online transportation problem is a metric space $M$, populated by $m$ parking garages of varying capacities. Over time cars arrive in $M$, and must be irrevocably assigned to a parking garage upon arrival in a way that respects the garage capacities. The objective is to minimize the aggregate distance traveled by the cars. In 1998, Kalyanasundaram and Pruhs conjectured that there is a $(2m-1)$-competitive deterministic algorithm for the online transportation problem, matching the optimal competitive ratio for the simpler online metric matching problem. Recently, Harada and Itoh presented the first $O(m)$-competitive deterministic algorithm for the online transportation problem. Our contribution is an alternative algorithm design and analysis that we believe is simpler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08381v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephen Arndt, Benjamin Moseley, Kirk Pruhs, Marc Uetz</dc:creator>
    </item>
    <item>
      <title>On the formalization of the notion of a concurrent algorithm</title>
      <link>https://arxiv.org/abs/2410.17821</link>
      <description>arXiv:2410.17821v3 Announce Type: replace-cross 
Abstract: Previous papers give accounts of quests for satisfactory formalizations of the classical informal notion of an algorithm and the contemporary informal notion of an interactive algoritm. In this paper, an attempt is made to generalize the results of the former quest to the contemporary informal notion of a concurrent algorithm. The notion of a concurrent proto-algorithm is introduced. The thought is that concurrent algorithms are equivalence classes of concurrent proto-algorithms under an appropriate equivalence relation. Three equivalence relations are defined. Two of them are deemed to be bounds for an appropriate equivalence relation and the third is likely an appropriate one. The connection between concurrency and non-determinism in the presented setting is also addressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17821v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>Warehouse storage and retrieval optimization via clustering, dynamical systems modeling, and GPU-accelerated routing</title>
      <link>https://arxiv.org/abs/2504.20655</link>
      <description>arXiv:2504.20655v2 Announce Type: replace-cross 
Abstract: This paper introduces a warehouse optimization procedure aimed at enhancing the efficiency of product storage and retrieval. By representing product locations and order flows within a time-evolving graph structure, we employ unsupervised clustering to define and refine compact order regions, effectively reducing picking distances. We describe the procedure using a dynamic mathematical model formulated using tools from random dynamical systems theory, enabling a principled analysis of the system's behavior over time even under random operational variations. For routing within this framework, we implement a parallelized Bellman-Ford algorithm, utilizing GPU acceleration to evaluate path segments efficiently. To address scalability challenges inherent in large routing graphs, we introduce a segmentation strategy that preserves performance while maintaining tractable memory requirements. Our results demonstrate significant improvements in both operational efficiency and computational feasibility for large-scale warehouse environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20655v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Magnus Bengtsson, Jens Wittsten, Jonas Waidringer</dc:creator>
    </item>
    <item>
      <title>Faster Distributed $\Delta$-Coloring via a Reduction to MIS</title>
      <link>https://arxiv.org/abs/2508.01762</link>
      <description>arXiv:2508.01762v2 Announce Type: replace-cross 
Abstract: Recent improvements on the deterministic complexities of fundamental graph problems in the LOCAL model of distributed computing have yielded state-of-the-art upper bounds of $\tilde{O}(\log^{5/3} n)$ rounds for maximal independent set (MIS) and $(\Delta + 1)$-coloring [Ghaffari, Grunau, FOCS'24] and $\tilde{O}(\log^{19/9} n)$ rounds for the more restrictive $\Delta$-coloring problem [Ghaffari, Kuhn, FOCS'21; Ghaffari, Grunau, FOCS'24; Bourreau, Brandt, Nolin, STOC'25]. In our work, we show that $\Delta$-coloring can be solved deterministically in $\tilde{O}(\log^{5/3} n)$ rounds as well, matching the currently best bound for $(\Delta + 1)$-coloring.
  We achieve our result by developing a reduction from $\Delta$-coloring to MIS that guarantees that the (asymptotic) complexity of $\Delta$-coloring is at most the complexity of MIS, unless MIS can be solved in sublogarithmic time, in which case, due to the $\Omega(\log n)$-round $\Delta$-coloring lower bound from [BFHKLRSU, STOC'16], our reduction implies a tight complexity of $\Theta(\log n)$ for $\Delta$-coloring. In particular, any improvement on the complexity of the MIS problem will yield the same improvement for the complexity of $\Delta$-coloring (up to the true complexity of $\Delta$-coloring).
  Our reduction yields improvements for $\Delta$-coloring in the randomized LOCAL model and when complexities are parameterized by both $n$ and $\Delta$. We obtain a randomized complexity bound of $\tilde{O}(\log^{5/3} \log n)$ rounds (improving over the state of the art of $\tilde{O}(\log^{8/3} \log n)$ rounds) on general graphs and tight complexities of $\Theta(\log n)$ and $\Theta(\log \log n)$ for the deterministic, resp.\ randomized, complexity on bounded-degree graphs. In the special case of graphs of constant clique number (which for instance include bipartite graphs), we also give a reduction to the $(\Delta+1)$-coloring problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01762v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yann Bourreau, Sebastian Brandt, Alexandre Nolin</dc:creator>
    </item>
    <item>
      <title>Algorithms for Optimizing Acyclic Queries</title>
      <link>https://arxiv.org/abs/2509.14144</link>
      <description>arXiv:2509.14144v2 Announce Type: replace-cross 
Abstract: Most research on query optimization has centered on binary join algorithms like hash join and sort-merge join. However, recent years have seen growing interest in theoretically optimal algorithms, notably Yannakakis' algorithm. These algorithms rely on join trees, which differ from the operator trees for binary joins and require new optimization techniques. We propose three approaches to constructing join trees for acyclic queries. First, we give an algorithm to enumerate all join trees of an alpha-acyclic query by edits with amortized constant delay, which forms the basis of a cost-based optimizer for acyclic joins. Second, we show that the Maximum Cardinality Search algorithm by Tarjan and Yannakakis constructs a unique shallowest join tree, rooted at any relation, for a Berge-acyclic query; this tree enables parallel execution of large join queries. Finally, we prove that any connected left-deep linear plan for a gamma-acyclic query can be converted into a join tree by a simple algorithm, allowing reuse of optimization infrastructure developed for binary joins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14144v2</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Luo, Wim Van den Broeck, Guy Van den Broeck, Yisu Remy Wang</dc:creator>
    </item>
  </channel>
</rss>
