<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Jun 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Practical implementation of geometric quasi-cyclic LDPC codes</title>
      <link>https://arxiv.org/abs/2405.20524</link>
      <description>arXiv:2405.20524v1 Announce Type: new 
Abstract: We detail for the first time a complete explicit description of the quasi-cyclic structure of all classical finite generalized quadrangles. Using these descriptions we construct families of quasi-cyclic LDPC codes derived from the point-line incidence matrix of the quadrangles by explicitly calculating quasi-cyclic generator and parity check matrices for these codes. This allows us to construct parity check and generator matrices of all such codes of length up to 400000. These codes cover a wide range of transmission rates, are easy and fast to implement and perform close to Shannon's limit with no visible error floors. We also include some performance data for these codes. Furthermore, we include a complete explicit description of the quasi-cyclic structure of the point-line and point-hyperplane incidences of the finite projective and affine spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20524v1</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simeon Ball, Tom\`as Ortega</dc:creator>
    </item>
    <item>
      <title>Waveform Design for Over-the-Air Computing</title>
      <link>https://arxiv.org/abs/2405.20877</link>
      <description>arXiv:2405.20877v1 Announce Type: new 
Abstract: In response to the increasing number of devices anticipated in next-generation networks, a shift toward over-the-air (OTA) computing has been proposed. Leveraging the superposition of multiple access channels, OTA computing enables efficient resource management by supporting simultaneous uncoded transmission in the time and the frequency domain. Thus, to advance the integration of OTA computing, our study presents a theoretical analysis addressing practical issues encountered in current digital communication transceivers, such as time sampling error and intersymbol interference (ISI). To this end, we examine the theoretical mean squared error (MSE) for OTA transmission under time sampling error and ISI, while also exploring methods for minimizing the MSE in the OTA transmission. Utilizing alternating optimization, we also derive optimal power policies for both the devices and the base station. Additionally, we propose a novel deep neural network (DNN)-based approach to design waveforms enhancing OTA transmission performance under time sampling error and ISI. To ensure fair comparison with existing waveforms like the raised cosine (RC) and the better-than-raised-cosine (BRTC), we incorporate a custom loss function integrating energy and bandwidth constraints, along with practical design considerations such as waveform symmetry. Simulation results validate our theoretical analysis and demonstrate performance gains of the designed pulse over RC and BTRC waveforms. To facilitate testing of our results without necessitating the DNN structure recreation, we provide curve fitting parameters for select DNN-based waveforms as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20877v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikos G. Evgenidis, Nikos A. Mitsiou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, Panagiotis Sarigiannidis, Ioannis T. Rekanos, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>Information limits and Thouless-Anderson-Palmer equations for spiked matrix models with structured noise</title>
      <link>https://arxiv.org/abs/2405.20993</link>
      <description>arXiv:2405.20993v1 Announce Type: new 
Abstract: We consider a prototypical problem of Bayesian inference for a structured spiked model: a low-rank signal is corrupted by additive noise. While both information-theoretic and algorithmic limits are well understood when the noise is i.i.d. Gaussian, the more realistic case of structured noise still proves to be challenging. To capture the structure while maintaining mathematical tractability, a line of work has focused on rotationally invariant noise. However, existing studies either provide sub-optimal algorithms or they are limited to a special class of noise ensembles. In this paper, we establish the first characterization of the information-theoretic limits for a noise matrix drawn from a general trace ensemble. These limits are then achieved by an efficient algorithm inspired by the theory of adaptive Thouless-Anderson-Palmer (TAP) equations. Our approach leverages tools from statistical physics (replica method) and random matrix theory (generalized spherical integrals), and it unveils the equivalence between the rotationally invariant model and a surrogate Gaussian model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20993v1</guid>
      <category>cs.IT</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean Barbier, Francesco Camilli, Marco Mondelli, Yizhou Xu</dc:creator>
    </item>
    <item>
      <title>Sphere packing proper colorings of an expander graph</title>
      <link>https://arxiv.org/abs/2405.20368</link>
      <description>arXiv:2405.20368v1 Announce Type: cross 
Abstract: We introduce a new notion of error-correcting codes on $[q]^n$ where a code is a set of proper $q$-colorings of some fixed $n$-vertex graph $G$. For a pair of proper $q$-colorings $X, Y$ of $G$, we define their distance as the minimum Hamming distance between $X$ and $\sigma(Y)$ over all $\sigma \in S_q$. We then say that a set of proper $q$-colorings of $G$ is $\delta$-distinct if any pair of colorings in the set have distance at least $\delta n$.
  We investigate how one-sided spectral expansion relates to the largest possible set of $\delta$-distinct colorings on a graph. For fixed $(\delta, \lambda) \in [0, 1] \times [-1, 1]$ and positive integer $d$, let $f_{\delta, \lambda, d}(n)$ denote the maximal size of a set of $\delta$-distinct colorings of any $d$-regular graph on at most $n$ vertices with normalized second eigenvalue at most $\lambda$. We study the growth of $f$ as $n$ goes to infinity. We partially characterize regimes of $(\delta, \lambda)$ where $f$ grows exponentially, is finite, and is at most $1$, respectively. We also prove several sharp phase transitions between these regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20368v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Honglin Zhu</dc:creator>
    </item>
    <item>
      <title>Private Mean Estimation with Person-Level Differential Privacy</title>
      <link>https://arxiv.org/abs/2405.20405</link>
      <description>arXiv:2405.20405v1 Announce Type: cross 
Abstract: We study differentially private (DP) mean estimation in the case where each person holds multiple samples. Commonly referred to as the "user-level" setting, DP here requires the usual notion of distributional stability when all of a person's datapoints can be modified. Informally, if $n$ people each have $m$ samples from an unknown $d$-dimensional distribution with bounded $k$-th moments, we show that
  \[n = \tilde \Theta\left(\frac{d}{\alpha^2 m} + \frac{d }{ \alpha m^{1/2} \varepsilon} + \frac{d}{\alpha^{k/(k-1)} m \varepsilon} + \frac{d}{\varepsilon}\right)\]
  people are necessary and sufficient to estimate the mean up to distance $\alpha$ in $\ell_2$-norm under $\varepsilon$-differential privacy (and its common relaxations). In the multivariate setting, we give computationally efficient algorithms under approximate DP (with slightly degraded sample complexity) and computationally inefficient algorithms under pure DP, and our nearly matching lower bounds hold for the most permissive case of approximate DP. Our computationally efficient estimators are based on the well known noisy-clipped-mean approach, but the analysis for our setting requires new bounds on the tails of sums of independent, vector-valued, bounded-moments random variables, and a new argument for bounding the bias introduced by clipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20405v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushant Agarwal, Gautam Kamath, Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan Ullman</dc:creator>
    </item>
    <item>
      <title>Understanding Encoder-Decoder Structures in Machine Learning Using Information Measures</title>
      <link>https://arxiv.org/abs/2405.20452</link>
      <description>arXiv:2405.20452v1 Announce Type: cross 
Abstract: We present new results to model and understand the role of encoder-decoder design in machine learning (ML) from an information-theoretic angle. We use two main information concepts, information sufficiency (IS) and mutual information loss (MIL), to represent predictive structures in machine learning. Our first main result provides a functional expression that characterizes the class of probabilistic models consistent with an IS encoder-decoder latent predictive structure. This result formally justifies the encoder-decoder forward stages many modern ML architectures adopt to learn latent (compressed) representations for classification. To illustrate IS as a realistic and relevant model assumption, we revisit some known ML concepts and present some interesting new examples: invariant, robust, sparse, and digital models. Furthermore, our IS characterization allows us to tackle the fundamental question of how much performance (predictive expressiveness) could be lost, using the cross entropy risk, when a given encoder-decoder architecture is adopted in a learning setting. Here, our second main result shows that a mutual information loss quantifies the lack of expressiveness attributed to the choice of a (biased) encoder-decoder ML design. Finally, we address the problem of universal cross-entropy learning with an encoder-decoder design where necessary and sufficiency conditions are established to meet this requirement. In all these results, Shannon's information measures offer new interpretations and explanations for representation learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20452v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jorge F. Silva, Victor Faraggi, Camilo Ramirez, Alvaro Egana, Eduardo Pavez</dc:creator>
    </item>
    <item>
      <title>Universal evaluation and design of imaging systems using information estimation</title>
      <link>https://arxiv.org/abs/2405.20559</link>
      <description>arXiv:2405.20559v1 Announce Type: cross 
Abstract: Information theory, which describes the transmission of signals in the presence of noise, has enabled the development of reliable communication systems that underlie the modern world. Imaging systems can also be viewed as a form of communication, in which information about the object is "transmitted" through images. However, the application of information theory to imaging systems has been limited by the challenges of accounting for their physical constraints. Here, we introduce a framework that addresses these limitations by modeling the probabilistic relationship between objects and their measurements. Using this framework, we develop a method to estimate information using only a dataset of noisy measurements, without making any assumptions about the image formation process. We demonstrate that these estimates comprehensively quantify measurement quality across a diverse range of imaging systems and applications. Furthermore, we introduce Information-Driven Encoder Analysis Learning (IDEAL), a technique to optimize the design of imaging hardware for maximum information capture. This work provides new insights into the fundamental performance limits of imaging systems and offers powerful new tools for their analysis and design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20559v1</guid>
      <category>physics.optics</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Pinkard, Leyla Kabuli, Eric Markley, Tiffany Chien, Jiantao Jiao, Laura Waller</dc:creator>
    </item>
    <item>
      <title>Causal Distillation for Alleviating Performance Heterogeneity in Recommender Systems</title>
      <link>https://arxiv.org/abs/2405.20626</link>
      <description>arXiv:2405.20626v1 Announce Type: cross 
Abstract: Recommendation performance usually exhibits a long-tail distribution over users -- a small portion of head users enjoy much more accurate recommendation services than the others. We reveal two sources of this performance heterogeneity problem: the uneven distribution of historical interactions (a natural source); and the biased training of recommender models (a model source). As addressing this problem cannot sacrifice the overall performance, a wise choice is to eliminate the model bias while maintaining the natural heterogeneity. The key to debiased training lies in eliminating the effect of confounders that influence both the user's historical behaviors and the next behavior. The emerging causal recommendation methods achieve this by modeling the causal effect between user behaviors, however potentially neglect unobserved confounders (\eg, friend suggestions) that are hard to measure in practice. To address unobserved confounders, we resort to the front-door adjustment (FDA) in causal theory and propose a causal multi-teacher distillation framework (CausalD). FDA requires proper mediators in order to estimate the causal effects of historical behaviors on the next behavior. To achieve this, we equip CausalD with multiple heterogeneous recommendation models to model the mediator distribution. Then, the causal effect estimated by FDA is the expectation of recommendation prediction over the mediator distribution and the prior distribution of historical behaviors, which is technically achieved by multi-teacher ensemble. To pursue efficient inference, CausalD further distills multiple teachers into one student model to directly infer the causal effect for making recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20626v1</guid>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengyu Zhang, Ziqi Jiang, Jiangchao Yao, Fuli Feng, Kun Kuang, Zhou Zhao, Shuo Li, Hongxia Yang, Tat-Seng Chua, Fei Wu</dc:creator>
    </item>
    <item>
      <title>Universal Exact Compression of Differentially Private Mechanisms</title>
      <link>https://arxiv.org/abs/2405.20782</link>
      <description>arXiv:2405.20782v1 Announce Type: cross 
Abstract: To reduce the communication cost of differential privacy mechanisms, we introduce a novel construction, called Poisson private representation (PPR), designed to compress and simulate any local randomizer while ensuring local differential privacy. Unlike previous simulation-based local differential privacy mechanisms, PPR exactly preserves the joint distribution of the data and the output of the original local randomizer. Hence, the PPR-compressed privacy mechanism retains all desirable statistical properties of the original privacy mechanism such as unbiasedness and Gaussianity. Moreover, PPR achieves a compression size within a logarithmic gap from the theoretical lower bound. Using the PPR, we give a new order-wise trade-off between communication, accuracy, central and local differential privacy for distributed mean estimation. Experiment results on distributed mean estimation show that PPR consistently gives a better trade-off between communication, accuracy and central differential privacy compared to the coordinate subsampled Gaussian mechanism, while also providing local differential privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20782v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanxiao Liu, Wei-Ning Chen, Ayfer \"Ozg\"ur, Cheuk Ting Li</dc:creator>
    </item>
    <item>
      <title>Byzantine-Resilient Federated PCA and Low Rank Column-wise Sensing</title>
      <link>https://arxiv.org/abs/2309.14512</link>
      <description>arXiv:2309.14512v2 Announce Type: replace 
Abstract: This work considers two related learning problems in a federated attack prone setting: federated principal components analysis (PCA) and federated low rank column-wise sensing (LRCS). The node attacks are assumed to be Byzantine which means that the attackers are omniscient and can collude. We introduce a novel provably Byzantine-resilient communication-efficient and sampleefficient algorithm, called Subspace-Median, that solves the PCA problem and is a key part of the solution for the LRCS problem. We also study the most natural Byzantine-resilient solution for federated PCA, a geometric median based modification of the federated power method, and explain why it is not useful. Our second main contribution is a complete alternating gradient descent (GD) and minimization (altGDmin) algorithm for Byzantine-resilient horizontally federated LRCS and sample and communication complexity guarantees for it. Extensive simulation experiments are used to corroborate our theoretical guarantees. The ideas that we develop for LRCS are easily extendable to other LR recovery problems as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14512v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankit Pratap Singh, Namrata Vaswani</dc:creator>
    </item>
    <item>
      <title>Query-Based Sampling of Heterogeneous CTMCs: Modeling and Optimization with Binary Freshness</title>
      <link>https://arxiv.org/abs/2310.02223</link>
      <description>arXiv:2310.02223v2 Announce Type: replace 
Abstract: We study a remote monitoring system in which a mutually independent and heterogeneous collection of finite-state irreducible continuous time Markov chain (CTMC) based information sources is considered. In this system, a common remote monitor queries the instantaneous states of the individual CTMCs according to a Poisson process with possibly different intensities across the sources, in order to maintain accurate estimates of the original sources. \color{black}Three information freshness models are considered to quantify the accuracy of the remote estimates: fresh when equal (FWE), fresh when sampled (FWS) and fresh when close (FWC). For each of these freshness models, closed-form expressions are derived for mean information freshness for a given source. Using these expressions, optimum sampling rates for all sources are obtained so as to maximize the weighted sum freshness of the monitoring system, subject to an overall sampling rate constraint. This optimization problem leads to a water-filling solution with quadratic worst case computational complexity in the number of information sources. Numerical examples are provided to validate the effectiveness of the optimum sampling policy in comparison to several baseline sampling policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02223v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nail Akar, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Higher-Order Staircase Codes</title>
      <link>https://arxiv.org/abs/2312.13415</link>
      <description>arXiv:2312.13415v2 Announce Type: replace 
Abstract: We generalize staircase codes and tiled diagonal zipper codes, preserving their key properties while allowing each coded symbol to be protected by arbitrarily many component codewords rather than only two. This generalization which we term "higher-order staircase codes" arises from the marriage of two distinct combinatorial objects: difference triangle sets and finite-geometric nets, which have typically been applied separately to code design. We demonstrate one possible realization of these codes, obtaining powerful, high-rate, low-error-floor, and low-complexity coding schemes based on simple iterative syndrome-domain decoding of coupled Hamming component codes. We anticipate that the proposed codes could improve performance--complexity--latency tradeoffs in high-throughput communications applications, most notably fiber-optic, in which classical staircase codes and zipper codes have been applied. We consider the construction of difference triangle sets having minimum sum-of-lengths, which lead to memory optimal realizations of higher-order staircase codes. These results also enable memory reductions for early families of convolutional codes constructed from difference triangle sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13415v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohannad Shehadeh, Frank R. Kschischang, Alvin Y. Sukmadji, William Kingsford</dc:creator>
    </item>
    <item>
      <title>An Information Theory Treatment of Animal Movement Tracks</title>
      <link>https://arxiv.org/abs/2403.16290</link>
      <description>arXiv:2403.16290v4 Announce Type: replace-cross 
Abstract: Position recordings of the two-dimensional tracks of animals moving over landscapes has progressed over the past three decades from hourly to second-by-second locations. Track segmentation methods for analyzing the behavioral information in such relocation data has lagged somewhat behind, with scales of analysis currently at the sub-hourly to minute level. A new approach is needed to bring segmentation analysis down to a second-by-second level. Here, a fine-scale approach is presented that rests heavily on concepts from Shannon's Information Theory. In this paper, we first briefly review and update concepts relating to movement path segmentation. We then discuss how cluster analysis can be used to organize the smallest viable statistical movement elements (StaMEs), which are $\mu$ steps long, and to code the next level of movement elements called ``words'' that are $m \mu$ steps long. Centroids of these word clusters are identified as canonical activity modes (CAMs). Unlike current behavioral change point analysis and hidden Markov model segmentation schemes, the approach presented here allows us to provide entropy measures for movement paths, compute the coding efficiencies of derived StaMEs and CAMs, and to assess error rates in the allocation of strings of $m$ StaMEs to CAM types. In addition our approach allows us to employ the Jensen-Shannon divergence measure to assess and compare the best choices for the various parameters (number of steps in a StaME, number of StaME types, number of StaMEs in a word, number of CAM types), as well as the best clustering methods for generating segments that can then be used to interpret and predict sequences of higher order segments. The theory presented here provides another tool in our toolbox for dealing with the effects of global change on the movement and redistribution of animals across altered landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16290v4</guid>
      <category>q-bio.PE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wayne M Getz</dc:creator>
    </item>
  </channel>
</rss>
