<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Sep 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improved Approximation Guarantees and Hardness Results for MNL-Driven Product Ranking</title>
      <link>https://arxiv.org/abs/2509.09180</link>
      <description>arXiv:2509.09180v1 Announce Type: new 
Abstract: In this paper, we address open computational questions regarding the market share ranking problem, recently introduced by Derakhshan et al. (2022). Their modelling framework incorporates the extremely popular Multinomial Logit (MNL) choice model, along with a novel search-based consider-then-choose paradigm. In a nutshell, the authors devised a Pandora's-Box-type search model, where different customer segments sequentially screen through a ranked list of products, one position after the other, forming their consideration set by including all products viewed up until terminating their inspection procedure. Subsequently, a purchasing decision out of this set is made based on a joint MNL choice model.
  Our main contribution consists in devising a polynomial-time approximation scheme for the market share ranking problem, utilizing fresh technical developments and analytical ideas, in conjunction with revising the original insights of Derakhshan et al. (2022). Along the way, we introduce a black-box reduction, mapping general instances of the market share ranking problem into ``bounded ratio'' instances, showing that this result directly leads to an elegant and easily-implementable quasi-PTAS. Finally, to provide a complete computational characterization, we prove that the market share ranking problem is strongly $\mathrm{NP}$-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09180v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danny Segev, Gidi Steinberg</dc:creator>
    </item>
    <item>
      <title>Additive Approximation Schemes for Low-Dimensional Embeddings</title>
      <link>https://arxiv.org/abs/2509.09652</link>
      <description>arXiv:2509.09652v1 Announce Type: new 
Abstract: We consider the task of fitting low-dimensional embeddings to high-dimensional data. In particular, we study the $k$-Euclidean Metric Violation problem ($\textsf{$k$-EMV}$), where the input is $D \in \mathbb{R}^{\binom{n}{2}}_{\geq 0}$ and the goal is to find the closest vector $X \in \mathbb{M}_{k}$, where $\mathbb{M}_k \subset \mathbb{R}^{\binom{n}{2}}_{\geq 0}$ is the set of all $k$-dimensional Euclidean metrics on $n$ points, and closeness is formulated as the following optimization problem, where $\| \cdot \|$ is the entry-wise $\ell_2$ norm: \[
  \textsf{OPT}_{\textrm{EMV}} = \min_{X \in \mathbb{M}_{k} } \Vert D - X \Vert_2^2\,.\] Cayton and Dasgupta [CD'06] showed that this problem is NP-Hard, even when $k=1$. Dhamdhere [Dha'04] obtained a $O(\log(n))$-approximation for $\textsf{$1$-EMV}$ and leaves finding a PTAS for it as an open question (reiterated recently by Lee [Lee'25]). Although $\textsf{$k$-EMV}$ has been studied in the statistics community for over 70 years, under the name "multi-dimensional scaling", there are no known efficient approximation algorithms for $k &gt; 1$, to the best of our knowledge.
  We provide the first polynomial-time additive approximation scheme for $\textsf{$k$-EMV}$. In particular, we obtain an embedding with objective value $\textsf{OPT}_{\textrm{EMV}} + \varepsilon \Vert D\Vert_2^2$ in $(n\cdot B)^{\mathsf{poly}(k, \varepsilon^{-1})}$ time, where each entry in $D$ can be represented by $B$ bits. We believe our algorithm is a crucial first step towards obtaining a PTAS for $\textsf{$k$-EMV}$. Our key technical contribution is a new analysis of correlation rounding for Sherali-Adams / Sum-of-Squares relaxations, tailored to low-dimensional embeddings. We also show that our techniques allow us to obtain additive approximation schemes for two related problems: a weighted variant of $\textsf{$k$-EMV}$ and $\ell_p$ low-rank approximation for $p&gt;2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09652v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashanti Anderson, Ainesh Bakshi, Samuel B. Hopkins</dc:creator>
    </item>
    <item>
      <title>Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications</title>
      <link>https://arxiv.org/abs/2509.08911</link>
      <description>arXiv:2509.08911v1 Announce Type: cross 
Abstract: The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning algorithm with numerous applications. Applied to the matrix version of the Learning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex, it is well known that MMWU achieves the minimax-optimal regret bound of $O(\sqrt{T\log d})$, where $T$ is the time horizon. In this paper, we present an improved algorithm achieving the instance-optimal regret bound of $O(\sqrt{T\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret, $I_d$ is the identity matrix, and $S(\cdot||\cdot)$ denotes the quantum relative entropy. Furthermore, our algorithm has the same computational complexity as MMWU, indicating that the improvement in the regret bound is ``free''.
  Technically, we first develop a general potential-based framework for matrix LEA, with MMWU being its special case induced by the standard exponential potential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace inequality built on a Laplace transform technique, which allows the application of general potential functions beyond exponential to matrix LEA. Our algorithm is finally induced by an optimal potential function from the vector LEA problem, based on the imaginary error function.
  Complementing the above, we provide a memory lower bound for matrix LEA, and explore the applications of our algorithm in quantum learning theory. We show that it outperforms the state of the art for learning quantum states corrupted by depolarization noise, random quantum states, and Gibbs states. In addition, applying our algorithm to linearized convex losses enables predicting nonlinear quantum properties, such as purity, quantum virtual cooling, and R\'{e}nyi-$2$ correlation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08911v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <category>stat.ML</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiyuan Gong, Tongyang Li, Xinzhao Wang, Zhiyu Zhang</dc:creator>
    </item>
    <item>
      <title>Maximizing social welfare among EF1 allocations at the presence of two types of agents</title>
      <link>https://arxiv.org/abs/2509.09641</link>
      <description>arXiv:2509.09641v1 Announce Type: cross 
Abstract: We study the fair allocation of indivisible items to $n$ agents to maximize the utilitarian social welfare, where the fairness criterion is envy-free up to one item and there are only two different utility functions shared by the agents. We present a $2$-approximation algorithm when the two utility functions are normalized, improving the previous best ratio of $16 \sqrt{n}$ shown for general normalized utility functions; thus this constant ratio approximation algorithm confirms the APX-completeness in this special case previously shown APX-hard. When there are only three agents, i.e., $n = 3$, the previous best ratio is $3$ shown for general utility functions, and we present an improved and tight $\frac 53$-approximation algorithm when the two utility functions are normalized, and a best possible and tight $2$-approximation algorithm when the two utility functions are unnormalized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09641v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaxuan Ma, Yong Chen, Guangting Chen, Mingyang Gong, Guohui Lin, An Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal Single-Choice Prophet Inequalities from Samples</title>
      <link>https://arxiv.org/abs/1911.07945</link>
      <description>arXiv:1911.07945v2 Announce Type: replace 
Abstract: We study the single-choice Prophet Inequality problem when the gambler is given access to samples. We show that the optimal competitive ratio of $1/2$ can be achieved with a single sample from each distribution. When the distributions are identical, we show that for any constant $\varepsilon &gt; 0$, $O(n)$ samples from the distribution suffice to achieve the optimal competitive ratio ($\approx 0.745$) within $(1+\varepsilon)$, resolving an open problem of Correa, D\"utting, Fischer, and Schewior.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.07945v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviad Rubinstein, Jack Z. Wang, S. Matthew Weinberg</dc:creator>
    </item>
    <item>
      <title>SplineSketch: Even More Accurate Quantiles with Error Guarantees</title>
      <link>https://arxiv.org/abs/2504.01206</link>
      <description>arXiv:2504.01206v2 Announce Type: replace 
Abstract: Space-efficient streaming estimation of quantiles in massive datasets is a fundamental problem with numerous applications in data monitoring and analysis. While theoretical research led to optimal algorithms, such as the Greenwald-Khanna algorithm or the KLL sketch, practitioners often use other sketches that perform significantly better in practice but lack theoretical guarantees. Most notably, the widely used $t$-digest has unbounded worst-case error.
  In this paper, we seek to get the best of both worlds. We present a new quantile summary, SplineSketch, for numeric data, offering near-optimal theoretical guarantees, namely uniformly bounded rank error, and outperforming $t$-digest by a factor of 2-20 on a range of synthetic and real-world datasets. To achieve such performance, we develop a novel approach that maintains a dynamic subdivision of the input range into buckets while fitting the input distribution using monotone cubic spline interpolation. The core challenge is implementing this method in a space-efficient manner while ensuring strong worst-case guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01206v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>stat.CO</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksander {\L}ukasiewicz, Jakub T\v{e}tek, Pavel Vesel\'y</dc:creator>
    </item>
    <item>
      <title>Nyldon Factorization of Thue-Morse Words and Fibonacci Words</title>
      <link>https://arxiv.org/abs/2507.23659</link>
      <description>arXiv:2507.23659v2 Announce Type: replace 
Abstract: The Nyldon factorization is a string factorization that is a non-decreasing product of Nyldon words. Nyldon words and Nyldon factorizations are recently defined combinatorial objects inspired by the well-known Lyndon words and Lyndon factorizations. In this paper, we investigate the Nyldon factorization of several words. First, we fully characterize the Nyldon factorizations of the (finite) Fibonacci and the (finite) Thue-Morse words. Moreover, we show that there exists a non-decreasing product of Nyldon words that is a factorization of the infinite Thue-Morse word.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23659v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaisei Kishi, Kazuki Kai, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai</dc:creator>
    </item>
    <item>
      <title>Sharp Online Hardness for Large Balanced Independent Sets</title>
      <link>https://arxiv.org/abs/2508.20785</link>
      <description>arXiv:2508.20785v2 Announce Type: replace 
Abstract: We study the algorithmic problem of finding large $\gamma$-balanced independent sets in dense random bipartite graphs; an independent set is $\gamma$-balanced if a $\gamma$ proportion of its vertices lie on one side of the bipartition. In the sparse regime, Perkins and Wang established tight bounds within the low-degree polynomial (LDP) framework, showing a factor-$1/(1-\gamma)$ statistical-computational gap via the Overlap Gap Property (OGP) framework tailored for stable algorithms. However, these techniques do not appear to extend to the dense setting. For the related large independent set problem in dense random graph, the best known algorithm is an online greedy procedure that is inherently unstable, and LDP algorithms are conjectured to fail even in the "easy" regime where greedy succeeds. We show that the largest $\gamma$-balanced independent set in dense random bipartite graphs has size $\alpha:=\frac{\log_b n}{\gamma(1-\gamma)}$ whp, where $n$ is the size of each bipartition, $p$ is the edge probability, and $b=1/(1-p)$. We design an online algorithm that achieves $(1-\epsilon)(1-\gamma)\alpha$ whp for any $\epsilon&gt;0$. We complement this with a sharp lower bound, showing that no online algorithm can achieve $(1+\epsilon)(1-\gamma)\alpha$ with nonnegligible probability. Our results suggest that the same factor-$1/(1-\gamma)$ gap is also present in the dense setting, supporting its conjectured universality. While the classical greedy procedure on $G(n,p)$ is straightforward, our algorithm is more intricate: it proceeds in two stages, incorporating a stopping time and suitable truncation to ensure that $\gamma$-balancedness-a global constraint-is met despite operating with limited information. Our lower bound utilizes the OGP framework; we build on a recent refinement of this framework for online models and extend it to the bipartite setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20785v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Dhawan, Eren C. K{\i}z{\i}lda\u{g}, Neeladri Maitra</dc:creator>
    </item>
    <item>
      <title>Compressibility Measures and Succinct Data Structures for Piecewise Linear Approximations</title>
      <link>https://arxiv.org/abs/2509.07827</link>
      <description>arXiv:2509.07827v3 Announce Type: replace 
Abstract: We study the problem of deriving compressibility measures for Piecewise Linear Approximations (PLAs), i.e., error-bounded approximations of a set of two-dimensional increasing data points using a sequence of segments. Such approximations are widely used tools in implementing many learned data structures, which mix learning models with traditional algorithmic design blocks to exploit regularities in the underlying data distribution, providing novel and effective space-time trade-offs. We introduce the first lower bounds to the cost of storing PLAs in two settings, namely compression and indexing. We then compare these compressibility measures to known data structures, and show that they are asymptotically optimal up to a constant factor from the space lower bounds. Finally, we design the first data structures for the aforementioned settings that achieve the space lower bounds plus small additive terms, which turn out to be succinct in most practical cases. Our data structures support the efficient retrieval and evaluation of a segment in the (compressed) PLA for a given $x$-value, which is a core operation in any learned data structure relying on PLAs. As a result, our paper offers the first theoretical analysis of the maximum compressibility achievable by PLA-based learned data structures, and provides novel storage schemes for PLAs offering strong theoretical guarantees while also suggesting simple and efficient practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07827v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Ferragina, Filippo Lari</dc:creator>
    </item>
    <item>
      <title>A Dynamic, Self-balancing k-d Tree</title>
      <link>https://arxiv.org/abs/2509.08148</link>
      <description>arXiv:2509.08148v2 Announce Type: replace 
Abstract: The original description of the k-d tree recognized that rebalancing techniques, used for building an AVL tree or a red-black tree, are not applicable to a k-d tree, because these techniques involve cyclic exchange of tree nodes, which destroys the sorted order of the k-d tree. For this reason, a static, balanced k-d tree is often built from all of the k-dimensional data en masse. However, it is possible to build a dynamic k-d tree that self-balances when necessary after insertion or deletion of each k-dimensional datum. This article describes insertion, deletion, and rebalacing algorithms for a dynamic, self-balancing k-d tree, and measures their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08148v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Russell A. Brown</dc:creator>
    </item>
  </channel>
</rss>
