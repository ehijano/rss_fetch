<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Design and Implementation of a Low-Power Low-Noise Biopotential Amplifier in 28 nm CMOS Technology with a Compact Die-Area of 2500~\si{\micro\meter\squared}</title>
      <link>https://arxiv.org/abs/2406.17779</link>
      <description>arXiv:2406.17779v1 Announce Type: new 
Abstract: This paper presents a compact low-power, low-noise bioamplifier for multi-channel electrode arrays, aimed at recording action potentials. The design we put forth attains a notable decrease in both size and power consumption. This is achieved by incorporating an active lowpass filter that doesn't rely on bulky DC-blocking capacitors, and by utilizing the TSMC 28 nm HPC CMOS technology. This paper presents extensive simulation results of noise and results from measured performance. With a mid-band gain of 58 dB, a -~3~dB bandwidth of 7 kHz (from 150 Hz to 7.1 kHz), and an input-referred noise of 15.8~\si{\micro\volt_{rms}} corresponding to a NEF of 12. The implemented design achieves a favourable trade-off between noise, area, and power consumption, surpassing previous findings in terms of size and power. The amplifier occupies the smallest area of 2500~\si{\micro\meter\squared} and consumes only 3.4~\si{\micro\watt} from a 1.2 V power supply corresponding to a power efficiency factor of 175 and an area efficiency factor of 0.43, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17779v1</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esmaeil Ranjbar Koleibi, Konin Koua, William Lemaire, Maher Benhouria, Marwan Besrour, Takwa Omrani, J\'er\'emy M\'enard, Louis-Philippe Gauthier, Montassar Dridi, Mahziar Serri Mazandarani, Benoit Gosselin, S\'ebastien Royand R\'ejean Fontaine</dc:creator>
    </item>
    <item>
      <title>Strong, but not weak, noise correlations are beneficial for population coding</title>
      <link>https://arxiv.org/abs/2406.18439</link>
      <description>arXiv:2406.18439v1 Announce Type: new 
Abstract: Neural correlations play a critical role in sensory information coding. They are of two kinds: signal correlations, when neurons have overlapping sensitivities, and noise correlations from network effects and shared noise. It is commonly thought that stimulus and noise correlations should have opposite signs to improve coding. However, experiments from early sensory systems and cortex typically show the opposite effect, with many pairs of neurons showing both types of correlations to be positive and large. Here, we develop a theory of information coding by correlated neurons which resolves this paradox. We show that noise correlations are always beneficial if they are strong enough. Extensive tests on retinal recordings under different visual stimuli confirm our predictions. Finally, using neuronal recordings and modeling, we show that for high dimensional stimuli noise correlation benefits the encoding of fine-grained details of visual stimuli, at the expense of large-scale features, which are already well encoded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18439v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Mahuas, Thomas Buffet, Olivier Marre, Ulisse Ferrari, Thierry Mora</dc:creator>
    </item>
    <item>
      <title>A principled framework to assess information theoretical fitness of brain functional sub-circuits</title>
      <link>https://arxiv.org/abs/2406.18531</link>
      <description>arXiv:2406.18531v1 Announce Type: new 
Abstract: In systems and network neuroscience, many common practices in brain connectomic analysis are often not properly scrutinized. One such practice is mapping a predetermined set of sub-circuits, like functional networks (FNs), onto subjects' functional connectomes (FCs) without adequately assessing the information-theoretic appropriateness of the partition. Another practice that goes unchallenged is thresholding weighted FCs to remove spurious connections without justifying the chosen threshold. This paper leverages recent theoretical advances in Stochastic Block Models (SBMs) to formally define and quantify the information-theoretic fitness (e.g., prominence) of a predetermined set of FNs when mapped to individual FCs under different fMRI task conditions. Our framework allows for evaluating any combination of FC granularity, FN partition, and thresholding strategy, thereby optimizing these choices to preserve important topological features of the human brain connectomes. Our results pave the way for the proper use of predetermined FNs and thresholding methods and provide insights for future research in individualized parcellations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18531v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duy Duong-Tran, Nghi Nguyen, Shizhuo Mu, Jiong Chen, Jingxuan Bao, Frederick Xu, Sumita Garai, Jose Cadena-Pico, Alan David Kaplan, Tianlong Chen, Yize Zhao, Li Shen, Joaqu\'in Go\~ni</dc:creator>
    </item>
    <item>
      <title>Applications of interpretable deep learning in neuroimaging: a comprehensive review</title>
      <link>https://arxiv.org/abs/2406.17792</link>
      <description>arXiv:2406.17792v1 Announce Type: cross 
Abstract: Clinical adoption of deep learning models has been hindered, in part, because the black-box nature of neural networks leads to concerns regarding their trustworthiness and reliability. These concerns are particularly relevant in the field of neuroimaging due to the complex brain phenotypes and inter-subject heterogeneity often encountered. The challenge can be addressed by interpretable deep learning (iDL) methods that enable the visualisation and interpretation of the inner workings of deep learning models. This study systematically reviewed the literature on neuroimaging applications of iDL methods and critically analysed how iDL explanation properties were evaluated. Seventy-five studies were included, and ten categories of iDL methods were identified. We also reviewed five properties of iDL explanations that were analysed in the included studies: biological validity, robustness, continuity, selectivity, and downstream task performance. We found that the most popular iDL approaches used in the literature may be sub-optimal for neuroimaging data, and we discussed possible future directions for the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17792v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lindsay Munroe, Mariana da Silva, Faezeh Heidari, Irina Grigorescu, Simon Dahan, Emma C. Robinson, Maria Deprez, Po-Wah So</dc:creator>
    </item>
    <item>
      <title>Embedded Silicon-Organic Integrated Neuromorphic System</title>
      <link>https://arxiv.org/abs/2210.12064</link>
      <description>arXiv:2210.12064v2 Announce Type: replace 
Abstract: The development of artificial intelligence (AI) and robotics are both based on the tenet of "science and technology are people-oriented", and both need to achieve efficient communication with the human brain. Based on multi-disciplinary research in systems neuroscience, computer architecture, and functional organic materials, we proposed the concept of using AI to simulate the operating principles and materials of the brain in hardware to develop brain-inspired intelligence technology, and realized the preparation of neuromorphic computing devices and basic materials. We simulated neurons and neural networks in terms of material and morphology, using a variety of organic polymers as the base materials for neuroelectronic devices, for building neural interfaces as well as organic neural devices and silicon neural computational modules. We assemble organic artificial synapses with simulated neurons from silicon-based Field-Programmable Gate Array (FPGA) into organic artificial neurons, the basic components of neural networks, and later construct biological neural network models based on the interpreted neural circuits. Finally, we also discuss how to further build neuromorphic devices based on these organic artificial neurons, which have both a neural interface friendly to nervous tissue and interact with information from real biological neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12064v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shengjie Zheng, Ling Liu, Junjie Yang, Jianwei Zhang, Tao Su, Bin Yue, Xiaojian Li</dc:creator>
    </item>
    <item>
      <title>Generating synthetic light-adapted electroretinogram waveforms using Artificial Intelligence to improve classification of retinal conditions in under-represented populations</title>
      <link>https://arxiv.org/abs/2404.11842</link>
      <description>arXiv:2404.11842v2 Announce Type: replace 
Abstract: Visual electrophysiology is often used clinically to determine functional changes associated with retinal or neurological conditions. The full-field flash electroretinogram (ERG) assesses the global contribution of the outer and inner retinal layers initiated by the rods and cone pathways depending on the state of retinal adaptation. Within clinical centers reference normative data are used to compare with clinical cases that may be rare or underpowered within a specific demographic. To bolster either reference or case datasets the application of synthetic ERG waveforms may offer benefits to disease classification and case-control studies. In this study and as a proof of concept, artificial intelligence (AI) to generate synthetic signals using Generative Adversarial Networks is deployed to up-scale male participants within an ISCEV reference dataset containing 68 participants, with waveforms from the right and left eye. Random Forest Classifiers further improved classification for sex within the group from a balanced accuracy of 0.72 to 0.83 with the added synthetic male waveforms. This is the first study to demonstrate the generation of synthetic ERG waveforms to improve machine learning classification modelling with electroretinogram waveforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11842v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikhail Kulyabin, Aleksei Zhdanov, Andreas Maier, Lynne Loh, Jose J. Estevez, Paul A. Constable</dc:creator>
    </item>
  </channel>
</rss>
